TALN 2010, Montréal, I9-23juillet 2010

Apprentissage non supervisé pour la traduction automatique :
application a un couple de langues peu doté

Do Thi Ngoc Diep1’2, Laurent Besacierl, Eric Castelliz

(1) Laboratoire LIG, GETALP, Grenoble, France
(2) Centre MICA, CNRSfUMI—2954, Hanoi, Vietnam
thi—ngoc—diep.do@imag.fr

Résumé Cet article présente une méthode non-supervisée pour extraire des paires de phrases paralleles a
partir d’un corpus comparable. Un systeme de traduction automatique est utilisé pour exploiter le corpus
comparable et détecter les paires de phrases paralleles. Un processus itératif est exécuté non seulement pour
augmenter le nombre de paires de phrases paralleles extraites, mais aussi pour améliorer la qualité globale du
systeme de traduction. Une comparaison avec une méthode seIr1i-supervisée est présentée également. Les
experiences montrent que la méthode non-supervisée peut étre réellement appliquée dans le cas 011 on manque
de données paralleles. Bien que les experiences préliminaires soient menées sur la traduction frangais-anglais,
cette méthode non-supervisée est également appliquée avec succes a un couple de langues peu doté :
vietnamien-frangais.

Abstract This paper presents an unsupervised method for extracting parallel sentence pairs from a
comparable corpus. A translation system is used to mine and detect the parallel sentence pairs from the
comparable corpus. An iterative process is implemented not only to increase the number of extracted parallel
sentence pairs but also to improve the overall quality of the translation system. A comparison between this
unsupervised method and a semi-supervised method is also presented. The experiments conducted show that
the unsupervised method can be really applied in cases where parallel data are not available. While preliminary
experiments are conducted on French-English translation, this unsupervised method is also applied
successfully to a low e-resourced language pair (Vietnamese-French).

Mots-clés 2 apprentissage non-supervisé, systeme de traduction automatique, corpus comparable, paires
de phrases paralleles

Keywords: unsupervised traiI1ing, machine translation, comparable corpus, parallel sentence pairs

DO TI-II NGOC DIEP, LAURENT BESACIER, ERIC CASTELLI

1 Introduction

Les systemes de traduction automatique (TA) obtiennent aujourd’hui de bons résultats sur certains couples
de langues comme anglais-francais, anglais-italien, anglais-espagnol, etc. Il existe de nombreuses approches
de TA : des approches expertes fondées sur des regles linguistiques, des approches empiriques fondées sur
l’apprentissage automatique a partir de corpus bilingues, ainsi que des approches hybrides. Toutefois, la
recherche sur la TA pour des couples de langues dits « peu dotés » doit faire face au déﬁ du manque de
données. La TA probabiliste est fondée sur l’apprentissage de modeles a partir de grands corpus paralleles
bilingues pour les langues source et cible. Ensuite, ces modeles et un module de recherche sont utilisés pour
décoder la meilleure hypothese de traduction a partir d’un texte inconnu (Brown et al., 1993 ; Koehn et al.,
2003). Ainsi un grand corpus parallele bilingue est préalablement nécessaire. Un tel corpus n’est pas
toujours disponible en grande quantité, surtout pour les langues peu dotées. Les méthodes les plus
communes pour construire des corpus paralleles consistent en des méthodes automatiques qui collectent des
paires de phrases paralleles a partir du Web (Resnik, Smith, 2003 ; Kilgarriff, Grefenstette, 2003), ou des
méthodes d’alignement qui extraient des documents/phrases paralleles a partir des deux corpus monolingues
(Gale, Church, 1993 ; Patry, Langlais, 2005). Il y a aussi les méthodes d’extraction de paires de phrases
paralleles a partir d’un corpus comparable (Zhao and Vogel, 2002; Fung and Cheung, 2004; Munteanu and
Marcu, 2006). Ces méthodes nécessitent un corpus parallele initial pour construire le premier systeme de
TA qui sera utilisé dans le processus d’extraction (voir plus de détails dans la section 2.1). Nous supposons
que dans le cas d’un couple de langues peu doté, méme un petit corpus parallele n’est pas forcément
disponible pour développer le systeme de TA initial. La question que nous nous posons alors est : est-ce
qu’un processus totalement non-supervisé, initialisé a partir d’un corpus comparable particulierement bruité,
permet d’apporter des solutions au probleme du manque de données paralleles ?

Cet article présente une méthode d’extraction entierement non-supervisée, qui est comparée avec une
méthode semi-supervisée. Les premiers résultats montrent que la méthode non-supervisée peut étre
réellement appliquée dans le cas du manque de données paralleles. La section 2 déﬁnit les deux méthodes
d’extraction de paires de phrases paralleles a partir d’un corpus comparable : la méthode seIr1i-supervisée et
la méthode totalement non-supervisée. La section 3 présente nos expériences et nos résultats obtenus
préalablement pour la méthode non-supervisée sur des données paralleles bruitées anglais - francais. La
section suivante présente une application de cette méthode sur un corpus comparable d’un couple de
langues peu doté : vietnamien - francais. La derniere section donne quelques conclusions et perspectives.

2 Apprentissage semi-supervisé et non-supervisé

2.1 Méthode d’apprentissage semi-supervisée

Un corpus comparable contient des données qui ne sont pas paralleles (des phrases non-alignées), mais «
étroitement liés par les memes contenus » (Zhao, Vogel, 2002 ; Fung, Cheung, 2004). Il contient « des
niveaux de parallélisme différents, tels que des mots, des chaines de mots, des phrases... » (Kumano et al.,
2007). Pour extraire des données paralleles a partir d’un corpus comparable, (Zhao, Vogel, 2002)
proposent un critere de maximum de vraisemblance qui combine des modeles de longueur des phrases et un
modele de lexique extrait d’un corpus parallele aligné existant. Un processus itératif est appliqué pour ré-
apprendre le modele de lexique en utilisant les données extraites. (Munteanu, Marcu, 2006) présentent une
méthode d’extraction des fragments paralleles de phrases. Chaque document en langue source est traduit
vers la langue cible, en utilisant un dictionnaire bilingue. Le document dans la langue cible qui correspond a
cette traduction est extrait. Des paires de phrases et de fragments paralleles sont extraits a partir de cette
paire de document en utilisant un lexique de traduction. (Abdul-Rauf, Schwenk, 2009) présentent une
technique similaire a celle de (Munteanu, Marcu, 2006), mais un systeme de TA statistique est utilisé au lieu

APPRENTISSAGE NON SUPERVISE POUR LA TRADUCTION AUTOMATIQUE
APPLICATION A UN COUPLE DE LANGUES PEU DOTE

d’un dictionnaire bilingue, et une métrique d’évaluation (TER) est utilisée pour décider du degré de
parallélisme entre les phrases. (Sarikaya et al, 2009) présente une méthode seIr1i-supervisée avec des
itérations lors desquelles les données extraites sont ajoutées au corpus initial parallele pour re-construire le
systeme de traduction. Toutes ces méthodes sont présentées comme des méthodes efﬁcaces pour extraire
des phrases/fragments paralleles a partir d’un corpus comparable.

Dans le contexte de notre travail, on considere que les termes corpus « comparable » et corpus « parallele
bruité » ont un sens équivalent, car un corpus « parallele bruité » peut étre extrait a partir d’un corpus «
comparable » en utilisant un module de recherche d’information (RI) fondé sur des caractéristiques de base
comme la date de publication, la longueur de phrases, etc. La proposition d’approches de RI avancées pour
l’eXploitation le corpus comparable est en dehors du champ de cet article dont le but est précisément de
proposer un processus itératif permettant de s’affranchir de méthodes de RI avancées pour l’eXtraction de
corpus paralleles.

2.2 Méthode d’apprentissage non-supervisée

Les méthodes presentées ci-dessus peuvent étre considérées comme des méthodes seIr1i-supervisées, qui ont
besoin d’un corpus parallele initial (ou au moins un dictionnaire bilingue) pour construire le systeme
d’extraction. Nous supposons que dans le cas des langues peu dotées, ce corpus parallele, méme de petite
taille, n’est pas disponible. Donc, nous proposons ici une méthode totalement non-supervisée ou le point de
départ est un corpus comparable bruité. Un des objectifs de ce travail est donc de voir si on peut construire
un systeme de TA acceptable a partir d’un tel point de départ (corpus comparable bruité, versus corpus
vraiment parallele). La ﬁgure 1 illustre la difference entre notre déﬁnition des deux méthodes. Dans le cas
de l’apprentissage non-supervisé, un systeme de TA statistique S0 (le systeme de référence) est construit a
partir d’un corpus comparable (C2) (a l'inverse, dans la méthode semi-supervisée, le systeme S0 est construit
a partir d’un corpus parallele (C1)). Bien sur, la qualité de S0 n’est pas bonne dans le cas non-supervisé.
Nous proposons d’utiliser ce systeme S0 pour exploiter un autre corpus comparable bruité (D), et aussi
pour améliorer la qualité globale du systeme de traduction. Le cote source du corpus D est traduit par le
systeme S0. La sortie est en suite comparée avec le cote cible du corpus D. Une métrique d’évaluation est
calculée pour chaque paire de phrases. Plusieurs métriques d’évaluation sont envisagées et comparées pour
déterminer laquelle est le plus appropriée : BLEU (Papineni et al., 2002), NIST (Doddington, 2002), TER
(Snover et al., 2006) et une modiﬁcation de PER : PER* (voir détails dans la section 3.3). Une paire est
considérée comme une paire parallele si la métrique d’évaluation est plus grande (avec les métriques BLEU,
NIST, PER*) ou moins grande (avec la métrique TER) qu’un certain seuil.

Corpus paralléle : C1 Semi—supervisé Corpus co parable : C2 Non—supervisé
Donnée l (3) Dmlnée (b)
corfparable : D l C0 Parable 5 D . ~ ,

TI-aduire et Dgnnee  Tradulre Ct DOPHCC
SMTO  paraHele _ 0 ﬁltrer par parallele
métrique métrique

Figure 1 : Méthode de l’apprentissage semi supervisée (a) et non-supervisée (b)

Les paires de phrases extraites sont ensuite combinées avec le systeme de référence S0 selon plusieurs
manieres pour créer un nouveau systeme de traduction. Un processus itératif est effectué qui va re-traduire
le cote source par le nouveau systeme, re-calculer les métriques d’évaluation et re-ﬁltrer les paires de
phrases paralleles. Nous espérons que chaque itération augmente non seulement le nombre de paires de
phrases paralleles extraites, mais améliore également la qualité du systeme de traduction. Pour utiliser les
données extraites, quatre combinaisons différentes sont proposées :

Do TH1 NGOC DIEP, LAURENT BESACIER, ERIC CASTELLI

0 W1 : le systeme de TA a la iemc etape est entraine par un corpus consistant en C2 etEi_1 (les donnees
extraites a la derniere iteration) ; E0 etant les donnees extraites lorsque le systeme de TA est entraine par
C2 seulement (S0).

0 W2 : le systeme de TA a la iemc etape est entraine par un corpus comprenant C2 et E0 + E1 +...+ EH
(les donnees sont extraites aux iterations precedentes).

0 W3 : a la iem‘ iteration, une nouvelle table de traduction est construite basee sur des donnees
extraites EH. Le systeme de TA decode en utilisant deux tables de traduction combinee dans un modele
log-lineaire : S0 et cette nouvelle table. Les poids associes a chacune des tables sont les memes.

0 W4 : la meme combinaison que W3, mais la table de traduction de S0 et la nouvelle table sont
combinees en donnant plus d’importance aux donnees extraites EH (par exemple 1:2).

3 Experiences préliminaires sur des données frangais-anglais

Dans cette section, nous presentons des experiences preliminaires concernant la methode non-supervisee,

qui est comparee a une approche seIr1i-supervisee. Deux systemes ont ete construits, un fonde sur la
methode semi-supervisee (Sysl), un autre base sur la methode non-supervisee (Sys2).

3.1 Preparation des données

Aﬁn de controler la precision et le rappel de la methode d’eXtraction, un corpus comparable « artiﬁciel » a
ete simule en assemblant des paires de phrases paralleles et non paralleles, ainsi ces paires sont marquees en
vue de l’estiInation de la precision et du rappel du processus d’extraction. Nous avons choisi le couple de
langues francais-anglais pour ces experiences preliminaires. Les paires de phrases paralleles ont ete choisies
dans le corpus Europarl, version 3 (Koehn, 2005). Le corpus comparable « artiﬁciel » a ete construit par
l’introduction d’un grand nombre de paires de phrases non-paralleles dans les donnees (environ 50%) (donc
il peut etre considere comme un corpus parallele bruite). Pour etre comparable avec le cas reel traite dans la
section 4 (pour les langues peu dotees), la taille des donnees experimentales a ete choisie relativement
petite. Ainsi, le corpus C1 (cas semi-supervise, voir ﬁg.1a) ne contient que 50K paires de phrases paralleles
correctes. Le corpus C2 (cas non supervise, voir ﬁg.1b) contient 25K paires de phrases paralleles correctes
(retirees a partir de C1) et 25K paires de phrases non-paralleles. Le corpus D, donnees d’entree pour le
processus d’eXtraction, a ete construit, quant a lui, avec 10K paires de phrases paralleles correctes et 10K
paires de phrases non-paralleles, differentes des paires de phrases de C1 et C2.

3.2 Construction du systéme

Les deux systemes Sysl et Sys2 ont ete construits en utilisant l’outil Moses (Koehn et al., 2007). Nous
avons utilise les parametres par defaut de Moses et le parametrage peut etre resume comme suit :

0 L’outil GIZA++ (Och, Ney, 2003) a ete utilise pour l’a1ignement au niveau des mots, l’option pour
l’eXtraction des sequences est de type « grow-diag-final-and »

0 14 caracteristiques ont ete utilisees dans le modele log-lineaire : le modele de distorsion (6
caracteristiques), un modele de langage, les probabilites de traduction bidirectionnelle au niveau
sequence (2 caracteristiques), les probabilites associees au lexique bilingue mots (2 caracteristiques),
une penalite de phrase, une penalite de mot et une penalite de distance de distorsion.

0 Le modele de langage cible (3-gramme) a ete construit a partir seulement de la partie anglaise du
corpus Europarl entier en utilisant l’outil SRILM (Stolcke, 2002).

0 Les modeles de traduction initiaux ont ete construits a partir des corpus C1 et C2, pour les
methodes semi-supervisee et non supervisee respectivement.

APPRENTISSAGE NON SUPERVISE POUR LA TRADUCTION AUTOMAT‘IQUE
APPLICATION A UN COUPLE DE LANGUES PEU DOTE

3.3 Commencer a partir d’un corpus paralléle ou comparable?

La premiere question a laquelle nous voulons répondre tout d’abord est de savoir si le systeme de TA basé
sur un corpus parallele bruité ou comparable peut étre utilisé pour ﬁltrer les données d’entrée aussi
efﬁcacement que le systeme de TA basé sur un corpus parallele. Pour répondre a cette question, le c6té
francais du corpus D a été traduit par les Sysl et Sys2. Ensuite, les traductions ont été comparées avec le
c6té anglais du corpus D. Quatre métriques d’évaluation ont été utilisées pour cette comparaison : BLEU,
NIST, T ER et PER*. Notre métrique PER* (la modiﬁcation de PER - position-independent word error
rate (Tilhnann et al., 1997)) est calculée en se fondant sur la similitude, alors que le PER mesure une erreur

(les mots différents) entre les hypotheses et la référence. Ainsi la formule de notre PER* est la suivante :
2 * nombre de mots identiques

‘PER = Iongueur de la hypothése + Iongueur de la référence

Ensuite, les distributions des scores d’évaluation pour les paires de phrases paralleles correctes et les paires
de phrases non-paralleles sont calculées et présentées dans la ﬁgure 2.

Distribution du score BLEU Distribution du score TER

10000ﬁ 10000 —
E,‘ —I—Para1lei pairs Sysl
8000 '. 3000 .' - -n - Wmng pairs Sysi
‘  ‘R —.n— Paratlel pairs Sys2
_ - -x- - Wrong pairs 83132

0000 ‘j, B000 £2 \
4000 -; 4000
‘V f \
J
2000 :_ 2000
ll
0 . —5|K—¥K--)IK— 0  " ‘

0 0.1'0.2 0.3 0.4 0.5 0.6 0.7 0.0 0.0 1 0 2 4 5 3 in 12 14 15 13

Distribution du score NIST
10000

3000

6000

4000 _

2000 I.

I

   

 (
0 2 4 6 8 10 12 14 16 18 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

Figure 2 : Les distributions des scores pour la méthode seIni-supervisée (Sysl) et non-supervisée (Sys2)

0

Nous pouvons faire les observations suivantes : les distributions des scores ont la méme forme entre Sysl et
Sys2. En particulier, les distributions des scores pour les paires non-paralleles sont presque identiques selon
les deux systemes. Ainsi, un corpus parallele bruité ou un corpus comparable peut remplacer un corpus
parallele dans la construction du systeme de TA initial. Par conséquent, cette méthode non-supervisée peut
étre réellement appliquée dans le cas du manque de données paralleles. Un autre résultat important est que
le PER*, un score simple et facile a calculer, peut étre considéré comme le meilleur score pour ﬁltrer les
paires de phrases paralleles correctes. Le tableau 1 présente la précision et le rappel du ﬁltrage des paires de
phrases paralleles des deux systemes : Sysl et Sys2.

Sysl — méthode sen1i—supervisée Sys2 — méthode non-supervisée
Filtré par Trouvé Correct Précision Rappel F1—mesure Filtré par Trouvé Correct Précision Rappel F1—mesure
B1eu=0.1 6908 6892 99.76 68.92 81.52 B1eu=0.1 6233 6218 99.75 62.18 76.61
Nist=0.4 8350 8347 99.96 83.47 90.97 Nist=0.4 7110 7108 99.97 71.08 83.08
Per*=0.3 10342 9785 94.61 97.85 96.20 Per*=0.3 10110 9468 93.65 94.68 94.16
Per*=0.4 9390 9333 99.39 93.33 96.27 Per*=0.4 8682 8629 99.38 86.29 92.37
Tableau 1 : Précision et rappel du ﬁltrage des paires de phrases paralleles (avec 10K paires des phrases
paralleles correctes)

Do TI-II Nooc DIEP, LAURENT BESACIER, ERIC CASTELLI
3.4 Itérations de la méthode non-supervisée

La section 3.3 a montré qu’une méthode non-supervisée peut étre utilisée aussi pour ﬁltrer/extraire les
paires de phrases paralleles a partir d’un corpus comparable. Toutefois, le résultat du ﬁltrage dans le Sys2
est plus faible que celui dans Sysl (par exemple, le nombre de paires de phrases correctes extraites est
réduit (Tableau 1)). Ainsi nous proposons, dans cette section, un processus itératif, aﬁn d’améliorer la
qualité du systeme de traduction, puis d’augmenter le nombre de paires de phrases extraites correctement.

Augmenter le nombre de paires de phrases correctes extraites : Les paires de phrases extraites sont
combinées avec le systeme de référence S0 de quatre maniere différentes (comme mentionné dans la section
2.2). L’expérience avec les itérations a été effectuée pour le Sys2 (non-supervisé). Aﬁn de recevoir le
nombre maximal de paires de phrases correctes extraites, pour toutes les itérations, on a choisi le score
d’évaluation PER* avec le seuil = 0,3, qui a donné le rappel maximum = 94,68% pour le systeme de
référence. La ﬁgure 3 présente le nombre de paires de phrases extraites correctement apres 6 itérations pour
les quatre combinaisons différentes : W1, W2, W3 et W4 décrites dans la section 2.2. Le nombre de paires
correctes extraites est augmenté dans tous les cas, mais la combinaison W2 introduit le plus grand nombre
de paires de phrases correctes extraites.

Augmenter la précision et le rappel du processus de ﬁltrage : La précision et le rappel de ces quatre
combinaisons sont présentés dans la ﬁgure 4. Parce que le processus de ﬁltrage se concentre sur l’eXtraction
du plus grand nombre de paires de phrases correctes extraites, la précision diminue. Toutefois, en utilisant
la combinaison W2, le rappel apres 6 itérations (97,77) atteint presque le rappel du systeme semi-supervisé
Sysl (97,85).

Evaluation du systéme de TA : La qualité du systeme de TA est évaluée également. Un ensemble de test
contenant 400 paires de phrases paralleles Francais-Anglais qui ont été extraites du corpus Europarl, est
utilisé. Chaque phrase francaise n’a qu’une seule référence en anglais. La qualité est calculée selon BLEU et
T ER. La ﬁgure 5 donne les scores d’évaluation pour les systemes apres chaque itération.

9800
9750
9700
9650
9500
9550
9500
9450

0.98

Sysl

0.97
n 96
0.95
0.94 1

093

   

0.92

W1 W2 W3 W4 0 91
Figure 3 : Nombre de paires de phrases extraites W1 wz W3 w4
correctement apres 6 itérations pour quatre Figure 4 : Précision et rappel du ﬁltrage en utilisant
combinaisons différentes des combinaisons différentes
Score BIEU de |'ensemb|e detest Score Ter de I'ensembIe detest

0.6050
0.0000
0 59 50
0 5000
0 5350
0.5300
0.5750
W1 W2 W3 W4 W1 W2 ‘W3 W4
Figure 5 : I-/Evaluation des systemes de traduction

Sysl

   

L’évaluation du systeme de TA révele un résultat important. La qualité du systeme de TA augmente
rapidement au cours des premieres itérations, mais diminue apres. On peut expliquer que, dans les premieres
itérations, un grand nombre de paires de phrases paralleles nouvelles sont extraites et sont incluses dans le
modele de traduction. Toutefois, dans les itérations suivantes, lorsque la précision du processus d’extraction

APPRENTISSAGE NON SUPERVISE POUR LA TRADUCTION AUTOMATIQUE
APPLICATION A UN COUPLE DE LANGUES PEU DOTE
diIninue, des paires de phrases non paralleles sont ajoutées au systeme ; le modele de traduction est alors
dégradé et la qualité du systeme de TA est réduite. Apres environ 3 itérations, le score BLEU peut
augmenter d’environ 2 points. On notera qu’il n’y a ici aucun réglage des parametres du modele log-linéaire
a chaque itération (pas de données de développement utilisées, etc.).

(Sarikaya et al, 2009) présente une méthode seIni-supervisée avec des itérations mais le systeme de TA
initial est fondé sur un corpus parallele. Il utilise la métrique d’évaluation Bleu pour le ﬁltrage, et une
combinaison semblable a notre combinaison W2. Cependant, leur recherche ne fournit pas une explication
complete sur la facon dont ils choisissent la métrique d’évaluation, ou la méthode de combinaison (une
seule est proposée a chaque fois), et en plus, la diminution de la qualité du systeme de TA apres plusieurs
itérations n’est pas mentionnée.

4 Application pour le couple de langues Vietnamien-frangais

Le Vietnamien est la 14°“ langue la plus parlée dans le monde. Cependant, les recherches sur la TA pour le
Vietnamien sont rares. Le plus ancien systeme de TA pour le Vietnamien est le systeme de « Logos
Corporation » des années 1970. Ce systeme a été développé pour traduire des manuels d’utilisation en
aéronautique de l’anglais vers le Vietnamien (Hutchins, 2001). Au VietnaIn, jusqu’a present, on compte peu
de groupes de recherche travaillant sur la TA Vietnamien - anglais (Ho, 2005) et les résultats obtenus par les
systemes sont modestes. Nous nous concentrons sur la construction d’un systeme de TA statistique
Vietnamien-francais. Le corpus d’apprentissage a été créé par l’eXploitation d’un corpus des nouvelles
journalistiques (news) collecté a partir du Web.

Une des méthodes d’exploitation a déja été présentée par les auteurs de cet article dans (Do et al., 2009).
Cette méthode est basée sur l’utilisation de la date de publication, des mots spéciaux et des scores
d’alignement des phrases. D’abord, les paires de documents paralleles possibles sont ﬁltrés utilisant la date
de publication et les mots spéciaux (les numéros, les symboles joints, les entités nommées). Deuxiemement,
des phrases dans une paire de documents paralleles possibles sont alignées en utilisant l’outil Champollion
(Ma, 2006), qui utilise des informations lexicales (lexemes, mots vides, dictionnaire bilingue, etc.). Enﬁn,
des paires de phrases paralleles sont extraites en utilisant des informations d’alignement, des informations de
longueur et un lexique du document. Cette méthode a été appliquée pour exploiter un corpus de texte a
partir d’un site Web multilingue d’actualités, le Vietnam News Agencyl (VNA) (contenant 20.884
documents francais et 54.406 documents vietnamiens) qui est un corpus véritablement comparable : memes
sujets traités, mais pas d’alignement évident en phrases. 50.322 paires de phrases « paralleles » ont été
extraites. Un systeme de TA statistique pour le Vietnamien-francais a ensuite été construit en utilisant l’outil
Moses avec les memes parametres par défaut que ceux décrits dans la section 3.2 (voir plus dans (Do et al.,
2009)). Ici, nous souhaitons comparer notre méthode non-supervisée, avec la méthode d’extraction
présentée dans (Do et al., 2009). La méthode proposée a été appliquée sur le méme corpus de VNA. Au
lieu d’aligner les phrases et de les ﬁltrer par des informations d’alignement de phrases, nous créons un
corpus comparable et appliquons la méthode non-supervisée proposée directement sur ce corpus bruité.

4.1 Préparation des données
Chaque phrase dans un document vietnaInien a été fusionnée avec toutes les phrases dans le document

francais correspondant. Ainsi une paire de documents vietnaInien (contenant m phrases) et francais
(contenant n phrases) produit mxn paires de phrases. A partir du corpus VNA, nous avons obtenu un

1 http://www.vnagency.com.vn/

DO TI-II NGOC DIEP, LAURENT BESACIER, ERIC CASTELLI
corpus comparable de 1.442.448 de paires de phrases. Nous avons gardé seulement les paires avec le
rapport de longueur (compté en mots) de la phrase francaise et de la phrase vietnamienne entre 0,8 et 1,3.
Nous avons obtenu ainsi un corpus comparable de 345.575 paires de phrases (nommé Can).

4.2 Création du systéme de traduction initial

Aﬁn d’appliquer la méthode non-supervisée proposée, nous avons divisé le corpus Can en deux ensembles :
un corpus d’apprentissage initial C2 et un corpus a « fouiller » D (C2 et D sont indiquées dans la ﬁgure 1).
Pour garantir une qualité minimale de C2 (et par conséquent pour la systeme de TA initial S0), nous
proposons ci-dessous un processus de ﬁltrage croisé pour extraire le corpus C2 :
0 Diviser le corpus Can en 4 sous-corpus contenant des paires de phrases différentes : SC1 (85.011
paires de phrases), SC2 (85.008 paires de phrases), SC3 (86.529 paires de phrases), SC4 (89.027 paires
de phrases).
0 Construire 4 systemes de TA différents : SC1 SMTsc1, SC2 SMTsc2, SC3 SMTSC3,
SC4 SMTSC4.
0 Appliquer la méthode non-supervisée pour chaque paire (SC1, SMTsc2), (SC2, SMTSCI), (SC3,
SMTSC4), (SC4, SMTSC3), (une itération seulement ; seuil de PER* = 0,45 pour assurer la ﬁabilité des
paires de phrases extraites (selon la ﬁgure 2) et un nombre acceptable de paires pour construire le
systeme de traduction). Nous obtenons les paires de phrases extraites C21, C22, C23, C24, et leur union
est considérée comme sufﬁsamment ﬁable pour servir comme corpus comparable initial C2. Le reste est
traité comme le corpus D.

S 2
SC SMTSC Traduire + I C2 Sous- Traduit Nombre de Nombre de

1—> ﬁltfef Par PER* 1 corpus par paires C2 paires D

S 1 SC1 SMTsc2 C21 : 2916 82095

2 —> ﬁltrer par PER* 2 SC3 SMTsc4 C23 2 3820 82709

 SC4 SMTSC3 C24: 3892 85135

Figure 6 : Procesus d’extraction du corpus C2, pour Tableau 2 : Données extraites pour C2 et D

la  (SC1, SMTSC2), (SC2, SMTSC1), 6tC.

Apres cette étape, nous avons obtenu un corpus C2 contenant 14.123 paires de phrases, et un corpus D
contenant 331.452 paires de phrases. La méthode non-supervisée décrite dans la section 2.2 est ensuite
appliquée sur C2 et D pour extraire plus de paires de phrases paralleles.

4.3 Application de la méthode non-supervisée

Le premier systeme de TA vietnamien-francais So a été construit a partir du corpus d’apprentissage C2 de
14.123 paires de phrases. Le corpus D contient 331.452 paires de phrases. La méthode non-supervisée a été
appliquée avec le type de combinaison W2 et la métrique d’évaluation PER*. Il n’y a pas de processus de
réglage des poids des modeles log-linéaires de traduction. Le nombre de paires de phrases extraites apres
chaque itération est indiqué dans la ﬁgure 7. Apres 5 itérations, nous avons obtenu 39.758 paires. La qualité
du systeme de TA est évaluée également sur un ensemble de test de 400 paires de phrases paralleles
extraites manuellement (le meme ensemble de test que dans (Do et al., 2009)). Les phrases en vietnamien
sont segmentées en syllabes (pas de segmentation en mots). Chaque phrase vietnamienne n’a qu’une seule
référence en francais. Les scores d’évaluation apres chaque itération sont reportés dans le tableau 3. Les
résultats dans ce cas sont similaires a ceux obtenus lors des expériences préliminaires : le nombre de paires
de phrases extraites augmente apres quelques itérations, la qualité du systeme de TA augmente également
lors des premieres itérations et diminue par la suite.

APPRENTISSAGE NON SUPERVISE POUR LA TRADUCT‘ION AUTOMATIQUE

APPLICATION A UN COUPLE DE LANGUES PEU DOTE
50000 -

40000 _ iter. Données Bleu Nist Ter
/‘ii’;/T‘? d’apprentissage

30000 0 14.123 30,67 6,45 0,59

// 1 26.517 32,18 6,70 0,57

20000 2 37.210 32,42 6,75 0,56

/ 3 38.530 32,45 6,77 0,55

10000 I I I I I 4 39.254 32,14 6,73 0,56

itéro itéril itér2 itér3 itér4 itér5 5 39.758 31,85 6,68 0,56

Figure 7 : Nombre de paires de phrases extraites apres Tableau 3 : Scores d’évaluation apres chaque
chaque itération dans le systeme de TA VN-FR itération pour le systeme de TA VN-FR

Bien que le nombre de paires de phrases d’apprentissage ait augmenté d’environ deux fois de l’itération 0 a
l’itération 1, le score d’évaluation n’augmente que de 2 points pour BLEU. Une raison est peut étre que le
systeme initial (So) a déja une bonne performance grace a notre ﬁltrage croisé décrit dans la section 4.2. En
outre, l’évaluation est conduite exclusivement avec des métriques automatiques en utilisant une seule
référence, donc une analyse plus approfondie devrait étre menée avec des évaluations subjectives. Pour
comparer avec la méthode d’exploitation présentée dans (Do et al., 2009), la qualité des systemes de TA
des deux méthodes (évaluée sur le méme corpus) est donnée dans le tableau 4. Bien que le nombre de paires
de phrases extraites dans notre méthode soit plus faible que celui dans (Do et al., 2009), la qualité du
systeme de TA est comparable. La méthode proposée dans (Do et al., 2009) dépend cependant de données/
informations supplémentaires telles que la qualité du dictionnaire bilingue ou des regles heuristiques.

Méthodes Donnée d’apprentissage Bleu Nist Ter
Informations lexicales
+ heuristiques (Do et al., 2009) 50322 32’74 6’78 0’55
Non-supervisée (it. 3) 38.530 32,45 6,77 0,55

Tableau 4 : Comparaison entre la méthode d’exploitation de (Do et al., 2009) et la méthode non-supervisée

A partir de ces résultats, nous pouvons dire que la méthode non-supervisée a été appliquée avec succes
pour une couple de langues peu doté : vietnamien-francais. Le résultat montre que cette méthode peut étre
réellement appliquée dans le cas d’un manque de données paralleles. En outre, la qualité du systeme de TA
construit a partir des données extraites est comparable avec celle du systeme de TA d’une autre méthode
utilisant des informations lexicales et des ﬁltrages heuristiques. Cette méthode proposée ne nécessite pas de
données supplémentaires. Nous avons l’intention d’appliquer cette méthode a une plus grande échelle pour
exploiter un plus grand ﬂux de données comparables extraites du Web.

5 Conclusions et perspectives

Cet article présente une méthode non-supervisée pour l’eXtraction de paires de phrases paralleles a partir
d’un corpus comparable. Un systeme de TA initial a été construit, fondé sur un corpus parallele bruité ou
comparable, au lieu d’un corpus parallele. Le systeme de TA initial a été ensuite utilisé pour traduire un
autre corpus comparable. Un processus itératif a été évalué pour augmenter le nombre de paires de phrases
paralleles extraites et pour améliorer la qualité du systeme de traduction. Les expériences montrent que
cette méthode peut étre réellement appliquée, notamInent dans le cas du manque de données paralleles.
Plusieurs méthodes de ﬁltrage et utilisant les données extraites ont également été présentées. Un résultat
intéressant est que la qualité du systeme de TA peut étre améliorée au cours des premieres itérations, mais
elle est dégradée plus tard en raison de l’ajout de données bruitées dans les modeles statistiques. En outre,
la qualité du systeme de TA construit avec cette méthode est comparable a celle d’une autre méthode qui
nécessite des données de meilleure qualité comme un dictionnaire bilingue, des heuristiques etc. Dans

DO TI-II NGOC DIEP, LAURENT BESACIER, ERIC CASTELLI
l’avenir, nous nous concentrerons sur l’approfondissement de l’analyse des meilleures techniques de ﬁltrage,
sur l’expérimentation a plus grande échelle, et sur des évaluations subjectives pour conﬁrmer notre méthode
non-supervisée.

6 Références
ABDUL—RAUF S., SCHWENK H. (2009). On the use of comparable corpora to improve SMT performance, Proceedings of the
12th Conference of the European Chapter of the Association for Computational Linguistics.

BROWN P.F., PIETRA S.A.D., PIETRA V.J.D., MERCER R.L. (1993). The mathematics of statistical machine translation:
parameter estimation. Computational Linguistics. Vol. 19, no. 2.

D0 T.N.D., LE V.B., BIGI B., BESACIER L., CASTELLI E. (2009). Exploitation d’un corpus bilingue pour la création d’un systeme
de traduction probabiliste Vietnarnien — Frangais. TALN 2009.

DODDINGTON G. (2002). Automatic evaluation of machine translation quality using n— gram co—occurrence statistics. In Human
Language Technology Proceedings.

FUNG P., CHEUNG P. (2004). Mining very—non—parallel corpora: parallel sentence and lexicon extraction via bootstrapping and
EM. Conference on Empirical Methods on Natural Language Processing.

GALE W.A., CHURCH K.W. (1993). A program for aligning sentences in bilingual corpora. Proceedings of the 29th annual
meeting on Association for Computational Linguistics.

H0 T.B. (2005). Current status of machine translation research in vietnarn, towards asian wide multi language machine
translation project. Vietnamese Language and Speech Processing Workshop.

HUTCI-I]NS W.J. (2001). Machine translation over fifty years. Histoire, epistemologie, langage. ISSN 0750-8069.

KILGARRIFF A, GREFENSTETTE G. (2003). Introduction to the special issue on the Web as corpus. Computational Linguistics,
volume 29.

KOEHN P. (2005). Europarl: a parallel corpus for statistical machine translation. Machine Translation Summit.

KOEHN P., OCH F.J., MARCU D. (2003). Statistical phrase—based translation. Conference of the North American Chapter of the
Association for Computational Linguistics on Human Language Technology Vol. 1.

KOEHN P., HOANG H., BIRCH A., CALLISON-BURCH C., ZENS R., FEDERICO M., BERTOLDI N., COWAN B., SHEN W., MORAN C.
(2007). Moses: open source tool—kit for statistical machine translation. Proceedings of the Association for Computational
Linguistics.

KUMANO, T., TANAKA H., TOKUNAGA T. (2007). Extracting phrasal alignments from comparable corpora by using joint
probability SMT model. Conference on Theoretical and Methodological Issues in Machine Translation.

MA X. (2006). Charnpollion: A robust parallel text sentence aligner. LREC: Fifth International Conference on Language
Resources and Evaluation.

MUNTEANU D.S., MARCU D. (2006). Extracting parallel sub—sentential fragments from non—parallel corpora. 44th annual
meeting of the Association for Computational Linguistics.

OCH F.J., NEY H. (2003). A systematic comparison of various statistical alignment models. Computational Linguistics 29.1

PAPINENI K., ROUKOS S., WARD T., ZHU W. (2002). BLEU:a method for automatic evaluation of machine translation. In
Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.

PATRY A., LANGLAIS P. (2005). Paradocs: un systeme d’identiﬁcation automatique de documents paralleles. I2e Conference
sur le Traitement Automatique des Langues Naturelles.

RESNIK P., SMITH N.A. (2003). The Web as a parallel corpus. Computational Linguistics.

SARIKAYA R., MASKEY S., ZHANG R., JAN E., WANG D., RAMABHADRAN B., ROUKOS S. (2009). Iterative sentence—pair extraction
from quasi—parallel corpora for machine translation. Interspeech.

SNOVER M., DORR B., SCHWARTZ R., MICCIULLA L., MAKHOUL J. (2006). A study of translation edit rate with targeted human
annotation. Proceedings ofAssociation for Machine Translation in the Americas.

STOLCKE A. (2002). SRILM an extensible language modeling toolkit. Intl. Conf on Spoken Language Processing.

TILLMANN C., VOGEL S., NEY H., ZUBIAGA A., SAWAF H. (1997). Accelerated DP based search for statistical translation. In 5th
European Conf on Speech Communication and Technology.

ZHAO B., VOGEL S. (2002). Adaptive parallel sentences mining from Web bilingual news collection. International Conference
on Data Mining.

