EVALUATION DE LA DETECTION DES EMOTIONS, OPINONS OU SENTHVIENTS

Evaluation de la detection des emotions, des opinions ou des sentiments :
dictature de la majorite ou respect de la diversite d’opinions ?

Jean-Yves Antoinel, Marc Le Tallecl, Jeanne Villaneau2

(1) Universite Francois Rabelais de Tours, LI, 37000 Blois
(2) Universite Européenne de Bretagne, VALORIA, 56100 Lorient
Jean-YVes.Antoine@univ—tours.fr, Marc.Le—Tal1ec@univ—tours.fr, Jearme.Villaneau@uniV-ubs.fr

Resume - Detection d’emotion, fouille d’opinion et analyse des sentiments sont generalement evalues par
comparaison des reponses du systeme concerne par rapport a celles contenues dans un corpus de reference.
Les questions posees dans cet article concernent a la fois la deﬁnition de la reference et la fiabilite des
metriques les plus ﬁequemment utilisees pour cette comparaison. Les experimentations menees pour evaluer
le systeme de detection d’emotions EmoLogus servent de base de reﬂexion pour ces deux problemes.
L’analyse des resultats d’EmoLogus et la comparaison entre les differentes metriques remettent en cause le
choix du vote majoritaire comme reference. Par ajlleurs elles montrent egalement la necessite de recourir a
des outils statistiques plus evolues que ceux generalement utilises pour obtenir des evaluations ﬁables de
systemes qui travaillent sur des donnees intrinsequement subjectives et incertaines.

Abstract - Emotion detection, opinion identiﬁcation and sentiment analysis are generally assessed by means
of the comparison of a reference corpus with the answers of the system. This paper addresses the problem of
the deﬁnition of the reference and the reliability of the metrics which are commonly used for this comparison.
We present some experiments led with EmoLogus, a system of emotion detection, to investigate these two
problems. A detailed analysis of the quantitative results obtained by EmoLogus on various metrics questions
the choice of a majority vote among several human judgments to build a reference. Besides, it shows the
necessity of using more sophisticated statistical tools to obtain a reliable evaluation of such systems which
are working on intrinsically subjective and uncertain data.

Mots-cles : Detection d’emotion, analyse de sentiments, fouille d’opinion ; Evaluation : metrique
d’evaluation, constitution de reference, analyse statistique des resultats.

Keywords: Detection of emotion, sentiment analysis, opinion mining, Evaluation: objective measures, test
reference, statistical analysis of the results.

1 Evaluation en detection des emotions / opinions / sentiments

La detection d’emotions, la fouille d’opinion ou l’analyse des sentiments sont des taches tres proches qui
consistent a trouver et categoriser dans des ﬂux langagiers oraux ou ecrits des passages porteurs d’un etat
emotionnel ou traduisant un jugement. La granularite de la detection est variable suivant l’application: il
peut s’agir d’un document ou d’un discours complet, d’un paragraphe, d’une phrase (qui peut etre
speciﬁquement un titre, par exemple) ou d’un tour de parole dans le cas du dialogue oral homrne-machine.
Le grain de categorisation recherche peut egalement varier d’une tache a l’autre. On peut ainsi ne considerer
que trois classes principales (valence positive, negative ou neutre) ou rechercher une caracterisation plus ﬁne
sous la forme de modalites correspondant aux emotions principales deﬁnies en psychologie : colere, joie,
degout, peur, surprise, tristesse et emotion neutre (Ekrnan 1999).

ANTOINE J .-Y., LE TALLEC M., VILLANEAU J.

Quelle que soit la tache consideree, l’evaluation suit toujours le meme paradign1e : celui de la comparaison
des reponses du systeme a une reference predefn1ie. Les differentes can1pagnes d’evaluation qui ont ete
menees a bien se dilferencient essentiellement par le choix de la metrique de comparaison. Soit C le non1bre
de classiﬁcations correctes (identiques a la reference) effectuees par le systeme et E le non1bre de ses erreurs.

- La robustesse (accuracy en anglais) correspond :31 la proportion de reponses correctes du systeme sur
l’ensemble du corpus de test. On a : R = C / (C+E). Cette mesure est surtout utilisee pour l’evaluation
individuelle des performances d’un systeme comn1e dans (Callejas et Lopez-Cozar 2008).

- La precision et le rappel sont souvent utilises en detection d’opinion et d’emotion. Le systeme peut
choisir la valence neutre qui peut etre interpretee comme une non-decision de la part de classiﬁeurs
entraines pour identiﬁer une expression emotive donnee. La precision quantiﬁe la justesse des decisions
prises par le systeme (P = C/(C+E)), tandis que le rappel estin1e sa part d’indecision (R = C/CR’, ou CR
est le non1bre d’enonces classes dar1s la reference). Ces deux indices peuvent etre calcules globalement
(n1acro-moyenne) ou etre la n1oyenne d’un calcul fait pour chacune des classes (micro -moyenne). La F-
mesure correspond a la moyenne harn1or1ique de la precision et du rappel. Elle estime le compron1is
entre une prise de risque se traduisant par un fort rappel mais une faible precision, et ir1versement. On a
F = 2.P.R / (P+R). Ces metriques ont ete adoptees lors de l’Emotion Challenge d’Interspeech 2009
(Schuller et. al. 2009) et pour l’evaluation de la valence dar1s tache Aﬂective Text de la campagne
SemEval-2 (Straparava & l\/Iihalceva 2007). La campagne DEﬁ Fouille de Texte irmove quelque peu en
deﬁr1issant un indice de conﬁance qui correspond a une F-n1esure ponderee lorsque les reponses du
systeme sont une distribution de probabilites sur chaque classe (Grouin et. al. 2007).

- D’usage moir1s frequent, le coefficient de correlation de Pearson est une autre mar1iere d’estimer la
proxin1ite des reponses avec la reference. On a CP = 0,,/(090,) ou Gsr est la covariance entre les reponses
du systeme et la reference, et 05 et cs, correspondent a la variance des reponses du systeme et des juges
qui ont etabli la reference sur le corpus de test. Cette mesure est utilisee dar1s la can1pagne SemEval-2
pour l’evaluation de la categorisation en modalite en1otionnelle (Straparava & Mihalceva 2007).

- Enﬁn, certaines evaluations choisissent d’evaluer le systeme comme un expert hun1air1, on cherchant a
estimer l’accord inter-annotateur observe entre les reponses du systeme et la reference. Le plus
souvent, cet accord est estin1e par un calcul de Kappa (Cohen 1960) : soit Po la proportion d’accord
observee effectivement et Pa celle correspondant a une armotation aleatoire, on a K = P0 - Pa / (1 — Pa).

La diversite des situations de test fait qu’il est malaise de comparer les resultats d’une campagne a une autre.
I1 n’en reste pas moir1s que peu de travaux ont etudie l’inﬂuence des pratiques de test sur les resultats. Les
multiples mesures de Kappa pour estin1er l’accord inter-armotateur or1t fait l’objet d’experimentations
critiques (Callejas & Lopez-Cozar 2008, Hayes & Krippendorf 2007). Mais en dehors de cette reﬂexion
methodologique (souvent le fait de psycholinguistes ou statisticiens), aucune can1pagne d'evaluation n’a par
exemple utilise de concert plusieurs n1etriques. Ce papier s’appuie precisement sur l’evaluation d’un systen1e
de detection des emotions pour repondre aux questions suivantes :

1) Quelles inﬂuences ont les metriques d’evaluation sur l’estimation des systemes ?

2) Comment interpreter clairement les resultats en termes de performances ?

3) Quelle est l’inﬂuence de l’utilisation systen1atique du vote n1ajoritaire sur l’evaluation ? Rend-elle
bien compte de la diversite des jugements hun1air1s et donc des attentes utilisateurs ?

2 Cas d’école : evaluation du systeme de detection des emotions EmoLogus

Pour repondre a ces questions, nous avons mene plusieurs experin1entations avec un systeme de detection
des emotions, EmoLogus developpe dar1s le cadre du projet ANR EmotiRob. Ce projet intervient dar1s un
contexte d'application original: la realisation d'un robot compagnon emotionnel pour des er1fants fragilises.
EmoL0gus est un composant qui sert a caracteriser l'emotion du locuteur en se basant sur le contenu
linguistique de ces messages oraux, et non, comn1e c’est souvent le cas, en conduisant une analyse
acoustique du signal de parole. Ilse base sur le principe de compositionnalite des emotions: les mots lexicaux
po ssedent une valeur en1otionnelle ﬁxe defn1ie par une norme psycholinguistique, tandis que les verbes et les
adjectifs agissent comme des predicats, dont le resultat depend de la valeur emotionnelle de leurs arguments
(LeTallec et al. 2010). Em0L0gus analyse ainsi la structure de l’enonce pour identiﬁer l’emotion qu’il porte.
11 a ete con1pare avec un systeme de base (baseline) qui ne considere l’enonce que comme un sac de mots:
on se contente ici de somn1er les valences emotionnelles des mots qui le composent.

EVALUATION DE LA DETECTION DES EMOTIONS, OPINONS OU SENTHVIENTS

Notre objectif etant de comparer les performances des deux systemes d’un point de vue purement
linguistique (i.e. sans integrer l’inﬂuence des erreurs de reconnaissance de la parole), les experimentations
ont ete menees sur un conte enfantin (Le Grand Nord), comme souvent sur ce type d’applications (Volkova
et al. 2010). Le corpus de test est de taille limitee (93 phrases) rnais la reference a ete obtenue, a la
difference de la plupart des campagnes d’evaluation, par un nombre eleve de juges (31 en pratique). Notre
objectif est en eifet d’etudier l’inﬂuence de la dispersion des jugements sur l’evaluation. L’armotation a
consiste a attribuer a chaque enonce une valeur emotionnelle sur une echelle de 5 classes variant de -2
(emotion tres negative) a +2 (tres positif). Deux evaluations ont donc ete conduites qui ont porte sur :

- la valence + intensité émotionnelle — Les cinq classes d’armotation sont considerees.
- la valence seule — on ne considere ici que trois classes : emotion positive, negative et neutre

Enﬁn, nous avons evalue l’inﬂuence du contexte de discours en realisant deux annotations manuelles
successives. Dans un premier cas (evaluation hors contexte), les enonces etaient presentes dans un ordre
aleatoire. Dans le second, l’ordre de presentation respectait le fil du conte. Les tableaux 1 et 2 presentent les
performances des deux systemes suivant les metriques presentees precedemment, a la fois pour l’armotation
en valence seule ou celle en valence et intensite.

Hors-contexte Robustesse F-mesure Pearson Kappa
EmoLogus 82,8 % 0,77 0,77 0,69
Baseline 64,6% 0,69 0,67 0,5
En-contexte Robustesse F-mesure Pearson Kappa
EmoLogus 75,3% 0,62 0,73 0,58

Baseline 53,8 % 0,39 0,42 0,31

Tableau 1 : Evaluation des performances en armotation en valence (3 classes).

Hors-contexte Robustesse F-mesure Pearson Kappa
EmoLogus 69,9 % 0,59 0,82 0,56
Baseline 52,7 % 0,41 0,69 0,30

En-contexte Robustesse F-mesure Pearson Kappa
EmoLogus 59,2% 0,47 0,79 0,48
Baseline 39,8 % 0,25 0,5 0,22

Tableau 2 : Evaluation des performances en annotation en valence et intensite (5 classes).

Fait rassurant, certaines conclusions se retrouvent sur toutes les metriques retenues : on observe dans tous
les cas une degradation des performances lors de la prise en compte du contexte. L’analyse des reponses des
systemes nous montre que ceux-ci peinent a integrer aussi fmement qu’un sujet humain le contexte dans
l’appreciation des emotions, l’enchainement des actions creant une ambiance difficile a modeliser. Par
ailleurs, trois des metriques sur quatre semblent indiquer que, sans surprise, la categorisation est plus difﬁcile
avec un nombre de classes superieur: les performances des systemes sont meilleures sur la tache de
classiﬁcation en valence seule. Seul le coefficient de correlation de Pearson se distingue ici. Cette
particularite nous amene a considerer avec reserve cette metrique comme indicateur de performance. 11 est
d’ailleurs malaise de rapprocher correlation et identite de reponses comme le fait l’usage de cette metrique a
fin d’evaluation. Dans les autres cas, nos observations, corroborees par d’autres etudes (Grouin et al. 2009)
posent la question de la mise en place d’une metrique qui serait moins sensible au nombre de classes aﬁn de
faciliter les comparaisons entre evaluations.

On note enfm que le systeme de base presente des performances inferieures a EmoLogus pour toutes les
metriques. Ce resultat montre l’interet d’une prise en compte de la structure des enonces. Cette coherence
des resultats pourrait laisser croire a l’absence d’inﬂuence de la metrique sur le classement des systemes
d’une campagne d’evaluation. Les resultats presentes ci-apres montrent qu’il n’en est rien.

ANTOINE J .-Y., LE TALLEC M., VILLANEAU J.

3 Prise en compte de la diversite des opinions dans l’evaluation des systemes

Les resultats precedents suggerent que les metriques utilisees couramment sont d'assez bons indicateurs de
la performance relative des systemes. Leurs indications restent toutefois difficiles a interpreter en termes de
qualite absolue, avant tout du fait de la dispersion des jugements humains. Les emotions, les opinions
correspondent en effet a des etats cognitifs complexes inﬂuences par le contexte a court-terme (historique de
l’interaction, situation d’enonciation) comme a long terme (vecu personnel et socioculturel) et dont la
perception varie de maniere sensible d'une personne a l'autre. I1 n’est donc pas etonnant que toutes les etudes
montrent que l’accord inter-armotateur est bien plus faible sur ce type de tache que sur, par exemple,
l'annotation en categories morpho-syntaxique. L’aImotation du corpus de test que nous avons realisee s’est
ainsi traduit par des valeurs de Kappa assez faibles entre les 31 juges : 0,48 en contexte et 0,51 hors
contexte. Plut6t que de discuter de la pertinence des mesures de Kappa, la ﬁgure 1 donne la repartition des
Votes des 31 juges pour la phrase <<c ’est court comme belle saison, je sais, mais lesjours seront trés longs».

 

Figure 1 : Exemple de distribution des votes sur un enonce du corpus

On voit que les votes des experts se distribuent sur l’ensemble de l’echelle d’aImotation. Face a une telle
dispersion, on peut s’interroger sur la pertinence d’une reference obtenue par vote majoritaire. Dans le cas
present, la categorie retenue ne represente que 38,7% des votes ! La reference en valence et intensite peut
ainsi representer moins de la majorite des votes dans 25,6% des annotations en contexte. Face a cette
observation, deux questions se posent des lors : 1) comment situer les performances des systemes face aux
capacites des sujets humains et 2) comment integrer la dispersion des jugements dans l’evaluation.

3.1 Evaluation des systemes et performances humaines

Compte-tenu de la dispersion des jugements humains observes, il est clair qu’aucun juge humain ne peut
egaler la reference de test, qui ne represente qu’une approximation de l’opinion moyenne d’une population
donnee. Des lors, les performances des systemes ne devraient pas etre estimees en termes de metriques
absolues, mais comparees a celles des sujets humains. Aussi avons-nous repris les jugements des 31
armotateurs que nous avons soumis aux memes metriques que les systemes testes. En ordonnant les resultats,
nous avons determine le classement des systemes parmi les armotateurs humains (tableaux 3 et 4).

Hors-contexte Robustesse F-mesure Pearson Kappa
EmoLogus 9 eme 22 eme 23 eme 10 eme
Baseline 31 eme 31 eme 33 eme 31 eme
En-contexte Robustesse F-mesure Pearson Kappa
EmoLogus 19 eme 32 eme 24 eme 24 eme
Baseline 33 eme 33 eme 33 eme 33 eme

Tableau 3 : Classement des systemes face aux 31 experts humains : annotation en valence (3 classes)

Plusieurs conclusions peuvent etre tirees de ces classements. Tout d’abord, les difficultes des deux systemes
a considerer le contexte se retrouvent, sans doute d’une maniere plus visible ici. Par ailleurs, si le systeme de
base a des performances mediocres, il est amusant de constater que, pour certaines metriques, ses
performances depassent celles des juges les plus atypiques. A l’oppose, EmoLogus presente un classement
tres honorable (3° sur 33) sur la tache d’etiquetage hors-contexte en valence et intensite. Performance que ne
traduisait pas vraiment les 75,3% de robustesse donnees au tableau 2. I1 semblerait que, sur une tache assez
complexe (5 classes), le systeme, base sur une norme emotionnelle equilibree, soit plus a meme d’adopter un
comportement moyen representatif de la population qu’un individu particulier.

EVALUATION DE LA DETECTION DES EMOTIONS, OPINONS OU SENTHVIENTS

Hors-contexte Robustesse F-mesure Pearson Kappa
EmoLogus 3 eme 13 eme 11 eme 9 eme
Baseline 31 eme 31 eme 30 eme 32 eme
En-contexte Robustesse F-mesure Pearson Kappa
EmoLogus 27 eme 28 eme 23 eme 18 eme
Baseline 33 eme 33 eme 33 eme 33 eme

Tableau 4 : Classement des systemes face aux 31 experts : annotation en valence+ intensite (5 classes)

11 nous sernble ainsi qu’une evaluation par classement par rapport a des juges hurnains est plus a meme de
faire ressortir les qualites et faiblesses des systemes. On remarque toutefois que ces classements varient
signiﬁcativement suivant la metrique utilisee. Cette observation est de nature a jeter un doute sur les
evaluations competitives ne prenant en consideration qu’une seule metrique, comme c’est generalement le
cas en detection d’emotions ou d’opinion. Elle nous incite par ailleurs a proposer une metrique qui prenne
rnieux en compte, a la base, la dispersion des jugements lors de l’etablissement de la reference.

3.2 Integrer la distribution des jugements pour eviter une dictature de la majorite

Les calculs de taux de robustesse, de precision ou de rappel reposent tous sur une evaluation binaire : une
reponse est consideree comrne bonne ou erronee au vu de la reference. Compte tenu de la fragilite d’une
reference obtenue par vote majoritaire, nous avons voulu ponderer ces calculs evaluatifs en tenant compte de
la distribution des jugements hurnains. Considerons une annotation en valence (3 classes). Pour un enonce
donne, supposons que les jugements se sont repartis suivant la distribution suivante :

Negatif : 35% Neutre : 48 % Positif : 17% E> Emotion choisie pour la reference : Neutre

Si le systeme propose la classe Neutre, sa reponse est consideree correcte a 48% dans notre evaluation
ponderee. S’il choisit la classe Négatzf, sa reponse est consideree comme correcte a 35%. Ce qui :1 nos yeux
represente une evaluation plus proche de la realite qu’une decision binaire. Par ailleurs, notre objectif est
d’estimer la performance des systemes par rapport aux capacites humaines, et non pas vis-a-vis d’une
reference quelque peu ideale. Des lors, le poids d’un enonce n’est plus de 1 dans le calcul du score global,
mais pondere par le poids de la classe qui a recu le maximum de votes : 0,48 dans le cas present. Cette
normalisation nous assure par ailleurs qu'un systeme qui choisirait systernatiquement la classe de reference
atteindrait par un score maximal de 100%. Ce modele de calcul fait disparaitre en pratique la notion de prise
de decision: tres peu d’enonces sont juges sans emotion par la totalite des juges (dans notre exemple : 1
enonce hors contexte et 0 en contexte) et la grande rnajorite des enonces (82 sur 93 hors contexte et 76 en
contexte) sont classes comme neutres par au moins l’un des juges. La notion de precision et rappel ne se
distingue donc plus d’un calcul en robustesse. De meme, les indices de Pearson et Kappa deviennent, tels
quels, inutilisables.

Hors-contexte Robustesse : Valence seule Robustesse : Valence + intensite

EmoLogus 87,4% (18 eme) 85,6% (9 eme)
Baseline 80,7% (32 eme) 71,9% (31 eme)

En-contexte Robustesse Robustesse

EmoLogus 79,3% (30 eme) 74,7%(28 eme)
Baseline 64,9 % (33 eme) 59,9%(33 eme)

Tableau 5 : Evaluation ponderee des systemes : resultats et classements.

Parmi les indices precedents, seule la robustesse reste donc signiﬁcative. Le tableau 5 donne les resultats de
ce calcul pondere. Ces resultats nous semblent representer plus ﬁdelement les performances intrinseques des

ANTOINE J .-Y., LE TALLEC M., VILLANEAU J.

systemes de deux points de vue. D'une part, les valeurs de performances se sont legerement accrues, ce qui
correspond au ressenti d’une analyse qualitative des reponses. En effet, en cas d’erreur, le systeme propose
souvent la classe arrivee en seconde position au sein de la population de juges, ce que prend en compte cette
metrique ponderee. A l’oppose, le classement du systeme par rapport aux juges humains s’est degrade. Une
fois encore, cette observation montre la dependance a la metrique d’evaluation d’une campagne de test de
type competitif.

4 Conclusion

L’analyse de ce << cas d’ecole » montre les difﬁcultes liees a l’evaluation de ces donnees subjectives que sont
les opinions et les emotions. Elle montre egalement que les indices d’evaluation classiquement utilises
donnent des resultats ir1stables donc peu ﬁables. Ce constat etant etabli, il reste a etudier des pistes pour
pallier cette insuffrsance. Le coefficient alpha de Krippendorff ouvre des perspectives interessantes par sa
plasticite : dans l'exemple d'evaluation presente dans ce papier, il permet en effet d'introduire des metriques
entre les classes et de mesurer de facon ﬁne l'ecart entre la notation proposee par un expert et la reference
complete dans sa dispersion, sans recours au vote majoritaire. Une autre piste a etudier est celle des
ensembles ﬂous : la reference que constitue l’ensemble des avis des experts correspond a des probabilites
d’appartenance ﬂoue (Milleman et Scholl 1996). Le meilleur systeme est celui qui donne l’ensemble net le
plus proche de cet ensemble ﬂou.

Remerciements : ce travail a ete pour partie realise dans le cadre de l’ANR EmotiRob (PSIROB’06).

Référen ces

CALLEJAS Z., LOPEZ-COZAR R. (2008) Inﬂuence of contextual information in emotion armotation for spoken
dialogue systems. Speech Communication. 50 (2008), 416-433

COHEN J. (1960) A coefficient of agreement for nominal scales. Educational & Psycho. Meas., 20, 37-46.
EKMAN P. (1999) Patterns of emotions: New Analysis of Anxiety and Emotion . Plenum Press.

GROUIN C., HURAULT-PLANTET M., PAROUBEK P., BERTHELIN J.B. (2009) DEFT’07: une campagne
d’evaluation en fouille d’opinion. Revue des Nouvelles Technologies de l'Information. Vol.E-17.1—24.

HAYES A.F, KRIPPENDORFF K. (2007) Answering the Call for a Standard Reliability Measure for Coding
Data. Communication Methods and Measures 1,1: 77-89.

LE TALLEC M., VILLANEAU J ., ANTOINE J.—Y., SAVARY A., SYSSAU-VACCARELLA A. (2010) Emologus, a
compostional model of emotion detection based on the propositionnal content of spoken utterances Proc.
Text, Speech and Dialogue, TSD'2010, Brno, Tchéquie, sept. 2010. In. LNCS/LNAI 6231, Springer

MILLEMANN S., SCHOLL P. (1996) Estimation de quantités subjectives ﬂoues par des techniques
connexionnistes. Application at l'évaluation du confort automobile. In. MODULAD, numéro 17, J uin 1996.

SCHULLER B., STEIDL S., BATLINER A. (2009) The INTERSPEECH 2009 Emotion Challenge. Proc.
Interspeech ’2009, Brighton, UK.

STRAPPARAVA C., MIHALCEVA R. (2007). SemEval—2007 Task 14: Affective Tex. Proc. 4th International
Workshop on Semantic Evaluations (SemEval—2007), Prague, Juin 2007, 70-74.

VOLKOVA E., MOI-ILER B., MEURES D., GERDEMANN D. AND BULTHOFF,H. (2010) Emotional perception of
fairy tales: achieving agreement in emotion armotation of text, Proc. NAA CL HLT ’ 2010

