TALN 2011, Montpellier, 27juin — l"'ju1'11et 2011

Quel apport des unités polylexicales dans une formule de lisibilité pour le
francais langue étrangére

Thomas Francois1= 2’ 3 Patrick Watrinzv 3
(l) Aspirant FNRS
(2) Centre de traitement automatique du langage (CENTAL), UCLouvain
(3) Institut Langage et Communication (IL&C), UCLouvain
thomas.francois @uc1ouvain.be, patrick.watrin@uc1ouvain.be

Résumé. Cette etude envisage l’emploi des unités polylexicales (UPS) comme prédicteurs dans une formule
de lisibilité pour le frangais langue étrangere. A l’aide d’ un extracteur d’UPs combinant une approche statistique
a un ﬁltre linguistique, nous déﬁnissons six variables qui prennent en compte la densité et la probabilité des UPS
nominales, mais aussi leur structure inteme. Nos expérimentations concluent a un faible pouvoir prédictif de ces
six variables et révelent qu’une simple approche basée sur la probabilité moyenne des n—gra1nmes des textes est
plus efﬁcace.

Abstract. This study considers the use of multi—words expressions (MWES) as predictors for a readability
formula for French as a foreign language. Using a MWES extractor combining a statistical approach with a lin-
guistic ﬁlter, we deﬁne six variables. These take into account the density and the probability of MWEs, but also
their internal structure. Our experiments conclude that the predictive power of these six variables is low. Moreover,
we show that a simple approach based on the average probability of n-grams is a more effective predictor.

M0tS-CléS 3 Lisibilité du FLE, unités polylexicales nominales, modeles N—grammes.

Keywords: Readability of FL, nominal MWEs, N—grams models.

THOMAS FRANCOIS, PATRICK WATRIN

1 Introduction

Avec le succes des approches communicatives et actionnelles dans l’enseignement des langues étrangeres, les
professeurs sont auj ourd’hui encourages a travailler avec des textes authentiques, aﬁn de mettre leurs étudiants en
contact avec des données linguistiques avérées. Le web constitue une précieuse source pour ce type de documents,
mais la recherche d’un document adapté au niveau des etudiants reste parfois ardue. Dans ce contexte, la lisibilité
a un role a jouer, car elle vise a developper des outils capables de prédire les difﬁcultés de comprehension d’un
texte pour une population donnee, uniquement au moyen de caractéristiques textuelles (telles que le nombre de
lettres par mots, le nombre de mots par phrase, etc.).

Cependant, si de nombreux travaux se sont penchés sur la lisibilité de l’anglais L1, on compte nettement moins
d’etudes sur la lisibilite en L2, et moins encore pour le frangais langue étrangere (FLE). Dans la majorite des
cas, ce sont des formules développées sur des natifs qui ont ete appliquees a des contextes d’enseignement des
L2. Or, la validite d’une telle approche est loin d’etre etablie, car elle repose sur trois hypotheses fragiles : (1) la
comprehension des lecteurs en L2 est comparable a celle de natifs; (2) les variables textuelles considerees dans
ces formules sont pertinentes pour la lecture en L2 et (3) la pondération de ces variables peut etre la meme au sein
d’ une formule pour une L1 et une L2.

Plusieurs auteurs (Laroche, 1979; Uitdenbogerd, 2005) ne s’accordent pas avec ce point de vue et considerent
que les particularités du processus de lecture en L2, decrits entre autres par Koda (2005), doivent etre pris en
compte dans les formules de lisibilité spéciﬁques aux L2. Nous avons précédemment montré que les temps et
modes verbaux constituent d’excellents prédicteurs pour la lisibilité des textes en FLE (Francois, 2009). Dans
cette etude, nous envisageons une autre facette textuelle a priori intéressante : les unités polylexicales (UPs)
nominales. En effet, des expérimentations que nous avons realisées précédemment ont conﬁrmé que la fréquence
des mots de contenu et, en particulier des noms, apportent une information utile en lisibilite. Par ailleurs, les UPs
sont associées a une pratique ﬂuide et appropriée de la langue (Pawley & Syder, 1983). On peut donc s’attendre a
ce que les apprenants d’une L2, et en particulier les débutants, rencontrent des difﬁcultés ales traiter.

Dans la section 2, nous synthétisons un ensemble de resultats de recherche a propos des UPs et de leur traitement,
en particulier lors de la lecture d’un texte en L2. La section 3 décrit la procedure expérimentale qui a eté appliquée
pour analyser la relation e11tre les UPs et la difﬁculté des textes pour des lecteurs de FLE. Les résultats de ces
experimentations sont rapportes et discutes dans la section 4.

2 Les unités polylexicales et la difﬁculté des textes

Dans cet article, nous designons sous le terme << unite polylexicale » un ensemble d’objets linguistiques dont le
sens et la forme peuvent etre plus ou moins ﬁgés (collocations, mots composes, expressions idiomatiques, etc.).
D’un point de vue statistique, cette classe d’ objets réfere communement a des << suites de mots qui se trouvent plus
frequemment associés qu’il ne le seraient par le seul fruit du hasard » (Dias et al., 2000, 213).

Plusieurs travaux en psychologie cognitive de la lecture, dont celui d’ Underwood et al. (2004), ont observe qu’en
moyenne, le traitement des unités polylexicales par des natifs est plus rapide que celui des chaines libres, a la
lecture comme lors de la production orale. Un effet similaire a aussi eté observe pour des apprenants de niveau
avancé (Underwood et al., 2004). Cependant, ces études portent sur le temps de lecture et, donc, de reconnaissance
des UPs, mais elles n’évaluent pas leur effet sur la comprehension. Or, chez des apprenants debutants ou interme-
diaires, il y a fort a parier que cet effet soit contrebalancé par le fait que les unités polylexicales rencontrées sont
(1) majoritairement inconnues des lecteurs et (2) d’autant plus difﬁciles a élucider a l’aide du contexte que leur
sens peut etre non—compositionnel.

En lisibilite, l’hypothese qu’une UP plus rare dans la langue serait plus ardue a la lecture n’a guere été exploree.
Weir & Anagnostou (2008) ont suggéré de se servir de la moyenne des frequences absolues des collocations pre-
sentes dans un texte comme d’ un indice de sa difﬁculte, sans valider leur approche par des expérimentations. Dans
un article anterieur, Ozasa et al. (2007) avaient présenté une formule de lisibilité pour des apprenants japonais de
l’anglais langue étrangere (ALE) qui comprend, entre autres variables, un indice de la difﬁculte des collocations.
Celui—ci n’apparait cependant pas signiﬁcatif au sein de leur modele de regression lineaire multiple, puisqu’il

QUEL APPORT DES UNITES POLYLEXICALES DANS UNE FORMULE DE LISIBILITE POUR LE FRANCAIS
LANGUE ETRANGERE

obtient un t 1 de 0, 4987, ce qui correspond a une p—valeur de 0, 6188 (Ozasa et al., 2007, 4).

Ainsi, il n’est pas evident que les UPs constituent un predicteur efﬁcace en lisibilité en L2. Comme les recherches
precitees n’ont abordé cette problématique que superﬁciellement, nous avons voulu l’explorer plus en detail au
travers du cas particulier du FLE.

3 Procédure expérimentale

Pour réaliser nos experimentations, il a eté nécessaire de : (1) rassembler un corpus deja annoté en termes de
difﬁculté; (2) developper un extracteur d’UPs nominales.

3.1 Le corpus

La conception d’ une formule de lisibilite implique l’annotation d’ un corpus en terme de difﬁculté et, par conse-
quent, le choix d’une echelle de reference. Dans le contexte de l’enseignement des langues en Europe, le Cadre
européen commun de references pour les langues (CECR) (Conseil de l’Europe, 2001) s’est impose comme un
choix evident. Cette norme deﬁnit six niveaux de progression — A1 (debutant) ; A2; B1 ; B2; C1 et C2 (avance).
Toutefois, aﬁn de mieux rendre compte de l’évolution des apprenants, plus rapide dans les premieres phases de
l’apprentissage, nous avons scindé les trois premiers niveaux obtenant ainsi neufs echelons distincts.

Notons que, depuis son introduction, le CECR a amené une certaine standardisation des manuels de FLE. Il a des
lors eté possible de rassembler, au depart d’un sous-ensemble de ces manuels, un corpus de textes annotes par des
expertsz. Nous avons ainsi rassemblé 1 895 textes, dont la taille varie de quelques phrases a plus de 2000 mots.
Par ailleurs, aﬁn de disposer d’un corpus de tests dont la probabilité a priori de chaque classe est similaire, nous
avons sélectionné aleatoirement 50 textes par niveau, retenant ainsi 450 textes pour nos expérimentations.

3.2 L’extraction des UPS

En ce qui conceme la procedure d’extraction des UPS, elle s’inspire largement des travaux de Daille (1995) en
ce qu’elle associe, a la validation statistique, un ensemble de ﬁltres linguistiques. En plus d’assurer une plus
grande precision, ces ﬁltres nous permettent de contraindre la nature grammaticale des candidats termes et d’ainsi
restreindre l’extraction aux structures nominales.

Dans ce systeme, la validation statistique implémente le rapport de la log—vraisemblance tel que decrit dans Silva
& Lopes (1999). Le fonctionnement de cette mesure, comme de l’ensemble des mesures d’association, suppose
une masse fréquentielle conséquente, masse qui n’était pas accessible au depart des textes de notre corpus. Pour
palier ce probleme, nous proposons dans Watrin & Francois (2011) le recours a une reference fréquentielle, c’est—
a—dire une base de données de n—grammes (et de leur fréquence) construite au depart de gros corpus. Dans le cadre
de cette etude, nous avons envisage l’indexation des 5—grammes du corpus de Google (Michel et al., 2011) (pour
les armees 2000-2008) et d’un corpus de 5 000 000 de mots issus de l’année 2009 du quotidien belge Le Soir.

4 Résultats et discussion

4.1 Capacité prédictive des unités polylexicales

Aﬁn de determiner l’interet des UPs en lisibilite du FLE, nous avons deﬁni six variables a meme de prendre en
compte diverses facettes de ce phénomene : (1) la proportion d’unités polylexicales nominales par rapport au
nombre de mots (NCPW) ; la proportion des 4 familles de structures morpho—syntaxiques suivantes : (2) N N, (3)

1. Dans le contexte de la regression linéaire multiple, la statistique t résulte d’un test de signiﬁcativité sur le coefﬁcient d’une des variables
explicatives (Howell, 2008, 264).

2. Bien entendu, ce processus de selection suppose que le niveau d’un texte est similaire a celui du manuel dont il est extrait. Pour le détail
des criteres utilisés pour la sélection, consulter Francois (2009).

THOMAS FRANCOIS, PATRICK WATRIN

Le Soir Google
Seuils 0 0 15 25 43 0 139 4000 9931
NCPW 0, 303 0,144 0,134 0,144 0,173 0,101 0,154 0,154
NN -0, 243 -0, 144 -0, 01 0, 03 -0, 223 -0, 134 0, 004 0, 007
NPN 0, 05 0,134 0, 09 0,111 0, 04 0,06 0,154 0,173
AN -0, 05 -0, 03 0, 02 0,08 -0, 07 0, 03 0,08 0, 091
NA 0, 363 0, 303 0, 273 0, 223 0, 373 0, 323 0, 253 0, 283
MeanP-UP -0, 03 -0, 03 -0, 04 -0, 05 0, 154 0, 164 0,141 0, 09

TABLE 1 — Correlation entre les variables independantes et la difﬁculte des textes. Le taux de signiﬁcativite est
indique comme suit: 1p < 0,05 ; 2p < 0,01; 3p < 0,0001

N PREP (DET) N, (4) A N et (5) N A ; et (6) la probabilite moyenne d’apparition des unites polylexicales du texte
(MeanP-UP), calculee sur la base des deux references decrites precedemment.

Par ailleurs, nous avons egalement fait varier le seuil 0 associe a la validation statistique. De cette maniere, nous
avons pu estimer l’i1npact de la force d’ association des constituants des UPs. Quatre seuils ont ete retenus pour
chacun des deux corpus de reference : un seuil nul ou toutes les structures lexicales nominales sont considerees;
un second et un quatrieme seuil qui correspondent respectivement a une precision de 30% et 50% pour notre
extracteur (Watrin & Francois, 2011) et une valeur intermediaire comme troisieme seuil. La Table 1 rapporte les
coefﬁcients de correlation de Pearson (r) entre les 6 variables susmentionnees et le niveau de difﬁculte des textes
du corpus de tests.

Ces resultats apportent des enseignements interessants. Premierement, on note que plusieurs variables, en parti-
culier NPCW et la structure NA, sont signiﬁcativement associees avec la difﬁculte des textes de notre corpus.
Elles semblent a premiere vue etre de bons candidats pour predire la difﬁculte de textes. Cependant, lorsqu’on les
integre au sein d’ une formule de lisibilite de type classique, c’est—a—dire qui considere uniquement le nombre de
lettres par mots (NLM) et le nombre de mots par phrase (NMP) 3, leur apport n’est pas signiﬁcatif (X2 = 2, 98;
p — value = 0, 08) 4. Les UPs n’amenent donc pas d’information Veritablement nouvelle par rapport aux variables
traditionnelles.

Une seconde observation notable est que le fait d’augmenter 0, et donc de renforcer le taux de cohesion des UPs,
tend a diminuer l’efﬁcacite des differents predicteurs. Sur base de ces resultats, on pourrait en conclure que les
UPs sont de moins bons predicteurs que l’ensemble des structures nominales complexes (0 = 0). Cependant, il
nous semble plus juste de limiter ce constat d’echec aux UPs detectees automatiquement a l’aide de techniques
statistiques. En effet, parmi les meilleurs candidats pour notre corpus, on trouve des UPs telles que << effet de
serre » ou << developpement durable », pertinentes dans un contexte d’apprentissage des L2, mais aussi << mardi
soir » ou << millions d’ euros ».

Confrontes a cette inadequation des techniques de detection des UPs au contexte de la lisibilite, nous nous sommes
poses une seconde question. Qu’en est—il de modeles plus simples, les modeles n—grammes, qui considerent des
suites de tokens sans motivation linguistique ?

4.2 Les modéles n-grammes

Pour veriﬁer l’efﬁcacite de modeles n—grammes en lisibilite, nous nous sommes servis de la frequence des n-
grammes d’ordre 1 a 5 contenus dans nos references (cf Section 3). Seul le modele bigramme s’est avere pertinent
pour notre approche. En effet, la capacite de discrimination des modeles d’ ordre superieur souffre trop du lissage,
le nombre de n—grammes inconnus augmentant proportionnellement a l’ordre du modele. La probabilite des eve-
nements inconnus etant toujours la meme, les variables qui en decoulent ne sont plus sufﬁsamment discriminantes.

Sur la base des bigrammes de Google et du Soir, nous avons deﬁni deux familles de predicteurs. La premiere re-
pose sur les probabilites conditionnelles des mots, P(w,- |w,-_1), desquels nous avons derive un modele n—gramme
classique, normalise en fonction du nombre m de mots par texte selon la formule suivante :

3. Les deux formules de lisibilite utilisées pour cette comparaison reposent sur une regression logistique ordinale, qui est décrite en detail
dans Francois (2009).

4. La technique statistique de comparaison entre les deux modeles assimile chacun d’eux a une hypothese d’explication des données et en
calcule le rapport de la log-vraisemblance multiplié par la constante -2. Des lors, ce rapport est distribué selon une loi chi-carré.

QUEL APPORT DES UNITES POLYLEXICALES DANS UNE FORMULE DE LISIBILITE POUR LE FRANCAIS
LANGUE ETRANGERE

nor1nTLProb MeanProb MedianProb meanNGProb medianNGProb gmeanNGProb
Google 0, 003 0, 333 -0, 04 0, 383 -0, 001 -0, 03
Le Soir -0, 06 0, 182 0, 01 0, 253 -0, 09 -0, 0007

TAB LE 2 — Correlation entre les Variables basées sur les n—gra1nmes et la difﬁculté des textes.

1 TN;
normTLProb = E 2 log P(w,-|w,-_1)

i=1

En marge de ce modele, nous avons aussi considéré la moyenne des probabilités conditionnelles (MeanProb) et
leur médiane (MedianProb). La seconde famille de prédicteurs s’intéresse quant a elle directement aux proba-
bilités des bigrammes, P(w1 (‘I 102), qui correspondent davantage aux probabilités prises en compte dans notre
approche des UPs. Nous avons ainsi calculé la moyenne (meanNGProb), la médiane (medianNGProb) et la
moyenne géométrique (gmeanNGPr0b), qui comme un modele n-gramme classique, multiplie les probabilités
entre—elles plut6t que d’ en faire la somme. Les correlations de ces 6 Variables avec la difﬁculté sont reprises dans
la Table 2.

La aussi, nos analyses apportent quelques constatations d’intéret. La premiere d’entre-elles est l’inefﬁcacité com-
plete des Variables basées sur un modele bigramme classique (r Vaut 0, 003 et -0, 06 pour n0rmTLProb), ce
qui nous parait hautement surprenant en regard des résultats rapportés dans les travaux sur l’anglais. Schwarm &
Ostendorf (2005), par exemple, disent employer des modeles n—grammes avec succes. Notons qu’ils ne rapportent
pas de correlation individuelle pour cette Variable et que leurs bonnes performances globales sont obtenues a l’aide
de nombreux prédicteurs.

Par contre, la moyenne des probabilités des bigrammes du texte (MeanProb) apparait largement signiﬁcative.
D’ailleurs, son addition a la formule de lisibilité baseline envisagée précédemment amene cette fois une amelio-
ration signiﬁcative des performances (R = 0, 67; X2 = 11,66; p — value = 0, 0006). Il est particulierement
intéressant par rapport a notre démarche de noter que MeanProb est plus informatif qu’une Variable plus ﬁne, qui
calcule la moyenne des probabilités des UPs (MeanP-UP). Ce résultat nous semble mettre sérieusement en ques-
tion l’intéret des UPs en lisibilité, et Vient par ailleurs répliquer les résultats de Ozasa et al. (2007) sur l’anglais.

5 Conclusion

Dans cette etude, nous avons testé les apports de la notion d’UPs dans une formule de lisibilité pour le FLE.
Ceux—ci se sont révélés négligeables, aussi bien de facon absolue qu’en comparaison avec une approche plus
simple basée sur les n—grammes. Notre experience souligne que la prise en compte automatique de notions plus
linguistiques ne conduit pas a des résultats satisfaisants pour la lisibilité du FLE. En effet, les traitements TAL
nécessaires sous—tendent trop d’approxi1nations qui nuisent a l’efﬁcacité des Variables : erreurs de l’extracteur
d’ UPs, probleme de couverture des references, etc.

Par ailleurs, nos expérimentations ont jeté un doute sur l’efﬁcacité des modeles n—grammes classiques pourtant lar-
gement employés dans le domaine. En effet, rappelons que, sur notre corpus, une simple approche par unigramme
produit une correlation élevée (r = -0, 59), ce qui n’est pas le cas des modeles d’ ordre supérieur (bigramme :
1" = -0, 06). Il nous faut donc conclure soit a un probleme d’esti1nation des probabilités au niveau des references,
soit remettre en question l’hypothese qui fonde l’emploi d’ un modele n—gramme en lisibilité, a savoir que la pro-
babilité d’un mot étant donné son historique est liée a sa difﬁculté de reconnaissance et de comprehension. Ce
dernier aspect requiererait cependant des expérimentations dans le cadre de modeles explicatifs et non prédictifs.

Enﬁn, on peut se demander si ce motif de résultats se reproduirait si (1) les UPs Verbales étaient également
considérées ; si (2) le repérage des UPs était effectué manuellement (ce qui représente toutefois un travail énorme) ;
et si (3) seules les expressions ﬁgées, plus opaques sémantiquement, étaient prises en compte. Cette derniere
perspective, intellectuellement attrayante, doit etre relativisée, car il est fort probable que ce type d’ UPs soit trop
rare dans les textes a analyser pour se révéler statistiquement informatif.

THOMAS FRANCOIS, PATRICK WATRIN

Références

CONSEIL DE L’ EUROPE (2001). Cadre europe’en commun de reference pour les langues : apprendre, enseigner,
e’valuer. Paris : Hatier.

DAILLE B. (1995). Combined approach for terminology extraction : lexical statistics and linguistic ﬁltering.
Rapport inteme, Lancaster University.

DIAS G., GUILLORE S. & LOPES J. (2000). Extraction automatique d’ associations textuelles a partir de corpora

non traites. In Proceedings of 5th International Conference on the Statistical Analysis of Textual Data, p. 213-
221.

FRANCOIS T. (2009). Combining a statistical language model with logistic regression to predict the lexical and
syntactic difﬁculty of texts for FFL. In Proceedings of the 12th Conference of the EACL : Student Research
Workshop, p. 19-27.

HOWELL D. (2008). Me’thodes statistiques en sciences humaines, 6eme e’dition. Bruxelles : De Boeck.

KODA K. (2005). Insights into second language reading : A cross-linguistic approach. Cambridge : Cambridge
University Press.

LAROCHE J. (1979). Readability measurement for foreign-language materials. System, 7(2), 131-135.
MICHEL J., SHEN Y., AIDEN A., VERES A., GRAY M., TEAM T. G. B., PICKETT J., HOIBERG D., CLANCY
D., NORVIG P., ORWANT J ., PINKER S., NOWAK M. & AIDEN E. (2011). Quantitative analysis of culture
using millions of digitized books. Science, 331(6014), 176-182.

OZASA T., WEIR G. & FUKUI M. (2007). Measuring readability for Japanese learners of English. In Procee-
dings of the 12th Conference of Pan—Paciﬁc Association of Applied Linguistics.

PAWLEY A. & SYDER F. (1983). Two puzzles for linguistic theory : nativelike selection and nativelike ﬂuency.
In J . RICHARDS & R. SCHMITT, Eds., Language and Communication, p. 191-225. London : Longman.
SCHWARM S. & OSTENDORF M. (2005). Reading level assessment using support vector machines and statistical
language models. Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, p.
523-530.

SILVA J . & LOPES G. (1999). A local maxima method and a fair dispersion normalization for extracting multi-
word units from corpora. In Sixth Meeting on Mathematics of Language.

UITDENBOGERD S. (2005). Readability of French as a foreign language and its uses. In Proceedings of the
Australian Document Computing Symposium, p. 19-25.

UNDERWOOD G., SCHMITT N. & GALPIN A. (2004). The eyes have it : An eye—movement study into the
processing of formulaic sequences. In N. SCHMITT, Ed., Formulaic sequences : acquisition processing and use,
p. 155-172. Amsterdam : John Benjamins.

WATRIN P. & FRANCOIS T. (2011). N-gram frequency database reference to handle MWE extraction in NLP
applications. In Unpublished manuscript.

WEIR G. & ANAGNOSTOU N. (2008). Collocation frequency as a readability factor. In Proceedings of the 13th
Conference of the Pan Pacific Association of Applied Linguistics.

