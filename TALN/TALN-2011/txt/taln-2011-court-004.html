<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Coop&#233;ration de m&#233;thodes statistiques et symboliques pour l&#8217;adaptation non-supervis&#233;e d&#8217;un syst&#232;me d&#8217;&#233;tiquetage en entit&#233;s nomm&#233;es</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Coop&#233;ration de m&#233;thodes statistiques et symboliques pour l&#8217;adaptation
non-supervis&#233;e d&#8217;un syst&#232;me d&#8217;&#233;tiquetage en entit&#233;s nomm&#233;es
</p>
<p>Fr&#233;d&#233;ric B&#233;chet1, Beno&#238;t Sagot2, Rosa Stern2,3
</p>
<p>(1) Aix Marseille Universit&#233;, LIF-CNRS, route de Luminy, Marseille
(2) Alpage, INRIA &amp; Univ. Paris 7, Rocquencourt, BP 105, 78153 Le Chesnay Cedex, France
</p>
<p>(3) Agence France-Presse &#8211; Medialab, 2 place de la Bourse, 75002 Paris, France
frederic.bechet@lif.univ-mrs.fr, benoit.sagot@inria.fr, rosa.stern@afp.com
</p>
<p>R&#233;sum&#233;. La d&#233;tection et le typage des entit&#233;s nomm&#233;es sont des t&#226;ches pour lesquelles ont &#233;t&#233; d&#233;velopp&#233;s
&#224; la fois des syst&#232;mes symboliques et probabilistes. Nous pr&#233;sentons les r&#233;sultats d&#8217;une exp&#233;rience visant &#224; faire
interagir le syst&#232;me &#224; base de r&#232;gles NP, d&#233;velopp&#233; sur des corpus provenant de l&#8217;AFP, int&#233;grant la base d&#8217;entit&#233;s
Aleda et qui a une bonne pr&#233;cision, et le syst&#232;me LIANE, entra&#238;n&#233; sur des transcriptions de l&#8217;oral provenant du
corpus ESTER et qui a un bon rappel. Nous montrons qu&#8217;on peut adapter &#224; un nouveau type de corpus, de mani&#232;re
non supervis&#233;e, un syst&#232;me probabiliste tel que LIANE gr&#226;ce &#224; des corpus volumineux annot&#233;s automatiquement
par NP. Cette adaptation ne n&#233;cessite aucune annotation manuelle suppl&#233;mentaire et illustre la compl&#233;mentarit&#233;
des m&#233;thodes num&#233;riques et symboliques pour la r&#233;solution de t&#226;ches linguistiques.
</p>
<p>Abstract. Named entity recognition and typing is achieved both by symbolic and probabilistic systems. We
report on an experiment for making the rule-based system NP, a high-precision system developed on AFP news
corpora and relies on the Aleda named entity database, interact with LIANE, a high-recall probabilistic system
trained on oral transcriptions from the ESTER corpus. We show that a probabilistic system such as LIANE can be
adapted to a new type of corpus in a non-supervized way thanks to large-scale corpora automatically annotated by
NP. This adaptation does not require any additional manual anotation and illustrates the complementarity between
numeric and symbolic techniques for tackling linguistic tasks.
</p>
<p>Mots-cl&#233;s : D&#233;tection d&#8217;entit&#233;s nomm&#233;es, adaptation &#224; un nouveau domaine, coop&#233;ration entre approches
probabilistes et symboliques.
</p>
<p>Keywords: Named entity recognition, domain adaptation, cooperation between probabilistic and sym-
bolic approaches.
</p>
<p>1 Introduction
</p>
<p>La reconnaissance d&#8217;entit&#233;s nomm&#233;es est une des t&#226;ches les plus &#233;tudi&#233;es du domaine du traitement automa-
tique des langues. Reconna&#238;tre dans du texte ou de la transcription de parole les mentions d&#8217;entit&#233;s nomm&#233;es
reste un pr&#233;alable n&#233;cessaire avant toute t&#226;che plus complexe telle que l&#8217;analyse syntaxique, l&#8217;analyse s&#233;mantique
ou l&#8217;extraction d&#8217;informations. Ainsi, la t&#226;che de reconnaissance d&#8217;entit&#233;s nomm&#233;es fait l&#8217;objet de nombreuses
campagnes d&#8217;&#233;valuation depuis plus d&#8217;une vingtaine d&#8217;ann&#233;es, dont les premi&#232;res ont &#233;t&#233; les campagnes MUC
(Message Understanding Conference). Ces campagnes ont donn&#233; lieu &#224; la construction de corpus de r&#233;f&#233;rence,
notamment pour l&#8217;anglais, le chinois, l&#8217;espagnol ou le japonais. Pour le fran&#231;ais, on peut citer notamment l&#8217;&#233;va-
luation men&#233;e dans le cadre de la campagne ESTER sur des transcriptions de nouvelles, qui a donn&#233; naissance &#224; un
corpus fran&#231;ais annot&#233; en entit&#233;s nomm&#233;es selon des directives assez diff&#233;rentes de celles des campagnes MUC,
notamment pour les emplois polys&#233;miques et m&#233;taphoriques (Galliano et al., 2009). Pour une discussion plus
pr&#233;cise de ces questions et des diff&#233;rents types d&#8217;ambigu&#239;t&#233;s rencontr&#233;es en reconnaissance des entit&#233;s nomm&#233;es,
on pourra se reporter &#224; (B&#233;chet, 2011).
</p>
<p>Toutes les campagnes d&#8217;&#233;valuation ont montr&#233; que la t&#226;che de reconnaissance d&#8217;entit&#233;s nomm&#233;es peut &#234;tre trait&#233;e
efficacement aussi bien avec des syst&#232;mes symboliques qu&#8217;avec des syst&#232;mes probabilistes. Elles ont &#233;galement
montr&#233; que les syst&#232;mes symboliques coupl&#233;s &#224; de tr&#232;s grands lexiques donnent de meilleurs r&#233;sultats que les</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FR&#201;D&#201;RIC B&#201;CHET, BENO&#206;T SAGOT, ROSA STERN
</p>
<p>syst&#232;mes probabilistes sur du texte canonique, en particulier en termes de pr&#233;cision. En revanche lorsque le texte &#224;
traiter contient du bruit (absence de capitalisation, de formatage, de ponctuation, sortie d&#8217;un syst&#232;me de reconnais-
sance de la parole. . .), les syst&#232;mes probabilistes sont plus robustes et obtiennent de meilleurs scores en rappel,
du moins tant que les donn&#233;es &#224; annoter sont d&#8217;un genre similaire &#224; celui du corpus de leur corpus apprentissage,
voire que les entit&#233;s nomm&#233;es y sont globalement les m&#234;mes.
</p>
<p>C&#8217;est &#224; partir de ce constat que nous avons d&#233;cid&#233; de tirer le meilleur parti des avantages des deux types de
syst&#232;mes, en effectuant des exp&#233;riences d&#8217;adaptation non supervis&#233;e du syst&#232;me probabiliste LIANE au domaine
des d&#233;p&#234;ches d&#8217;agence, qui n&#8217;est pas celui du corpus ESTER sur lequel il est entra&#238;n&#233;. Nous avons utilis&#233; pour cela
les annotations produites par le syst&#232;me symbolique NP coupl&#233; &#224; la base d&#8217;entit&#233;s Aleda, NP ayant &#233;t&#233; d&#233;velopp&#233;
plus particuli&#232;rement pour le traitement de d&#233;p&#234;ches d&#8217;agence. Apr&#232;s avoir d&#233;crit successivement NP (section 2) et
LIANE (section 3), nous d&#233;crivons le d&#233;tail de ce processus d&#8217;adaptation (section 4) puis en montrons les r&#233;sultats
sur le corpus d&#8217;&#233;valuation form&#233; de d&#233;p&#234;ches AFP d&#233;velopp&#233; par (Stern &amp; Sagot, 2010a) (section 5).
</p>
<p>2 NP, syst&#232;me &#224; base de r&#232;gles reposant sur la ressource lexicale Aleda
</p>
<p>Le syst&#232;me NP, dont une version pr&#233;c&#233;dente a &#233;t&#233; d&#233;crite par Stern &amp; Sagot (2010a), est un syst&#232;me de d&#233;tection,
typage et r&#233;solution d&#8217;entit&#233;s nomm&#233;es d&#233;velopp&#233; initialement pour le fran&#231;ais et en cours d&#8217;adaptation &#224; l&#8217;anglais.
Bien que g&#233;n&#233;rique, il a &#233;t&#233; con&#231;u en priorit&#233; pour le traitement de d&#233;p&#234;ches de l&#8217;Agence France-Presse. Il est donc
adapt&#233; aux donn&#233;es trait&#233;es dans ce travail. NP est constitu&#233; de deux modules, l&#8217;un pour la d&#233;tection ambigu&#235; et
l&#8217;autre pour la d&#233;sambigu&#239;sation et la r&#233;solution des mentions.
</p>
<p>Les deux modules qui constituent NP reposent surAleda, une base de donn&#233;es d&#8217;entit&#233;s et de mentions possibles de
ces entit&#233;s construite automatiquement &#224; partir de ressources librement disponibles. Aleda est distribu&#233;e librement
en tant que composante du projet lexical libre Alexina 1. Une version pr&#233;liminaire d&#8217;Aleda (int&#233;gr&#233;e &#224; l&#8217;&#233;poque
&#224; la distribution de SXPipe) est d&#233;crite par Stern &amp; Sagot (2010b). Aleda contient 855 403 entit&#233;s et 2,32 million
de variantes d&#233;notationnelles qui d&#233;notent des lieux (LOC), des organisations et entreprises (ORG), des personnes
(PERS), des produits, des noms d&#8217;&#339;uvres, des noms de produits et de marques, des animaux remarquables (Dolly)
et des personnages de fiction (Ars&#232;ne Lupin). Ces entit&#233;s ont &#233;t&#233; extraites principalement &#224; partir de deux sources
d&#8217;informations librement disponibles, &#224; savoir geonames pour les noms de lieu2 et la Wikipedia fran&#231;aise pour
les autres types d&#8217;entit&#233;s3. Chaque entit&#233; a un identifiant unique qui contient un identifiant de la ressource d&#8217;o&#249;
elle a &#233;t&#233; extraite, un identifiant interne &#224; chaque ressource (un identifiant geonames ou un identifiant d&#8217;article de
la Wikipedia fran&#231;aise) et des informations suppl&#233;mentaires dont un poids heuristique (le nombre d&#8217;habitants du
lieu pour geonames, le nombre de lignes de l&#8217;article correspondant dans Wikipedia).
</p>
<p>Pour les noms de lieux, nous avons tout d&#8217;abord extrait de la volumineuse base geonames les entit&#233;s dont le type
a &#233;t&#233; jug&#233; pertinent pour le traitement de d&#233;p&#234;ches d&#8217;agence (villes, pays, etc., mais pas les noms de montagnes
par exemple). M&#234;me ainsi filtr&#233;e, la base geonames contient beaucoup trop d&#8217;entit&#233;s pour que toutes puissent &#234;tre
utilis&#233;es. Nous avons donc s&#233;lectionn&#233; heuristiquement un certain nombre d&#8217;entit&#233;s jug&#233;es pertinentes au vu de la
nature des donn&#233;es &#224; traiter, &#224; savoir des d&#233;p&#234;ches AFP &#233;manant du bureau fran&#231;ais de l&#8217;Agence (474 509 entit&#233;s
de lieu). Pour les autres types d&#8217;entit&#233;s, nous nous sommes appuy&#233;s sur la Wikipedia fran&#231;aise, dans la lign&#233;e de
travaux ant&#233;rieurs (Balasuriya et al., 2009; Charton &amp; Torres-Moreno, 2009). Pour optimiser la couverture de la
ressource extraite, nous avons proc&#233;d&#233; &#224; une extraction en deux &#233;tapes, qui repose sur les cat&#233;gories wikipedia4.
Ce m&#233;canisme, bien qu&#8217;initi&#233; manuellement par un petit volume de donn&#233;es annot&#233;es, permet de r&#233;cup&#233;rer un
nombre tr&#232;s important d&#8217;entit&#233;s nomm&#233;es de la Wikipedia (400 169 entit&#233;s). Pour chacune de ces entit&#233;s, nous
extrayons un nom normalis&#233; qui est le titre de son article, un poids correspondant simplement au nombre de lignes
de l&#8217;article, ainsi que diff&#233;rentes variantes d&#233;notationnelles &#224; partir des liens de redirection. Pour les noms de
personnes, des variantes suppl&#233;mentaires sont calcul&#233;es avec pr&#233;noms abr&#233;g&#233;s et sans pr&#233;noms.
</p>
<p>1http://gforge.inria.fr/projects/alexina/
2geonames est librement t&#233;l&#233;chargeable sur http://www.geonames.org.
3http://download.wikimedia.org/frwiki/latest/frwiki-latest-pages-articles.xml.bz2
4Tout d&#8217;abord, nous avons associ&#233; manuellement &#224; quelques dizaines de cat&#233;gories wikipedia un type associ&#233; (par exemple N&#233; en 1983
</p>
<p>indique presque certainement une entit&#233; de type personne). Ceci nous a permis de typer un certain nombre d&#8217;articles wikipedia, dont nous
avons extrait toutes les cat&#233;gories. Nous avons alors identifi&#233; les cat&#233;gories associ&#233;es &#224; au moins 2 articles et permettant de pr&#233;dire le type
des entit&#233;s d&#233;j&#224; typ&#233;es avec une pr&#233;cision acceptable (75% sauf pour les cat&#233;gories rares). Nous avons alors repris l&#8217;ensemble des articles de
Wikipedia, et pour chaque article nous avons compt&#233; pour chaque type possible le nombre de fois qu&#8217;il est d&#233;clench&#233; par l&#8217;une des cat&#233;gories
associ&#233;es &#224; l&#8217;article. Le type le mieux class&#233; est alors attribu&#233; &#224; l&#8217;article.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ADAPTATION NON-SUPERVIS&#201;E D&#8217;UN SYST&#200;ME D&#8217;&#201;TIQUETAGE EN ENTIT&#201;S NOMM&#201;ES
</p>
<p>Le r&#233;sultat de ces deux processus d&#8217;extraction est enrichi et corrig&#233; par de courtes listes d&#8217;entit&#233;s &#224; &#233;liminer et &#224;
ajouter, d&#233;velopp&#233;es &#224; la main. Les 855 403 entit&#233;s qui forment ainsi Aleda se r&#233;partissent de la fa&#231;on suivante :
573 074 lieux et monuments, 215 179 personnes, 29 181 titres d&#8217;&#339;uvres, 25 247 organisations, 8 862 entreprises,
3 846 produits et marques, 997 personnages de fiction et 17 animaux remarquables.
</p>
<p>Une grammaire non-contextuelle de 137 r&#232;gles a &#233;t&#233; d&#233;velopp&#233;e pour d&#233;tecter et typer les mentions d&#8217;entit&#233;s
nomm&#233;es &#224; partir des mentions pr&#233;sentes dans Aleda ; des motifs contextuels (p.ex. ville/localit&#233;/village de ou
Dr/M./Mme. . .) sont &#233;galement utilis&#233;s. La reconnaissance est faite de fa&#231;on ambigu&#235; par l&#8217;architecture dag2dag
de SXPipe (Sagot &amp; Boullier, 2008). Des heuristiques de d&#233;sambigu&#239;sation sont appliqu&#233;es pour r&#233;duire en partie
cette ambigu&#239;t&#233;. La sortie de ce module est donc un graphe (DAG) dans lequel chaque entit&#233; nomm&#233;e candidate
(empan et type) est repr&#233;sent&#233;e par une transition diff&#233;rente.
</p>
<p>Un second module effectue alors deux t&#226;ches de fa&#231;on conjointe : il r&#233;sout les ambigu&#239;t&#233;s d&#8217;empan et de type
(PERS, LOC, ORG. . .) et assigne &#224; chaque mention une entr&#233;e dans la base (r&#233;solution). Comme pour la d&#233;tec-
tion, ce module de typage et de r&#233;solution repose sur des heuristiques utilisant des informations qualitatives et
quantitatives. Il fait par exemple usage du poids attribu&#233; aux entit&#233;s par Aleda ainsi que de la notion de saillance
pour favoriser les analyses impliquant des entit&#233;s d&#233;j&#224; rencontr&#233;es dans le m&#234;me document (ici, la m&#234;me d&#233;p&#234;che)
ou qui sont coh&#233;rentes avec le contexte (pays, ville) identifi&#233; dans le document.
</p>
<p>3 LIANE, syst&#232;me hybride g&#233;n&#233;ratif/discriminant
</p>
<p>Le processus de d&#233;tection d&#8217;entit&#233;s nomm&#233;es dans un texte est compos&#233; de deux sous-t&#226;ches : une t&#226;che de
segmentation consistant &#224; trouver les bornes de d&#233;but et de fin des entit&#233;s ; une t&#226;che de classification consistant
&#224; attribuer la bonne cat&#233;gorie &#224; l&#8217;entit&#233; d&#233;tect&#233;e (PERS, LOC, ORG. . .). Ces deux t&#226;ches peuvent &#234;tre effectu&#233;es
de mani&#232;re jointe si le processus de classification est appliqu&#233; au niveau des mots. Dans ce cas chaque mot
appartenant &#224; l&#8217;expression d&#8217;une entit&#233; nomm&#233;e re&#231;oit une &#233;tiquette correspondant &#224; la fois au type de l&#8217;entit&#233;
mais aussi &#224; sa position &#224; l&#8217;int&#233;rieur de celle-ci. Tous les mots ne participant pas &#224; l&#8217;expression d&#8217;une entit&#233;
re&#231;oivent une &#233;tiquette vide. Trois &#233;tiquettes de position sont utilis&#233;s : B indique le d&#233;but d&#8217;un chunk ; I indique
que le mot est situ&#233; &#224; l&#8217;int&#233;rieur d&#8217;un chunk mais ne le d&#233;bute pas ; et O correspond &#224; tous les mots hors chunks.
</p>
<p>En consid&#233;rant le processus de d&#233;tection des entit&#233;s nomm&#233;es comme un processus d&#8217;&#233;tiquetage, gr&#226;ce aux &#233;ti-
quettes de positionnement et de type d&#8217;entit&#233;s, toutes les m&#233;thodes d&#233;velopp&#233;es dans le cadre de l&#8217;&#233;tiquetage en
parties du discours (POS) peuvent &#234;tre utilis&#233;es, notamment les m&#233;thodes num&#233;riques. Parmi celles-ci, deux prin-
cipales approches ont &#233;t&#233; suivies : les mod&#232;les g&#233;n&#233;ratifs tels que les Mod&#232;les de Markov Cach&#233;s (Hidden Markov
Models - HMM) (Bikel et al., 1999) et les mod&#232;les discriminants tels que MaxEnt (Brothwick et al., 1998) ou les
Champs de Markov Al&#233;atoires (Conditional Random Field - CRF) (McCallum &amp; Li, 2003).
</p>
<p>Le syst&#232;me LIANE utilis&#233; dans cette &#233;tude est d&#233;crit dans Bechet &amp; Charton (2010). Il est bas&#233; sur une approche
mixte utilisant tout d&#8217;abord un processus g&#233;n&#233;ratif &#224; base de HMM pour pr&#233;dire une &#233;tiquette syntaxique (POS) et
s&#233;mantique &#224; chaque mot d&#8217;un texte ; ensuite un processus discriminant &#224; base de CRF est utilis&#233; pour trouver les
bornes et le type complet de chaque entit&#233; en utilisant le mod&#232;le BIO pr&#233;sent&#233; pr&#233;c&#233;demment. Il y a deux raisons
pour justifier l&#8217;emploi d&#8217;un HMM en amont d&#8217;un &#233;tiqueteur &#224; base de CRF :
&#8211; Tout d&#8217;abord les mod&#232;les d&#8217;&#233;tiquetage par HMM permettent de rajouter tr&#232;s facilement plusieurs sources d&#8217;in-
formation dans les estimations des probabilit&#233;s des mots sachant les classes. Ils sont &#233;galement assez tol&#233;rants
au bruit dans les donn&#233;es d&#8217;apprentissage, &#224; partir du moment o&#249; les fr&#233;quences relatives des diff&#233;rents &#233;v&#233;ne-
ments mod&#233;lis&#233;s sont respect&#233;es.
</p>
<p>&#8211; Ensuite cette premi&#232;re phase d&#8217;&#233;tiquetage va permettre d&#8217;enlever un certain nombre d&#8217;ambigu&#239;t&#233;s en attribuant
des &#233;tiquettes syntaxiques et s&#233;mantiques aux mots d&#8217;un texte. Cela permettra de simplifier l&#8217;&#233;tiquetage par le
CRF qui pourra se concentrer sur les aspects de segmentation et d&#8217;attribution d&#8217;une &#233;tiquette finale.
</p>
<p>Les mod&#232;les HMM et CRF sont appris sur un corpus annot&#233; selon le format suivant (sur la phrase d&#8217;exemple
&#8220;Investiture aujourd&#8217;hui &#224; Bamako Mali du pr&#233;sident Amadou Toumani Tour&#233;&#8221;) :
</p>
<p>investiture NFS O du PREPDU O
aujourd&#8217;hui ADV B-TIME pr&#233;sident NMS O
&#224; PREPADE O Amadou PERS B-PERS
Bamako LOC B-LOC Toumani PERS I-PERS
Mali LOC B-LOC Tour&#233; PERS I-PERS</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FR&#201;D&#201;RIC B&#201;CHET, BENO&#206;T SAGOT, ROSA STERN
</p>
<p>4 Adaptation du syst&#232;me statistique &#224; un nouveau domaine
</p>
<p>Comme d&#233;crit dans Bechet &amp; Charton (2010), le syst&#232;me LIANE a &#233;t&#233; d&#233;velopp&#233; dans le cadre de la campagne
d&#8217;&#233;valuation ESTER portant sur la transcription et l&#8217;annotation en entit&#233;s nomm&#233;es d&#8217;&#233;missions de radio, prin-
cipalement des journaux d&#8217;information. Les corpus d&#8217;apprentissage utilis&#233;s sont ceux de la campagne ESTER,
constitu&#233; d&#8217;une centaine d&#8217;heures de transcriptions annot&#233;es en entit&#233;s nomm&#233;es. Le corpus cible de cette &#233;tude
est un corpus de d&#233;p&#234;ches AFP. Bien que le contenu th&#233;matique de ces deux cadres applicatifs soit proche (des
donn&#233;es d&#8217;actualit&#233;), le type de langue utilis&#233; est diff&#233;rent : transcriptions de l&#8217;oral pour le corpus ESTER prove-
nant de sources multiples (France Inter, RFI, Radio Africa, Radio Tele Maroc, etc.). L&#8217;&#233;tude des r&#233;sultats obtenus
apr&#232;s application du syst&#232;me LIANE au corpus AFP nous a permis de distinguer deux types de probl&#232;mes :
&#8211; manque de couverture lexicale : les donn&#233;es ESTER contiennent des &#233;missions diffus&#233;es en 2007 et d&#233;but 2008
alors que les d&#233;p&#234;ches AFP analys&#233;es couvrent des p&#233;riodes plus r&#233;centes ;
</p>
<p>&#8211; mauvaise mod&#233;lisation des ph&#233;nom&#232;nes sp&#233;cifiques &#224; l&#8217;&#233;crit : le corpus ESTER &#233;tant compos&#233; de transcription
de l&#8217;oral, il ne contient aucun &#171; raccourci &#187; sp&#233;cifique &#224; l&#8217;&#233;crit tels que l&#8217;emploi d&#8217;abr&#233;viations (la graphieM. par
exemple dans la s&#233;quenceM. Dupond) ou l&#8217;ajout d&#8217;informations compl&#233;mentaires par l&#8217;emploi de caract&#232;res de
formatage (p.ex. les incises avec des parenth&#232;ses telles que : Le syndicat Force Ouvri&#232;re (FO) a annonc&#233;. . .).
</p>
<p>L&#8217;adaptation d&#8217;un syst&#232;me statistique &#224; un nouveau domaine n&#233;cessite g&#233;n&#233;ralement l&#8217;annotation manuelle d&#8217;un
corpus d&#8217;adaptation couvrant les nouveaux ph&#233;nom&#232;nes &#224; mod&#233;liser. Ce corpus d&#8217;adaptation est souvent de taille
modeste en raison du co&#251;t &#233;lev&#233; des annotations en entit&#233;s nomm&#233;es. Comme indiqu&#233; dans l&#8217;introduction, nous
avons explor&#233; une voie alternative qui consiste &#224; annoter automatiquement un corpus de tr&#232;s grande taille. Nous
avons utilis&#233; pour cela le syst&#232;me NP, sp&#233;cialis&#233; dans notre domaine cible, celui des d&#233;p&#234;ches d&#8217;agence. L&#8217;objectif
est d&#8217;obtenir sans co&#251;t suppl&#233;mentaire (aucune supervision n&#8217;est n&#233;cessaire) un syst&#232;me statistique adapt&#233; &#224; un
domaine particulier &#224; partir d&#8217;un syst&#232;me symbolique existant. Ces deux types de syst&#232;mes ayant des particularit&#233;s
compl&#233;mentaires (pr&#233;cision &#233;lev&#233;e pour le syst&#232;me symbolique, rappel important et robustesse au bruit pour le
syst&#232;me statistique), il est int&#233;ressant de disposer des deux selon les applications vis&#233;es.
</p>
<p>La proc&#233;dure d&#8217;adaptation non supervis&#233;e utilis&#233;e ici a consist&#233; tout d&#8217;abord &#224; collecter un corpus d&#8217;adaptation
brut, non annot&#233;, appel&#233; CA. Nous avons utilis&#233; ici un corpus de d&#233;p&#234;ches de l&#8217;AFP des ann&#233;es 2009 et 2010
constitu&#233; de 83M de mots (3M de phrases). Nous avons annot&#233; en entit&#233;s nomm&#233;es le corpus CA avec le syst&#232;me
NP. Nous avons ainsi d&#233;tect&#233; 3,2M d&#8217;occurrences d&#8217;entit&#233;s nomm&#233;es, repr&#233;sentant 168K entit&#233;s distinctes.
</p>
<p>Le corpus CA a aussi &#233;t&#233; &#233;tiquet&#233; avec l&#8217;&#233;tiqueteur morphosyntaxique HMM du syst&#232;me LIANE. Nous avons
enfin &#171; fusionn&#233; &#187; les &#233;tiquettes de parties de discours et les &#233;tiquettes d&#8217;entit&#233;s nomm&#233;es comme suit : tout nom
propre ou mot inconnu contenu dans une entit&#233; nomm&#233;e de type t d&#233;tect&#233; par NP re&#231;oit l&#8217;&#233;tiquette t comme partie
de discours. Nous avons obtenu ainsi le corpus C &#8242;A &#233;tiquet&#233; &#224; la fois en partie de discours et en entit&#233;s nomm&#233;es.
</p>
<p>Par exemple, pour la phrase le commissaire du Portugal Jorge Palmeirim, le syst&#232;me NP a produit :
le commissaire du &lt;EN type=&quot;Location&quot; name=&quot;Portuguese Republic&quot;&gt;Portugal&lt;/EN&gt;
&lt;EN type=&quot;Person&quot; name=&quot;Jorge Palmeirim&quot;&gt;Jorge Palmeirim&lt;/EN&gt;.
</p>
<p>De son cot&#233;, l&#8217;&#233;tiqueteur HMM de LIANE a produit l&#8217;annotation suivante :
(le DET)(commissaire N)(du PREP)(Portugal ORG)(Jorge PERS)(Palmeirim UNK).
</p>
<p>&#192; partir de ces deux annotations, nous produisons automatiquement le corpus :
</p>
<p>le DET O Portugal LOC B-LOC
commissaire N O Jorge PERS B-PERS
du PREP O Palmeirim PERS I-PERS
</p>
<p>Les distributions du mod&#232;le HMM ont &#233;t&#233; directement r&#233;estim&#233;es sur C &#8242;A, produisant ainsi la version adapt&#233;e
LIANE 1. Pour l&#8217;&#233;tiqueteur CRF, le corpus d&#8217;apprentissage constitu&#233; des corpus ESTER annot&#233;s manuellement
a &#233;t&#233; enrichi avec des phrases s&#233;lectionn&#233;es du corpus C &#8242;A, avec un crit&#232;re qui repose sur la fr&#233;quence des entit&#233;s
d&#233;tect&#233;es : en s&#233;lectionnant les phrases contenant les entit&#233;s les plus fr&#233;quentes on esp&#232;re diminuer le risque
d&#8217;erreur d&#8217;&#233;tiquetage dans les donn&#233;es d&#8217;apprentissage. Pour &#233;viter que quelques entit&#233;s ne repr&#233;sentent &#224; elles
seules la majorit&#233; des exemples retenus, nous avons &#233;galement limit&#233; le nombre maximum de phrases contenant
chaque entit&#233;. Ainsi nous gardons n phrases parmi toutes celles contenant les entit&#233;s d&#233;tect&#233;es plus de x fois dans
le corpus. En faisant varier n et x on peut mesurer l&#8217;impact de l&#8217;ajout de donn&#233;es annot&#233;es automatiquement dans
les corpus d&#8217;apprentissage de LIANE. L&#8217;utilisation compl&#232;te du corpus (n = 400, x = 10) permet de produire le
second syst&#232;me adapt&#233;, nomm&#233; LIANE 2.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ADAPTATION NON-SUPERVIS&#201;E D&#8217;UN SYST&#200;ME D&#8217;&#201;TIQUETAGE EN ENTIT&#201;S NOMM&#201;ES
</p>
<p>Syst&#232;mes NP LIANE (sans adapt.) LIANE 1 (adapt. lex.) LIANE 2 (adapt. lex.+segm.)
Entit&#233; Precision Rappel Precision Rappel Precision Rappel Precision Rappel
LOC 86.4 86.3 81.6 80.7 82.2 81.5 69.8 85.1
ORG 94.6 48.1 51.4 55.5 52.6 58.0 53.0 59.1
PERS 92.1 82.1 81.3 88.4 81.1 91.0 78.3 93.6
</p>
<p>TAB. 1 &#8211; R&#233;sultats comparatifs en pr&#233;cision et rappel de NP, LIANE, et des deux adaptations de LIANE r&#233;alis&#233;es
gr&#226;ce aux donn&#233;es annot&#233;es automatiquement par NP
</p>
<p> 50
</p>
<p> 51
</p>
<p> 52
</p>
<p> 53
</p>
<p> 54
</p>
<p> 55
</p>
<p> 56
</p>
<p> 57
</p>
<p> 58
</p>
<p> 59
</p>
<p> 60
</p>
<p> 1  2  3  4  5  6
</p>
<p>Rappel - ORG noadapt
Rappel - ORG adapt
Prec - ORG noadapt
</p>
<p>Prec - ORG adapt
</p>
<p> 76
</p>
<p> 78
</p>
<p> 80
</p>
<p> 82
</p>
<p> 84
</p>
<p> 86
</p>
<p> 88
</p>
<p> 90
</p>
<p> 92
</p>
<p> 94
</p>
<p> 1  2  3  4  5  6
</p>
<p>Rappel - PERS noadapt
Rappel - PERS adapt
Prec - PERS noadapt
</p>
<p>Prec - PERS adapt
</p>
<p>FIG. 1 &#8211; Courbes d&#8217;apprentissage de LIANE sur les cat&#233;gories PERS et ORG en fonction du volume des donn&#233;es
d&#8217;apprentissage issues du corpus &#233;tiquet&#233; par NP. Les r&#233;sultats sont donn&#233;s avec et sans adaptation lexicale.
</p>
<p>5 R&#233;sultats
</p>
<p>L&#8217;&#233;valuation de NP, de la version initiale de LIANE et des versions adapt&#233;es d&#233;crites &#224; la section pr&#233;c&#233;dente a &#233;t&#233;
r&#233;alis&#233;e sur une nouvelle version du corpus de r&#233;f&#233;rence d&#233;velopp&#233; et utilis&#233; par Stern &amp; Sagot (2010b), corpus
qui est disponible librement dans le cadre de la distribution de SXPipe. Ce corpus, form&#233; de 100 d&#233;p&#234;ches AFP
contenant chacune une moyenne de 300 mots, a &#233;t&#233; annot&#233; manuellement en entit&#233;s nomm&#233;es sous forme de
marqueurs XML balisant le texte. Ces balises, outre l&#8217;empan de chaque mention, contiennent des informations sur
son type ainsi que sur son r&#233;f&#233;rent repr&#233;sent&#233; par un num&#233;ro d&#8217;entr&#233;e dans la base Aleda. Dans son &#233;tat actuel, ce
corpus de r&#233;f&#233;rence ne contient des annotations que pour des entit&#233;s de type PERS, LOC et ORG (y compris les
noms d&#8217;entreprises)5. Il contient un total de 1456 mentions d&#8217;entit&#233;s.
</p>
<p>Les r&#233;sultats sont donn&#233;s en fonction des mesures de rappel et pr&#233;cision strictes : une hypoth&#232;se est consid&#233;r&#233;e
comme correcte uniquement si sa segmentation et son typage son corrects6. Comme le montre le tableau 1, le
syst&#232;me NP donne de bons r&#233;sultats en terme de pr&#233;cision pour les trois types d&#8217;entit&#233;s. Le rappel sur les LOC est
&#233;galement &#233;lev&#233; (86.3%), illustrant ainsi l&#8217;apport de la base d&#8217;entit&#233;s Aleda. Comme pr&#233;vu, le syst&#232;me LIANE
obtient une pr&#233;cision plus faible, mais un rappel int&#233;ressant pour les entit&#233;s ORG et PERS. Les r&#233;sultats de LIANE
s&#8217;am&#233;liorent significativement en adaptant ce syst&#232;me, d&#8217;une part au niveau lexical en r&#233;estimant les distributions
de l&#8217;&#233;tiqueteur HMM, mais &#233;galement au niveau segmentation en ajoutant au corpus d&#8217;apprentissage des CRF des
phrases annot&#233;s par NP. Le gain en terme de rappel est de l&#8217;ordre de 4% en absolu pour chaque cat&#233;gorie. Rappe-
lons que cette adaptation est non supervis&#233;e et qu&#8217;elle a pour but d&#8217;obtenir un syst&#232;me statistique compl&#233;mentaire
au syst&#232;me symbolique NP. La figure 1 illustre cette compl&#233;mentarit&#233; en montrant les courbes d&#8217;apprentissage du
syst&#232;me LIANE sur les cat&#233;gories ORG et PERS lorsque l&#8217;on fait cro&#238;tre le volume de donn&#233;es AFP annot&#233;es
par NP ajout&#233; au corpus d&#8217;apprentissage des CRF7. On constate que le rappel augmente en fonction de l&#8217;ajout de
donn&#233;es, mais au prix d&#8217;une certaine diminution en pr&#233;cision. L&#8217;augmentation du rappel est encourageante dans
la perspective d&#8217;int&#233;grer plus encore les deux types de syst&#232;mes, par rapport &#224; un cadre applicatif pr&#233;cis, pour
exploiter au mieux la bonne pr&#233;cision des mod&#232;les symboliques et le bon rappel des mod&#232;les num&#233;riques.
</p>
<p>5Les annotations de mentions ne comprennent pas les tokens non constitutifs du nom de l&#8217;entit&#233; lui-m&#234;me : les titres pr&#233;c&#233;dant les noms
de personnes notamment en sont exclus (Mme ou Dr).
</p>
<p>6Les mesures utilis&#233;es dans ESTER &#233;taient plus graduelles, donnant un poids diff&#233;rents aux erreurs de fronti&#232;re, de typage ainsi qu&#8217;aux
erreurs de reconnaissance dues &#224; la transcription automatique de la parole
</p>
<p>7les 6 points d&#8217;abscisse de ces courbes correspondent respectivement &#224; des volumes de 0, 127K, 209K, 498K, 1,2M et 1,9M mots ajout&#233;s
aux 1,3M mots du corpus ESTER</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FR&#201;D&#201;RIC B&#201;CHET, BENO&#206;T SAGOT, ROSA STERN
</p>
<p>6 Conclusion et perspectives
</p>
<p>La traditionnelle opposition entre m&#233;thodes symboliques et m&#233;thodes num&#233;riques a nourri quantit&#233; de d&#233;bats &#224;
l&#8217;occasion de campagnes d&#8217;&#233;valuation sur des t&#226;ches telles que l&#8217;&#233;tiquetage en parties de discours ou l&#8217;annotation
en entit&#233;s nomm&#233;es. Si aucune m&#233;thode ne s&#8217;est av&#233;r&#233;e gagnante dans toutes les conditions de tests, ces deux
familles de m&#233;thodes ont montr&#233; des comportements diff&#233;rents, et fortement compl&#233;mentaires, que l&#8217;on peut
r&#233;sumer de fa&#231;on simplificatrice comme suit : bonne pr&#233;cision pour les approches symboliques, bon rappel pour les
approches num&#233;riques. Nous avons montr&#233; dans cette &#233;tude comment cette compl&#233;mentarit&#233; pouvait &#234;tre exploit&#233;e
pour adapter un syst&#232;me num&#233;rique d&#8217;annotation en entit&#233;s nomm&#233;es &#224; une nouvelle t&#226;che &#224; l&#8217;aide d&#8217;un syst&#232;me
symbolique. Cette adaptation nous permet de disposer de deux syst&#232;mes compl&#233;mentaires, l&#8217;un privil&#233;giant la
pr&#233;cision, l&#8217;autre le rappel, sans n&#233;cessiter aucune annotation suppl&#233;mentaire, illustrant la compl&#233;mentarit&#233; des
m&#233;thodes num&#233;riques et symboliques pour la r&#233;solution de t&#226;ches linguistiques.
</p>
<p>L&#8217;interaction NP et LIANE, qui est donc ici une instance simplifi&#233;e du paradigme du co-training, pourrait toutefois
&#234;tre pouss&#233;e plus avant. Des exp&#233;riences en marge de ce travail visant &#224; int&#233;grer un lexique issu d&#8217;Aleda aux
versions adapt&#233;es de LIANE se sont av&#233;r&#233;es inop&#233;rantes, probablement parce que les corpus annot&#233;s par NP
utilis&#233;s pour l&#8217;entra&#238;nement int&#233;graient d&#233;j&#224; une partie importante de ces informations lexicales. Mais un couplage
plus fin avec Aleda, notamment en prenant en compte les poids associ&#233;s aux entit&#233;s, devrait permettre d&#8217;am&#233;liorer
les r&#233;sultats de LIANE. &#192; l&#8217;inverse, la sortie de LIANE pourrait servir de source d&#8217;information au module de NP
charg&#233; de la d&#233;sambigu&#239;sation. Ces pistes, et d&#8217;autres, devraient confirmer les r&#233;sultats pr&#233;sent&#233;s ici et valider la
pertinence d&#8217;approches mixtes ou hybrides pour des t&#226;ches telles que la reconnaissance d&#8217;entit&#233;s nomm&#233;es.
</p>
<p>Remerciements
</p>
<p>Ce travail a &#233;t&#233; effectu&#233; dans le cadre du projet ANR EDyLex (ANR-09-CORD-008).
</p>
<p>R&#233;f&#233;rences
</p>
<p>BALASURIYA D., RINGLAND N., NOTHMAN J., MURPHY T. &amp; CURRAN J. R. (2009). Named entity recog-
nition in wikipedia. In People&#8217;s Web &#8217;09 : Proceedings of the 2009 Workshop on The People&#8217;s Web Meets NLP,
p. 10&#8211;18, Suntec, Singapour.
BECHET F. &amp; CHARTON E. (2010). Unsupervised knowledge acquisition for extracting named entities from
speech. In 2010 IEEE International Conference on Acoustics, Speech and Signal Processing.
BIKEL D. M., SCHWARTZ R. L. &amp; WEISCHEDEL R. M. (1999). An algorithm that learns what&#8217;s in a name.
Machine Learning, 24(1-3), 211&#8211;231.
BROTHWICK A., STERLING J., AGICHTEIN E. &amp; GRISHMAN R. (1998). Exploiting diverse knowledge sources
via maximum entropy in named entity recognition. In 6th Workshop on Very Large Corpora (ACL &#8217;98), Montr&#233;al.
B&#201;CHET F. (2011). Named Entity Recognition. In G. TUR &amp; R. DE MORI, Eds., Spoken Language Understan-
ding : systems for extracting semantic information from speech, p. 257&#8211;290. Wiley.
CHARTON E. &amp; TORRES-MORENO J.-M. (2009). Classification d&#8217;un contenu encyclop&#233;dique en vue d&#8217;un
&#233;tiquetage par entit&#233;s nomm&#233;es. In Actes de TALN 2009, Senlis, France.
GALLIANO S., GRAVIER G. &amp; CHAUBARD L. (2009). The Ester 2 Evaluation Campaign for the Rich Trans-
cription of French Radio Broadcasts. In Interspeech 2009.
MCCALLUM A. &amp; LI W. (2003). Early results for named entity recognition with conditional random fields,
feature induction and web-enhanced lexicons. In Seventh Conference on Natural Language Learning (CoNLL).
SAGOT B. &amp; BOULLIER P. (2008). SXPipe 2 : architecture pour le traitement pr&#233;syntaxique de corpus bruts.
Traitement Automatique des Langues (T.A.L.), 49(2), 155&#8211;188.
STERN R. &amp; SAGOT B. (2010a). D&#233;tection et r&#233;solution d&#8217;entit&#233;s nomm&#233;es dans des d&#233;p&#234;ches d&#8217;agence. In
Actes de la Conf&#233;rence TALN 2010, Montr&#233;al, Canada.
STERN R. &amp; SAGOT B. (2010b). Resources for named entity recognition and resolution in news wires. In
Proceedings of LREC 2010 Workshop on Resources and Evaluation for Identity Matching, Entity Resolution and
Entity Management, La Valette, Malte.</p>

</div></div>
</body></html>