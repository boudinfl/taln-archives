TALN 2011, Montpellier, 27juin — 1"'ju1'11et 2011

Coopération de méthodes statistiques et symboliques pour l’adaptation
non-supervisée d’un systéme d’étiquetage en entités nommées

Frederic Bechetl, Benoit Sagot2, Rosa Stern2’3
(1) Aix Marseille Universite, LIF-CNRS, route de Luminy, Marseille
(2) Alpage, INRIA & Univ. Paris 7, Rocquencourt, BP 105, 78153 Le Chesnay Cedex, France
(3) Agence France-Presse — Medialab, 2 place de la Bourse, 75002 Paris, France

frederic .bechet@lif . univ—mrs . fr, benoit . sagot@inria . fr, rosa . stern@afp . com

Resume. La detection et le typage des entites nommees sont des taches pour lesquelles ont ete developpes
a la fois des systemes symboliques et probabilistes. Nous presentons les resultats d’ une experience Visant a faire
interagir le systeme a base de regles NP, developpe sur des corpus provenant de l’AFP, integrant la base d’ entites
Aleda et qui a une bonne precision, et le systeme LIANE, entraine sur des transcriptions de l’oral provenant du
corpus ESTER et qui a un bon rappel. Nous montrons qu’on peut adapter a un nouveau type de corpus, de maniere
non supervisee, un systeme probabiliste tel que LIANE grace a des corpus volumineux armotes automatiquement
par NP. Cette adaptation ne necessite aucune annotation manuelle supplementaire et illustre la complementarite
des methodes numeriques et symboliques pour la resolution de taches linguistiques.

Abstract. Named entity recognition and typing is achieved both by symbolic and probabilistic systems. We
report on an experiment for making the rule-based system NP, a high-precision system developed on AFP news
corpora and relies on the Alecia named entity database, interact with LIANE, a high—recall probabilistic system
trained on oral transcriptions from the ESTER corpus. We show that a probabilistic system such as LIANE can be
adapted to a new type of corpus in a non—supervized way thanks to large—scale corpora automatically armotated by
NP. This adaptation does not require any additional manual anotation and illustrates the complementarity between
numeric and symbolic techniques for tackling linguistic tasks.

M0tS-CléS 3 Detection d’entites nommees, adaptation a un nouveau domaine, cooperation entre approches
probabilistes et symboliques.

Keywords: Named entity recognition, domain adaptation, cooperation between probabilistic and sy1n—
bolic approaches.

1 Introduction

La reconnaissance d’entites nommees est une des taches les plus etudiees du domaine du traitement automa-
tique des langues. Reconnaitre dans du texte ou de la transcription de parole les mentions d’entites nommees
reste un prealable necessaire avant toute tache plus complexe telle que l’analyse syntaxique, l’analyse semantique
ou l’extraction d’informations. Ainsi, la tache de reconnaissance d’entites nommees fait l’objet de nombreuses
campagnes d’evaluation depuis plus d’une vingtaine d’annees, dont les premieres ont ete les campagnes MUC
(Message Understanding Conference). Ces campagnes ont donne lieu a la construction de corpus de reference,
notamment pour l’anglais, le chinois, l’espagnol ou le japonais. Pour le frangais, on peut citer notamment l’eva—
luation menee dans le cadre de la campagne ESTER sur des transcriptions de nouvelles, qui a donne naissance a un
corpus frangais annote en entites nommees selon des directives assez differentes de celles des campagnes MUC,
notamment pour les emplois polysemiques et metaphoriques (Galliano et al., 2009). Pour une discussion plus
precise de ces questions et des differents types d’ ambigu'1'tes rencontrees en reconnaissance des entites nommees,
on pourra se reporter at (Bechet, 2011).

Toutes les campagnes d’ evaluation ont montre que la tache de reconnaissance d’entites nommees peut etre traitee
efﬁcacement aussi bien avec des systemes symboliques qu’avec des systemes probabilistes. Elles ont egalement
montre que les systemes symboliques couples a de tres grands lexiques donnent de meilleurs resultats que les

FREDERIC BECHET, BENoiT SAGOT, ROSA STERN

systemes probabilistes sur du texte canonique, en particulier en termes de precision. En revanche lorsque le texte a
traiter contient du bruit (absence de capitalisation, de formatage, de ponctuation, sortie d’un systeme de reconnais-
sance de la parole. . .), les systemes probabilistes sont plus robustes et obtiennent de meilleurs scores en rappel,
du moins tant que les données a annoter sont d’ un genre sirnilaire a celui du corpus de leur corpus apprentissage,
Voire que les entités nommées y sont globalement les memes.

C’est a partir de ce constat que nous avons decide de tirer le meilleur parti des avantages des deux types de
systemes, en effectuant des experiences d’adaptation non supervisée du systeme probabiliste LIANE au domaine
des dépeches d’agence, qui n’est pas celui du corpus ESTER sur lequel il est entrainé. Nous avons utilise pour cela
les annotations produites par le systeme symbolique NP couple a la base d’ entités Aleda, NP ayant été développe
plus particulierement pour le traitement de depeches d’agence. Apres avoir decrit successivement NP (section 2) et
LIANE (section 3), nous décrivons le detail de ce processus d’adaptation (section 4) puis en montrons les resultats
sur le corpus d’éValuation formé de dépeches AFP developpe par (Stern & Sagot, 2010a) (section 5).

2 NP, systéme £1 base de régles reposant sur la ressource lexicale Aleda

Le systeme NP, dont une Version précédente a ete decrite par Stern & Sagot (2010a), est un systeme de detection,
typage et resolution d’ entités nommées développé initialement pour le frangais et en cours d’ adaptation a l’ anglais.
Bien que generique, il a eté congu en priorité pour le traitement de dépeches de l’Agence France—Presse. Il est donc
adapte aux données traitées dans ce travail. NP est constitue de deux modules, l’un pour la detection ambigue et
l’autre pour la désambigu'1'sation et la resolution des mentions.

Les deux modules qui constituent NP reposent sur Aleda, une base de données d’ entités et de mentions possibles de
ces entités construite automatiquement a partir de ressources librement disponibles. Aleda est distribuée librement
en tant que composante du proj et lexical libre Alexina 1. Une Version preliminaire d’ Aleda (intégrée a l’époque
a la distribution de SXPipe) est décrite par Stern & Sagot (20l0b). Aleda contient 855 403 entites et 2,32 million
de Variantes dénotationnelles qui denotent des lieux (LOC), des organisations et entreprises (ORG), des personnes
(PERS), des produits, des noms d’oeuVres, des noms de produits et de marques, des animaux remarquables (Dolly)
et des personnages de ﬁction (Arséne Lupin). Ces entités ont eté extraites principalement a partir de deux sources
d’informations librement disponibles, a savoir geonames pour les noms de lieu2 et la Wikipedia frangaise pour
les autres types d’entités3. Chaque entité a un identiﬁant unique qui contient un identiﬁant de la ressource d’ ou
elle a eté extraite, un identiﬁant inteme a chaque ressource (un identiﬁant geonames ou un identiﬁant d’article de
la Wikipedia francaise) et des informations supplémentaires dont un poids heuristique (le nombre d’habitants du
lieu pour geonames, le nombre de lignes de l’a1ticle correspondant dans Wikipedia).

Pour les noms de lieux, nous avons tout d’abord extrait de la Volumineuse base geonames les entités dont le type
a eté jugé pertinent pour le traitement de dépeches d’ agence (Villes, pays, etc., mais pas les noms de montagnes
par exemple). Meme ainsi ﬁltrée, la base geonames contient beaucoup trop d’entités pour que toutes puissent etre
utilisees. Nous avons donc sélectionné heuristiquement un certain nombre d’ entités jugees pertinentes au Vu de la
nature des données a traiter, a savoir des dépeches AFP emanant du bureau frangais de l’Agence (474 509 entités
de lieu). Pour les autres types d’ entites, nous nous sommes appuyés sur la Wikipedia frangaise, dans la lignee de
travaux antérieurs (Balasuriya et al., 2009; Charton & Torres—Moreno, 2009). Pour optimiser la couverture de la
ressource extraite, nous avons procédé a une extraction en deux etapes, qui repose sur les catégories wikipedia4.
Ce mécanisme, bien qu’initié manuellement par un petit Volume de données annotées, permet de recuperer un
nombre tres important d’entités nommées de la Wikipedia (400 169 entites). Pour chacune de ces entités, nous
extrayons un nom normalise qui est le titre de son article, un poids correspondant simplement au nombre de lignes
de l’article, ainsi que differentes Variantes dénotationnelles a partir des liens de redirection. Pour les noms de
personnes, des Variantes supplémentaires sont calculées avec prénoms abrégés et sans prénoms.

Ihttp://gforge.inria.fr/projects/alexina/

Zgeonames est librement téléchargeable sur http : / /www . geonames . org.

3http : //download. wikimedia . org/frwiki/latest/frwiki—latest—pages—articles . xml .bz2

4Tout d’abord, nous avons associé manuellement a quelques dizaines de catégories wikipedia un type associé (par exemple Ne’ en 1983
indique presque certainement une entité de type personne). Ceci nous a permis de typer un certain nombre d’articles wikipedia, dont nous
avons extrait toutes les catégories. Nous avons alors identiﬁé les catégories associées 51 au moins 2 articles et permettant de prédire le type
des entités déja typées avec une précision acceptable (75% sauf pour les catégories rares). Nous avons alors repris l’ensemble des articles de
Wikipedia, et pour chaque article nous avons compté pour chaque type possible le nombre de fois qu’il est déclenché par l’une des catégories
associées a l’article. Le type le mieux classé est alors attribué a l’article.

ADAPTATION NON-SUPERVISEE D’UN SYSTEME D’ETIQUETAGE EN ENTITES NOMMEES

Le résultat de ces deux processus d’ extraction est enrichi et corrigé par de courtes listes d’entités a éliminer et a
aj outer, développées a la main. Les 855 403 entités qui forment ainsi Aleda se répartissent de la fagon suivante :
573 074 lieux et monuments, 215 179 personnes, 29 181 titres d’oeuvres, 25 247 organisations, 8 862 entreprises,
3 846 produits et marques, 997 personnages de ﬁction et 17 animaux remarquables.

Une grammaire non—contextuelle de 137 regles a ete developpee pour détecter et typer les mentions d’entites
nommées a partir des mentions présentes dans Aleda; des motifs contextuels (p.ex. ville/localite’/ﬁzillage de ou
Drﬂl/I./Mme. . .) sont également utilises. La reconnaissance est faite de fagon ambigue par l’architecture dag2 dag
de SXPipe (Sagot & Boullier, 2008). Des heuristiques de desambigu'1'sation sont appliquées pour reduire en partie
cette ambigu'1'té. La sortie de ce module est donc un graphe (DAG) dans lequel chaque entité nommée candidate
(empan et type) est représentée par une transition différente.

Un second module effectue alors deux taches de fagon conjointe : il resout les ambigu'1'tés d’empan et de type
(PERS, LOC, ORG. . .) et assigne a chaque mention une entree dans la base (resolution). Comme pour la detec-
tion, ce module de typage et de resolution repose sur des heuristiques utilisant des informations qualitatives et
quantitatives. ll fait par exemple usage du poids attribué aux entités par Aleda ainsi que de la notion de saillance
pour favoriser les analyses impliquant des entités deja rencontrées dans le meme document (ici, la meme dépeche)
ou qui sont coherentes avec le contexte (pays, ville) identiﬁé dans le document.

3 LIANE, systéme hybride génératif/discriminant

Le processus de detection d’entités nommées dans un texte est compose de deux sous—taches : une tache de
segmentation consistant a trouver les bomes de debut et de ﬁn des entités; une tache de classiﬁcation consistant
a attribuer la bonne categorie a l’entité detectee (PERS, LOC, ORG. . .). Ces deux taches peuvent etre effectuées
de maniere jointe si le processus de classiﬁcation est applique au niveau des mots. Dans ce cas chaque mot
appartenant a l’expression d’une entité nommée regoit une etiquette correspondant a la fois au type de l’entite
mais aussi a sa position a l’intérieur de celle-ci. Tous les mots ne participant pas a l’expression d’une entité
recoivent une etiquette vide. Trois etiquettes de position sont utilises : B indique le debut d’un chunk; I indique
que le mot est situé a l’interieur d’un chunk mais ne le débute pas; et 0 correspond a tous les mots hors chunks.

En considérant le processus de detection des entités nommées comme un processus d’étiquetage, grace aux eti-
quettes de positionnement et de type d’entités, toutes les méthodes développées dans le cadre de l’etiquetage en
parties du discours (POS) peuvent etre utilisees, notamment les méthodes numeriques. Parmi celles—ci, deux prin-
cipales approches ont eté suivies : les modeles generatifs tels que les Modeles de Markov Caches (Hidden Markov
Models — HMM) (Bikel et al., 1999) et les modeles discriminants tels que MaxEnt (Brothwick et al., 1998) ou les
Champs de Markov Aléatoires (Conditional Random Field — CRF) (McCallu1n & Li, 2003).

Le systeme LIANE utilise dans cette etude est decrit dans Bechet & Charton (2010). Il est base sur une approche

mixte utilisant tout d’abord un processus generatif a base de HMM pour predire une etiquette syntaxique (POS) et

semantique a chaque mot d’un texte; ensuite un processus discriminant a base de CRF est utilise pour trouver les
bomes et le type complet de chaque entité en utilisant le modele BIO presente precédemment. Il y a deux raisons
pour justiﬁer l’emploi d’un HMM en amont d’un étiqueteur a base de CRF :

— Tout d’abord les modeles d’etiquetage par HMM permettent de rajouter tres facilement plusieurs sources d’in—
formation dans les estimations des probabilités des mots sachant les classes. Ils sont egalement assez tolérants
au bruit dans les données d’apprentissage, a partir du moment ou les fréquences relatives des djfférents evene-
ments modelises sont respectees.

— Ensuite cette premiere phase d’étiquetage va permettre d’ enlever un certain nombre d’ambigu'1'tés en attribuant
des etiquettes syntaxiques et semantiques aux mots d’un texte. Cela permettra de simpliﬁer l’étiquetage par le
CRF qui pourra se concentrer sur les aspects de segmentation et d’attribution d’une etiquette ﬁnale.

Les modeles HMM et CRF sont appris sur un corpus annote selon le format suivant (sur la phrase d’ exemple

“Investiture aujourd ’hui a Bamako Mali du président Amadou Toumani Touré”) :

investiture NFS O du PREPDU O
aujourd’ hui ADV B—TIME président NMS O
é PREPADE O Amadou PERS B-PERS
Bamako LOC B-LOC Toumani PERS I-PERS

Mali LOC B-LOC Touré PERS I-PERS

FREDERIC BECHET, BENoiT SAGOT, ROSA STERN

4 Adaptation du systéme statistique £1 un nouveau domaine

Comme decrit dans Bechet & Charton (2010), le systeme LIANE a été developpe dans le cadre de la campagne
d’ evaluation ESTER portant sur la transcription et l’annotation en entités nommées d’émissions de radio, prin-
cipalement des joumaux d’information. Les corpus d’apprentissage utilises sont ceux de la campagne ESTER,
constitué d’une centaine d’heures de transcriptions annotees en entités nommées. Le corpus cible de cette etude
est un corpus de dépeches AFP. Bien que le contenu thematique de ces deux cadres applicatifs soit proche (des
données d’actualité), le type de langue utilise est different : transcriptions de l’oral pour le corpus ESTER prove-
nant de sources multiples (France Inter, RFI, Radio Africa, Radio Tele Maroc, etc.). L’ etude des résultats obtenus
apres application du systeme LIANE au corpus AFP nous a permis de distinguer deux types de problemes :

— manque de couverture lexicale : les données ESTER contiennent des emissions diffusees en 2007 et debut 2008
alors que les dépeches AFP analysées couvrent des periodes plus recentes;

— mauvaise modélisation des phenomenes spéciﬁques a l’ecrit : le corpus ESTER étant compose de transcription
de l’ oral, il ne contient aucun << raccourci » spéciﬁque a l’écrit tels que 1’ emploi d’ abreviations (la graphie M. par
exemple dans la sequence M Dupond) ou l’aj out d’informations complémentaires par l’emploi de caracteres de
formatage (p.ex. les incises avec des parentheses telles que : Le syndicat Force Ouvriére (F0) a armonce’. . .).

L’ adaptation d’un systeme statistique a un nouveau domaine necessite genéralement l’annotation manuelle d’ un
corpus d’adaptation couvrant les nouveaux phenomenes a modéliser. Ce corpus d’adaptation est souvent de taille
modeste en raison du coﬁt élevé des annotations en entites nommées. Comme indiqué dans l’introduction, nous
avons explore une Voie altemative qui consiste a armoter automatiquement un corpus de tres grande taille. Nous
avons utilise pour cela le systeme NP, specialise dans notre domaine cible, celui des dépeches d’agence. L’ obj ectif
est d’obtenir sans coﬁt supplémentaire (aucune supervision n’est necessaire) un systeme statistique adapte a un
domaine particulier a partir d’un systeme symbolique existant. Ces deux types de systemes ayant des particularités
complementaires (precision élevée pour le systeme symbolique, rappel important et robustesse au bruit pour le
systeme statistique), il est intéressant de disposer des deux selon les applications Visees.

La procedure d’adaptation non supervisée utilisee ici a consiste tout d’abord a collecter un corpus d’adaptation
brut, non annote, appele CA. Nous avons utilise ici un corpus de dépeches de l’AFP des armees 2009 et 2010
constitué de 83M de mots (3M de phrases). Nous avons annoté en entités nommées le corpus CA avec le systeme
NP. Nous avons ainsi détecté 3,2M d’occurrences d’entités nommées, représentant 168K entités distinctes.

Le corpus CA a aussi eté étiquete avec l’étiqueteur morphosyntaxique HMM du systeme LIANE. Nous avons
enﬁn << fusionne » les étiquettes de parties de discours et les étiquettes d’entités nommees comme suit : tout nom
propre ou mot inconnu contenu dans une entité nommée de type t détecté par NP regoit l’étiquette t comme partie
de discours. Nous avons obtenu ainsi le corpus 0:4 étiqueté a la fois en partie de discours et en entités nommées.

Par exemple, pour la phrase le commissaire du Portugal Jorge Palmeirim, le systeme NP a produit :

le commissaire du <EN type="Location" name="Portuguese Republic">Portugal</EN>
<EN type="Person" name="Jorge Palmeirim">Jorge Palmeirim</EN>.

De son cote, l’étiqueteur HMM de LIANE a produit l’annotation suivante :
(le DET)(commissaire N)(du PREP)(Portugal ORG)(Jorge PERS)(Palmeirim UNK).
A partir de ces deux armotations, nous produisons automatiquement le corpus :

le DET 0 Portugal LOC B-LOC
commissaire N 0 Jorge PERS B—PERS
du PREP O Palmeirim PERS I-PERS

Les distributions du modele HMM ont eté directement réestimées sur C’,’4, produisant ainsi la Version adaptée
LIANE 1. Pour l’étiqueteur CRF, le corpus d’apprentissage constitué des corpus ESTER armotes manuellement
a eté enrichi avec des phrases sélectionnées du corpus C'1’4, avec un critere qui repose sur la frequence des entités
détectées : en sélectionnant les phrases contenant les entités les plus fréquentes on espere diminuer le risque
d’erreur d’étiquetage dans les données d’apprentissage. Pour éviter que quelques entités ne représentent a elles
seules la maj orité des exemples retenus, nous avons egalement limité le nombre maximum de phrases contenant
chaque entité. Ainsi nous gardons n phrases parmi toutes celles contenant les entités détectées plus de :17 fois dans
le corpus. En faisant Varier n et :17 on peut mesurer l’impact de l’aj out de données armotées automatiquement dans
les corpus d’apprentissage de LIANE. L’utilisation complete du corpus (n = 400, {I7 = 10) permet de produire le
second systeme adapté, nomme LIANE 2.

ADAPTATION NON-SUPERVISEE D’UN SYSTEME D’ETIQUETAGE EN ENTITES NOMMEES

Systemes NP LIANE (sans adapt.) LIANE 1 (adapt. lex.) LIANE 2 (adapt. 1ex.+segm.)
Entité Precision Rappel Precision Rappel Precision Rappel Precision Rappel
LOC 86.4 86.3 81.6 80.7 82.2 81.5 69.8 85.1

ORG 94.6 48.1 51.4 55.5 52.6 58.0 53.0 59.1
PERS 92.1 82.1 81.3 88.4 81.1 91.0 78.3 93.6

TAB. 1 — Résultats comparatifs en précision et rappel de NP, LIANE, et des deux adaptations de LIANE réalisées
grace aux données annotées automatiquement par NP

  
     
 

60
5 9  
—————— L’ ‘K-
58 _____ _‘
57 “““ “
Rappel — PERS noadapt —'—
56 Rappel — PERS adapt '"'*""
Prec — PERS noadapt 
55 Rappel — ORG noadapt —~— ‘ adapt *9’
54 Rappel — ORG adapt  " _
Prec — ORG noadapt 
53 Prec — ORG adapt ------ --
‘- .... \_ '
52 \" ~..\_
51 “
.., ____________________ ..

 

50
1 2 3 4 5 6 1 2 3 4 5 6

FIG. 1 — Courbes d’apprentissage de LIANE sur les catégories PERS et ORG en fonction du Volume des données
d’ apprentissage issues du corpus étiqueté par NP. Les résultats sont donnés avec et sans adaptation lexicale.

5 Résultats

L’ évaluation de NP, de la Version initiale de LIANE et des Versions adaptées décrites a la section précédente a été
réalisée sur une nouvelle Version du corpus de référence développé et utilisé par Stem & Sagot (20l0b), corpus
qui est disponible librement dans le cadre de la distribution de SXPipe. Ce corpus, formé de 100 dépéches AFP
contenant chacune une moyenne de 300 mots, a été annoté manuellement en entités nommées sous forme de
marqueurs XML balisant le texte. Ces balises, outre l’empan de chaque mention, contiennent des informations sur
son type ainsi que sur son référent représenté par un numéro d’ entrée dans la base Aleda. Dans son état actuel, ce
corpus de référence ne contient des annotations que pour des entités de type PERS, LOC et ORG (y compris les
noms d’entreprises)5. ll contient un total de 1456 mentions d’entités.

Les résultats sont donnés en fonction des mesures de rappel et précision strictes : une hypothése est considérée
comme correcte uniquement si sa segmentation et son typage son correctsé. Comme le montre le tableau 1, le
systéme NP donne de bons résultats en terme de précision pour les trois types d’entités. Le rappel sur les LOC est
également élevé (86.3%), illustrant ainsi l’apport de la base d’entités Aleda. Comme prévu, le systéme LIANE
obtient une précision plus faible, mais un rappel intéressant pour les entités ORG et PERS. Les résultats de LIANE
s’améliorent signiﬁcativement en adaptant ce systéme, d’une part au niveau lexical en réestimant les distributions
de l’étiqueteur HMM, mais également au niveau segmentation en aj outant au corpus d’apprentissage des CRF des
phrases annotés par NP. Le gain en terme de rappel est de l’ordre de 4% en absolu pour chaque catégorie. Rappe-
lons que cette adaptation est non supervisée et qu’elle a pour but d’obtenir un systéme statistique complémentaire
au systéme symbolique NP. La ﬁgure 1 illustre cette complémentarité en montrant les courbes d’apprentissage du
systéme LIANE sur les catégories ORG et PERS lorsque l’on fait croitre le Volume de données AFP annotées
par NP ajouté au corpus d’apprentissage des CRF7. On constate que le rappel augmente en fonction de l’ajout de
données, mais au prix d’une certaine diminution en précision. L’ augmentation du rappel est encourageante dans
la perspective d’intégrer plus encore les deux types de systémes, par rapport a un cadre applicatif précis, pour
exploiter au mieux la bonne précision des modéles symboliques et le bon rappel des modéles numériques.

5Les annotations de mentions ne comprennent pas les tokens non constitutifs du nom de 1’entité lui-méme : les titres précédant les noms
de personnes notamment en sont exclus (Mme ou Dr).

5Les mesures utilisées dans ESTER étaient plus graduelles, donnant un poids différents aux erreurs de frontiére, de typage ainsi qu’ aux
erreurs de reconnaissance dues a la transcription automatique de la parole

7les 6 points d’abscisse de ces courbes correspondent respectivement a des volumes de 0, 127K, 209K, 498K, 1,2M et 1,9M mots ajoutés
aux 1,3M mots du corpus ESTER

FREDERIC BECHET, BENoiT SAGOT, ROSA STERN
6 Conclusion et perspectives

La traditionnelle opposition entre methodes symboliques et methodes numeriques a nourri quantite de debats a
l’occasion de campagnes d’evaluation sur des taches telles que l’etiquetage en parties de discours ou l’annotation
en entites nommees. Si aucune methode ne s’est averee gagnante dans toutes les conditions de tests, ces deux
familles de methodes ont montre des comportements differents, et fortement complementaires, que l’on peut
resumer de fagon simpliﬁcatrice comme suit : bonne precision pour les approches symboliques, bon rappel pour les
approches numeriques. Nous avons montre dans cette etude comment cette complementarite pouvait etre exploitee
pour adapter un systeme numerique d’annotation en entites nommees a une nouvelle tache a l’aide d’un systeme
symbolique. Cette adaptation nous permet de disposer de deux systemes complementaires, l’un privilegiant la
precision, l’autre le rappel, sans necessiter aucune annotation supplementaire, illustrant la complementarite des
methodes numeriques et symboliques pour la resolution detaches linguistiques.

L’ interaction NP et LIANE, qui est donc ici une instance simpliﬁee du paradigme du co-training, pourrait toutefois
etre poussee plus avant. Des experiences en marge de ce travail visant a integrer un lexique issu d’Aleda aux
versions adaptees de LIANE se sont averees inoperantes, probablement parce que les corpus annotes par NP
utilises pour l’entrainement integraient deja une partie importante de ces informations lexicales. Mais un couplage
plus ﬁn avec Aleda, notamment en prenant en compte les poids associes aux entites, devrait permettre d’ameliorer
les resultats de LIANE. A l’inverse, la sortie de LIANE pourrait servir de source d’information au module de NP
charge de la desambiguisation. Ces pistes, et d’autres, devraient conﬁrmer les resultats presentes ici et Valider la
pertinence d’approches mixtes ou hybrides pour des taches telles que la reconnaissance d’ entites nommees.

Remerciements

Ce travail a ete effectue dans le cadre du projet ANR EDyLex (ANR—09—CORD-008).

References

BALASURIYA D., RINGLAND N., NOTHMAN J ., MURPHY T. & CURRAN J . R. (2009). Named entity recog-
nition in wikipedia. In People ’s Web ’09 : Proceedings of the 2009 Workshop on The People ’s Web Meets NLP,
p. 10-18, Suntec, Singapour.

BECHET F. & CHARTON E. (2010). Unsupervised knowledge acquisition for extracting named entities from
speech. In 2010 IEEE International Conference on Acoustics, Speech and Signal Processing.

BIKEL D. M., SCHWARTZ R. L. & WEISCHEDEL R. M. (1999). An algorithm that learns what’s in a name.
Machine learning, 24(1—3), 211-231.

BROTHWICK A., STERLING J ., AGICHTEIN E. & GRISHMAN R. (1998). Exploiting diverse knowledge sources
via maximum entropy in named entity recognition. In 6th Workshop on Very large Corpora (ACL ’98), Montreal.
BECHET F. (2011). Named Entity Recognition. In G. TUR & R. DE MORI, Eds., Spoken language Understan-
ding : systems for extracting semantic information from speech, p. 257-290. Wiley.

CHARTON E. & TORRES—MORENO J .—M. (2009). Classiﬁcation d’un contenu encyclopedique en vue d’un
etiquetage par entites nommees. In Actes de TALN 2009, Senlis, France.

GALLIANO S., GRAVIER G. & CHAUBARD L. (2009). The Ester 2 Evaluation Campaign for the Rich Trans-
cription of French Radio Broadcasts. In Interspeech 2009.

MCCALLUM A. & LI W. (2003). Early results for named entity recognition with conditional random ﬁelds,
feature induction and web—enhanced lexicons. In Seventh Conference on Natural Language learning (CoNLL).
SAGOT B. & BOULLIER P. (2008). SXPipe 2 : architecture pour le traitement presyntaxique de corpus bruts.
Traitement Automatique des langues (T.A.L.), 49(2), 155-188.

STERN R. & SAGOT B. (2010a). Detection et resolution d’entites nommees dans des depeches d’agence. In
Actes de la Conference TALN 2010, Montreal, Canada.

STERN R. & SAGOT B. (2010b). Resources for named entity recognition and resolution in news wires. In
Proceedings of LREC 2010 Workshop on Resources and Evaluation for Identity Matching, Entity Resolution and
Entity Management, La Valette, Malte.

