<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Filtrage de relations pour l&#8217;extraction d&#8217;information non supervis&#233;e</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Filtrage de relations pour l&#8217;extraction d&#8217;information non supervis&#233;e
</p>
<p>Wei Wang1 Romaric Besan&#231;on1 Olivier Ferret1 Brigitte Grau2
</p>
<p>(1) CEA, LIST, 18 route du Panorama, BP 6, 92265 Fontenay-aux-Roses
(2) LIMSI, UPR-3251 CNRS-DR4, Bat. 508, BP 133, 91403 Orsay Cedex
</p>
<p>wei.wang@cea.fr, romaric.besancon@cea.fr, olivier.ferret@cea.fr, brigitte.grau@limsi.fr
</p>
<p>R&#233;sum&#233;. Le domaine de l&#8217;extraction d&#8217;information s&#8217;est r&#233;cemment d&#233;velopp&#233; en limitant les contraintes
sur la d&#233;finition des informations &#224; extraire, ouvrant la voie &#224; des applications de veille plus ouvertes. Dans ce
contexte de l&#8217;extraction d&#8217;information non supervis&#233;e, nous nous int&#233;ressons &#224; l&#8217;identification et la caract&#233;risation
de nouvelles relations entre des types d&#8217;entit&#233;s fix&#233;s. Un des d&#233;fis de cette t&#226;che est de faire face &#224; la masse
importante de candidats pour ces relations lorsque l&#8217;on consid&#232;re des corpus de grande taille. Nous pr&#233;sentons dans
cet article une approche pour le filtrage des relations combinant m&#233;thode heuristique et m&#233;thode par apprentissage.
Nous &#233;valuons ce filtrage de mani&#232;re intrins&#232;que et par son impact sur un regroupement s&#233;mantique des relations.
</p>
<p>Abstract. Information Extraction have recently been extended to new areas, by loosening the constraints on
the strict definition of the information extracted, thus allowing to design more open information extraction systems.
In this new domain of unsupervised information extraction, we focus on the task of extracting and characterizing
new relations between a given set of entity types. One of the challenges of this task is to deal with the large
amount of candidate relations when extracting them from a large corpus. We propose in this paper an approach
for filtering such candidate relations, based on heuristic and machine learning methods. We present an evaluation
of this filtering phase and an evaluation of the impact of the filtering on the semantic clustering of relations.
</p>
<p>Mots-cl&#233;s : Extraction d&#8217;information non supervis&#233;e, filtrage, apprentissage automatique, clustering.
</p>
<p>Keywords: Unsupervised information extraction, filtering, machine learning, clustering.
</p>
<p>1 Introduction1
</p>
<p>Les ann&#233;es r&#233;centes ont vu se d&#233;velopper de nouveaux paradigmes dans le domaine de l&#8217;extraction d&#8217;information
(EI), parmi lesquels la notion d&#8217;EI non supervis&#233;e. Cette approche prend comme point de d&#233;part des entit&#233;s ou
des types d&#8217;entit&#233;s et se fixe comme objectif de mettre en &#233;vidence les relations intervenant entre ces entit&#233;s, sans
connaissance a priori de leur type. Cette mise en &#233;vidence est &#233;ventuellement suivie d&#8217;un regroupement de ces re-
lations en fonction de leurs similarit&#233;s pour en faire la synth&#232;se. Les travaux effectu&#233;s dans ce champ de recherche
s&#8217;envisagent selon trois points de vue. Le premier est l&#8217;acquisition de connaissances, que ce soit des connaissances
sur le monde collect&#233;es &#224; vaste &#233;chelle &#224; partir du Web, comme avec le concept d&#8217;Open Information Extraction
d&#233;velopp&#233; dans (Banko et al., 2007), ou dans des domaines plus sp&#233;cialis&#233;s, comme le domaine biologique, o&#249;
cette extraction est le moyen d&#8217;ajouter de nouveaux types de relations entre entit&#233;s &#224; une ontologie existante (Cia-
ramita et al., 2005). Le deuxi&#232;me se situe dans le cadre d&#8217;applications d&#8217;EI, o&#249; ce type d&#8217;approche correspond
&#224; la volont&#233; d&#8217;offrir aux utilisateurs des modes d&#8217;extraction de l&#8217;information plus souples et plus ouverts quant
&#224; la sp&#233;cification de leur besoin informationnel. L&#8217;approche On-demand information extraction (Sekine, 2006),
pr&#233;figur&#233;e dans (Hasegawa et al., 2004) et concr&#233;tis&#233;e par les travaux sur la Preemptive Information Extraction
(Shinyama &amp; Sekine, 2006), vise ainsi &#224; induire l&#8217;&#233;quivalent d&#8217;un template &#224; partir d&#8217;un ensemble de documents
repr&#233;sentatifs des informations &#224; extraire, obtenus par le biais d&#8217;un moteur de recherche, par le regroupement des
relations qui en sont extraites (Rosenfeld &amp; Feldman, 2007). Enfin, l&#8217;EI non supervis&#233;e peut aussi servir &#224; com-
pl&#233;ter l&#8217;EI supervis&#233;e, qui d&#233;pend de corpus annot&#233;s qui ne sont g&#233;n&#233;ralement pas de grande taille, &#233;tant donn&#233;
la complexit&#233; des t&#226;ches consid&#233;r&#233;es. Les r&#233;sultats d&#8217;une approche non supervis&#233;e peuvent alors &#234;tre utilis&#233;s pour
&#233;largir la couvertures des mod&#232;les appris (Banko &amp; Etzioni, 2008; Gonz&#225;lez &amp; Turmo, 2009).
</p>
<p>Dans cet article, nous nous pla&#231;ons dans le cadre du deuxi&#232;me point de vue expos&#233; ci-dessus, celui d&#8217;une extrac-
1Ce travail a &#233;t&#233; partiellement r&#233;alis&#233; dans le cadre du projet FILTRAR-S soutenu par le programme CSOSG 2008 de l&#8217;ANR.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>WANG ET AL.
</p>
<p>tion d&#8217;information plus souple, en y int&#233;grant la probl&#233;matique du filtrage des relations extraites telle qu&#8217;elle est
abord&#233;e dans (Banko et al., 2007), mais avec un point de vue diff&#233;rent. Nous pr&#233;sentons ainsi un travail visant
&#224; d&#233;terminer si deux entit&#233;s nomm&#233;es cooccurrant dans une phrase entretiennent ou non une relation sans fixer
d&#8217;a priori sur la nature de cette relation. Compte tenu de notre perspective globale, nous &#233;valuons dans un second
temps l&#8217;impact d&#8217;un tel filtrage sur le regroupement des relations extraites.
</p>
<p>2 Vue d&#8217;ensemble
</p>
<p>Le travail que nous pr&#233;sentons ici s&#8217;inscrit dans un contexte plus large visant &#224; d&#233;velopper un processus d&#8217;ex-
traction d&#8217;information non supervis&#233;e susceptible de r&#233;pondre &#224; des probl&#233;matiques de veille telle que &#171; suivre
tous les &#233;v&#233;nements faisant intervenir les soci&#233;t&#233;s X et Y &#187;. &#192; la base de ce processus, nous nous restreignons
comme les travaux ci-dessus, hormis (Banko et al., 2007), aux relations pr&#233;sentes entre deux entit&#233;s nomm&#233;es.
Plus formellement, les relations extraites des textes sont caract&#233;ris&#233;es par deux grandes cat&#233;gories d&#8217;information
permettant tout &#224; la fois de les d&#233;finir et de fournir les &#233;l&#233;ments n&#233;cessaires &#224; leur regroupement : un couple
d&#8217;entit&#233;s nomm&#233;es (E1 et E2) et une caract&#233;risation linguistique de la relation (Cpre, Cmid, Cpost).
</p>
<p>In 2002, Kerry voted to authorize the use of force against Saddam in Irak.
</p>
<p>E1 (PERSONNE) E2 (PERSONNE)
</p>
<p>Cpre Cmid Cpost
</p>
<p>Cpre, Cmid et Cpost correspondent respectivement &#224; la partie de la phrase pr&#233;c&#233;dant la premi&#232;re entit&#233; E1, situ&#233;e
entre les deux entit&#233;s et suivant la seconde entit&#233; E2. L&#8217;ensemble recouvre l&#8217;expression linguistique de la relation.
Le plus souvent Cmid exprime la relation proprement dite tandis que Cpre et Cpost fournissent plut&#244;t des &#233;l&#233;ments
de contexte pouvant &#234;tre utiles dans la perspective de son regroupement avec d&#8217;autres relations.
</p>
<p>Le processus d&#8217;extraction d&#8217;information non supervis&#233;e d&#233;fini autour de cette notion de relation s&#8217;effectue avec
les &#233;tapes suivantes : pr&#233;-traitement linguistique des textes, extraction de relations candidates, filtrage des relations
candidates et regroupement des relations selon leur similarit&#233;. Le pr&#233;-traitement linguistique des textes permet de
mettre en &#233;vidence les informations n&#233;cessaires &#224; la d&#233;finition des relations. Ce pr&#233;-traitement comporte donc une
reconnaissance des entit&#233;s nomm&#233;es pour les types d&#8217;entit&#233;s vis&#233;s, une d&#233;sambigu&#239;sation morpho-syntaxique des
mots ainsi que leur normalisation. Ces traitements s&#8217;appuient sur les outils d&#8217;OpenNLP. Nous nous concentrons
sur six types de couples d&#8217;entit&#233;s : ORG - LIEU, ORG - ORG, ORG - PERS, PERS - LIEU, PERS -ORG, PERS - PERS.
</p>
<p>3 Filtrage des relations
</p>
<p>Les relations candidates, extraites de 18 mois du New York Times issus du corpus AQUAINT-2, sont constitu&#233;es par
tout couple d&#8217;entit&#233;s nomm&#233;es (EN) dont les types correspondent aux types cibl&#233;s, avec pour seules restrictions
la cooccurrence de ces entit&#233;s dans une m&#234;me phrase et la pr&#233;sence d&#8217;au moins un verbe entre les deux. Leur
examen montre qu&#8217;un nombre tr&#232;s significatif des relations ainsi extraites ne sont pas valides. Cette strat&#233;gie
basique d&#8217;extraction, int&#233;ressante en domaine de sp&#233;cialit&#233;, n&#8217;est pas suffisamment s&#233;lective en domaine ouvert.
Nous avons donc cherch&#233; &#224; la compl&#233;ter par un processus de filtrage visant, comme dans (Banko &amp; Etzioni, 2008),
&#224; d&#233;terminer si deux entit&#233;s dans une phrase sont li&#233;es par une relation, sans a priori sur la nature de cette relation.
</p>
<p>3.1 Filtrage heuristique
</p>
<p>Compte tenu du nombre important de relations invalides, nous avons d&#8217;abord d&#233;fini un nombre restreint d&#8217;heuris-
tiques pour r&#233;aliser un filtrage &#224; gros grain. Ces heuristiques sont au nombre de trois :
</p>
<p>&#8211; suppression des relations comportant entre leurs deux entit&#233;s un verbe exprimant un discours rapport&#233; ;
&#8211; limitation &#224; 10 du nombre de mots entre les deux entit&#233;s. Au-del&#224; de cette limite empirique, le nombre des
</p>
<p>relations effectives entre les deux entit&#233;s devient en effet tr&#232;s faible ;
&#8211; limitation &#224; 1 du nombre des verbes entre les deux entit&#233;s, sauf si ce sont des auxiliaires.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FILTRAGE DE RELATIONS
</p>
<p>L&#8217;application de ces heuristiques aux relations extraites a globalement pour cons&#233;quence de r&#233;duire leur volume
d&#8217;environ 50%. Nous avons choisi au hasard 50 relations de chaque type et nous avons proc&#233;d&#233; &#224; une annotation
manuelle de leur validit&#233;. Le taux de fausses relations constat&#233; parmi les relations filtr&#233;es &#233;tant encore assez &#233;lev&#233;,
50,7% pour les 6 types consid&#233;r&#233;s, nous avons mis en &#339;uvre un second filtrage, &#224; grain plus fin.
</p>
<p>3.2 Filtrage par apprentissage
</p>
<p>Cette seconde &#233;tape de filtrage repose sur un classifieur statistique d&#233;cidant si une relation extraite est v&#233;ritable-
ment sous-tendue par une relation effective entre ses entit&#233;s. Nous avons construit pour ce faire un corpus d&#8217;en-
tra&#238;nement et de test en annotant manuellement un ensemble de 200 relations s&#233;lectionn&#233;es au hasard et annot&#233;es
par les types d&#8217;EN. L&#8217;annotation distinguait les relations correctes, les relations incorrectes du fait d&#8217;un probl&#232;me
de reconnaissance des EN et les relations fausses du fait de l&#8217;absence de relation. Les relations incorrectes du fait
des EN (20%) ont &#233;t&#233; &#233;cart&#233;es pour l&#8217;entra&#238;nement et le test des classifieurs. Le corpus r&#233;sultant se compose donc
de 964 relations, 531 &#233;tant correctes et 433 &#233;tant fausses, ce qui constitue un ensemble suffisamment &#233;quilibr&#233;
pour l&#8217;apprentissage des mod&#232;les statistiques.
</p>
<p>Plusieurs de ces mod&#232;les ont &#233;t&#233; test&#233;s en se concentrant d&#8217;abord sur des mod&#232;les exploitant un ensemble de
caract&#233;ristiques non structur&#233;es2. Les diff&#233;rents classifieurs ont &#233;t&#233; entra&#238;n&#233;s en utilisant le m&#234;me ensemble de
caract&#233;ristiques, classiques pour l&#8217;extraction de relations, &#224; l&#8217;instar de (Banko &amp; Etzioni, 2008) :
</p>
<p>&#8211; le type des entit&#233;s nomm&#233;es E1 et E1 ;
&#8211; la cat&#233;gorie morpho-syntaxique des mots situ&#233;s entre les deux entit&#233;s avec un trait binaire pour chaque couple
</p>
<p>(position dans la s&#233;quence, cat&#233;gorie), les bigrammes de cat&#233;gories morpho-syntaxiques entre E1 et E2 avec
un trait binaire pour chaque triplet (position i, cati, cati+1) ;
</p>
<p>&#8211; la cat&#233;gorie morpho-syntaxique des deux mots pr&#233;c&#233;dant E1 et des deux mots suivant E2, &#224; la fois en tant
qu&#8217;unigrammes et en tant que bigrammes ;
</p>
<p>&#8211; la s&#233;quence des cat&#233;gories morpho-syntaxiques entre E1 et E2. Chaque s&#233;quence possible de 10 cat&#233;gories est
encod&#233;e comme une caract&#233;ristique binaire ;
</p>
<p>&#8211; le nombre de mots entre E1 et E2 ;
&#8211; le nombre de signes de ponctuation (virgule, guillemet, parenth&#232;se . . .) entre E1 et E2.
</p>
<p>Nous avons &#233;galement test&#233; un classifieur prenant en compte la notion de s&#233;quence en nous appuyant sur les
Champs Conditionnels Al&#233;atoires (CRF). Dans ce cas, la t&#226;che consid&#233;r&#233;e prend la forme d&#8217;un &#233;tiquetage cher-
chant &#224; associer &#224; chaque mot d&#8217;une phrase l&#8217;une des quatre &#233;tiquettes suivantes : O pour un mot de la phrase en
dehors d&#8217;une relation, ENT pour une EN d&#233;finissant une relation potentielle (E1 ou E2), B-REL pour le premier
mot d&#8217;une relation suivant E1, I-REL pour un mot faisant partie d&#8217;une relation. Dans ce sch&#233;ma, une relation est
jug&#233;e correcte lorsque l&#8217;&#233;tiquetage suit une configuration de type O &#8211; ENT &#8211; B-REL &#8211; I-REL* &#8211; ENT &#8211; O tandis
qu&#8217;elle est jug&#233;e fausse si l&#8217;&#233;tiquetage produit une configuration O &#8211; ENT &#8211; O* &#8211; ENT &#8211; O. Ce mod&#232;le &#224; base de
CRF lin&#233;aires s&#8217;appuie sur l&#8217;ensemble de caract&#233;ristiques suivant :
</p>
<p>&#8211; la cat&#233;gorie morpho-syntaxique du mot courant, du mot pr&#233;c&#233;dent et du mot suivant ;
&#8211; les bigrammes de cat&#233;gories morpho-syntaxiques &lt; cati&#8722;1, cati &gt;, avec i=-1,0,1 (0 est le mot courant) ;
&#8211; le type d&#8217;entit&#233; nomm&#233;e du mot courant et de chacun des 6 mots le pr&#233;c&#233;dant et le suivant. Ce type peut avoir
</p>
<p>une valeur NIL lorsque le mot ne fait pas partie d&#8217;une entit&#233; nomm&#233;e.
</p>
<p>Une validation crois&#233;e a &#233;t&#233; faite pour &#233;valuer ces diff&#233;rents classifieurs en d&#233;coupant le corpus en 10 parties
&#233;gales. Le tableau 1 montre les r&#233;sultats obtenus par le SVM, le meilleur des premiers classifieurs test&#233;s, et les
CRF. L&#8217;int&#233;gration par ces derniers d&#8217;un mod&#232;le de s&#233;quence leur conf&#232;re une l&#233;g&#232;re sup&#233;riorit&#233; par rapport au
SVM. C&#8217;est donc ce mod&#232;le que nous avons retenu pour le filtrage des relations. On notera &#233;galement un certain
&#233;quilibre entre la pr&#233;cision et le rappel. Enfin, comme le montre la derni&#232;re ligne du tableau 1, ces r&#233;sultats se
comparent favorablement &#224; ceux de (Banko &amp; Etzioni, 2008) sur le m&#234;me sujet mais sur un corpus diff&#233;rent
constitu&#233; de documents Web. Dans ce dernier cas, la pr&#233;cision est plus forte que la n&#244;tre mais le rappel tr&#232;s
largement inf&#233;rieur. Il faut n&#233;anmoins pr&#233;ciser que dans (Banko &amp; Etzioni, 2008), les relations extraites peuvent
faire intervenir des entit&#233;s plus g&#233;n&#233;rales que des entit&#233;s nomm&#233;es, ce qui est a priori un facteur de difficult&#233;.
En revanche, le corpus d&#8217;apprentissage de (Banko &amp; Etzioni, 2008) est constitu&#233; de relations s&#233;lectionn&#233;es sur la
</p>
<p>2Nous avons ainsi entra&#238;n&#233; quatre types de classifieurs : bay&#233;sien na&#239;f, maximum d&#8217;entropie (MaxEnt), arbre de d&#233;cision et Machines &#224;
Vecteurs de Support (SVM).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>WANG ET AL.
</p>
<p>Mod&#232;le Exactitude Pr&#233;cision Rappel F1-mesure
SVM 0,732 0,740 0,798 0,767
CRF 0,745 0,762 0,782 0,771
</p>
<p>(Banko &amp; Etzioni, 2008) / 0,883 0,452 0,598
</p>
<p>TAB. 1 &#8211; &#201;valuation des classifieurs statistiques
</p>
<p>base d&#8217;heuristiques appliqu&#233;es aux r&#233;sultats d&#8217;un analyseur syntaxique. La gamme des expressions linguistiques
apprises est donc limit&#233;e dans leur cas par les possibilit&#233;s de l&#8217;analyseur syntaxique utilis&#233;, probl&#232;me auquel nous
n&#8217;avons pas &#224; faire face et qui peut expliquer pour partie leur faible rappel.
</p>
<p>3.3 Application du filtrage des relations
</p>
<p>L&#8217;extraction des relations se compose de 3 &#233;tapes : (1) une extraction initiale, en ne posant comme contraintes
que la cooccurrence dans une phrase d&#8217;entit&#233;s nomm&#233;es de types donn&#233;s et la pr&#233;sence d&#8217;au moins un verbe entre
les deux ; (2) le filtrage heuristique permettant d&#8217;&#233;carter avec une bonne pr&#233;cision un grand nombre de relations
fausses ; (3) l&#8217;application du filtrage statistique permettant de discriminer plus finement les relations correctes.
</p>
<p>Type des relations ORG-LIEU ORG-ORG ORG-PERS PERS-LIEU PERS-ORG PERS-PERS
extraction initiale 71 858 77 025 73 895 152 514 126 281 175 802
</p>
<p>heuristiques 33 505 (47%) 37 061 (48%) 32 033 (43%) 72 221 (47%) 66 035 (52%) 78 530 (45%)
classifieur CRF 16 700 (23%) 17 025 (22%) 12 098 (16%) 55 174 (36%) 50 487 (40%) 42 463 (24%)
d&#233;doublonnage 15 226 (21%) 13 704 (18%) 10 054 (14%) 47 700 (31%) 40 238 (32%) 38 786 (22%)
</p>
<p>TAB. 2 &#8211; Volume et pourcentage, relativement &#224; leur nombre initial, des relations apr&#232;s chaque &#233;tape de filtrage
</p>
<p>Le constat de la pr&#233;sence dans nos relations filtr&#233;es d&#8217;un certain nombre de relations identiques, pour une part
issues d&#8217;articles sur un m&#234;me sujet ou d&#8217;articles correspondant &#224; des rubriques tr&#232;s format&#233;es, nous a conduit
&#224; compl&#233;ter ce processus de filtrage par un d&#233;doublonnage final visant &#224; &#233;liminer ces relations redondantes. Il
est &#224; noter que cette op&#233;ration de d&#233;doublonnage vient en derni&#232;re position, &#224; la fois du fait de son co&#251;t, plus
important que celui des autres op&#233;ration de filtrage et de sa d&#233;pendance vis-&#224;-vis de l&#8217;&#233;valuation de la similarit&#233;
entre les relations, exploit&#233;e ensuite directement pour le regroupement des relations. Si ce filtrage rejette un grand
nombre des relations extraites initialement, le volume des relations restantes est a priori suffisant pour alimenter
les &#233;tapes suivantes du processus d&#8217;EI. Par ailleurs, nous nous situons dans un contexte de traitement de volumes
textuels importants caract&#233;ris&#233;s par une certaine redondance informationnelle conduisant &#224; privil&#233;gier la pr&#233;cision
des processus d&#8217;extraction afin d&#8217;&#233;viter un bruit trop important.
</p>
<p>4 Impact du filtrage des relations sur leur regroupement
</p>
<p>4.1 Regroupement des relations
</p>
<p>&#192; l&#8217;instar de beaucoup de travaux dans le domaine de l&#8217;extraction d&#8217;information non supervis&#233;e comme (Shinyama
&amp; Sekine, 2006) ou (Rosenfeld &amp; Feldman, 2007), notre objectif final est le regroupement des relations selon leur
similarit&#233;, en particulier pour en faciliter l&#8217;exploration. Mais notre but ici &#233;tant d&#8217;&#233;tudier l&#8217;influence du filtrage sur
le regroupement, nous nous contenterons d&#8217;une approche simple (Hasegawa et al., 2004) visant &#224; rassembler les
relations &#233;quivalentes sur le plan s&#233;mantique. L&#8217;&#233;quivalence de deux relations est &#233;valu&#233;e par la mesure cosinus
appliqu&#233;e &#224; une repr&#233;sentation de type &#171; sac de mots &#187; de la caract&#233;risation linguistique des relations. Seule la
partie Cmid de cette caract&#233;risation est prise en compte.
</p>
<p>Pour le regroupement, nous avons choisi l&#8217;algorithme Markov Clustering (van Dongen, 2000). Cet algorithme
partitionne un graphe de similarit&#233; en clusters disjoints en r&#233;alisant une s&#233;rie de marches al&#233;atoires dans ce graphe.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FILTRAGE DE RELATIONS
</p>
<p>L&#8217;hypoth&#232;se est ici qu&#8217;un cluster se caract&#233;rise par une forte densit&#233; de liens entre ses &#233;l&#233;ments et qu&#8217;en &#171; sortir &#187;
ne peut donc se faire qu&#8217;apr&#232;s un nombre important de pas. Cet algorithme it&#233;ratif converge en pratique rapidement
et se montre capable de faire face &#224; nos graphes compos&#233;s de quelques dizaines de milliers de n&#339;uds. Par ailleurs,
il d&#233;termine de mani&#232;re intrins&#232;que le nombre de clusters &#224; former et n&#8217;est d&#233;pendant pour ce faire que d&#8217;un seul
param&#232;tre &#8211; le facteur d&#8217;inflation &#8211; que nous avons laiss&#233; &#224; sa valeur par d&#233;faut.
</p>
<p>Le Markov Clustering s&#8217;appuyant sur un graphe de similarit&#233; des &#233;l&#233;ments &#224; regrouper, le probl&#232;me de son calcul
pour plusieurs dizaines de milliers de relations se pose ici. Nous avons eu recours pour ce faire &#224; l&#8217;algorithme All
Pairs Similarity Search (Bayardo et al., 2007) qui permet, moyennant la fixation d&#8217;un seuil de similarit&#233; minimale,
de calculer efficacement et de mani&#232;re exacte une mesure telle que cosinus pour tous les couples d&#8217;&#233;l&#233;ments dont la
similarit&#233; est sup&#233;rieure au seuil fix&#233;. Cette valeur de similarit&#233; minimale a &#233;t&#233; &#233;tablie gr&#226;ce au Microsoft Research
Paraphrase Corpus, qui rassemble un ensemble de couples de phrases3 associ&#233;es &#224; un jugement de paraphrase.
Le calcul de la mesure cosinus pour tous ces couples nous a permis de retenir une valeur minimale de 0,45 pour
les exp&#233;rimentations de la section suivante, seuil correspondant aux trois-quarts des valeurs calcul&#233;es.
</p>
<p>4.2 &#201;valuation de l&#8217;impact du filtrage des relations
</p>
<p>Nous avons cherch&#233; &#224; &#233;valuer l&#8217;impact du filtrage des relations sur le regroupement de relations en comparant
la qualit&#233; des regroupements form&#233;s avec ou sans filtrage &#224; la suite de la m&#233;thode de regroupement d&#233;crite ci-
dessus. Une classification de r&#233;f&#233;rence n&#8217;existant pas pour des relations telles que les n&#244;tres, nous avons utilis&#233; des
mesures internes d&#8217;&#233;valuation des regroupements. Les mesures de ce type permettent d&#8217;&#233;tablir si le regroupement
obtenu refl&#232;te bien les valeurs de similarit&#233;s dans l&#8217;espace des relations. L&#8217;objectif est ici de tester si l&#8217;espace des
relations apr&#232;s filtrage pr&#233;sente une meilleure distribution des similarit&#233;s vis-&#224;-vis de sa capacit&#233; &#224; regrouper les
relations. Parmi les diff&#233;rentes mesures existantes, nous avons retenu la mesure de la densit&#233; attendue (expected
density), qui est &#233;valu&#233;e dans (Stein et al., 2003) comme la mesure ayant la meilleure corr&#233;lation avec la mesure
externe de F-mesure pour le clustering de documents (la mesure usuelle de l&#8217;indice de Dunn &#233;tant jug&#233;e moins
stable). Nous avons utilis&#233; dans nos exp&#233;riences une version modifi&#233;e de cette mesure, moins d&#233;pendante de la
taille de l&#8217;ensemble des objets &#224; regrouper, d&#233;finie par &#961; dans l&#8217;&#233;quation (1). De fa&#231;on compl&#233;mentaire, nous avons
&#233;galement utilis&#233; la mesure de connectivit&#233; (connectivity) (Handl et al., 2005), d&#233;finie par c dans l&#8217;&#233;quation (2),
qui &#233;value dans quelle proportion les relations des plus proches voisins ne sont pas coup&#233;es par le clustering. Cette
mesure est int&#233;ressante dans notre cas parce qu&#8217;elle s&#8217;appuie sur la structure du graphe de similarit&#233; que nous
utilisons aussi pour la m&#233;thode de clustering4. Les deux mesures se d&#233;finissent ainsi &#224; partir d&#8217;un graphe pond&#233;r&#233;
(V,E,w), o&#249; V est l&#8217;ensemble des n&#339;uds, E l&#8217;ensemble des arcs et w, la pond&#233;ration des arcs.
</p>
<p>&#961; =
|C|&#8721;
i=1
</p>
<p>|Vi|
|V |
</p>
<p>&#952;i
&#952;
</p>
<p>(1) c =
|V |&#8721;
i=1
</p>
<p>p&#8721;
j=1
</p>
<p>xi,nni(j) (2)
</p>
<p>Pour la d&#233;finition de &#961;, C est l&#8217;ensemble des clusters, Vi les n&#339;uds du cluster i, et &#952; une mesure de densit&#233; des
objets &#224; regrouper, d&#233;finie par &#952; = ln(w(G))/ln(|V |), avec w(G) = |V |+&#8721;e&#8712;E w(e), et &#952;i est la m&#234;me mesure
pour le graphe restreint aux n&#339;uds du cluster Ci. Pour la d&#233;finition de c, p est le nombre de voisins consid&#233;r&#233;s,
nni(j), le jie&#768;me plus proche voisin de i et xi,nni(j), &#233;gal &#224; 0 si i et nni(j) sont dans le m&#234;me cluster et 1/j sinon.
Ces deux mesures &#233;voluent de fa&#231;on inverse : plus la mesure &#961; est &#233;lev&#233;e, plus le clustering est jug&#233; de bonne
qualit&#233;, alors qu&#8217;un c plus bas est signe d&#8217;un meilleur clustering.
</p>
<p>Les r&#233;sultats de ces mesures sont pr&#233;sent&#233;s dans le tableau 3. Les deux mesures utilis&#233;es montrent que le clustering
est dans la plupart des cas de meilleure qualit&#233; apr&#232;s le filtrage des relations, ce qui montre son utilit&#233; pour le
regroupement des relations. Les deux couples d&#8217;entit&#233;s pour lesquels cette tendance n&#8217;est pas v&#233;rifi&#233;e pour la
mesure de densit&#233; attendue, ORG &#8211; LIEU et PERS &#8211; LIEU, ont en commun de faire intervenir des entit&#233;s de type
lieu. Ce constat s&#8217;explique peut-&#234;tre par une sp&#233;cificit&#233; de ces entit&#233;s. En effet, lorsqu&#8217;une entit&#233; de type lieu
est pr&#233;sente dans une phrase et qu&#8217;elle n&#8217;est pas en relation avec l&#8217;autre entit&#233; consid&#233;r&#233;e dans la phrase, il est
fr&#233;quent qu&#8217;elle soit inclue dans un compl&#233;ment circonstanciel de lieu. Or, avec la mesure de similarit&#233; choisie,
les formes des compl&#233;ments circonstanciels de lieu peuvent induire une similarit&#233; entre les phrases valide du point
de vue d&#8217;un regroupement global et donc donner un bon score de clustering. Ces premiers r&#233;sultats montrant
</p>
<p>3Le corpus distingue un ensemble d&#8217;apprentissage et un ensemble de test que nous avons fusionn&#233;s dans le cas pr&#233;sent.
4Cette mesure est &#233;galement d&#233;pendante de la taille du corpus : pour pallier ce probl&#232;me, cette mesure est calcul&#233;e pour un sous-ensemble
</p>
<p>de relations choisies al&#233;atoirement, en l&#8217;occurrence 5000 relations pr&#233;sentes avant et apr&#232;s filtrage dans les r&#233;sultats pr&#233;sent&#233;s.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>WANG ET AL.
</p>
<p>Expected density Connectivity (p = 20)
avant filtrage apr&#232;s filtrage avant filtrage apr&#232;s filtrage
</p>
<p>ORG &#8211; ORG 1,06 1,13 5335,7 3450,8
ORG &#8211; LIEU 1,13 1,02 4458,7 2837,6
ORG &#8211; PERS 1,09 1,17 3025,4 1532,4
PERS &#8211; ORG 1,02 1,06 5638,0 4620,0
PERS &#8211; LIEU 1.08 1,07 5632,5 4571,3
PERS &#8211; PERS 1,13 1,15 3892,7 2569,2
</p>
<p>TAB. 3 &#8211; R&#233;sultats de l&#8217;&#233;valuation interne du regroupement des relations. Les r&#233;sultats en gras sont les meilleurs
scores (la mesure expected density doit &#234;tre maximis&#233;e, la mesure connectivity doit &#234;tre minimis&#233;e)
</p>
<p>l&#8217;impact positif du filtrage pour le regroupement des relations ne donnent qu&#8217;une premi&#232;re tendance et doivent
&#234;tre confirm&#233;s par une &#233;valuation s&#8217;appuyant sur une classification de r&#233;f&#233;rence.
</p>
<p>5 Conclusion
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; un travail sur le filtrage de relations semi-structur&#233;es dans le contexte de
l&#8217;extraction d&#8217;information non supervis&#233;e visant &#224; d&#233;terminer si deux entit&#233;s nomm&#233;es cooccurrant dans une
phrase sont en relation, sans a priori sur la nature de cette relation. Ce filtrage est r&#233;alis&#233; par la combinaison
d&#8217;heuristiques pour &#233;liminer les cas les plus simples et d&#8217;un classifieur appris &#224; partir d&#8217;exemples. Concernant ce
dernier, les &#233;valuations ont montr&#233; une l&#233;g&#232;re sup&#233;riorit&#233; des CRF sur les SVM. Dans la perspective du processus
d&#8217;extraction non supervis&#233;e que nous d&#233;veloppons, nous avons &#233;galement caract&#233;ris&#233; l&#8217;int&#233;r&#234;t de ce filtrage pour
le regroupement s&#233;mantique des relations par l&#8217;utilisation et l&#8217;adaptation de mesures internes d&#8217;&#233;valuation de la
qualit&#233; des regroupements form&#233;s.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BANKO M., CAFARELLA M. J., SODERLAND S., BROADHEAD M. &amp; ETZIONI O. (2007). Open Information
Extraction from the Web. In IJCAI-07, p. 2670&#8211;2676.
BANKO M. &amp; ETZIONI O. (2008). The tradeoffs between open and traditional relation extraction. In 48th
</p>
<p>Annual Meeting of the ACL : Human Language Technologies (ACL-08 : HLT), p. 28&#8211;36.
BAYARDO R. J., MA Y. &amp; SRIKANT R. (2007). Scaling up all pairs similarity search. In 16th international
conference on World Wide Web, p. 131&#8211;140.
CIARAMITA M., GANGEMI A., RATSCH E., SARIC J. &amp; ROJAS I. (2005). Unsupervised learning of semantic
relations between concepts of a molecular biology ontology. In IJCAI 2005, p. 659&#8211;664.
GONZ&#193;LEZ E. &amp; TURMO J. (2009). Unsupervised relation extraction by massive clustering. In Ninth IEEE
International Conference on Data Mining (ICDM 2009), p. 782&#8211;787.
HANDL J., KNOWLES J. &amp; KELL D. B. (2005). Computational cluster validation in post-genomic data analysis.
Bioinformatics, 21(15), 3201&#8211;3212.
HASEGAWA T., SEKINE S. &amp; GRISHMAN R. (2004). Discovering relations among named entities from large
corpora. In 42nd Meeting of the Association for Computational Linguistics (ACL&#8217;04), p. 415&#8211;422.
ROSENFELD B. &amp; FELDMAN R. (2007). Clustering for unsupervised relation identification. In Sixteenth ACM
conference on Conference on information and knowledge management (CIKM&#8217;07), p. 411&#8211;418.
SEKINE S. (2006). On-demand information extraction. In COLING-ACL 2006, p. 731&#8211;738.
SHINYAMA Y. &amp; SEKINE S. (2006). Preemptive information extraction using unrestricted relation discovery. In
HLT-NAACL 2006, p. 304&#8211;311.
STEIN B., SVEN &amp; WISSBROCK F. (2003). On Cluster Validity and the Information Need of Users. In Proc.
3rd IASTED International Conference on Artificial Intelligence and Applications (AIA&#8217;03), p. 404&#8211;413.
VAN DONGEN S. (2000). Graph Clustering by Flow Simulation. PhD thesis, University of Utrecht.</p>

</div></div>
</body></html>