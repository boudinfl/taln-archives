TALN 2011, Montpellier, 27juin — 1"'ju1'11et 2011

Filtrage de relations pour l’extraction d’information non supervisee

Wei Wang1 Romaric Besangonl Olivier Ferretl Brigitte Grauz
(1) CEA, LIST, 18 route du Panorama, BP 6, 92265 Fontenay-aux-Roses
(2) LIMSI, UPR-3251 CNRS-DR4, Bat. 508, BP 133, 91403 Orsay Cedex
wei.wang@cea.fr, romaric.besancon@cea.fr, olivier.ferret@cea.fr, brigitte.grau@limsi.fr

Résllnlé. Le domaine de l’extraction d’information s’est recemment developpe en lirnitant les contraintes
sur la deﬁnition des informations a extraire, ouvrant la voie a des applications de veille plus ouvertes. Dans ce
contexte de l’extraction d’information non supervisee, nous nous interessons a l’identiﬁcation et la caracterisation
de nouvelles relations entre des types d’ entites ﬁxes. Un des deﬁs de cette tache est de faire face a la masse
importante de candidats pour ces relations lorsque l’on considere des corpus de grande taille. Nous presentons dans
cet article une approche pour le ﬁltrage des relations combinant methode heuristique et methode par apprentissage.
Nous evaluons ce ﬁltrage de maniere intrinseque et par son impact sur un regroupement semantique des relations.

Abstract. Information Extraction have recently been extended to new areas, by loosening the constraints on
the strict deﬁnition of the information extracted, thus allowing to design more open information extraction systems.
In this new domain of unsupervised information extraction, we focus on the task of extracting and characterizing
new relations between a given set of entity types. One of the challenges of this task is to deal with the large
amount of candidate relations when extracting them from a large corpus. We propose in this paper an approach
for ﬁltering such candidate relations, based on heuristic and machine learning methods. We present an evaluation
of this ﬁltering phase and an evaluation of the impact of the ﬁltering on the semantic clustering of relations.

M0tS-CléS 3 Extraction d’information non supervisee, ﬁltrage, apprentissage automatique, clustering.

Keywords: Unsupervised information extraction, ﬁltering, machine learning, clustering.

1 Introduction1

Les annees recentes ont vu se developper de nouveaux paradigmes dans le domaine de l’extraction d’information
(EI), parrni lesquels la notion d’EI non supervisee. Cette approche prend comme point de depart des entites ou
des types d’entites et se ﬁxe comme obj ectif de mettre en evidence les relations intervenant entre ces entites, sans
connaissance a priori de leur type. Cette mise en evidence est eventuellement suivie d’un regroupement de ces re-
lations en fonction de leurs sirnilarites pour en faire la synthese. Les travaux effectues dans ce champ de recherche
s’envisagent selon trois points de vue. Le premier est l’acquisition de connaissances, que ce soit des connaissances
sur le monde collectees a vaste echelle a partir du Web, comme avec le concept d’0pen Information Extraction
developpe dans (Banko et al., 2007), ou dans des domaines plus specialises, comme le domaine biologique, ou
cette extraction est le moyen d’ ajouter de nouveaux types de relations entre entites a une ontologie existante (Cia-
ramita et al., 2005). Le deuxieme se situe dans le cadre d’ applications d’EI, ou ce type d’approche correspond
a la volonte d’ offrir aux utilisateurs des modes d’extraction de l’information plus souples et plus ouverts quant
a la speciﬁcation de leur besoin informationnel. L’ approche 0n—demand information extraction (Sekine, 2006),
preﬁguree dans (Hasegawa et al., 2004) et concretisee par les travaux sur la Preemptive Information Extraction
(Shinyama & Sekine, 2006), vise ainsi a induire l’equivalent d’un template a partir d’un ensemble de documents
representatifs des informations a extraire, obtenus par le biais d’ un moteur de recherche, par le regroupement des
relations qui en sont extraites (Rosenfeld & Feldrnan, 2007). Enﬁn, l’EI non supervisee peut aussi servir a com-
pleter l’EI supervisee, qui depend de corpus armotes qui ne sont generalement pas de grande taille, etant donne
la complexite des taches considerees. Les resultats d’une approche non supervisee peuvent alors etre utilises pour
elargir la couvertures des modeles appris (Banko & Etzioni, 2008; Gonzélez & Turmo, 2009).

Dans cet article, nous nous plagons dans le cadre du deuxieme point de vue expose ci—dessus, celui d’une extrac-

1Ce travail a été partiellement réalisé dans le cadre du projet FILTRAR-S soutenu par le programme CSOSG 2008 de l’ANR.

WANG ET AL.

tion d’information plus souple, en y intégrant la problematique du ﬁltrage des relations extraites telle qu’elle est
abordée dans (Banko et al., 2007), mais avec un point de vue different. Nous presentons ainsi un travail visant
a determiner si deux entités nommees cooccurrant dans une phrase entretiennent ou non une relation sans ﬁxer
d’a priori sur la nature de cette relation. Compte tenu de notre perspective globale, nous évaluons dans un second
temps l’impact d’un tel ﬁltrage sur le regroupement des relations extraites.

2 Vue d’ensemble

Le travail que nous présentons ici s’inscrit dans un contexte plus large visant a développer un processus d’ ex-
traction d’information non supervisée susceptible de repondre a des problematiques de veille telle que << suivre
tous les évenements faisant intervenir les sociétés X et Y ». A la base de ce processus, nous nous restreignons
comme les travaux ci—dessus, hormis (Banko et al., 2007), aux relations présentes entre deux entités nommées.
Plus formellement, les relations extraites des textes sont caractérisées par deux grandes categories d’information
permettant tout a la fois de les déﬁnir et de fournir les elements necessaires a leur regroupement : un couple
d’entités nommées (El et E2) et une caracterisation linguistique de la relation (Cpre, Cmid, Cpost).

mere Cimﬂcﬁ Cposat
(ma ,-rm‘.
In 2002, Kerry voted to authorlze the use of force agalnst Saddam In Irak.
km;  ;
E1 (PERSONNE) E2 (PERSONNE)

Cpre, Cmid et Cpost correspondent respectivement a la partie de la phrase precedant la premiere entité El, situee
er1tre les deux entités et suivant la seconde entité E2. L’ ensemble recouvre l’expression linguistique de la relation.
Le plus souvent Cmid exprime la relation proprement dite tandis que Cpre et Cpost foumissent plutot des elements
de contexte pouvant etre utiles dans la perspective de son regroupement avec d’autres relations.

Le processus d’extraction d’information non supervisée déﬁni autour de cette notion de relation s’effectue avec
les etapes suivantes : pre—traitement linguistique des textes, extraction de relations candidates, ﬁltrage des relations
candidates et regroupement des relations selon leur similarite. Le pré—traitement linguistique des textes permet de
mettre en evidence les informations necessaires a la deﬁnition des relations. Ce pré—traitement comporte donc une
reconnaissance des entités nommees pour les types d’entités vises, une desambigu'1'sation morpho—syntaxique des
mots ainsi que leur normalisation. Ces traitements s’appuient sur les outils d’OpenNLP. Nous nous concentrons
sur six types de couples d’entités : ORG — LIEU, ORG — ORG, ORG — PERS, PERS — LIEU, PERS -ORG, PERS — PERS.

3 Filtrage des relations

Les relations candidates, extraites de 18 mois du New York Times issus du corpus AQUAINT—2, sont constituées par
tout couple d’entités nommees (EN) dont les types correspondent aux types cibles, avec pour seules restrictions
la cooccurrence de ces entités dans une meme phrase et la presence d’au moins un verbe er1tre les deux. Leur
examen montre qu’un nombre tres signiﬁcatif des relations ainsi extraites ne sont pas valides. Cette stratégie
basique d’extraction, interessante en domaine de specialité, n’est pas sufﬁsamment selective en domaine ouvert.
Nous avons donc cherche a la compléter par un processus de ﬁltrage visant, comme dans (Banko & Etzioni, 2008),
a determiner si deux entités dans une phrase sont liees par une relation, sans a priori sur la nature de cette relation.

3.1 Filtrage heuristique

Compte tenu du nombre important de relations invalides, nous avons d’abord déﬁni un nombre restreint d’heuris—
tiques pour realiser un ﬁltrage a gros grain. Ces heuristiques sont au nombre de trois :

— suppression des relations comportant entre leurs deux entités un verbe exprimant un discours rapporté;
— limitation a 10 du nombre de mots entre les deux entités. Au—dela de cette limite empirique, le nombre des
relations effectives er1tre les deux entités devient en effet tres faible;
— limitation a 1 du nombre des verbes entre les deux entités, sauf si ce sont des auxiliaires.

FILTRAGE DE RELATIONS

L’ application de ces heuristiques aux relations extraites a globalement pour consequence de réduire leur volume
d’ environ 50%. Nous avons choisi au hasard 50 relations de chaque type et nous avons procedé a une annotation
manuelle de leur validité. Le taux de fausses relations constaté parmi les relations ﬁltrees etant encore assez élevé,
50,7% pour les 6 types considérés, nous avons mis en oeuvre un second ﬁltrage, a grain plus ﬁn.

3.2 Filtrage par apprentissage

Cette seconde étape de ﬁltrage repose sur un classiﬁeur statistique décidant si une relation extraite est veritable-
ment sous—tendue par une relation effective entre ses entites. Nous avons constr11it pour ce faire un corpus d’en—
trainement et de test en annotant manuellement un ensemble de 200 relations sélectionnées au hasard et annotees
par les types d’ EN. L’ annotation distinguait les relations correctes, les relations incorrectes du fait d’un probleme
de reconnaissance des EN et les relations fausses du fait de l’absence de relation. Les relations incorrectes du fait
des EN (20%) ont ete ecartées pour l’entrainement et le test des classiﬁeurs. Le corpus resultant se compose donc
de 964 relations, 531 étant correctes et 433 étant fausses, ce qui constitue un ensemble sufﬁsamment equilibré
pour l’apprentissage des modeles statistiques.

Plusieurs de ces modeles ont eté testes en se concentrant d’ abord sur des modeles exploitant un ensemble de
caractéristiques non structureesz. Les différents classiﬁeurs ont eté entrainés en utilisant le meme ensemble de
caracteristiques, classiques pour l’extraction de relations, a l’instar de (Banko & Etzioni, 2008) :

— le type des entités nommées El et E1 ;

— la catégorie morpho—syntaxique des mots situés entre les deux entités avec un trait binaire pour chaque couple
(position dans la séquence, catégorie), les bigrammes de categories morpho—syntaxiques entre El et E2 avec
un trait binaire pour chaque triplet (position i, cat,-, cat,-+1) ;

— la catégorie morpho—syntaxique des deux mots précedant El et des deux mots suivant E2, a la fois en tant
qu’unigrammes et en tant que bigrammes ;

— la sequence des categories morpho—syntaxiques entre El et E2. Chaque sequence possible de 10 categories est
encodée comme une caractéristique binaire;

— le nombre de mots entre El et E2 ;

— le nombre de signes de ponctuation (virgule, guillemet, parenthese . . .) entre El et E2.

Nous avons également testé un classiﬁeur prenant en compte la notion de sequence en nous appuyant sur les
Champs Conditiormels Aléatoires (CRF). Dans ce cas, la tache considéree prend la forme d’un étiquetage cher-
chant a associer a chaque mot d’une phrase l’une des quatre étiquettes suivantes : O pour un mot de la phrase en
dehors d’une relation, ENT pour une EN deﬁnissant une relation potentielle (El ou E2), B—REL pour le premier
mot d’une relation suivant El, I—REL pour un mot faisant partie d’une relation. Dans ce schema, une relation est
jugée correcte lorsque l’étiquetage suit une conﬁguration de type 0 — ENT — B—REL — I—REL* — ENT — O tandis
qu’elle est jugée fausse si l’etiquetage produit une conﬁguration O — ENT — 0* — ENT — 0. Ce modele a base de
CRF linéaires s’appuie sur l’ensemble de caractéristiques suivant :

— la catégorie morpho—syntaxique du mot courant, du mot precedent et du mot suivant;

— les bigrammes de categories morpho—syntaxiques < cat,--1, cat, >, avec i=-1,0,1 (0 est le mot courant) ;

— le type d’entité nommée du mot courant et de chacun des 6 mots le précédant et le suivant. Ce type peut avoir
une valeur NIL lorsque le mot ne fait pas partie d’une entité nommée.

Une validation croisée a eté faite pour evaluer ces différents classiﬁeurs en decoupant le corpus en 10 parties
egales. Le tableau 1 montre les résultats obtenus par le SVM, le meilleur des premiers classiﬁeurs testes, et les
CRF. L’intégration par ces derniers d’un modele de sequence leur confere une légere supériorite par rapport au
SVM. C’est donc ce modele que nous avons retenu pour le ﬁltrage des relations. On notera également un certain
equilibre entre la precision et le rappel. Enﬁn, comme le montre la demiere ligne du tableau 1, ces resultats se
comparent favorablement a ceux de (Banko & Etzioni, 2008) sur le meme sujet mais sur un corpus different
constitue de documents Web. Dans ce demier cas, la precision est plus forte que la notre mais le rappel tres
largement inférieur. Il faut néanmoins preciser que dans (Banko & Etzioni, 2008), les relations extraites peuvent
faire intervenir des entités plus generales que des entités nommées, ce qui est a priori un facteur de difﬁculté.
En revanche, le corpus d’ apprentissage de (Banko & Etzioni, 2008) est constitue de relations sélectionnées sur la

2Nous avons ainsi entrainé quatre types dc classiﬁeurs : bayésien naif, maximum d’entropie (MaxEnt), arbre dc décision ct Machines 5
Vecteurs dc Support (SVM).

WANG ET AL.

Modéle Exactitude Précision Rappel F1-mesure
SVM 0,732 0,740 0,798 0,767
CRF 0,745 0,762 0,782 0,771
| (Banko&Etzioni, 2008) | / | 0,883 | 0,452 | 0,598 |

TAB. 1 — Evaluation des classiﬁeurs statistiques

base d’heuristiques appliquees aux résultats d’un analyseur syntaxique. La gamme des expressions linguistiques
apprises est donc limitee dans leur cas par les possibilités de l’analyseur syntaxique utilise, probleme auquel nous
n’aVons pas a faire face et qui peut expliquer pour partie leur faible rappel.

3.3 Application du ﬁltrage des relations

L’ extraction des relations se compose de 3 etapes : (1) une extraction initiale, en ne posant comme contraintes
que la cooccurrence dans une phrase d’entités nommees de types donnés et la presence d’au moins un Verbe e11tre
les deux; (2) le ﬁltrage heuristique permettant d’ecarter avec une bonne precision un grand nombre de relations
fausses; (3) l’application du ﬁltrage statistique pennettant de discriminer plus ﬁnement les relations correctes.

Type des relations ORG-LIEU ORG-ORG ORG-PERS PERS-LIEU PERS-ORG PERS-PERS
extraction initiale 71 858 77 025 73 895 152 514 126 281 175 802
heuristiques 33 505 (47%) 37 061 (48%) 32 033 (43%) 72 221 (47%) 66 035 (52%) 78 530 (45%)
classiﬁeur CRF 16 700 (23%) 17 025 (22%) 12 098 (15%) 55 174 (35%) 50 487 (40%) 42 463 (24%)
dédoublormage 15 226 (21%) 13 704 (18%) 10 054 (14%) 47 700 (31%) 40 238 (32%) 38 786 (22%)

TAB. 2 — Volume et pourcentage, relativement a leur nombre initial, des relations apres chaque étape de ﬁltrage

Le constat de la presence dans nos relations ﬁltrees d’un certain nombre de relations identiques, pour une part
issues d’articles sur un meme sujet ou d’articles correspondant a des rubriques tres formatées, nous a conduit
51 compléter ce processus de ﬁltrage par un dédoublonnage ﬁnal Visant a éliminer ces relations redondantes. Il
est a noter que cette operation de dedoublonnage Vient en derniere position, a la fois du fait de son coﬁt, plus
important que celui des autres operation de ﬁltrage et de sa dépendance Vis—a—Vis de l’éValuation de la similarite
e11tre les relations, exploitée ensuite directement pour le regroupement des relations. Si ce ﬁltrage rej ette un grand
nombre des relations extraites initialement, le Volume des relations restantes est a priori sufﬁsant pour alimenter
les etapes suivantes du processus d’EI. Par ailleurs, nous nous situons dans un contexte de traitement de Volumes
textuels importants caractérisés par une certaine redondance informationnelle conduisant a privilégier la precision
des processus d’extraction aﬁn d’eViter un bruit trop important.

4 Impact du ﬁltrage des relations sur leur regroupement

4.1 Regroupement des relations

A l’instar de beaucoup de travaux dans le domaine de l’extraction d’information non supervisée comme (Shinyama
& Sekine, 2006) ou (Rosenfeld & Feldman, 2007), notre obj ectif ﬁnal est le regroupement des relations selon leur
similarité, en particulier pour en faciliter l’exploration. Mais notre but ici étant d’etudier l’inﬂuence du ﬁltrage sur
le regroupement, nous nous contenterons d’ une approche simple (Hasegawa et al., 2004) Visant a rassembler les
relations équivalentes sur le plan sémantique. L’ equivalence de deux relations est évaluée par la mesure cosinus
appliquee a une representation de type << sac de mots » de la caracterisation linguistique des relations. Seule la
partie Cmid de cette caractérisation est prise en compte.

Pour le regroupement, nous avons choisi l’algorithme Markov Clustering (Van Dongen, 2000). Cet algorithme
partitionne un graphe de similarité en clusters disjoints en realisant une serie de marches aleatoires dans ce graphe.

FILTRAGE DE RELATIONS

L’ hypothese est ici qu’un cluster se caractérise par une forte densité de liens entre ses elements et qu’en << sortir »
ne peut donc se faire qu’ apres un nombre important de pas. Cet algorithme itératif converge en pratique rapidement
et se montre capable de faire face a nos graphes composes de quelques dizaines de milliers de noeuds. Par ailleurs,
il determine de maniere intrinseque le nombre de clusters a former et n’est dependant pour ce faire que d’un seul
parametre — le facteur d’ inﬂation — que nous avons laissé a sa Valeur par defaut.

Le Markov Clustering s’appuyant sur un graphe de similarite des elements a regrouper, le probleme de son calcul
pour plusieurs dizaines de milliers de relations se pose ici. Nous avons eu recours pour ce faire a l’algorithme All
Pairs Similarity Search (Bayardo et al., 2007) qui permet, moyennant la ﬁxation d’un seuil de similarite minimale,
de calculer efﬁcacement et de maniere exacte une mesure telle que cosinus pour tous les couples d’ elements dont la
similarité est superieure au seuil ﬁxe. Cette Valeur de similarité minimale a eté etablie grace au Microsoft Research
Paraphrase Corpus, qui rassemble un ensemble de couples de phrases3 associées a un jugement de paraphrase.
Le calcul de la mesure cosinus pour tous ces couples nous a permis de retenir une Valeur minimale de 0,45 pour
les expérimentations de la section suivante, seuil correspondant aux trois—quarts des Valeurs calculees.

4.2 Evaluation de l’impact du ﬁltrage des relations

Nous avons cherche a evaluer l’iInpact du ﬁltrage des relations sur le regroupement de relations en comparant
la qualité des regroupements formes avec ou sans ﬁltrage a la suite de la méthode de regroupement décrite ci-
dessus. Une classiﬁcation de reference n’existant pas pour des relations telles que les notres, nous avons utilise des
mesures intemes d’ evaluation des regroupements. Les mesures de ce type permettent d’établir si le regroupement
obtenu reﬂete bien les Valeurs de similarites dans l’espace des relations. L’ objectif est ici de tester si l’espace des
relations apres ﬁltrage presente une meilleure distribution des similarites Vis—a—Vis de sa capacite a regrouper les
relations. Patmi les différentes mesures existantes, nous avons retenu la mesure de la densité attendue (expected
density), qui est evaluée dans (Stein et al., 2003) comme la mesure ayant la meilleure correlation avec la mesure
exteme de F-mesure pour le clustering de documents (la mesure usuelle de l’indice de Dunn etant jugée moins
stable). Nous avons utilise dans nos experiences une Version modiﬁée de cette mesure, moins dependante de la
taille de l’ensemble des obj ets a regrouper, déﬁnie par p dans l’equation (1). De fagon complémentaire, nous avons
également utilise la mesure de connectivité (connectivity) (Handl et al., 2005), déﬁnie par c dans l’équation (2),
qui evalue dans quelle proportion les relations des plus proches Voisins ne sont pas coupees par le clustering. Cette
mesure est interessante dans notre cas parce qu’elle s’appuie sur la structure du graphe de similarite que nous
utilisons aussi pour la méthode de clustering4. Les deux mesures se déﬁnissent ainsi a partir d’un graphe pondére
(V, E, w), ou V est l’ensemble des noeuds, E l’ensemble des arcs et w, la pondération des arcs.

|C’| |V| 12

p=Zl,‘,§|l% <1) c=ZZw.,....m (2)

72:1 72:1 j=1

Pour la deﬁnition de p, C’ est l’ensemble des clusters, V, les noeuds du cluster 1', et 0 une mesure de densité des
objets a regrouper, déﬁnie par 0 = ln(w(G))/ln(|V|), avec w(G) = |V| + Zea: w(e), et 0, est la meme mesure
pour le graphe restreint aux noeuds du cluster C’,-. Pour la deﬁnition de c, p est le nombre de Voisins considerés,
nn, (j), le jiéme plus proche Voisin de 2' et 1:,-,m1.(j), égal a 0 si 1' et nn, (j) sont dans le meme cluster et 1 / j sinon.
Ces deux mesures evoluent de facon inverse : plus la mesure p est élevée, plus le clustering est jugé de bonne
qualité, alors qu’un c plus bas est signe d’un meilleur clustering.

Les resultats de ces mesures sont présentés dans le tableau 3. Les deux mesures utilisees montrent que le clustering
est dans la plupart des cas de meilleure qualité apres le ﬁltrage des relations, ce qui montre son utilite pour le
regroupement des relations. Les deux couples d’ entités pour lesquels cette tendance n’est pas Veriﬁée pour la
mesure de densité attendue, ORG — LIEU et PERS — LIEU, ont en commun de faire intervenir des entités de type
lieu. Ce constat s’explique peut—etre par une speciﬁcité de ces entités. En effet, lorsqu’une entité de type lieu
est présente dans une phrase et qu’elle n’est pas en relation avec l’autre entité considéree dans la phrase, il est
frequent qu’elle soit inclue dans un complement circonstanciel de lieu. Or, avec la mesure de similarité choisie,
les formes des complements circonstanciels de lieu peuvent induire une similarité entre les phrases Valide du point
de Vue d’un regroupement global et donc donner un bon score de clustering. Ces premiers résultats montrant

3Le corpus distingue un ensemble d’ apprentissage et un ensemble de test que nous avons fusionnés dans le cas présent.
4Cette mesure est également dépendante de la taille du corpus : pour pallier ce probleme, cette mesure est calculée pour un sous-ensemble
de relations choisies aléatoirement, en 1’occurrence 5000 relations présentes avant et apres ﬁltrage dans les résultats présentés.

WANG ET AL.

Expected density Connectivity (p = 20)
avant ﬁltrage apres ﬁltrage avant ﬁltrage apres ﬁltrage

ORG - ORG 1,06 1,13 5335,7 3450,8
ORG — LIEU 1,13 1,02 4458,7 2837,6
ORG — PERS 1,09 1,17 3025,4 1532,4
PERS — ORG 1,02 1,06 5638,0 4620,0
PERS — LIEU 1.08 1,07 5632,5 4571,3
PERS — PERS 1,13 1,15 3892,7 2569,2

TAB. 3 - Résultats de l’évaluation interne du regroupement des relations. Les resultats en gras sont les meilleurs
scores (la mesure expected density doit etre maximisée, la mesure connectivity doit etre minimisee)

l’i1npact positif du ﬁltrage pour le regroupement des relations ne donnent qu’une premiere tendance et doivent
etre conﬁrmes par une evaluation s’appuyant sur une classiﬁcation de reference.

5 Conclusion

Dans cet article, nous avons présenté un travail sur le ﬁltrage de relations semi—structurées dans le contexte de
l’extraction d’information non supervisée visant a determiner si deux entités nommées cooccurrant dans une
phrase sont en relation, sans a priori sur la nature de cette relation. Ce ﬁltrage est realise par la combinaison
d’heuristiques pour éliminer les cas les plus simples et d’un classiﬁeur appris a partir d’exemples. Concernant ce
dernier, les evaluations ont montré une legere superiorité des CRF sur les SVM. Dans la perspective du processus
d’ extraction non supervisée que nous développons, nous avons également caractérisé l’intéret de ce ﬁltrage pour
le regroupement semantique des relations par l’utilisation et l’adaptation de mesures internes d’ evaluation de la
qualité des regroupements formés.

Références

BANKO M., CAFARELLA M. J ., SODERLAND S., BROADHEAD M. & ETZIONI 0. (2007). Open Information
Extraction from the Web. In IJCAI—07, p. 2670-2676.

BANKO M. & ETZIONI O. (2008). The tradeoffs between open and traditional relation extraction. In 48”‘
Annual Meeting of the ACL : Human language Technologies (ACL—08 : HLT), p. 28-36.

BAYARDO R. J ., MA Y. & SRIKANT R. (2007). Scaling up all pairs similarity search. In 16”‘ international
conference on World Wide Web, p. 131-140.

CIARAMITA M., GANGEMI A., RATSCH E., SARIC J . & ROJAS I. (2005). Unsupervised learning of semantic
relations between concepts of a molecular biology ontology. In I] CAI 2005, p. 659-664.

GONZALEZ E. & TURMO J . (2009). Unsupervised relation extraction by massive clustering. In Ninth IEEE
International Conference on Data Mining (ICDM 2009), p. 782-787.

HANDL J ., KNOWLES J . & KELL D. B. (2005). Computational cluster validation in post—genomic data analysis.
Bioinformatics, 21(15), 3201-3212.

HASEGAWA T., SEKINE S. & GRISHMAN R. (2004). Discovering relations among named entities from large
corpora. In 42”‘ Meeting of the Association for Computational Linguistics (ACL’04), p. 415-422.

ROSENFELD B. & FELDMAN R. (2007). Clustering for unsupervised relation identiﬁcation. In Sixteenth ACM
conference on Conference on information and knowledge management (CIKM’07), p. 411-418.

SEKINE S. (2006). On—demand information extraction. In COLING—ACL 2006, p. 731-738.

SHINYAMA Y. & SEKINE S. (2006). Preemptive information extraction using unrestricted relation discovery. In
HLT—NAACL 2006, p. 304-311.

STEIN B., SVEN & WISSBROCK F. (2003). On Cluster Validity and the Information Need of Users. In Proc.
3rd IASTED International Conference on Artiﬁcial Intelligence and Applications (AIA’03), p. 404-413.

VAN DONGEN S. (2000). Graph Clustering by Flow Simulation. PhD thesis, University of Utrecht.

