<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Alignement automatique pour la compr&#233;hension litt&#233;rale de l&#8217;oral par approche segmentale</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Alignement automatique pour la compr&#233;hension litt&#233;rale de l&#8217;oral par
approche segmentale
</p>
<p>St&#233;phane Huet et Fabrice Lef&#232;vre
Universit&#233; d&#8217;Avignon, LIA-CERI, France
</p>
<p>{stephane.huet,fabrice.lefevre}@univ-avignon.fr
</p>
<p>R&#233;sum&#233;. Les approches statistiques les plus performantes actuellement pour la compr&#233;hension automatique
du langage naturel n&#233;cessitent une annotation segmentale des donn&#233;es d&#8217;entra&#238;nement. Nous &#233;tudions dans cet ar-
ticle une alternative permettant d&#8217;obtenir de fa&#231;on non-supervis&#233;e un alignement segmental d&#8217;unit&#233;s conceptuelles
sur les mots. L&#8217;impact de l&#8217;alignement automatique sur les performances du syst&#232;me de compr&#233;hension est &#233;valu&#233;
sur une t&#226;che de dialogue oral.
</p>
<p>Abstract. Most recent efficient statistical approaches for language understanding require a segmental anno-
tation of the training data. In this paper we study an alternative that obtains a segmental alignment of conceptual
units with words in an unsupervised way. The impact of the automatic alignment on the understanding system
performance is evaluated on a spoken dialogue task.
</p>
<p>Mots-cl&#233;s : Alignement non-supervis&#233;, compr&#233;hension de la parole.
</p>
<p>Keywords: Unsupervised alignment, spoken language understanding.
</p>
<p>1 Introduction
</p>
<p>Une des toutes premi&#232;res &#233;tapes pour construire un syst&#232;me de compr&#233;hension de l&#8217;oral pour les syst&#232;mes de
dialogue est l&#8217;extraction de concepts litt&#233;raux &#224; partir d&#8217;une s&#233;quence de mots issue d&#8217;un syst&#232;me de reconnais-
sance de la parole. Pour r&#233;soudre ce probl&#232;me d&#8217;&#233;tiquetage en concepts, un certain nombre de techniques sont
disponibles. Ces techniques reposent sur des mod&#232;les classiques maintenant, qui peuvent &#234;tre g&#233;n&#233;ratifs ou discri-
minants, parmi lesquels on peut citer : les mod&#232;les de Markov cach&#233;s, les transducteurs &#224; &#233;tats finis, les mod&#232;les
de Markov &#224; entropie maximale, les machines &#224; vecteurs supports, les r&#233;seaux bay&#233;siens dynamiques (Dyna-
mic Bayesian Networks, DBN) ou encore les champs de Markov conditionnels (Conditional Markov Random
Fields, CRF (Lafferty et al., 2001)). Dans (Hahn et al., 2010), il est montr&#233; que les CRF permettent d&#8217;obtenir les
meilleures performances sur la t&#226;che MEDIA (Bonneau Maynard et al., 2008) en fran&#231;ais, mais aussi sur deux
corpus comparables en italien et en polonais. De m&#234;me, la robustesse des CRF a pu &#234;tre montr&#233;e en observant ses
r&#233;sultats sur la compr&#233;hension de transcriptions manuelles et automatiques.
</p>
<p>Dans beaucoup d&#8217;approches, l&#8217;interpr&#233;tation litt&#233;rale se contente d&#8217;une relation lexique-concept ; c&#8217;est ainsi le cas
du syst&#232;me PHOENIX (Ward, 1991) bas&#233; sur la d&#233;tection de mots-clefs. L&#8217;approche segmentale fait une analyse
plus fine en consid&#233;rant la phrase comme une s&#233;quence de segments lors de son interpr&#233;tation. Elle permet alors
de relier correctement les diff&#233;rents niveaux d&#8217;analyse : lexicaux, syntaxiques et s&#233;mantiques. Toutefois, afin de
simplifier la mise en &#339;uvre, les segments ont &#233;t&#233; d&#233;finis sp&#233;cifiquement pour l&#8217;annotation conceptuelle et n&#8217;ont
pas de relation impos&#233;e avec les unit&#233;s syntaxiques (chunks, groupes syntaxiques...). Une autre raison est que
l&#8217;objectif &#233;tant d&#8217;utiliser le module d&#8217;interpr&#233;tation au sein de syst&#232;mes de dialogue oral, les donn&#233;es qui sont ici
trait&#233;es sont fortement bruit&#233;es (langage naturel tr&#232;s spontan&#233; et agrammatical, erreurs dues &#224; la reconnaissance
automatique de la parole), ce qui perturbe fortement les analyseurs syntaxiques.
</p>
<p>L&#8217;approche segmentale pr&#233;sente aussi l&#8217;int&#233;r&#234;t de pouvoir d&#233;coupler la d&#233;tection d&#8217;une unit&#233; conceptuelle de
l&#8217;estimation de sa valeur. La valeur correspond &#224; la normalisation de la forme de surface associ&#233;e au concept ; par
exemple si au concept temps-depart est associ&#233; le segment &#171; pas avant 11h &#187;, sa valeur est &#171; matin &#187;. De m&#234;me
pour &#171; entre 8h et 12h &#187; ou &#171; dans la matin&#233;e &#187;. L&#8217;estimation de la valeur n&#233;cessite donc un ancrage des concepts
sur les mots de la phrase. Il est alors possible de traiter le probl&#232;me de normalisation &#224; partir de r&#232;gles sous formes</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ST&#201;PHANE HUET ET FABRICE LEF&#200;VRE
</p>
<p>d&#8217;expressions r&#233;guli&#232;res ou &#224; l&#8217;aide de mod&#232;les de langages sp&#233;cifiques &#224; chaque concept (ce qui permet alors une
approche int&#233;gr&#233;e de l&#8217;interpr&#233;tation (Lef&#232;vre, 2007)). Dans le cas d&#8217;approches globales (c-&#224;-d non segmentales),
la d&#233;tection des valeurs doit &#234;tre associ&#233;e aux classes conceptuelles &#224; reconna&#238;tre, comme dans (Mairesse et al.,
2009). Le processus est alourdi consid&#233;rablement et n&#8217;est plus envisageable que lorsque le nombre de valeurs
possibles est limit&#233;.
</p>
<p>L&#8217;inconv&#233;nient majeur de l&#8217;approche segmentale est bien s&#251;r son co&#251;t : associer des &#233;tiquettes conceptuelles &#224;
la transcription d&#8217;un dialogue est une t&#226;che d&#233;j&#224; complexe et sa complexit&#233; est augment&#233;e par la d&#233;limitation
pr&#233;cise du support (segment lexical) correspondant &#224; chaque unit&#233;. La campagne d&#8217;&#233;valuation des syst&#232;mes de
compr&#233;hension automatique MEDIA a &#233;t&#233; la premi&#232;re occasion de r&#233;aliser et de rendre disponible un corpus de
taille cons&#233;quente poss&#233;dant une annotation segmentale ; toutefois la difficult&#233; reste enti&#232;re &#224; chaque fois qu&#8217;il
faut d&#233;velopper un corpus pour une nouvelle t&#226;che.
</p>
<p>Nous proposons dans cette &#233;tude un proc&#233;d&#233; permettant de r&#233;duire l&#8217;effort n&#233;cessaire &#224; la production de corpus
d&#8217;entra&#238;nement pour obtenir des mod&#232;les d&#8217;annotation conceptuelle segmentale. En faisant l&#8217;hypoth&#232;se que les
unit&#233;s conceptuelles associ&#233;es &#224; une phrase ont &#233;t&#233; d&#233;tect&#233;es automatiquement ou fournies par un expert, nous
&#233;tudions comment les associer &#224; leur support lexical dans la phrase sans connaissances a priori. Dans ce cadre,
des techniques d&#8217;alignement de la traduction automatiques sont utilis&#233;es pour obtenir de mani&#232;re non-supervis&#233;e
une annotation conceptuelle segmentale. Si l&#8217;id&#233;e d&#8217;appliquer des m&#233;thodes issues de la traduction automatique
pour construire des syst&#232;mes de compr&#233;hension n&#8217;est pas nouvelle (Hahn et al., 2010), l&#8217;apport principal de notre
&#233;tude est de montrer l&#8217;int&#233;r&#234;t des m&#233;thodes d&#8217;alignement pour le probl&#232;me de l&#8217;alignement segmental.
</p>
<p>Nous pr&#233;sentons dans l&#8217;article les adaptations n&#233;cessaires &#224; l&#8217;application de techniques d&#8217;alignement dans ce
nouveau contexte. Elles sont peu nombreuses afin de garder la plus grande g&#233;n&#233;ralit&#233; &#224; l&#8217;approche et aussi de
pouvoir b&#233;n&#233;ficier d&#8217;outils logiciels d&#233;j&#224; disponibles. Nous &#233;valuons la qualit&#233; des alignements par l&#8217;approche
non-supervis&#233;e par rapport aux annotations de r&#233;f&#233;rence dans deux situations d&#8217;int&#233;r&#234;t : l&#8217;une o&#249; l&#8217;ordre des
concepts dans la phrase est connu a priori et l&#8217;autre o&#249; ce n&#8217;est pas le cas. Finalement, la v&#233;ritable &#233;valuation de
l&#8217;approche consiste &#224; utiliser des alignements produits pour entra&#238;ner des syst&#232;mes de compr&#233;hension &#224; base de
CRF afin de mesurer leur impact sur les performances finales du syst&#232;me.
</p>
<p>Apr&#232;s un rappel des principes du d&#233;codage conceptuel segmental dans la section 2, l&#8217;alignement automatique de
corpus parall&#232;les sera pr&#233;sent&#233; dans la section 3 avec les particularit&#233;s li&#233;es &#224; l&#8217;alignement de concepts s&#233;man-
tiques. La pr&#233;sentation des exp&#233;riences et les commentaires des r&#233;sultats seront donn&#233;s en section 4.
</p>
<p>2 D&#233;codage conceptuel segmental
</p>
<p>Si l&#8217;interpr&#233;tation litt&#233;rale peut &#234;tre vue comme une traduction de la langue naturelle vers l&#8217;ensemble des s&#233;-
quences d&#8217;&#233;tiquettes s&#233;mantiques, alors les m&#233;thodes et les mod&#232;les de traduction peuvent &#234;tre utilis&#233;s. Consid&#233;-
rant le fait que le nombre de concepts est en g&#233;n&#233;ral bien plus faible que la taille du vocabulaire de mots, ce type
particulier de traduction peut aussi &#234;tre consid&#233;r&#233; simplement comme un probl&#232;me de classification dans lequel
les constituants conceptuels repr&#233;sentent les classes &#224; reconna&#238;tre. Il est donc possible de r&#233;aliser l&#8217;interpr&#233;tation
par le biais de m&#233;thodes et mod&#232;les de classification. Les approches discriminantes mod&#233;lisent la distribution de
probabilit&#233;s conditionnelles d&#8217;une s&#233;quence de constituants s&#233;mantiques (concepts) c1 . . . cn consid&#233;rant une s&#233;-
quence de mots w1 . . . wT : P (cn1 |wT1 ). Dans l&#8217;approche g&#233;n&#233;rative, c&#8217;est la probabilit&#233; jointe P (cn1 , wT1 ) qui sera
mod&#233;lis&#233;e, permettant de calculer des inf&#233;rences pour la pr&#233;diction de donn&#233;es ou l&#8217;apprentissage des param&#232;tres.
</p>
<p>Les mod&#232;les g&#233;n&#233;ratifs (de type mod&#232;les de Markov cach&#233;s) ont &#233;t&#233; introduits en premier pour traiter le probl&#232;me
de compr&#233;hension par des approches probabilistes (Levin &amp; Pieraccini, 1995). Des variantes ont &#233;t&#233; propos&#233;es
plus r&#233;cemment offrant plus de degr&#233;s de libert&#233; dans la mod&#233;lisation (par exemple (He &amp; Young, 2005; Lef&#232;vre,
2007)). Depuis, les mod&#232;les log-lin&#233;aires ont assez clairement montr&#233; leur sup&#233;riorit&#233; sur des t&#226;ches d&#8217;&#233;tiquetage
s&#233;quentiel (Hahn et al., 2010). Plusieurs variantes existent, se distinguant par les hypoth&#232;ses d&#8217;ind&#233;pendance
conditionnelle entre les variables et par l&#8217;&#233;tape de normalisation. Les CRF (Lafferty et al., 2001) repr&#233;sentent des
cha&#238;nes lin&#233;aires de variables al&#233;atoires ind&#233;pendantes, toutes conditionn&#233;es sur la s&#233;quence enti&#232;re &#233;tiquet&#233;e, et
la normalisation est globale &#224; la s&#233;quence.
</p>
<p>Certaines approches g&#233;n&#233;ratives comme les DBN permettent l&#8217;inf&#233;rence dans des mod&#232;les multi-niveaux (Le-
f&#232;vre, 2007) et prennent donc en compte intrins&#232;quement la segmentation. Pour les mod&#232;les ne permettant pas la</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ALIGNEMENT AUTOMATIQUE POUR LA COMPR&#201;HENSION LITT&#201;RALE DE L&#8217;ORAL
</p>
<p>FIGURE 1 &#8211; Exemple d&#8217;alignement des mots avec leurs concepts s&#233;mantiques.
</p>
<p>repr&#233;sentation &#224; plusieurs niveaux, comme les CRF, il convient de repr&#233;senter la notion de segment directement au
niveau des &#233;tiquettes &#224; classer. Le formalisme BIO est utilis&#233; : B est ajout&#233; aux &#233;tiquettes d&#233;butant un segment, I &#224;
l&#8217;int&#233;rieur d&#8217;un segment et O aux segments hors-domaine (si ceux-ci ne sont pas d&#233;j&#224; trait&#233;s par une &#233;tiquette sp&#233;-
cifique). Dans le cas de la figure 1, la s&#233;quence de concepts devient : B-cmd-tache I-cmd-tache I-cmd-tache B-null
I-null B-loc-ville I-loc-ville I-loc-ville I-loc-ville I-loc-ville B-tps-date I-tps-date B-tps-date I-tps-date
</p>
<p>I-tps-date.
</p>
<p>3 Alignement de concepts s&#233;mantiques
</p>
<p>L&#8217;alignement automatique est une des probl&#233;matiques majeures du domaine de la traduction automatique. Les
alignements mot-&#224;-mot sont ainsi utilis&#233;s pour construire des tables de segments qui sont au c&#339;ur de nombreux
syst&#232;mes de traduction statistiques actuels (Koehn et al., 2007). L&#8217;alignement en traduction consiste &#224; trouver
quels mots correspondent dans deux phrases qui sont la traduction l&#8217;une de l&#8217;autre. Ce processus est confront&#233; &#224;
plusieurs difficult&#233;s : certains mots ne sont associ&#233;s &#224; aucun mot dans la traduction ; d&#8217;autres au contraire sont
traduits par plusieurs mots ; les r&#232;gles syntaxiques peuvent enfin diff&#233;rer suivant les langues, les mots en relation
pouvant ainsi &#234;tre &#224; des positions tr&#232;s diff&#233;rentes d&#8217;une langue &#224; une autre.
</p>
<p>Plusieurs mod&#232;les statistiques ont &#233;t&#233; propos&#233;s pour aligner deux phrases (Brown et al., 1993). Un de leurs grands
int&#233;r&#234;ts est qu&#8217;ils sont construits &#224; partir de corpus parall&#232;les align&#233;s au niveau des phrases, sans aucune annotation
manuelle au niveau des mots. Formellement, &#224; partir d&#8217;une phrase S = s1 . . . sm exprim&#233;e dans une langue source
et de sa traduction T = t1 . . . tn, un alignement A = a1 . . . am de type IBM revient &#224; connecter chaque mot de
S &#224; un mot de T (aj &#8712; {1, ..., n}) ou au mot vide (aj = 0), ce dernier rendant compte des mots cibles non
traduits. Les mod&#232;les statistiques IBM permettent d&#8217;&#233;valuer la probabilit&#233; de traduction de S vers T en estimant
P (S,A|T ). Le meilleur alignement A&#770; peut &#234;tre d&#233;termin&#233; &#224; partir de ce crit&#232;re &#224; l&#8217;aide d&#8217;un algorithme de Viterbi :
A&#770; = argmaxAP (S,A|T ).
Les diff&#233;rents mod&#232;les IBM diff&#232;rent suivant leur niveau de complexit&#233;. IBM1 fait des hypoth&#232;ses fortes quant &#224;
l&#8217;ind&#233;pendance entre les alignements et se limite &#224; l&#8217;&#233;valuation des probabilit&#233;s de transfert P (si|tj). Le mod&#232;le
HMM (Vogel et al., 1996), qui est une am&#233;lioration du mod&#232;le IBM2, prend en compte un nouveau param&#232;tre
P (aj |aj&#8722;1, n) qui suppose une d&#233;pendance d&#8217;ordre 1 entre les variables d&#8217;alignement. Les mod&#232;les suivants
(IBM3 &#224; IBM5) introduisent la notion de distorsion, qui mesure la probabilit&#233; de r&#233;ordonnancement des mots de
T par rapport &#224; la position des mots S avec lesquels ils sont align&#233;s, et celle de fertilit&#233;, qui d&#233;termine le nombre
moyen de mots sources qui sont align&#233;s dans une m&#234;me phrase avec un mot cible donn&#233;. Afin d&#8217;am&#233;liorer la
qualit&#233; des alignements, les mod&#232;les IBM sont g&#233;n&#233;ralement appliqu&#233;s dans les deux directions de traduction. On
op&#232;re ensuite une intersection entre les deux alignements ainsi obtenus, en &#233;tendant les alignements aux fronti&#232;res
des groupes de mots d&#233;j&#224; connect&#233;s suivant des heuristiques (Och et al., 1999).
</p>
<p>Si l&#8217;on dispose d&#8217;une m&#233;thode capable de rep&#233;rer automatiquement les concepts contenus dans un tour de parole,
l&#8217;annotation segmentale peut &#234;tre obtenue au moyen d&#8217;un alignement entre les mots du tour du parole S = wT1 et
les concepts T = cn1 qui ont &#233;t&#233; d&#233;tect&#233;s (Fig. 1). Les concepts g&#233;n&#233;r&#233;s suivent id&#233;alement le m&#234;me ordre que les
mots avec lesquels ils doivent &#234;tre align&#233;s. Un cadre plus r&#233;aliste consiste toutefois &#224; consid&#233;rer que les concepts
sont produits sous forme de sacs plut&#244;t que de s&#233;quences ordonn&#233;es.
</p>
<p>Les m&#233;thodes statistiques con&#231;ues pour la traduction automatique sont pertinentes dans notre cadre applicatif,
en consid&#233;rant que la langue cible est celle des concepts. Il existe toutefois des diff&#233;rences notables entre les
deux domaines d&#8217;application. Tout d&#8217;abord, chaque mot ne peut &#234;tre au plus align&#233; qu&#8217;&#224; un concept, alors qu&#8217;un
concept est align&#233; &#224; au moins un mot. En cons&#233;quence, la fertilit&#233; des mots ne peut &#234;tre que 1 dans le cas d&#8217;un
alignement des concepts vers les mots et celle des concepts est sup&#233;rieure ou &#233;gale &#224; 1 dans la direction oppos&#233;e.
Par construction des mod&#232;les IBM, l&#8217;alignement des concepts vers les mots ne permet d&#8217;aligner qu&#8217;un mot au plus</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ST&#201;PHANE HUET ET FABRICE LEF&#200;VRE
</p>
<p>par concept, ce qui emp&#234;che d&#8217;avoir un nombre d&#8217;alignements satisfaisants pour cette direction.
</p>
<p>Une autre diff&#233;rence notable avec la traduction r&#233;side dans l&#8217;absence du mot vide dans le cas de l&#8217;alignement avec
les concepts s&#233;mantiques, chaque mot de la s&#233;quence &#224; aligner devant &#234;tre align&#233; &#224; au moins un concept. Le r&#244;le
s&#233;mantique null attribu&#233; aux mots qui ne sont pas associ&#233;s &#224; un concept pertinent dans le cadre de la compr&#233;-
hension joue un r&#244;le similaire au mot vide. Toutefois, des exp&#233;riences pr&#233;liminaires sur l&#8217;alignement ont montr&#233;
qu&#8217;il &#233;tait pr&#233;f&#233;rable d&#8217;introduire l&#8217;&#233;tiquette null dans la liste des concepts pour aider les mod&#232;les d&#8217;alignement &#224;
reconna&#238;tre que certains mots ne sont pas associ&#233;s &#224; des concepts pertinents.
</p>
<p>Enfin, une derni&#232;re diff&#233;rence concerne la notion de s&#233;quentialit&#233;. En effet, alors que l&#8217;ordre des mots d&#8217;une
langue n&#8217;est pas al&#233;atoire et suit une certaine logique propre aux r&#232;gles syntaxiques de la langue, cela n&#8217;est pas
le cas lorsque l&#8217;on doit aligner une s&#233;quence de mots avec un sac de concepts. Or, les mod&#232;les HMM et IBM2
&#224; IBM5 ont des param&#232;tres qui supposent l&#8217;influence de la position du mot source correspondant ou celles des
traductions des mots cibles adjacents sur la position d&#8217;un mot cible. Le caract&#232;re al&#233;atoire des positions des
&#233;tiquettes conceptuelles est ainsi de nature &#224; perturber ces types de mod&#232;les, contrairement &#224; IBM1.
</p>
<p>4 Exp&#233;riences et r&#233;sultats
</p>
<p>4.1 Cadre exp&#233;rimental
</p>
<p>Les m&#233;thodes employ&#233;es sont &#233;valu&#233;es sur le corpus MEDIA (Bonneau Maynard et al., 2008). Les donn&#233;es se
composent de dialogues homme-machine collect&#233;es &#224; l&#8217;aide d&#8217;une proc&#233;dure de magicien d&#8217;Oz dans le domaine
de la n&#233;gociation pour des services touristiques. Ce corpus, r&#233;alis&#233; dans le cadre d&#8217;une t&#226;che r&#233;aliste, est annot&#233;
par 145 concepts s&#233;mantiques diff&#233;rents et est constitu&#233; de donn&#233;es audio, accompagn&#233;es de leur transcription
automatique et de leur r&#233;f&#233;rence. Le corpus est divis&#233; en trois parties : un ensemble d&#8217;apprentissage (12 k tours de
parole), un ensemble de d&#233;veloppement (1,2 k) et un ensemble de test (3 k).
</p>
<p>Les exp&#233;riences men&#233;es sur les m&#233;thodes d&#8217;alignement ont &#233;t&#233; r&#233;alis&#233;es sur le corpus de d&#233;veloppement au moyen
de l&#8217;outil MGIZA++ (Gao &amp; Vogel, 2008), une version multithread&#233;e de GIZA++ qui pr&#233;sente l&#8217;avantage d&#8217;offrir
des param&#232;tres 1 permettant d&#8217;appliquer sur les corpus de d&#233;veloppement et de test des mod&#232;les d&#8217;alignement
pr&#233;c&#233;demment appris. L&#8217;&#233;tape de d&#233;codage conceptuel a &#233;t&#233; &#233;valu&#233;e quant &#224; elle sur le corpus de test. Diff&#233;rentes
configurations ont &#233;t&#233; test&#233;es : versions manuelle ou automatique de la transcription, prise en compte ou non
des valeurs pour le calcul des erreurs. Plusieurs types d&#8217;ordonnancement des concepts &#224; aligner ont en outre &#233;t&#233;
consid&#233;r&#233;s : une id&#233;ale laissant telles quelles les s&#233;quences de concepts de la r&#233;f&#233;rence et deux autres plus r&#233;alistes
triant les concepts dans l&#8217;ordre alphab&#233;tique ou de mani&#232;re al&#233;atoire, simulant ainsi des sacs de concepts.
</p>
<p>L&#8217;ordre de grandeur du temps mis pour la r&#233;alisation de ces exp&#233;riences est de quelques minutes pour l&#8217;alignement
automatique des 12 k phrases, de quelques heures pour l&#8217;apprentissage des mod&#232;les CRF 2 et de quelques secondes
pour le d&#233;codage du test.
</p>
<p>4.2 R&#233;sultats exp&#233;rimentaux
</p>
<p>La qualit&#233; de l&#8217;alignement est estim&#233;e &#224; l&#8217;aide de l&#8217;AER (Alignment Error Rate), une m&#233;trique souvent employ&#233;e
en traduction automatique (Och &amp; Ney, 2000). Si H repr&#233;sente les alignements sugg&#233;r&#233;s par la m&#233;thode automa-
tique et R les alignements de la r&#233;f&#233;rence, l&#8217;AER est calcul&#233;e par la relation 3 :
</p>
<p>AER = 1&#8722; 2&#215; |H &#8745;R||H|+ |R| (1)
</p>
<p>Comme les alignements sont ensuite utilis&#233;s pour &#233;tiqueter et comme les positions des concepts &#224; aligner ne cor-
respondent pas dans toutes les versions du corpus &#224; celui de la r&#233;f&#233;rence, nous avons consid&#233;rer qu&#8217;un alignement
&#233;tait un couple (wi, cj) plut&#244;t que (i, j).
</p>
<p>1. previousa, previsoust, previousn...
2. Wapiti a &#233;t&#233; utilis&#233; dans nos exp&#233;riences, http://wapiti.limsi.fr/.
3. L&#8217;&#233;galit&#233; est simplifi&#233;e par rapport &#224; celle donn&#233;e habituellement du fait qu&#8217;ici tous les alignements sont consid&#233;r&#233;s comme s&#251;rs dans la
</p>
<p>r&#233;f&#233;rence.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ALIGNEMENT AUTOMATIQUE POUR LA COMPR&#201;HENSION LITT&#201;RALE DE L&#8217;ORAL
</p>
<p>Le tableau 1 pr&#233;sente les r&#233;sultats d&#8217;alignement mesur&#233;s sur le corpus de d&#233;veloppement selon le mode choisi pour
ordonner les concepts et selon la direction consid&#233;r&#233;e d&#8217;alignement. Les trois premi&#232;res lignes montrent le r&#233;sultats
obtenus &#224; partir de la cha&#238;ne d&#8217;it&#233;rations des mod&#232;les IBM 4 utilis&#233;e pour construire les mod&#232;les de traduction par
MOSES, le syst&#232;me &#224; l&#8217;&#233;tat de l&#8217;art le plus utilis&#233; actuellement (Koehn et al., 2007). Comme attendu, l&#8217;AER
mesur&#233; avec des mod&#232;les d&#8217;alignement dans le sens concept &#8594; mot (deuxi&#232;me ligne), qui ne peuvent associer
qu&#8217;un mot maximum &#224; chaque concept, est bien sup&#233;rieur &#224; celui obtenu avec des mod&#232;les construits dans le sens
oppos&#233; (premi&#232;re ligne). L&#8217;utilisation de l&#8217;heuristique par d&#233;faut de MOSES (grow-diag-final) montre toutefois que
la sym&#233;trisation des alignements obtenus dans les deux directions conduit &#224; un gain en terme d&#8217;AER (troisi&#232;me
ligne). Les mod&#232;les IBM1, contrairement aux autres mod&#232;les, ne prennent pas en compte l&#8217;ordre de succession des
mots sources et cibles dans leurs calculs de probabilit&#233;s d&#8217;alignement, ce qui les rend int&#233;ressants pour traiter des
sacs de concepts. Les r&#233;sultats obtenus en appliquant des mod&#232;les IBM1 puis en sym&#233;trisant les alignements dans
les deux sens (quatri&#232;me ligne) montrent que ces mod&#232;les conduisent finalement &#224; des performances inf&#233;rieures
&#224; IBM4 et m&#234;me &#224; HMM (derni&#232;re ligne), que ce soit pour des concepts tri&#233;s selon les ordres alphab&#233;tique ou
al&#233;atoire (2 derni&#232;res colonnes).
</p>
<p>S&#233;quentiel Alphab&#233;tique Al&#233;atoire
</p>
<p>mot&#8594; concept IBM4 14,4 29,2 28,6
concept&#8594; mot IBM4 40,9 51,6 49,0
</p>
<p>sym&#233;tris&#233; IBM4 12,8 27,3 25,7
</p>
<p>sym&#233;tris&#233; IBM1 28,2 33,2 33,1
sym&#233;tris&#233; HMM 14,8 29,9 28,7
</p>
<p>TABLE 1 &#8211; AER (%) sur le corpus de d&#233;veloppement en variant les mod&#232;les d&#8217;alignement et leur direction.
</p>
<p>Les r&#233;sultats pr&#233;c&#233;dents montrent que les performances mesur&#233;es lorsque l&#8217;on consid&#232;re les s&#233;quences de concepts
de la r&#233;f&#233;rence sont fortement d&#233;grad&#233;es quand on est face &#224; des sacs de concepts. Afin de limiter les perturbations
des mod&#232;les IBM qui apprennent des param&#232;tres sur la s&#233;quentialit&#233;, nous r&#233;ordonnons les s&#233;quences apr&#232;s un
premier alignement A1 produit par le mod&#232;le IBM4 sym&#233;tris&#233;. Deux strat&#233;gies ont alors &#233;t&#233; consid&#233;r&#233;es pour
d&#233;terminer la nouvelle position de chaque concept cj : l&#8217;une r&#233;alisant une simple moyenne des positions des mots
wi avec lesquels il est align&#233; suivant A1 (Tab. 2, deuxi&#232;me colonne), l&#8217;autre obtenue en pond&#233;rant chaque position
par les probabilit&#233; de transfert P (wi|cj) et P (cj |wi) d&#233;termin&#233;es par IBM4 (troisi&#232;me colonne). L&#8217;utilisation des
mod&#232;les d&#8217;alignement appris sur le corpus d&#8217;apprentissage ainsi r&#233;ordonn&#233; montre une am&#233;lioration significative
de l&#8217;AER, la diminution de l&#8217;AER &#233;tant plus importante encore en prenant en compte les probabilit&#233;s de transfert.
Cette phase de r&#233;ordonnancement peut &#234;tre r&#233;it&#233;r&#233;e tant que les performances continuent &#224; &#234;tre am&#233;lior&#233;es en
utilisant &#224; l&#8217;it&#233;ration i des corpus d&#8217;apprentissage et de d&#233;veloppement r&#233;ordonn&#233;s suivant les derniers mod&#232;les
d&#8217;alignement Ai obtenus. En proc&#233;dant ainsi jusqu&#8217;&#224; l&#8217;it&#233;ration 3 pour l&#8217;ordre alphab&#233;tique et jusqu&#8217;&#224; l&#8217;it&#233;ration
7 dans le cas al&#233;atoire, l&#8217;AER atteint une valeur inf&#233;rieure &#224; 20% (derni&#232;re colonne). Il est &#224; noter que le tri
al&#233;atoire conduit &#224; de meilleurs r&#233;sultats que l&#8217;ordre alphab&#233;tique du fait que les mod&#232;les IBM4 apprennent des
probabilit&#233;s de distorsion qui sont davantage biais&#233;es lorsque l&#8217;on effectue un tri alphab&#233;tique, en voyant appara&#238;tre
plus souvent les m&#234;mes s&#233;quences de concepts alors que celles-ci ne sont pas celles de la r&#233;f&#233;rence.
</p>
<p>Initial R&#233;ordonnancement 1&#232;re it&#233;ration R&#233;ordonnancement derni&#232;re it&#233;ration
simple avec probabilit&#233;s de transfert avec probabilit&#233;s de transfert
</p>
<p>Alphab&#233;tique 27,3 22,2 21,0 19,4
Al&#233;atoire 25,7 21,9 20,2 18,5
</p>
<p>TABLE 2 &#8211; AER (%) sur le corpus de d&#233;veloppement en variant la strat&#233;gie de r&#233;ordonnancement des concepts.
</p>
<p>Pour la t&#226;che de compr&#233;hension, des CRF sont entra&#238;n&#233;s &#224; partir de corpus d&#8217;entra&#238;nement dont l&#8217;&#233;tiquetage est
r&#233;alis&#233; soit par des experts, soit par des m&#233;thodes automatiques d&#8217;alignement. Le crit&#232;re de performance utilis&#233;
pour &#233;valuer la compr&#233;hension est le taux d&#8217;erreur en concepts (Concept Error Rate, CER). Il s&#8217;obtient en faisant le
ratio de la somme des concepts de l&#8217;hypoth&#232;se substitu&#233;s, ins&#233;r&#233;s ou omis et du nombre total de concepts pr&#233;sents
dans l&#8217;annotation manuelle de r&#233;f&#233;rence, calcul&#233;s apr&#232;s un alignement de Levenshtein entre les deux s&#233;quences
</p>
<p>4. 5 it&#233;rations d&#8217;IBM1, 5 it&#233;rations d&#8217;HMM, 3 it&#233;rations d&#8217;IBM3 puis 3 it&#233;rations d&#8217;IBM4.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ST&#201;PHANE HUET ET FABRICE LEF&#200;VRE
</p>
<p>de concepts hypoth&#232;se et r&#233;f&#233;rence. Le concept null n&#8217;est pas pris en compte lors du calcul du score. &#192; partir
d&#8217;un syst&#232;me &#224; l&#8217;&#233;tat de l&#8217;art, les d&#233;gradations dues aux diff&#233;rentes conditions d&#8217;alignement sont rapport&#233;es dans
le Tableau 3. On retiendra qu&#8217;en tenant compte des valeurs, l&#8217;augmentation du CER est au plus de 8,0 % (17,6 % &#224;
25,6 %), que l&#8217;apport de l&#8217;ordre la ram&#232;ne &#224; 3,7 % (17,6 % &#224; 21,3 %) et enfin qu&#8217;avec la transcription automatique
la d&#233;gradation li&#233;e aux alignements automatiques est moins grande (resp. 5,8 et 2,0 %).
</p>
<p>Erreurs en Concept (Concept+valeur) Manuel S&#233;quentiel Alphab&#233;tique Al&#233;atoire
</p>
<p>Transcription manuelle 13,9 (17,6) 17,7 (21,3) 22,6 (26,4) 22,0 (25,6)
Transcription automatique (WER 31 %) 24,7 (29,8) 27,1 (31,8) 31,5 (36,4) 30,6 (35,6)
</p>
<p>TABLE 3 &#8211; CER (%) du d&#233;codage conceptuel en variant la m&#233;thode d&#8217;alignement des donn&#233;es d&#8217;entrainement.
</p>
<p>Conclusion
</p>
<p>Dans cette &#233;tude nous proposons une approche non-supervis&#233;e au probl&#232;me de l&#8217;alignement des unit&#233;s concep-
tuelles pour la compr&#233;hension automatique du langage naturel. La qualit&#233; de l&#8217;alignement obtenu, d&#233;j&#224; bonne dans
le cas g&#233;n&#233;ral (&lt; 20 % d&#8217;erreurs sur les associations mot-concept), est am&#233;lior&#233;e par la connaissance de l&#8217;ordre
des unit&#233;s &#224; aligner (&lt; 15 %). Lorsque l&#8217;on utilise des CRF appris sur des corpus o&#249; les mots sont align&#233;s automa-
tiquement avec des sacs de concepts, l&#8217;impact mesur&#233; sur les erreurs d&#8217;annotation, de l&#8217;ordre de 8 %, est r&#233;duit &#224;
6 % quand le texte analys&#233; est transcrit automatiquement. Aussi nous pensons que le rapport co&#251;t/performance est
plut&#244;t favorable &#224; la m&#233;thode propos&#233;e.
</p>
<p>R&#233;f&#233;rences
BONNEAU MAYNARD H., DENIS A., B&#201;CHET F., DEVILLERS L., LEF&#200;VRE F., QUIGNARD M., ROSSET S. &amp; VILLA-
NEAU J. (2008). MEDIA : &#233;valuation de la compr&#233;hension dans les syst&#232;mes de dialogue. In L&#8217;&#233;valuation des technologies
de traitement de la langue, les campagnes Technolangue, p. 209&#8211;232. Herm&#232;s, Lavoisier.
BROWN P. F., DELLA PIETRA S. A., DELLA PIETRA V. J. &amp; MERCER R. L. (1993). The mathematics of statistical
machine translation : Parameter estimation. Computational Linguistics, 19(2), 263&#8211;311.
GAO Q. &amp; VOGEL S. (2008). Parallel implementations of word alignment tool. In Software Engineering, Testing, and
Quality Assurance for Natural Language Processing, p. 49&#8211;57, Columbus, OH, USA.
HAHN S., DINARELLI M., RAYMOND C., LEF&#200;VRE F., LEHEN P., DE MORI R., MOSCHITTI A., NEY H. &amp; RICCARDI
G. (2010). Comparing stochastic approaches to spoken language understanding in multiple languages. IEEE Transactions
on Audio, Speech and Language Processing (TASLP), PP, 1&#8211;15.
HE Y. &amp; YOUNG S. (2005). Spoken language understanding using the hidden vector state model. Speech Communication,
48(3&#8211;4), 262&#8211;275.
KOEHN P., HOANG H., BIRCH A., CALLISON-BURCH C., FEDERICO M., BERTOLDI N., COWAN B., SHEN W., MORAN
C., ZENS R., DYER C., BOJAR O., CONSTANTIN A. &amp; HERBST E. (2007). Moses : Open source toolkit for statistical
machine translation. In Proceedings of ACL, Companion Volume, p. 177&#8211;180, Prague, Czech Republic.
LAFFERTY J., MCCALLUM A. &amp; PEREIRA F. (2001). Conditional random fields : Probabilistic models for segmenting and
labeling sequence data. In Proceedings of ICML, p. 282&#8211;289, Williamstown, MA, USA.
LEF&#200;VRE F. (2007). Dynamic bayesian networks and discriminative classifiers for multi-stage semantic interpretation. In
Proceedings of ICASSP, Honolulu, Hawai.
LEVIN E. &amp; PIERACCINI R. (1995). Concept-based spontaneous speech understanding system. In Proceedings of Euros-
peech, p. 555&#8211;558, Madrid, Spain.
MAIRESSE F., GA&#352;IC&#769; M., JURC&#780;&#205;C&#780;EK F., KEIZER S., THOMSON B., YU K. &amp; YOUNG S. (2009). Spoken language
understanding from unaligned data using discriminative classification models. In Proceedings of ICASSP, Taipei, Taiwan.
OCH F. J. &amp; NEY H. (2000). A comparison of alignment models for statistical machine translation. In Proceedings of
Coling, volume 2, p. 1086&#8211;1090, Saarbr&#252;cken, Germany.
OCH F. J., TILLMANN C. &amp; NEY H. (1999). Improved alignment models for statistical machine translation. In Proceedings
of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, p. 20&#8211;28,
College Park, MD, USA.
VOGEL S., NEY H. &amp; TILLMANN C. (1996). HMM-based word alignment in statistical translation. In Proceedings of
Coling, volume 2, p. 836&#8211;841, Copenhagen, Denmark.
WARD W. (1991). Understanding Spontaneous Speech. In Proceedings of ICASSP, p. 365&#8211;368, Toronto, Canada.</p>

</div></div>
</body></html>