TALN 2011, Montpellier, 27juin — l"'ju1'11et 2011

Alignement automatique pour la compréhension littérale de l’oral par
approche segmentale

Stephane Huet et Fabrice Lefévre
Université d’Avignon, LIA-CERI, France
{ stephane.huet,fabrice.lefevre} @univ-avignon.fr

Résllnlé. Les approches statistiques les plus performantes actuellement pour la comprehension automatique
du langage naturel necessitent une annotation segmentale des donnees d’entrainement. Nous etudions dans cet ar-
ticle une alternative permettant d’obtenir de fagon non-supervisee un alignement segmental d’unites conceptuelles
sur les mots. L’ impact de l’alignement automatique sur les performances du systeme de comprehension est evalue
sur une tache de dialogue oral.

Abstract. Most recent efﬁcient statistical approaches for language understanding require a segmental armo-
tation of the training data. In this paper we study an alternative that obtains a segmental alignment of conceptual
units with words in an unsupervised way. The impact of the automatic alignment on the understanding system
performance is evaluated on a spoken dialogue task.

M0tS-CléS 3 Alignement non—supervise, comprehension de la parole.

Keywords: Unsupervised alignment, spoken language understanding.

1 Introduction

Une des toutes premieres etapes pour construire un systeme de comprehension de l’oral pour les systemes de
dialogue est l’extraction de concepts litteraux a partir d’une sequence de mots issue d’un systeme de reconnais-
sance de la parole. Pour resoudre ce probleme d’ etiquetage en concepts, un certain nombre de techniques sont
disponibles. Ces techniques reposent sur des modeles classiques maintenant, qui peuvent etre generatifs ou discri-
minants, parrni lesquels on peut citer : les modeles de Markov caches, les transducteurs a etats ﬁnis, les modeles
de Markov a entropie maxirnale, les machines a vecteurs supports, les reseaux bayesiens dynamiques (Dyna-
mic Bayesian Networks, DBN) ou encore les champs de Markov conditionnels (Conditional Markov Random
Fields, CRF (Lafferty et al., 2001)). Dans (Hahn et al., 2010), il est montre que les CRF permettent d’obtenir les
meilleures performances sur la tache MEDIA (Bonneau Maynard et al., 2008) en frangais, mais aussi sur deux
corpus comparables en italien et en polonais. De meme, la robustesse des CRF a pu etre montree en observant ses
resultats sur la comprehension de transcriptions manuelles et automatiques.

Dans beaucoup d’approches, l’interpretation litterale se contente d’une relation lexique—concept; c’est ainsi le cas
du systeme PHOENIX (Ward, 1991) base sur la detection de mots—clefs. L’ approche segmentale fait une analyse
plus ﬁne en considerant la phrase comme une sequence de segments lors de son interpretation. Elle permet alors
de relier correctement les differents niveaux d’analyse : lexicaux, syntaxiques et semantiques. Toutefois, aﬁn de
sirnpliﬁer la mise en oeuvre, les segments ont ete deﬁnis speciﬁquement pour l’annotation conceptuelle et n’ont
pas de relation imposee avec les unites syntaxiques (chunks, groupes syntaxiques...). Une autre raison est que
l’objectif etant d’utiliser le module d’interpretation au sein de systemes de dialogue oral, les donnees qui sont ici
traitees sont fortement bruitees (langage naturel tres spontane et agrarnmatical, erreurs dues a la reconnaissance
automatique de la parole), ce qui perturbe fortement les analyseurs syntaxiques.

L’ approche segmentale presente aussi l’interet de pouvoir decoupler la detection d’une unite conceptuelle de
l’estimation de sa valeur. La valeur correspond a la normalisation de la forme de surface associee au concept; par
exemple si au concept temps—depart est associe le segment << pas avant 11h », sa valeur est « matin ». De meme
pour << entre 8h et 12h » ou << dans la matinee ». L’estimation de la valeur necessite donc un ancrage des concepts
sur les mots de la phrase. Il est alors possible de traiter le probleme de normalisation a partir de regles sous formes

STEPHANE HUET ET FABRICE LEFEVRE

d’ expressions régulieres ou a l’aide de modeles de langages spéciﬁques a chaque concept (ce qui permet alors une
approche intégree de l’interprétation (Lefevre, 2007)). Dans le cas d’approches globales (c—a—d non segmentales),
la detection des valeurs doit etre associée aux classes conceptuelles a reconnaitre, comme dans (Mairesse et al.,
2009). Le processus est alourdi considerablement et n’est plus envisageable que lorsque le nombre de valeurs
possibles est limité.

L’inconvénient majeur de l’approche segmentale est bien sur son coﬁt : associer des etiquettes conceptuelles a
la transcription d’un dialogue est une tache déja complexe et sa complexite est augmentée par la delimitation
precise du support (segment lexical) correspondant a chaque unite. La carnpagne d’évaluation des systemes de
comprehension automatique MEDIA a ete la premiere occasion de réaliser et de rendre disponible un corpus de
taille consequente possedant une armotation segmentale; toutefois la difﬁculté reste entiere a chaque fois qu’il
faut developper un corpus pour une nouvelle tache.

Nous proposons dans cette etude un procedé permettant de réduire l’effort necessaire a la production de corpus
d’entrainement pour obtenir des modeles d’annotation conceptuelle segmentale. En faisant l’hypothese que les
unites conceptuelles associées a une phrase ont été détectées automatiquement ou foumies par un expert, nous
étudions comment les associer a leur support lexical dans la phrase sans connaissances a priori. Dans ce cadre,
des techniques d’alignement de la traduction automatiques sont utilisées pour obtenir de maniere non—supervisée
une annotation conceptuelle segmentale. Si l’idée d’appliquer des methodes issues de la traduction automatique
pour construire des systemes de comprehension n’est pas nouvelle (Halm et al., 2010), l’apport principal de notre
etude est de montrer l’intéret des méthodes d’alignement pour le probleme de l’alignement segmental.

Nous présentons dans l’article les adaptations necessaires a l’application de techniques d’alignement dans ce
nouveau contexte. Elles sont peu nombreuses aﬁn de garder la plus grande géneralité a l’approche et aussi de
pouvoir béneﬁcier d’outils logiciels déja disponibles. Nous evaluons la qualité des alignements par l’approche
non—supervisée par rapport aux annotations de reference dans deux situations d’interet : l’une ou l’ordre des
concepts dans la phrase est connu a priori et l’autre ou ce n’est pas le cas. Finalement, la veritable evaluation de
l’approche consiste a utiliser des alignements produits pour entrainer des systemes de comprehension a base de
CRF aﬁn de mesurer leur impact sur les performances ﬁnales du systeme.

Apres un rappel des principes du décodage conceptuel segmental dans la section 2, l’alignement automatique de
corpus paralleles sera presente dans la section 3 avec les particularités liees a l’alignement de concepts seman-
tiques. La presentation des experiences et les commentaires des résultats seront donnés en section 4.

2 Décodage conceptuel segmental

Si l’interprétation littérale peut etre vue comme une traduction de la langue naturelle vers l’ensemble des se-
quences d’étiquettes sémantiques, alors les methodes et les modeles de traduction peuvent etre utilises. Conside-
rant le fait que le nombre de concepts est en general bien plus faible que la taille du Vocabulaire de mots, ce type
particulier de traduction peut aussi etre considére simplement comme un probleme de classiﬁcation dans lequel
les constituants conceptuels représentent les classes a reconnaitre. Il est donc possible de realiser l’interpretation
par le biais de methodes et modeles de classiﬁcation. Les approches discriminantes modélisent la distribution de
probabilités conditionnelles d’une sequence de constituants semantiques (concepts) c1 . . . cu considerant une se-
quence de mots w1 . . .wT : P(cf  Dans l’approche generative, c’est la probabilité jointe P(cf, wf) qui sera
modélisee, permettant de calculer des inferences pour la prediction de données ou l’apprentissage des parametres.

Les modeles géneratifs (de type modeles de Markov caches) ont eté introduits en premier pour traiter le probleme
de comprehension par des approches probabilistes (Levin & Pieraccini, 1995). Des variantes ont été proposees
plus récemment offrant plus de degrés de liberté dans la modélisation (par exemple (He & Young, 2005; Lefevre,
2007)). Depuis, les modeles log—linéaires ont assez clairement montré leur superiorite sur des taches d’étiquetage
séquentiel (Halm et al., 2010). Plusieurs variantes existent, se distinguant par les hypotheses d’independance
conditionnelle er1tre les variables et par l’étape de normalisation. Les CRF (Lafferty et al., 2001) représentent des
chaines lineaires de variables aleatoires independantes, toutes conditionnées sur la sequence entiere etiquetee, et
la normalisation est globale a la sequence.

Certaines approches génératives comme les DBN permettent l’inference dans des modeles multi-niveaux (Le-
fevre, 2007) et prennent donc en compte intrinsequement la segmentation. Pour les modeles ne permettant pas la

ALIGNEMENT AUTOMATIQUE POUR LA COMPREHENSION LITTERALE DE L’ ORAL

Je voudrais réserver en fait pour la ville de Nice du 1er au 3 novembre

 I/1 \//// / In/,4

oca1isat1on-v111e temps-date temps

FIGURE 1 — Exemple d’alignement des mots avec leurs concepts sémantiques.

representation a plusieurs niveaux, comme les CRF, il convient de représenter la notion de segment directement au
niveau des étiquettes a classer. Le formalisme BIO est utilise : B est ajouté aux étiquettes debutant un segment, I a
l’intérieur d’un segment et 0 aux segments hors—domaine (si ceux—ci ne sont pas déja traités par une etiquette spe-
ciﬁque). Dans le cas de la ﬁgure 1, la sequence de concepts devient : B—cmd—tache I—cmd—tache I—cmd—tache B—null
I—null B—loc—ville I—loc—ville I—loc—ville I—loc—ville I—loc—ville B—tps—date I—tps—date B—tps—date I—tps—date
I—tps—date.

3 Alignement de concepts sémantiques

L’ alignement automatique est une des problématiques majeures du domaine de la traduction automatique. Les
alignements mot—a-mot sont ainsi utilises pour constr11ire des tables de segments qui sont au coeur de nombreux
systemes de traduction statistiques actuels (Koehn et al., 2007). L’ alignement en traduction consiste a trouver
quels mots correspondent dans deux phrases qui sont la traduction l’une de l’autre. Ce processus est confronté a
plusieurs difﬁcultés : certains mots ne sont associés a aucun mot dans la traduction; d’autres au contraire sont
traduits par plusieurs mots; les regles syntaxiques peuvent enﬁn différer suivant les langues, les mots en relation
pouvant ainsi etre a des positions tres différentes d’une langue a une autre.

Plusieurs modeles statistiques ont été proposes pour aligner deux phrases (Brown et al., 1993). Un de leurs grands
intérets est qu’ils sont construits a partir de corpus paralleles alignés au niveau des phrases, sans aucune annotation
manuelle au niveau des mots. Formellement, a partir d’une phrase S’ = s1 . . . sm exprimée dans une langue source
et de sa traduction T = t1 . . .25”, un alignement A = a1 . . . am de type IBM revient a connecter chaque mot de
5' a un mot de T (aj E {1, ..., n}) ou au mot Vide (0/j = 0), ce demier rendant compte des mots cibles non
traduits. Les modeles statistiques IBM permettent d’éValuer la probabilité de traduction de .5’ Vers T en estimant
If (S, A|T). Le meilleur alignement /A1 peut etre determine a partir de ce critere a l’aide d’un algorithme de Viterbi :
A = argmaxAP(S',A|T).

Les différents modeles IBM different suivant leur niveau de complexité. IBM1 fait des hypotheses fortes quant a
l’indépendance entre les alignements et se limite a l’éValuation des probabilités de transfert P (s,-|tj). Le modele
HMM (Vogel et al., 1996), qui est une amelioration du modele IBM2, prend en compte un nouveau parametre
P(aj|aj_1, n) qui suppose une dépendance d’ordre 1 e11tre les Variables d’alignement. Les modeles suivants
(IBM3 a IBM5) introduisent la notion de distorsion, qui mesure la probabilité de réordonnancement des mots de
T par rapport a la position des mots S’ avec lesquels ils sont alignes, et celle de fertilité, qui determine le nombre
moyen de mots sources qui sont alignés dans une meme phrase avec un mot cible donné. Aﬁn d’améliorer la
qualité des alignements, les modeles IBM sont généralement appliqués dans les deux directions de traduction. On
opere ensuite une intersection entre les deux alignements ainsi obtenus, en étendant les alignements aux frontieres
des groupes de mots déja connectés suivant des heuristiques (Och et al., 1999).

Si l’on dispose d’une méthode capable de repérer automatiquement les concepts contenus dans un tour de parole,
l’annotation segmentale peut etre obtenue au moyen d’un alignement entre les mots du tour du parole S’ = w? et
les concepts T = c? qui ont été detectés (Fig. 1). Les concepts générés suivent idéalement le meme ordre que les
mots avec lesquels ils doivent etre alignés. Un cadre plus réaliste consiste toutefois a considérer que les concepts
sont produits sous forme de sacs plutot que de sequences ordonnées.

Les méthodes statistiques congues pour la traduction automatique sont pertinentes dans notre cadre applicatif,
en considérant que la langue cible est celle des concepts. Il existe toutefois des differences notables entre les
deux domaines d’ application. Tout d’abord, chaque mot ne peut etre au plus aligne qu’a un concept, alors qu’un
concept est aligne a au moins un mot. En consequence, la fertilité des mots ne peut etre que 1 dans le cas d’un
alignement des concepts Vers les mots et celle des concepts est supérieure ou égale a 1 dans la direction opposée.
Par construction des modeles IBM, l’alignement des concepts Vers les mots ne permet d’aligner qu’un mot au plus

STEPHANE HUET ET FABRICE LEFEVRE

par concept, ce qui empeche d’aVoir un nombre d’alignements satisfaisants pour cette direction.

Une autre difference notable avec la traduction reside dans l’absence du mot Vide dans le cas de l’alignement avec
les concepts sémantiques, chaque mot de la sequence a aligner devant etre aligné a au moins un concept. Le role
sémantique null attribue aux mots qui ne sont pas associés a un concept pertinent dans le cadre de la compre-
hension joue un role similaire au mot Vide. Toutefois, des experiences préliminaires sur l’alignement ont montre
qu’il était preferable d’introduire l’étiquette null dans la liste des concepts pour aider les modeles d’a1ignement a
reconnaitre que certains mots ne sont pas associés a des concepts pertinents.

Enﬁn, une derniere difference concerne la notion de séquentialite. En effet, alors que l’ordre des mots d’une
langue n’est pas aleatoire et suit une certaine logique propre aux regles syntaxiques de la langue, cela n’est pas
le cas lorsque l’on doit aligner une sequence de mots avec un sac de concepts. Or, les modeles HMM et IBM2
a IBM5 ont des parametres qui supposent l’inﬂuence de la position du mot source correspondant ou celles des
traductions des mots cibles adjacents sur la position d’un mot cible. Le caractere aleatoire des positions des
etiquettes conceptuelles est ainsi de nature a perturber ces types de modeles, contrairement a IBMl.

4 Expériences et résultats

4.1 Cadre expérimental

Les méthodes employees sont évaluées sur le corpus MEDIA (Bonneau Maynard et al., 2008). Les données se
composent de dialogues homme—machine collectees a l’aide d’une procedure de magicien d’Oz dans le domaine
de la négociation pour des services touristiques. Ce corpus, realise dans le cadre d’une tache réaliste, est annoté
par 145 concepts semantiques différents et est constitué de données audio, accompagnees de leur transcription
automatique et de leur reference. Le corpus est divisé en trois parties : un ensemble d’apprentissage (12 k tours de
parole), un ensemble de developpement (l,2 k) et un ensemble detest (3 k).

Les experiences menées sur les methodes d’alignement ont ete realisées sur le corpus de developpement au moyen
de l’outil MGIZA++ (Gao & Vogel, 2008), une Version multithreadee de GIZA++ qui presente l’aVantage d’offrir
des parametresl permettant d’appliquer sur les corpus de développement et de test des modeles d’alignement
précédemment appris. L’ étape de décodage conceptuel a ete evaluee quant a elle sur le corpus detest. Differentes
conﬁgurations ont ete testees : Versions manuelle ou automatique de la transcription, prise en compte ou non
des Valeurs pour le calcul des erreurs. Plusieurs types d’ordonnancement des concepts a aligner ont en outre ete
considérés : une ideale laissant telles quelles les sequences de concepts de la reference et deux autres plus realistes
triant les concepts dans l’ordre alphabetique ou de maniere aleatoire, simulant ainsi des sacs de concepts.

L’ ordre de grandeur du temps mis pour la realisation de ces experiences est de quelques minutes pour l’alignement
automatique des 12 k phrases, de quelques heures pour l’apprentissage des modeles CRF 2 et de quelques secondes
pour le décodage du test.

4.2 Résultats expérimentaux

La qualite de l’alignement est estimee a l’aide de l’AER (Alignment Error Rate), une metrique souvent employee
en traduction automatique (Och & Ney, 2000). Si H représente les alignements suggeres par la methode automa-
tique et R les alignements de la reference, l’AER est calculee par la relation 3 :

2><|HnR|

AER=1—
|H|+|R|

(1)
Come les alignements sont ensuite utilises pour etiqueter et comme les positions des concepts a aligner ne cor-
respondent pas dans toutes les Versions du corpus a celui de la reference, nous avons considérer qu’un alignement
était un couple (w,~, cj) plutot que (i, j

l. previousa, previsoust, previousn...

2. Wapiti a été utilisé dans nos expériences, http : //wapiti . limsi . fr/.

3. L’éga1ité est simpliﬁée par rapport a celle donnée habituellement du fait qu’ici tous les alignements sont considérés comme sﬁrs dans la
référence.

ALIGNEMENT AUTOMATIQUE POUR LA COMPREHENSION LITTERALE DE L’ ORAL

Le tableau 1 présente les resultats d’alignement mesures sur le corpus de developpement selon le mode choisi pour
ordonner les concepts et selon la direction considérée d’ alignement. Les trois premieres lignes montrent le resultats
obtenus a partir de la chaine d’itérations des modeles IBM 4 utilisee pour construire les modeles de traduction par
MOSES, le systeme a l’état de l’art le plus utilise actuellement (Koehn et al., 2007). Come attendu, l’AER
mesuré avec des modeles d’ alignement dans le sens concept —> mot (deuxieme ligne), qui ne peuvent associer
qu’un mot maximum a chaque concept, est bien supérieur a celui obtenu avec des modeles constr11its dans le sens
oppose (premiere ligne). L’utilisation de l’heuristique par defaut de MOSES (grow—diag—ﬁnal) montre toutefois que
la symétrisation des alignements obtenus dans les deux directions conduit a un gain en terme d’AER (troisieme
ligne). Les modeles IBM1, contrairement aux autres modeles, ne prennent pas en compte l’ordre de succession des
mots sources et cibles dans leurs calculs de probabilités d’alignement, ce qui les rend intéressants pour traiter des
sacs de concepts. Les resultats obtenus en appliquant des modeles IBM1 puis en symétrisant les alignements dans
les deux sens (quatrieme ligne) montrent que ces modeles conduisent ﬁnalement a des performances inférieures
a IBM4 et meme a HMM (demiere ligne), que ce soit pour des concepts tries selon les ordres alphabétique ou
aléatoire (2 demieres colonnes).

Séquentiel Alphabetique Aleatoire

mot —> concept IBM4 14,4 29,2 28,6
concept —> mot IBM4 40,9 51,6 49,0
symétrisé IBM4 12,8 27,3 25,7
symetrise IBM1 28,2 33,2 33,1
symetrisé HMM 14,8 29,9 28,7

TABLE 1 — AER (%) sur le corpus de developpement en Variant les modeles d’alignement et leur direction.

Les resultats precedents montrent que les performances mesurées lorsque l’on considere les sequences de concepts
de la reference sont fortement dégradees quand on est face a des sacs de concepts. Aﬁn de limiter les perturbations
des modeles IBM qui apprennent des parametres sur la sequentialité, nous reordonnons les sequences apres un
premier alignement A1 produit par le modele IBM4 symétrisé. Deux strategies ont alors eté considérees pour
determiner la nouvelle position de chaque concept Cj : l’une realisant une simple moyenne des positions des mots
w,- avec lesquels il est aligné suivant A1 (Tab. 2, deuxieme colonne), l’autre obtenue en pondérant chaque position
par les probabilité de transfert P (w,- |cj) et P(cj  determinées par IBM4 (troisieme colonne). L’utilisation des
modeles d’alignement appris sur le corpus d’apprentissage ainsi réordonne montre une amelioration signiﬁcative
de l’AER, la diminution de l’AER etant plus importante encore en prenant en compte les probabilites de transfert.
Cette phase de réordonnancement peut etre réiteree tant que les performances continuent a etre améliorées en
utilisant a l’itération i des corpus d’apprentissage et de développement réordonnes suivant les derniers modeles
d’a1ignement A, obtenus. En procédant ainsi jusqu’a l’itération 3 pour l’ordre alphabétique et jusqu’a l’itération
7 dans le cas aleatoire, l’AER atteint une Valeur inferieure a 20% (demiere colonne). Il est a noter que le tri
aleatoire conduit a de meilleurs resultats que l’ordre alphabétique du fait que les modeles IBM4 apprennent des
probabilités de distorsion qui sont davantage biaisees lorsque l’on effectue un tri alphabétique, en Voyant apparaitre
plus souvent les memes sequences de concepts alors que celles—ci ne sont pas celles de la reference.

Initial Réordonnancement lére iteration Réordonnancement demiere iteration
simple avec probabilités de transfert avec probabilités de transfert
Alphabétique 27,3 22,2 21,0 19,4
Aleatoire 25,7 21,9 20,2 18,5

TABLE 2 — AER (%) sur le corpus de developpement en Variant la stratégie de réordonnancement des concepts.

Pour la tache de comprehension, des CRF sont entrainés a partir de corpus d’ entrainement dont l’étiquetage est
realise soit par des experts, soit par des methodes automatiques d’alignement. Le critere de performance utilise
pour évaluer la comprehension est le taux d’erreur en concepts (Concept Error Rate, CER). Il s’ obtient en faisant le
ratio de la somme des concepts de l’hypothese substitues, insérés ou omis et du nombre total de concepts presents
dans l’annotation manuelle de reference, calculés apres un alignement de Levenshtein entre les deux sequences

4. 5 itérations d’[BM1, 5 itérations d’I-I1VI1VI, 3 itérations d’[BM3 puis 3 itérations d’[BM4.

STEPHANE HUET ET FABRICE LEFEVRE

de concepts hypothese et reference. Le concept null n’est pas pris en compte lors du calcul du score. A partir
d’un systeme a l’état de l’art, les degradations dues aux differentes conditions d’alignement sont rapportees dans
le Tableau 3. On retiendra qu’en tenant compte des valeurs, l’augmentation du CER est au plus de 8,0 % (17,6 % a
25,6 %), que l’apport de l’ordre la ramene a 3,7 % (17,6 % a 21,3 %) et enﬁn qu’avec la transcription automatique
la degradation liee aux alignements automatiques est moins grande (resp. 5,8 et 2,0 %).

Erreurs en Concept (Concept+valeur) Manuel Séquentiel Alphabétique Aleatoire

Transcription manuelle 13,9 (17,6) 17,7 (21,3) 22,6 (26,4) 22,0 (25,6)
Transcription automatique (WER 31 %) 24,7 (29,8) 27,1 (31,8) 31,5 (36,4) 30,6 (35,6)

TABLE 3 — CER (%) du décodage conceptuel en variant la méthode d’a1ignement des données d’entrainement.
Conclusion

Dans cette etude nous proposons une approche non—supervisée au probleme de l’alignement des unites concep-
tuelles pour la comprehension automatique du langage naturel. La qualité de l’alignement obtenu, deja bonne dans
le cas general (< 20 % d’erreurs sur les associations mot—concept), est ameliorée par la connaissance de l’ordre
des unites a aligner (< 15 %). Lorsque l’on utilise des CRF appris sur des corpus ou les mots sont alignés automa-
tiquement avec des sacs de concepts, l’i1npact mesuré sur les erreurs d’annotation, de l’ordre de 8 %, est reduit a
6 % quand le texte analyse est transcrit automatiquement. Aussi nous pensons que le rapport coﬁt/performance est
plutot favorable a la methode proposée.

Références

BONNEAU MAYNARD H., DENIs A., BECHET F., DEvILLERs L., LEFEVRE F., QUIGNARD M., ROssET S. & VILLA-
NEAU J. (2008). MEDIA : évaluation de la comprehension dans les systemes de dialogue. In L’évaluation des technologies
de traitement de la langue, les campagnes Technolangue, p. 209-232. Hermes, Lavoisier.

BROWN P. F., DELLA PIETRA S. A., DELLA PIETRA V. J. & MERCER R. L. (1993). The mathematics of statistical
machine translation : Parameter estimation. Computational Linguistics, 19(2), 263-311.

GAO Q. & VOGEL S. (2008). Parallel implementations of word alignment tool. In Software Engineering, Testing, and
Quality Assurance for Natural Language Processing, p. 49-57, Columbus, OH, USA.

HAHN S., DINARELLI M., RAYMOND C., LEFEVRE F., LEHEN P., DE MORI R., MOSCHITTI A., NEY H. & RICCARDI
G. (2010). Comparing stochastic approaches to spoken language understanding in multiple languages. IEEE Transactions
on Audio, Speech and Language Processing (TASLP), PP, 1-15.

HE Y. & YOUNG S. (2005). Spoken language understanding using the hidden vector state model. Speech Communication,
48(3—4), 262-275.

KOEHN P., HOANG H., BIRCH A., CALLISON-BURCH C., FEDERICO M., BERTOLDI N., COWAN B., SHEN W., MORAN
C., ZENS R., DYER C., BOJAR 0., CONSTANTIN A. & HERBST E. (2007). Moses : Open source toolkit for statistical
machine translation. In Proceedings of ACL, Companion Volume, p. 177-180, Prague, Czech Republic.

LAFFERTY J ., MCCALLUM A. & PEREIRA F. (2001). Conditional random ﬁelds : Probabilistic models for segmenting and
labeling sequence data. In Proceedings of ICML, p. 282-289, Williamstown, MA, USA.

LEFEVRE F. (2007). Dynamic bayesian networks and discriminative classiﬁers for multi-stage semantic interpretation. In
Proceedings of ICASSP, Honolulu, Hawai.

LEVIN E. & PIERACCINI R. (1995). Concept-based spontaneous speech understanding system. In Proceedings of Euros-
peech, p. 555-558, Madrid, Spain.

MAIRESSE F., GAsIC M., JURCICEK F., KEIZER S., THOMSON B., YU K. & YOUNG S. (2009). Spoken language
understanding from unaligned data using discriminative classiﬁcation models. In Proceedings of ICASSP, Taipei, Taiwan.
OCH F. J. & NEY H. (2000). A comparison of alignment models for statistical machine translation. In Proceedings of
Coling, volmne 2, p. 1086-1090, Saarbriicken, Germany.

OCH F. J ., TILLMANN C. & NEY H. (1999). Improved alignment models for statistical machine translation. In Proceedings
of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, p. 20-28,
College Park, MD, USA.

VOGEL S., NEY H. & TILLMANN C. (1996). I-Il\/Il\/I-based word alignment in statistical translation. In Proceedings of
Coling, volume 2, p. 836-841, Copenhagen, Denmark.

WARD W. (1991). Understanding Spontaneous Speech. In Proceedings of ICASSP, p. 365-368, Toronto, Canada.

