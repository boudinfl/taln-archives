<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Ajout d&#8217;informations contextuelles pour la recherche de passages au sein de Wikip&#233;dia</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Ajout d&#8217;informations contextuelles pour la recherche de passages au sein
de Wikip&#233;dia
</p>
<p>Romain Deveaud Eric SanJuan Patrice Bellot
LIA - Universit&#233; d&#8217;Avignon
</p>
<p>339, chemin des Meinajari&#232;s Agroparc BP 91228
84 911 Avignon Cedex 9
</p>
<p>{romain.deveaud,eric.sanjuan,patrice.bellot}@univ-avignon.fr
</p>
<p>R&#233;sum&#233;. La recherche de passages consiste &#224; extraire uniquement des passages pertinents par rapport &#224; une
requ&#234;te utilisateur plut&#244;t qu&#8217;un ensemble de documents entiers. Cette r&#233;cup&#233;ration de passages est souvent handi-
cap&#233;e par le manque d&#8217;informations compl&#233;mentaires concernant le contexte de la recherche initi&#233;e par l&#8217;utilisa-
teur. Des &#233;tudes montrent que l&#8217;ajout d&#8217;informations contextuelles par l&#8217;utilisateur peut am&#233;liorer les performances
des syst&#232;mes de recherche de passages. Nous confirmons ces observations dans cet article, et nous introduisons
&#233;galement une m&#233;thode d&#8217;enrichissement de la requ&#234;te &#224; partir d&#8217;informations contextuelles issues de documents
encyclop&#233;diques. Nous menons des exp&#233;rimentations en utilisant la collection et les m&#233;thodes d&#8217;&#233;valuation pro-
pos&#233;es par la campagne INEX. Les r&#233;sultats obtenus montrent que l&#8217;ajout d&#8217;informations contextuelles permet
d&#8217;am&#233;liorer significativement les performances de notre syst&#232;me de recherche de passages. Nous observons &#233;ga-
lement que notre approche automatique obtient les meilleurs r&#233;sultats parmi les diff&#233;rentes approches que nous
&#233;valuons.
</p>
<p>Abstract. Traditional Information Retrieval aims to present whole documents that are relevant to a user
request. However, there is sometimes only one sentence that is relevant in the document. The purpose of Focused
Information Retrieval is to find and extract relevant passages instead of entire documents. This retrieval task often
lacks of complement concerning the context of the information need of the user. Studies show that the perfor-
mance of focused retrieval systems are improved when user manually add contextual information. In this paper
we confirm these observation, and we also introduce a query expansion approach using contextual information
taken from encyclopedic documents. We use the INEX workshop collection and evaluation framework in our ex-
periments. Results show that adding contextual information significantly improves the performance of our focused
retrieval system. We also see that our automatic approach obtains the best results among the different approach
we evaluate.
</p>
<p>Mots-cl&#233;s : Recherche de passages, enrichissement de requ&#234;tes, contexte, Wikipedia, INEX, entropie.
</p>
<p>Keywords: Focused retrieval, query expansion, context, Wikipedia, INEX, entropy.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ROMAIN DEVEAUD, ERIC SANJUAN, PATRICE BELLOT
</p>
<p>1 Introduction
</p>
<p>Les approches traditionnelles de Recherche d&#8217;Information (RI) cherchent &#224; retrouver le ou les documents les plus
pertinents par rapport &#224; une requ&#234;te. Parfois, seule une petite partie d&#8217;un document est tr&#232;s pertinente mais celui-ci
est mal class&#233; et l&#8217;information n&#8217;est pas pr&#233;sent&#233;e &#224; l&#8217;utilisateur. La recherche de passages consiste &#224; rechercher
uniquement ces passages pertinents, en laissant le soin au syst&#232;me de d&#233;terminer le meilleur niveau de granularit&#233;
des documents tout en &#233;vitant le recouvrement entre diff&#233;rents passages.
</p>
<p>La recherche de passages restreints, ou Focused Information Retrieval (Trotman et al., 2010; Arvola et al., 2011),
ajoute une contrainte qui consiste &#224; limiter la taille totale du texte pr&#233;sent&#233; &#224; l&#8217;utilisateur. Cette taille est fix&#233;e par
des contraintes techniques telles que la taille d&#8217;un &#233;cran d&#8217;un t&#233;l&#233;phone portable. Les passages extraits et pr&#233;sent&#233;s
&#224; l&#8217;utilisateur doivent &#233;galement &#234;tre lisibles et compr&#233;hensibles (Harman &amp; Over, 2002). Cette t&#226;che s&#8217;approche
ainsi de celle du r&#233;sum&#233; automatique puisqu&#8217;il s&#8217;agit de r&#233;cup&#233;rer les passages les plus importants dans un corpus,
plut&#244;t que de r&#233;cup&#233;rer l&#8217;ensemble des passages pertinents (Dang, 2005; Dang &amp; Owczarzak, 2008; Harman &amp;
Over, 2002). Cependant, &#224; la diff&#233;rence des r&#233;sum&#233;s automatiques, il ne s&#8217;agit pas de g&#233;n&#233;rer un r&#233;sum&#233; mais
bien d&#8217;extraire des passages des documents, ces passages pouvant &#234;tre utilis&#233;s dans un processus de recherche
d&#8217;information interactive. La campagne d&#8217;&#233;valuation INEX a &#233;t&#233; cr&#233;&#233;e dans le but de d&#233;velopper la recherche
de passages et d&#8217;&#233;l&#233;ments dans des documents XML. Dans ce contexte, un cadre d&#8217;&#233;valuation de recherche de
passages est utilis&#233; depuis l&#8217;apparition de la t&#226;che Focused de la piste Ad Hoc (Kamps et al., 2008).
</p>
<p>C&#8217;est lors de l&#8217;&#233;dition 2010 que la campagne INEX a vu appara&#238;tre une t&#226;che de recherche de passages restreints.
Un corpus de requ&#234;tes a &#233;t&#233; constitu&#233; en reprenant la m&#233;thodologie des pr&#233;c&#233;dentes campagnes, en retenant de
fa&#231;on prioritaire les requ&#234;tes dont les &#233;l&#233;ments de r&#233;ponse &#233;taient r&#233;partis dans plusieurs pages Wikipedia. Par
ailleurs, chaque requ&#234;te constitu&#233;e d&#8217;un titre tr&#232;s court &#233;tait compl&#233;t&#233;e par une liste de termes (mots-cl&#233;s ou
syntagmes nominaux) pr&#233;cisant le contexte th&#233;matique de la recherche.
</p>
<p>Au moyen d&#8217;un syst&#232;me de recherche de passages, nous proposons de montrer que non seulement ce contexte
am&#233;liore les r&#233;sultats de la recherche mais aussi qu&#8217;il est possible d&#8217;en retrouver une variante automatiquement
qui aboutit &#224; des hausses de performance comparables. Cela, dans le cadre d&#8217;un processus de recherche encyclo-
p&#233;dique &#224; partir de requ&#234;tes complexes, constitue une avanc&#233;e notable &#224; mettre en regard avec les r&#233;sultats souvent
d&#233;cevants obtenus par les m&#233;thodes automatiques d&#8217;enrichissement.
</p>
<p>2 M&#233;thodologie
</p>
<p>2.1 Extraction de phrases et attribution de scores
</p>
<p>Dans toutes nos exp&#233;rimentations nous utilisons le syst&#232;me que nous avons propos&#233; comme &#233;talon &#224; la t&#226;che de
Question-R&#233;ponse d&#8217;INEX (SanJuan et al., 2011). Ce syst&#232;me utilise Indri 1 pour l&#8217;indexation et l&#8217;extraction de
documents ainsi qu&#8217;une approche par mod&#232;les de langue pour la RI (Metzler &amp; Croft, 2004). Lors de l&#8217;indexation,
les mots ne sont pas tronqu&#233;s de mani&#232;re &#224; permettre des recherches exactes, et leurs positions dans les docu-
ments sont m&#233;moris&#233;es. Ce syst&#232;me int&#232;gre &#233;galement un &#233;tiqueteur morpho-syntaxique incluant l&#8217;&#233;tiquetage de
la ponctuation : TreeTagger 2.
</p>
<p>Nous utilisons une approximation rapide de l&#8217;algorithme LexRank (Erkan &amp; Radev, 2004) guid&#233;e par la requ&#234;te
afin d&#8217;attribuer des scores &#224; des phrases extraites du corpus. Ces phrases sont consid&#233;r&#233;es comme des paquets de
lemmes o&#249; seuls les adjectifs et les noms sont retenus. Un sous-graphe d&#8217;intersection est form&#233; avec les phrases
qui poss&#232;dent au moins un mot en commun avec requ&#234;te et avec celles qui poss&#232;dent au moins un mot en commun
avec ces premi&#232;res phrases. Les phrases sont les sommets du sous-graphe, et une ar&#234;te relie deux sommets si les
deux phrases ont au moins un mot en commun. La valeur d&#8217;une ar&#234;te reliant deux sommets est le nombre de
mots en commun entre les deux phrases repr&#233;sent&#233;es par ces sommets. Chaque sommet re&#231;oit un poids initial
correspondant au nombre de mots de la requ&#234;te pr&#233;sents dans la phrase, incr&#233;ment&#233; d&#8217;une unit&#233;. L&#8217;algorithme
LexRank attribue alors des scores &#224; chacune des phrases du sous-graphe. Les 1 500 phrases poss&#233;dant les scores
les plus importants sont conserv&#233;es.
</p>
<p>1. www.lemurproject.org
2. www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTagger.html</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AJOUT D&#8217;INFORMATIONS CONTEXTUELLES ISSUES DE WIKIP&#201;DIA POUR LA RECHERCHE DE PASSAGES
</p>
<p>2.2 Recherche d&#8217;information cibl&#233;e par extraction de phrases
</p>
<p>Les requ&#234;tes que nous utilisons proviennent de la collection fournie pour la t&#226;che Ad Hoc de l&#8217;&#233;dition 2010 de
la campagne INEX (Arvola et al., 2011). Plusieurs types d&#8217;informations sont disponibles pour chaque topic (voir
figure 1).
</p>
<p>Figure 1 : Un extrait de topic de la t&#226;che Ad Hoc d&#8217;INEX 2010.
&lt; t i t l e &gt;health risk coca leaf&lt; / t i t l e &gt;
&lt; p h r a s e t i t l e &gt;&quot; h e a l t h r i s k &quot; &quot; coca l e a f &quot; &quot; t r a d i t i o n a l coca l e a f consumpt ion &quot; &quot; h e a l t h s t u d y &quot;&lt; / p h r a s e t i t l e &gt;
</p>
<p>Le champ &lt;title&gt; contient une requ&#234;te utilisateur de quelques mots-cl&#233;s, telle qu&#8217;elle serait entr&#233;e dans un
moteur de recherche grand public. Le champ &lt;phrasetitle&gt; contient quant &#224; lui des syntagmes nominaux et
des mots-cl&#233;s explicitement ajout&#233;s par l&#8217;utilisateur pour pr&#233;ciser le contexte de sa recherche et ainsi aider le sys-
t&#232;me &#224; retrouver les passages susceptibles de l&#8217;int&#233;resser. Les exp&#233;rimentations men&#233;es par (Vechtomova, 2005)
montrent notamment qu&#8217;un ajout manuel, par l&#8217;utilisateur, de multi-mots li&#233;s au contexte apporte une am&#233;lioration
des r&#233;sultats.
</p>
<p>Recherche de mots au sein de s&#233;quences Dans notre premi&#232;re approche, les mots-cl&#233;s et syntagmes nominaux
suppl&#233;mentaires de la requ&#234;te sont ajout&#233;s au mod&#232;le de langage comme des s&#233;quences de mots autorisant jusqu&#8217;&#224;
4 insertions dans le cas de multi-mots. On voit par exemple dans l&#8217;extrait de passage ci-dessous que le syst&#232;me a
autoris&#233; l&#8217;insertion des deux mots &#171; or &#187; et &#171; cuca &#187; au sein du multi-mot &#171; coca leaf &#187;, tout en respectant l&#8217;ordre
d&#8217;apparition pr&#233;cis&#233; par l&#8217;utilisateur dans le champ &lt;phrasetitle&gt; :
</p>
<p>He inquires about the coca or cuca leaf from Peru ...
</p>
<p>Nous consid&#233;rons &#233;galement le cas de fen&#234;tres non ordonn&#233;es. Toujours pour le m&#234;me topic, notre syst&#232;me a
extrait le passage suivant en autorisant des insertions et l&#8217;inversion de l&#8217;ordre de mots :
</p>
<p>... purchasing , personnel , risk management , environmental health and safety ...
</p>
<p>Cette approche, qui ne consid&#232;re donc que la position relative des mots sans utilisation de pond&#233;ration, s&#8217;est
r&#233;v&#233;l&#233;e efficace lors de pr&#233;c&#233;dentes participations &#224; INEX (SanJuan &amp; Ibekwe-SanJuan, 2010).
</p>
<p>Pond&#233;ration des mots selon leur importance contextuelle La deuxi&#232;me approche que nous exp&#233;rimentons
consiste &#224; ajouter des mots ou des multi-mots pond&#233;r&#233;s selon leur importance informative par rapport au contexte
de la recherche. En effet, dans un document, certains mots sont plus importants que d&#8217;autres en terme de valeur
informative. Dans cette approche nous utilisons une mesure d&#8217;entropie, bas&#233;e notamment sur la fr&#233;quence des
mots dans le document, reconnue pour sa capacit&#233; de mise en &#233;vidence des mots ou des multi-mots les plus
informatifs. Ces mots sont directement extraits d&#8217;une page Wikipedia s&#233;lectionn&#233;e automatiquement &#224; partir de la
requ&#234;te utilisateur. C&#8217;est donc dans cette page que le contexte de recherche va pouvoir &#234;tre explor&#233; comme nous
le d&#233;taillons dans la section 3.
</p>
<p>Extraction de phrases La partie du syst&#232;me permettant de r&#233;cup&#233;rer les passages est commune &#224; ces diff&#233;rentes
approches. Nous proc&#233;dons d&#8217;abord &#224; une extraction des 50 documents les plus pertinents en utilisant une approche
par mod&#232;les de langue, o&#249; les probabilit&#233;s sont estim&#233;es par maximum de vraisemblance et liss&#233;es par une r&#232;gle
de Dirichlet. Ce lissage permet d&#8217;&#233;viter les probabilit&#233;s nulles ; il est particuli&#232;rement adapt&#233; aux requ&#234;tes form&#233;es
de mots-cl&#233;s (Zhai &amp; Lafferty, 2004). Le texte des documents extraits lors de cette premi&#232;re passe sont concat&#233;n&#233;s
et segment&#233;s en phrases. Les documents de la collection contiennent de nombreux tableaux et listes, mais ces
informations ne peuvent pas &#234;tre int&#233;gr&#233;es dans des passages, c&#8217;est pourquoi leur contenu est &#233;cart&#233;. Les phrases
sont ordonn&#233;es par score d&#233;croissant. Chaque phrase est alors consid&#233;r&#233;e comme une suite de mots autorisant
l&#8217;insertion toutes les insertions de caract&#232;res n&#8217;&#233;tant pas des lettres ni des chiffres. Tous les passages qui v&#233;rifient
ces conditions sont extraits des 50 documents pr&#233;c&#233;demment retenus. Les scores des phrases obtenus par la m&#233;-
thode d&#233;taill&#233;e dans la section 2.1 sont utilis&#233;s pour pond&#233;rer les passages. Ils sont enfin ordonn&#233;s par pond&#233;ration
d&#233;croissante. Voici un exemple de passage extrait par le syst&#232;me qui r&#233;pond au topic pr&#233;sent&#233; dans la figure 1 :
</p>
<p>Because cocaine is a stimulant , a user will often drink large amounts of alcohol during and after
usage or smoke cannabis to dull &quot;crash&quot; or &quot;come down&quot; effects and hasten slumber.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ROMAIN DEVEAUD, ERIC SANJUAN, PATRICE BELLOT
</p>
<p>3 Recherche automatique du contexte
</p>
<p>Dans les approches que nous avons pr&#233;sent&#233;es, nous enrichissons la recherche de passages pertinents avec des
&#233;l&#233;ments issus du contexte de la requ&#234;te. Nous avons vu que ce contexte pouvait notamment &#234;tre repr&#233;sent&#233; par
plusieurs termes ajout&#233;s manuellement par l&#8217;utilisateur. Plusieurs &#233;tudes ont explor&#233; l&#8217;utilisation de Wikipedia
comme collection externe pour l&#8217;enrichissement de requ&#234;tes (Koolen et al., 2009; Li et al., 2007; Milne et al.,
2007; Xu et al., 2009). Seulement, ces &#233;tudes ne rapportent des r&#233;sultats que pour la recherche de documents
entiers et non pour la recherche de passages.
</p>
<p>Nous avons mis en place une biblioth&#232;que logicielle 3 permettant d&#8217;associer une page Wikip&#233;dia &#224; une requ&#234;te.
Nous interrogeons le moteur de recherche de Wikip&#233;dia et nous s&#233;lectionnons le premier r&#233;sultat renvoy&#233; comme
la page contenant les informations contextuelles. Ceci nous permet notamment d&#8217;&#233;viter les pages de d&#233;sambi-
gu&#239;sation qui ne contiennent que des liens vers d&#8217;autres pages. Les interrogations sont effectu&#233;es sur la version
en ligne de l&#8217;encyclop&#233;die ce qui nous assure d&#8217;avoir les informations les plus &#224; jour. Par exemple, une requ&#234;te
&#171; bonaparte empereur &#187; nous permettra de r&#233;cup&#233;rer automatiquement la page Wikipedia de Napoleon Ier.
</p>
<p>Une fois la page r&#233;cup&#233;r&#233;e, le texte brut est extrait. Une mesure d&#8217;entropie est calcul&#233;e pour les tous les n-grammes
pr&#233;sents dans le texte. Soit une suite de mots S = (w1, ..., wn), la mesure d&#8217;entropie H est calcul&#233;e selon la
formule suivante :
</p>
<p>H(S) = &#8722;
n&#8721;
i=1
</p>
<p>PWiki(wi)&#215; log2(PWiki(wi))
</p>
<p>o&#249; les probabilit&#233;s d&#8217;apparition des mots sont calcul&#233;es sur l&#8217;ensemble des mots de la page Wikipedia associ&#233;e &#224;
la requ&#234;te. Cette mesure permet de refl&#233;ter l&#8217;importance relative de tous ces mots dans la page Wikipedia. En effet
dans le cas de la page de Napoleon Ier, le terme &#171; premier empereur &#187; a bien plus d&#8217;importance que &#171; nombreux
ouvrages &#187; dans le contexte d&#8217;une recherche sur Napoleon Bonaparte.
</p>
<p>Ces scores d&#8217;entropie nous permettent ainsi de pond&#233;rer diff&#233;rents mots selon leur importance informative dans le
contexte de la requ&#234;te initiale de l&#8217;utilisateur. L&#8217;utilisation d&#8217;une mesure d&#8217;entropie pour l&#8217;extraction et la pond&#233;-
ration de mots a d&#233;j&#224; prouv&#233; son efficacit&#233; dans le cadre d&#8217;une recherche de livres entiers (Deveaud et al., 2011),
c&#8217;est pourquoi nous l&#8217;int&#233;grons &#224; notre approche de recherche de passages d&#233;crite dans la section 2.2. Dans nos
exp&#233;rimentations, nous n&#8217;extrayons pour l&#8217;instant que des unigrammes des pages Wikipedia ; si on reprend la
notation ci-dessus, S = (w1).
</p>
<p>4 Exp&#233;rimentations et r&#233;sultats
</p>
<p>Nos exp&#233;rimentations sont men&#233;es avec les 107 topics de la t&#226;che Ad Hoc d&#8217;INEX 2010 et leurs jugements de per-
tinence. Nous comparons notre approche de r&#233;cup&#233;ration automatique du contexte avec les approches manuelles
que nous avons d&#233;crites dans la section 2.2 ainsi qu&#8217;avec les r&#233;sultats du syst&#232;me de l&#8217;Indian Statistical Institute
(ISI2010) qui a obtenu les meilleurs r&#233;sultats de recherche de passages restreints d&#8217;INEX 2010. Ce syst&#232;me utilise
des m&#233;thodes de classification directement sur les &#233;l&#233;ments XML pr&#233;sents dans les documents afin d&#8217;extraire des
&#233;l&#233;ments entiers, et non pas seulement des phrases. La baseline que nous proposons dans cet article utilise des
requ&#234;tes utilisateur uniquement compos&#233;es de mots-cl&#233;s (le champ &lt;title&gt; des topics).
</p>
<p>Les r&#233;sultats obtenus pour l&#8217;extraction de passages de 1 000 caract&#232;res au maximum sont pr&#233;sent&#233;s dans le ta-
bleau 1. Nous pr&#233;sentons &#233;galement dans le tableau 2 les r&#233;sultats obtenus dans le cas d&#8217;une recherche de passages
o&#249; le nombre de caract&#232;res n&#8217;est pas limit&#233;. Lors d&#8217;une recherche de passages, les utilisateurs vont &#234;tre attentifs
aux tout premiers r&#233;sultats renvoy&#233;s par le syst&#232;me, c&#8217;est pourquoi nous privil&#233;gions une mesure &#224; 1% de rappel.
</p>
<p>L&#8217;approche d&#8217;ajout automatique d&#8217;informations contextuelles est celle qui fonctionne le mieux pour les deux
types d&#8217;extraction de passages. L&#8217;am&#233;lioration observ&#233;e pour la recherche de passages restreints par rapport au
syst&#232;me ISI2010 est de l&#8217;ordre de 5%. On observe dans le tableau 2 que les pr&#233;cisions contextuelles apport&#233;es
par les utilisateurs am&#233;liorent les performances de fa&#231;on significative par rapport &#224; la baseline, ce qui confirme
les constatations de (Vechtomova, 2005). L&#8217;utilisation d&#8217;une fen&#234;tre ordonn&#233;e pour la recherche de multi-termes
semble mieux marcher dans le cas o&#249; les passages sont limit&#233;s &#224; 1000 caract&#232;res. En effet, l&#8217;ordre des mots d&#233;fini
</p>
<p>3. mirimiri.org</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AJOUT D&#8217;INFORMATIONS CONTEXTUELLES ISSUES DE WIKIP&#201;DIA POUR LA RECHERCHE DE PASSAGES
</p>
<p>TABLE 1: R&#233;sultat de recherche de passages restreints &#224; 1 000 caract&#232;res, en terme de pr&#233;cision interpol&#233;e &#224;
diff&#233;rents niveaux de rappel (iP).
</p>
<p>Approche iP[0.00] iP[0.01] iP[0.05] iP[0.10]
</p>
<p>contexte automatique 0, 565 0, 167 0, 080 0, 020
ISI2010 &#8722; 0, 153 0, 019 0, 000
contexte utilisateur / fen&#234;tre ordonn&#233;e 0, 492 0, 148 0, 000 0, 000
contexte utilisateur / fen&#234;tre non ordonn&#233;e 0, 529 0, 147 0, 000 0, 000
baseline 0, 486 0, 141 0, 000 0, 000
</p>
<p>TABLE 2: R&#233;sultat de recherche de passages, en terme de pr&#233;cision interpol&#233;e &#224; diff&#233;rents niveaux de rappel (iP).
T-test unilat&#233;ral appari&#233; sur la significativit&#233; de l&#8217;am&#233;lioration des diff&#233;rentes m&#233;thodes vis-&#224;-vis de la baseline
sur les topics avec iP[0.00] &lt; 1 (&#8727; : p &lt; 0,1 ; &#8727;&#8727; : p &lt; 0,05) .
</p>
<p>Approche iP[0.00] iP[0.01] iP[0.05] iP[0.10]
</p>
<p>contexte automatique 0, 647&#8727;&#8727; 0, 565&#8727; 0, 453&#8727;&#8727; 0, 358&#8727;&#8727;
</p>
<p>contexte utilisateur / fen&#234;tre non ordonn&#233;e 0, 634&#8727;&#8727; 0, 533&#8727;&#8727; 0, 385&#8727;&#8727; 0, 279&#8727;
</p>
<p>contexte utilisateur / fen&#234;tre ordonn&#233;e 0, 613&#8727; 0, 522&#8727;&#8727; 0, 385&#8727;&#8727; 0, 288&#8727;
</p>
<p>baseline 0,585 0,504 0,359 0,265
</p>
<p>par l&#8217;utilisateur prend plus d&#8217;importance dans le cas o&#249; le syst&#232;me doit chercher des passages courts. A contrario,
le syst&#232;me est plus performant avec des fen&#234;tres non ordonn&#233;es lorsqu&#8217;il n&#8217;y a pas de limitation dans la taille des
passages.
</p>
<p>De son c&#244;t&#233;, l&#8217;approche par d&#233;tection automatique du contexte et extraction des mots informatifs par mesure d&#8217;en-
tropie obtient les meilleurs r&#233;sultats pour les mesures pr&#233;sent&#233;es. Ces am&#233;liorations peuvent &#234;tres expliqu&#233;es par
le fait que le vocabulaire introduit par les utilisateurs est assez redondant, ce qui handicape l&#8217;extraction de nou-
velles phrases. Inversement, les mots extraits des pages Wikipedia associ&#233;s aux requ&#234;tes apportent du vocabulaire
nouveau. C&#8217;est cette extension du vocabulaire &#224; des mots rares et sp&#233;cifiques permet au syst&#232;me d&#8217;extraire des
phrases pertinentes qui n&#8217;auraient pas &#233;t&#233; pr&#233;sentes autrement. En effet le mot &#171; cocaine &#187; n&#8217;&#233;tait pas mentionn&#233;
dans le topic pr&#233;sent&#233; dans la section 2.2, et il a &#233;t&#233; d&#233;sign&#233; par le syst&#232;me comme un mot important compte tenu
du contexte de la recherche, ce qui a permis de r&#233;cup&#233;rer le passage suivant :
</p>
<p>The production , the distribution and the sale of cocaine products is restricted (and illegal in most
contexts) in most countries.
</p>
<p>Parfois, certains mots extraits des pages Wikipedia ne sont pas importants dans le contexte de la recherche de
l&#8217;utilisateur. La pond&#233;ration apport&#233;e par la mesure d&#8217;entropie permet alors de refl&#233;ter leur importance contextuelle
et de limiter leur effet n&#233;gatif.
</p>
<p>5 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; dans cet article un syst&#232;me de recherche de passages restreints. Cette approche consiste &#224;
former des passages pertinents &#224; partir de phrases extraites des documents, et &#224; les renvoyer &#224; l&#8217;utilisateur. Nous
avons pr&#233;sent&#233; le syst&#232;me d&#8217;extraction de phrases que nous utilisons qui sert &#233;galement de syst&#232;me &#233;talon pour la
t&#226;che Question-R&#233;ponse de la campagne d&#8217;&#233;valuation INEX.
</p>
<p>Nous avons propos&#233; une m&#233;thode automatique d&#8217;enrichissement de requ&#234;tes avec des mots fortement li&#233;s au
contexte de la recherche. Ces mots sont extraits automatiquement des pages Wikipedia associ&#233;es aux requ&#234;tes et
pond&#233;r&#233;s &#224; l&#8217;aide d&#8217;une mesure d&#8217;entropie. Nous utilisons cette mesure pour pond&#233;rer les mots extraits afin de
refl&#233;ter leur importance contextuelle au sein de la page Wikipedia.
</p>
<p>Ces recherches ont b&#233;n&#233;fici&#233; du soutien financier de l&#8217;Agence Nationale de la Recherche (ANR 2010 CORD 001 02) en faveur du projet
CAAS.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ROMAIN DEVEAUD, ERIC SANJUAN, PATRICE BELLOT
</p>
<p>Nous avons compar&#233; cette m&#233;thode automatique &#224; une m&#233;thode manuelle o&#249; le contexte est pr&#233;cis&#233; par l&#8217;utilisateur
au moment de la requ&#234;te. Nous avons &#233;galement report&#233; les scores obtenus par le meilleur syst&#232;me d&#8217;INEX 2010.
L&#8217;approche automatique que nous proposons est la m&#233;thode qui obtient les meilleurs r&#233;sultats pour les diff&#233;rentes
mesures propos&#233;es, pour des passages libres ou restreints &#224; 1 000 caract&#232;res.
</p>
<p>R&#233;f&#233;rences
ARVOLA P., GEVA S., KAMPS J., SCHENKEL R., TROTMAN A. &amp; VAINIO J. (2011). Overview of the inex
2010 ad hoc track. In S. GEVA, J. KAMPS, R. SCHENKEL &amp; A. TROTMAN, Eds., Comparative Evaluation of
Focused Retrieval, Lecture Notes in Computer Science. Springer Berlin / Heidelberg.
DANG H. T. (2005). Overview of DUC 2005. In Proceedings of the 2005 Document Understanding Workshop.
DANG H. T. &amp; OWCZARZAK K. (2008). Overview of the tac 2008 update summarization task. In Text Analysis
Conference (TAC).
DEVEAUD R., BOUDIN F. &amp; BELLOT P. (2011). Lia at inex 2010 book track. In S. GEVA, J. KAMPS, R.
SCHENKEL &amp; A. TROTMAN, Eds., Comparative Evaluation of Focused Retrieval, Lecture Notes in Computer
Science : Springer Berlin / Heidelberg.
ERKAN G. &amp; RADEV D. R. (2004). Lexrank : graph-based lexical centrality as salience in text summarization.
J. Artif. Int. Res., 22, 457&#8211;479.
HARMAN D. &amp; OVER P. (2002). The duc summarization evaluations. In Proceedings of the second international
conference on Human Language Technology Research, HLT &#8217;02, p. 44&#8211;51, San Francisco, CA, USA : Morgan
Kaufmann Publishers Inc.
KAMPS J., PEHCEVSKI J., KAZAI G., LALMAS M. &amp; ROBERTSON S. (2008). Inex 2007 evaluation measures.
In N. FUHR, J. KAMPS, M. LALMAS &amp; A. TROTMAN, Eds., Focused Access to XML Documents, volume 4862
of Lecture Notes in Computer Science, p. 24&#8211;33. Springer Berlin / Heidelberg.
KOOLEN M., KAZAI G. &amp; CRASWELL N. (2009). Wikipedia pages as entry points for book search. In Pro-
ceedings of the Second ACM International Conference on Web Search and Data Mining, WSDM &#8217;09, p. 44&#8211;53,
New York, NY, USA : ACM.
LI Y., LUK W. P. R., HO K. S. E. &amp; CHUNG F. L. K. (2007). Improving weak ad-hoc queries using wikipedia
as external corpus. In Proceedings of the 30th annual international ACM SIGIR conference on Research and
development in information retrieval, SIGIR &#8217;07, p. 797&#8211;798, New York, NY, USA : ACM.
METZLER D. &amp; CROFT W. B. (2004). Combining the language model and inference network approaches to
retrieval. Inf. Process. Manage., 40, 735&#8211;750.
MILNE D. N., WITTEN I. H. &amp; NICHOLS D. M. (2007). A knowledge-based search engine powered by wikipe-
dia. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,
CIKM &#8217;07, p. 445&#8211;454, New York, NY, USA : ACM.
SANJUAN E., BELLOT P., MORICEAU V. &amp; TANNIER X. (2011). Overview of the 2010 qa track. In S. GEVA,
J. KAMPS, R. SCHENKEL &amp; A. TROTMAN, Eds., Comparative Evaluation of Focused Retrieval, Lecture Notes
in Computer Science : Springer Berlin / Heidelberg.
SANJUAN E. &amp; IBEKWE-SANJUAN F. (2010). Multi word term queries for focused information retrieval. In
A. GELBUKH, Ed., Computational Linguistics and Intelligent Text Processing, volume 6008 of Lecture Notes in
Computer Science, p. 590&#8211;601. Springer Berlin / Heidelberg.
TROTMAN A., JIA X.-F. &amp; GEVA S. (2010). Fast and effective focused retrieval. In S. GEVA, J. KAMPS &amp;
A. TROTMAN, Eds., Focused Retrieval and Evaluation, volume 6203 of Lecture Notes in Computer Science, p.
229&#8211;241. Springer Berlin / Heidelberg.
VECHTOMOVA O. (2005). The role of multi-word units in interactive information retrieval. In D. LOSADA &amp;
J. FERN&#193;NDEZ-LUNA, Eds., Advances in Information Retrieval, volume 3408 of Lecture Notes in Computer
Science, p. 403&#8211;420. Springer Berlin / Heidelberg.
XU Y., JONES G. J. &amp; WANG B. (2009). Query dependent pseudo-relevance feedback based on wikipedia.
In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information
retrieval, SIGIR &#8217;09, p. 59&#8211;66, New York, NY, USA : ACM.
ZHAI C. &amp; LAFFERTY J. (2004). A study of smoothing methods for language models applied to information
retrieval. ACM Trans. Inf. Syst., 22, 179&#8211;214.</p>

</div></div>
</body></html>