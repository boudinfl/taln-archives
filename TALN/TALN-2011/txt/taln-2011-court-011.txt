TALN 2011, Montpellier, 27juin — l"'ju1'11et 2011

Ajout d’informations contextuelles pour la recherche de passages au sein
de Wikipédia

Romain Deveaud Eric SanJuan Patrice Bellot
LIA - Université d’Avignon
339, chemin des Meinajariés Agroparc BP 91228
84 911 Avignon Cedex 9

{romain.deveaud,eric.sanjuan,patrice.bellot}@univ—avignon.fr

Résumé. La recherche de passages consiste a extraire uniquement des passages pertinents par rapport a une
requete utilisateur plut6t qu’un ensemble de documents entiers. Cette recuperation de passages est souvent handi-
capée par le manque d’informations complémentaires concemant le contexte de la recherche initiée par l’utilisa—
teur. Des études montrent que 1’ aj out d’ informations contextuelles par l’utilisateur peut améliorer les performances
des systemes de recherche de passages. Nous conﬁrmons ces observations dans cet article, et nous introduisons
également une méthode d’enrichissement de la requete a partir d’informations contextuelles issues de documents
encyclopédiques. Nous menons des expérimentations en utilisant la collection et les méthodes d’évaluation pro-
posées par la carnpagne INEX. Les résultats obtenus montrent que l’ajout d’informations contextuelles permet
d’ ameliorer signiﬁcativement les performances de notre systeme de recherche de passages. Nous observons ega-
lement que notre approche automatique obtient les meilleurs résultats parrni les différentes approches que nous
évaluons.

Abstract. Traditional Information Retrieval aims to present whole documents that are relevant to a user
request. However, there is sometimes only one sentence that is relevant in the document. The purpose of Focused
Information Retrieval is to ﬁnd and extract relevant passages instead of entire documents. This retrieval task often
lacks of complement concerning the context of the information need of the user. Studies show that the perfor-
mance of focused retrieval systems are improved when user manually add contextual information. In this paper
we conﬁrm these observation, and we also introduce a query expansion approach using contextual information
taken from encyclopedic documents. We use the INEX workshop collection and evaluation framework in our ex-
periments. Results show that adding contextual information signiﬁcantly improves the performance of our focused
retrieval system. We also see that our automatic approach obtains the best results among the different approach
we evaluate.

M0tS-CléS 3 Recherche de passages, enrichissement de requetes, contexte, Wikipedia, INEX, entropie.

Keywords: Focused retrieval, query expansion, context, Wikipedia, INEX, entropy.

ROMAIN DEVEAUD, ERIC SANJUAN, PATRICE BELLOT

1 Introduction

Les approches traditionnelles de Recherche d’ Information (RI) cherchent a retrouver le ou les documents les plus
pertinents par rapport a une requete. Parfois, seule une petite partie d’un document est tres pertinente mais celui—ci
est mal classé et l’information n’est pas presentée a l’utilisateur. La recherche de passages consiste a rechercher
uniquement ces passages pertinents, en laissant le soin au systeme de determiner le meilleur niveau de granularite
des documents tout en évitant le recouvrement er1tre differents passages.

La recherche de passages restreints, ou Focused Information Retrieval (Trotman et al., 2010; Arvola et al., 2011),
aj oute une contrainte qui consiste a limiter la taille totale du texte presente a l’utilisateur. Cette taille est ﬁxée par
des contraintes techniques telles que la taille d’un écran d’un telephone portable. Les passages extraits et présentes
a l’utilisateur doivent également etre lisibles et compréhensibles (Harman & Over, 2002). Cette tache s’approche
ainsi de celle du resume automatique puisqu’il s’agit de recuperer les passages les plus importants dans un corpus,
plutot que de recuperer l’ensemble des passages pertinents (Dang, 2005; Dang & Owczarzak, 2008; Harman &
Over, 2002). Cependant, a la difference des resumes automatiques, il ne s’agit pas de generer un resume mais
bien d’extraire des passages des documents, ces passages pouvant etre utilises dans un processus de recherche
d’information interactive. La campagne d’évaluation INEX a eté créée dans le but de developper la recherche
de passages et d’éléments dans des documents XML. Dans ce contexte, un cadre d’évaluation de recherche de
passages est utilise depuis l’apparition de la tache Focused de la piste Ad Hoc (Kamps et al., 2008).

C’est lors de l’édition 2010 que la campagne INEX a vu apparaitre une tache de recherche de passages restreints.
Un corpus de requetes a eté constitue en reprenant la methodologie des precedentes campagnes, en retenant de
fagon prioritaire les requetes dont les elements de réponse étaient répartis dans plusieurs pages Wikipedia. Par
ailleurs, chaque requete constituée d’un titre tres court etait completee par une liste de termes (mots-cles ou
syntagmes nominaux) précisant le contexte thématique de la recherche.

Au moyen d’un systeme de recherche de passages, nous proposons de montrer que non seulement ce contexte
améliore les résultats de la recherche mais aussi qu’il est possible d’ en retrouver une variante automatiquement
qui aboutit a des hausses de performance comparables. Cela, dans le cadre d’ un processus de recherche encyclo-
pédique a partir de requetes complexes, constitue une avancee notable a mettre en regard avec les résultats souvent
décevants obtenus par les méthodes automatiques d’enrichissement.

2 Méthodologie

2.1 Extraction de phrases et attribution de scores

Dans toutes nos expérimentations nous utilisons le systeme que nous avons propose comme étalon a la tache de
Question—Réponse d’INEX (SanJuan et al., 2011). Ce systeme utilise Indril pour l’indexation et l’extraction de
documents ainsi qu’une approche par modeles de langue pour la RI (Metzler & Croft, 2004). Lors de l’indexation,
les mots ne sont pas tronqués de maniere a permettre des recherches exactes, et leurs positions dans les docu-
ments sont mémorisées. Ce systeme integre egalement un etiqueteur morpho—syntaxique incluant l’étiquetage de
la ponctuation : TreeTagger 2.

Nous utilisons une approximation rapide de l’algorith1ne LexRank (Erkan & Radev, 2004) guidée par la requete
aﬁn d’attribuer des scores a des phrases extraites du corpus. Ces phrases sont considérées comme des paquets de
lemmes ou seuls les adjectifs et les noms sont retenus. Un sous—graphe d’intersection est formé avec les phrases
qui possedent au moins un mot en commun avec requete et avec celles qui possedent au moins un mot en commun
avec ces premieres phrases. Les phrases sont les sommets du sous—graphe, et une arete relie deux sommets si les
deux phrases ont au moins un mot en commun. La valeur d’une arete reliant deux sommets est le nombre de
mots en commun entre les deux phrases représentées par ces sommets. Chaque sommet regoit un poids initial
correspondant au nombre de mots de la requete presents dans la phrase, incrémenté d’une unite. L’ algorithme
LexRank attribue alors des scores a chacune des phrases du sous—graphe. Les 1 500 phrases possédant les scores
les plus importants sont conservees.

1. www . lemurproject . org
2. www . ims . uni—stuttgart . de/projekte/corplex/TreeTagger/DecisionTreeTagger . html

AJOUT D’INFORMATIONS CONTEXTUELLES ISSUES DE WIKIPEDIA POUR LA RECHERCHE DE PASSAGES

2.2 Recherche d’information ciblée par extraction de phrases
Les requetes que nous utilisons proviennent de la collection foumie pour la tache Ad Hoc de l’edition 2010 de

la ca1npagneINEX (Arvola et al., 2011). Plusieurs types d’informations sont disponibles pour chaque topic (voir
ﬁgure 1).

Figure 1 : Un extrait de topic de la tache Ad Hoc d’INEX 2010.

<tille>health risk coca 1eaf</tit1e>
<phraselille>"health risk" "coca leaf" "traditional coca leaf consumption" "health study"</phraselille>

Le champ <t it le> contient une requete utilisateur de quelques mots—cles, telle qu’elle serait entree dans un
moteur de recherche grand public. Le champ <phraset it le> contient quant a lui des syntagmes nominaux et
des mots—cles explicitement aj outes par l’utilisateur pour preciser le contexte de sa recherche et ainsi aider le sys-
teme a retrouver les passages susceptibles de l’interesser. Les experimentations menees par (Vechtomova, 2005)
montrentnota1mnentqu’un aj out manuel, par l’utilisateur, de multi—mots lies au contexte apporte une amelioration
des resultats.

Recherche de mots au sein de sequences Dans notre premiere approche, les mots—cles et syntagmes nominaux
supplementaires de la requete sont aj outes au modele de langage comme des sequences de mots autorisant jusqu’a
4 insertions dans le cas de multi—mots. On voit par exemple dans l’extrait de passage ci—dessous que le systeme a
autorise l’insertion des deux mots << or » et << cuca » au sein du multi—mot << coca leaf», tout en respectant l’ordre
d’ apparition precise par l’utilisateur dans le champ <phrasetitle> :

He inquires about the coca or cuca leaf from Peru 

Nous considerons egalement le cas de fenetres non ordonnees. Toujours pour le meme topic, notre systeme a
extrait le passage suivant en autorisant des insertions et l’inversion de l’ordre de mots :

 purchasing , personnel, risk management, environmental health and safety 

Cette approche, qui ne considere donc que la position relative des mots sans utilisation de ponderation, s’est
revelee efﬁcace lors de precedentes participations a INEX (SanJuan & Ibekwe-SanJuan, 2010).

Ponderation des mots selon leur importance contextuelle La deuxieme approche que nous experimentons
consiste a ajouter des mots ou des multi—mots ponderes selon leur importance informative par rapport au contexte
de la recherche. En effet, dans un document, certains mots sont plus importants que d’autres en terme de Valeur
informative. Dans cette approche nous utilisons une mesure d’entropie, basee notamment sur la frequence des
mots dans le document, reconnue pour sa capacite de mise en evidence des mots ou des multi—mots les plus
informatifs. Ces mots sont directement extraits d’une page Wikipedia selectionnee automatiquement a partir de la
requete utilisateur. C’est donc dans cette page que le contexte de recherche va pouvoir etre explore comme nous
le detaillons dans la section 3.

Extraction de phrases La partie du systeme permettant de recuperer les passages est commune a ces differentes
approches. Nous procedons d’ abord a une extraction des 5 0 documents les plus pertinents en utilisant une approche
par modeles de langue, ou les probabilites sont estimees par maximum de vraisemblance et lissees par une regle
de Dirichlet. Ce lissage permet d’eviter les probabilites nulles ; il est particulierement adapte aux requetes formees
de mots—cles (Zhai & Lafferty, 2004). Le texte des documents extraits lors de cette premiere passe sont concatenes
et segmentes en phrases. Les documents de la collection contiennent de nombreux tableaux et listes, mais ces
informations ne peuvent pas etre integrees dans des passages, c’est pourquoi leur contenu est ecarte. Les phrases
sont ordonnees par score decroissant. Chaque phrase est alors consideree comme une suite de mots autorisant
l’insertion toutes les insertions de caracteres n’etant pas des lettres ni des chiffres. Tous les passages qui veriﬁent
ces conditions sont extraits des 50 documents precedemment retenus. Les scores des phrases obtenus par la me-
thode detaillee dans la section 2.1 sont utilises pour ponderer les passages. Ils sont enﬁn ordonnes par ponderation
decroissante. Voici un exemple de passage extrait par le systeme qui repond au topic presente dans la ﬁgure 1 :

Because cocaine is a stimulant , a user will often drink large amounts of alcohol during and after
usage or smoke cannabis to dull "crash" or "come down" eﬂects and hasten slumber

ROMAIN DEVEAUD, ERIC SANJUAN, PATRICE BELLOT

3 Recherche automatique du contexte

Dans les approches que nous avons présentées, nous enrichissons la recherche de passages pertinents avec des
elements issus du contexte de la requete. Nous avons vu que ce contexte pouvait notamment etre représenté par
plusieurs termes ajoutés manuellement par l’utilisateur. Plusieurs études ont explore l’utilisation de Wikipedia
comme collection exteme pour l’enrichissement de requetes (Koolen et al., 2009; Li et al., 2007; Milne et al.,
2007; Xu et al., 2009). Seulement, ces études ne rapportent des résultats que pour la recherche de documents
entiers et non pour la recherche de passages.

Nous avons mis en place une bibliotheque logicielle3 permettant d’associer une page Wikipedia a une requete.
Nous interrogeons le moteur de recherche de Wikipedia et nous sélectionnons le premier résultat renvoyé comme
la page contenant les informations contextuelles. Ceci nous permet notamment d’éviter les pages de désambi—
gu'1'sation qui ne contiennent que des liens vers d’autres pages. Les interrogations sont effectuées sur la version
en ligne de l’encyclopédie ce qui nous assure d’avoir les informations les plus a jour. Par exemple, une requete
<< bonaparte empereur » nous permettra de récupérer automatiquement la page Wikipedia de Napoleon I”.

Une fois la page récupéree, le texte brut est extrait. Une mesure d’ entropie est calculée pour les tous les n-grammes
presents dans le texte. Soit une suite de mots S’ = (w1,...,wn), la mesure d’entropie H est calculée selon la
formule suivante :

W;
H09) = — ZPW7lk7l(w7l) >< 10g2(PWiI<:7l(wi))
i=1
ou les probabilités d’apparition des mots sont calculées sur l’ensemble des mots de la page Wikipedia associée a
la requete. Cette mesure permet de reﬂéter l’importance relative de tous ces mots dans la page Wikipedia. En effet
dans le cas de la page de Napoleon 1”, le terme << premier empereur » a bien plus d’importance que << nombreux
ouvrages » dans le contexte d’une recherche sur Napoleon Bonaparte.

Ces scores d’entropie nous permettent ainsi de pondérer djfférents mots selon leur importance informative dans le
contexte de la requete initiale de l’utilisateur. L’utilisation d’une mesure d’entropie pour l’extraction et la ponde-
ration de mots a déja prouve son efﬁcacite dans le cadre d’une recherche de livres entiers (Deveaud et al., 2011),
c’est pourquoi nous l’intégrons a notre approche de recherche de passages décrite dans la section 2.2. Dans nos
expérimentations, nous n’extrayons pour l’instant que des unigrammes des pages Wikipedia; si on reprend la
notation ci-dessus, S’ = (wl).

4 Expérimentations et résultats

Nos expérimentations sont menées avec les 107 topics de la tache Ad Hoc d’INEX 2010 et leurs jugements de per-
tinence. Nous comparons notre approche de recuperation automatique du contexte avec les approches manuelles
que nous avons décrites dans la section 2.2 ainsi qu’avec les résultats du systeme de l’Indian Statistical Institute
(ISI2010) qui a obtenu les meilleurs résultats de recherche de passages restreints d’lNEX 2010. Ce systeme utilise
des méthodes de classiﬁcation directement sur les elements XML presents dans les documents aﬁn d’extraire des
elements entiers, et non pas seulement des phrases. La baseline que nous proposons dans cet article utilise des
requetes utilisateur uniquement composées de mots—clés (le champ <t it le> des topics).

Les résultats obtenus pour l’extraction de passages de 1 000 caracteres au maximum sont présentés dans le ta-
bleau 1. Nous présentons également dans le tableau 2 les résultats obtenus dans le cas d’une recherche de passages
ou le nombre de caracteres n’est pas limité. Lors d’une recherche de passages, les utilisateurs vont etre attentifs
aux tout premiers résultats renvoyés par le systeme, c’est pourquoi nous privilégions une mesure a 1% de rappel.

L’ approche d’ajout automatique d’informations contextuelles est celle qui fonctionne le mieux pour les deux
types d’ extraction de passages. L’ amelioration observée pour la recherche de passages restreints par rapport au
systeme ISI2010 est de l’ordre de 5%. On observe dans le tableau 2 que les précisions contextuelles apportees
par les utilisateurs améliorent les performances de fagon signiﬁcative par rapport a la baseline, ce qui conﬁrme
les constatations de (Vechtomova, 2005). L’utilisation d’une fenetre ordonnée pour la recherche de multi-termes
semble mieux marcher dans le cas ou les passages sont limités a 1000 caracteres. En effet, l’ordre des mots déﬁni

3. mirimiri . org

AJOUT D’INFORMATIONS CONTEXTUELLES ISSUES DE WIKIPEDIA POUR LA RECHERCHE DE PASSAGES

TABLE 1: Resultat de recherche de passages restreints a 1 000 caracteres, en terme de precision interpolée a
différents niveaux de rappel (iP).

Approche iP[0.00] iP[0.01] iP[0.05] iP[0.10]
contexte auton1atique 0, 565 0, 167 0,080 0,020
ISI2010 — 0, 153 0,019 0,000
contexte utilisateur / fenétre ordonnée 0, 492 0, 148 0, 000 0, 000
contexte utilisateur / fenétre non ordonnée 0, 529 0, 147 0, 000 0, 000
baseline 0, 486 0, 141 0, 000 0, 000

TABLE 2: Résultat de recherche de passages, en tenne de precision interpolee a différents niveaux de rappel (iP).
T—test unilateral apparié sur la signiﬁcativite de l’amelioration des differentes methodes Vis-a—Vis de la baseline
sur les topics avec iP[0.00] < 1 (* : p < 0,1 ; ** : p < 0,05) .

Approche iP[0.00] iP[0.01] iP[0.05] iP[0.10]
contexte auton1atique 0, 647** 0, 565* 0, 453** 0, 358**
contexte utilisateurl fenétre non ordonnée 0, 634** 0, 533“ 0, 385** 0, 279*
contexte utilisateurl fenétre ordonnée 0, 613* 0, 522“ 0, 385** 0, 288*
baseline 0,585 0,504 0,359 0,265

par l’utilisateur prend plus d’importance dans le cas ou le systeme doit chercher des passages courts. A contrario,
le systeme est plus performant avec des fenetres non ordonnées lorsqu’il n’y a pas delimitation dans la taille des
passages.

De son cote, l’approche par detection automatique du contexte et extraction des mots informatifs par mesure d’en-
tropie obtient les meilleurs résultats pour les mesures presentées. Ces ameliorations peuvent etres expliquees par
le fait que le Vocabulaire introduit par les utilisateurs est assez redondant, ce qui handicape l’extraction de nou-
Velles phrases. Inversement, les mots extraits des pages Wikipedia associés aux requetes apportent du Vocabulaire
nouveau. C’est cette extension du Vocabulaire a des mots rares et spéciﬁques pennet au systeme d’extraire des
phrases pertinentes qui n’auraient pas ete présentes autrement. En effet le mot << cocaine » n’etait pas mentionné
dans le topic presente dans la section 2.2, et il a eté désigné par le systeme comme un mot important compte tenu
du contexte de la recherche, ce qui a permis de récuperer le passage suivant :

The production , the distribution and the sale of cocaine products is restricted (and illegal in most
contexts) in most countries.

Parfois, certains mots extraits des pages Wikipedia ne sont pas importants dans le contexte de la recherche de
l’utilisateur. La pondération apportée par la mesure d’ entropie permet alors de reﬂéter leur importance contextuelle
et de limiter leur effet négatif.

5 Conclusion

Nous avons présenté dans cet article un systeme de recherche de passages restreints. Cette approche consiste a
former des passages pertinents a partir de phrases extraites des documents, et ales renvoyer a l’utilisateur. Nous
avons presente le systeme d’extraction de phrases que nous utilisons qui sert egalement de systeme étalon pour la
tache Question-Réponse de la campagne d’eValuation INEX.

Nous avons propose une methode automatique d’enrichissement de requetes avec des mots fortement lies au
contexte de la recherche. Ces mots sont extraits automatiquement des pages Wikipedia associées aux requetes et
pondéres a l’aide d’une mesure d’entropie. Nous utilisons cette mesure pour pondérer les mots extraits aﬁn de
reﬂéter leur importance contextuelle au sein de la page Wikipedia.

Ces recherches ont bénéﬁcié du soutien ﬁnancier de l’Agence Nationale de la Recherche (ANR 2010 CORD 001 02) en faveur du projet
CAAS.

ROMAIN DEVEAUD, ERIC SANJUAN, PATRICE BELLOT

Nous avons compare cette méthode automatique a une methode manuelle ou le contexte est precise par l’uti1isateur
au moment de la requete. Nous avons également reporte les scores obtenus par le meilleur systeme d’INEX 2010.
L’ approche automatique que nous proposons est la méthode qui obtient les meilleurs resultats pour les differentes
mesures proposees, pour des passages libres ou restreints a 1 000 caracteres.

Références

ARVOLA P., GEVA S., KAMPS J ., SCHENKEL R., TROTMAN A. & VAINIO J . (2011). Overview of the inex
2010 ad hoc track. In S. GEVA, J . KAMPS, R. SCHENKEL & A. TROTMAN, Eds., Comparative Evaluation of
Focused Retrieval, Lecture Notes in Computer Science. Springer Berlin / Heidelberg.

DANG H. T. (2005). Overview of DUC 2005. In Proceedings of the 2005 Document Understanding Workshop.

DANG H. T. & OWCZARZAK K. (2008). Overview of the tac 2008 update summarization task. In Text Analysis
Conference (TAC).

DEVEAUD R., BOUDIN F. & BELLOT P. (2011). Lia at inex 2010 book track. In S. GEVA, J . KAMPS, R.

SCHENKEL & A. TROTMAN, Eds., Comparative Evaluation of Focused Retrieval, Lecture Notes in Computer
Science : Springer Berlin / Heidelberg.

ERKAN G. & RADEV D. R. (2004). Lexrank : graph—based lexical centrality as salience in text sunnnarization.
J. Artif. Int. Res., 22, 457-479.

HARMAN D. & OVER P. (2002). The duc summarization evaluations. In Proceedings of the second international
conference on Human Language Technology Research, HLT ’02, p. 44-51, San Francisco, CA, USA : Morgan
Kaufmann Publishers Inc.

KAMPS J ., PEHCEVSKI J ., KAZAI G., LALMAS M. & ROBERTSON S. (2008). Inex 2007 evaluation measures.
In N. FUHR, J . KAMPS, M. LALMAS & A. TROTMAN, Eds., Focused Access to XML Documents, volume 4862
of lecture Notes in Computer Science, p. 24-33. Springer Berlin / Heidelberg.

KOOLEN M., KAZAI G. & CRASWELL N. (2009). Wikipedia pages as entry points for book search. In Pro-
ceedings of the Second ACM International Conference on Web Search and Data Mining, WSDM ’09, p. 44-53,
New York, NY, USA : ACM.

LI Y., LUK W. P. R., HO K. S. E. & CHUNG F. L. K. (2007). Improving weak ad—hoc queries using wikipedia
as external corpus. In Proceedings of the 30th annual international ACM SIGIR conference on Research and
development in information retrieval, SIGIR ’07, p. 797-798, New York, NY, USA : ACM.

METZLER D. & CROFT W. B. (2004). Combining the language model and inference network approaches to
retrieval. Inf Process. Manage., 40, 735-750.

MILNE D. N., WITTEN I. H. & NICHOLS D. M. (2007). A knowledge—based search engine powered by wikipe-
dia. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,
CIKM ’07, p. 445-454, New York, NY, USA : ACM.

SANJUAN E., BELLOT P., MORICEAU V. & TANNIER X. (2011). Overview of the 2010 qa track. In S. GEVA,
J . KAMPS, R. SCHENKEL & A. TROTMAN, Eds., Comparative Evaluation of Focused Retrieval, Lecture Notes
in Computer Science : Springer Berlin / Heidelberg.

SANJUAN E. & IBEKWE—SANJUAN F. (2010). Multi word term queries for focused information retrieval. In
A. GELBUKH, Ed., Computational Linguistics and Intelligent Text Processing, volume 6008 of Lecture Notes in
Computer Science, p. 590-601. Springer Berlin / Heidelberg.

TROTMAN A., J IA X.—F. & GEVA S. (2010). Fast and effective focused retrieval. In S. GEVA, J . KAMPS &
A. TROTMAN, Eds., Focused Retrieval and Evaluation, volume 6203 of lecture Notes in Computer Science, p.
229-241. Springer Berlin / Heidelberg.

VECHTOMOVA O. (2005). The role of multi—word units in interactive information retrieval. In D. LOSADA &
J . FERNANDEZ-LUNA, Eds., Advances in Information Retrieval, volume 3408 of lecture Notes in Computer
Science, p. 403-420. Springer Berlin / Heidelberg.

XU Y., JONES G. J . & WANG B. (2009). Query dependent pseudo-relevance feedback based on wikipedia.
In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information
retrieval, SIGIR ’09, p. 59-66, New York, NY, USA : ACM.

ZHAI C. & LAFFERTY J . (2004). A study of smoothing methods for language models applied to information
retrieval. ACM Trans. Inf Syst., 22, 179-214.

