TALN 2011, Montpellier, 27juin — 1"'ju1'11et 2011

Le TAL au service de l’ALAO/ELAO
L’exemple des exercices de dictée automatisés

Richard Beaufort Sophie Roekhaut
CENTAL, UCLouvain, Place Blaise Pascal 1, B-1348 Louvain-la-Neuve
{richard.beaufort,sophie.roekhaut} @uclouvain.be

Résumé. Ce papier s’inscrit dans le cadre general de l’Apprentissage et de l’Enseignement des Langues
Assistés par Ordinateur, et conceme plus particulierement l’automatisation des exercices de dictée. Il présente une
méthode de correction des copies d’apprenants qui se Veut originale en deux points. Premierement, la méthode
exploite la composition d’automates a états ﬁnis pour détecter et pour analyser les erreurs. Deuxiemement, elle
repose sur une analyse morphosyntaxique automatique de l’original de la dictée, ce qui facilite la production de
diagnostics.

Abstract. This paper comes within the scope of the Computer Assisted Language Learning framework,
and addresses more especially the automation of dictation exercises. It presents a correction method of learners’
copies that is original in two ways. First, the method exploits the composition of ﬁnite—state automata, to both
detect and analyze the errors. Second, it relies on an automatic morphosyntactic analysis of the original dictation,
which makes it easier to produce diagnoses.

M0tS-CléS 3 ALAO/ELAO, exercices de dictée, alignement, diagnostic, machines a états ﬁnis.

Keywords: CALL, dictation exercises, alignment, diagnosis, ﬁnite—state machines.

1 Introduction

L’ Apprentissage et l’Enseignement des Langues Assistés par Ordinateur (ALAO/ELAO) ont pour obj ectif premier
d’améliorer l’acquisition des langues par les apprenants. Pourtant, force est de constater qu’actuellement, l’inVes—
tissement dans le domaine a plus été technologique que didactique : pour l’essentiel, la numérisation des cours
n’a pas modiﬁé leur contenu ni leurs méthodes d’éValuation (Desmet & Héroguel, 2005). Selon les spécialistes,
l’amélioration de l’apprentissage et de l’enseignement implique de dépasser les sempitemels exercices fermés,
tels que les textes a trous et les choix multiples qui, s’ils sont faciles a corriger, limitent considérablement les pos-
sibilités d’éValuation des connaissances. Il faudrait au moins proposer des exercices semi—ouVerts, qui autorisent
plusieurs réponses relativement prévisibles, pour autant que la correction automatique de ces exercices soit ﬁable :
apprentissage et enseignement, en effet, ne tolerent pas l’approxi1nation (Antoniadis et al., 2009).

La dictée, ou l’enseignant lit a haute Voix un passage que les étudiants doivent copier, est typiquement l’un de
ces exercices semi-ouverts qui, s’il était automatisé, pourrait considérablement améliorer l’apprentissage et l’en-
seignement des langues. La dictée est ainsi un tres bon moyen d’estimer le niveau d’un étudiant (Coniam, 1996).
Sa pratique, en outre, permet d’améliorer des competences telles que la maitrise de la grammaire, les capacités
de lecture, la connaissance du Vocabulaire et le niveau de comprehension (Rahimi, 2008). Actuellement pourtant,
rares ont été les essais d’automatisation de cet exercice. Or, grace aux synthétiseurs de la parole, lire automati-
quement un texte inconnu n’est plus un probleme. Mais la correction d’une copie d’apprenant, par contre, est une
étape beaucoup plus delicate a automatiser, parce qu’elle pose deux questions sensibles : la detection de la place
réelle des erreurs et leur classiﬁcation.

RICHARD BEAUFORT, SOPHIE ROEKHAUT

2 Etat de l’art

L’ importance d’exercices semi—ouverts en ALAO/ELAO a souvent eté mise en avant. Des tests ont en outre mon-
tre l’interet de la dictee comme moyen d’évaluation et d’amélioration de la maitrise de la langue, qu’il s’agisse
d’ apprenants natifs ou d’ allophones, pour autant que ceux—ci presentent un niveau de maitrise avancé de la langue
étudiée (niveaux Cl ou C2 du Cadre europe’en commun de reference pour les langues). Pourtant, peu de travaux
ont directement conceme l’automatisation de cet exercice et de sa correction.

Le travail le plus signiﬁcatif dans le domaine est certainement celui de Santiago—Oriola (1998). La partie de ce tra-
vail qui nous intéresse ici est la methode de correction proposée : elle repose sur le fait que le lien entre graphie et
prononciation n’est pas aise a acquérir en frangais : seuls 80 a 85% des lettres d’un texte transcrivent un phoneme,
ce qui est la cause de nombreuses fautes d’orthographe. Sur cette base, la correction proposee se divise en deux
modules : un premier module s’occupe de la detection des erreurs en realisant un alignement de l’original et de la
copie dirigé par des regles de transformation phonologiques ; un second module ne produit pas un diagnostic, mais
se’lectionne un diagnostic pre’—e’tabli, associé dans les ressources du systeme a une ou plusieurs erreurs recensées
dans la langue. Hormis une evaluation de l’outil qui a montré que 80% des 24 enfants l’ayant testé l’ont apprecié,
ce travail tres intéressant n’a malheureusement pas eté poursuivi.

Plus récemment, le logiciel de dictées la Dicte’e interactive a eté presente dans la revue Alsic, dediée a l’appren—
tissage des langues (Ruggia, 2000). Cet article, centre sur la presentation du potentiel de l’outil, ne donne qu’une
seule information concemant la methode de correction des erreurs : elle cible les erreurs courantes chez les appre-
nants italophones de niveau faux—debutant en frangais. Cette methode est donc probablement peu génerique.

Ces demieres annees, la dictee a completement disparu de la litterature scientiﬁque. Dans le domaine des exer-
cices semi-ouverts, on peut cependant encore noter les travaux de Desmet & Héroguel (2005), dont la plateforme
d’ apprentissage des langues étrangeres autorise entre autres la realisation de traductions de phrases d’une langue
source vers une langue cible. Le principe de correction proposé se rapproche de l’exercice de dictée dans lequel
l’original est disponible : l’idée, ici, est de produire plusieurs formulations (les << originaux »), et de sélectionner,
par approximate string matching, la formulation dont la réponse de l’apprenant se rapproche le plus. Le systeme,
qui travaille au niveau du mot, signale ensuite les erreurs a l’apprenant en remplagant un mauvais mot par XXX,
un mot superﬂu par (XXX) et un mot manquant, par (. . .). Par contre, aucun diagnostic n’est produit.

3 Le systéme de correction proposé

Notre methode de correction partage deux similarités avec celle de Santiago—Oriola (1998). Premierement, elle
comprend deux etapes, une phase de detection precedant une phase de diagnostic. Deuxiemement, la phase de
detection repose sur un alignement de l’original et de la copie.

Un aspect distingue particulierement notre approche : la totalité de la correction repose sur une analyse morpho-
syntaxique de l’original de la dictée. Cette analyse est produite par le systeme eLite (Beaufort & Ruelle, 2006),
qui realise successivement un pré—traitement, une analyse morphologique et une desambigu'1'sation contextuelle
du texte. La désambigu'1'sation est obtenue par l’application d’un modele de langue probabiliste (Beaufort et al.,
2002). Les informations morphosyntaxiques sont ensuite stockées dans une structure de données qui contient,
entre autres, une couche Sent correspondant aux phrases, et une couche Word correspondant aux mots.

Une fois l’analyse de l’original d’une dictee terminée, la structure de données correspondante est sauvegardée
dans un ﬁchier XML, qui sera charge par notre module de correction lorsqu’il devra traiter une copie de cette
dictée. Au—dela des informations morphosyntaxiques qui seront utilisées par le module de correction, il faut noter
que le processus de correction dans son ensemble est inﬂuence par cette structure de données : la couche Sent, qui
identiﬁe les phrases du texte, permet en effet d’appliquer le module de correction phrase par phrase, ce qui reduit
considerablement la complexité du processus.

Détection. Comme dans l’etat de l’art, la detection des erreurs de l’apprenant se fait sur la base d’ un alignement
de la phrase originale et de la copie. Classiquement, cet alignement est obtenu en calculant la distance d’ edition
des deux sequences (Darnerau, 1964; Levenshtein, 1966). Or, la distance d’édition classique n’autorise que des
operations de base : substitution, insertion et suppression d’ un caractere, et transposition de deux caracteres conti-
gus. Ceci est genant dans le cas qui nous occupe, parce que les erreurs des apprenants correspondent souvent a des
substitutions n—m, ou n caracteres se substituent a m caracteres : —es 4-) —ent, —ait 4-) —aient, —er <—> —e’es, etc. Dans

EXERCICES DE DICTEE AUTOMATISES

2) vectorisation del'alignen1ent

.demander un entretien...

...demandé_ un nentretie 
.00000000000-000000000...

I—|

3) insertion de marqueurs d'erreu.rs
...demand er un

. d e m a n d é _ ] u n
4) insertion des lirnites de mots

...entreti
...entreti

FIGURE 1 — Illustration des étapes 2 a 4 de la detection des erreurs

m
5
PP
H
m
I-P
.-
m
5

u—u—
I—JA—J

m
5
PP
H
m
I-P
.-
m
5

mm
55
.5...
,_.,_.
——
HI
._.._.
mm
55
I-PI-P
HH
mm
I-PI-P
5..-
mm
55
1

le cadre de la distance d’édition classique, la substitution n—m se modélise sous la forme de plusieurs operations
d’édition, ce qui tend a l’écarter des solutions pertinentes, étant donné que la distance qui lui est attribuée est la
somme de plusieurs operations. Aﬁn de dépasser cette limite, nous avons eu recours aux machines a états ﬁnis eta
une méthode que nous avons décrite dans (Beaufort, 2010) : étant donne deux sequences £17 et y représentées sous la
forme des automates a états ﬁnis X et 3/, nous constr11isons le transducteur pondéré 8 correspondant a l’ensemble
E des alignements possibles entre £17 pour y. Cet ensemble est obtenu au travers de la cascade de compositions :

5=Xo.7-'03} (1)

ou .7: est un transducteur pondéré qui modélise les operations d’ edition acceptees. Le meilleur alignement entre
:17 et y correspond au meilleur chemin de 8, obtenu par calcul du plus court chemin d’un graphe. La méthode est
appelée composition ﬁltrée, parce que le transducteur pondéré .7-‘ peut etre considéré comme un ﬁltre qui determine
la taille de l’intersection er1tre {B et y. Le ﬁltre F est compile sous la forme d’un transducteur .7-‘ a partir d’un ﬁchier
de regles de réécriture de la forme :

<25‘-’—>¢/w (2)

ou la sequence ¢ peut se réécrire 1p et se Voit dans ce cas attribuer le poids w. 11 s’agit donc de reglesfacultatives,
ce qui permet a ¢ soit de rester inchangé, soit de se Voir appliquer plusieurs réécritures.

L’ algorithme de detection des erreurs, illustré en Figure 1, est entierement constr11it autour de ce principe :

1. la phrase originale {B et la copie y sont converties en automates a états ﬁnis X et 3/. Les deux automates sont
composes au travers du ﬁltre .7-' qui représente les operations d’édition classiques ainsi que la substitution
n—m des sequences graphiques couramment confondues en frangais. Actuellement, le ﬁltre autorise surtout
la substitution des terminaisons nominales et Verbales, telles que celles que nous avons citées précédem—
ment. Le transducteur 8 des alignements possibles entre :17 et y est ensuite réduit a son meilleur chemin 8’,
correspondant au meilleur alignement de :17 et y ;

2. le transducteur E’ est parcouru et converti en trois Vecteurs : un pour la phrase originale, un pour la copie,
et un pour les poids associés aux operations réalisees. Dans le Vecteur de poids, un poids positif indique le
debut d’une operation d’édition;

3. les trois Vecteurs sont parcourus en parallele aﬁn d’entourer les erreurs de marqueurs [ et] qui en indiquent
les limites. Le systeme considere qu’une erreur commence quand le poids est different de 0, et qu’elle ﬁnit
lorsque le poids redevient 0 et que les deux Vecteurs de lettres présentent des caracteres identiques ;

4. il reste a identiﬁer les frontieres de mots a l’aide de marqueurs { et }. A ce niveau, l’algorithme est guide
par l’analyse linguistique, qui parcourt successivement les elements de la couche Word. Sur cette base,
le systeme identiﬁe le mot courant dans le Vecteur de la phrase originale. Ensuite, il adapte les frontieres
au besoin, pour inclure dans le mot courant les erreurs contigues qui correspondent a des insertions de
caracteres alphabétiques. C’est le cas du n dans la forme Qentretien;

5. chaque erreur est ensuite sauvegardée dans le Word adéquat de la structure de données. Cette sauvegarde
s’accompagne de calculs permettant de catégoriser l’erreur : dans ou en frontiére d ’e’le’ment, élément man-
quant, élément superﬂu, erreur ne contenant que des séparateurs. Ces indices guideront l’établissement du
diagnostic.

RICHARD BEAUFORT, SOPHIE ROEKHAUT

Diagnostic. A ce stade, toutes les informations disponibles sont sauvegardees dans les elements Word de la
structure de donnees : l’analyse morphosyntaxique de la forme correcte et, s’il y a eu erreur, la forme erronee et les
indices preleves. Le diagnostic n’est declenche que sur les elements Word contenant une erreur. Dans l’ensemble,
les erreurs concement (1) un separateur, (2) un mot simple ou (3) une sequence d’elements (mots et separateurs).
L’ orientation du diagnostic Vers une erreur sur sequence depend de l’indice associe a l’erreur : un separateur
manquant peut indiquer une fusion en une forme du lexique (quoi que —> quoique, d ’avantage —> davantage),
un separateur superﬂu, une segmentation en plusieurs formes du lexique (quoique —> quoi que, davantage —>
d’avantage). Si les indices l’y poussent, l’algorithrne de diagnostic commence donc par tester une erreur sur
sequence, et ne propose un autre diagnostic que si ces tests echouent. Pour des raisons de clarte cependant, nous
commengons par detailler le fonctionnement du diagnostic sur separateur et sur mot simple.

1) Le diagnostic relatif a une erreur sur separateur (ponctuation ou espace) est tres simple a produire : si l’indice
sauvegarde est superﬂu ou manquant, le diagnostic est identique. Sinon, le separateur existe mais est errone, et le
diagnostic signale simplement que l’on attendait un separateur different.

2) Une erreur sur mot simple peut etre lexicale et/ou grammaticale. Une erreur est lexicale si la forme erronee est
hors—Vocabulaire (Qentretien) ou appartient a la meme categorie que la forme correcte, mais possede un lemme
different (sceptique 4-) septique). Une erreur est grammaticale si la forme erronee presente des traits grammaticaux
differents de ceux de la forme correcte (parle <—> parles different au niveau de la personne). Une forme erronee
peut bien sur cumuler erreur lexicale et grammaticale (diﬂérent <—> diﬂérant cumulent erreur de lemme et erreur
de categorie). Pour poser l’un de ces diagnostics, nous commengons par rechercher la forme erronee dans le
lexique. Si la forme n’y ﬁgure pas, elle est consideree comme hors—Vocabulaire. Dans le cas contraire, l’idee est
de comparer l’analyse linguistique retenue pour la forme correcte lors de la preparation de la dictee, a l’ensemble
d’ analyses possibles proposees par le lexique pour la forme erronee, et de retenir l’analyse de la forme erronee la
plus proche de celle de la forme correcte.

Qu’il s’agisse d’une forme correcte ou erronee, une analyse linguistique est toujours constituee d’un lemme et des
traits grammaticaux suivants : temps/mode, genre, nombre, personne.

La methode de comparaison d’analyse que nous utilisons est fort proche de la methode d’alignement que nous
avons presentee precedemment. Elle est illustree en Figure 2 : on compile l’analyse de la forme correcte (a1) et
l’ensemble d’analyses de la forme erronees (ag) sous la forme d’automates a etats ﬁnis (resp. A1 et A2). Sur
cette base, la meilleure analyse a conserver pour la forme erronee (Ag) correspond au meilleur chemin de la
composition de ces deux automates au travers d’un ﬁltre .7-‘,5 :

E = B6St(./41 0 ft 0 A2) 

ou le ﬁltre autorise des conversions ponderees er1tre traits grammaticaux. Par exemple, un inﬁnitif peut etre converti
en participe passe moyennant un coﬁt de 1 et en nom moyennant un coﬁt de 5. Le meilleur chemin er1tre les deux
analyses est donc celui qui realise les transformations de traits les moins coﬁteuses.

Lorsque les lemmes des deux formes different (sceptique 4-) septique), la composition des automates echoue.
Dans ce cas, l’erreur est au moins lexicale. Il reste cependant a choisir l’analyse de la forme erronee et a tester
une eventuelle erreur grammaticale. Le meme calcul est de ce fait reproduit sur deux nouveaux automates, ne
presentant que les traits grammaticaux des deux formes a comparer. Cette composition donne touj ours un resultat.

3) Dans le principe, l’analyse d’une erreur sur sequence se deroule comme celle d’un mot simple : la sequence
erronee est recherchee dans un lexique. S’il n’y a pas de resultat cependant, la sequence n’est pas consideree
comme hors—Vocabulaire; le diagnostic s’oriente simplement Vers l’un des deux autres types d’erreurs.

La recherche de la sequence erronee dans le lexique differe en deux points de la recherche d’un mot simple : il
faut construire la sequence a rechercher et choisir un lexique approprie.

En cas de separateur manquant (quoique pour quot’ que, davantage pour d ’avantage), on suppose que la forme
erronee est un mot simple. Les mots corrects (par exemple, quoi et que) sont dans ce cas concatenes sans separateur
(quoique) et recherches dans le meme lexique que celui utilise pour l’analyse des erreurs sur mots simples.

En cas de separateur superﬂu (quoi que pour quoique, d ’avantage pour davantage), on suppose que la forme
erronee contient plusieurs formes correctes simples. Les segments de mots (par exemple, d et avantage) sont
dans ce cas concatenes autour du separateur superﬂu (d ’avantage) et recherches dans un lexique correspondant a
l’expression reguliere suivante :

(Wo1"dApo | (Word S'ep))+ Word (4)

ou WordApo est un mot termine par une apostrophe (d ’, qu’, etc.) et Sep est un espace ou un trait d’union. Cette
expression autorise donc simplement une suite de mots respectant les conventions typographiques du frangais.

EXERCICES DE DICTEE AUTOMATISES

    
   

 
  
 

  

IfPr:IdPa/2

M'%
’m‘’@‘
@

INFINIT:PARTPRES/ 1

 

    

I. Automate A1 repre’sentant I ’analyse de laforme correcte.
Ici, I ’analyse est augmente’e par composition avec le ﬁltre .7-‘,5

 

3. Intersection des deux automates. Le chemin rouge correspond a la meilleure analyse

FIGURE 2 — Aide au diagnostic : composition des analyses

4 Premiere évaluation et travaux futurs

Nous avons realise une premiere évaluation sur le corpus de dictées de Lenoble—Pinson, numérisé et étiqueté par
Fairon & Simon (2009). Ce corpus comprend 1 300 dictées réalisées sur une période de 40 années (1969-2008)
aux Facultés Universitaires Saint—Louis (Bruxelles, Belgique) par des étudiants de 1” et 29 baccalauréat. Dans
le corpus original, les erreurs étaient réparties en trois categories : usage, grammaire et ponctuation. La Version
numérisée rafﬁne ce classement en ajoutant trois categories : homophone, nouvelle orthographe et transcription.
Les fautes répertoriées nouvelle orthographe signiﬁent que l’étudiant a signalé employer une convention (1’or—
thographe traditionnelle ou la nouvelle orthographe), mais a malgré tout utilise des formes de 1’autre convention.
Les erreurs de transcription correspondent a des passages (un ou plusieurs mots complets) manquants ou aj outés
par l’étudiant. 11 faut noter que le classement dans les différentes categories est probablement a uniformiser : par
exemple, la confusion quelquefois —> quelle que fois est classée dans usage, alors que quelque 4-) quel que est
classée dans homophone. Notre évaluation, réalisée sur un sous—ensemble de 441 dictées présentant 5 152 erreurs,
a porté sur la qualité du systeme de detection d’une part, et sur la qualité du systeme de diagnostic d’autre part.

1) Globalement, 99% des erreurs (5 111 sur 5 152) sont correctement détectées et alignées. Toutes les erreurs
de detection sont dues a des problemes de transcription, qu’il s’agisse de passages superﬂus ou manquants. Le
systeme est alors peu performant, puisqu’i1 ne gere correctement que 59% de ces erreurs. Pour comprendre 1e
phénomene, Voici un exemple de passage tronqué :

. . . francaise [, quels qu’en puissent etre la gravite’ et le nombre] .

RICHARD BEAUFORT, SOPHIE ROEKHAUT

Contre toute attente, le systeme a favorise l’alignement du e ﬁnal defrancaise sur le ent de puissent. Apres analyse
des poids des differents alignements possibles, cette erreur est en fait due au ﬁltre, a qui l’on demande de favoriser
la substitution ent <—> e. Ce point ne manquera pas d’ etre étudié.

2) Evaluation du diagnostic. L’ evaluation a porté ici sur l’ensemble des erreurs, sauf celles de transcription, dont
la detection—meme pose probleme. Le corpus de test est de ce fait reduit a 5 052 erreurs. Nous ne générons pas le
meme classement que celui de Fairon & Simon (2009). L’ evaluation a de ce fait consisté a valider manuellement
les analyses produites, et ce a deux niveaux : en surface (séparateur superﬂu ou manquant, erreur lexicale et/ou
grammaticale, etc.) et en profondeur (mot hors-vocabulaire, erreur de lemme, erreur sur un trait grammatical, etc.).
Toute erreur d’analyse, quel que soit son niveau, a donné lieu au rejet du diagnostic dans son ensemble.

En l’état actuel, le systeme a ete capable d’ analyser correctement 83% des erreurs (4 200 sur 5 052). Ce résultat est
a nuancer. 51,4% des erreurs d’analyse se repartissent entre les categories nouvelle orthographe, usage et homo-
phone. Actuellement, nous ne gerons pas la nouvelle orthographe, ce qui explique les erreurs dans cette categorie :
toute orthographe nouvelle, absente de nos lexiques, a eté a tort classée comme hors—vocabulaire. Les erreurs re-
censées dans les categories usage et homophone concement toutes des sequences sur—segmentées, comme quel
que pour quelque ou d ’avantage pour davantage. Ceci est dﬁ au fait que le systeme, au moment de l’evaluation,
n’utilisait pas encore le lexique multi—mot decrit a l’Equation 4. Dans l’ensemble, ces erreurs devraient donc etre
facilement corrigees.

4l,4% des erreurs concement l’analyse grammaticale. L’erreur, dans ce cas, est souvent déja présente dans l’ana-
lyse de la forme correcte. Il s’agit soit de confusions de categories entre nom et adjectif, soit de confusions de
modes entre indicatif, subjonctif et impératif, soit de confusions de personnes au singulier. Ce type d’erreurs in-
dique clairement que l’analyse syntaxique realisee sur la dictée doit etre amélioree. Actuellement, nous pensons
aborder le probleme a l’aide de grammaires locales, qui guideront le modele de langue.

Références

ANTONIADIS G., GRANGER S., KRAIF 0., PONTON C. & ZAMPA V. (2009). NLP and CALL : integration is
working. In Proceedings of TaLC7, 7th Conference of Teaching and language Corpora.

BEAUFORT R. (2010). Composition ﬁltrée et marqueurs de regles de réécriture pour une distance d’édition
ﬂexible. Application a la correction des mots hors-vocabulaire. Traitement Automatique des langues (T.A.L.),
51(1), 11-40.

BEAUFORT R., DUTOIT T. & PAGEL V. (2002). Analyse syntaxique du frangais. Pondération par trigrammes
lissés et classes d’ ambigu'1'tes lexicales. In Proc. JEP, p. 133-136.

BEAUFORT R. & RUELLE A. (2006). eLite : Systeme de synthese de la parole a orientation linguistique. In
Proc. JEP, p. 509-512.

CONIAM D. (1996). Computerized dictation for assessing listening proﬁciency. Calico Journal, 13, 73-86.

DAMERAU F. (1964). A technique for computer detection and correction of spelling errors. Communications of
the ACM, 7(3), 171-176.

DESMET P. & HEROGUEL A. (2005). Les enjeux de la creation d’un environnement d’apprentissage electro-
nique axe sur la comprehension orale a l’aide du systeme auteur IDIOMA—TIC. Alsic. Apprentissage des langues
et Systemes d ’Information et de Communication, 8(1), 281-303.

FAIRON C. & SIMON A. (2009). Informatisation d’un corpus de dictées : 40 années de pratique orthographique
(1967-2008). In Pour l’amour des mots. Glanures lexicales, dictionnairiques, grammaticales et syntaxiques.
Hommage a Michele Lenoble—Pinson., p. 131-154.

LEVENSHTEIN V. (1966). Binary codes capable of correcting deletions, insertions and reversals. Soviet Physics,
10, 707-710.

RAHIMI M. (2008). Using Dictation to Improve Language Proﬁciency. Asian EFL Journal.

RUGGIA S. (2000). La dictée interactive. Alsic. Apprentissage des langues et Systemes d ’Information et de
Communication, 3(1), 99-108.

SANTIAGO—ORIOLA C. (1998). Systeme vocal interactif pour l’apprentissage des langues — la synthese de la
parole au service de la dicte’e. PhD thesis, Toulouse III.

