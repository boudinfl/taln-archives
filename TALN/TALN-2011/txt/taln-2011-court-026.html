<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Utiliser l&#8217;amor&#231;age pour am&#233;liorer une mesure de similarit&#233; s&#233;mantique</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Utiliser l&#8217;amor&#231;age pour am&#233;liorer une mesure de similarit&#233; s&#233;mantique
</p>
<p>Olivier Ferret
CEA, LIST, Laboratoire Vision et Ing&#233;nierie des Contenus,
</p>
<p>Fontenay-aux-Roses, F-92265 France.
olivier.ferret@cea.fr
</p>
<p>R&#233;sum&#233;. Les travaux sur les mesures de similarit&#233; s&#233;mantique de nature distributionnelle ont abouti &#224; un
certain consensus quant &#224; leurs performances et ont montr&#233; notamment que leurs r&#233;sultats sont surtout int&#233;res-
sants pour des mots de forte fr&#233;quence et une similarit&#233; s&#233;mantique &#233;tendue, non restreinte aux seuls synonymes.
Dans cet article, nous proposons une m&#233;thode d&#8217;am&#233;lioration d&#8217;une mesure de similarit&#233; classique permettant
de r&#233;&#233;quilibrer ses r&#233;sultats pour les mots de plus faible fr&#233;quence. Cette m&#233;thode est fond&#233;e sur un m&#233;canisme
d&#8217;amor&#231;age : un ensemble d&#8217;exemples et de contre-exemples de mots s&#233;mantiquement li&#233;s sont s&#233;lectionn&#233;s de
fa&#231;on non supervis&#233;e &#224; partir des r&#233;sultats de la mesure initiale et servent &#224; l&#8217;entra&#238;nement d&#8217;un classifieur super-
vis&#233;. Celui-ci est ensuite utilis&#233; pour r&#233;ordonner les voisins s&#233;mantiques initiaux. Nous &#233;valuons l&#8217;int&#233;r&#234;t de ce
r&#233;ordonnancement pour un large ensemble de noms anglais couvrant diff&#233;rents domaines fr&#233;quentiels.
</p>
<p>Abstract. Work about distributional semantic similarity measures has now widely shown that such mea-
sures are mainly reliable for high frequency words and for capturing semantic relatedness rather than strict seman-
tic similarity. In this article, we propose a method for improving such a measure for middle and low frequency
words. This method is based on a bootstrapping mechanism : a set of examples and counter-examples of semanti-
cally related words are selected in an unsupervised way from the results of the initial measure and used for training
a supervised classifier. This classifier is then applied for reranking the initial semantic neighbors. We evaluate the
interest of this reranking for a large set of english nouns with various frequencies.
</p>
<p>Mots-cl&#233;s : Extraction de voisins s&#233;mantiques, similarit&#233; s&#233;mantique, m&#233;thodes distributionnelles.
Keywords: Semantic neighbor extraction, semantic similarity, distributional methods.
</p>
<p>1 Introduction
</p>
<p>Le travail pr&#233;sent&#233; ici prend place dans le domaine de la s&#233;mantique lexicale et plus particuli&#232;rement de la si-
milarit&#233; s&#233;mantique au niveau lexical. La notion de similarit&#233; s&#233;mantique couvre, aussi bien du point de vue de
sa d&#233;finition que de sa caract&#233;risation, une pluralit&#233; d&#8217;approches. Concernant sa d&#233;finition, la dichotomie princi-
pale se fait entre une similarit&#233; reposant sur des relations s&#233;mantiques de nature paradigmatique (hyperonymie,
synonymie, etc) et une similarit&#233; reposant sur des relations s&#233;mantiques de nature syntagmatique (relations de
coh&#233;sion lexicale au statut th&#233;orique plus flou). Cette dichotomie recouvre celle faite entre les notions de semantic
similarity et de semantic relatedness. Bien que justifi&#233;e par la diff&#233;rence de nature des relations impliqu&#233;es, cette
diff&#233;renciation n&#8217;est pas en pratique toujours tr&#232;s nette, en particulier au niveau de l&#8217;&#233;valuation. Dans le cadre du
travail pr&#233;sent&#233; ici, nous nous focalisons plus sp&#233;cifiquement sur une caract&#233;risation distributionnelle de la simi-
larit&#233; s&#233;mantique. Les recherches la concernant ont montr&#233; que les relations s&#233;mantiques couvertes par une telle
approche rel&#232;vent &#224; la fois de l&#8217;axe paradigmatique et de l&#8217;axe syntagmatique. &#192; d&#233;faut donc de nous restreindre &#224;
un seul type de relations, nous nous efforcerons de distinguer au niveau des &#233;valuations les proximit&#233;s s&#233;mantiques
relevant de relations comme la synonymie de celles impliquant un ensemble plus large de relations s&#233;mantiques.
</p>
<p>Au-del&#224; d&#8217;une mise en &#339;uvre &#171; classique &#187; de l&#8217;approche distributionnelle telle qu&#8217;elle est incarn&#233;e par (Curran
&amp; Moens, 2002), un certain nombre de propositions ont &#233;t&#233; faites pour am&#233;liorer les r&#233;sultats dans le cadre de
ce paradigme. Une part significative de ces propositions portent sur la pond&#233;ration des &#233;l&#233;ments constitutifs des
contextes associ&#233;s aux mots mais un certain nombre impliquent des changements plus profonds. L&#8217;utilisation de
techniques de r&#233;duction de dimensions, en l&#8217;occurrence l&#8217;analyse s&#233;mantique latente dans (Pad&#243; &amp; Lapata, 2007),
ou la red&#233;finition de l&#8217;approche distributionnelle dans le cadre bay&#233;sien dans (Kazama et al., 2010), se classent</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OLIVIER FERRET
</p>
<p>dans cette seconde cat&#233;gorie. La premi&#232;re est quant &#224; elle repr&#233;sent&#233;e par (Broda et al., 2009) au travers du
passage de valeurs de poids &#224; des valeurs de rang ou par (Zhitomirsky-Geffet &amp; Dagan, 2009), repris et &#233;tendu
par (Yamamoto &amp; Asakura, 2010), qui utilise une technique d&#8217;amor&#231;age pour modifier les poids des &#233;l&#233;ments des
contextes distributionnels en fonction des voisinages s&#233;mantiques calcul&#233;s.
</p>
<p>Dans sa perspective g&#233;n&#233;rale, le travail pr&#233;sent&#233; ici se rapproche de (Zhitomirsky-Geffet &amp; Dagan, 2009) du point
de vue de l&#8217;utilisation de l&#8217;amor&#231;age mais adopte une m&#233;thode diff&#233;rente : les &#171; meilleurs &#187; voisins s&#233;mantiques
ne servent plus en effet &#224; modifier directement les poids des &#233;l&#233;ments des contextes distributionnelles mais plus
indirectement &#224; entra&#238;ner un classifieur supervis&#233;, &#224; la mani&#232;re de (Hagiwara et al., 2009), pour apprendre une
mesure de similarit&#233; am&#233;liorant certaines d&#233;ficiences de la mesure initiale.
</p>
<p>2 Une mesure de similarit&#233; s&#233;mantique distributionnelle
</p>
<p>2.1 D&#233;finition
</p>
<p>Pour qu&#8217;un m&#233;canisme d&#8217;amor&#231;age puisse &#234;tre mis en &#339;uvre, il est n&#233;cessaire de s&#8217;appuyer sur un processus initial
produisant des r&#233;sultats d&#8217;un niveau suffisamment &#233;lev&#233;, au moins dans un certain p&#233;rim&#232;tre. Dans le cas pr&#233;sent,
cette exigence implique de disposer d&#8217;une mesure de similarit&#233; s&#233;mantique montrant un bon niveau de r&#233;sultat
dans les &#233;valuations permettant classiquement de juger de telles mesures tels que des tests de type TOEFL ou
l&#8217;extraction de voisins s&#233;mantiques pour la construction de th&#233;saurus. Dans (Ferret, 2010), nous avons d&#233;fini, au
terme d&#8217;une s&#233;lection effectu&#233;e gr&#226;ce un test de type TOEFL, une mesure de similarit&#233; s&#233;mantique distribution-
nelle pr&#233;sentant des r&#233;sultats au moins comparables aux r&#233;sultats de l&#8217;&#233;tat de l&#8217;art pour des mesures de m&#234;me
nature. Cette mesure, d&#233;finie pour l&#8217;anglais &#224; partir du corpus AQUAINT-2, un corpus journalistique d&#8217;une taille
de 380 millions de mots, pr&#233;sente les caract&#233;ristiques suivantes :
&#8211; contextes distributionnels form&#233;s de cooccurrents graphiques, c&#8217;est-&#224;-dire des mots captur&#233;s dans une fen&#234;tre
</p>
<p>de taille fixe centr&#233;e sur toutes les occurrences du mot cible. Ces cooccurrents sont plus pr&#233;cis&#233;ment restreints
aux mots pleins des textes, autrement dit les noms, verbes et adjectifs ;
</p>
<p>&#8211; taille de fen&#234;tre = 1, i.e. cooccurrents &#224; tr&#232;s faible port&#233;e ;
&#8211; filtrage tr&#232;s conservateur des contextes : suppression des cooccurrents n&#8217;apparaissant qu&#8217;une seule fois ;
&#8211; utilisation de l&#8217;information mutuelle pour la pond&#233;ration des cooccurrents formant les contextes ;
&#8211; mesure de similarit&#233; entre les contextes, pour &#233;valuer la similarit&#233; s&#233;mantique des mots = cosinus.
Ces donn&#233;es distributionnelles n&#8217;ont &#233;t&#233; constitu&#233;es que pour des noms de fr&#233;quence strictement sup&#233;rieure &#224; 10.
</p>
<p>2.2 Application et &#233;valuation
</p>
<p>Une des applications des mesures de similarit&#233; telle que celle de la section pr&#233;c&#233;dente, application qui permet aussi
de les &#233;valuer, est l&#8217;extraction de voisins s&#233;mantiques. Dans (Ferret, 2010) comme dans la plupart des travaux
similaires, cette extraction est r&#233;alis&#233;e de fa&#231;on tr&#232;s simple : la mesure de similarit&#233; retenue est calcul&#233;e entre
chaque mot cible et chacun de ses voisins potentiels. Ces voisins sont ensuite tri&#233;s dans l&#8217;ordre d&#233;croissant des
valeurs de cette mesure et lesN (ici,N = 100) premiers sont conserv&#233;s comme voisins s&#233;mantiques du mot cible.
Le tableau 1 montre les r&#233;sultats de l&#8217;application de la mesure de similarit&#233; s&#233;mantique de la section pr&#233;c&#233;dente
&#224; l&#8217;extraction de voisins s&#233;mantiques. Deux ressources de r&#233;f&#233;rence compl&#233;mentaires sont consid&#233;r&#233;es : WordNet
(W), dans sa version 3.0, permet de caract&#233;riser la similarit&#233; fond&#233;e sur des relations paradigmatiques tandis que
le th&#233;saurus Moby (M) regroupe des mots li&#233;s par des relations plus diverses. Comme l&#8217;illustre la 4e&#768;me colonne
du tableau, ces deux ressources sont aussi tr&#232;s diff&#233;rentes en termes de richesse. Le but &#233;tant d&#8217;&#233;valuer la capacit&#233;
&#224; extraire des voisins s&#233;mantiques, elles sont filtr&#233;es pour en exclure les entr&#233;es et les voisins non pr&#233;sents dans
le vocabulaire du corpus AQUAINT-2 (cf. la diff&#233;rence entre le nombre de mots de la 1e&#768;re colonne et le nombre
de mots effectivement &#233;valu&#233;s de la 3e&#768;me colonne). Une fusion de ces deux ressources a &#233;galement &#233;t&#233; faite
(WM). La fr&#233;quence des mots &#233;tant une donn&#233;e importante des approches distributionnelles, les r&#233;sultats globaux
sont diff&#233;renci&#233;s suivant trois tranches fr&#233;quentielles &#224; peu pr&#232;s &#233;quilibr&#233;es en termes d&#8217;effectifs : les mots tr&#232;s
fr&#233;quents (fr&#233;quence&gt; 1000), moyennement fr&#233;quents (100 &lt; fr&#233;quence &#8804; 1000) et faiblement fr&#233;quents (10 &lt;
fr&#233;quence &#8804; 100). Ces r&#233;sultats se d&#233;clinent sous la forme de diff&#233;rentes mesures. La 5e&#768;me colonne donne ainsi
le taux de rappel par rapport aux ressources consid&#233;r&#233;es pour les 100 premiers voisins de chaque mot. Ces voisins</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L&#8217;AMOR&#199;AGE POUR LA SIMILARIT&#201; S&#201;MANTIQUE
</p>
<p>fr&#233;q. r&#233;f. #mots
&#233;val.
</p>
<p>#syn. /
mot
</p>
<p>rappel R-pr&#233;c. MAP P@1 P@5 P@10 P@100
</p>
<p>&gt; 10 W 10 473 2,9 24,6 8,2 9,8 11,7 5,1 3,4 0,7
(tous) M 9 216 50,0 9,5 6,7 3,2 24,1 16,4 13,0 4,8
# 14 670 WM 12 243 38,7 9,8 7,7 5,6 22,5 14,1 10,8 3,8
&gt; 1000 W 3 690 3,7 28,3 11,1 12,5 17,2 7,7 5,1 1,0
# 4 378 M 3 732 69,4 11,4 10,2 4,9 41,3 28,0 21,9 7,9
</p>
<p>WM 4 164 63,2 11,5 11,0 6,5 41,3 26,8 20,8 7,3
100 &lt; W 3 732 2,6 28,6 10,4 12,5 13,6 5,8 3,7 0,7
&#8804; 1000 M 3 306 41,3 9,3 6,5 3,1 18,7 13,1 10,4 3,8
# 5 175 WM 4 392 32,0 9,8 9,3 7,4 20,9 12,3 9,3 3,2
&#8804; 100 W 3 051 2,3 11,9 2,1 3,3 2,6 1,2 0,9 0,3
# 5 117 M 2 178 30,1 2,8 1,2 0,5 2,5 1,5 1,5 0,9
</p>
<p>WM 3 687 18,9 3,5 2,1 2,4 3,3 1,7 1,5 0,7
</p>
<p>TAB. 1 &#8211; &#201;valuation de l&#8217;extraction de voisins s&#233;mantiques
</p>
<p>&#233;tant ordonn&#233;s, il est en outre possible de r&#233;utiliser les m&#233;triques d&#8217;&#233;valuation classiquement utilis&#233;es en recherche
d&#8217;information en faisant jouer aux mots cibles le r&#244;le de requ&#234;tes et aux voisins celui des documents. C&#8217;est l&#8217;objet
des derni&#232;res colonnes du tableau 1 : la R-pr&#233;cision (R-pr&#233;c.) est la pr&#233;cision obtenue en se limitant aux R premiers
voisins, R &#233;tant le nombre de synonymes dans la ressource de r&#233;f&#233;rence pour l&#8217;entr&#233;e consid&#233;r&#233;e ; la MAP (Mean
Average Precision) est la moyenne des pr&#233;cisions pour chacun des rangs auxquels un synonyme de r&#233;f&#233;rence a
&#233;t&#233; identifi&#233; ; enfin, sont donn&#233;es les pr&#233;cisions pour diff&#233;rents seuils de nombre de voisins s&#233;mantiques examin&#233;s
(pr&#233;cision apr&#232;s examen des 1, 5, 10 et 100 premiers voisins). Toutes ces valeurs sont donn&#233;es en pourcentage.
</p>
<p>3 Am&#233;liorer une mesure de similarit&#233; s&#233;mantique
</p>
<p>Pour reprendre rapidement l&#8217;analyse du tableau 1 faite dans (Ferret, 2010), le constat d&#8217;une faiblesse d&#8217;ensemble
des r&#233;sultats s&#8217;impose, en particulier pour les mots peu fr&#233;quents, et la n&#233;cessit&#233; de les am&#233;liorer appara&#238;t claire-
ment. (Ferret, 2010) rapporte ainsi une tentative dans ce sens transposant au probl&#232;me de l&#8217;extraction de voisins
s&#233;mantiques la m&#233;thode d&#8217;amor&#231;age pr&#233;sent&#233;e dans (Zhitomirsky-Geffet &amp; Dagan, 2009) et appliqu&#233;e initiale-
ment &#224; l&#8217;extraction de mots en relation d&#8217;implication textuelle. Cette tentative ne fut n&#233;anmoins pas concluante,
aboutissant &#224; une d&#233;gradation globale des r&#233;sultats plut&#244;t qu&#8217;&#224; leur am&#233;lioration.
</p>
<p>La m&#233;thode d&#8217;am&#233;lioration pr&#233;sent&#233;e ici reprend l&#8217;id&#233;e d&#8217;amor&#231;age de (Zhitomirsky-Geffet &amp; Dagan, 2009) mais
l&#8217;applique diff&#233;remment. (Hagiwara et al., 2009) a montr&#233; qu&#8217;il est possible d&#8217;entra&#238;ner et d&#8217;appliquer avec un bon
niveau de performance un classifieur de type Machine &#224; Vecteurs de Support (SVM) pour d&#233;cider si deux mots
sont ou ne sont pas synonymes. La notion de synonymie est &#224; prendre ici au sens large compte tenu des ressources
utilis&#233;es pour l&#8217;&#233;valuation. Ce travail montre &#233;galement que la valeur de la fonction de d&#233;cision caract&#233;risant
les SVM, dont on n&#8217;utilise que le signe dans le cas d&#8217;une classification binaire, peut jouer, pour l&#8217;ordonnance-
ment des voisins s&#233;mantiques, le m&#234;me r&#244;le que la valeur d&#8217;une mesure de similarit&#233; telle que celle d&#233;finie &#224;
la section 2. &#192; la diff&#233;rence de (Hagiwara et al., 2009), nous ne disposons pas d&#8217;un ensemble d&#8217;exemples et de
contre-exemples &#233;tiquet&#233;s manuellement pour r&#233;aliser l&#8217;entra&#238;nement d&#8217;un tel classifieur. En revanche, les voisins
s&#233;mantiques obtenus en appliquant la mesure de similarit&#233; de la section 2 peuvent &#234;tre exploit&#233;s pour construire
cet ensemble. Cette mesure n&#8217;offre pas de crit&#232;re &#233;vident pour discriminer les mots s&#233;mantiquement li&#233;s mais le
tableau 1 fournit des informations pour s&#233;lectionner un ensemble d&#8217;exemples et de contre-exemples en minimisant
le nombre d&#8217;erreurs. Ces erreurs correspondent &#224; des exemples consid&#233;r&#233;s comme positifs mais en r&#233;alit&#233; n&#233;gatifs
et d&#8217;exemples consid&#233;r&#233;s comme n&#233;gatifs mais en fait positifs. Dans cette optique, nous proposons d&#8217;entra&#238;ner un
classifieur SVM gr&#226;ce &#224; ces ensembles et de l&#8217;appliquer ensuite pour r&#233;ordonner les voisins s&#233;mantiques obtenus
pr&#233;c&#233;demment. Le point cl&#233; de l&#8217;am&#233;lioration des r&#233;sultats par ce moyen est de s&#233;lectionner de fa&#231;on non supervi-
s&#233;e, les ressources de r&#233;f&#233;rence ne servant que pour l&#8217;&#233;valuation, un nombre suffisamment &#233;lev&#233; de bons exemples
et contre-exemples pour compenser les erreurs inh&#233;rentes &#224; une telle s&#233;lection.
</p>
<p>Avant de pr&#233;senter plus en d&#233;tail ce processus de s&#233;lection, il convient de pr&#233;ciser la nature des exemples et des</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OLIVIER FERRET
</p>
<p>contre-exemples. Nous reprenons de ce point de vue la conception d&#233;velopp&#233;e dans (Hagiwara et al., 2009) :
un exemple est constitu&#233; d&#8217;un couple de mots consid&#233;r&#233;s comme synonymes ou plus g&#233;n&#233;ralement s&#233;mantique-
ment li&#233;s ; un contre-exemple est form&#233; d&#8217;un couple de mots entre lesquels un tel lien s&#233;mantique n&#8217;existe pas.
La repr&#233;sentation de ces couples pour un classifieur de type SVM s&#8217;effectue en associant leurs repr&#233;sentations
distributionnelles. Cette association s&#8217;effectue pour chaque couple (M1, M2) en sommant le poids des cooccur-
rents communs aux mots M1 et M2. Les cooccurrents de Mx non pr&#233;sents dans My se voient attribuer un poids
nul. Chaque exemple ou contre-exemple a donc la m&#234;me forme que la repr&#233;sentation distributionnelle d&#8217;un mot,
c&#8217;est-&#224;-dire un vecteur de mots pond&#233;r&#233;s.
</p>
<p>Concernant la s&#233;lection des exemples et des contre-exemples, le tableau 1 montre clairement que le cas des
exemples est beaucoup plus probl&#233;matique que celui des contre-exemples dans la mesure o&#249; le nombre de mots
s&#233;mantiquement li&#233;s diminue tr&#232;s fortement d&#232;s que l&#8217;on consid&#232;re des voisins de rang un peu &#233;lev&#233;. Dans les
exp&#233;rimentations de la section 4, nous avons ainsi pris comme exemples n&#233;gatifs des couples {mot cible, voisin
du mot cible de rang 10}. Le choix d&#8217;un rang sup&#233;rieur garantirait un nombre plus faible de faux contre-exemples
(i.e. couples de mots en fait synonymes) et donc a priori, de meilleurs r&#233;sultats. En pratique, l&#8217;utilisation de voisins
du mot cible de rang assez faible conduit &#224; une performance sup&#233;rieure, sans doute parce que ceux-ci sont plus
utiles en termes de discrimination, &#233;tant plus proches de la zone de transition entre exemples et contre-exemples.
</p>
<p>Pour la s&#233;lection des exemples, le tableau 1 impose un double constat : les chances de trouver un voisin s&#233;manti-
quement proche sont d&#8217;autant plus importantes que la fr&#233;quence du mot cible est &#233;lev&#233;e et que le rang du voisin
est faible. Suivant cette logique, nous avons retenu comme premier ensemble d&#8217;exemples tous les couples {mot
cible de fr&#233;quence &gt; 1000, voisin de rang 1 du mot cible}, soit un total de 4 378 exemples pour lesquels 4 378
contre-exemples d&#233;finis selon le principe d&#233;crit ci-dessus ont &#233;t&#233; &#233;galement construits. Dans (Hagiwara et al.,
2009), le rapport nombre d&#8217;exemples / nombre de contre-exemples est &#233;gal &#224; 6,5 environ mais il n&#8217;est pas apparu
dans notre cas qu&#8217;un tel d&#233;s&#233;quilibre permettait d&#8217;obtenir des r&#233;sultats significativement meilleurs. Compte tenu
de notre nombre important d&#8217;exemples et de caract&#233;ristiques associ&#233;es &#224; chacun d&#8217;eux, nous avons donc opt&#233; pour
un nombre identique d&#8217;exemples et de contre-exemples.
</p>
<p>FIG. 1 &#8211; Principe de la restriction pour la s&#233;lection des exemples
</p>
<p>En se fondant sur les r&#233;sultats obtenus avec notre r&#233;f&#233;rence la plus riche (WM) pour 4 164 des 4 378 mots
cibles impliqu&#233;s ci-dessus, le taux d&#8217;erreur de la s&#233;lection des contre-exemples est, avec la m&#233;thode pr&#233;c&#233;dente,
de 26,8% tandis que celui de la s&#233;lection des exemples est de 58,7%. Ce sch&#233;ma de s&#233;lection simple pr&#233;sente
donc l&#8217;inconv&#233;nient d&#8217;impliquer un nombre important d&#8217;exemples et de contre-exemples avec des taux d&#8217;erreur
importants. Nous avons donc &#233;galement test&#233; une m&#233;thode de s&#233;lection plus restrictive au sein des mots cibles
de fr&#233;quence sup&#233;rieure &#224; 1000, m&#233;thode illustr&#233;e par la figure 1. Les voisins s&#233;mantiques pour les mots de
fr&#233;quence sup&#233;rieure &#224; 1000 se trouvant eux aussi majoritairement dans cette m&#234;me tranche fr&#233;quentielle, nous
faisons l&#8217;hypoth&#232;se que si un mot cible A ayant comme voisin de rang 1 un mot B, ce voisin a d&#8217;autant plus de
chances d&#8217;&#234;tre un mot s&#233;mantiquement li&#233; &#224; A que A est lui-m&#234;me le voisin de rang 1 de B en tant que mot cible.
En pratique, ces cas de sym&#233;trie entre mot cible et voisin de rang 1 se produisent pour 1052 mots cibles, ce qui
permet de construire 526 exemples puisque de ce point de vue, les couples {A,B} et {B,A} sont &#233;quivalents. En
revanche, nous avons retenu les 1052 contre-exemples correspondant &#224; tous les mots cibles concern&#233;s suivant le
principe (mot cible, voisin de rang 10). Notre hypoth&#232;se se trouve par ailleurs confirm&#233;e : parmi les 526 exemples
ainsi s&#233;lectionn&#233;s, le taux d&#8217;erreur n&#8217;est en effet plus que de 43% par rapport &#224; la r&#233;f&#233;rence WM.
</p>
<p>4 Exp&#233;rimentations et &#233;valuation
</p>
<p>La mise en &#339;uvre effective de notre approche de r&#233;ordonnancement des voisins s&#233;mantiques n&#233;cessite de fixer
un certain nombre de param&#232;tres li&#233;s aux SVM. De m&#234;me que (Hagiwara et al., 2009), nous avons adopt&#233; un</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L&#8217;AMOR&#199;AGE POUR LA SIMILARIT&#201; S&#201;MANTIQUE
</p>
<p>noyau RBF et une strat&#233;gie de type grid search pour l&#8217;optimisation du param&#232;tre &#947; fixant la largeur de la fonction
gaussienne du noyau RBF et du param&#232;tre C d&#8217;ajustement entre la taille de la marge et le taux d&#8217;erreur. Cette
optimisation a &#233;t&#233; r&#233;alis&#233;e pour chacun des deux ensembles d&#8217;apprentissage d&#233;crits &#224; la section pr&#233;c&#233;dente en se
fondant sur la mesure de pr&#233;cision calcul&#233;e dans le cadre d&#8217;une validation crois&#233;e divisant ces ensembles en 5
parties. Chacun des deux mod&#232;les ainsi construits en utilisant l&#8217;outil LIBSVM a ensuite &#233;t&#233; appliqu&#233; &#224; la totalit&#233;
des 14 670 noms cibles de notre &#233;valuation initiale. Plus pr&#233;cis&#233;ment, pour chaque nom cible, une repr&#233;sentation
d&#8217;exemple a &#233;t&#233; construite pour chaque couple {nom cible, voisin} et a &#233;t&#233; soumise au mod&#232;le SVM consid&#233;r&#233;
en mode classification. L&#8217;ensemble de ces voisins ont ensuite &#233;t&#233; r&#233;ordonn&#233;s suivant la valeur de la fonction
de d&#233;cision ainsi calcul&#233;e pour chaque voisin. Le tableau 2 donne les r&#233;sultats de ce r&#233;ordonnancement pour le
</p>
<p>fr&#233;q. r&#233;f. R-pr&#233;c. MAP P@1 P@5 P@10
W -0,8 (-10%) -0,8 (-8%) -0,9 (-8%) -0,4 (-8%) -0,3 (-9%)
</p>
<p>f &gt; 10 M 0,4 (6%) 0,2 (6%) 3,4 (14%) 1,1 (7%) 0,7 (5%)
WM 0,1 (1%) 0,0 (0%) 2,1 (9%) 0,6 (4%) 0,5 (5%)
W -2,1 (-19%) -2,1 (-17%) -2,4 (-14%) -1,3 (-17%) -0,8 (-16%)
</p>
<p>f &gt; 1000 M -0,5 (-5%) -0,4 (-8%) -1,0 (-2%) &#8225; -2,2 (-8%) -1,6 (-7%)
WM -0,9 (-8%) -0,8 (-12%) -2,1 (-5%) -2,4 (-9%) -1,7 (-8%)
W -1,7 (-16%) -1,8 (-14%) -2,1 (-15%) -0,7 (-12%) -0,3 (-8%)
</p>
<p>100 &lt; f M 0,8 (12%) 0,5 (16%) 7,2 (39%) 3,3 (25%) 2,3 (22%)
&#8804; 1000 WM -0,2 (-2%) -0,4 (-5%) 3,8 (18%) 2,1 (17%) 1,6 (17%)
</p>
<p>W 1,9 (90%) 2,0 (61%) 2,5 (96%) 1,0 (83%) 0,5 (56%)
f &#8804; 100 M 1,0 (83%) 0,6 (120%) 5,6 (224%) 3,4 (227%) 2,3 (153%)
</p>
<p>WM 1,6 (76%) 1,5 (62%) 4,6 (139%) 2,5 (147%) 1,6 (107%)
</p>
<p>TAB. 2 &#8211; Impact du r&#233;ordonnancement des voisins avec le mod&#232;le &#224; 526 exemples
</p>
<p>mod&#232;le fond&#233; sur 526 exemples et le tableau 3 pour celui fond&#233; sur 4 378 exemples. Compte tenu du nombre
de mesures, nous avons choisi de ne faire appara&#238;tre que les diff&#233;rences par rapport aux r&#233;sultats du tableau 1, &#224;
la fois en termes de valeur et de pourcentage (outre le signe indiquant le sens de la diff&#233;rence, la couleur verte
indique une variation positive et la couleur rouge, une variation n&#233;gative). L&#8217;&#233;valuation portant sur un processus
de r&#233;ordonnancement des voisins, les valeurs de rappel et de pr&#233;cision au rang maximum restent identiques par
rapport &#224; celles du tableau 1 et ne sont pas rappel&#233;es.
</p>
<p>fr&#233;q. r&#233;f. R-pr&#233;c. MAP P@1 P@5 P@10
W -0,4 (-5%) &#8225; -0,5 (-5%) -0,5 (-4%) &#8225; -0,1 (-2%) &#8225; -0,1 (-3%) &#8225;
</p>
<p>&gt; 10 M 0,4 (6%) 0,2 (6%) 3,4 (14%) 1,5 (9%) 0,7 (5%)
WM 0,1 (1%) 0,0 (0%) 2,3 (10%) 1,0 (7%) 0,6 (6%)
W -1,2 (-11%) -1,1 (-9%) -1,4 (-8%) -0,3 (-4%) &#8225; -0,2 (-4%)
</p>
<p>&gt; 1000 M -0,2 (-2%) -0,2 (-4%) -0,2 (-0%) &#8225; -0,6 (-2%) &#8225; -0,8 (-4%)
WM -0,6 (-5%) -0,5 (-8%) -0,8 (-2%) &#8225; -0,7 (-3%) -0,9 (-4%)
W -1,5 (-14%) -1,7 (-14%) -1,6 (-12%) -0,7 (-12%) -0,4 (-11%)
</p>
<p>100 &lt; f M 0,6 (9%) 0,4 (13%) 6,8 (36%) 2,7 (21%) 1,8 (17%)
&#8804; 1000 WM -0,3 (-3%) -0,4 (-5%) 3,6 (17%) 1,7 (14%) 1,2 (13%)
</p>
<p>W 1,7 (81%) 1,6 (48%) 2,1 (81%) 0,8 (67%) 0,5 (56%)
f &#8804; 100 M 0,9 (75%) 0,5 (100%) 5,0 (200%) 3,1 (207%) 2,0 (133%)
</p>
<p>WM 1,4 (67%) 1,1 (46%) 4,0 (121%) 2,2 (129%) 1,3 (87%)
</p>
<p>TAB. 3 &#8211; Impact du r&#233;ordonnancement des voisins avec le mod&#232;le &#224; 4 378 exemples
</p>
<p>Tr&#232;s clairement, la tendance g&#233;n&#233;rale pour les deux mod&#232;les consid&#233;r&#233;s est la m&#234;me : le processus de r&#233;ordon-
nancement propos&#233; induit une augmentation significative de toutes les mesures au niveau global avec M et WM
comme r&#233;f&#233;rences1. En revanche, une diminution de ces m&#234;mes mesures est observ&#233;e avec W comme r&#233;f&#233;rence.
</p>
<p>1La significativit&#233; statistique des r&#233;sultats a &#233;t&#233; &#233;valu&#233;e gr&#226;ce &#224; un test de Wilcoxon avec un seuil de 0,01, les &#233;chantillons &#233;tant appari&#233;s.
Seuls les r&#233;sultats suivis du signe &#8225; sont consid&#233;r&#233;s comme non significatifs, ce qui ne concerne que des d&#233;gradations de performance.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>OLIVIER FERRET
</p>
<p>Autrement dit, par rapport &#224; la mesure de similarit&#233; initiale, ce r&#233;ordonnancement favorise les mots s&#233;mantique-
ment li&#233;s mais le fait partiellement au d&#233;triment des synonymes. Cette tendance n&#8217;est pas surprenante de par le
m&#233;canisme d&#8217;amor&#231;age utilis&#233; : les premiers sont en effet largement mieux repr&#233;sent&#233;s que les seconds dans les
exemples s&#233;lectionn&#233;s du fait m&#234;me de leur meilleure repr&#233;sentation au niveau global. Les mod&#232;les SVM appris
ne font en l&#8217;occurrence qu&#8217;amplifier un &#233;tat de fait d&#233;j&#224; pr&#233;sent initialement.
L&#8217;analyse plus fine de ces r&#233;sultats selon le domaine fr&#233;quentiel des noms consid&#233;r&#233;s met en &#233;vidence une
deuxi&#232;me grande tendance : l&#8217;am&#233;lioration des r&#233;sultats produite par le r&#233;ordonnancement est d&#8217;autant plus sen-
sible que la fr&#233;quence du nom est faible. Ainsi, pour les noms de fr&#233;quence inf&#233;rieure &#224; 100, cette am&#233;lioration
s&#8217;observe quelle que soit la r&#233;f&#233;rence prise ; pour les noms de fr&#233;quence comprise entre 100 et 1000, elle s&#8217;iden-
tifie &#224; la tendance g&#233;n&#233;rale tandis que pour les noms de fr&#233;quence sup&#233;rieure &#224; 1000, la variation correspond &#224;
une d&#233;gradation par rapport &#224; toutes les r&#233;f&#233;rences. D&#8217;une certaine fa&#231;on, on peut donc dire que ce processus de
r&#233;ordonnancement r&#233;&#233;quilibre la mesure de similarit&#233; initiale, tr&#232;s fortement biais&#233;e vers les fortes fr&#233;quences. La
comparaison des tableaux 2 et 3 ne fait quant &#224; elle appara&#238;tre que des diff&#233;rences assez faibles entre les deux
mod&#232;les SVM. L&#8217;utilisation des 4 378 exemples permet d&#8217;obtenir des r&#233;sultats globaux un peu meilleurs mais
cette sup&#233;riorit&#233; n&#8217;est v&#233;ritablement notable qu&#8217;avec W comme r&#233;f&#233;rence. Par ailleurs, elle s&#8217;inverse pour les mots
de fr&#233;quence inf&#233;rieure &#224; 100 par rapport &#224; toutes les r&#233;f&#233;rences et pour la tranche fr&#233;quentielle interm&#233;diaire, par
rapport &#224; M et &#224; WM. On peut &#224; cet &#233;gard observer un certain parall&#233;lisme en termes de tendances entre la compa-
raison des deux mod&#232;les SVM et la comparaison de la mesure initiale et de ces mod&#232;les SVM. En final, le choix
parmi ces deux mod&#232;les peut aussi &#234;tre motiv&#233; par le fait que le mod&#232;le fond&#233; sur 526 exemples est beaucoup plus
petit (nombre inf&#233;rieur de vecteurs de support) et donc, plus efficace que son alter ego.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; une m&#233;thode d&#8217;am&#233;lioration d&#8217;une mesure de similarit&#233; s&#233;mantique de nature
distributionnelle exploitant l&#8217;amor&#231;age. Plus pr&#233;cis&#233;ment, cette m&#233;thode est fond&#233;e sur le r&#233;ordonnancement des
voisins s&#233;mantiques obtenus par la mesure initiale gr&#226;ce &#224; un classifieur de type SVM. Ce classifieur est entra&#238;n&#233;
sur la base d&#8217;exemples et de contre-exemples s&#233;lectionn&#233;s de fa&#231;on non supervis&#233;e &#224; partir des r&#233;sultats de la
mesure de similarit&#233; initiale. Cette m&#233;thode a montr&#233; plus particuli&#232;rement son int&#233;r&#234;t pour les mots de faible
fr&#233;quence et pour une similarit&#233; s&#233;mantique d&#233;passant la stricte synonymie. Dans la perspective de minimiser la
taille des mod&#232;les construits, d&#233;j&#224; explor&#233;e ici au travers du nombre d&#8217;exemples, nous envisageons de prolonger
ce travail en y int&#233;grant la probl&#233;matique de la s&#233;lection de caract&#233;ristiques.
</p>
<p>R&#233;f&#233;rences
BRODA B., PIASECKI M. &amp; SZPAKOWICZ S. (2009). Rank-Based Transformation in Measuring Semantic
Relatedness. In 22nd Canadian Conference on Artificial Intelligence, p. 187&#8211;190.
CURRAN J. &amp; MOENS M. (2002). Improvements in automatic thesaurus extraction. In Workshop of the ACL
Special Interest Group on the Lexicon (SIGLEX), p. 59&#8211;66.
FERRET O. (2010). Similarit&#233; s&#233;mantique et extraction de synonymes &#224; partir de corpus. In 17e&#768;me Conf&#233;rence
sur le Traitement Automatique des Langues Naturelles (TALN 2010).
HAGIWARA M., OGAWA Y. &amp; TOYAMA K. (2009). Supervised synonym acquisition using distributional fea-
tures and syntactic patterns. Information and Media Technologies, 4(2), 59&#8211;83.
KAZAMA J., DE SAEGER S., KURODA K., MURATA M. &amp; TORISAWA K. (2010). A bayesian method for
robust estimation of distributional similarities. In 48th Annual Meeting of the Association for Computational
Linguistics, p. 247&#8211;256.
PAD&#211; S. &amp; LAPATA M. (2007). Dependency-based construction of semantic space models. Computational
Linguistics, 33(2), 161&#8211;199.
YAMAMOTO K. &amp; ASAKURA T. (2010). Even unassociated features can improve lexical distributional similarity.
In Second Workshop on NLP Challenges in the Information Explosion Era (NLPIX 2010), p. 32&#8211;39.
ZHITOMIRSKY-GEFFET M. &amp; DAGAN I. (2009). Bootstrapping Distributional Feature Vector Quality. Compu-
tational Linguistics, 35(3), 435&#8211;461.</p>

</div></div>
</body></html>