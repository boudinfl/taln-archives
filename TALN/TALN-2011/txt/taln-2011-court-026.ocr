TALN 2011, Montpellier, 27juin — 1°’ju1'11et 2011

Utiliser Pamorcage pour améliorer une mesure de similarité sémantique

Olivier Ferret
CEA, LIST, Laboratoire Vision et Ingenierie des Contenus,
Fontenay-aux-Roses, F-92265 France.
olivier.ferret@cea.fr

Résllnlé. Les travaux sur les mesures de similarite semantique de nature distributionnelle ont abouti a un
certain consensus quant a leurs performances et ont montre notamment que leurs resultats sont surtout interes-
sants pour des mots de forte frequence et une similarite semantique etendue, non restreinte aux seuls synonymes.
Dans cet article, nous proposons une methode d’amelioration d’une mesure de similarite classique permettant
de reequilibrer ses resultats pour les mots de plus faible frequence. Cette methode est fondee sur un mecanisme
d’amorgage : un ensemble d’exemples et de contre—exemples de mots semantiquement hes sont selectionnes de
fagon non supervisee a partir des resultats de la mesure initiale et servent a l’entrainement d’un classiﬁeur super-
vise. Celui—ci est ensuite utilise pour reordonner les Voisins semantiques initiaux. Nous evaluons l’interet de ce
reordonnancement pour un large ensemble de noms anglais couvrant differents domaines frequentiels.

Abstract. Work about distributional semantic similarity measures has now widely shown that such mea-
sures are mainly reliable for high frequency words and for capturing semantic relatedness rather than strict seman-
tic similarity. In this article, we propose a method for improving such a measure for middle and low frequency
words. This method is based on a bootstrapping mechanism : a set of examples and counter—examples of semanti-
cally related words are selected in an unsupervised way from the results of the initial measure and used for training
a supervised classiﬁer. This classiﬁer is then applied for reranking the initial semantic neighbors. We evaluate the
interest of this reranking for a large set of english nouns with various frequencies.

M0tS-CléS 3 Extraction de Voisins semantiques, similarite semantique, methodes distributionnelles.

Keywords: Semantic neighbor extraction, semantic similarity, distributional methods.

1 Introduction

Le travail presente ici prend place dans le domaine de la semantique lexicale et plus particulierement de la si-
milarite semantique au niveau lexical. La notion de similarite’ semantique couvre, aussi bien du point de vue de
sa deﬁnition que de sa caracterisation, une pluralite d’approches. Concemant sa deﬁnition, la dichotomie princi-
pale se fait entre une similarite reposant sur des relations semantiques de nature paradigmatique (hyperonymie,
synonymie, etc) et une similarite reposant sur des relations semantiques de nature syntagmatique (relations de
cohesion lexicale au statut theorique plus ﬂou). Cette dichotomie recouvre celle faite entre les notions de semantic
similarity et de semantic relatedness. Bien que justiﬁee par la difference de nature des relations impliquees, cette
differenciation n’est pas en pratique touj ours tres nette, en particulier au niveau de l’evaluation. Dans le cadre du
travail presente ici, nous nous focalisons plus speciﬁquement sur une caracterisation distributionnelle de la simi-
larite semantique. Les recherches la concemant ont montre que les relations semantiques couvertes par une telle
approche relevent a la fois de l’axe paradigmatique et de l’axe syntagmatique. A defaut donc de nous restreindre a
un seul type de relations, nous nous efforcerons de distinguer au niveau des evaluations les proximites semantiques
relevant de relations comme la synonymie de celles impliquant un ensemble plus large de relations semantiques.

Au—dela d’une Inise en oeuvre << classique » de l’approche distributionnelle telle qu’elle est incarnee par (Curran
& Moens, 2002), un certain nombre de propositions ont ete faites pour ameliorer les resultats dans le cadre de
ce paradigme. Une part signiﬁcative de ces propositions portent sur la ponderation des elements constitutifs des
contextes associes aux mots mais un certain nombre impliquent des changements plus profonds. L’ utilisation de
techniques de reduction de dimensions, en l’occurrence l’analyse semantique latente dans (Pade & Lapata, 2007),
ou la redeﬁnition de l’approche distributionnelle dans le cadre bayesien dans (Kazama et al., 2010), se classent

OLIVIER FERRET

dans cette seconde categorie. La premiere est quant a elle représentee par (Broda et al., 2009) au travers du
passage de valeurs de poids a des valeurs de rang ou par (Zhitomirsky—Geffet & Dagan, 2009), repris et étendu
par (Yamamoto & Asakura, 2010), qui utilise une technique d’ amorcage pour modiﬁer les poids des elements des
contextes distributionnels en fonction des voisinages sémantiques calcules.

Dans sa perspective genérale, le travail presenté ici se rapproche de (Zhitomirsky-Geffet & Dagan, 2009) du point
de vue de l’utilisation de l’amorgage mais adopte une methode différente : les << meilleurs » voisins sémantiques
ne servent plus en effet a modiﬁer directement les poids des elements des contextes distributionnelles mais plus
indirectement a entrainer un classiﬁeur supervise, a la maniere de (Hagiwara et al., 2009), pour apprendre une
mesure de similarité ameliorant certaines deﬁciences de la mesure initiale.

2 Une mesure de similarité sémantique distributionnelle

2.1 Déﬁnition

Pour qu’un mécanisme d’amorgage puisse etre mis en oeuvre, il est necessaire de s’appuyer sur un processus initial
produisant des resultats d’un niveau sufﬁsamment éleve, au moins dans un certain périmetre. Dans le cas present,
cette exigence implique de disposer d’une mesure de similarité sémantique montrant un bon niveau de resultat
dans les evaluations permettant classiquement de juger de telles mesures tels que des tests de type TOEFL ou
l’extraction de voisins sémantiques pour la construction de thesaurus. Dans (Ferret, 2010), nous avons déﬁni, au
terme d’une selection effectuee grace un test de type TOEFL, une mesure de similarité sémantique distribution-
nelle présentant des resultats au moins comparables aux resultats de l’etat de l’art pour des mesures de meme
nature. Cette mesure, déﬁnie pour l’anglais a partir du corpus AQUAINT—2, un corpus joumalistique d’une taille
de 380 millions de mots, presente les caracteristiques suivantes :

— contextes distributionnels formes de cooccurrents graphiques, c’est-a-dire des mots captures dans une fenetre
de taille ﬁxe centrée sur toutes les occurrences du mot cible. Ces cooccurrents sont plus précisément restreints
aux mots pleins des textes, autrement dit les noms, verbes et adj ectifs;

— taille de fenetre = 1, i.e. cooccurrents a tres faible portée;

— ﬁltrage tres conservateur des contextes : suppression des cooccurrents n’apparaissant qu’une seule fois;

— utilisation de 1’ information mutuelle pour la pondération des cooccurrents formant les contextes ;

— mesure de similarité entre les contextes, pour evaluer la similarité sémantique des mots = cosinus.

Ces donnees distributionnelles n’ont ete constituées que pour des noms de frequence strictement supérieure a 10.

2.2 Application et évaluation

Une des applications des mesures de similarité telle que celle de la section precedente, application qui permet aussi
de les evaluer, est l’extraction de voisins semantiques. Dans (Ferret, 2010) comme dans la plupart des travaux
similaires, cette extraction est realisée de facon tres simple : la mesure de similarité retenue est calculée entre
chaque mot cible et chacun de ses voisins potentiels. Ces voisins sont ensuite tries dans l’ordre décroissant des
valeurs de cette mesure et les N (ici, N = 100) premiers sont conserves comme voisins sémantiques du mot cible.

Le tableau 1 montre les résultats de l’application de la mesure de similarité sémantique de la section précédente
a l’extraction de voisins sémantiques. Deux ressources de reference complémentaires sont considerees : WordNet
(W), dans sa version 3.0, permet de caracteriser la similarité fondée sur des relations paradigmatiques tandis que
le thesaurus Moby (M) regroupe des mots lies par des relations plus diverses. Comme l’illustre la 4éme colonne
du tableau, ces deux ressources sont aussi tres differentes en termes de richesse. Le but etant d’evaluer la capacité
a extraire des voisins semantiques, elles sont ﬁltrees pour en exclure les entrees et les voisins non presents dans
le vocabulaire du corpus AQUAINT—2 (cf. la difference entre le nombre de mots de la 1e” colonne et le nombre
de mots effectivement evalues de la 3éme colonne). Une fusion de ces deux ressources a egalement eté faite
(WM). La frequence des mots etant une donnee importante des approches distributionnelles, les résultats globaux
sont différenciés suivant trois tranches fréquentielles a peu pres équilibrees en termes d’effectifs : les mots tres
frequents (frequence > 1000), moyennement frequents (100 < frequence 3 1000) et faiblement frequents (10 <
frequence 3 100). Ces resultats se declinent sous la forme de differentes mesures. La Séme colonne donne ainsi
le taux de rappel par rapport aux ressources considérées pour les 100 premiers voisins de chaque mot. Ces voisins

L’ AMORCAGE POUR LA SIMILARITE SEMANTIQUE

fréq. réf. #mots #syn. / rappel R-préc. MAP P@1 P@5 P@ 10 P@ 100
éval. mot
> 10 W 10 473 2,9 24,6 8,2 9,8 11,7 5,1 3,4 0,7
(tous) M 9 216 50,0 9,5 6,7 3,2 24,1 16,4 13,0 4,8
#14 670 WM 12 243 38,7 9,8 7,7 5,6 22,5 14,1 10,8 3,8
> 1000 W 3 690 3,7 28,3 11,1 12,5 17,2 7,7 5,1 1,0
# 4 378 M 3 732 69,4 11,4 10,2 4,9 41,3 28,0 21,9 7,9
WM 4 164 63,2 11,5 11,0 6,5 41,3 26,8 20,8 7,3
100 < W 3 732 2,6 28,6 10,4 12,5 13,6 5,8 3,7 0,7
3 1000 M 3 306 41,3 9,3 6,5 3,1 18,7 13,1 10,4 3,8
# 5 175 WM 4 392 32,0 9,8 9,3 7,4 20,9 12,3 9,3 3,2
3 100 W 3 051 2,3 11,9 2,1 3,3 2,6 1,2 0,9 0,3
# 5 117 M 2 178 30,1 2,8 1,2 0,5 2,5 1,5 1,5 0,9
WM 3 687 18,9 3,5 2,1 2,4 3,3 1,7 1,5 0,7

TAB. 1 — Evaluation de l’extraction de voisins sémantiques

étant ordonnés, il est en outre possible de réutiliser les metriques d’ evaluation classiquement utilisées en recherche
d’information en faisant jouer aux mots cibles le role de requetes et aux voisins celui des documents. C’est l’objet
des demieres colonnes du tableau 1 : la R-precision (R—préc.) est la precision obtenue en se limitant aux R premiers
voisins, R etant le nombre de synonymes dans la ressource de reference pour l’entrée considéree; la MAP (Mean
Average Precision) est la moyenne des precisions pour chacun des rangs auxquels un synonyme de reference a
ete identiﬁé; enﬁn, sont donnees les precisions pour djfférents seuils de nombre de voisins semantiques examines
(precision apres examen des 1, 5, 10 et 100 premiers voisins). Toutes ces valeurs sont donnees en pourcentage.

3 Améliorer une mesure de similarité sémantique

Pour reprendre rapidement l’analyse du tableau 1 faite dans (Ferret, 2010), le constat d’une faiblesse d’ensemble
des résultats s’i1npose, en particulier pour les mots peu frequents, et la nécessité de les ameliorer apparait claire-
ment. (Ferret, 2010) rapporte ainsi une tentative dans ce sens transposant au probleme de l’extraction de voisins
sémantiques la methode d’amorcage présentée dans (Zhitomirsky—Geffet & Dagan, 2009) et appliquée initiale-
ment a l’extraction de mots en relation d’i1nplication textuelle. Cette tentative ne fut neanmoins pas concluante,
aboutissant a une degradation globale des resultats plutot qu’a leur amelioration.

La methode d’amelioration présentée ici reprend l’idee d’amorcage de (Zhitomirsky—Geffet & Dagan, 2009) mais
l’ applique djfferemment. (Hagiwara et al., 2009) a montre qu’il est possible d’ entrainer et d’ appliquer avec un bon
niveau de performance un classiﬁeur de type Machine 51 Vecteurs de Support (SVM) pour decider si deux mots
sont ou ne sont pas synonymes. La notion de synonymie est a prendre ici au sens large compte tenu des ressources
utilisées pour l’évaluation. Ce travail montre egalement que la valeur de la fonction de decision caractérisant
les SVM, dont on n’utilise que le signe dans le cas d’une classiﬁcation binaire, peut jouer, pour l’ordonnance-
ment des voisins semantiques, le meme role que la valeur d’une mesure de similarité telle que celle déﬁnie a
la section 2. A la difference de (Hagiwara et al., 2009), nous ne disposons pas d’un ensemble d’exemples et de
contre—exemples étiquetés manuellement pour realiser l’entrainement d’un tel classiﬁeur. En revanche, les voisins
sémantiques obtenus en appliquant la mesure de similarité de la section 2 peuvent etre exploites pour construire
cet ensemble. Cette mesure n’offre pas de critere evident pour discriminer les mots semantiquement hes mais le
tableau 1 foumit des informations pour sélectionner un ensemble d’exemples et de contre—exemples en minimisant
le nombre d’erreurs. Ces erreurs correspondent a des exemples considerés comme positifs mais en réalite negatifs
et d’exemples considerés comme negatifs mais en fait positifs. Dans cette optique, nous proposons d’entrainer un
classiﬁeur SVM grace a ces ensembles et de l’appliquer ensuite pour réordonner les voisins sémantiques obtenus
précédemment. Le point clé de l’amélioration des resultats par ce moyen est de sélectionner de facon non supervi-
sée, les ressources de reference ne servant que pour l’évaluation, un nombre sufﬁsamment élevé de bons exemples
et contre—exemples pour compenser les erreurs inherentes a une telle selection.

Avant de presenter plus en detail ce processus de selection, il convient de préciser la nature des exemples et des

OLIVIER FERRET

contre-exemples. Nous reprenons de ce point de vue la conception developpee dans (Hagiwara et al., 2009) :
un exemple est constitue d’un couple de mots consideres comme synonymes ou plus generalement semantique—
ment lies; un contre—exemple est forme d’un couple de mots er1tre lesquels un tel lien semantique n’existe pas.
La representation de ces couples pour un classiﬁeur de type SVM s’effectue en associant leurs representations
distributionnelles. Cette association s’effectue pour chaque couple (M1, M2) en sommant le poids des cooccur—
rents communs aux mots M1 et M2. Les cooccurrents de Mg, non presents dans My se voient attribuer un poids
nul. Chaque exemple ou contre—exemple a donc la meme forme que la representation distributionnelle d’un mot,
c’est—a—dire un vecteur de mots ponderes.

Concernant la selection des exemples et des contre-exemples, le tableau 1 montre clairement que le cas des
exemples est beaucoup plus problematique que celui des contre-exemples dans la mesure ou le nombre de mots
semantiquement lies diminue tres fortement des que l’on considere des voisins de rang un peu eleve. Dans les
experimentations de la section 4, nous avons ainsi pris comme exemples negatifs des couples {mot cible, voisin
du mot cible de rang 10}. Le choix d’un rang superieur garantirait un nombre plus faible de faux contre-exemples
(i. e. couples de mots en fait synonymes) et donc a priori, de meilleurs resultats. En pratique, l’utilisation de voisins
du mot cible de rang assez faible conduit a une performance superieure, sans doute parce que ceux—ci sont plus
utiles en termes de discrimination, etant plus proches de la zone de transition entre exemples et contre-exemples.

Pour la selection des exemples, le tableau 1 impose un double constat : les chances de trouver un voisin semanti-
quement proche sont d’autant plus importantes que la frequence du mot cible est elevee et que le rang du voisin
est faible. Suivant cette logique, nous avons retenu comme premier ensemble d’exemples tous les couples {mot
cible de frequence > 1000, voisin de rang 1 du mot cible}, soit un total de 4 378 exemples pour lesquels 4 378
contre-exemples deﬁnis selon le principe decrit ci—dessus ont ete egalement construits. Dans (Hagiwara et al.,
2009), le rapport nombre d’exemples / nombre de contre-exemples est egal a 6,5 environ mais il n’est pas apparu
dans notre cas qu’un tel desequilibre permettait d’obtenir des resultats signiﬁcativement meilleurs. Compte tenu
de notre nombre important d’exemples et de caracteristiques associees a chacun d’eux, nous avons donc opte pour
un nombre identique d’exemples et de contre-exemples.

mot cible Voisin de rang 1
A P B
B P A

Cj>D
Dm>F

FIG. 1 — Principe de la restriction pour la selection des exemples

En se fondant sur les resultats obtenus avec notre reference la plus riche (WM) pour 4 164 des 4 378 mots
cibles impliques ci—dessus, le taux d’erreur de la selection des contre-exemples est, avec la methode precedente,
de 26,8% tandis que celui de la selection des exemples est de 58,7%. Ce schema de selection simple presente
donc l’inconvenient d’i1npliquer un nombre important d’exemples et de contre-exemples avec des taux d’erreur
importants. Nous avons donc egalement teste une methode de selection plus restrictive au sein des mots cibles
de frequence superieure a 1000, methode illustree par la ﬁgure 1. Les voisins semantiques pour les mots de
frequence superieure a 1000 se trouvant eux aussi majoritairement dans cette meme tranche frequentielle, nous
faisons l’hypothese que si un mot cible A ayant comme voisin de rang 1 un mot B, ce voisin a d’autant plus de
chances d’etre un mot semantiquement he a A que A est lui—meme le voisin de rang 1 de B en tant que mot cible.
En pratique, ces cas de symetrie er1tre mot cible et voisin de rang 1 se produisent pour 1052 mots cibles, ce qui
permet de construire 526 exemples puisque de ce point de vue, les couples {A,B} et {B,A} sont equivalents. En
revanche, nous avons retenu les 1052 contre-exemples correspondant a tous les mots cibles concemes suivant le
principe (mot cible, voisin de rang 10). Notre hypothese se trouve par ailleurs conﬁrmee : parmi les 526 exemples
ainsi selectionnes, le taux d’erreur n’est en effet plus que de 43% par rapport a la reference WM.

4 Expérimentations et évaluation

La mise en oeuvre effective de notre approche de reordonnancement des voisins semantiques necessite de ﬁxer
un certain nombre de parametres hes aux SVM. De meme que (Hagiwara et al., 2009), nous avons adopte un

L’ AMORCAGE POUR LA SIMILARITE SEMANTIQUE

noyau RBF et une strategie de type grid search pour l’opti1nisation du parametre *y ﬁxant la largeur de la fonction
gaussienne du noyau RBF et du parametre C’ d’ajustement entre la taille de la marge et le taux d’erreur. Cette
optimisation a eté realisée pour chacun des deux ensembles d’apprentissage decrits a la section précédente en se
fondant sur la mesure de precision calculée dans le cadre d’une validation croisée divisant ces ensembles en 5
parties. Chacun des deux modeles ainsi construits en utilisant l’outil LIBSVM a ensuite eté applique a la totalité
des 14 670 noms cibles de notre evaluation initiale. Plus precisement, pour chaque nom cible, une representation
d’exemple a ete construite pour chaque couple {nom cible, voisin} et a eté soumise au modele SVM considéré
en mode classiﬁcation. L’ ensemble de ces voisins ont ensuite ete réordonnés suivant la valeur de la fonction
de decision ainsi calculée pour chaque voisin. Le tableau 2 donne les résultats de ce reordonnancement pour le

| fréq. | réf. | R-préc. | MAP | P@1 | P@5 | P@10 |
W -0,8 (-10%) -0,8 (-8%) -0,9 (-8%) -0,4 (-8%) -0,3 (-9%)
f > 10 M 0,4 (6%) 0,2 (6%) 3,4 (14%) 1,1 (7%) 0,7 (5%)
WM 0,1 (1%) 0,0 (0%) 2,1 (9%) 0,6 (4%) 0,5 (5%)
W -2,1 (-19%) -2,1 (-17%) -2,4 (-14%) -1,3 (-17%) -0,8 (-16%)
f > 1000 M -0,5 (-5%) -0,4 (-8%) -1,0 (-2%)1 -2,2 (-8%) -1,6 (-7%)
WM -0,9 (-8%) -0,8 (-12%) -2,1 (-5%) -2,4 (-9%) -1,7 (-8%)
W -1,7 (-16%) -1,8 (-14%) -2,1 (-15%) -0,7 (-12%) -0,3 (-8%)
100 < f M 0,8 (12%) 0,5 (16%) 7,2 (39%) 3,3 (25%) 2,3 (22%)
g 1000 WM -0,2 (-2%) -0,4 (-5%) 3,8 (18%) 2,1 (17%) 1,6 (17%)
W 1,9 (90%) 2,0 (61%) 2,5 (96%) 1,0 (83%) 0,5 (56%)
f g 100 M 1,0 (83%) 0,6 (120%) 5,6 (224%) 3,4 (227%) 2,3 (153%)
WM 1,6 (76%) 1,5 (62%) 4,6 (139%) 2,5 (147%) 1,6 (107%)

TAB. 2 — Impact du reordonnancement des voisins avec le modele a 526 exemples

modele fondé sur 526 exemples et le tableau 3 pour celui fondé sur 4 378 exemples. Compte tenu du nombre
de mesures, nous avons choisi de ne faire apparaitre que les differences par rapport aux resultats du tableau 1, a
la fois en termes de valeur et de pourcentage (outre le signe indiquant le sens de la difference, la couleur verte
indique une variation positive et la couleur rouge, une variation negative). L’ evaluation portant sur un processus
de reordonnancement des voisins, les valeurs de rappel et de precision au rang maximum restent identiques par
rapport a celles du tableau 1 et ne sont pas rappelées.

| fréq. | réf. | R-préc. | MAP | P@1 | P@5 | P@10 |
W -0,4 (-5%) 1 -0,5 (-5%) -0,5 (-4%) 1 -0,1 (-2%) 1 -0,1 (-3%) 1
> 10 M 0,4 (6%) 0,2 (6%) 3,4 (14%) 1,5 (9%) 0,7 (5%)

WM 0,1 (1%) 0,0 (0%) 2,3 (10%) 1,0 (7%) 0,6 (6%)
W -1,2 (-11%) -1,1 (-9%) -1,4 (-8%) -0,3 (-4%) 1 -0,2 (-4%)
> 1000 M -0,2 (-2%) -0,2 (-4%) -0,2 (-0%)1 -0,6 (-2%)1 -0,8 (-4%)
WM -0,6 (-5%) -0,5 (-8%) -0,8 (-2%) 1 -0,7 (-3%) -0,9 (-4%)
W -1,5 (-14%) -1,7 (-14%) -1,6 (-12%) -0,7 (-12%) -0,4 (-11%)
100 < f M 0,6 (9%) 0,4 (13%) 6,8 (36%) 2,7 (21%) 1,8 (17%)
g 1000 WM -0,3 (-3%) -0,4 (-5%) 3,6 (17%) 1,7 (14%) 1,2 (13%)
W 1,7 (81%) 1,6 (48%) 2,1 (81%) 0,8 (67%) 0,5 (56%)
f g 100 M 0,9 (75%) 0,5 (100%) 5,0 (200%) 3,1 (207%) 2,0 (133%)
WM 1,4 (67%) 1,1 (46%) 4,0 (121%) 2,2 (129%) 1,3 (87%)

TAB. 3 — Impact du reordonnancement des voisins avec le modele a 4 378 exemples

Tres clairement, la tendance générale pour les deux modeles considéres est la meme : le processus de réordon—
nancement propose induit une augmentation signiﬁcative de toutes les mesures au niveau global avec M et WM
comme reférencesl. En revanche, une diminution de ces memes mesures est observee avec W comme reference.

1La signiﬁcativité statistique des résultats a été évaluée grace 5: un test de Wilcoxon avec un seuil de 0,01, les échantillons étant appariés.
Seuls les résultats suivis du signe 1 sont considérés comme non signiﬁcatifs, ce qui ne conceme que des degradations de performance.

OLIVIER FERRET

Autrement dit, par rapport a la mesure de similarité initiale, ce reordonnancement favorise les mots sémantique—
ment lies mais le fait partiellement au detriment des synonymes. Cette tendance n’est pas surprenante de par le
mecanisme d’amorgage utilise : les premiers sont en effet largement mieux représentés que les seconds dans les
exemples sélectionnés du fait meme de leur meilleure representation au niveau global. Les modeles SVM appris
ne font en l’occurrence qu’ampliﬁer un état de fait deja present initialement.

L’ analyse plus ﬁne de ces résultats selon le domaine fréquentiel des noms considérés met en evidence une
deuxieme grande tendance : l’amélioration des résultats produite par le reordonnancement est d’autant plus sen-
sible que la frequence du nom est faible. Ainsi, pour les noms de frequence inférieure a 100, cette amelioration
s’observe quelle que soit la reference prise; pour les noms de frequence comprise entre 100 et 1000, elle s’iden—
tiﬁe a la tendance générale tandis que pour les noms de frequence supérieure a 1000, la variation correspond a
une degradation par rapport a toutes les references. D’une certaine fagon, on peut donc dire que ce processus de
réordonnancement reéquilibre la mesure de similarité initiale, tres fortement biaisée vers les fortes frequences. La
comparaison des tableaux 2 et 3 ne fait quant a elle apparaitre que des differences assez faibles er1tre les deux
modeles SVM. L’utilisation des 4 378 exemples permet d’obtenir des résultats globaux un peu meilleurs mais
cette superiorité n’ est veritablement notable qu’ avec W comme reference. Par ailleurs, elle s’inverse pour les mots
de frequence inférieure a 100 par rapport a toutes les references et pour la tranche fréquentielle intermediaire, par
rapport a M et a WM. On peut a cet egard observer un certain parallelisme en termes de tendances er1tre la compa-
raison des deux modeles SVM et la comparaison de la mesure initiale et de ces modeles SVM. En ﬁnal, le choix
parmi ces deux modeles peut aussi etre motive par le fait que le modele fondé sur 526 exemples est beaucoup plus
petit (nombre inférieur de vecteurs de support) et donc, plus efﬁcace que son alter ego.

5 Conclusion et perspectives

Dans cet article, nous avons presente une methode d’ amelioration d’une mesure de similarité sémantique de nature
distributionnelle exploitant l’amorgage. Plus précisément, cette méthode est fondée sur le reordonnancement des
voisins sémantiques obtenus par la mesure initiale grace a un classiﬁeur de type SVM. Ce classiﬁeur est entrainé
sur la base d’exemples et de contre—exemples sélectionnés de facon non supervisée a partir des resultats de la
mesure de similarité initiale. Cette methode a montre plus particulierement son interet pour les mots de faible
fréquence et pour une similarité sémantique dépassant la stricte synonymie. Dans la perspective de minimiser la
taille des modeles construits, deja explorée ici au travers du nombre d’exemples, nous envisageons de prolonger
ce travail en y intégrant la problematique de la selection de caractéristiques.

Références

BRODA B., PIASECKI M. & SZPAKOWICZ S. (2009). Rank—Based Transformation in Measuring Semantic
Relatedness. In 22"‘‘‘ Canadian Conference on Artificial Intelligence, p. 187-190.

CURRAN J. & MOENS M. (2002). Improvements in automatic thesaurus extraction. In Workshop of the ACL
Special Interest Group on the Lexicon (SIGLEX), p. 59-66.

FERRET O. (2010). Similarite sémantique et extraction de synonymes a partir de corpus. In I 7am” Confe’rence
sur le Traitement Automatique des Langues Naturelles (TALN 2010).

HAGIWARA M., OGAWA Y. & TOYAMA K. (2009). Supervised synonym acquisition using distributional fea-
tures and syntactic patterns. Information and Media Technologies, 4(2), 59-83.

KAZAMA J ., DE SAEGER S., KURODA K., MURATA M. & TORISAWA K. (2010). A bayesian method for

robust estimation of distributional similarities. In 48”‘ Annual Meeting of the Association for Computational
Linguistics, p. 247-256.

PADO S. & LAPATA M. (2007). Dependency—based construction of semantic space models. Computational
Linguistics, 33(2), 161-199.

YAMAMOTO K. & ASAKURA T. (2010). Even unassociated features can improve lexical distributional similarity.
In Second Workshop on NLP Challenges in the Information Explosion Era (NLPIX 2010), p. 32-39.

ZHITOMIRSKY-GEFFET M. & DAGAN I. (2009). Bootstrapping Distributional Feature Vector Quality. Compu-
tational Linguistics, 35(3), 435-461.

