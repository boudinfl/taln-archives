<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Mesure non-supervis&#233;e du degr&#233; d&#8217;appartenance d&#8217;une entit&#233; &#224; un type</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Mesure non-supervis&#233;e du degr&#233; d&#8217;appartenance d&#8217;une entit&#233; &#224; un type
</p>
<p>Ludovic Bonnefoy1,2, Patrice Bellot1, Michel Benoit2
(1) Universit&#233; d&#8217;Avignon - CERI/LIA, Agroparc &#8211; B.P. 1228, 84911 Avignon Cedex 9
</p>
<p>(2) iSmart, Le Mercure A, 13851 Aix-en-Provence Cedex 3
patrice.bellot@univ-avignon.fr, {ludovic.bonnefoy,michel.benoit}@ismart.fr
</p>
<p>R&#233;sum&#233;. La recherche d&#8217;entit&#233;s nomm&#233;es a &#233;t&#233; le sujet de nombreux travaux. Cependant, la construction des
ressources n&#233;cessaires &#224; de tels syst&#232;mes reste un probl&#232;me majeur. Dans ce papier, nous proposons une m&#233;thode
compl&#233;mentaire aux outils capables de reconna&#238;tre des entit&#233;s de types larges, dont l&#8217;objectif est de d&#233;terminer
si une entit&#233; est d&#8217;un type donn&#233;, et ce de mani&#232;re non-supervis&#233;e et quel que soit le type. Nous proposons pour
cela une approche bas&#233;e sur la comparaison de mod&#232;les de langage estim&#233;s &#224; partir du Web. L&#8217;int&#233;r&#234;t de notre
approche est valid&#233; par une &#233;valuation sur 100 entit&#233;s et 273 types diff&#233;rents.
</p>
<p>Abstract. Searching for named entities has been the subject of many researches. In this paper, we seek to
determine whether a named entity is of a given type and in what extent it is. We propose to address this issue by
an unsupervised Web oriented language modeling approach. The interest of it is demonstrated by our evaluation
on 100 entities and 273 different types.
</p>
<p>Mots-cl&#233;s : typage d&#8217;entit&#233;s nomm&#233;es, comparaison de distribution de mots, divergence de Kullback-
Leibler.
</p>
<p>Keywords: named entity identification, language modeling approach, Kullback-Leibler divergence.
</p>
<p>1 Introduction
</p>
<p>Depuis les ann&#233;es 1990, les entit&#233;s nomm&#233;es sont au centre de nombreux travaux en traitement de la langue
naturelle &#233;crite (r&#233;sum&#233; automatique, ontologies, . . .). Un tel d&#233;veloppement est, en grande partie, d&#251; &#224; l&#8217;impul-
sion donn&#233;e par de multiples campagnes d&#8217;&#233;valuation, qui ont accord&#233; une part importante &#224; leur identification
et utilisation au sein de leurs pistes tels que MUC (Named Entity task 1), TREC (avec la t&#226;che Question Answe-
ring (Voorhees, 1999)). . .
</p>
<p>En l&#8217;absence de corpus d&#8217;apprentissage, les premi&#232;res m&#233;thodes de recherche d&#8217;entit&#233;s nomm&#233;es, se basaient sur
l&#8217;utilisation de larges ensembles de patrons d&#8217;extraction (Nadeau &amp; Sekine, 2007) et aujourd&#8217;hui encore il est
conseill&#233; de proc&#233;der de la sorte si un corpus d&#8217;entra&#238;nement n&#8217;est pas disponible pour les types souhait&#233;s (Sekine
&amp; Nobata, 2004). Lorsque les premiers corpus d&#8217;apprentissage pour certains types (personne, lieu, organisation et
date) firent leur apparition, la plupart des m&#233;thodes d&#8217;apprentissage automatique furent utilis&#233;es pour ce probl&#232;me
telles que les mod&#232;les de Markov cach&#233;s (Bikel et al., 1997), les arbres de d&#233;cision (Sekine, 1998) ou encore les
SVMs (Asahara &amp; Matsumoto, 2003) et les CRFs (McCallum, 2003). Des m&#233;thodes dites semi-supervis&#233;es ont
aussi &#233;t&#233; &#233;tudi&#233;es telle le bootstrapping qui consiste &#224; d&#233;marrer d&#8217;un petit jeu d&#8217;exemples et de l&#8217;agrandir par
it&#233;rations successives en ayant recours &#224; divers crit&#232;res comme les relations syntaxiques (Cucchiarelli &amp; Velardi,
2001) ou synonymiques (Pasca et al., 2006).
</p>
<p>La reconnaissance des entit&#233;s nomm&#233;es est centrale dans bon nombre de probl&#233;matiques en recherche d&#8217;informa-
tion comme par exemple Questions-R&#233;ponses (QR). Cette t&#226;che a connu un fort engouement ces derni&#232;res ann&#233;es.
En effet, on a pu voir plusieurs campagnes d&#8217;&#233;valuation internationales en faire un sujet important (TREC, CLEF,
INEX, Equer, . . .). Un syst&#232;me QR pr&#233;sente au moins deux diff&#233;rences par rapport &#224; un syst&#232;me de recherche d&#8217;in-
formation (RI). La premi&#232;re est la formulation de la requ&#234;te qui est une phrase interrogative en langage naturel
(par exemple &quot;Je veux conna&#238;tre les sp&#233;cifications techniques du nouveau Blackberry&quot;). Cela a de l&#8217;int&#233;r&#234;t pour
les utilisateurs (la formulation de requ&#234;tes efficaces sous forme de mots cl&#233;s est une t&#226;che difficile) et pour les
syst&#232;mes (apport d&#8217;un contexte et d&#8217;informations suppl&#233;mentaires). La seconde principale diff&#233;rence est la forme
</p>
<p>1. http ://cs.nyu.edu/faculty/grishman/NEtask20.book_1.html</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LUDOVIC BONNEFOY, PATRICE BELLOT, MICHEL BENOIT
</p>
<p>des r&#233;sultats : un moteur de RI va retourner une liste de documents, dans lesquels l&#8217;utilisateur va &#234;tre en charge de
trouver la r&#233;ponse par lui m&#234;me, tandis qu&#8217;en QR, le syst&#232;me doit retourner une s&#233;rie de r&#233;ponses pr&#233;cises (c&#8217;est-
&#224;-dire des cha&#238;nes correspondant exactement &#224; ce que l&#8217;utilisateur recherche), g&#233;n&#233;ralement des entit&#233;s nomm&#233;es.
C&#8217;est pourquoi une identification correcte (localisation et typage) des entit&#233;s nomm&#233;es est une &#233;tape vitale.
</p>
<p>La principale barri&#232;re &#224; l&#8217;utilisation des m&#233;thodes &#233;voqu&#233;es pr&#233;c&#233;demment (patrons d&#8217;extraction et m&#233;thodes
d&#8217;apprentissage) est la constitution des ressources propres &#224; chaque domaine d&#8217;application. En effet, les m&#233;thodes
supervis&#233;es apprennent diff&#233;rents param&#232;tres sur des corpus annot&#233;s manuellement, o&#249; chaque entit&#233; d&#8217;un des
types souhait&#233;s est relev&#233;e. On comprend que lorsque le nombre de types &#224; reconna&#238;tre augmente, le temps d&#8217;an-
notation de tels corpus devient r&#233;dhibitoire. De mani&#232;re similaire, la cr&#233;ation de patrons d&#8217;extraction de plus en
plus pr&#233;cis et difficile &#224; maintenir. Dans cet article, nous proposons une m&#233;thode non-supervis&#233;e compl&#233;mentaire
&#224; ces outils, ayant pour but de d&#233;terminer si une entit&#233; (dans son sens le plus large, c&#8217;est-&#224;-dire toute r&#233;ponse qu&#8217;un
syst&#232;me de questions-r&#233;ponses pourrait &#234;tre amen&#233; &#224; devoir retrouver) est d&#8217;un type donn&#233; et &#224; quel degr&#233;.
</p>
<p>L&#8217;objectif de cette m&#233;thode est de mesurer la proximit&#233; d&#8217;un entit&#233; et d&#8217;un type mais aussi de deux entit&#233;s entre
elles. Cette probl&#233;matique est int&#233;ressante comme l&#8217;atteste la cr&#233;ation en 2009 de la piste Entity Relation Finding
&#224; TREC, sa poursuite en 2010 et 2011 2.
</p>
<p>Un des points les plus importants, est d&#8217;arriver &#224; traiter ce probl&#232;me pour n&#8217;importe quel type d&#8217;entit&#233;s et pas
seulement les quelques types de tr&#232;s haut niveau (personnes, lieux, organisation, dates,. . .) que l&#8217;on a l&#8217;habitude
de rencontrer depuis les campagnes MUC (Nadeau &amp; Sekine, 2007) ou les quelques dizaines de types plus fins
(c&#8217;est-&#224;-dire des sous cat&#233;gories des types de haut niveau (Sekine et al., 2002)) qu&#8217;exploitent certains syst&#232;mes.
Notre objectif est de pouvoir traiter de mani&#232;re &#233;gale et automatique des types g&#233;n&#233;raux tels que &quot;esp&#232;ce animale&quot;
ou beaucoup plus fins, tels que &quot;co&#233;quipier&quot; ou encore &quot;distilleries de whisky&quot;.
</p>
<p>Les applications d&#8217;une telle m&#233;thode sont multiples. Tout d&#8217;abord la validation d&#8217;un type attribu&#233; &#224; une entit&#233; pou-
vant servir &#224; &#233;liminer par exemple des r&#233;ponses candidates dans un syst&#232;me de question-r&#233;ponse. Un deuxi&#232;me
exemple d&#8217;application serait la construction automatique de lexique d&#8217;entit&#233; nomm&#233;es ou le peuplement auto-
matique d&#8217;ontologies (du moins pour les relations is-A). Enfin, l&#8217;on pourrait envisager par exemple, une aide &#224;
l&#8217;annotation semi-manuelle d&#8217;entit&#233; nomm&#233;es avec des types s&#233;mantiques fins, o&#249; l&#8217;utilisateur s&#233;lectionnerait les
types corrects parmiles premiers types retourn&#233;s par la m&#233;thode.
</p>
<p>Cet article est compos&#233; de la mani&#232;re suivante : dans une premi&#232;re partie, nous pr&#233;sentons une solution pour me-
surer le degr&#233; d&#8217;appartenance d&#8217;une entit&#233; nomm&#233;e &#224; un type donn&#233; de mani&#232;re non-supervis&#233;e. Dans la seconde
partie, nous proposons un cadre d&#8217;&#233;valuation et discutons les r&#233;sultats obtenus par notre proposition.
</p>
<p>2 Mesure de la proximit&#233; s&#233;mantique d&#8217;une entit&#233; et d&#8217;un type donn&#233;
</p>
<p>Comme nous l&#8217;avons &#233;voqu&#233; plus haut, nous aspirons ici &#224; une m&#233;thode efficace pour d&#233;terminer si une entit&#233;
est d&#8217;un type donn&#233; sans apprentissage au pr&#233;alable, afin de se passer de corpus co&#251;teux et limitant le nombre de
types que l&#8217;on peut traiter. C&#8217;est pourquoi nous avons opt&#233; pour une approche orient&#233;e Web.
</p>
<p>Ce travail part de plusieurs constats formul&#233;s apr&#232;s une analyse manuelle des pages Web retourn&#233;es par des mo-
teurs de recherche du Web lorsqu&#8217;on les interroge avec des entit&#233;s ou leurs types. Nous nous sommes aper&#231;u que
les pages associ&#233;es &#224; chaque type avaient tendance &#224; poss&#233;der un vocabulaire sp&#233;cifique, c&#8217;est-&#224;-dire que certains
mots avaient un nombre d&#8217;occurrences largement sup&#233;rieur &#224; celui qui est le leur dans un corpus g&#233;n&#233;rique (en-
semble tr&#232;s large de documents, traitant de toutes sortes de sujets) et qu&#8217;au contraire, certains mots n&#8217;apparaissent
pas ou peu. Par exemple, pour le type &quot;rasoir &#233;lectrique&quot;, certains mots comme &quot;rasoir&quot;, &quot;autonomie&quot;, &quot;tondeuse&quot;,
&quot;rasage&quot;. . . sont tr&#232;s fr&#233;quents dans les pages Web retourn&#233;es par le moteur de recherche alors qu&#8217;ils sont plut&#244;t
rares dans un corpus g&#233;n&#233;rique.
</p>
<p>En &#233;tudiant les pages Web associ&#233;es &#224; des entit&#233;s, nous avons v&#233;rifi&#233; que, pour chacune, l&#8217;on obtenait des pro-
babilit&#233;s d&#8217;apparition des mots g&#233;n&#233;ralement &#233;loign&#233;es de celles que l&#8217;on trouve dans un corpus g&#233;n&#233;rique (par
exemple pour iPod certains mot comme &quot;apple&quot;,&quot;mp3&quot;,&quot;musique&quot;,&quot;&#233;couteurs&quot;,&quot;media&quot;, . . . ont une probabilit&#233;
d&#8217;apparition &#233;lev&#233;e).
</p>
<p>Notre derni&#232;re observation est que la distribution des probabilit&#233;s d&#8217;apparition des mots, dans les pages associ&#233;es
&#224; une entit&#233; donn&#233;e, est proche de celle des mots dans les pages Web associ&#233;es au type la caract&#233;risant le plus
</p>
<p>2. http ://ilps.science.uva.nl/trec-entity/2010/11/plans-for-entity-2011/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>MESURE NON SUPERVIS&#201;E DE L&#8217;APPARTENANCE D&#8217;UNE ENTIT&#201; &#192; UN TYPE
</p>
<p>(par exemple, pour un &quot;Philips HQ 6990/33&quot; on a un ensemble de mots comme &quot;Philips&quot;,&quot;rasoir&quot;,&quot;&#233;lectrique&quot;,
&quot;confortable&quot;,&quot;rasage&quot;. . .qui ont une fr&#233;quence &#233;lev&#233;e et qui est proche de l&#8217;ensemble de mots r&#233;cup&#233;r&#233; pour
&quot;rasoir &#233;lectrique&quot;).
</p>
<p>L&#8217;id&#233;e de la m&#233;thode que nous avons mise en &#339;uvre d&#233;coule de ces observations. Elle consiste &#224; comparer le
mod&#232;le de langage LE (c&#8217;est-&#224;-dire la distribution de probabilit&#233; des mots dans une collection) associ&#233; &#224; une
entit&#233; donn&#233;e &#224; un mod&#232;le de langage Ltype associ&#233; &#224; un type d&#8217;entit&#233; donn&#233;.
</p>
<p>Tout d&#8217;abord il faut collecter deux ensembles de documents, un premier li&#233; &#224; une entit&#233; (ex : &quot;Isaac Asimov&quot;) et
un second correspondant au type que l&#8217;on veut tester (ex : &quot;science-fiction writers&quot;). Ces documents seront ici des
pages Web r&#233;cup&#233;r&#233;es en interrogeant un moteur de recherche. Ensuite, calculer la distribution de probabilit&#233; des
mots pour chacun de ces deux ensembles et les lisser avec le lissage de Dirichlet.
</p>
<p>p&#8242;(w|E) =
{
ps(w|E) si w est pr&#233;sent dans un ensemble de pages Web E
&#945;dp(w|C) sinon (1)
</p>
<p>o&#249; p&#8242;(w|E) est la probabilit&#233; du mot w dans un ensemble de pages Web E, ps(w|E) est la probabilit&#233; liss&#233;e de w,
p(w|C) est la probabilit&#233; de w dans une collection C (consiste ici en 10% du corpus ClueWeb09B 3 soit environ 5
millions de pages Web choisies al&#233;atoirement). La probabilit&#233; p(w|C) est liss&#233;e avec un lissage de Laplace (donne
un nombre d&#8217;occurences de 1 &#224; un mot non pr&#233;sent et rajoute 1 &#224; un mot pr&#233;sent) et &#945;d est un facteur. ps(w|E) et
&#945;d sont estim&#233;es de la mani&#232;re suivante :
</p>
<p>ps(w|E) = tf(w,E) + &#181;.p(w|C)&#8721;
w&#8242;&#8712;V tf(w&#8242;, E) + &#181;
</p>
<p>&#945;d =
&#181;&#8721;
</p>
<p>w&#8712;V tf(w,E) + &#181;
(2)
</p>
<p>o&#249; tf(w,E) est le nombre d&#8217;occurrences du mot w dans l&#8217;ensemble E, V est l&#8217;ensemble des mots w&#8242; pr&#233;sents
dans E et &#181; est un facteur dont la valeur est empiriquement fix&#233;e &#224; 2000 (valeur choisie par (Chen &amp; Goodman,
1998) pour de larges collections journalistiques).
</p>
<p>L&#8217;ultime &#233;tape est la comparaison des probabilit&#233;s p&#8242;E d&#8217;apparition des mots dans les pages Web associ&#233;es &#224;
l&#8217;entit&#233; &#224; celles p&#8242;type des mots dans les pages Web relatives au type. Pour cela nous calculons la divergence de
Kullback-Leibler (KLD) entre les deux mod&#232;les :
</p>
<p>KLD(E, type) =
&#8721;
i
</p>
<p>p&#8242;E(i).log
p&#8242;E(i)
p&#8242;type(i)
</p>
<p>(3)
</p>
<p>o&#249;KLD(E, type) est la divergence de Kullback-Leibler pour une entit&#233;E et un type donn&#233;, p&#8242;E(i) (resp. p
&#8242;
type(i))
</p>
<p>est la probabilit&#233; d&#8217;apparition du ie mot dans les documents associ&#233;s &#224; l&#8217;entit&#233; E (resp. au type).
</p>
<p>Cette m&#233;thode propose ainsi une mani&#232;re de calculer le degr&#233; d&#8217;appartenance de n&#8217;importe quelle entit&#233; donn&#233;e &#224;
n&#8217;importe quel type donn&#233;.
</p>
<p>3 R&#233;sultats
</p>
<p>Il n&#8217;existe que tr&#232;s peu de travaux qui se proposent de mesurer le degr&#233; d&#8217;appartenance d&#8217;une entit&#233; &#224; n&#8217;importe
quel type (Pasca, 2004) (Talukdar &amp; Pereira, 2010). Cela a pour cons&#233;quence, qu&#8217;il n&#8217;existe pas &#224; notre connais-
sance de jeux de donn&#233;es de r&#233;f&#233;rence d&#233;di&#233;es &#224; l&#8217;&#233;valuation de cette t&#226;che et qui soient disponibles. Pour cette
raison nous avions d&#233;cid&#233; de d&#233;terminer l&#8217;int&#234;ret de notre approche indirectement, en mesurant son impact dans un
syst&#232;me de type QR. Pour cela nous avions particip&#233; &#224; la t&#226;che Entity &#224; Trec 2010. Bien que les r&#233;sultats pr&#233;sent&#233;s
dans (Bonnefoy et al., 2011) aient montr&#233; une am&#233;lioration, il fut difficile d&#8217;en mesurer exactement sa respon-
sabilit&#233; tant le nombre de param&#232;tres &#224; prendre en compte dans de tels syst&#232;mes est important. Dans cet article,
afin d&#8217;avoir une &#233;valuation de la qualit&#233; intrins&#232;que de notre proposition, nous avons construit un jeu d&#8217;&#233;valua-
tion. Nous avons pour cela utilis&#233; DBPedia qui met &#224; disposition un grand nombre d&#8217;entit&#233;s associ&#233;es &#224; plusieurs
types (sp&#233;cifi&#233;s dans diff&#233;rentes ontologies). Nous avons collect&#233; 100 diff&#233;rentes entit&#233;s (al&#233;atoirement) de cette
base ainsi que les types qui leur sont associ&#233;s et d&#233;finis dans l&#8217;ontologie l&#233;g&#232;re owl. Cette ontologie d&#233;finit 273
</p>
<p>3. http ://boston.lti.cs.cmu.edu/Data/clueWeb09/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LUDOVIC BONNEFOY, PATRICE BELLOT, MICHEL BENOIT
</p>
<p>types diff&#233;rents, ainsi que leurs liens entre eux 4. Par ce biais il est possible d&#8217;associer de 1 &#224; 4 types (profondeur
maximum de l&#8217;ontologie) par entit&#233;, pour une moyenne de 2,83 types.
</p>
<p>Avec ces &#233;l&#233;ments, l&#8217;&#233;valuation consiste &#224; classer les 273 types, pour chaque entit&#233;, en fonction de son degr&#233;
d&#8217;appartenance &#224; chacun d&#8217;entre eux (les plus pertinents en haut du classement). Trois mesures nous ont sembl&#233;
int&#233;ressantes. La premi&#232;re est la pr&#233;cision &#224; 1 (P@1) qui va permettre d&#8217;&#233;valuer la capacit&#233; du syst&#232;me &#224; ramener
un type correct en premi&#232;re position. La seconde est la moyenne des r&#233;ciproques des rangs 5 (MRR) qui est
l&#8217;inverse du rang moyen auquel le premier &#233;l&#233;ment correct est retrouv&#233;. La derni&#232;re est la pr&#233;cision interpol&#233;e
pour un rappel de 1 (iPR1) qui permet d&#8217;avoir le rang moyen auquel tous les &#233;l&#233;ments corrects ont &#233;t&#233; ramen&#233;s.
</p>
<p>L&#8217;&#233;valuation de notre contribution va se faire au regard de deux diff&#233;rentes &quot;baselines&quot;. La premi&#232;re, tr&#232;s simple
et qui fera office de borne inf&#233;rieure, consiste &#224; trier les 273 types pour chaque entit&#233;, de mani&#232;re al&#233;atoire.
Cependant un seul classement al&#233;atoire pourrait ne pas &#234;tre repr&#233;sentatif, c&#8217;est pourquoi nous avons d&#233;cid&#233; que
plut&#244;t que d&#8217;effectuer un tel classement, nous mesurerions la probabilit&#233; d&#8217;obtenir avec des tirages al&#233;atoires un
classement aussi &quot;bon&quot; que le meilleur des notres. Ceci peut &#234;tre estim&#233; avec la fonction de r&#233;partition d&#8217;une
fonction g&#233;om&#233;trique. Elle repr&#233;sente la somme des probabilit&#233;s d&#8217;avoir au minimum autant de bonnes r&#233;ponses
en x tirages al&#233;atoires (donc au rang x). Cette &quot;baseline&quot; sera d&#233;sign&#233;e &#224; partir de ce point sous le nom Al&#233;atoire.
</p>
<p>La deuxi&#232;me baseline consiste en l&#8217;utilisation de patrons d&#8217;extractions sp&#233;cifiquements &#233;tudi&#233;s pour d&#233;terminer les
relations is-A entre une entit&#233; et un type ((Hearst, 1992), (Pasca, 2004),. . .) comme &quot;type such as entit&#233;&quot;. L&#8217;id&#233;e de
la baseline est de compter le nombre de pages Web retrouv&#233;es par un moteur de recherche lorsque l&#8217;on lui soumet
la requ&#234;te &quot;type * entit&#233;&quot;, qui signifie que nous recherchons tous les documents dans lesquels on retrouve le type
suivi de l&#8217;entit&#233; et s&#233;par&#233;s au maximum par un mot (&quot;including&quot; par exemple) et de classer les types par ordre
d&#233;croissant. Cette m&#233;thode est appel&#233;e Patron.
</p>
<p>Pour cette premi&#232;re &#233;valuation, nous souhaitons &#233;tudier la qualit&#233; de notre mod&#232;le avec diff&#233;rentes variations. Nous
avons imagin&#233; quatre voies qui diff&#232;rent sur le jeu de documents utilis&#233; pour estimer les distributions de mots.
Trois diff&#233;rentes mani&#232;res de construire un jeu de documents ont &#233;t&#233; envisag&#233;es. Les deux premi&#232;res consistent
&#224; r&#233;cup&#233;rer les pages Web ou les snippets retourn&#233;s par un moteur de recherche (ici Yahoo !) en lui soumettant
le type ou l&#8217;entit&#233;. La troisi&#232;me voie est sp&#233;cifique au jeu de documents relatif au type. Dans les deux m&#233;thodes
pr&#233;c&#233;dentes, nous r&#233;cup&#233;rions des documents en relation avec le type. Nous proposons ici de r&#233;cup&#233;rer des pages
chacune d&#233;di&#233;e &#224; une entit&#233; du type. Pour cela nous r&#233;cup&#233;rons des entit&#233;s du type et leur page Wikip&#233;dia (via
DBPedia). Ici, nous ne r&#233;cup&#233;rons pas la premi&#232;re page Web que pourrait nous retourner un moteur de recherche
car nous ne pourrions &#234;tre s&#251;r qu&#8217;il s&#8217;agit bien d&#8217;une page li&#233;e &#224; cette entit&#233; et non pas &#224; un homonyme. Nous
ferons r&#233;f&#233;rence &#224; ces trois variantes sous les noms : sWeb, sSnippet et sEntities.
</p>
<p>Les quatre premi&#232;res m&#233;thodes que nous allons comparer proposent diff&#233;rentes combinaisons de ces trois mani&#232;res
de construire les jeux de documents. Les m&#233;thodes sont sWeb, sSnippet, sWeb/sSnippet et sEntities/sWeb. Le nom
d&#233;crit la m&#233;thode utilis&#233;e pour la r&#233;cup&#233;ration des documents pour le type et l&#8217;entit&#233; (s&#233;par&#233; par &quot;/&quot;) 6.
</p>
<p>Methodes Baselines
Mesure sWeb sSnippet sWeb/sSnippet sEntities/sWeb Al&#233;atoire Patron
MRR 0,3410 (2,93) 0,4224 (2,36) 0,3609 (2,77) 0,2299 (4,35) &lt; 0,0020 0,3019 (3,31)
iPR1 0,0693 (40,84) 0,0753 (37,58) 0,0569 (49,74) 0,1185 (23,88) &lt; 0,0246 0,0627 (44,34)
</p>
<p>TABLE 1 &#8211; &#201;valuation avec la moyenne des r&#233;ciproques des rangs (MRR) et la pr&#233;cision interpol&#233;e pour un rappel
de 1 (iPR1) compar&#233; aux deux &quot;baselines&quot;. Pour chaque m&#233;thode, nous utilisons 100 pages Web ou snippets.
Al&#233;atoire est calcul&#233; par rapport &#224; la meilleure m&#233;thode pour la mesure &#233;tudi&#233;e. Le score entre parenth&#232;ses est le
rang moyen correspondant au score associ&#233;.
</p>
<p>Les premiers r&#233;sultats Tableau 1 montrent plusieurs choses int&#233;ressantes. La principale est que tous les essais
de notre proposition obtiennent de meilleurs r&#233;sultats que les &quot;baselines&quot;. Par exemple, obtenir un classement au
moins aussi bon que sSnippet, au regard de la moyenne des r&#233;ciproques des rang, en classant al&#233;atoirement les
types pour les entit&#233;s, n&#8217;a que 0,2% chances de se r&#233;aliser. De plus elle est meilleure que la baseline utilisant des
patrons inspir&#233;s de (Hearst, 1992) qui pourtant permettent d&#8217;obtenir dans de nombreuses t&#226;ches des r&#233;sultats &#233;tat
</p>
<p>4. http ://mappings.dbpedia.org/server/ontology/classes
5. MRR = 1
</p>
<p>Q
</p>
<p>&#8721;|Q|
i=1
</p>
<p>1
ranki
</p>
<p>6. L&#8217;absence de &quot;/&quot; signifie que la m&#234;me m&#233;thode est utilis&#233;e pour les deux &#233;l&#233;ments (sWeb = sWeb/sWeb et sSnippet = sSnippet/sSnippet).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>MESURE NON SUPERVIS&#201;E DE L&#8217;APPARTENANCE D&#8217;UNE ENTIT&#201; &#192; UN TYPE
</p>
<p>de l&#8217;art. La deuxi&#232;me observation est qu&#8217;il est pr&#233;f&#233;rable d&#8217;utiliser les snippets &#224; la place des pages Web pour
construire les jeux de documents. Cela est en partie d&#251; au bruit que les pages Web contiennent. Une explication
compl&#233;mentaire serait que les pages Web avec un rang &#233;lev&#233; ne sont pas (ou peu) relatives &#224; la requ&#234;te et leur
utilisation modifient &#224; ce point les distributions de mots, qu&#8217;elles ne correspondent plus aux types et aux entit&#233;s.
</p>
<p>Pour valider cette hypoth&#232;se, nous avons test&#233; deux autres m&#233;thodes : sWeb10 et sSnippet10. Elles diff&#232;rent de
sWeb et sSnippet dans le sens o&#249; seuls les 10 premiers &#233;l&#233;ments retourn&#233;s par le moteur de recherche sont utilis&#233;s
pour construire les jeux de documents. Les r&#233;sultats sont pr&#233;sent&#233;s Tableau 2. La comparaison des deux premi&#232;res
colonnes donne l&#8217;avantage &#224; l&#8217;utilisation de 10 pages Web au lieu de 100. Cela confirme notre intuition que les
pages Web avec un rang &#233;lev&#233; ne sont pas assez pertinentes et perturbent la mise au point d&#8217;un mod&#232;le li&#233; &#224; un type
ou une entit&#233;. Cette tendance n&#8217;est pas retrouv&#233;e en ce qui concerne l&#8217;utilisation de snippets car nous disposons
alors de trop peu d&#8217;information pour estimer une distribution des mots pertinente.
</p>
<p>Mesure sWeb sWeb10 sSnippet sSnippet10
MRR 0,3410 (2,93) 0,3756 (2,66) 0,4224 (2,36) 0,3550 (2,82)
iPR1 0,0693 (40,84) 0,0781 (36,24) 0,0753 (37,58) 0,0690 (41,01)
</p>
<p>TABLE 2 &#8211; &#201;valuation pour sWeb et sSnippet de l&#8217;impact du nombre de pages Web utilis&#233;es pour construire les
jeux de documents. Pour chaque m&#233;thode, nous comparons une version avec 100 ou 10 &#233;l&#233;ments (pages Web ou
snippets). Le score entre parenth&#232;ses est le rang moyen correspondant au score.
</p>
<p>Dans le Tableau 1, nous pouvons aussi remarquer (colonne 4) que l&#8217;utilisation de pages Wikip&#233;dia d&#8217;entit&#233;s d&#8217;un
type donn&#233; pour constituer le jeu de documents se situe largement en de&#231;a des autres m&#233;thodes pour la moyenne
des r&#233;ciproques des rangs (presque moiti&#233; moins qu&#8217;avec les snippets). Il est alors surprenant de remarquer qu&#8217;elle
est la meilleure pour la pr&#233;cision interpol&#233;e (iPR1) (environ 1,5 fois sup&#233;rieur &#224; celui des snippets).
</p>
<p>Dans le Tableau 3 nous cherchons &#224; d&#233;terminer quel est le rang moyen o&#249; le type le plus fin (celui de plus bas
niveau) d&#8217;une entit&#233; est retrouv&#233;. Une &#233;valuation dans ce sens a &#233;t&#233; faites pour sWeb et sSnippet sous les noms
sWebMax et sSnippetMax. On peut tout d&#8217;abord constater que les types les plus fins sont retrouv&#233;s 1 fois sur 4 en
premi&#232;re position (resp. environ 1/5) lorsque l&#8217;on utilise les snippets (resp. les pages Web). De plus, les r&#233;sultats
obtenus pour MRR montrent qu&#8217;en moyenne le type le plus fin est retrouv&#233; dans les premiers rangs et que cela est
tr&#232;s proche du rang o&#249; est trouv&#233;e la premi&#232;re r&#233;ponse correcte pour sWeb et sSnippet. Dans le Tableau 1, l&#8217;iPR1
nous indique que tous les bons types d&#8217;une entit&#233; sont retrouv&#233;s aux alentours du rang 40. On peut donc d&#233;duire de
ces deux informations que ce sont les types de plus haut niveau (ex : personne, lieu. . .) qui sont les plus difficiles
&#224; retrouver. La raison d&#8217;une telle diff&#233;rence est que le vocabulaire dans les documents li&#233;s aux types fins est plus
pr&#233;cis, donc plus discriminant, qu&#8217;il ne l&#8217;est dans les documents li&#233;s aux types g&#233;n&#233;raux. Ceci positionne notre
proposition non pas comme une alternative aux syst&#232;mes de reconnaissance d&#8217;entit&#233;s nomm&#233;es mais comme un
compl&#233;ment pour caract&#233;riser plus finement des entit&#233;s.
</p>
<p>Pourquoi l&#8217;utilisation des pages Wikip&#233;dia d&#8217;entit&#233;s du type &#233;tudi&#233; est-il moins performant pour trouver les types
fins que les autres m&#233;thodes et pourquoi l&#8217;est-il plus pour les types plus larges ? Pour le premier &#233;l&#233;ment, la raison
est probablement qu&#8217;&#233;tant donn&#233; que nous sommes dans le cas de documents encyclop&#233;diques, les r&#233;dacteurs
tendent &#224; &#233;viter les r&#233;p&#233;titions et les mots sp&#233;cifiques (&#224; une entit&#233; ou un type) ne sont pas vus plusieurs fois
mais se retrouvent sous la forme de synonymes. Le deuxi&#232;me, s&#8217;explique par le formatage sp&#233;cifique des pages
Wikip&#233;dia. En effet toutes les fiches concernant, par exemple, des personnes, commencent avec un texte du type :
&quot;X est n&#233; en DD-MM-YYYY &#224; Y&quot; et poss&#232;dent des infobox communes.
</p>
<p>Mesure sWeb sWebMax sSnippet sSnippetMax
P@1 0,2348 0,1900 0,2762 0,2500
MRR 0,3410 (2,93) 0,2616 (3,82) 0,4224 (2,36) 0,3159 (3,17)
</p>
<p>TABLE 3 &#8211; Mesure de la pr&#233;cision au rang 1 et la moyenne des r&#233;ciproques des rangs (MRR). Les m&#233;thodes
sWebMax et sSnippetMax consid&#232;rent uniquement le type le plus fin d&#8217;une entit&#233; comme correct. Le score entre
parenth&#232;ses est le rang moyen correspondant au score associ&#233;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LUDOVIC BONNEFOY, PATRICE BELLOT, MICHEL BENOIT
</p>
<p>4 Conclusions et perspectives
</p>
<p>Nous avons pr&#233;sent&#233; une m&#233;thode non-supervis&#233;e pour estimer dans quelle mesure une entit&#233; est d&#8217;un type donn&#233;
(quel qu&#8217;il soit) en comparant les distributions de mots dans des documents li&#233;s &#224; l&#8217;entit&#233; et li&#233;s au type.
</p>
<p>L&#8217;&#233;valuation que nous avons r&#233;alis&#233;e, sur 100 entit&#233;s et 273 types, montre que cette voie est prometteuse est permet
d&#8217;obtenir des r&#233;sultats int&#233;ressants. Nous avons montr&#233; que notre proposition fonctionne mieux sur des types fins
et sp&#233;cifiques que sur des types trop larges et pourrait se situer comme compl&#233;ment aux outils de reconnaissance
d&#8217;entit&#233;s nomm&#233;es existants.
</p>
<p>En terme de perspectives, nous consid&#233;rons diff&#233;rentes mani&#232;res de calculer les distributions de probabilit&#233; (concepts
s&#233;mantiques, concepts latents, utilisation de listes de mots outils, suppression des mots uniques. . .), diff&#233;rentes
techniques de lissage (par exemple bas&#233;es sur la hi&#233;rarchie des types), de calcul de similarit&#233; entre distributions,
l&#8217;utilisation du contexte d&#8217;apparition de l&#8217;entit&#233;. . .
</p>
<p>Retenons enfin que notre m&#233;thode de mesure d&#8217;appartenance d&#8217;une entit&#233; &#224; un type poss&#232;de des applications
int&#233;ressantes pour l&#8217;aide &#224; la constitution de bases de connaissances puisqu&#8217;elle pourrait permettre d&#8217;identifier,
&#224; partir d&#8217;un exemple (instance) et du nom de sa cat&#233;gorie (concept), d&#8217;autres instances similaires ou proches.
L&#8217;&#233;tude des &#233;l&#233;ments linguistiques ayant permis cette identification pourrait &#224; son tour conduire &#224; d&#233;finir les
contextes d&#8217;apparition possibles des instances ainsi que certaines de leurs propri&#233;t&#233;s ontologiques. Tout cela fait
l&#8217;objet de nos travaux actuels.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ASAHARA M. &amp; MATSUMOTO Y. (2003). Japanese named entity extraction with redundant morphological
analysis. Human Language Technology conference - North American chapter of the ACL.
BIKEL D., MILLER S., SCHWARTZ R. &amp; WEISCHEDEL R. (1997). Nymble : a high-performance learning
name-finder. Proc. Conference on Applied Natural Language Processing.
BONNEFOY L., BELLOT P. &amp; BENOIT M. (2011). Une approche non supervis&#233;e pour le typage et la validation
d&#8217;une r&#233;ponse &#224; une question en langage naturel : application &#224; la t&#226;che entity de trec 2010. Huiti&#232;me &#233;dition de
la COnf&#233;rence en Recherche d&#8217;Information et Applications.
CHEN S. F. &amp; GOODMAN J. (1998). An empirical study of smoothing techniques for language modeling.
CUCCHIARELLI A. &amp; VELARDI P. (2001). Unsupervised named entity recognition using syntactic and semantic
contextual evidence. Computational Linguistics 27 :1.123-131, Cambridge : MIT Press.
HEARST M. (1992). Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th
International Conference on Computational Linguistics (COLING-92), 539&#8211;545.
MCCALLUM A. (2003). Early results for named entity recognition with conditional random fields, features
induction and web-enhanced lexicons. Proc. Conference on Computational Natural Language Learning.
NADEAU D. &amp; SEKINE S. (2007). A survey of named entity recognition and classification. Linguisticae Inves-
tigationes, Vol. 30, No. 1. (January 2007), pp. 3-26.
PASCA M. (2004). Acquisition of categorized named entities for web search. 2004 ACM CIKM International
Conference on Information and Knowledge Management, Washington, DC, USA, November 8-13.
PASCA M., LIN D., BIGHAM J., LIFCHITS A. &amp; JAIN A. (2006). Organizing and searching the world wide web
of facts-step one : The one-million fact extraction challenge. Proc. National Conference on Artificial Intelligence.
SEKINE S. (1998). Description of the japanese ne system used for met-2. Message Understanding Conference.
SEKINE S. &amp; NOBATA C. (2004). Definition, dictionaries and tagger for extended named entity hierarchy. Proc.
Conference on Language Resources and Evaluation.
SEKINE S., SUDO K. &amp; NOBATA C. (2002). Extended named entity hierarchy. Proceedings of 3rd International
Conference on Language Resources and Evaluation (LREC&#8217;02).
TALUKDAR P. P. &amp; PEREIRA F. (2010). Experiments in graph-based semi-supervised learning methods for
class-instance acquisition. Proceedings of the 48th Annual Meeting of the Association for Computational Lin-
guistics (2010), pp. 1473-1481.
VOORHEES E. M. (1999). The trec-8 question answering track report. NIST Special Publication 500-246 : The
Eighth Text REtrieval Conference (TREC-8).</p>

</div></div>
</body></html>