TALN 2011, Montpellier, 27juin — 1"'ju1'11et 2011

Mesure non-supervisée du degré d’appartenance d’une entité £1 un type

Ludovic Bonnefoylrz, Patrice Bellotl, Michel Benoitz
(1) Université d’Avignon - CERI/LIA, Agroparc — B.P. 1228, 84911 Avignon Cedex 9
(2) iSmart, Le Mercure A, 13851 Aix-en-Provence Cedex 3
patrice.bel1ot@univ-avignon.fr, {ludovic.bonnefoy,rr1ichel.benoit} @ismart.fr

Résﬂmé. La recherche d’ entites nommees a ete le suj et de nombreux travaux. Cependant, la construction des
ressources necessaires a de tels systemes reste un probleme maj eur. Dans ce papier, nous proposons une methode
complementaire aux outils capables de reconnaitre des entites de types larges, dont l’objectif est de determiner
si une entite est d’un type donne, et ce de maniere non—supervisee et quel que soit le type. Nous proposons pour
cela une approche basee sur la comparaison de modeles de langage estimes a partir du Web. L’interet de notre
approche est valide par une evaluation sur 100 entites et 273 types differents.

Abstract. Searching for named entities has been the subject of many researches. In this paper, we seek to
determine whether a named entity is of a given type and in what extent it is. We propose to address this issue by
an unsupervised Web oriented language modeling approach. The interest of it is demonstrated by our evaluation
on 100 entities and 273 different types.

M0tS-CléS 3 typage d’entites nommees, comparaison de distribution de mots, divergence de Kullback-
Leibler.

Keywords: named entity identiﬁcation, language modeling approach, Kullback—Leibler divergence.

1 Introduction

Depuis les annees 1990, les entites nommees sont au centre de nombreux travaux en traitement de la langue
naturelle ecrite (resume automatique, ontologies, .. .). Un tel developpement est, en grande partie, dﬁ a l’irnpul-
sion donnee par de multiples carnpagnes d’evaluation, qui ont accorde une part irnportante a leur identiﬁcation
et utilisation au sein de leurs pistes tels que MUC (Named Entity task 1), TREC (avec la tache Question Answe-
ring (Voorhees, 1999)). ..

En l’absence de corpus d’apprentissage, les premieres methodes de recherche d’entites nommees, se basaient sur
l’utilisation de larges ensembles de patrons d’extraction (Nadeau & Sekine, 2007) et aujourd’hui encore il est
conseille de proceder de la sorte si un corpus d’entrainement n’est pas disponible pour les types souhaites (Sekine
& Nobata, 2004). Lorsque les premiers corpus d’apprentissage pour certains types (personne, lieu, organisation et
date) ﬁrent leur apparition, la plupart des methodes d’apprentissage automatique furent utilisees pour ce probleme
telles que les modeles de Markov caches (Bikel et al., 1997), les arbres de decision (Sekine, 1998) ou encore les
SVMs (Asahara & Matsurnoto, 2003) et les CRFs (McCallum, 2003). Des methodes dites serni-supervisees ont
aussi ete etudiees telle le bootstrapping qui consiste a demarrer d’un petit jeu d’exemples et de l’agrandir par
iterations successives en ayant recours a divers criteres comme les relations syntaxiques (Cucchiarelli & Velardi,
2001) ou synonyrniques (Pasca et al., 2006).

La reconnaissance des entites nommees est centrale dans bon nombre de problematiques en recherche d’informa—
tion comme par exemple Questions—Reponses (QR). Cette tache a connu un fort engouement ces dernieres armees.
En effet, on a pu voir plusieurs carnpagnes d’evaluation intemationales en faire un sujet important (TREC, CLEF,
INEX, Equer, . . .). Un systeme QR presente au moins deux differences par rapport a un systeme de recherche d’in-
formation (RI). La premiere est la formulation de la requete qui est une phrase interrogative en langage naturel
(par exemple "Je veux connaitre les speciﬁcations techniques du nouveau Blackberry"). Cela a de l’interet pour
les utilisateurs (la formulation de requetes efﬁcaces sous forme de mots cles est une tache difﬁcile) et pour les
systemes (apport d’un contexte et d’informations supplementaires). La seconde principale difference est la forme

1. http ://cs.nyu.edu/faculty/grishman/NEtask20.book_1.htrnl

LUDOVIC BONNEFOY, PATRICE BELLOT, MICHEL BENOIT

des résultats : un moteur de RI Va retoumer une liste de documents, dans lesquels l’utilisateur Va etre en charge de
trouver la réponse par lui meme, tandis qu’en QR, le systeme doit retoumer une série de reponses precises (c’est—
a—dire des chaines correspondant exactement a ce que l’utilisateur recherche), généralement des entites nommées.
C’est pourquoi une identiﬁcation correcte (localisation et typage) des entités nommées est une étape Vitale.

La principale barriere a l’utilisation des methodes evoquées précedemment (patrons d’extraction et methodes
d’ apprentissage) est la constitution des ressources propres a chaque domaine d’application. En effet, les méthodes
supervisées apprennent djfférents parametres sur des corpus armotes manuellement, ou chaque entité d’un des
types souhaités est relevée. On comprend que lorsque le nombre de types a reconnaitre augmente, le temps d’an—
notation de tels corpus devient rédhibitoire. De maniere similaire, la creation de patrons d’ extraction de plus en
plus precis et difﬁcile a maintenir. Dans cet article, nous proposons une méthode non—supervisée complémentaire
a ces outils, ayant pour but de determiner si une entité (dans son sens le plus large, c’est—a—dire toute réponse qu’un
systeme de questions—réponses pourrait etre amené a devoir retrouver) est d’un type donné eta quel degré.

L’ obj ectif de cette méthode est de mesurer la proximité d’un entité et d’ un type mais aussi de deux entités entre
elles. Cette problématique est interessante comme l’atteste la creation en 2009 de la piste Entity Relation Finding
a TREC, sa poursuite en 2010 et 20112.

Un des points les plus importants, est d’arriVer a traiter ce probleme pour n’importe quel type d’entités et pas
seulement les quelques types de tres haut niveau (personnes, lieux, organisation, dates,. . .) que l’on a l’habitude
de rencontrer depuis les campagnes MUC (Nadeau & Sekine, 2007) ou les quelques dizaines de types plus ﬁns
(c’est—a—dire des sous categories des types de haut niveau (Sekine et al., 2002)) qu’exploitent certains systemes.
Notre obj ectif est de pouvoir traiter de maniere egale et automatique des types généraux tels que "espece animale"
ou beaucoup plus ﬁns, tels que "coéquipier" ou encore "distilleries de whisky".

Les applications d’une telle methode sont multiples. Tout d’ abord la Validation d’un type attribue a une entité pou-
Vant servir a éliminer par exemple des réponses candidates dans un systeme de question—reponse. Un deuxieme
exemple d’application serait la construction automatique de lexique d’entité nommées ou le peuplement auto-
matique d’ ontologies (du moins pour les relations is-A). Enﬁn, l’on pourrait envisager par exemple, une aide a
l’annotation semi-manuelle d’entite nommées avec des types semantiques ﬁns, ou l’utilisateur sélectionnerait les
types corrects parmiles premiers types retoumés par la méthode.

Cet article est compose de la maniere suivante : dans une premiere partie, nous présentons une solution pour me-
surer le degre d’appartenance d’une entité nommée a un type donné de maniere non—superVisée. Dans la seconde
partie, nous proposons un cadre d’éValuation et discutons les résultats obtenus par notre proposition.

2 Mesure de la proximité sémantique d’une entité et d’un type donné

Comme nous l’aVons évoque plus haut, nous aspirons ici a une methode efﬁcace pour determiner si une entité
est d’ un type donné sans apprentissage au préalable, aﬁn de se passer de corpus coﬁteux et limitant le nombre de
types que l’on peut traiter. C’est pourquoi nous avons opté pour une approche orientée Web.

Ce travail part de plusieurs constats formules apres une analyse manuelle des pages Web retoumées par des mo-
teurs de recherche du Web lorsqu’on les interroge avec des entités ou leurs types. Nous nous sommes apercu que
les pages associées a chaque type avaient tendance a posséder un Vocabulaire spéciﬁque, c’est—a—dire que certains
mots avaient un nombre d’ occurrences largement supérieur a celui qui est le leur dans un corpus génerique (en-
semble tres large de documents, traitant de toutes sortes de suj ets) et qu’au contraire, certains mots n’apparaissent
pas ou peu. Par exemple, pour le type "rasoir électrique ", certains mots comme "rasoir", "autonomie ", "tondeuse ",
"rasage ". .. sont tres frequents dans les pages Web retoumees par le moteur de recherche alors qu’ils sont plutot

rares dans un corpus génerique.

En étudiant les pages Web associées a des entités, nous avons Vériﬁé que, pour chacune, l’on obtenait des pro-
babilites d’apparition des mots généralement éloignées de celles que l’on trouve dans un corpus générique (par
H H H H’ H H

exemple pour iPod certains mot comme "apple , mp3 ", "musique , ecouteurs , media",  ont une probabilité
d’ apparition elevée).

Notre derniere observation est que la distribution des probabilités d’apparition des mots, dans les pages associees
a une entité donnee, est proche de celle des mots dans les pages Web associées au type la caracterisant le plus

2. http ://ilps.science.uva.nl/trec-entity/2010/1 1/plans-for-entity-201 1/

MESURE NON SUPERVISEE DE L’APPARTENANCE D’UNE ENTITE A UN TYPE

(par exemple, pour un "Philips HQ 6990/33" on a un ensemble de mots comme "Philips", "rasoir", "électrique ",
"confortable","rasage". . .qui ont une frequence elevée et qui est proche de l’ensemble de mots récupére pour
"rasoir électrique ").

L’idée de la methode que nous avons Inise en oeuvre découle de ces observations. Elle consiste a comparer le
modele de langage L E (c’est—a—dire la distribution de probabilité des mots dans une collection) associé a une
entite donnee a un modele de langage Ltype associe a un type d’entité donné.

Tout d’abord il faut collecter deux ensembles de documents, un premier he a une entité (ex : "Isaac Asimov") et
un second correspondant au type que l’on veut tester (ex : "science—ﬁction writers"). Ces documents seront ici des
pages Web récupérees en interrogeant un moteur de recherche. Ensuite, calculer la distribution de probabilité des
mots pour chacun de ces deux ensembles et les lisser avec le lissage de Dirichlet.

ps  si W est present dans un ensemble de pages Web E
o4dp(w|C') sinon

p’(w|E) ={ <1)

ou p’ est la probabilite du mot w dans un ensemble de pages Web E, ps  est la probabilite lissee de w,
p(w|C') est la probabilité de w dans une collection C’ (consiste ici en 10% du corpus ClueWeb09B 3 soit environ 5
millions de pages Web choisies aleatoirement). La probabilité p(w|C') est lissée avec un lissage de Laplace (donne
un nombre d’occurences de 1 a un mot non present et rajoute 1 a un mot present) et ad est un facteur. ps (w  et
04¢ sont estimées de la maniere suivante :

tf(wa E) + M-p(w|0) /J

Zw’eVtf(w/2E) +/.» C” = ZweVtf(wvE) +1» ‘2’

I>s(w|E) =
ou t f (w, E) est le nombre d’occurrences du mot w dans l’ensemble E, V est l’ensemble des mots w’ presents
dans E et ,u est un facteur dont la valeur est empiriquement ﬁxee a 2000 (valeur choisie par (Chen & Goodman,
1998) pour de larges collections joumalistiques).

L’ultime étape est la comparaison des probabilites pg d’apparition des mots dans les pages Web associees a
l’entité a celles pgw des mots dans les pages Web relatives au type. Pour cela nous calculons la divergence de
Kullback—Leibler (KLD) entre les deux modeles :
, . p’E(i)
KLD(E, type) = Z pE(z).1ogf (3)
7; ptype (1)

ou K LD(E , type) est la divergence de Kullback—Leibler pour une entité E et un type donne, pg  (resp. pg”, 
est la probabilite d’ apparition du 1'9 mot dans les documents associés a l’entite E (resp. au type).

Cette methode propose ainsi une maniere de calculer le degré d’appartenance de n’importe quelle entité donnée a
n’importe quel type donne.

3 Résultats

ll n’existe que tres peu de travaux qui se proposent de mesurer le degré d’appartenance d’une entité a n’importe
quel type (Pasca, 2004) (Talukdar & Pereira, 2010). Cela a pour consequence, qu’il n’existe pas a notre connais—
sance de jeux de données de reference dediées a l’évaluation de cette tache et qui soient disponibles. Pour cette
raison nous avions decide de determiner l’interet de notre approche indirectement, en mesurant son impact dans un
systeme de type QR. Pour cela nous avions participé a la tache Entity a Trec 2010. Bien que les résultats presentés
dans (Bonnefoy et al., 2011) aient montré une amelioration, il fut difﬁcile d’en mesurer exactement sa respon-
sabilité tant le nombre de parametres a prendre en compte dans de tels systemes est important. Dans cet article,
aﬁn d’avoir une evaluation de la qualité intrinseque de notre proposition, nous avons constr11it un jeu d’evalua—
tion. Nous avons pour cela utilise DBPedia qui met a disposition un grand nombre d’entités associées a plusieurs
types (speciﬁes dans differentes ontologies). Nous avons collecté 100 differentes entités (aléatoirement) de cette
base ainsi que les types qui leur sont associés et deﬁnis dans l’ontologie légere owl. Cette ontologie déﬁnit 273

3. http ://boston.lti.cs.cmu.edu/Data/clueWeb09/

LUDOVIC BONNEFOY, PATRICE BELLOT, MICHEL BENOIT

types differents, ainsi que leurs liens entre eux 4. Par ce biais il est possible d’associer de 1 £1 4 types (profondeur
maximum de l’ontologie) par entité, pour une moyenne de 2,83 types.

Avec ces elements, l’eValuation consiste £1 classer les 273 types, pour chaque entité, en fonction de son degré
d’ appartenance £1 chacun d’ entre eux (les plus pertinents en haut du classement). Trois mesures nous ont semblé
interessantes. La premiere est la precision £1 1 (P@ 1) qui Va permettre d’eValuer la capacite du systeme £1 ramener
un type correct en premiere position. La seconde est la moyenne des réciproques des rangs5 (MRR) qui est
l’inVerse du rang moyen auquel le premier element correct est retrouvé. La demiere est la precision interpolée
pour un rappel de 1 (iPR1) qui permet d’aVoir le rang moyen auquel tous les elements corrects ont eté ramenés.

L’ evaluation de notre contribution Va se faire au regard de deux djfferentes "baselines". La premiere, tres simple
et qui fera ofﬁce de borne inférieure, consiste £1 trier les 273 types pour chaque entite, de maniere aléatoire.
Cependant un seul classement aleatoire pourrait ne pas etre représentatif, c’est pourquoi nous avons decide que
plutot que d’ effectuer un tel classement, nous mesurerions la probabilité d’obtenir avec des tirages aleatoires un
classement aussi "bon" que le meilleur des notres. Ceci peut etre estimé avec la fonction de repartition d’une
fonction géometrique. Elle représente la somme des probabilités d’aVoir au minimum autant de bonnes reponses
en X tirages aleatoires (donc au rang x). Cette "baseline" sera designee £1 partir de ce point sous le nom Aléatoire.

La deuxieme baseline consiste en l’utilisation de patrons d’ extractions speciﬁquements étudiés pour determiner les
relations is-A er1tre une entité et un type ((Hearst, 1992), (Pasca, 2004),. . .) comme "type such as entite’ ". L’ idée de
la baseline est de compter le nombre de pages Web retrouvées par un moteur de recherche lorsque l’on lui soumet
la requete "type * entire", qui signiﬁe que nous recherchons tous les documents dans lesquels on retrouve le type
suivi de l’entite et sépares au maximum par un mot ("including " par exemple) et de classer les types par ordre
décroissant. Cette methode est appelée Patron.

Pour cette premiere evaluation, nous souhaitons etudier la qualite de notre modele avec différentes Variations. Nous
avons imagine quatre Voies qui different sur le jeu de documents utilise pour estimer les distributions de mots.
Trois differentes manieres de construire un jeu de documents ont ete envisagées. Les deux premieres consistent
£1 recuperer les pages Web ou les snippets retoumes par un moteur de recherche (ici Yahoo !) en lui soumettant
le type ou l’entite. La troisieme Voie est spéciﬁque au jeu de documents relatif au type. Dans les deux methodes
précédentes, nous récupérions des documents en relation avec le type. Nous proposons ici de recuperer des pages
chacune dédiée £1 une entité du type. Pour cela nous recupérons des entités du type et leur page Wikipédia (Via
DBPedia). Ici, nous ne récupérons pas la premiere page Web que pourrait nous retoumer un moteur de recherche
car nous ne pourrions etre sur qu’il s’agit bien d’une page liée £1 cette entité et non pas £1 un homonyme. Nous
ferons reference £1 ces trois Variantes sous les noms : sWeb, sSm'ppet et sEntt'tt'es.

Les quatre premieres méthodes que nous allons comparer proposent differentes combinaisons de ces trois manieres
de construire les jeux de documents. Les méthodes sont sWeb, sSm'ppet, sWeb/sSm'ppet et sEntt'tt'es/sWeb. Le nom
décrit la methode utilisée pour la recuperation des documents pour le type et l’entité (separe par ''l'') 5.

Methodes Baselines

Mesure sWeb sSnippet sWeb/sSnippet sEntities/sWeb Aléatoire Patron
MRR 0,3410 (2,93) 0,4224 (2,36) 0,3609 (2,77) 0,2299 (4,35) < 0,0020 0,3019 (3,31)
iPR1 0,0693 (40,84) 0,0753 (37,58) 0,0569 (49,74) 0,1185 (23,88) < 0,0246 0,0627 (44,34)

TABLE 1 — Evaluation avec la moyenne des reciproques des rangs (MRR) et la precision interpolee pour un rappel
de 1 (iPR1) compare aux deux "baselines". Pour chaque méthode, nous utilisons 100 pages Web ou snippets.
Aléatoire est calculé par rapport £1 la meilleure methode pour la mesure étudiee. Le score er1tre parentheses est le
rang moyen correspondant au score associé.

Les premiers resultats Tableau 1 montrent plusieurs choses intéressantes. La principale est que tous les essais
de notre proposition obtiennent de meilleurs résultats que les "baselines". Par exemple, obtenir un classement au
moins aussi bon que sSnippet, au regard de la moyenne des réciproques des rang, en classant aleatoirement les
types pour les entités, n’a que 0,2% chances de se réaliser. De plus elle est meilleure que la baseline utilisant des
patrons inspires de (Hearst, 1992) qui pourtant permettent d’ obtenir dans de nombreuses t£1ches des resultats état

4. http ://mappings.dbpedia.org/server/ontology/classes

_ |Q|
5' MRR _ % 212:1 7'a.71LIs:,-

6. L’ absence dc "/" signiﬁe que la méme méthodc est utilisée pour les dcux éléments (sWeb = sWeb/sWeb ct ssnippet = sSnippet/sSnippet).

MESURE NON SUPERVISEE DE L’APPARTENANCE D’UNE ENTITE A UN TYPE

de l’art. La deuxieme observation est qu’il est preferable d’utiliser les snippets a la place des pages Web pour
construire les jeux de documents. Cela est en partie dﬁ au bruit que les pages Web contiennent. Une explication
complémentaire serait que les pages Web avec un rang élevé ne sont pas (ou peu) relatives a la requete et leur
utilisation modiﬁent a ce point les distributions de mots, qu’elles ne correspondent plus aux types et aux entités.

Pour Valider cette hypothese, nous avons testé deux autres méthodes : sWebl0 et sSm'ppetl0. Elles different de
sWeb et sSm'ppet dans le sens ou seuls les 10 premiers elements retoumes par le moteur de recherche sont utilises
pour constr11ire les jeux de documents. Les résultats sont presentes Tableau 2. La comparaison des deux premieres
colonnes donne l’avantage a l’utilisation de 10 pages Web au lieu de 100. Cela conﬁrme notre intuition que les
pages Web avec un rang élevé ne sont pas assez pertinentes et perturbent la mise au point d’un modele lie a un type
ou une entité. Cette tendance n’est pas retrouvee en ce qui conceme l’utilisation de snippets car nous disposons
alors de trop peu d’information pour estimer une distribution des mots pertinente.

Mesure sWeb sWeb10 sSnippet sSnippet10
MRR 0,3410 (2,93) 0,3756 (2,66) 0,4224 (2,36) 0,3550 (2,82)
iPR1 0,0693 (40,84) 0,0781 (36,24) 0,0753 (37,58) 0,0690 (41,01)

TABLE 2 — Evaluation pour sWeb et sSnippet de l’i1npact du nombre de pages Web utilisées pour constr11ire les
jeux de documents. Pour chaque méthode, nous comparons une version avec 100 ou 10 elements (pages Web ou
snippets). Le score entre parentheses est le rang moyen correspondant au score.

Dans le Tableau 1, nous pouvons aussi remarquer (colonne 4) que l’utilisation de pages Wikipedia d’ entites d’un
type donne pour constituer le jeu de documents se situe largement en dega des autres methodes pour la moyenne
des reciproques des rangs (presque moitie moins qu’avec les snippets). 11 est alors surprenant de remarquer qu’elle
est la meilleure pour la precision interpolée (iPR1) (environ 1,5 fois superieur a celui des snippets).

Dans le Tableau 3 nous cherchons a determiner quel est le rang moyen ou le type le plus ﬁn (celui de plus bas
niveau) d’une entité est retrouvé. Une evaluation dans ce sens a eté faites pour sWeb et sSm'ppet sous les noms
sWebMax et sSnippetMax. On peut tout d’abord constater que les types les plus ﬁns sont retrouves 1 fois sur 4 en
premiere position (resp. environ 1/5) lorsque l’on utilise les snippets (resp. les pages Web). De plus, les résultats
obtenus pour MRR montrent qu’en moyenne le type le plus ﬁn est retrouvé dans les premiers rangs et que cela est
tres proche du rang ou est trouvée la premiere réponse correcte pour sWeb et sSm'ppet. Dans le Tableau 1, l’iPR1
nous indique que tous les bons types d’une entité sont retrouves aux alentours du rang 40. On peut donc deduire de
ces deux informations que ce sont les types de plus haut niveau (ex : personne, lieu. . .) qui sont les plus difﬁciles
a retrouver. La raison d’une telle difference est que le vocabulaire dans les documents lies aux types ﬁns est plus
precis, donc plus discriminant, qu’il ne l’est dans les documents lies aux types généraux. Ceci positionne notre
proposition non pas comme une alternative aux systemes de reconnaissance d’entités nommées mais comme un
complement pour caractériser plus ﬁnement des entites.

Pourquoi l’utilisation des pages Wikipedia d’entités du type étudié est—il moins performant pour trouver les types
ﬁns que les autres methodes et pourquoi l’est—il plus pour les types plus larges ‘.7 Pour le premier element, la raison
est probablement qu’étant donne que nous sommes dans le cas de documents encyclopédiques, les rédacteurs
tendent a éviter les repetitions et les mots speciﬁques (a une entite ou un type) ne sont pas vus plusieurs fois
mais se retrouvent sous la forme de synonymes. Le deuxieme, s’explique par le formatage spéciﬁque des pages
Wikipédia. En effet toutes les ﬁches concemant, par exemple, des personnes, commencent avec un texte du type :
"X est ne en DD—MM—YYYY a Y" et possedent des infobox communes.

Mesure sWeb sWebMax sSnippet sSnippetMax
P@1 0,2348 0,1900 0,2762 0,2500
MRR 0,3410 (2,93) 0,2616 (3,82) 0,4224 (2,36) 0,3159 (3,17)

TABLE 3 — Mesure de la precision au rang 1 et la moyenne des reciproques des rangs (MRR). Les methodes
sWebMax et sSnippetMax considerent uniquement le type le plus ﬁn d’une entité comme correct. Le score entre
parentheses est le rang moyen correspondant au score associe.

LUDOVIC BONNEFOY, PATRICE BELLOT, MICHEL BENOIT

4 Conclusions et perspectives

Nous avons présenté une méthode non—supervisée pour estimer dans quelle mesure une entité est d’un type donné
(quel qu’il soit) en comparant les distributions de mots dans des documents lies a l’entité et lies au type.

L’éva1uation que nous avons réalisée, sur 100 entités et 273 types, montre que cette voie est prometteuse est permet
d’obtenir des résultats intéressants. Nous avons montre que notre proposition fonctionne mieux sur des types ﬁns
et spéciﬁques que sur des types trop larges et pourrait se situer comme complement aux outils de reconnaissance
d’entités nommées existants.

En terme de perspectives, nous considérons différentes manieres de calculer les distributions de probabilité (concepts
sémantiques, concepts latents, utilisation de listes de mots outils, suppression des mots uniques. . .), différentes
techniques de lissage (par exemple basées sur la hiérarchie des types), de calcul de similarité entre distributions,
l’utilisation du contexte d’ apparition de l’entité. ..

Retenons enﬁn que notre méthode de mesure d’appartenance d’une entité a un type possede des applications
intéressantes pour l’aide a la constitution de bases de connaissances puisqu’elle pourrait permettre d’identiﬁer,
a partir d’un exemple (instance) et du nom de sa catégorie (concept), d’autres instances similaires ou proches.
L’ etude des elements linguistiques ayant permis cette identiﬁcation pourrait a son tour conduire a déﬁnir les
contextes d’ apparition possibles des instances ainsi que certaines de leurs propriétés ontologiques. Tout cela fait
l’objet de nos travaux actuels.

Références

ASAHARA M. & MATSUMOTO Y. (2003). Japanese named entity extraction with redundant morphological
analysis. Human Language Technology conference — North American chapter of the ACL.

BIKEL D., MILLER S., SCHWARTZ R. & WEISCHEDEL R. (1997). Nymble : a high—performance learning
name—ﬁnder. Proc. Conference on Applied Natural Language Processing.

BONNEFOY L., BELLOT P. & BENOIT M. (2011). Une approche non supervisée pour le typage et la validation
d’une réponse a une question en langage naturel : application a la tache entity de trec 2010. Huitieme e’dition de
la C0nfe’rence en Recherche d ’Information et Applications.

CHEN S. F. & GOODMAN J . (1998). An empirical study of smoothing techniques for language modeling.
CUCCHIARELLI A. & VELARDI P. (2001). Unsupervised named entity recognition using syntactic and semantic
contextual evidence. Computational Linguistics 27 :1 .123—1 31, Cambridge : MIT Press.

HEARST M. (1992). Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th
International Conference on Computational Linguistics (COLING—92), 539-545.

MCCALLUM A. (2003). Early results for named entity recognition with conditional random ﬁelds, features
induction and web—enhanced lexicons. Proc. Conference on Computational Natural Language Learning.
NADEAU D. & SEKINE S. (2007). A survey of named entity recognition and classiﬁcation. Linguisticae Inves-
tigationes, Vol. 30, No. 1. (January 2007), pp. 3-26.

PASCA M. (2004). Acquisition of categorized named entities for web search. 2004 ACM CIKM International
Conference on Information and Knowledge Management, Washington, DC, USA, November 8-13.

PASCA M., LIN D., BIGHAM J ., LIFCHITS A. & JAIN A. (2006). Organizing and searching the world wide web
of facts-step one : The one—1nillion fact extraction challenge. Proc. National Conference on Artificial Intelligence.
SEKINE S. (1998). Description of the japanese ne system used for met-2. Message Understanding Conference.
SEKINE S. & NOBATA C. (2004). Deﬁnition, dictionaries and tagger for extended named entity hierarchy. Proc.
Conference on Language Resources and Evaluation.

SEKINE S ., SUDO K. & NOBATA C. (2002). Extended named entity hierarchy. Proceedings of 3rd International
Conference on Language Resources and Evaluation (LREC’02).

TALUKDAR P. P. & PEREIRA F. (2010). Experiments in graph—based semi-supervised learning methods for
class—instance acquisition. Proceedings of the 48th Annual Meeting of the Association for Computational Lin-
guistics (2010), pp. 1473-1481.

VOORHEES E. M. (1999). The trec—8 question answering track report. NIST Special Publication 500-246 : The
Eighth Text REtrieval Conference (TREC-8).

