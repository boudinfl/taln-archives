TALN 2011, Montpellier, 27 juin -1” jui11et2011

Evaluation de G—LexAr
pour la traduction automatique statistique

Wigdan Mekki(1), Julien Gosme(1), Fathi Debi1i(2), Yves Lepage(3), Nadine Lucas“)
(1) GREYC, UMR 6072, CNRS, Université de Caen Basse-Normandie, Caen, France
(2) LLACAN, UMR 8135, CNRS, Villejuif, France
(3) IPS, Université Waseda, J apon

Résumé. G—LexAr est un analyseur morphologique de l’arabe qui a récemment regu des améliorations subs-
tantielles. Cet article propose une evaluation de cet analyseur en tant qu’outil de pré—traitement pour la traduction
automatique statistique, ce dont il n’a encore jamais fait l’ objet. Nous étudions l’impact des djfférentes formes pro-
posées par son analyse (voyellation, lemmatisation et segmentation) sur un systeme de traduction arabe—anglais,
ainsi que l’i1npact de la combinaison de ces formes. Nos experiences montrent que l’utilisation séparée de cha-
cune de ces formes n’a que peu d’inﬂuence sur la qualité des traductions obtenues, tandis que leur combinaison y
contribue de fagon tres bénéﬁque.

Abstract. G—LexAr is an Arabic morphological analyzer that has recently been improved for speed. This
paper gives an assessment of this analyzer as a preprocessing tool for statistical machine translation. We study
the impact of the use of its possible outputs (Vocalized, lemmatized and segmented) through an Arabic—English
machine translation system, as well as the impact of the combination of these outputs. Our experiments show that
using these outputs separately does not inﬂuence much translation quality. However, their combination leads to
major improvements.

M0tS-CléS 3 traduction automatique statistique, analyse morphologique, pré—traitement de l’arabe.

Keywords: statistical machine translation, morphological analysis, arabic preprocessing.

1 Introduction

L’ arabe est une langue a morphologie riche dont la complexité présente des déﬁs pour la traduction automatique
(voir (Habash, 2007) pour une description des problemes morphologiques relatifs a cette tache).

Des experiences utilisant l’analyse morphologique pour améliorer la traduction automatique ont déja été menées
pour l’allemand (p. ex. NieBen & Ney, 2004) ou le turc (p. ex. Bisazza & Federico, 2009). Ces travaux utilisent
diverses sortes de segmentation, lemmatisation et étiquetage grammatical. Dans le cas de l’arabe, les travaux de
Lee (2004), utilisant une approche de segmentation en racines et afﬁxes, puis de Habash & Sadat (2006), avec
une approche de tokenization linguistiquement motivée, ont montré que le pré—traitement morphologique peut
etre utile a la traduction automatique statistique. D’un autre cote, Diab et al. (2007) ont montré que l’utilisation
de la voyellation seule ne conduit a aucune amelioration (voyellation partielle), Voire a de moins bons résultats
(voyellation complete).

Dans cet article, nous évaluons l’analyseur morphologique de l’arabe G—LexAr (Debili et al., 2002) sur des taches
de traduction automatique statistique arabe—anglais, en utilisant l’analyse morphologique comme étape de pre-

WIGDAN MEKKI, JULIEN GOSME, FATH1 DEBILI,YVES LEPAGE, NADINE LUCAS

traitement. G-LexAr Version 3 n’a encore jamais fait l’objet d’une telle evaluation, et a récemment été optimise.

Cet article est organise comme suit : la section 2 décrit l’analyseur morphologique G-LexAr et l’analyseur de
reference que nous utilisons, BAMA ; la section 3 présente les details de la conception d’un systeme de traduction
automatique de reference ainsi que les résultats obtenus avec ces deux analyseurs ; la section 4 conclut ces travaux.

2 Analyse morphologique

Cette section présente une Vue globale des deux analyseurs compares : G-LexAr et BAMA. Pour une description
détaillée de G-LexAr Version 2, Voir (Debili et al., 2002) et pour BAMA utilise comme reference Voir (Buckwalter,
2002)

2.1 G-LexAr

G-LexAr est un programme d’analyse morpho—grammaticale de l’arabe (arabe classique et standard modeme),
pouvant traiter des textes d’entrée Voyellés ou non. Il produit en sortie des analyses ou les mots peuvent etre
indépendamment segmentés, Voyellés, lemmatisés ou étiquetes. Il est fondé sur la Inise en oeuvre d’un grand
nombre de dictionnaires et regles qui privilégient la rapidité des traitements a l’espace mémoire.

ll opere en trois étapes. La premiere segmente le texte d’ entrée en unites morphologiques, c’est—a—dire en formes
simples et agglutinées de l’arabe (hyper—formes), puis ﬁltre les chaines de caracteres qui ne relevent pas de l’ana-
lyse morphologique de l’arabe proprement dite. La deuxieme étape analyse ces hyper—formes indépendamment de
leur contexte. A chaque hyper—forme est attribué, sous forme d’un arbre, l’ensemble de ses segmentations, Voyel—
lations, lemmatisations et étiquettes grammaticales possibles. Les lemmes résultants de la lemmatisation sont en
fait des hyper—lemmes dans la mesure ou ils sont associés a des formes simples ou agglutinées. De fagon ana-
logue, les hyper—formes correspondent a des hyper—catégories grammaticales, car elles sont elles aussi associées
indjfféremment a des formes simples ou agglutinées.

L’ approche fondée sur l’utilisation de dictionnaires de formes simples et de regles assure une large couverture,
mais s’aVérait en pratique assez lente dans la Version 2. Pour gagner en temps d’analyse, une nouvelle architecture
a tout récemment été développée (G-LexAr V. 3). Elle met en oeuvre en frontal un dictionnaire d’ hyper—formes ou
chaque entree est accompagnée de sa propre arborescence lexicale. Dans ces conditions, l’analyse morphologique
de l’arabe est comparable a celle du frangais ou de l’anglais : elle consiste en un simple acces. Ainsi, elle n’est
soumise a une analyse traditionnelle en <proclitique + forme simple + enclitique> que lorsque l’unité morpho-
logique n’est pas reconnue, c’est—a—dire lorsqu’elle ne ﬁgure pas dans le dictionnaire d’hyper-formes. Le résultat
de cette deuxieme étape est une succession de mots accompagnés de leurs arborescences lexicales. La ﬁgure 1 en

donne un exemple, avec le résultat de l’analyse morphologique du mot ‘._V,L:f place a la racine de de l’arbre
signiﬁant leur livre "ktAbhm". Dans cette ﬁgure, on distingue :

1. les découpages potentiels du mot en <proclitique + forme simple + enclitique>, ici au nombre de deux : <k
+ tAb + h1n> ou <ktAb + hm> (premier niveau apres la racine) ;

2. les Voyellations potentielles associées produites par la deuxieme étape (deuxieme niveau, "kitAbihim" leur
livre, ou "kuttAbuhum" leurs écrivains;

3. les lemmes associés a ces deux Voyellations (troisieme niveau, un seul lemme pour "kitAbihim" qui est
"kitAb" livre et deux lemmes possible pour "kuttAbuhum", le premier est "kuttAb" et le second est "kAtib").
Ces lemmes se présentent sous la forme <proclitique Voyellé + lemme Voyelle + enclitique Voyelle>;

EVALUATION DE G—LEXAR POUR LA TRADUCTION AUTOMATIQUE STATISTIQUE

[ktAbhm]
WW
‘leur livre’
 
[kjta_Abjhjm] [kuttfkbuhum]
 c~’é‘=’
‘1611f1iVf6’ ’leurs ecrivains’
[kitaAb + him] 9-‘ + elf? + [1<aAtib + him] 9» + u_»§V[kuttAb + hum] 
| I I

FIGURE 1 — Exemple de representation arborescente resultant de la deuxieme etape avec l’unité morphologique,
la forme Voyellee, la forme lemmatisee et l’hyper—forme.

4. les étiquettes grammaticales potentielles associées a l’un de ces lemmes (feuilles de l’arbre) ;

Enﬁn, dans la troisieme étape, on procede a l’étiquetage grammatical a proprement parler en elaguant ces arbo-
rescences lexicales. L’ élagage consiste a ne retenir que les branches dont les feuilles ont des etiquettes Vériﬁant
un certain nombre de regles portant sur la légitimite de la succession de ces etiquettes. Pour rendre ces traite-
ments plus rapides, l’élagage met en oeuvre un dictionnaire pré—compilé qui associe aux couples (mot, ensemble
d’étiquettes) les arborescences lexicales elaguées qui leur correspondent. A performance linguistique identique et
relativement a la Version 2 de l’analyseur, cette nouvelle architecture a permis les ameliorations suivantes : de 1,3
a 2,2 ko/seconde, la Vitesse est passée de 5,7 a 10,8 ko/seconde, soit une analyse trois a cinq fois plus rapide.

2.2 BAMA

Dans les experiences suivantes, nous comparons G—LexAr a l’analyseur morphologique de Buckwalter (BAMA),
qui est consideré comme l’un des meilleurs analyseurs de l’arabe, et qui est par consequent tres repandu. Contrai-
rement a G—LexAr, il utilise une approche concaténative du lexique, ou les regles morphologiques et orthogra-
phiques sont intégrées directement dans le lexique au lieu d’etre précisées en fonction des regles générales qui
interagissent pour produire la sortie.

Pour chaque chaine d’entrée, l’analyseur foumit une solution (systematiquement en translittération Buckwalter,

WIGDAN MEKKI, JULIEN GOSME, FATH1 DEBILI,YVES LEPAGE, NADINE LUCAS

alors que G-LexAr traite le texte arabe sous sa forme brute), comprenant un lemme sous la forme d’un identiﬁant
unique, une Ventilation des morphemes constituants (preﬁxes, racine, et sufﬁxes), leurs etiquettes grammaticales
et la traduction correspondante en anglais. Un exemple est donné dans la ﬁgure 2.

INPUT STRING: J-ls}!

SOLUTION 1: >alogAz
LEMMA_ID: lugoz_1
POS: >alogAz /NOUN
GLOSS: mysteries /enigmas
SOLUTION 2: >alogAzu
LEMMA_ID: lugoz_1
POS: >al0gAz/NOUN+u/CASE_DEF_NOM
GLOSS: mysteries/enigmas + [def.nom.]
SOLUTION 3: >alogAza
LEMMA_ID: lugoz_1
POS : >al0gAz /NOUN+a/CASE_DEF_ACC
GLOSS: mysteries/enigmas + [def.acc.]
SOLUTION 4: >alogAzi
LEMMA_ID: lugoz_1
POS: >alogAz/NOUN+a/CASE_DEF_GEN
GLOSS: mysteries/enigmas + [def.gen.]

FIGURE 2 — Exemple de sortie de BAMA : chaque solution consiste ici en un identiﬁant de lemme (LEMMA_lD),
une etiquette grammaticale (POS) et une traduction (GLOSS).

3 Evaluation des analyseurs en traduction automatique statistique

Nous comparons l’analyseur G-LexAr avec BAMA en les utilisant comme outils de pré—traitement sur des taches
de traduction automatique statistique, a l’aide du systeme open source Moses (Koehn et al., 2007). Nous utilisons
comme données d’entrainement un échantillon de 251 000 couples de phrases paralleles arabe-anglais extraites
d’un corpus constitue d’articles de joumaux (Arabic—English Automatically Extracted Parallel Text) publie par
le LDC (Linguistic Data Consortium). Le corpus ainsi constitue, sous sa forme brute et sans pre—traitement, est
appele << original » par la suite.

Les deux analyseurs produisent une liste de solutions possibles pour chaque hyper—forme, classées selon le score
de pertinence. Dans les experiences suivantes, nous ne conservons que la premiere. Les sorties de l’analyseur
G-LexAr comprennent des formes Voyellees, lemmatisees et segmentees. BAMA quant a lui ne foumit pas de
forme Voyellée, aussi nous ne considérons que les deux formes (translittérées) lemmatisées et segmentées. Nous
construisons ainsi 6 systemes de traductions : un en utilisant le corpus original, trois en traitant ce corpus avec
chacune des analyses de G-LexAr séparément, et deux avec chacune des analyses de BAMA separement egale—
ment.

Les jeux de developpement et de test sont constitués respectivement de 500 couples de phrases. Les mesures
utilisées pour l’éValuation sont BLEU, TER et mWER. Nous calculons des intervalles de conﬁance a l’aide de la
methode par ré—échantillonnage par amorce décrite dans (Koehn, 2004) : 1 000 corpus detest de 500 phrases sont
constitues par echantillonnage uniforme avec remise a partir des 500 phrases de test mentionnées ci—dessus. Les
résultats sont présentés au tableau 1.

Le score de conﬁance global atteint 95 % dans cette premiere experience. Le recours aux analyseurs ne semble
pas apporter d’amelioration par rapport au corpus original, et semble meme avoir tendance a degrader légerement
les scores. En particulier, le systeme ayant recours a la forme Voyellée obtient systematiquement de moins bons

TABLE 1 — Scores medians et intervalles de conﬁance (entre crochets) obtenus par les systemes de traduction, sur
la base de 1 000 corpus de test. Les meilleurs scores selon les mesures TER et mWER sont les plus faibles, les

EVALUATION DE G—LEXAR POUR LA TRADUCTION AUTOMATIQUE STATISTIQUE

meilleurs selon BLEU sont les plus éleves.

mWER BLEU TER
original 0.4874 [0.4772, 0.4985] 0.2121 [0.1990, 0.2250] 0.8239 [0.8032, 0.8480]
Voyellée 0.4962 [0.4855, 0.5071] 0.1978 [0.1847, 0.2113] 0.8394 [0.8175, 0.8634]
G-LexAr lemmatisée 0.5000 [0.4896, 0.5106] 0.1973 [0.1850, 0.2092] 0.8451 [0.8237, 0.8699]
segmentée 0.4823 [0.4722, 0.4929] 0.2066 [0.1850, 0.2092] 0.8165 [0.7955, 0.8400]
B AM A lemmatisée 0.4869 [0.4774, 0.4972] 0.2091 [0.l963, 0.2214] 0.8111 [0.7905, 0.8332]
segmentee 0.4822 [0.472l, 0.4924] 0.1957 [0.l835, 0.2091] 0.8430 [0.8208, 0.8689]
intersection [0.4896, 0.4924] [0.1990, 0.2091] [0.8237, 0.8332]

résultats, conformément aux experiences de Diab et al. (2007). Les differences entre les scores medians selon
chacune des trois mesures sont cependant tres faibles, et n’eVoluent pas toujours dans le meme sens d’une mesure
a l’autre. En fait, d’apres les intervalles de conﬁance, elles ne sont pas signiﬁcatives : pour une mesure donnee, les
intervalles de scores des systemes G-Leyalr, BAMA et original se chevauchent (les intervalles speciﬁes sur la ligne
intersection du tableau ne sont pas Vides). Les deux analyseurs produisent donc des sorties de qualité similaire.

Dans cette premiere experience, l’utilisation séparée des formes Voyellee, lemmatisee ou segmentée avec l’un ou
l’autre des analyseurs n’a pas apporte d’ amelioration notable. Par consequent, dans une deuxieme experience,
nous combinons ces formes aﬁn de créer deux nouveaux systemes que nous appelons << combines », c’est—a-dire
ayant recours a toutes les analyses d’un meme analyseur simultanément (Voyellée + lemmatisée + segmentée
pour G—LexAr, lemmatisee + segmentée pour BAMA). Pour une entree, toutes les formes correspondantes sont
traduites et l’hypothese de traduction ayant le meilleur score a la sortie de Moses est gardee comme hypothese
ﬁnale. Les résultats sont presentes dans le tableau 2.

TABLE 2 — Comparaison des systemes combines avec le systeme original.

mWER BLEU TER
original 0.4876 0.2121 0.8244
G-LexAr combine 0.4312 0.2072 0.7300
BAMA combine 0.4261 0.2095 0.7164

On constate une nette amelioration des scores par rapport au tableau 1. Les deux systemes combines sont desor-
mais bien meilleurs que le systeme original selon TER et mWER (-11 % ou -12 % relativement au systeme original
pour G-LexAr, -13 % pour BAMA sur ces deux mesures), et ne sont que légerement en retrait selon BLEU (moins
d’ un—de1ni point en retrait, soit seulement 2 %). Le gain selon TER et mWER est bien plus important que la légere
perte en BLEU. Par consequent, le recours simultane a toutes les formes produites par un analyseur ameliore les
résultats d’un systeme de traduction automatique, alors que le recours a ces formes prises separement les degrade,
comme l’a montre la premiere experience.

4 Conclusion

Cet article a donne un apergu de l’analyseur G-LexAr, dont la Version 3 est plus performante en Vitesse de trai-
tement que la Version 2. Dans nos experiences en traduction automatique statistique, ses performances se sont

WIGDAN MEKKI, JULIEN GOSME, FATH1 DEBILI,YVES LEPAGE, NADINE LUCAS

revelees comparables a celles de BAMA, considere comme la reference en analyse morphologique de l’arabe.
G—LexAr a come avantage indéniable pour les arabisants de traiter directement un texte brut arabe sans necessi-
ter de transliteration intermédiaire.

Les experiences presentées ici conﬁrment les resultats de Diab et al. (2007) : la voyellation de l’arabe ne serait
pas benéﬁque en traduction automatique statistique. Plus généralement, nous avons vu que l’utilisation se’pare’e
des formes que peut produire un analyseur (voyellation, segmentation et lemmatisation) n’améliore pas les scores,
alors qu’une utilisation combine’e serait bénéﬁque. Pour aller plus loin, nous envisageons d’étudier plus precise-
ment les contributions positives ou negatives de chacune des formes analysées au sein meme des systemes combi-
nes. L’ extension de ces experiences a d’autres domaines ou couples de langues, y compris en utilisant l’arabe en
cible, permettra également d’afﬁner ces resultats.

Enﬁn, des experiences non rapportées dans cet article ont montré que l’une des faiblesses de l’analyseur G—LexAr
est qu’il n’indexe pas encore les mots d’emprunt (voir Gosme et al., 2010). Nous pensons que la resolution de ce
probleme permettra des resultats encore meilleurs.

Références

BISAZZA A. & FEDERICO M. (2009). Morphological pre—processing for Turkish to English statistical machine
translation. In Proceedings of the International Workshop on Spoken language Translation, p. 129-135.
BUCKWALTER T. (2002). Buckwalter Arabic Morphological Analyzer Version 1.0. LDC catalog number
LDC2002L49. Rapport inteme, ISBN 1—58563-257—0.

DEBILI F., ACHOUR H. & SOUISSI E. (2002). De l’etiquetage grammatical a la voyellation automatique de
l’arabe. Correspondances, 71, 10-28.

DIAB M., GHONEIM M. & HABASH N. (2007). Arabic diacritization in the context of statistical machine
translation. In Proceedings of MT-Summit.

GOSME J ., MEKKI W., LEPAGE Y. & DEBILLI F. (2010). Evaluation of GLexAr tl1rough Arabic-English

Statistical Machine Translation Systems. In Proceedings of the 7th International Workshop on Spoken Language
Translation (IWSLT 2010), Paris, France.

HABASH N. (2007). Arabic Morphological Representations for Machine Translation, In Arabic Computational
Morphology, volume 38 of Text, Speech and language Technology, p. 263-285. Springer Netherlands.

HABASH N. & SADAT F. (2006). Arabic preprocessing schemes for statistical machine translation. In Procee-
dings of the Human language Technology Conference of the NAACL, p. 49-52 : Association for Computational
Linguistics.

KOEHN P. (2004). Statistical signiﬁcance tests for machine translation evaluation. In Proceedings of EMNLP,
volume 4, p. 388-395.

KOEHN P., HOANG H., BIRCH A., CALLISON-BURCH C., FEDERICO M., BERTOLDI N., COWAN B., SHEN
W., MORAN C., ZENS R., DYER C., BOJAR 0., CONSTANTIN A. & HERBST E. (2007). Moses : Open source
toolkit for statistical machine translation. In Proceedings of ACL 2007 demonstration session.

LEE Y. (2004). Morphological analysis for statistical machine translation. In Proceedings of HLT—NAACL 2004,
p. 57-60 : Association for Computational Linguistics.

NIESSEN S. & NEY H. (2004). Statistical machine translation with scarce resources using morpho-syntactic
information. Computational linguistics, 30(2), 181-204.

