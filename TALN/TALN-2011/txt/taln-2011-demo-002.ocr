TALN 2011, Montpellier, 27 juin - 1 er juillet 2011 — Session démonstration

SpatiAnn, un outil pour annoter l’utilisati0n de l’espace dans les corpus vidéo

Annelies Braffort, Laurence Bolot

LIMSI—CNRS, Campus d'Orsay Bt. 508, BP 133, F-91403 Orsay cx, France
annelies.braffo1t@limsi.fr, laurence.bolot@limsi.fr

SpatiAnn (Spatial Annotator) est un logiciel développé au LIMSI pour l’annotation de l’utilisation de l’espace par les gestes
dans les corpus vidéo de langue des signes ou multimodaux. Les gestes s’expriment dans le temps, mais aussi dans l’espace,
nommé « espace de signation >> pour la langue des signes et « espace de gestualisation >> pour le multimodal. Des études de plus
en plus nombreuses portent sur l’utilisation linguistique de cet espace et nécessitent des annotations. Les logiciels d’annotation
actuels (Elan, Anvil, iLex...) ne permettent pas d’annoter de maniere directe des informations de nature tridimensionnelles.
Actuellement, les annotations sont basées sur une segmentation arbitraire de l’espace, par exemple dans un plan vertical tel que
le « gesture space >> de McNeill (1992), ou sous forme de cubes (Lenseigne, Dalle 2005), ce qui peut limiter les analyses qui
s’appuient sur ces annotations. C’est pourquoi nous développons actuellement un logiciel qui permet d’annoter directement en
3d. Il se présente sous la forme d’un cube, ou la vidéo est projetée sur l’une des faces. On peut aussi projeter plusieurs vidéos, en
fonction des différentes vues dont on dispose, ce qui permet d’annoter dans un contexte d’interaction. La ﬁgure 1 montre un
exemple avec le corpus DEGELS1 (Boutora, Braffort 2011) pour lequel on dispose de trois vues. L’utilisateur peut manipuler le
cube aﬁn d’annoter « devant » la vidéo de son choix. Cette annotation peut prendre n’importe quelle forme, le vocabulaire
controlé et sa forme graphique sont libres. Pour nos études, nous utilisons un vocabulaire controlé constitué d’un ensemble ﬁni
de formes géométriques simples (point, segment, plan, tore, volume...), qui catégorise la trace du geste dans l’espace. Par
exemple la trace d’un pointage associé a un mouvement circulaire (description d’un rond-point) est catégorisée par un tore place
a l’endroit pointé (figure 1). Ces traces sont, comme toutes les autres annotations, synchronisées avec la vidéo. Elles peuvent étre
plus ou moins actives selon leur utilisation dans le discours. Une trace réalisée précédemment dans la vidéo s’atténue au cours
du temps mais peut étre réactivée par un pointage anaphorique. Cela se visualise en faisant varier sa transparence.

 

Figure 1 : Utilisation de SpatiAnn avec un corpus constitué de trois vues

Le logiciel est développé actuellement sous la forme d’un prototype autonome en vue d’évaluer et d’améliorer son ergonomie.
Dans un deuxieme temps, ce prototype sera intégré dans un systeme distribué permettant son emploi avec le logiciel
d’annotation AnCoLin développé dans le cadre du projet européen Dicta-Sign (Collet, Gonzalez, Milachon 2010). Dans un
troisieme temps, on envisage d’en développer une version sous forme d’un plugin utilisable avec certains logiciels courants, tels
qu’Anvil et Elan, afin de le rendre accessible at une plus grande partie de la communauté scientifique concernée.

MCNEHL, D. (1992). Hand and Mind: What gestures reveal about thought. Chicago: Univ. of Chicago Press.

LENSEIGNE, B., DALLE, P. (2005). A Signing space model for the interpretation of sign language interactions. Actes de Sign
Language Linguistics and the Application of Information Technology to Sign Languages.

BOUTORA L., BRAFFORT A. (201 1). DEGELS1. oai:crdo.fr:crdo000767.

COLLET, C., Gonzalez M., Milachon F. (2010). Distributed system architecture for assisted annotation of video corpora. Actes de
International workshop on the Representation and Processing of Sign Languages : Corpora and Sign Language Technologies
(LREC 2010).

