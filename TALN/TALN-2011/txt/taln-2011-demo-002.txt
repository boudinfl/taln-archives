
SpatiAnn, un outil pour annoter l’utilisation de l’espace dans les corpus vidéo

Annelies Braffort, Laurence Bolot
LIMSI-CNRS, Campus d'Orsay Bt. 508, BP 133, F-91403 Orsay cx, France
annelies.braffort@limsi.fr, laurence.bolot@limsi.fr
SpatiAnn (Spatial Annotator) est un logiciel développé au LIMSI pour l’annotation de l’utilisation de l’espace par les gestes
dans les corpus vidéo de langue des signes ou multimodaux. Les gestes s’expriment dans le temps, mais aussi dans l’espace,
nommé « espace de signation » pour la langue des signes et « espace de gestualisation » pour le multimodal. Des études de plus
en plus nombreuses portent sur l’utilisation linguistique de cet espace et nécessitent des annotations. Les logiciels d’annotation
actuels (Elan, Anvil, iLex…) ne permettent pas d’annoter de manière directe des informations de nature tridimensionnelles.
Actuellement, les annotations sont basées sur une segmentation arbitraire de l’espace, par exemple dans un plan vertical tel que
le « gesture space » de McNeill (1992), ou sous forme de cubes (Lenseigne, Dalle 2005), ce qui peut limiter les analyses qui
s’appuient sur ces annotations. C’est pourquoi nous développons actuellement un logiciel qui permet d’annoter directement en
3d. Il se présente sous la forme d’un cube, où la vidéo est projetée sur l’une des faces. On peut aussi projeter plusieurs vidéos, en
fonction des différentes vues dont on dispose, ce qui permet d’annoter dans un contexte d’interaction. La figure 1 montre un
exemple avec le corpus DEGELS1 (Boutora, Braffort 2011) pour lequel on dispose de trois vues. L’utilisateur peut manipuler le
cube afin d’annoter « devant » la vidéo de son choix. Cette annotation peut prendre n’importe quelle forme, le vocabulaire
contrôlé et sa forme graphique sont libres. Pour nos études, nous utilisons un vocabulaire contrôlé constitué d’un ensemble fini
de formes géométriques simples (point, segment, plan, tore, volume…), qui catégorise la trace du geste dans l’espace. Par
exemple la trace d’un pointage associé à un mouvement circulaire (description d’un rond-point) est catégorisée par un tore placé
à l’endroit pointé (figure 1). Ces traces sont, comme toutes les autres annotations, synchronisées avec la vidéo. Elles peuvent être
plus ou moins actives selon leur utilisation dans le discours. Une trace réalisée précédemment dans la vidéo s’atténue au cours
du temps mais peut être réactivée par un pointage anaphorique. Cela se visualise en faisant varier sa transparence.
Figure 1 : Utilisation de SpatiAnn avec un corpus constitué de trois vues
Le logiciel est développé actuellement sous la forme d’un prototype autonome en vue d’évaluer et d’améliorer son ergonomie.
Dans un deuxième temps, ce prototype sera intégré dans un système distribué permettant son emploi avec le logiciel
d’annotation AnCoLin développé dans le cadre du projet européen Dicta-Sign (Collet, Gonzalez, Milachon 2010). Dans un
troisième temps, on envisage d’en développer une version sous forme d’un plugin utilisable avec certains logiciels courants, tels
qu’Anvil et Elan, afin de le rendre accessible à une plus grande partie de la communauté scientifique concernée.

MCNEILL, D. (1992). Hand and Mind: What gestures reveal about thought. Chicago: Univ. of Chicago Press.
LENSEIGNE, B., DALLE, P. (2005). A Signing space model for the interpretation of sign language interactions. Actes de Sign
Language Linguistics and the Application of Information Technology to Sign Languages.
BOUTORA L., BRAFFORT A. (2011). DEGELS1. oai:crdo.fr:crdo000767.
COLLET, C., Gonzalez M., Milachon F. (2010). Distributed system architecture for assisted annotation of video corpora. Actes de
International workshop on the Representation and Processing of Sign Languages : Corpora and Sign Language Technologies
(LREC 2010).
