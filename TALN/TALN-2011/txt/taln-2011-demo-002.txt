TALN 2011, Montpellier, 27 juin - 1er juillet 2011 – Session démonstration 
SpatiAnn, un outil pour annoter l’utilisation de l’espace dans les corpus vidéo 
Annelies Braffort, Laurence Bolot 
LIMSI-CNRS, Campus d'Orsay Bt. 508, BP 133, F-91403 Orsay cx, France 
annelies.braffort@limsi.fr, laurence.bolot@limsi.fr 
SpatiAnn (Spatial Annotator) est un logiciel développé au LIMSI pour l’annotation de l’utilisation de l’espace par les gestes 
dans les corpus vidéo de langue des signes ou multimodaux. Les gestes s’expriment dans le temps, mais aussi dans l’espace, 
nommé « espace de signation » pour la langue des signes et « espace de gestualisation » pour le multimodal. Des études de plus 
en plus nombreuses portent sur l’utilisation linguistique de cet espace et nécessitent des annotations. Les logiciels d’annotation 
actuels (Elan, Anvil, iLex…) ne permettent pas d’annoter de manière directe des informations de nature tridimensionnelles. 
Actuellement, les annotations sont basées sur une segmentation arbitraire de l’espace, par exemple dans un plan vertical tel que 
le « gesture space » de McNeill (1992), ou sous forme de cubes (Lenseigne, Dalle 2005), ce qui peut limiter les analyses qui 
s’appuient sur ces annotations. C’est pourquoi nous développons actuellement un logiciel qui permet d’annoter directement en 
3d. Il se présente sous la forme d’un cube, où la vidéo est projetée sur l’une des faces. On peut aussi projeter plusieurs vidéos, en 
fonction des différentes vues dont on dispose, ce qui permet d’annoter dans un contexte d’interaction. La figure 1 montre un 
exemple avec le corpus DEGELS1 (Boutora, Braffort 2011) pour lequel on dispose de trois vues. L’utilisateur peut manipuler le 
cube afin d’annoter « devant » la vidéo de son choix. Cette annotation peut prendre n’importe quelle forme, le vocabulaire 
contrôlé et sa forme graphique sont libres. Pour nos études, nous utilisons un vocabulaire contrôlé constitué d’un ensemble fini 
de formes géométriques simples (point, segment, plan, tore, volume…), qui catégorise la trace du geste dans l’espace. Par 
exemple la trace d’un pointage associé à un mouvement circulaire (description d’un rond-point) est catégorisée par un tore placé 
à l’endroit pointé (figure 1). Ces traces sont, comme toutes les autres annotations, synchronisées avec la vidéo. Elles peuvent être 
plus ou moins actives selon leur utilisation dans le discours. Une trace réalisée précédemment dans la vidéo s’atténue au cours 
du temps mais peut être réactivée par un pointage anaphorique. Cela se visualise en faisant varier sa transparence. 
 
Figure 1 : Utilisation de SpatiAnn avec un corpus constitué de trois vues 
Le logiciel est développé actuellement sous la forme d’un prototype autonome en vue d’évaluer et d’améliorer son ergonomie. 
Dans un deuxième temps, ce prototype sera intégré dans un système distribué permettant son emploi avec le logiciel 
d’annotation AnCoLin développé dans le cadre du projet européen Dicta-Sign (Collet, Gonzalez, Milachon 2010). Dans un 
troisième temps, on envisage d’en développer une version sous forme d’un plugin utilisable avec certains logiciels courants, tels 
qu’Anvil et Elan, afin de le rendre accessible à une plus grande partie de la communauté scientifique concernée. 
MCNEILL, D. (1992). Hand and Mind: What gestures reveal about thought. Chicago: Univ. of Chicago Press. 
LENSEIGNE, B., DALLE, P. (2005). A Signing space model for the interpretation of sign language interactions. Actes de Sign 
Language Linguistics and the Application of Information Technology to Sign Languages. 
BOUTORA L., BRAFFORT A. (2011). DEGELS1. oai:crdo.fr:crdo000767. 
COLLET, C., Gonzalez M., Milachon F. (2010). Distributed system architecture for assisted annotation of video corpora. Actes de 
International workshop on the Representation and Processing of Sign Languages : Corpora and Sign Language Technologies 
(LREC 2010). 
