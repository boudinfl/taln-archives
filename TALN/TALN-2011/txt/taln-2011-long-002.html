<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>G&#233;n&#233;ration automatique de motifs de d&#233;tection d&#8217;entit&#233;s nomm&#233;es en utilisant des contenus encyclop&#233;diques</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>G&#233;n&#233;ration automatique de motifs de d&#233;tection d&#8217;entit&#233;s
nomm&#233;es en utilisant des contenus encyclop&#233;diques.
</p>
<p>Eric Charton1 Michel Gagnon1 Benoit Ozell1
</p>
<p>(1) &#201;cole Polytechnique, 2900 boul. Edouard Montpetit, Montr&#233;al, Canada
{eric.charton, michel.gagnon, benoit.ozell}@polymtl.ca
</p>
<p>R&#233;sum&#233;. Les encyclop&#233;dies num&#233;riques contiennent aujourd&#8217;hui de vastes inventaires de
formes d&#8217;&#233;critures pour des noms de personnes, de lieux, de produits ou d&#8217;organisation. Nous
pr&#233;sentons un syst&#232;me hybride de d&#233;tection d&#8217;entit&#233;s nomm&#233;es qui combine un classifieur &#224;
base de Champs Conditionnel Al&#233;atoires avec un ensemble de motifs de d&#233;tection extraits au-
tomatiquement d&#8217;un contenu encyclop&#233;dique. Nous proposons d&#8217;extraire depuis des &#233;ditions
en plusieurs langues de l&#8217;encyclop&#233;die Wikip&#233;dia de grandes quantit&#233;s de formes d&#8217;&#233;criture
que nous utilisons en tant que motifs de d&#233;tection des entit&#233;s nomm&#233;es. Nous d&#233;crivons une
m&#233;thode qui nous assure de ne conserver dans cette ressources que des formes non ambigu&#235;s
susceptibles de venir renforcer un syst&#232;me de d&#233;tection d&#8217;entit&#233;s nomm&#233;es automatique. Nous
proc&#233;dons &#224; un ensemble d&#8217;exp&#233;riences qui nous permettent de comparer un syst&#232;me d&#8217;&#233;tique-
tage &#224; base de CRF avec un syst&#232;me utilisant exclusivement des motifs de d&#233;tection. Puis nous
fusionnons les r&#233;sultats des deux syst&#232;mes et montrons qu&#8217;un gain de performances est obtenu
gr&#226;ce &#224; cette proposition.
</p>
<p>Abstract. Encyclopedic content can provide numerous samples of surface writing forms
for persons, places, products or organisations names. In this paper we present an hybrid named
entities recognition system based on a gazetteer automatically extracted. We propose to extract
it from various language editions of Wikipedia encyclopedia. The wide amount of surface forms
extracted from this encyclopedic content is then used as detection pattern of named entities. We
build a labelling tool using those patterns. This labelling tool is used as simple pattern detection
component, to combine with a Conditional Random Field tagger. We compare the performances
of each component of our system with the results previously obtained by various systems in the
French NER campaign ESTER 2. Finally, we show that the fusion of a CRF label tool with a
pattern based ones, can improve the global performances of a named entity recognition system.
</p>
<p>Mots-cl&#233;s : &#201;tiqueteur, Entit&#233;s nomm&#233;es, Lexiques.
</p>
<p>Keywords: Tagger, Named entities, Gazetteer.
</p>
<p>1 Introduction
</p>
<p>La t&#226;che d&#8217;&#233;tiquetage par des entit&#233;s nomm&#233;es (EEN) est un processus lors duquel chaque mot
d&#8217;une phrase correspondant &#224; une entit&#233; nomm&#233;e (EN) (g&#233;n&#233;ralement un nom propre et par ex-
tension des dates ou des quantit&#233;s) re&#231;oit une &#233;tiquette de classe. Cette classe correspond &#224; un</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>{ERIC.CHARTON, MICHEL.GAGNON, BENOIT.OZELL}@POLYMTL.CA
</p>
<p>arbre taxonomique dans la complexit&#233; et la nature s&#233;mantique peuvent varier. La t&#226;che d&#8217;EEN
s&#8217;&#233;tend &#224; la reconnaissance de locution nominales (au sens de suite de mots, fig&#233;e par l&#8217;usage,
pouvant &#234;tre substitu&#233;e &#224; un nom) en regroupant plusieurs mots &#233;tiquet&#233;s (comme par exemple
dans le cas de Paris qui est une entit&#233; de type localit&#233; tout comme Ville Lumi&#232;re, ou encore
l&#8217;acronyme TGV qui d&#233;crit le m&#234;me produit de type v&#233;hicule que la locution nominale Train
&#224; Grande Vitesse). Les campagnes d&#8217;&#233;valuation telles que MUC 1, ACE (Doddington et al.,
2004), CoNLL (Tjong &amp; Meulder, 2003) et dans le contexte francophone, la t&#226;che d&#8217;&#233;tiquetage
de la campagne ESTER 2 (Galliano et al., 2009), ont permis d&#8217;exp&#233;rimenter des approches var-
i&#233;es dans un contexte standardis&#233; et de mesurer leurs performances avec des m&#233;triques com-
munes. A la suite des ces campagnes, deux grandes familles de syst&#232;mes d&#8217;EEN ont fait la
d&#233;monstration de leur potentiel : celles d&#233;riv&#233;es de la linguistique computationnelle, recourant
&#224; des r&#232;gles de d&#233;tection plus ou moins sophistiqu&#233;es, et celles par apprentissage automatique
qui consistent &#224; entra&#238;ner un classifieur sur un corpus pr&#233;-&#233;tiquet&#233;. Ces deux grandes familles
d&#8217;approches exploitent &#224; des degr&#233;s divers des ressources lexicales externes dont la finalit&#233; est
de renforcer leur capacit&#233;s de d&#233;tection d&#8217;EN. L&#8217;une des caract&#233;ristiques r&#233;currente des sys-
t&#232;mes d&#8217;EEN &#224; base de r&#232;gles est qu&#8217;ils int&#232;grent dans leur processus de d&#233;tection d&#8217;EN des
lexiques plus ou moins riches, dont la disponibilit&#233; de grand corpus num&#233;riques favorise au-
jourd&#8217;hui l&#8217;extraction automatis&#233;e. Dans ce contexte, nous avons souhait&#233; chercher &#224; &#233;valuer
dans quelle mesure un lexique de grande taille, tel que ceux impl&#233;ment&#233;s dans les d&#233;tecteurs
&#224; base de r&#232;gles, pourrait &#234;tre utilis&#233; en tant que syst&#232;me rudimentaire de d&#233;tection par motif
pour am&#233;liorer un &#233;tiqueteur num&#233;rique. Cette communication, pr&#233;sente une ressource lex-
icale automatiquement extraite du corpus Wikip&#233;dia, que nous utilisons en tant que motifs
rudimentaires de d&#233;tection d&#8217;EN. Nous &#233;valuons les capacit&#233;s d&#8217;un syst&#232;me d&#8217;EEN reposant
uniquement sur ces motifs de d&#233;tection, puis nous l&#8217;hybridons avec un syst&#232;me d&#8217;EEN par
apprentissage automatique &#224; base de CRF.
</p>
<p>L&#8217;article est structur&#233; ainsi : dans la section 2, nous passons en revue les diff&#233;rentes m&#233;thodes
d&#8217;&#233;tiquetages d&#8217;EN propos&#233;es et leur caract&#233;ristiques. Nous pr&#233;sentons ensuite dans la section
3 notre proposition de syst&#232;me d&#8217;EEN par motifs. Nous d&#233;crivons une m&#233;thode d&#8217;extraction
de motifs de d&#233;tection non ambigus contenus dans un corpus encyclop&#233;dique, et la ressource
que nous avons obtenue. Puis, dans la section 4, nous &#233;valuons ce syst&#232;me de d&#233;tection &#224; base
de motifs en l&#8217;appliquant au corpus de test ESTER 2. Nous fusionnons ses r&#233;sultats avec ceux
obtenus par un EEN &#224; base de CRF et discutons du gain de performance obtenu. Nous conclu-
ons dans la section 5 qu&#8217;il est possible d&#8217;&#233;laborer une m&#233;thode peu co&#251;teuse d&#8217;introduction de
connaissance lexicale en compl&#233;ment des m&#233;thodes statistiques et que cette m&#233;thode permet
d&#8217;am&#233;liorer la robustesse des syst&#232;me d&#8217;EEN.
</p>
<p>2 M&#233;thodes d&#8217;&#233;tiquetage d&#8217;entit&#233;s nomm&#233;es
</p>
<p>Pour extraire les EN d&#8217;un texte l&#8217;utilisation, en tant que motifs de d&#233;tection, de lexiques d&#8217;en-
tit&#233;s issus de corpus tels que Wikip&#233;dia est une solution applicable (Bunescu &amp; Pasca, 2006;
Nothman et al., 2009; Kazama &amp; Torisawa, 2007) mais insuffisante pour plusieurs raisons.
En premier lieu, de nombreuses entit&#233;s &#224; d&#233;tecter sont absentes de ces corpus de ressources,
</p>
<p>1. Voir http://www-nlpir.nist.gov/related_projects/muc/proceedings/ne_task.
html.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G&#201;N&#201;RATION AUTOMATIQUE DE MOTIFS DE D&#201;TECTION D&#8217;ENTIT&#201;S NOMM&#201;ES.
</p>
<p>fussent-ils aussi vaste que Wikip&#233;dia (principe des mots hors vocabulaires ou OOV) ; en sec-
ond lieu, de nombreuses EN sont hautement ambigu&#235;s et ne permettent pas la d&#233;tection directe
sans recours &#224; une analyse de leur contexte. Les lexiques apparaissent donc toujours en renfort
d&#8217;un &#233;tiqueteur &#224; r&#232;gle ou en tant que ressource pour am&#233;liorer l&#8217;apprentissage d&#8217;un &#233;tiqueteur
statistique.
</p>
<p>2.1 M&#233;thodes automatiques par apprentissage
</p>
<p>De mani&#232;re g&#233;n&#233;rale, la plupart des approches de reconnaissance automatique reposent sur la
th&#233;orie des probabilit&#233;s et peuvent &#234;tre caract&#233;ris&#233;es par une m&#233;thode g&#233;n&#233;rative ou discrim-
inante selon que la distribution de probabilit&#233;s de la caract&#233;ristique &#224; reconna&#238;tre est mod-
&#233;lis&#233;e ou non. Cette diff&#233;rence joue un r&#244;le important dans la t&#226;che d&#8217;&#233;tiquetage d&#8217;EN. En
effet, un classifieur discriminant est th&#233;oriquement plus pr&#233;cis mais moins capable d&#8217;inf&#233;rer
qu&#8217;un classifieur g&#233;n&#233;ratif et donc moins adaptable aux innombrables possibilit&#233;s de repr&#233;sen-
tations d&#8217;une EN. Ces deux voies possibles d&#8217;approches se retrouvent dans la t&#226;che d&#8217;&#233;tique-
tage d&#8217;EN : les m&#233;thodes g&#233;n&#233;ratives, comme par exemple celle reposant sur des mod&#232;les de
Markov cach&#233;s (HMM) (Bikel et al., 1999), et les m&#233;thodes discriminantes telles que SVM,
Maximum Entropie (MaxEnt) (Borthwick et al., 1998). Les Champs Conditionnels Al&#233;atoires
(CRF) (Lafferty et al., 2001) occupent une place &#224; part car ils combinent une nature g&#233;n&#233;rative
et discriminante. Comme les mod&#232;les discriminants, ils tiennent compte, lors de la construc-
tion du mod&#232;le, des nombreuses observations issues du corpus d&#8217;apprentissage et les corr&#232;lent
entre elles lors de l&#8217;entrainement. Mais &#224; l&#8217;instar des mod&#232;les g&#233;n&#233;ratifs, les CRF probabilisent
les d&#233;cisions en fonction de la position des s&#233;quences d&#8217;apprentissage. Ce mode de fonction-
nement hybride qui favorise l&#8217;inf&#233;rence, c&#8217;est-&#224;-dire la reconnaissance par un classifieur CRF
d&#8217;une entit&#233; qu&#8217;il n&#8217;a jamais observ&#233;e dans le corpus d&#8217;apprentissage, mais aussi la pr&#233;cision
en utilisant les donn&#233;es d&#8217;apprentissage pour discriminer, explique pourquoi des &#233;tudes (Ray-
mond &amp; Riccardi, 2007) montrent r&#233;guli&#232;rement que les syst&#232;mes &#224; base de CRF sont plus
performants que ceux &#224; base de HMM, de SVM ou de MaxEnt pour r&#233;soudre la t&#226;che d&#8217;&#233;ti-
quetage d&#8217;EN avec un syst&#232;me automatique. La performance d&#8217;un syst&#232;me CRF est aussi tr&#232;s
largement d&#233;pendante de la formation des &#233;chantillons d&#8217;apprentissage qui vont lui &#234;tre soumis
(McCallum &amp; Li, 2003). Pourtant, dans un contexte exp&#233;rimental normalis&#233; tel que celui de la
campagne ESTER, quelque soit le soin apport&#233; &#224; la s&#233;lection des &#233;chantillons et &#224; la formation
du corpus d&#8217;apprentissage, il est r&#233;guli&#232;rement observ&#233; (voir par exemple (Raymond &amp; Fay-
olle, 2010)) que les performances du CRF demeurent inf&#233;rieures &#224; celles d&#8217;un EEN &#224; base de
r&#232;gles sur des donn&#233;es non bruit&#233;es.
</p>
<p>2.2 M&#233;thodes &#224; r&#232;gles et automates
</p>
<p>Les syst&#232;mes d&#8217;EEN &#224; base de r&#232;gles utilisent des m&#233;thodes linguistiques ou des automates
&#224; &#233;tats finis pour identifier les EN dans un texte. Certains de ces syst&#232;mes sont fortement in-
spir&#233;s par les m&#233;thodes linguistiques. Tel XIP (Brun et al., 2010) qui en partant d&#8217;un ensemble
de r&#232;gles, identifie les syntagmes noyaux et extrait les relations de d&#233;pendance syntaxiques
pour localiser des EN. L&#8217;analyse syntaxique peut d&#8217;ailleurs &#234;tre plus ou moins profonde pour
d&#233;tecter des structures qui fiabiliseront le processus de d&#233;tection des EN. D&#8217;autres syst&#232;mes</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>{ERIC.CHARTON, MICHEL.GAGNON, BENOIT.OZELL}@POLYMTL.CA
</p>
<p>Paris Prod
Pers
Org
LocIBM
</p>
<p>MC Paris
</p>
<p>IBM PC
</p>
<p>E Kf
</p>
<p>Prod
Pers
Org
Loc
</p>
<p>MC Paris
</p>
<p>IBM PC
</p>
<p>E Kg
</p>
<p>FIGURE 1 &#8211; Repr&#233;sentation du principe de r&#233;duction de l&#8217;ensemble de formes de surface
disponibles par identifications des motifs non discriminants.
</p>
<p>d&#8217;EEN &#224; r&#232;gles se contentent d&#8217;automates de d&#233;tection plus ou moins sophistiqu&#233;s. Ainsi, le
syst&#232;me CasEN, d&#233;ploy&#233; lors de la campagne ESTER 2 (Nouvel et al., 2010) exploite exclu-
sivement des transducteurs, environ 150, qui s&#8217;appliquent &#224; reconnaitre des s&#233;quences de mots
qui contiennent une EN.
</p>
<p>La plupart des syst&#232;mes de cette famille des syst&#232;mes d&#8217;EEN non automatiques compl&#232;tent
le processus de d&#233;tection par un ensemble de r&#232;gles tr&#232;s sp&#233;cialis&#233;es qui font appel &#224; des
ressources lexicales, des informations li&#233;es aux parties du discours, et parfois des traits lexico-
s&#233;mantiques.
</p>
<p>La litt&#233;rature fait apparaitre que la famille des &#233;tiqueteurs &#224; r&#232;gles utilise quasi syst&#233;matique-
ment des automates compl&#233;mentaires pour identifier les expressions num&#233;riques, les quantit&#233;s,
les devises, les dates. Ces automates, lorsqu&#8217;ils sont appuy&#233;s par des ressources lexicales, peu-
vent &#234;tre amen&#233;s &#224; jouer un r&#244;le plus ou moins important dans l&#8217;identification des EN de la
famille des noms propres. Mais de mani&#232;re g&#233;n&#233;rale, peu d&#8217;explications d&#233;taill&#233;es sont fournies
sur le r&#244;le et l&#8217;influence sur les performances globales des syst&#232;mes de ces ressources lexicales
associ&#233;es &#224; des automates. L&#8217;un des objectifs du travail pr&#233;sent&#233; dans cet article sera de con-
tribuer &#224; l&#8217;&#233;tude de l&#8217;influence des lexiques utilis&#233;s directement en tant qu&#8217;automates simples
pour d&#233;tecter des EN sans avoir &#224; utiliser le syst&#232;me de r&#232;gles ou le classifieur num&#233;rique.
</p>
<p>3 Syst&#232;me propos&#233;
</p>
<p>Nous proposons d&#8217;enrichir un syst&#232;me d&#8217;EEN &#224; base de CRF avec un ensemble de motifs de
d&#233;tection extraits automatiquement depuis l&#8217;encyclop&#233;die Wikip&#233;dia. Notre id&#233;e est qu&#8217;il est
possible d&#8217;am&#233;liorer les performances d&#8217;un syst&#232;me d&#8217;EEN par apprentissage automatique en
lui associant un module qui d&#233;tecterait les graphies non ambigu&#235;s des EN. Nous souhaitons
ainsi &#233;valuer &#224; quel point les motifs issus de ressources lexicales qui renforcent les syst&#232;mes &#224;
base de r&#232;gle influent sur les performances globales de cette famille d&#8217;&#233;tiqueteurs. Cette propo-
sition permet d&#8217;envisager d&#8217;int&#233;grer une connaissance lexicale rudimentaire dans un processus
d&#8217;EEN par CRF pour le rapprocher des performances des syst&#232;mes linguistiques et &#224; base de r&#232;-
gles. Les motifs de d&#233;tection que nous proposons d&#8217;extraire sont rudimentaires et ne concernent
que des EN non ambigu&#235;s. Leur principe fonctionnel peut &#234;tre illustr&#233; par ces exemples :</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G&#201;N&#201;RATION AUTOMATIQUE DE MOTIFS DE D&#201;TECTION D&#8217;ENTIT&#201;S NOMM&#201;ES.
</p>
<p>&#8211; Si nous prenons l&#8217;exemple du nom Montr&#233;al, celui-ci correspond &#224; plusieurs entit&#233;s dis-
tinctes (Montr&#233;al (Qu&#233;bec), Montr&#233;al (Ard&#232;che)) qui sont de classe identique, &#224; savoir des
localit&#233;s (&#233;tiquette LOC). Consid&#233;rons une graphie associ&#233;e &#224; une EN, que nous appelons
forme de surface de cette EN. Il est possible d&#8217;exploiter une forme de surface Montr&#233;al en
tant que motif pour d&#233;tecter plusieurs entit&#233;s nomm&#233;es d&#8217;identit&#233;s diff&#233;rentes mais qui sont
toute de type LOC.
</p>
<p>&#8211; La forme de surface Paris, en revanche, est associ&#233;e &#224; plusieurs entit&#233;s de type localit&#233; telles
que Paris, France ou Paris, Texas (LOC), mais aussi &#224; des noms de personnes (PERS.HUM)
Antoine Paris, Paris Hilton, de navires ou de produits (le Paquebot Paris (PROD.VEHICLE))
ou l&#8217;album musical Paris (PROD.DIV)). La forme de surface Paris est donc hautement
ambigu&#235; et ne peut &#234;tre utilis&#233;e en tant que motif de d&#233;tection susceptible d&#8217;identifier une
entit&#233; et de lui attribuer une classe d&#8217;&#233;tiquetage valable.
</p>
<p>&#8211; On pourra en revanche conserver les formes de surfaces int&#233;grant un &#233;l&#233;ment ambigu, mais
plus longues - de type bi-grammes &#224; n-grammes, si elles sont non ambigu&#235;s : ainsi les formes
de surface MC Paris (nom de personne) ou SS Paris (nom de v&#233;hicule) peuvent &#234;tre utilis&#233;es
en tant que motifs de d&#233;tection.
</p>
<p>On peut formaliser d&#8217;apr&#232;s ces exemples que l&#8217;ensemble des motifs de d&#233;tection non ambigus
est le sous ensemble injectif constitu&#233; des relations entre l&#8217;ensemble des formes de surfaces
et l&#8217;ensemble des classes qui leur sont reli&#233;es, si et seulement si tout &#233;l&#233;ment de l&#8217;ensemble
d&#8217;arriv&#233;e K poss&#232;de au plus un ant&#233;c&#233;dent par g de l&#8217;ensemble de d&#233;part E (voir figure 1).
</p>
<p>3.1 Extraction automatique de motifs de d&#233;tection
</p>
<p>Nous souhaitons extraire les motifs de d&#233;tection depuis l&#8217;encyclop&#233;die Wikip&#233;dia. Nous avons
pr&#233;sent&#233; dans (Charton &amp; Torres-Moreno, 2009) un syst&#232;me capable de produire, d&#8217;apr&#232;s un
corpus encyclop&#233;dique tel que Wikip&#233;dia, une ressource multilingue de concepts que nous
avons intitul&#233; m&#233;tadonn&#233;es. Ces m&#233;tadonn&#233;es incluent des noms propres, des noms communs,
des entit&#233;s nomm&#233;es, ainsi que des locutions rigoureusement class&#233;es selon la norme tax-
onomique de la campagne ESTER 2 et associ&#233;es chacune &#224; plusieurs formes de surface. La
proportion des ensembles de fiches encyclop&#233;diques transform&#233;es en m&#233;tadonn&#233;es affect&#233;es &#224;
chaque classe est pr&#233;sent&#233;e dans la table 1. Pour chaque m&#233;tadonn&#233;e, les formes de surfaces qui
permettent d&#8217;&#233;crire le concept encyclop&#233;dique sont collect&#233;es dans les &#233;ditions polonaise, itali-
enne, fran&#231;aise, anglaise, espagnole, allemande et italienne de Wikip&#233;dia. La quantit&#233; totale de
formes de surfaces disponibles est indiqu&#233;e dans la table 2. Un exemple d&#8217;ensemble de formes
de surfaces contenu dans une m&#233;tadonn&#233;e est montr&#233; dans la figure 2. Cet exemple 2 montre
l&#8217;ambigu&#239;t&#233; de certains motifs collect&#233;s dans le corpus encyclop&#233;dique. On peut observer dans
cet exemple que la forme Renault est hautement ambigu&#235; (puisqu&#8217;elle caract&#233;rise &#233;galement un
nom de personne dans l&#8217;encyclop&#233;die), en revanche, des s&#233;quences telles que Renault Nissan
Group, Renault Motor collect&#233;es depuis Wikip&#233;dia en Anglais ou encore le sigle RNUR col-
lect&#233; depuis Wikip&#233;dia en Polonais, sont des motifs de d&#233;tection non ambigus. Nous obtenons
ainsi un ensemble de paires compos&#233;es de motifs de d&#233;tections associ&#233;s &#224; une classe unique,
que nous allons utiliser trivialement dans un &#233;tiqueteur d&#8217;EN &#224; expression r&#233;guli&#232;res.
</p>
<p>2. Consultable en ligne sur http://www.nlgbase.org/perl/display.pl?query=
Renault&amp;search=EN</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>{ERIC.CHARTON, MICHEL.GAGNON, BENOIT.OZELL}@POLYMTL.CA
</p>
<p>Qt&#233; Contenu Classe taxonomique
3515 Fonctions et titres FONC
753629 Lieu LOC
346218 Organisations ORG
972663 Personne PERS
411569 Produit PROD
14294 Date TIME
621082 Contenu encyclop&#233;dique UNK
3122970 m&#233;tadonn&#233;es disponibles
</p>
<p>TABLE 1 &#8211; Quantit&#233; de m&#233;tadonn&#233;es disponibles pour chaque classe d&#8217;&#233;tiquetage.
</p>
<p>3 122 970 m&#233;tadonn&#233;es disponibles
8 142 183 formes de surface disponibles
5 832 730 formes de surface conserv&#233;es
</p>
<p>TABLE 2 &#8211; Formes de surfaces non ambigu&#235;s extraites depuis les m&#233;tadonn&#233;es et utilisables en
tant que motifs de d&#233;tection.
</p>
<p>3.2 &#201;tiqueteur CRF
</p>
<p>Nous utilisons en tant que baseline la premi&#232;re version de l&#8217;&#233;tiqueteur d&#8217;EN mis au point par
le LIA pour la campagne ESTER 2 (B&#233;chet &amp; Charton, 2010). Nous l&#8217;intitulons CRF-V1. Cet
&#233;tiqueteur a pour caract&#233;ristique d&#8217;&#234;tre entra&#238;n&#233; sur un corpus de grande taille pr&#233;alablement
&#233;tiquet&#233; par un &#233;tiqueteur HMM, en utilisant une ressource lexicale issue des m&#233;tadonn&#233;es. Des
it&#233;rations successives permettent de diminuer le bruit qui subsiste sur le corpus d&#8217;entrainement.
</p>
<p>La version que nous utilisons ici pour comparer notre syst&#232;me &#224; CRF-V1 est intitul&#233;e CRF-V2
et d&#233;crite dans (Charton &amp; Torres-Moreno, 2010). Elle compl&#232;te la phase de pr&#233;paration par
HMM du corpus d&#8217;entrainement par un &#233;tiquetage suppl&#233;mentaire utilisant les liens internes
de Wikip&#233;dia. CRF-V2 est appris sur un ensemble de phrases issues du corpus d&#8217;entrainement
d&#8217;ESTER 2, renforc&#233; par 140 000 phrases &#233;tiquet&#233;es extraites depuis Wikip&#233;dia en fran&#231;ais.
CRF-V2 est l&#233;g&#232;rement plus performant que CRF-V1. Il a d&#233;j&#224; &#233;t&#233; d&#233;ploy&#233; dans le syst&#232;me
Poly-Co du challenge GREC 2010 3.
</p>
<p>L&#8217;architecture compl&#232;te du syst&#232;me est la suivante. Dans un premier temps, les deux &#233;tiqueteurs
d&#8217;EN, celui &#224; motifs et celui &#224; CRF, sont appliqu&#233;s sur le document &#224; &#233;tiqueter. On obtient par
ce moyen deux documents &#233;tiquet&#233;s que nous nommerons doc.crf et doc.rule. L&#8217;&#233;tiquetage
des EN de ces documents est soit un nom de classe k (issu de la taxonomie ESTER) soit le
label ind&#233;fini UNK appliqu&#233; lorsqu&#8217;aucune &#233;tiquette n&#8217;est attribu&#233;e. Dans un second temps une
fusion de doc.crf et doc.rule est r&#233;alis&#233;e. Le processus de fusion est trivial et consiste &#224; com-
parer les &#233;tiquettes appliqu&#233;es &#224; doc.crf et doc.rule en donnant priorit&#233; &#224; l&#8217;un des documents.
L&#8217;algorithme de fusion donne ici priorit&#233; aux EN contenues dans doc.crf .
</p>
<p>3. Voir http://www.itri.brighton.ac.uk/research/genchal10/grec/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G&#201;N&#201;RATION AUTOMATIQUE DE MOTIFS DE D&#201;TECTION D&#8217;ENTIT&#201;S NOMM&#201;ES.
</p>
<p>FIGURE 2 &#8211; Un exemple de formes de surface collect&#233;es pour la m&#233;tadonn&#233;es de classe ORG
correspondant &#224; la fiche encyclop&#233;dique du constructeur automobile Renault dans plusieurs
&#233;ditions linguistiques de Wikip&#233;dia.
</p>
<p>4 &#201;valuation et r&#233;sultats
</p>
<p>Nous &#233;valuons les capacit&#233;s d&#8217;un EEN &#224; base de motifs en le comparant aux autres m&#233;thodes
d&#8217;&#233;tiquetage dont les r&#233;sultats sont connus pour un corpus de r&#233;f&#233;rence. Puis nous &#233;valuons les
performances d&#8217;un EEN &#224; CRF renforc&#233; par l&#8217;EEN &#224; motifs. Notre exp&#233;rience vise &#224; mesurer
jusqu&#8217;&#224; quel point l&#8217;introduction de motifs de d&#233;tection non ambigus et collect&#233;s automatique-
ment peuvent am&#233;liorer les performances du CRF, et le cas &#233;ch&#233;ant jusqu&#8217;&#224; quel point il permet
de rapprocher les performances des CRF de ceux &#224; base de r&#232;gles, sur des corpus non bruit&#233;s.
Nous utiliserons le corpus de test de la campagne ESTER 2.
</p>
<p>4.1 Corpus et mesures de r&#233;f&#233;rence
</p>
<p>Le corpus complet de la t&#226;che de d&#233;tection d&#8217;EN d&#8217;ESTER 2 se compose de 72 heures d&#8217;&#233;mis-
sions radiophoniques francophones (France-Inter, France Info, RFI, RTM, France Culture, Ra-
dio Classique) manuellement transcrites et annot&#233;es en EN suivant les conventions des deux
campagnes ESTER. La premi&#232;re campagne comportait un jeu de 30 types d&#8217;EN r&#233;parties en 9
cat&#233;gories racines, alors que la seconde poss&#232;de un jeu de 37 types d&#8217;entit&#233;s nomm&#233;es r&#233;par-
ties en 7 cat&#233;gories racines (personne, fonction, organisation, lieu, fabrication humaine, date et
heure, quantit&#233;s). Seules les cat&#233;gories racines sont mesur&#233;es dans les r&#233;sultats de r&#233;f&#233;rence.
La campagne ESTER 2 pr&#233;voit plusieurs t&#226;ches de reconnaissance d&#8217;EN : la premi&#232;re consiste
&#224; reconna&#238;tre les EN dans la transcription manuelle du corpus de test (NE-Ref). La seconde
s&#8217;applique &#224; trois transcriptions automatiques dites ASR et dont les taux d&#8217;erreurs de recon-
naissance de mots vont croissants : 12.11%, 17.83% et 26.09%. La volont&#233; de l&#8217;organisateur
est ici de tester la pr&#233;cision des syst&#232;mes sur NE-Ref qui est non bruit&#233;, mais aussi leur ro-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>{ERIC.CHARTON, MICHEL.GAGNON, BENOIT.OZELL}@POLYMTL.CA
</p>
<p>EN AMOUNT FONC LOC ORG PERS PROD TIME tous
Qt&#233; 239 196 1215 1267 1108 58 1025 5123
pr&#233;cision 0,85 0,61 0,77 0,79 0,93 0,53 0,91 0,86
rappel 0,56 0,559 0,81 0,63 0,75 0,12 0,60 0,718
F-Score 0,68 0,58 0,79 0,70 0,84 0,20 0,73 0,78
</p>
<p>TABLE 3 &#8211; R&#233;sultats par entit&#233; &#224; &#233;tiqueter du syst&#232;me LIA dit CRF-V1 appliqu&#233; au corpus
NE-Ref lors de la campagne ESTER 2.
</p>
<p>EN AMOUNT FONC LOC ORG PERS PROD TIME tous
Qt&#233; 239 196 1215 1267 1108 58 1025 5123
pr&#233;cision 0,93 0,818 0,897 0,89 0,97 100 0,95 0,93
rappel 0,86 0,899 0,88 0,83 0,95 0,42 0,95 0,91
F-Score 0,90 0,85 0,89 0,87 0,97 0,59 0,96 0,93
</p>
<p>TABLE 4 &#8211; R&#233;sultats par entit&#233; &#224; &#233;tiqueter du syst&#232;me XIP de Xerox &#224; base de r&#232;gles appliqu&#233;
au corpus NE-Ref lors de la campagne ESTER 2.
</p>
<p>bustesse dans le contexte plus difficile des corpus de test ASR bruit&#233;s de mani&#232;re croissante.
</p>
<p>Les r&#233;sultats de la campagne ESTER 2 (Galliano et al., 2009) soulignent l&#8217;efficacit&#233; d&#8217;un sys-
t&#232;me EEN &#224; base de r&#232;gle linguistique sur la transcription de r&#233;f&#233;rence (NE-Ref). Sur ce corpus,
les deux meilleurs syst&#232;mes sont &#224; base de r&#232;gle, et le troisi&#232;me est de type automatique &#224; base
de CRF. Le tableau 4 pr&#233;sente les r&#233;sultats obtenus par le meilleur syst&#232;me sur transcriptions de
r&#233;f&#233;rence (NE-Ref) en termes de Pr&#233;cision, Rappel, F-Score. Le tableau 3 pr&#233;sente les r&#233;sultats
du meilleur syst&#232;me automatique &#224; CRF sur ce m&#234;me corpus de r&#233;f&#233;rence. Nous consid&#233;rerons
les r&#233;sultats du meilleur syst&#232;me linguistique (XIP) et du meilleur syst&#232;me automatique (CRF-
V1) sur le corpus NE-Ref pour situer les performances obtenues par l&#8217;hybridation de l&#8217;&#233;tique-
teur &#224; motif, que nous appellerons ici EEN-M, avec CRF-V2.
</p>
<p>Ce plan d&#8217;exp&#233;rience vise &#224; &#233;valuer dans quelle mesure un ensemble de motifs appris automa-
tiquement sur un corpus encyclop&#233;dique peut am&#233;liorer les performances du syst&#232;me CRF et
jusqu&#8217;&#224; quel point les performances de ce syst&#232;me CRF am&#233;lior&#233; peuvent se rapprocher d&#8217;un
syst&#232;me d&#8217;EEN de nature linguistique &#224; l&#8217;&#233;tat de l&#8217;art (en l&#8217;occurrence le syst&#232;me XIP). Notre
exp&#233;rience consistera &#224; appliquer au corpus NE-Ref d&#8217;ESTER 2 les d&#233;tecteurs EEN-M et CRF-
V2 et &#224; fusionner leurs r&#233;sultats puis &#224; mesurer les performances de chaque &#233;l&#233;ment de notre
syst&#232;me.
</p>
<p>4.2 R&#233;sultats
</p>
<p>Le tableau 5 expose les r&#233;sultats des diff&#233;rents composants de notre syst&#232;me d&#8217;EEN. Il indique
pour chaque jeu d&#8217;&#233;tiquettes du corpus de test NE-Ref ESTER 2 les performances individuelles
de chaque composant. Dans la section motif du tableau, qui pr&#233;sente les r&#233;sultats de l&#8217;&#233;tique-
teur par d&#233;tection de motif EEN-M, on remarque que la classe AMOUNT n&#8217;est pas trait&#233;e par
ce composant d&#8217;&#233;tiquetage car non observ&#233;e dans les m&#233;tadonn&#233;es utilis&#233;es pour collecter les
motifs. La classe TIME qui correspond aux dates dans le corpus ESTER 2 est pour ce qui la</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G&#201;N&#201;RATION AUTOMATIQUE DE MOTIFS DE D&#201;TECTION D&#8217;ENTIT&#201;S NOMM&#201;ES.
</p>
<p>EN AMOUNT FONC LOC ORG PERS PROD TIME tous
Qt&#233; 239 196 1215 1267 1108 58 1025 5123
</p>
<p>EEN-M pr&#233;cision x 0,85 0,73 0,94 0,98 0.11 0,96 0,88
/ Motifs rappel x 0,30 0,32 0,27 0,50 0,07 0,36 0,34
</p>
<p>F-Score x 0,43 0,44 0,42 0,66 0,08 0,53 0,48
CRF-V2 pr&#233;cision 0,90 0,99 0,77 0,92 0,94 0.38 0,97 0,88
</p>
<p>rappel 0,70 0,46 0,90 0,61 0,93 0,25 0,69 0,74
F-Score 0,79 0,63 0,83 0,73 0,93 0,30 0,89 0,80
</p>
<p>Hybride pr&#233;cision 0.90 0.91 0.76 0,91 0,96 0.27 0,96 0,88
rappel 0,70 0,55 0,92 0,60 0,93 0,25 0,83 0,78
F-Score 0,79 0,69 0,83 0,72 0,94 0,26 0,90 0,83
</p>
<p>CRF-V1 F-Score 0,68 0,58 0,79 0,70 0,84 0,20 0,73 0,78
</p>
<p>TABLE 5 &#8211; R&#233;sultats d&#233;taill&#233;s du syst&#232;me EEN &#224; motifs de d&#233;tection, CRF (dit CRF-V2) et hy-
bride, compar&#233; au syst&#232;me CRF du LIA (dit CRF-V1) ayant obtenu les meilleures perfomances
sur le corpus de test NE-Ref de la campagne ESTER 2.
</p>
<p>concerne trait&#233;e car cette classe de contenu est repr&#233;sent&#233;e dans Wikip&#233;dia et donc mod&#233;lis&#233;e
dans les m&#233;tadonn&#233;es 4. On note que EEN-M offre une couverture de d&#233;tection des EN relative-
ment faible (rappel de 0,34) mais une pr&#233;cision sup&#233;rieure &#224; celle de CRF-V1. Cette pr&#233;cision
est &#233;galement sup&#233;rieure &#224; celle de l&#8217;&#233;tiqueteur &#224; r&#232;gles linguistique pr&#233;sent&#233; dans le tableau 4
pour les classes FONC, ORG et TIME. Il est important de remarquer les performances inf&#233;rieures
de EEN-M sur la d&#233;tection de la classe LOC qui sont attribuables &#224; l&#8217;impossibilit&#233; pour EEN-M
de traiter la diff&#233;rence entre les notions LOC.ADMI et ORG.GSP (un nom toponymique peut
d&#233;signer une localit&#233; ou une organisation g&#233;o-politique dans le corpus ESTER 2) par un sys-
t&#232;me &#224; motif.
</p>
<p>La section CRF-V2 pr&#233;sente les r&#233;sultats de l&#8217;&#233;tiqueteur CRF am&#233;lior&#233; tel que d&#233;crit dans la
section 3. On observe que les performances de cet &#233;tiqueteur sont l&#233;g&#232;rement meilleures que
celles de l&#8217;&#233;tiqueteur d&#233;ploy&#233; par le LIA lors de la campagne ESTER 2, et dont les r&#233;sul-
tats sont indiqu&#233;s dans la section CRF-V1 du tableau. Une comparaison plus d&#233;taill&#233;e avec
le tableau 3 montre que les performances de CRF-V2 sont am&#233;lior&#233;es globalement tant pour
la pr&#233;cision que le rappel, avec les m&#234;mes difficult&#233;s de mod&#233;lisation des s&#233;quences d&#8217;EN de
type PROD. L&#8217;am&#233;lioration des performances du syst&#232;me CRF-V2 appliqu&#233; sur NE-Ref, par
rapport &#224; CRF-V1, n&#8217;est pas l&#8217;objet de cette communication, mais doivent &#234;tre comment&#233;es ici
car l&#8217;am&#233;lioration de la pr&#233;cision joue un r&#244;le sur le processus de fusion. Les exp&#233;riences de fu-
sions que nous avons men&#233;es entre les r&#233;sultats produits par CRF-V1 et ceux de EEN-M nous
ont montr&#233; une tr&#232;s l&#233;g&#232;re minoration des performances globales du syst&#232;me (les moindres
performances de CRF-V1 &#233;tant compens&#233;es par l&#8217;introduction des EN d&#233;tect&#233;es par EEN-M).
</p>
<p>L&#8217;hybridation de EEN-M et CRF-V2 indiqu&#233;e dans la ligne Hybride du tableau 5, est le r&#233;sultat
de la fusion entre les deux sorties de ces syst&#232;mes. Elle montre un gain de performance de 3%
sur CRF-V2 seul, et de plus de 5% par rapport &#224; CRF-V1 d&#233;ploy&#233; lors de ESTER 2.
</p>
<p>4. Voir par exemple la cat&#233;gorie http://fr.wikipedia.org/wiki/Categorie:Jour_de_
septembre et une m&#233;tadonn&#233;e telle que http://www.nlgbase.org/perl/display.pl?query=
2septembre&amp;search=FR</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>{ERIC.CHARTON, MICHEL.GAGNON, BENOIT.OZELL}@POLYMTL.CA
</p>
<p>4.3 Discussion
</p>
<p>Il appara&#238;t que le syst&#232;me de d&#233;tection hybride &#224; base de motifs et de CRF propos&#233; am&#233;liore
substantiellement les performances du syst&#232;me CRF-V1 d&#233;ploy&#233; lors de la campagne ESTER
2 sur le corpus de r&#233;f&#233;rence NE-Ref.
</p>
<p>On notera que les exp&#233;riences d&#8217;hybridation de m&#233;tadonn&#233;es et du syst&#232;me CRF qui avaient
&#233;t&#233; employ&#233;es lors de cette campagne, qui reposaient sur une d&#233;tection de motifs non d&#233;sam-
bigu&#239;s&#233;s associ&#233;e &#224; un calcul de similarit&#233; cosinus entre le contexte du motif et les m&#233;ta-
donn&#233;es, n&#8217;avaient produit qu&#8217;un gain de 1% sur un F-Score du CRF de 0,77 (voir sur ce
point (B&#233;chet &amp; Charton, 2010)). Le module de d&#233;tection de motifs exp&#233;riment&#233; dans cet ar-
ticle introduit un gain de 3% sur un F-Score de CRF de 0,80. Ce gain souligne le potentiel de
la m&#233;thode. On observe par ailleurs que notre proposition r&#233;duit globalement l&#8217;&#233;cart de per-
formance entre un syst&#232;me &#224; r&#232;gles et un syst&#232;me statistique compl&#233;t&#233; par des motifs, sur une
transcription de r&#233;f&#233;rence corrig&#233;e telle que NE-Ref de ESTER2.
</p>
<p>En terme de pr&#233;cisions, les performances de notre syst&#232;me s&#8217;approchent pour plusieurs classes
de celles obtenues par le meilleur syst&#232;me &#224; r&#232;gles linguistiques appliqu&#233; sur NE-Ref, lors
de la campagne ESTER 2. Ces r&#233;sultats permettent d&#8217;envisager qu&#8217;une augmentation de la
couverture des formes de surfaces extraites des m&#233;tadonn&#233;es (par exemple &#224; la suite d&#8217;une
augmentation de la quantit&#233; de formes de surfaces disponibles dans Wikip&#233;dia) puisse fournir
d&#8217;autres gains de performance.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Nous avons d&#233;crit une m&#233;thode d&#8217;introduction dans un syst&#232;me d&#8217;&#233;tiquetage d&#8217;entit&#233;s nom-
m&#233;es &#224; base de CRF d&#8217;un composant d&#8217;identification d&#8217;EN exploitant des motifs de d&#233;tection
collect&#233;s automatiquement dans un corpus encyclop&#233;dique. Il &#233;tait apparu lors de la campagne
ESTER 2 qu&#8217;un syst&#232;me CRF correctement entrain&#233; pouvait obtenir les meilleurs r&#233;sultats sur
un corpus bruit&#233;, mais que les syst&#232;mes d&#8217;EEN &#224; r&#232;gles linguistiques &#233;taient plus performants
sur des corpus non bruit&#233;s. Nous avons donc cherch&#233; &#224; &#233;valuer dans quelle mesure le renforce-
ment d&#8217;un CRF par des motifs de d&#233;tection simples pouvait r&#233;duire l&#8217;&#233;cart de performances
entre un &#233;tiqueteur CRF et un &#233;tiqueteur &#224; base de r&#232;gle sur un document textuel non bruit&#233;.
Nous avons montr&#233; que notre proposition pouvait amener un gain de performances global im-
portant sur un syst&#232;me CRF, et am&#233;liorer de mani&#232;re cons&#233;quente sa pr&#233;cision. La solution
que nous proposons am&#233;liore la robustesse d&#8217;un syst&#232;me CRF sur des corpus non bruit&#233;s et
r&#233;duit l&#8217;&#233;cart avec un syst&#232;me d&#8217;EEN linguistique tout en conservant au CRF son faible co&#251;t
de d&#233;veloppement, l&#8217;int&#233;gralit&#233; du processus d&#8217;entrainement de notre syst&#232;me demeurant au-
tomatique. La pr&#233;cision du syst&#232;me que nous avons &#233;labor&#233; et sa facilit&#233; de d&#233;ploiement nous
ont permis de l&#8217;entrainer dans plusieurs versions linguistiques (Fran&#231;ais, Espagnol et Anglais)
et de l&#8217;exploiter en tant que module dans des applications qui prolongent la t&#226;che d&#8217;&#233;tiquetage
d&#8217;entit&#233;s nomm&#233;es. Nous travaillons en particulier sur la d&#233;tection de co-r&#233;f&#233;rences et avons &#224;
ce titre d&#233;ploy&#233; cet &#233;tiqueteur dans sa version anglaise en tant que composant de l&#8217;architecture
de d&#233;tection de co-r&#233;f&#233;rence du challenge Grec 2010 ou il a obtenu des r&#233;sultats satisfaisants 5.
</p>
<p>5. Les ressources d&#233;crites sont disponibles sous forme d&#8217;API et en t&#233;l&#233;chargement sur www.nlgbase.org.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G&#201;N&#201;RATION AUTOMATIQUE DE MOTIFS DE D&#201;TECTION D&#8217;ENTIT&#201;S NOMM&#201;ES.
</p>
<p>R&#233;f&#233;rences
</p>
<p>B&#201;CHET F. &amp; CHARTON E. (2010). Unsupervised knowledge acquisition for extracting
named entities from speech. In ICASSP 2010, Dallas : ICASSP.
</p>
<p>BIKEL D., SCHWARTZ R. &amp; WEISCHEDEL R. (1999). An algorithm that learns whats in a
name. Machine learning, 7.
</p>
<p>BORTHWICK A., STERLING J., AGICHTEIN E. &amp; R (1998). Exploiting diverse knowledge
sources via maximum entropy in named entity. Proc. of the Sixth, p. 152&#8211;160.
</p>
<p>BRUN C., EHRMANN M. &amp; MAUPERTUIS C. D. (2010). Un syst&#232;me de d&#233;tection d&#8217;entit&#233;s
nomm&#233;es adapt&#233; pour la campagne d&#8217;&#233;valuation ESTER 2. In TALN 2010, volume 2.
</p>
<p>BUNESCU R. &amp; PASCA M. (2006). Using encyclopedic knowledge for named entity disam-
biguation. In Proceedings of EACL, volume 6.
</p>
<p>CHARTON E. &amp; TORRES-MORENO J. (2009). Classification d&#8217;un contenu encyclop&#233;dique
en vue d&#8217;un &#233;tiquetage par entit&#233;s nomm&#233;es. In Taln 2009, volume 1, p. 24&#8211;26 : TALN.
</p>
<p>CHARTON E. &amp; TORRES-MORENO J. (2010). NLGbAse : a free linguistic resource for Natu-
ral Language Processing systems. In LREC, Ed., LREC 2010, number 1, Matla : Proceedings
of LREC 2010.
</p>
<p>DODDINGTON G., MITCHELL A., PRZYBOCKI M., RAMSHAW L., STRASSEL S. &amp;
WEISCHEDEL R. (2004). The automatic content extraction (ACE) program&#8211;tasks, data, and
evaluation. In Proceedings of LREC, volume 4, p. 837&#8211;840 : Citeseer.
</p>
<p>GALLIANO S., GRAVIER G. &amp; CHAUBARD L. (2009). The ESTER 2 Evaluation Campaign
for the Rich Transcription of French Radio Broadcasts. In International Speech Communica-
tion Association conference 2009, p. 2583&#8211;2586 : Interspeech 2010.
</p>
<p>KAZAMA J. &amp; TORISAWA K. (2007). Exploiting Wikipedia as external knowledge for
named entity recognition. In Proceedings of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational Natural Language Learning (EMNLP-
CoNLL), p. 698&#8211;707.
</p>
<p>LAFFERTY J., MCCALLUM A. &amp; PEREIRA F. (2001). Conditional random fields : Proba-
bilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth
International Conference on Machine Learning, p. 282&#8211;289 : Citeseer.
</p>
<p>MCCALLUM A. &amp; LI W. (2003). Early results for named entity recognition with conditional
random fields, feature induction and web-enhanced lexicons. In Proceedings of the seventh
conference on Natural language learning at HLT-NAACL 2003 -, p. 188&#8211;191, Morristown,
NJ, USA : Association for Computational Linguistics.
</p>
<p>NOTHMAN J., MURPHY T. &amp; CURRAN J. (2009). Analysing Wikipedia and gold-standard
corpora for NER training. In Proceedings of the 12th Conference of the European Chapter
of the Association for Computational Linguistics, number April, p. 612&#8211;620 : Association for
Computational Linguistics.
</p>
<p>NOUVEL D., ANTOINE J., FRIBURGER N. &amp; MAUREL D. (2010). An analysis of the per-
formances of the casen named entities recognition system in the ester2 evaluation campaign.
LREC 2010.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>{ERIC.CHARTON, MICHEL.GAGNON, BENOIT.OZELL}@POLYMTL.CA
</p>
<p>RAYMOND C. &amp; FAYOLLE J. (2010). Reconnaissance robuste d&#8217;entit&#233;s nomm&#233;es sur de
la parole transcrite automatiquement. In Traitement Automatique des Langues Naturelles,
volume 1, p. 19&#8211;23.
</p>
<p>RAYMOND C. &amp; RICCARDI G. (2007). Generative and discriminative algorithms for spoken
language understanding. In Proceedings of Interspeech2007, Antwerp, Belgium, p.2&#771; : Citeseer.
</p>
<p>TJONG E. &amp; MEULDER F. D. (2003). Introduction to the conll-2003 shared task : Language-
independent named entity recognition. In In CoNLL.</p>

</div></div>
</body></html>