<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Une approche faiblement supervis&#233;e pour l&#8217;extraction de relations &#224; large &#233;chelle</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Une approche faiblement supervis&#233;e pour l&#8217;extraction de relations &#224; large
&#233;chelle
</p>
<p>Ludovic Jean-Louis Romaric Besan&#231;on Olivier Ferret Adrien Durand
CEA, LIST, Laboratoire Vision et Ing&#233;nierie des Contenus
</p>
<p>Fontenay-aux-Roses, F-92265, France.
{ludovic.jean-louis,romaric.besancon,olivier.ferret,adrien.durand}@cea.fr
</p>
<p>R&#233;sum&#233;. Les syst&#232;mes d&#8217;extraction d&#8217;information traditionnels se focalisent sur un domaine sp&#233;cifique et
un nombre limit&#233; de relations. Les travaux r&#233;cents dans ce domaine ont cependant vu &#233;merger la probl&#233;matique
des syst&#232;mes d&#8217;extraction d&#8217;information &#224; large &#233;chelle. &#192; l&#8217;instar des syst&#232;mes de question-r&#233;ponse en domaine
ouvert, ces syst&#232;mes se caract&#233;risent &#224; la fois par le traitement d&#8217;un grand nombre de relations et par une absence
de restriction quant aux domaines abord&#233;s. Dans cet article, nous pr&#233;sentons un syst&#232;me d&#8217;extraction d&#8217;infor-
mation &#224; large &#233;chelle fond&#233; sur un apprentissage faiblement supervis&#233; de patrons d&#8217;extraction de relations. Cet
apprentissage repose sur la donn&#233;e de couples d&#8217;entit&#233;s en relation dont la projection dans un corpus de r&#233;f&#233;rence
permet de constituer la base d&#8217;exemples de relations support de l&#8217;induction des patrons d&#8217;extraction. Nous pr&#233;sen-
tons &#233;galement les r&#233;sultats de l&#8217;application de cette approche dans le cadre d&#8217;&#233;valuation d&#233;fini par la t&#226;che KBP
de l&#8217;&#233;valuation TAC 2010.
</p>
<p>Abstract. Standard Information Extraction (IE) systems are designed for a specific domain and a limited
number of relations. Recent work has been undertaken to deal with large-scale IE systems. Such systems are
characterized by a large number of relations and no restriction on the domain, which makes difficult the definition
of manual resources or the use of supervised techniques. In this paper, we present a large-scale IE system based
on a weakly supervised method of pattern learning. This method uses pairs of entities known to be in relation to
automatically extract example sentences from which the patterns are learned. We present the results of this system
on the data from the KBP task of the TAC 2010 evaluation campaign.
</p>
<p>Mots-cl&#233;s : extraction d&#8217;information, extraction de relations.
Keywords: information extraction, relation extraction.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LUDOVIC JEAN-LOUIS, ROMARIC BESAN&#199;ON, OLIVIER FERRET, ADRIEN DURAND
</p>
<p>1 Introduction
</p>
<p>Dans le cadre de l&#8217;extraction d&#8217;information, l&#8217;extraction de relations est un processus dont l&#8217;objectif est de d&#233;ter-
miner l&#8217;existence d&#8217;un lien s&#233;mantique entre deux entit&#233;s et lorsque cela est possible, de caract&#233;riser la nature de
ce lien. Nous nous int&#233;ressons plus particuli&#232;rement dans cette &#233;tude &#224; l&#8217;extraction de relations entre entit&#233;s nom-
m&#233;es en vue de la collecte et de la construction d&#8217;une base de connaissances &#224; large &#233;chelle. En effet, on trouve
dans des sources d&#8217;informations ouvertes, en particulier dans le contexte du Web s&#233;mantique, un grand nombre
d&#8217;informations disponibles sous forme semi-structur&#233;e : par exemple, l&#8217;encyclop&#233;die Wikip&#233;dia contient des in-
formations qui peuvent &#234;tre structur&#233;es sous forme d&#8217;une base de donn&#233;es, comme le montre le projet DBpedia1
(Bizer et al., 2009). Cette structuration premi&#232;re des informations semi-structur&#233;es peut alors &#234;tre compl&#233;t&#233;e par
l&#8217;extraction automatique de relations entre entit&#233;s &#224; partir de texte brut.
</p>
<p>Les travaux ayant pour objet l&#8217;extraction de relations peuvent &#234;tre consid&#233;r&#233;s selon l&#8217;angle du degr&#233; de supervision
qu&#8217;ils requi&#232;rent. Au degr&#233; le plus faible, que l&#8217;on qualifie d&#8217;approche non supervis&#233;e, le type des relations &#224;
extraire n&#8217;est pas d&#233;fini a priori, que ce soit par le biais d&#8217;exemples ou d&#8217;un mod&#232;le. Tout au plus peuvent &#234;tre
fix&#233;es certaines contraintes sur les entit&#233;s reli&#233;es, comme leur type par exemple. Le type des relations extraites
est quant &#224; lui d&#233;fini a posteriori, en regroupant les relations jug&#233;es similaires. Une telle approche est mise en
&#339;uvre dans (Shinyama &amp; Sekine, 2006) ou dans (Banko &amp; Etzioni, 2008) par exemple. &#192; l&#8217;autre extr&#234;me de
cette &#233;chelle, le type des relations vis&#233;es mais aussi les moyens de les extraire &#224; partir des textes sont d&#233;finis
a priori. Cette approche dite supervis&#233;e se caract&#233;rise soit par la donn&#233;e d&#8217;un mod&#232;le &#233;labor&#233; manuellement,
typiquement sous la forme de r&#232;gles, soit par l&#8217;association d&#8217;un ensemble d&#8217;exemples de relations en contexte
issus de l&#8217;annotation d&#8217;un corpus et d&#8217;un algorithme d&#8217;apprentissage permettant d&#8217;en construire automatiquement
un mod&#232;le. Cette seconde option est domin&#233;e par les mod&#232;les d&#8217;apprentissage statistique, qui se focalisent sur la
prise en compte d&#8217;un large spectre de caract&#233;ristiques de diff&#233;rents types (lexicales, syntaxiques, s&#233;mantiques ...)
(Zhou et al., 2005) et sur l&#8217;&#233;laboration de fonctions noyaux permettant de prendre en compte ces caract&#233;ristiques,
en particulier lorsqu&#8217;elles ont des structures complexes comme celles produites par l&#8217;analyse syntaxique (Zhou
et al., 2007).
Entre ces deux p&#244;les se trouvent les approches dites faiblement supervis&#233;es, vocable recouvrant l&#8217;id&#233;e que des
exemples ou un mod&#232;le sont fournis pour le d&#233;veloppement du syst&#232;me d&#8217;extraction de relations mais que cette
seule contribution n&#8217;est pas suffisante pour la r&#233;alisation d&#8217;un syst&#232;me pleinement op&#233;rationnel. De ce fait, elle doit
&#234;tre &#233;tendue de mani&#232;re automatique, g&#233;n&#233;ralement en exploitant un corpus non annot&#233;. Les travaux existant en la
mati&#232;re font appara&#238;tre deux cas de sous-d&#233;termination de la contribution initiale, cas pouvant &#234;tre &#233;ventuellement
associ&#233;s :
</p>
<p>&#8211; une sous-d&#233;termination li&#233;e au volume de cette contribution. Seul un petit ensemble de relations exemples ou
un mod&#232;le incomplet sont fournis ;
</p>
<p>&#8211; une sous-d&#233;termination li&#233;e &#224; la nature de la contribution initiale, ce qui se produit lorsque les exemples ou le
mod&#232;le doivent &#234;tre instanci&#233;s pour &#234;tre utilis&#233;s.
</p>
<p>Le premier cas de figure est typiquement trait&#233; suivant la m&#233;thodologie initi&#233;e par Hearst (1992) gr&#226;ce &#224; un m&#233;-
canisme d&#8217;amor&#231;age exploitant le petit ensemble initial d&#8217;exemples de relations ou de r&#232;gles d&#8217;extraction pour
acqu&#233;rir de nouveaux exemples &#224; partir d&#8217;un corpus et venir ainsi enrichir progressivement le mod&#232;le des relations
vis&#233;es au fil de cycles successifs d&#8217;application de ces deux &#233;tapes. (Agichtein &amp; Gravano, 2000) en est un repr&#233;-
sentant typique pour les relations entre entit&#233;s nomm&#233;es. Bien qu&#8217;op&#233;rant dans un champ diff&#233;rent &#8211; l&#8217;extraction
de structures qualia &#8211; (Claveau &amp; S&#233;billot, 2004) offre un autre exemple d&#8217;amor&#231;age pour l&#8217;induction de patrons
linguistiques en combinant deux syst&#232;mes aux caract&#233;ristiques diff&#233;rentes.
</p>
<p>Le second cas de figure est quant &#224; lui illustr&#233; par la notion r&#233;cente de &#171; Distant supervision &#187;, introduite formel-
lement par (Mintz et al., 2009) mais d&#233;j&#224; pr&#233;sente dans certains travaux sur l&#8217;amor&#231;age. Les exemples sont ici
donn&#233;s sous une forme sous-d&#233;termin&#233;e puisque r&#233;duite &#224; un couple d&#8217;entit&#233;s : ils sont donc &#224; la fois priv&#233;s de
contexte et de caract&#233;risation linguistiques. Le d&#233;veloppement de ce type d&#8217;approches est favoris&#233; par la mise &#224;
disposition de larges bases de connaissances extraites de ressources telles que Wikip&#233;dia.
</p>
<p>Dans cet article, nous pr&#233;sentons un syst&#232;me d&#8217;extraction d&#8217;information &#224; large &#233;chelle fond&#233; sur un apprentissage
faiblement supervis&#233; de patrons d&#8217;extraction de relations reposant sur des exemples sous la forme de couples d&#8217;en-
tit&#233;s. Ces couples sont projet&#233;s dans un corpus de r&#233;f&#233;rence pour constituer la base d&#8217;exemples de relations &#224; partir
</p>
<p>1http://dbpedia.org/About</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>EXTRACTION DE RELATIONS &#192; LARGE &#201;CHELLE
</p>
<p>Relations connues
rel(E1,E2)
</p>
<p>Relations &#224; compl&#233;ter
rel(E1,?)corpus
</p>
<p>Recherche d'occurrences 
de relations
</p>
<p>Induction de patrons
</p>
<p>Recherche de phrases 
candidates
</p>
<p>Application des patrons
</p>
<p>Extraction-s&#233;lection des 
r&#233;ponses
</p>
<p>Filtrage des r&#233;ponses
</p>
<p>Apprentissage des patrons de relations Extraction des relations
</p>
<p>Patrons de relations
</p>
<p>Expansion
</p>
<p>Relations extraites
</p>
<p>founded(Metawe,2005)
founded(HDNet,2001)
</p>
<p>... network was HDNet, founded in 2001 by Dallas..
Metaweb, founded in 2005 is a spinoff company.
</p>
<p>&lt;E1&gt;, founded in &lt;E2&gt;
</p>
<p>country(Bernama,?)
</p>
<p>Bernama
Malaysaian National news agency
</p>
<p>&#8230; relations between Malaysia and Britain, 
the state Bernama news agency &#8230;
News agency Bernama says Malaysian 
prime minister will ...
</p>
<p>&#8230; relations between Malaysia and Britain, 
the state Bernama news agency &#8230;
</p>
<p>Malaysia
</p>
<p>Malaysia
</p>
<p>FIG. 1 &#8211; Architecture g&#233;n&#233;rale du syst&#232;me
</p>
<p>de laquelle les patrons d&#8217;extraction sont appris. Ce travail se rattache donc au concept de &#171; Distant supervision &#187;.
Nous pr&#233;sentons &#233;galement les r&#233;sultats de l&#8217;application d&#8217;une telle approche dans le cadre d&#8217;&#233;valuation d&#233;fini par
la t&#226;che KBP (Knowledge Based Population) de l&#8217;&#233;valuation TAC 2010 (Text Analysis Conference).
</p>
<p>2 Pr&#233;sentation de l&#8217;approche
</p>
<p>Nous nous concentrons dans notre approche sur l&#8217;extraction de relations &#224; large &#233;chelle en supposant la pr&#233;exis-
tence d&#8217;une base de connaissances partiellement remplie, extraite automatiquement &#224; partir de donn&#233;es semi-
structur&#233;es. Nous nous limitons ici aux relations entre entit&#233;s nomm&#233;es &#233;tant donn&#233; que, n&#8217;intervenant pas en
domaine de sp&#233;cialit&#233; o&#249; la recherche des entit&#233;s peut &#234;tre guid&#233;e par une terminologie existante, nous avons
volontairement choisi de nous focaliser sur des entit&#233;s ais&#233;ment identifiables. La notion de &#171; large &#233;chelle &#187; se
d&#233;cline quant &#224; elle selon plusieurs dimensions. La premi&#232;re r&#233;side dans le grand nombre de types de relations
diff&#233;rents consid&#233;r&#233;s, induisant une mise en &#339;uvre difficile pour une approche &#224; bases de r&#232;gles &#233;crites manuel-
lement. La deuxi&#232;me est li&#233;e &#224; la prise en compte initiale d&#8217;un grand nombre de relations existantes (c&#8217;est-&#224;-dire
l&#8217;association de deux valeurs d&#8217;entit&#233;s &#224; un type de relation) ; ces relations fournissent un bon ensemble de d&#233;part
pour l&#8217;apprentissage automatique d&#8217;un mod&#232;le de ces types de relations. Enfin, le corpus dans lequel de nouvelles
relations sont recherch&#233;es est lui-m&#234;me important, ce qui implique l&#8217;utilisation de techniques d&#8217;indexation et de
recherche pour extraire des bons candidats (on ne peut pas envisager l&#8217;application directe de patrons sur toutes les
phrases du corpus). Cette approche, illustr&#233;e par la figure 1, s&#8217;articule en deux phases : une phase d&#8217;apprentissage
de patrons &#224; partir d&#8217;occurrences de relations connues et une phase d&#8217;extraction de relations pour la d&#233;couverte
de nouvelles relations. La premi&#232;re phase part des relations connues R(E1,E2) pour trouver des occurrences de
ces relations dans un corpus, c&#8217;est-&#224;-dire les diff&#233;rentes expressions de cette relation dans les textes et utiliser ces
occurrences pour induire des patrons de reconnaissance pour le type de relation concern&#233;. La seconde phase part
de relations incompl&#232;tes R(E1,x), o&#249; l&#8217;entit&#233; source E1 est connue et l&#8217;entit&#233; cible x est &#224; trouver, cherche des
occurrences de relations impliquant E1 dans un corpus, puis extrait l&#8217;entit&#233; x en utilisant les patrons induits dans
la premi&#232;re phase. Ces deux phases sont d&#233;taill&#233;es dans les sections suivantes.
</p>
<p>2.1 Apprentissage des patrons
</p>
<p>L&#8217;apprentissage des patrons de relations repose sur l&#8217;induction (ou g&#233;n&#233;ralisation) de patrons lexicaux &#224; partir
de phrases exemples contenant des occurrences des relations consid&#233;r&#233;es. L&#8217;objectif de cet apprentissage est de</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LUDOVIC JEAN-LOUIS, ROMARIC BESAN&#199;ON, OLIVIER FERRET, ADRIEN DURAND
</p>
<p>capturer les diff&#233;rentes expressions d&#8217;une relation s&#233;mantique entre deux entit&#233;s. Par exemple, les deux extraits de
phrases ci-dessous contiennent des occurrences de relations pour le type founded_by, instanci&#233; pour les couples
d&#8217;entit&#233;s (Charles Revson ; Revlon Cosmetics) et (Mayer Lehman ; Lehman Brothers investment).
The glamourous cabaret chanteuse reportedly had had a romantic liaison with
&lt;source&gt;Charles Revson&lt;/source&gt;, the founder of &lt;cible&gt;Revlon Cosmetics&lt;/cible&gt; ... &#8211; Lehman was a great-
grandson of &lt;source&gt;Mayer Lehman&lt;/source&gt;, a founder of the &lt;cible&gt;Lehman Brothers investment&lt;/cible&gt;
house ...
Plusieurs travaux pr&#233;sentent des algorithmes de g&#233;n&#233;ralisation de patrons lexicaux (Ravichandran, 2005; Schlaefer
et al., 2006; Ruiz-Casado et al., 2007). Notre approche est similaire &#224; celle de (Pantel et al., 2004) et reprend plus
directement encore la m&#233;thode de (Embarek &amp; Ferret, 2008). L&#8217;id&#233;e g&#233;n&#233;rale de l&#8217;approche est de trouver, dans
le contexte entre les entit&#233;s cible et source, des points communs entre deux phrases exprimant la relation que l&#8217;on
veut capturer. Ici, nous cherchons ces points communs parmi trois niveaux d&#8217;information linguistique : forme de
surface, lemme et cat&#233;gorie morpho-syntaxique. Ces informations linguistiques sont mises en &#233;vidence gr&#226;ce &#224;
l&#8217;outil OpenNLP2, qui est plus globalement &#233;galement utilis&#233; pour la reconnaissance des entit&#233;s nomm&#233;es. La
pr&#233;sence de ces trois niveaux d&#8217;information donne une plus grande expressivit&#233; aux patrons construits et permet
ainsi de trouver un compromis int&#233;ressant en termes de niveau de g&#233;n&#233;ralisation entre la sp&#233;cificit&#233; des &#233;l&#233;ments
lexicalis&#233;s et le caract&#232;re plus g&#233;n&#233;ral des cat&#233;gories morpho-syntaxiques.
</p>
<p>L&#8217;induction d&#8217;un patron &#224; partir de deux occurrences de relation est plus pr&#233;cis&#233;ment compos&#233;e des trois &#233;tapes
suivantes :
</p>
<p>&#8211; le calcul de la distance d&#8217;&#233;dition entre les deux phrases exemples, c&#8217;est-&#224;-dire le nombre minimal d&#8217;op&#233;ra-
tions d&#8217;&#233;ditions (insertion, suppression, substitution) &#224; effectuer pour passer d&#8217;une phrase &#224; l&#8217;autre. Toutes les
op&#233;rations ont ici le m&#234;me poids ;
</p>
<p>&#8211; l&#8217;alignement optimal des phrases exemples &#224; partir de la matrice des distances entre sous-s&#233;quences issue du
calcul de la distance d&#8217;&#233;dition. L&#8217;algorithme classique pour trouver un tel alignement est ici &#233;tendu en permettant
la mise en correspondance de deux mots lors d&#8217;une substitution selon les trois niveaux d&#8217;information possibles ;
</p>
<p>&#8211; construction des patrons en compl&#233;tant si n&#233;cessaire les alignements par des op&#233;rateurs jokers (*s*), repr&#233;sen-
tant 0 ou 1 mot quelconque, et (*g*), repr&#233;sentant exactement un mot quelconque.
</p>
<p>Le tableau 1 montre un exemple d&#8217;induction de patron pour le type de relation founded_by &#224; partir des deux
extraits de phrases ci-dessus. On peut noter la pr&#233;sence de la cat&#233;gorie DET (d&#233;terminant) comme g&#233;n&#233;ralisation
pour (a|the), ce qui rend le patron pertinent pour d&#8217;autres extraits tels que &quot;Charles Kettering, another founder of
DELCO ...&quot;.
</p>
<p>Charles Revson , the founder of Revlon Cosmetics
Mayer Lehman , a founder of the Lehman Brothers investment
&lt;source&gt; , DET founder of (*s*) &lt;cible&gt;
</p>
<p>TAB. 1 &#8211; Exemple d&#8217;induction de patron de relation
</p>
<p>Cet exemple illustre &#233;galement le fait que la g&#233;n&#233;ralisation peut aller jusqu&#8217;&#224; l&#8217;utilisation de jokers pouvant se sub-
stituer &#224; n&#8217;importe quel mot. Comme il est toujours possible de g&#233;n&#233;raliser deux phrases en un patron ne contenant
que des jokers, il est n&#233;cessaire de fixer une limite sup&#233;rieure au nombre de jokers pouvant &#234;tre introduits dans
une op&#233;ration de g&#233;n&#233;ralisation pour conserver un niveau de sp&#233;cificit&#233; raisonnable des patrons. Par ailleurs, tra-
vaillant en domaine ouvert et avec des entit&#233;s nomm&#233;es assez g&#233;n&#233;rales, nous souhaitons plut&#244;t induire un nombre
important de patrons sp&#233;cifiques qu&#8217;un ensemble restreint de patrons tr&#232;s g&#233;n&#233;raux, ceci afin de privil&#233;gier la pr&#233;-
cision. C&#8217;est &#233;galement pour cette raison que nous ne cherchons pas &#224; g&#233;n&#233;raliser les patrons en leur r&#233;appliquant
la proc&#233;dure d&#8217;induction d&#233;crite. Dans l&#8217;&#233;valuation pr&#233;sent&#233;e en section 3, le nombre maximal de jokers dans un
patron est donc fix&#233; &#224; 1.
</p>
<p>Dans le contexte de supervision distante dans lequel nous nous pla&#231;ons, les phrases exemples ne sont pas direc-
tement fournies en tant que telles mais r&#233;sultent de la projection dans un corpus de relations se pr&#233;sentant sous la
forme de couples d&#8217;entit&#233;s (par exemple le couple (Ray Charles, Albany) pour le type de relation city_of_birth).
Plus concr&#232;tement dans notre cas, elles sont r&#233;cup&#233;r&#233;es en soumettant &#224; un moteur de recherche des requ&#234;tes conte-
</p>
<p>2http://opennlp.sourceforge.net/index.html</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>EXTRACTION DE RELATIONS &#192; LARGE &#201;CHELLE
</p>
<p>nant des couples d&#8217;entit&#233;s pour un type de relations donn&#233; et en restreignant les r&#233;sultats du moteur aux phrases
contenant effectivement les deux valeurs des entit&#233;s. On peut souligner que la nature des restrictions appliqu&#233;es a
un impact direct sur la quantit&#233; et la pr&#233;cision des patrons induits. Plus on impose de contraintes, moins on obtient
de phrases exemples, mais meilleurs seront les patrons induits. Par exemple, les auteurs de (Agirre et al., 2009) ne
retiennent que les phrases exemples dans lesquelles les paires d&#8217;entit&#233;s apparaissent dans un voisinage de z&#233;ro &#224;
dix mots.
</p>
<p>Il est important de noter que le processus d&#8217;induction de patrons s&#8217;effectue en comparant les phrases exemples
deux &#224; deux. Il peut donc &#234;tre co&#251;teux (en temps de calcul) lorsque le nombre de phrases exemples est important :
pour 10 000 exemples, on a environ 50 millions de couples distincts de phrases &#224; comparer (n(n &#8722; 1)/2 exacte-
ment). Pour traiter ce probl&#232;me, la solution imm&#233;diate consiste &#224; r&#233;duire de fa&#231;on drastique le nombre de phrases
exemples en amont du processus d&#8217;induction, la cons&#233;quence &#233;tant une r&#233;duction de la couverture des diff&#233;rentes
forme d&#8217;expression des types de relations. Une autre solution consiste &#224; faire une r&#233;duction s&#233;lective du nombre
de couples de phrases exemples &#224; g&#233;n&#233;raliser en &#233;vitant de consid&#233;rer les couples de phrases dont la distance est
visiblement trop grande pour induire des patrons int&#233;ressants. M&#234;me si la distance utilis&#233;e pour cette induction
est une distance d&#8217;&#233;dition, donc tenant compte de l&#8217;ordre des mots, il est &#233;vident qu&#8217;un faible recoupement des
phrases en termes de mots conduira &#224; une valeur &#233;lev&#233;e de la distance d&#8217;&#233;dition. Le filtrage a priori des couples
de phrases peut donc se fonder sur une mesure s&#8217;appliquant &#224; une repr&#233;sentation de type &#171; sac de mots &#187;, telle que
la mesure cosinus, en fixant une valeur minimale en dessous de laquelle la g&#233;n&#233;ralisation des couples de phrases
n&#8217;est pas r&#233;alis&#233;e. Or, la mesure cosinus peut &#234;tre &#233;valu&#233;e de mani&#232;re efficace, soit avec une bonne approximation,
comme dans le cas du Local Sensitive Hashing (Gionis et al., 1999), soit de mani&#232;re exacte mais en fixant un seuil
de similarit&#233; minimale, ce qui correspond &#224; notre cas de figure. Nous avons donc retenu pour notre filtrage l&#8217;al-
gorithme All Pairs Similarity Search (APSS), propos&#233; dans (Bayardo et al., 2007), qui calcule la mesure cosinus
pour les seules paires d&#8217;objets consid&#233;r&#233;s &#8211; ici, les phrases exemples &#8211; dont la similarit&#233; est sup&#233;rieure ou &#233;gale
&#224; un seuil fix&#233; a priori. Cet algorithme se fonde plus pr&#233;cis&#233;ment sur une s&#233;rie d&#8217;optimisations dans l&#8217;indexation
des objets tenant compte des informations recueillies sur leurs caract&#233;ristiques et d&#8217;un tri appliqu&#233; &#224; ces objets en
fonction de ces m&#234;mes caract&#233;ristiques.
</p>
<p>Notons que lors de l&#8217;induction de patrons &#224; partir d&#8217;un grand volume de phrases exemples, on retrouve de nom-
breux doublons, soit parce que la m&#234;me phrase exemple se trouve dans plusieurs documents, soit parce que l&#8217;on
retrouve la m&#234;me forme d&#8217;expression d&#8217;un type de relations avec des valeurs diff&#233;rentes (Obama&#8217;s height is 1.87m ;
Sarkozy&#8217;s height is 1.65m). Ainsi, nous proposons de filtrer les phrases exemples &#224; deux niveaux : d&#8217;abord avec un
seuil de similarit&#233; fort afin d&#8217;identifier et &#233;liminer les phrases identiques ; puis avec un seuil de similarit&#233; faible
pour s&#8217;assurer d&#8217;un niveau minimal de similarit&#233; entre les phrases en vue du processus d&#8217;induction.
</p>
<p>2.2 Extraction des relations
</p>
<p>L&#8217;extraction de nouvelles relations se fait &#224; partir des types de relations existants et d&#8217;entit&#233;s connues : on cherche
&#224; compl&#233;ter une base de connaissances existante en compl&#233;tant les informations concernant les entit&#233;s qu&#8217;elle
contient. La premi&#232;re &#233;tape de l&#8217;extraction de relations est la recherche de phrases candidates pouvant contenir
l&#8217;expression d&#8217;une relation. Elle prend comme point de d&#233;part des requ&#234;tes contenant une entit&#233; nomm&#233;e associ&#233;e
&#224; son type et le type de l&#8217;information recherch&#233;e. La recherche proprement dite est r&#233;alis&#233;e, comme dans le cas
de l&#8217;apprentissage de patrons, gr&#226;ce &#224; un moteur de recherche ayant pr&#233;alablement index&#233; le corpus cible pour
l&#8217;extraction des relations. Nous nous sommes appuy&#233;s dans notre cas sur le moteur Luc&#232;ne3, avec une indexation
adapt&#233;e aux caract&#233;ristiques de notre recherche : les documents initiaux sont d&#233;coup&#233;s en unit&#233;s d&#8217;indexation de
petite taille, trois phrases, gr&#226;ce &#224; une fen&#234;tre glissante et au sein de ces unit&#233;s, sont index&#233;s les mots pleins sous
leur forme normalis&#233;e et les entit&#233;s nomm&#233;es, avec leur type. L&#8217;interrogation du corpus pr&#233;sente en outre la par-
ticularit&#233; d&#8217;inclure une phase d&#8217;expansion de l&#8217;entit&#233; source. En effet, on retrouve souvent dans les documents
des formes plus ou moins d&#233;velopp&#233;es des entit&#233;s nomm&#233;es : par exemple Bill Clinton est g&#233;n&#233;ralement utilis&#233; au
lieu de William Jefferson Blythe III Clinton. Il est donc int&#233;ressant de savoir que ces deux mentions d&#8217;entit&#233;s sont
&#233;quivalentes et associ&#233;es &#224; la m&#234;me entit&#233;, en particulier lors de la recherche de documents. Nous utilisons donc
une &#233;tape d&#8217;expansion des entit&#233;s visant &#224; associer &#224; une entit&#233; donn&#233;e les formes alternatives lui faisant r&#233;f&#233;rence.
Pour l&#8217;entit&#233; &quot;Barack Obama&quot;, on a ainsi : {B. Hussein Obama, Barack H. Obama Junior, Barack Obama Jr, Ba-
rack Hussein Obama Jr., etc.}. L&#8217;int&#233;r&#234;t est de pouvoir augmenter les chances de retrouver des phrases candidates
</p>
<p>3http://lucene.apache.org/java/docs/index.html</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LUDOVIC JEAN-LOUIS, ROMARIC BESAN&#199;ON, OLIVIER FERRET, ADRIEN DURAND
</p>
<p>li&#233;es &#224; l&#8217;entit&#233; puisque l&#8217;on consid&#232;re tous les documents dans lesquels apparaissent ses diff&#233;rentes expressions.
Une base d&#8217;expansion des entit&#233;s a &#233;t&#233; constitu&#233;e de fa&#231;on automatique &#224; partir du corpus Wikip&#233;dia4 en collectant
pour chaque entit&#233; les formulations extraites des pages de redirection de Wikip&#233;dia vers cette entit&#233;. Au total, la
base d&#8217;expansion contient des formes &#233;tendues pour environ 2,4 millions d&#8217;entr&#233;es.
</p>
<p>Nous appliquons ensuite sur les phrases candidates s&#233;lectionn&#233;es les patrons induits lors de la phase d&#8217;apprentis-
sage. Les entit&#233;s cibles extraites par ces patrons sont cumul&#233;es pour ne retenir finalement que les plus fr&#233;quentes :
notre hypoth&#232;se est que les entit&#233;s cibles les plus pertinentes apparaissent plus souvent dans les documents que
les moins pertinentes. Pour les relations mono-valu&#233;es (ex. : date de naissance), une seule valeur est conserv&#233;e.
Pour les relations multi-valu&#233;es (ex. : lieux de r&#233;sidence), un nombre arbitraire de trois valeurs sont conserv&#233;es
&#224; d&#233;faut de connaissances fournies a priori ou extraites des textes quant &#224; ce point. Enfin, un dernier filtre est
appliqu&#233; sur les entit&#233;s cibles pour v&#233;rifier la compatibilit&#233; des valeurs obtenues avec les contraintes relatives au
type d&#8217;information recherch&#233; qu&#8217;elle repr&#233;sentent, d&#233;finies par des listes de valeurs ou d&#8217;expressions r&#233;guli&#232;res :
on v&#233;rifie par exemple que le pays de naissance d&#8217;une personne fasse bien partie de la liste des pays connus.
</p>
<p>3 &#201;valuation
Nous pr&#233;sentons dans cette section les r&#233;sultats de l&#8217;&#233;valuation de notre syst&#232;me en utilisant les donn&#233;es de la t&#226;che
Slot Filling de la campagne d&#8217;&#233;valuation TAC-KBP 2010 (TAC-KBP, 2010). Nos exp&#233;rimentations ont donc &#233;t&#233;
r&#233;alis&#233;es pour l&#8217;anglais. La t&#226;che Slot Filling correspond aux sp&#233;cifications de notre contexte de travail telles que
nous les avons d&#233;finies &#224; la section 2 : son objectif est d&#8217;extraire &#224; partir d&#8217;un vaste corpus l&#8217;entit&#233; cible d&#8217;une
relation ayant comme source une entit&#233; pr&#233;sente dans une base de connaissances abritant un ensemble important
d&#8217;exemples du type de relation vis&#233;. Les types de relations consid&#233;r&#233;s dans ce cadre sont au nombre de 42, r&#233;partis
en 16 relations pour des entit&#233;s de type ORGANISATION (ORG) et 26 relations pour les entit&#233;s de type PERSONNE
(PERS). La liste des types de relations trait&#233;s est pr&#233;sent&#233;e dans le tableau 2. Nous pr&#233;cisons que les exp&#233;riences
ont &#233;t&#233; r&#233;alis&#233;es sur un cluster de 24 n&#339;uds (4 processeurs/n&#339;ud) avec une parall&#233;lisation par type de relations.
</p>
<p>3.1 Cadre d&#8217;&#233;valuation
</p>
<p>Les donn&#233;es d&#8217;&#233;valuation issues de TAC-KBP sont les suivantes :
</p>
<p>&#8211; un corpus de textes compos&#233; d&#8217;environ 1,8 millions de documents (1 780 980 exactement) r&#233;partis en 0,04% de
transcriptions (conversations t&#233;l&#233;phoniques, journaux radio, conversations radio), 72,24% d&#8217;articles de presse
et 27,72% de pages Web ;
</p>
<p>&#8211; une base de connaissances (KB) reposant sur une image de Wikip&#233;dia d&#8217;octobre 2008. Un identifiant unique et
un type d&#8217;entit&#233; sont attribu&#233;s &#224; chaque page contenant des infobox. Le type d&#8217;entit&#233; personne, organisation,
entit&#233; g&#233;opolitique ou inconnu est associ&#233; &#224; chaque page en fonction des champs contenus dans les infobox.
Typiquement, les infobox Infobox_Actor sont ainsi li&#233;es &#224; des personnes. Au final 818 741 entit&#233;s ont &#233;t&#233;
retenues pour former la KB, chacune d&#8217;elles &#233;tant associ&#233;e &#224; un ensemble de propri&#233;t&#233;s (champs des infobox)
ainsi qu&#8217;&#224; un texte la d&#233;crivant. Ainsi les relations sont repr&#233;sent&#233;es dans la KB par des tuples (identifiant,
type infobox, nom, type, propri&#233;t&#233;, valeurs), ex. : (E0000437 ; Infobox_Actor ; Julia Roberts ; PER ; birthplace ;
Atlanta) ;
</p>
<p>&#8211; une table de correspondance entre les propri&#233;t&#233;s issues de Wikip&#233;dia et les types de relations retenus pour
l&#8217;&#233;valuation. Par exemple, Infobox_Actor:birthplace est convertie en per:city_of_birth. Cette correspondance
permet de prendre en compte une certaine h&#233;t&#233;rog&#233;n&#233;it&#233; de d&#233;signation des propri&#233;t&#233;s dans Wikip&#233;dia ;
</p>
<p>&#8211; une liste de 100 entit&#233;s sources pour lesquelles on cherche &#224; extraire toutes les entit&#233;s en relation pour tous les
types de relations consid&#233;r&#233;s. On d&#233;nombre parmi ces entit&#233;s 15 entit&#233;s pr&#233;sentes dans la KB et 85 inconnues
de la KB. Par ailleurs, toutes les relations consid&#233;r&#233;es ne trouvent pas d&#8217;entit&#233;s cibles dans le corpus pour ces
100 entit&#233;s. Dans le cadre de cette &#233;tude, nous nous focalisons uniquement sur les relations pour lesquelles il
existe une entit&#233; cible dans le corpus5, ce qui repr&#233;sente au total 2069 relations. Le d&#233;tail par type de relations
est pr&#233;sent&#233; dans la colonne Nb Ref. du tableau 2.
4Plus pr&#233;cis&#233;ment, la version mise &#224; disposition par l&#8217;universit&#233; de New York : http://nlp.cs.nyu.edu/wikipedia-data
5Les entit&#233;s cibles existantes dans le corpus sont &#233;tablies par la r&#233;f&#233;rence fournie par les organisateurs de la campagne, construite &#224; partir
</p>
<p>des r&#233;sultats des participants.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>EXTRACTION DE RELATIONS &#192; LARGE &#201;CHELLE
</p>
<p>Ty
pe
</p>
<p>sd
e
</p>
<p>re
la
</p>
<p>tio
ns
</p>
<p>Ty
pe
</p>
<p>de
ci
</p>
<p>bl
e
</p>
<p>Co
uv
</p>
<p>.
D
</p>
<p>oc
.
</p>
<p>Co
uv
</p>
<p>.
R
</p>
<p>el
.
</p>
<p>N
b
</p>
<p>A
pp
</p>
<p>r.
N
</p>
<p>b
Te
</p>
<p>st
N
</p>
<p>b
In
</p>
<p>du
c.
</p>
<p>N
b
</p>
<p>Pa
tr
</p>
<p>on
s
</p>
<p>Co
uv
</p>
<p>.
Pa
</p>
<p>tr
on
</p>
<p>s
N
</p>
<p>b
R
</p>
<p>ef
.
</p>
<p>o
rg
</p>
<p>:a
lte
</p>
<p>rn
at
</p>
<p>e_
na
</p>
<p>m
es
</p>
<p>O
RG
</p>
<p>89
,1
</p>
<p>7%
33
</p>
<p>,3
3%
</p>
<p>20
01
</p>
<p>3
10
</p>
<p>00
6
</p>
<p>21
4
</p>
<p>6
00
</p>
<p>7
66
</p>
<p>,1
0%
</p>
<p>12
0
</p>
<p>o
rg
</p>
<p>:c
ity
</p>
<p>_o
f_
</p>
<p>he
ad
</p>
<p>qu
ar
</p>
<p>te
rs
</p>
<p>LO
C
</p>
<p>+
lis
</p>
<p>te
90
</p>
<p>,1
2%
</p>
<p>59
,2
</p>
<p>6%
6
</p>
<p>84
7
</p>
<p>3
42
</p>
<p>3
4
</p>
<p>55
3
</p>
<p>2
01
</p>
<p>0
74
</p>
<p>9
65
</p>
<p>,5
2%
</p>
<p>81
o
</p>
<p>rg
:c
</p>
<p>o
u
</p>
<p>n
tr
</p>
<p>y_
of
</p>
<p>_h
ea
</p>
<p>dq
ua
</p>
<p>rte
rs
</p>
<p>LO
C
</p>
<p>+
lis
</p>
<p>te
91
</p>
<p>,0
4%
</p>
<p>55
,2
</p>
<p>2%
18
</p>
<p>40
1
</p>
<p>9
20
</p>
<p>0
2
</p>
<p>11
0
</p>
<p>18
5
</p>
<p>15
8
</p>
<p>69
,5
</p>
<p>6%
67
</p>
<p>o
rg
</p>
<p>:d
iss
</p>
<p>ol
ve
</p>
<p>d
D
</p>
<p>AT
E
</p>
<p>10
0%
</p>
<p>25
%
</p>
<p>53
2
</p>
<p>26
6
</p>
<p>87
77
</p>
<p>5
0%
</p>
<p>4
o
</p>
<p>rg
:fo
</p>
<p>un
de
</p>
<p>d_
by
</p>
<p>O
RG
</p>
<p>/P
ER
</p>
<p>95
,4
</p>
<p>5%
31
</p>
<p>,8
2%
</p>
<p>1
95
</p>
<p>4
97
</p>
<p>7
19
</p>
<p>7
4
</p>
<p>38
5
</p>
<p>77
,8
</p>
<p>7%
28
</p>
<p>o
rg
</p>
<p>:fo
un
</p>
<p>de
d
</p>
<p>D
AT
</p>
<p>E
92
</p>
<p>,8
6%
</p>
<p>53
,5
</p>
<p>7%
13
</p>
<p>68
8
</p>
<p>6
84
</p>
<p>4
12
</p>
<p>7
22
</p>
<p>48
2
</p>
<p>77
,3
</p>
<p>4%
22
</p>
<p>o
rg
</p>
<p>:m
em
</p>
<p>be
r_
</p>
<p>of
O
</p>
<p>RG
10
</p>
<p>0%
10
</p>
<p>0%
7
</p>
<p>95
1
</p>
<p>3
97
</p>
<p>6
10
</p>
<p>2
10
</p>
<p>3
70
</p>
<p>%
2
</p>
<p>o
rg
</p>
<p>:m
em
</p>
<p>be
rs
</p>
<p>O
RG
</p>
<p>77
,7
</p>
<p>8%
11
</p>
<p>,1
1%
</p>
<p>53
1
</p>
<p>26
5
</p>
<p>18
3
</p>
<p>55
2
</p>
<p>86
%
</p>
<p>9
o
</p>
<p>rg
:n
</p>
<p>u
m
</p>
<p>be
r_
</p>
<p>of
_e
</p>
<p>m
pl
</p>
<p>oy
ee
</p>
<p>s_
m
</p>
<p>em
be
</p>
<p>rs
re
</p>
<p>ge
x
</p>
<p>p
+
</p>
<p>lis
te
</p>
<p>90
,4
</p>
<p>8%
23
</p>
<p>,8
1%
</p>
<p>7
17
</p>
<p>3
3
</p>
<p>58
6
</p>
<p>21
6
</p>
<p>3
10
</p>
<p>9
10
</p>
<p>0%
21
</p>
<p>o
rg
</p>
<p>:p
ar
</p>
<p>en
ts
</p>
<p>O
RG
</p>
<p>96
,6
</p>
<p>7%
43
</p>
<p>,3
3%
</p>
<p>22
36
</p>
<p>1
11
</p>
<p>18
1
</p>
<p>3
01
</p>
<p>3
48
</p>
<p>5
94
</p>
<p>7
69
</p>
<p>,0
4%
</p>
<p>30
o
</p>
<p>rg
:p
</p>
<p>ol
iti
</p>
<p>ca
l_
</p>
<p>re
lig
</p>
<p>io
us
</p>
<p>_a
ffi
</p>
<p>lia
tio
</p>
<p>n
O
</p>
<p>RG
78
</p>
<p>,5
7%
</p>
<p>64
,2
</p>
<p>9%
3
</p>
<p>42
7
</p>
<p>1
71
</p>
<p>3
40
</p>
<p>6
3
</p>
<p>25
0
</p>
<p>55
,3
</p>
<p>6%
14
</p>
<p>o
rg
</p>
<p>:s
ha
</p>
<p>re
ho
</p>
<p>ld
er
</p>
<p>s
O
</p>
<p>RG
/P
</p>
<p>ER
66
</p>
<p>,6
7%
</p>
<p>33
,3
</p>
<p>3%
3
</p>
<p>2
0
</p>
<p>0
0%
</p>
<p>3
o
</p>
<p>rg
:s
</p>
<p>ta
te
</p>
<p>or
pr
</p>
<p>ov
in
</p>
<p>ce
_o
</p>
<p>f_
he
</p>
<p>ad
qu
</p>
<p>ar
te
</p>
<p>rs
LO
</p>
<p>C
+
</p>
<p>lis
te
</p>
<p>92
,6
</p>
<p>5%
63
</p>
<p>,2
4%
</p>
<p>9
67
</p>
<p>2
4
</p>
<p>83
6
</p>
<p>1
42
</p>
<p>2
14
</p>
<p>8
61
</p>
<p>0
69
</p>
<p>,9
3%
</p>
<p>68
o
</p>
<p>rg
:s
</p>
<p>u
bs
</p>
<p>id
ia
</p>
<p>rie
s
</p>
<p>O
RG
</p>
<p>82
,6
</p>
<p>9%
28
</p>
<p>,8
5%
</p>
<p>5
58
</p>
<p>8
2
</p>
<p>79
4
</p>
<p>49
8
</p>
<p>3
76
</p>
<p>4
56
</p>
<p>,4
8%
</p>
<p>52
o
</p>
<p>rg
:to
</p>
<p>p_
m
</p>
<p>em
be
</p>
<p>rs
_e
</p>
<p>m
pl
</p>
<p>oy
ee
</p>
<p>s
PE
</p>
<p>R
91
</p>
<p>,4
8%
</p>
<p>37
,2
</p>
<p>2%
40
</p>
<p>92
9
</p>
<p>20
46
</p>
<p>4
10
</p>
<p>8
1
</p>
<p>01
0
</p>
<p>70
,5
</p>
<p>7%
22
</p>
<p>3
o
</p>
<p>rg
:w
</p>
<p>eb
sit
</p>
<p>e
re
</p>
<p>ge
x
</p>
<p>p
78
</p>
<p>,2
6%
</p>
<p>30
,4
</p>
<p>3%
30
</p>
<p>81
3
</p>
<p>15
40
</p>
<p>7
32
</p>
<p>28
0%
</p>
<p>23
</p>
<p>pe
r:
</p>
<p>ag
e
</p>
<p>re
ge
</p>
<p>x
p
</p>
<p>+
lis
</p>
<p>te
85
</p>
<p>,3
2%
</p>
<p>32
,1
</p>
<p>1%
15
</p>
<p>7
79
</p>
<p>3
1
</p>
<p>0%
10
</p>
<p>9
pe
</p>
<p>r:
al
</p>
<p>te
rn
</p>
<p>at
e_
</p>
<p>na
m
</p>
<p>es
PE
</p>
<p>R
61
</p>
<p>,6
3%
</p>
<p>11
,6
</p>
<p>3%
18
</p>
<p>11
5
</p>
<p>9
05
</p>
<p>7
68
</p>
<p>2
81
</p>
<p>8
82
</p>
<p>,5
8%
</p>
<p>86
pe
</p>
<p>r:
ca
</p>
<p>u
se
</p>
<p>_
o
</p>
<p>f_
de
</p>
<p>at
h
</p>
<p>lis
te
</p>
<p>10
0%
</p>
<p>0%
1
</p>
<p>1
0
</p>
<p>0
0%
</p>
<p>2
pe
</p>
<p>r:
ch
</p>
<p>ar
ge
</p>
<p>s
lis
</p>
<p>te
61
</p>
<p>,5
4%
</p>
<p>0%
18
</p>
<p>4
92
</p>
<p>0
0
</p>
<p>0%
13
</p>
<p>pe
r:
</p>
<p>ch
ild
</p>
<p>re
n
</p>
<p>PE
R
</p>
<p>72
%
</p>
<p>16
%
</p>
<p>2
01
</p>
<p>0
1
</p>
<p>00
5
</p>
<p>14
7
</p>
<p>23
8
</p>
<p>0%
25
</p>
<p>pe
r:
</p>
<p>ci
tie
</p>
<p>s_
of
</p>
<p>_r
es
</p>
<p>id
en
</p>
<p>ce
LO
</p>
<p>C
+
</p>
<p>lis
te
</p>
<p>77
,5
</p>
<p>9%
34
</p>
<p>,4
8%
</p>
<p>3
63
</p>
<p>1
1
</p>
<p>81
5
</p>
<p>72
2
</p>
<p>14
29
</p>
<p>7
77
</p>
<p>,8
8%
</p>
<p>58
pe
</p>
<p>r:
ci
</p>
<p>ty
_o
</p>
<p>f_
bi
</p>
<p>rth
LO
</p>
<p>C
+
</p>
<p>lis
te
</p>
<p>69
,2
</p>
<p>3%
15
</p>
<p>,3
8%
</p>
<p>4
74
</p>
<p>5
2
</p>
<p>37
3
</p>
<p>2
25
</p>
<p>2
62
</p>
<p>45
5
</p>
<p>63
,3
</p>
<p>4%
13
</p>
<p>pe
r:
</p>
<p>ci
ty
</p>
<p>_o
f_
</p>
<p>de
at
</p>
<p>h
LO
</p>
<p>C
+
</p>
<p>lis
te
</p>
<p>10
0%
</p>
<p>10
0%
</p>
<p>1
63
</p>
<p>1
81
</p>
<p>6
50
</p>
<p>5
2
</p>
<p>86
0
</p>
<p>70
,2
</p>
<p>7%
1
</p>
<p>pe
r:
</p>
<p>co
u
</p>
<p>n
tr
</p>
<p>ie
s_
</p>
<p>of
_r
</p>
<p>es
id
</p>
<p>en
ce
</p>
<p>LO
C
</p>
<p>+
lis
</p>
<p>te
73
</p>
<p>,5
3%
</p>
<p>20
,5
</p>
<p>9%
8
</p>
<p>09
8
</p>
<p>4
04
</p>
<p>9
2
</p>
<p>18
1
</p>
<p>20
5
</p>
<p>34
4
</p>
<p>80
,0
</p>
<p>8%
34
</p>
<p>pe
r:
</p>
<p>co
u
</p>
<p>n
tr
</p>
<p>y_
of
</p>
<p>_b
irt
</p>
<p>h
LO
</p>
<p>C
+
</p>
<p>lis
te
</p>
<p>82
,3
</p>
<p>5%
5,
</p>
<p>88
%
</p>
<p>11
08
</p>
<p>5
5
</p>
<p>54
2
</p>
<p>11
19
</p>
<p>2
9
</p>
<p>14
5
</p>
<p>38
5
</p>
<p>65
,0
</p>
<p>2%
17
</p>
<p>pe
r:
</p>
<p>co
u
</p>
<p>n
tr
</p>
<p>y_
of
</p>
<p>_d
ea
</p>
<p>th
LO
</p>
<p>C
+
</p>
<p>lis
te
</p>
<p>2
87
</p>
<p>3
1
</p>
<p>43
6
</p>
<p>1
06
</p>
<p>8
22
</p>
<p>37
4
</p>
<p>62
,8
</p>
<p>9%
0
</p>
<p>pe
r:
</p>
<p>da
te
</p>
<p>_o
f_
</p>
<p>bi
rth
</p>
<p>D
AT
</p>
<p>E
90
</p>
<p>%
20
</p>
<p>%
11
</p>
<p>68
9
</p>
<p>5
84
</p>
<p>5
30
</p>
<p>22
0%
</p>
<p>20
pe
</p>
<p>r:
da
</p>
<p>te
_o
</p>
<p>f_
de
</p>
<p>at
h
</p>
<p>D
AT
</p>
<p>E
10
</p>
<p>0%
0%
</p>
<p>4
69
</p>
<p>2
2
</p>
<p>34
6
</p>
<p>54
63
</p>
<p>33
,3
</p>
<p>3%
1
</p>
<p>pe
r:
</p>
<p>em
pl
</p>
<p>oy
ee
</p>
<p>_o
f
</p>
<p>O
RG
</p>
<p>84
,2
</p>
<p>1%
29
</p>
<p>,3
2%
</p>
<p>24
76
</p>
<p>2
12
</p>
<p>38
1
</p>
<p>2
43
</p>
<p>5
70
</p>
<p>4
83
</p>
<p>3
71
</p>
<p>,1
3%
</p>
<p>13
3
</p>
<p>pe
r:
</p>
<p>m
em
</p>
<p>be
r_
</p>
<p>of
O
</p>
<p>RG
82
</p>
<p>,4
2%
</p>
<p>36
,2
</p>
<p>6%
27
</p>
<p>52
3
</p>
<p>13
76
</p>
<p>1
3
</p>
<p>90
1
</p>
<p>74
0
</p>
<p>99
9
</p>
<p>57
,2
</p>
<p>5%
91
</p>
<p>pe
r:
</p>
<p>o
rig
</p>
<p>in
lis
</p>
<p>te
81
</p>
<p>,5
8%
</p>
<p>42
,1
</p>
<p>1%
37
</p>
<p>62
6
</p>
<p>18
81
</p>
<p>3
2
</p>
<p>71
0
</p>
<p>27
6
</p>
<p>65
3
</p>
<p>74
,4
</p>
<p>1%
76
</p>
<p>pe
r:
</p>
<p>o
th
</p>
<p>er
_f
</p>
<p>am
ily
</p>
<p>PE
R
</p>
<p>86
,6
</p>
<p>7%
33
</p>
<p>,3
3%
</p>
<p>4
2
</p>
<p>0
0
</p>
<p>0%
30
</p>
<p>pe
r:
</p>
<p>pa
re
</p>
<p>nt
s
</p>
<p>PE
R
</p>
<p>78
,1
</p>
<p>3%
9,
</p>
<p>38
%
</p>
<p>1
31
</p>
<p>4
65
</p>
<p>7
37
</p>
<p>60
4
</p>
<p>77
,7
</p>
<p>8%
64
</p>
<p>pe
r:
</p>
<p>re
lig
</p>
<p>io
n
</p>
<p>lis
te
</p>
<p>85
,7
</p>
<p>1%
57
</p>
<p>,1
4%
</p>
<p>1
46
</p>
<p>8
73
</p>
<p>4
51
</p>
<p>5
1
</p>
<p>57
5
</p>
<p>80
%
</p>
<p>7
pe
</p>
<p>r:
sc
</p>
<p>ho
ol
</p>
<p>s_
at
</p>
<p>te
nd
</p>
<p>ed
O
</p>
<p>RG
+
</p>
<p>lis
te
</p>
<p>87
,5
</p>
<p>0%
37
</p>
<p>,5
0%
</p>
<p>2
24
</p>
<p>6
1
</p>
<p>12
3
</p>
<p>67
17
</p>
<p>0
4,
</p>
<p>17
%
</p>
<p>16
pe
</p>
<p>r:
sib
</p>
<p>lin
gs
</p>
<p>PE
R
</p>
<p>78
,2
</p>
<p>6%
20
</p>
<p>,2
9%
</p>
<p>4
2
</p>
<p>0
0
</p>
<p>0%
69
</p>
<p>pe
r:
</p>
<p>sp
ou
</p>
<p>se
PE
</p>
<p>R
80
</p>
<p>%
35
</p>
<p>,5
6%
</p>
<p>5
38
</p>
<p>5
2
</p>
<p>69
3
</p>
<p>3
09
</p>
<p>4
31
</p>
<p>4
32
</p>
<p>9
80
</p>
<p>%
45
</p>
<p>pe
r:
</p>
<p>st
at
</p>
<p>eo
rp
</p>
<p>ro
v
</p>
<p>in
ce
</p>
<p>_o
f_
</p>
<p>bi
rth
</p>
<p>LO
C
</p>
<p>+
lis
</p>
<p>te
80
</p>
<p>%
50
</p>
<p>%
7
</p>
<p>04
7
</p>
<p>3
52
</p>
<p>3
2
</p>
<p>09
7
</p>
<p>60
78
</p>
<p>2
75
</p>
<p>,4
2%
</p>
<p>10
pe
</p>
<p>r:
st
</p>
<p>at
eo
</p>
<p>rp
ro
</p>
<p>v
in
</p>
<p>ce
_o
</p>
<p>f_
de
</p>
<p>at
h
</p>
<p>LO
C
</p>
<p>+
lis
</p>
<p>te
10
</p>
<p>0%
10
</p>
<p>0%
1
</p>
<p>61
6
</p>
<p>80
8
</p>
<p>27
8
</p>
<p>91
1
</p>
<p>66
,6
</p>
<p>7%
1
</p>
<p>pe
r:
</p>
<p>st
at
</p>
<p>es
_o
</p>
<p>r_
pr
</p>
<p>ov
in
</p>
<p>ce
s_
</p>
<p>of
_r
</p>
<p>es
id
</p>
<p>en
ce
</p>
<p>LO
C
</p>
<p>+
lis
</p>
<p>te
84
</p>
<p>,2
1%
</p>
<p>50
%
</p>
<p>4
98
</p>
<p>0
2
</p>
<p>49
0
</p>
<p>1
16
</p>
<p>6
11
</p>
<p>5
41
</p>
<p>8
77
</p>
<p>,9
0%
</p>
<p>38
pe
</p>
<p>r:
tit
</p>
<p>le
lis
</p>
<p>te
84
</p>
<p>,5
5%
</p>
<p>52
,7
</p>
<p>7%
31
</p>
<p>57
4
</p>
<p>15
78
</p>
<p>7
8
</p>
<p>79
7
</p>
<p>1
57
</p>
<p>3
51
</p>
<p>2
49
</p>
<p>,0
7%
</p>
<p>34
3
</p>
<p>TA
B
</p>
<p>.
2
</p>
<p>&#8211;
R
</p>
<p>&#233;s
ul
</p>
<p>ta
ts
</p>
<p>de
sd
</p>
<p>iff
&#233;r
</p>
<p>en
te
</p>
<p>s
&#233;t
</p>
<p>ap
es
</p>
<p>,p
ou
</p>
<p>rt
ou
</p>
<p>s
le
</p>
<p>st
yp
</p>
<p>es
de
</p>
<p>re
la
</p>
<p>tio
ns
</p>
<p>Ty
pe
</p>
<p>de
ci
</p>
<p>bl
e
</p>
<p>:
m
</p>
<p>&#233;c
an
</p>
<p>ism
e
</p>
<p>u
til
</p>
<p>is&#233;
po
</p>
<p>ur
re
</p>
<p>tr
ou
</p>
<p>ve
r
</p>
<p>l&#8217;e
nt
</p>
<p>it&#233;
ci
</p>
<p>bl
e.
</p>
<p>Co
uv
</p>
<p>.
D
</p>
<p>oc
.
</p>
<p>:
co
</p>
<p>u
v
</p>
<p>er
tu
</p>
<p>re
de
</p>
<p>sd
oc
</p>
<p>um
en
</p>
<p>ts
de
</p>
<p>r&#233;
f&#233;
</p>
<p>re
nc
</p>
<p>e
da
</p>
<p>ns
le
</p>
<p>sr
&#233;s
</p>
<p>ul
ta
</p>
<p>ts
de
</p>
<p>la
re
</p>
<p>ch
er
</p>
<p>ch
e
</p>
<p>de
ph
</p>
<p>ra
se
</p>
<p>s.
Co
</p>
<p>uv
.
</p>
<p>Re
l.
</p>
<p>:
co
</p>
<p>u
v
</p>
<p>er
tu
</p>
<p>re
de
</p>
<p>sp
hr
</p>
<p>as
es
</p>
<p>ca
n
</p>
<p>di
da
</p>
<p>te
sd
</p>
<p>e
r&#233;
</p>
<p>f&#233;
re
</p>
<p>nc
e.
</p>
<p>Nb
Ap
</p>
<p>pr
.
</p>
<p>:
n
</p>
<p>o
m
</p>
<p>br
ed
</p>
<p>er
el
</p>
<p>at
io
</p>
<p>ns
po
</p>
<p>ur
l&#8217;a
</p>
<p>pp
re
</p>
<p>nt
iss
</p>
<p>ag
e
</p>
<p>de
sp
</p>
<p>at
ro
</p>
<p>ns
.N
</p>
<p>b
Te
</p>
<p>st
:
</p>
<p>n
o
</p>
<p>m
br
</p>
<p>ed
er
</p>
<p>el
at
</p>
<p>io
ns
</p>
<p>po
ur
</p>
<p>l&#8217;&#233;
va
</p>
<p>lu
at
</p>
<p>io
n
</p>
<p>de
sp
</p>
<p>at
ro
</p>
<p>ns
.N
</p>
<p>b
In
</p>
<p>du
c.
</p>
<p>:
n
</p>
<p>o
m
</p>
<p>br
ed
</p>
<p>ep
hr
</p>
<p>as
es
</p>
<p>co
n
</p>
<p>te
na
</p>
<p>nt
de
</p>
<p>so
cc
</p>
<p>u
rr
</p>
<p>en
ce
</p>
<p>s
de
</p>
<p>re
la
</p>
<p>tio
ns
</p>
<p>po
ur
</p>
<p>l&#8217;i
nd
</p>
<p>uc
tio
</p>
<p>n
de
</p>
<p>sp
at
</p>
<p>ro
ns
</p>
<p>.N
b
</p>
<p>Pa
tr
</p>
<p>o
n
</p>
<p>s
:
</p>
<p>n
o
</p>
<p>m
br
</p>
<p>e
de
</p>
<p>pa
tro
</p>
<p>ns
in
</p>
<p>du
its
</p>
<p>&#224;
pa
</p>
<p>rti
rd
</p>
<p>es
o
</p>
<p>cc
u
</p>
<p>rr
en
</p>
<p>ce
s
</p>
<p>de
re
</p>
<p>la
tio
</p>
<p>ns
.C
</p>
<p>ou
v.
</p>
<p>Pa
tr
</p>
<p>o
n
</p>
<p>s
:
</p>
<p>co
u
</p>
<p>v
er
</p>
<p>tu
re
</p>
<p>de
sp
</p>
<p>at
ro
</p>
<p>ns
in
</p>
<p>du
its
</p>
<p>.N
b
</p>
<p>Re
f.:
</p>
<p>n
o
</p>
<p>m
br
</p>
<p>e
de
</p>
<p>re
la
</p>
<p>tio
ns
</p>
<p>de
r&#233;
</p>
<p>f&#233;
re
</p>
<p>nc
e.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LUDOVIC JEAN-LOUIS, ROMARIC BESAN&#199;ON, OLIVIER FERRET, ADRIEN DURAND
</p>
<p>3.2 &#201;valuation de l&#8217;apprentissage des patrons
Les patrons servent &#224; confirmer/infirmer la pr&#233;sence d&#8217;une relation entre deux entit&#233;s. Il est donc important de
v&#233;rifier que les patrons appris aient une couverture suffisamment large pour retrouver le plus possible de variantes
parmi les occurrences de relations. Pour &#233;valuer la qualit&#233; des patrons, nous avons s&#233;par&#233; les relations connues
en deux ensembles : un ensemble d&#8217;apprentissage (2/3 des relations) et un ensemble de test (1/3 des relations).
Nous mesurons la qualit&#233; de la couverture des patrons en calculant le pourcentage des occurrences de relations
de l&#8217;ensemble de test que l&#8217;on retrouve en appliquant les patrons appris &#224; partir des occurrences de relations de
l&#8217;ensemble d&#8217;apprentissage. Le corpus utilis&#233; pour r&#233;aliser cette &#233;valuation est le corpus TAC-KBP 2010 d&#233;crit
ci-dessus. Pr&#233;cisons que l&#8217;utilisation de ce corpus pour &#233;valuer l&#8217;extraction des relations n&#8217;emp&#234;che pas son utili-
sation pour l&#8217;apprentissage des patrons, les relations &#233;tant diff&#233;rentes pour les deux t&#226;ches.
</p>
<p>Nous indiquons dans le tableau 2 le nombre de relations de l&#8217;ensemble d&#8217;apprentissage et de l&#8217;ensemble de test
respectivement dans les colonnes Nb. Appr et Nb. Test. Le nombre de phrases trouv&#233;es contenant des occurrences
des relations du corpus d&#8217;entra&#238;nement, et qui ont donc servi pour l&#8217;induction des patrons, est indiqu&#233; dans la
colonne Nb. Induc. Le nombre de patrons g&#233;n&#233;r&#233;s &#224; partir de ces phrases candidates est indiqu&#233; dans la colonne
Nb. Patrons de ce m&#234;me tableau.
</p>
<p>Par exemple, pour le type de relation org:alternate_names, &#224; partir des 20 013 relations de l&#8217;ensemble d&#8217;appren-
tissage, seules 214 phrases candidates contenant l&#8217;expression d&#8217;une de ces relations sont s&#233;lectionn&#233;es. Ces 214
phrases servent &#224; g&#233;n&#233;rer 6 007 patrons, qui ont une couverture de 66,10% (i.e. on retrouve 66,10% des phrases
contenant des occurrences des 10 006 relations de test). L&#8217;&#233;cart cons&#233;quent entre les 20 013 relations et les 214
phrases trouv&#233;es est d&#251; &#224; deux facteurs :
</p>
<p>&#8211; une contrainte r&#233;ductrice impos&#233;e lors de la s&#233;lection des phrases candidates. Seules les phrases dont tous les
mots des entit&#233;s nomm&#233;es sont correctement identifi&#233;s sont en effet conserv&#233;es. Or, les entit&#233;s peuvent &#234;tre
partiellement (ou mal) reconnues lors des traitements linguistiques ;
</p>
<p>&#8211; la nature des documents du corpus : 72% des documents sont des articles de presse &#233;dit&#233;s entre janvier 2008 et
ao&#251;t 2009, ce qui explique le peu de documents, voir aucun, concernant certaines personnes ou organisations
pourtant pr&#233;sentes dans la KB.
</p>
<p>Les r&#233;sultats de la couverture des patrons sont pr&#233;sent&#233;s dans le tableau 2 pour chaque type de relations dans la co-
lonne Couv. Patrons. &#192; titre indicatif, le temps d&#8217;induction des patrons pour le type de relations per:country_of_birth
(11 192 phrases exemples &#224; comparer) passe de 690mn et 5s pour la version sans filtrage &#224; 0mn et 30s pour la
version avec filtrage6, ce qui illustre l&#8217;int&#233;r&#234;t de celui-ci en termes de temps de calcul.
</p>
<p>3.3 &#201;valuation de l&#8217;extraction des relations
L&#8217;extraction des relations comprenant plusieurs &#233;tapes, chacune d&#8217;entre elles peut influer sur le r&#233;sultat global.
Nous proposons donc de faire une &#233;valuation s&#233;par&#233;e de la recherche des phrases candidates et de l&#8217;extraction des
relations proprement dite.
</p>
<p>3.3.1 Recherche des phrases candidates
</p>
<p>Une condition n&#233;cessaire pour des extraire relations pertinentes est de s&#8217;assurer que le moteur de recherche ren-
voie suffisamment de documents pertinents pour nous permettre de retrouver des entit&#233;s cibles. Nous avons donc
mesur&#233; la couverture en documents de notre recherche de phrases candidates, &#224; savoir le pourcentage de docu-
ments renvoy&#233;s par l&#8217;index que l&#8217;on retrouve effectivement dans la r&#233;f&#233;rence. Nous avons test&#233; de ce point de vue
diff&#233;rentes strat&#233;gies en faisant varier des param&#232;tres comme le nombre de r&#233;sultats retourn&#233;s et l&#8217;utilisation ou
non de l&#8217;expansion pour la requ&#234;te. Les r&#233;sultats de cette &#233;valuation nous ont ainsi conduit &#224; utiliser les entit&#233;s
sources et leurs formes &#233;tendues pour interrogation de l&#8217;index et prendre en compte les 1000 premiers r&#233;sultats
retourn&#233;s : ces param&#232;tres permettent de retrouver 84,24% des documents de r&#233;f&#233;rence. Le r&#233;sultat d&#233;taill&#233; par
type de relations est donn&#233; par la colonne Couv. Doc du tableau 2.
</p>
<p>&#192; partir des documents ainsi s&#233;lectionn&#233;s, les phrases candidates &#224; l&#8217;extraction d&#8217;une relation pour un type donn&#233;
6La version avec filtrage &#233;tant parall&#233;lis&#233;e, le temps donn&#233; est une somme des temps comptabilis&#233;s au niveau de chaque processeur.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>EXTRACTION DE RELATIONS &#192; LARGE &#201;CHELLE
</p>
<p>sont extraites en retenant les phrases contenant &#224; la fois l&#8217;entit&#233; source et le type de l&#8217;entit&#233; cible. La qualit&#233; et la
quantit&#233; des phrases candidates sont largement influenc&#233;es par la qualit&#233; de la reconnaissance des entit&#233;s nomm&#233;es.
Comme nous ne disposons pas d&#8217;annotation de r&#233;f&#233;rence pour les entit&#233;s nomm&#233;es du corpus, il n&#8217;est pas possible
de mesurer les pertes caus&#233;es par la mauvaise reconnaissance des entit&#233;s. En revanche, nous avons &#233;valu&#233; la
proportion de documents de r&#233;f&#233;rence dans lesquels nous retrouvons des phrases candidates. Cette donn&#233;e permet
de fixer une borne maximale pour le pourcentage de relations qu&#8217;il serait possible d&#8217;extraire si les &#233;tapes &#224; la
suite se d&#233;roulaient id&#233;alement. Nous obtenons au total une couverture de 37,55% des phrases appartenant aux
documents de r&#233;f&#233;rence. Le d&#233;tail par type de relations est pr&#233;sent&#233; &#224; la colonne Couv. Rel du tableau 2.
</p>
<p>3.3.2 Extraction de relations
</p>
<p>Pour &#233;valuer les relations extraites, nous avons r&#233;utilis&#233; les mesures et les outils d&#8217;&#233;valuation fournis par la cam-
pagne TAC-KBP7 sans nous limiter aux seuls documents pr&#233;sents dans la r&#233;f&#233;rence pour accepter une relation
correcte8. Le tableau 3 fournit les r&#233;sultats de cette &#233;valuation en agglom&#233;rant tous les types de relations et en
caract&#233;risant l&#8217;impact du filtrage a posteriori des entit&#233;s cibles sur les relations extraites en termes de rappel (R.),
pr&#233;cision (P.) et f1-mesure (F1.). Pour m&#233;moire, ce filtrage consiste &#224; s&#8217;assurer que l&#8217;entit&#233; cible valide des ex-
pressions r&#233;guli&#232;res et/ou une liste ferm&#233;e de valeurs. Nous indiquons dans la colonne Type de cible du tableau 2
le m&#233;canisme utilis&#233; pour chaque type de relations.
</p>
<p>Les r&#233;sultats du tableau 3 montrent d&#8217;une part, que ce filtrage am&#233;liore les performances (en moyenne +2,74% de
f1-mesure) et d&#8217;autre part, valident l&#8217;hypoth&#232;se que les patrons induits &#224; partir de l&#8217;APSS sont aussi pertinents que
ceux induits en consid&#233;rant tous les exemples de relations deux &#224; deux (dans ce cas, il y a m&#234;me une am&#233;lioration
de +1,72% de la f1-mesure en moyenne).
</p>
<p>Avant filtrage Apr&#232;s filtrage
R. (%) P. (%) F1. (%) R. (%) P. (%) F1. (%)
</p>
<p>Tous les couples d&#8217;entit&#233;s 16,28 11,20 13,26 18,07 13,66 15,56
APSS 16,90 12,76 14,54 18,67 16,87 17,72
</p>
<p>TAB. 3 &#8211; &#201;valuation de l&#8217;impact du filtrage des r&#233;ponses
</p>
<p>Le tableau 4 pr&#233;sente les r&#233;sultats de diff&#233;rents syst&#232;mes sur deux corpus tr&#232;s similaires, les corpus KBP 2009 et
KBP 2010, ce dernier ajoutant au premier des documents Web et des transcriptions, a priori plus difficiles. Bien
que ces chiffres ne portent que sur les relations effectivement pr&#233;sentes dans le corpus, ils int&#232;grent la contrainte
pour les syst&#232;mes ayant particip&#233; &#224; la t&#226;che Slot Filling de devoir d&#233;cider si la relation existe ou non dans le
corpus, ce que notre syst&#232;me, d&#233;velopp&#233; en dehors du contexte de ces campagnes, ne fait pas. Dans ce tableau,
les colonnes 2009 et 2010 d&#233;signent les scores des trois syst&#232;mes les plus et les moins performants de KBP
2009 et 2010. Ji et al. (2010) ont montr&#233; que sur 492 relations de r&#233;f&#233;rence, 60,4% se trouvaient dans la m&#234;me
phrase tandis que les 39,6% restantes d&#233;passaient l&#8217;espace phrastique dans leur expression et n&#233;cessitaient pour
leur extraction la r&#233;solution de cor&#233;f&#233;rences ou l&#8217;application de m&#233;canismes d&#8217;inf&#233;rence impliquant par exemple
la composition de plusieurs relations ou l&#8217;utilisation de connaissances a priori sur les types de relations. De ce
fait, nous avons distingu&#233; dans la colonne 2010 (a) du tableau 4 les scores des syst&#232;mes qui nous sont les plus
directement comparables, c&#8217;est-&#224;-dire ceux se limitant &#224; l&#8217;extraction de relations au niveau phrastique.
</p>
<p>On peut noter que le meilleur syst&#232;me de KBP 2010 (Chada et al., 2010) se d&#233;tache tr&#232;s nettement : +36,63%
par rapport au deuxi&#232;me et +4,68% par rapport &#224; un annotateur humain. Cette pr&#233;dominance s&#8217;appuie &#224; la fois
sur l&#8217;utilisation d&#8217;un corpus annot&#233; manuellement (diff&#233;rent du corpus KBP) de 3 millions de documents et la
pr&#233;sence de plusieurs m&#233;canismes d&#8217;extraction de relations au niveau inter-phrastique : cor&#233;f&#233;rence pronominale,
m&#233;tonymie entre entit&#233;s, r&#233;solution de d&#233;pendances s&#233;mantiques entre les mots et les entit&#233;s, etc. L&#8217;utilisation du
corpus suppl&#233;mentaire semble &#234;tre l&#8217;&#233;l&#233;ment d&#233;terminant par rapport aux syst&#232;mes venant &#224; la suite imm&#233;diate,
ceux-ci se distinguant de syst&#232;mes plus m&#233;dians par la prise en compte des relations inter-phrastiques. Les plus
mauvais r&#233;sultats, plus faibles en 2010, sont d&#251;s pour une bonne part &#224; des syst&#232;mes en cours de d&#233;veloppement.
</p>
<p>7http://nlp.cs.qc.cuny.edu/kbp/2010/scoring.html
8La r&#233;f&#233;rence du point de vue des documents n&#8217;&#233;tant constitu&#233;e qu&#8217;&#224; partir des r&#233;sultats des participants &#224; l&#8217;&#233;valuation TAC-KBP, elle n&#8217;est
</p>
<p>en effet pas compl&#232;te.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LUDOVIC JEAN-LOUIS, ROMARIC BESAN&#199;ON, OLIVIER FERRET, ADRIEN DURAND
</p>
<p>Concernant notre syst&#232;me, le tableau 4 permet de situer nos r&#233;sultats dans la moyenne des r&#233;sultats obtenus par
les participants de l&#8217;&#233;valuation KBP 2010 et parmi les trois premiers syst&#232;mes pour les approches faisant de
l&#8217;extraction de relations au niveau de la phrase. Dans ce dernier cas, l&#8217;approche la plus performante (29,15% de
f1-mesure) (Byrne &amp; Dunnion, 2010) utilise des r&#232;gles construites manuellement permettant d&#8217;atteindre un score
de pr&#233;cision (66,55%) &#233;quivalent au meilleur score de la campagne (66,80%) et un score de rappel (18,67%) se
situant dans la moyenne de la campagne (15,33%). Ce fort d&#233;s&#233;quilibre entre pr&#233;cision et rappel est d&#8217;ailleurs
assez symptomatique des approches manuelles.
</p>
<p>Syst&#232;mes TAC KBP 2009 2010 2010 (a)
Nb. soumissions (N) / participants N=16 / 8 N=31 / 15 N=18
Annotateur humain 58,99% 61,10% 61,10%
1er score 34,35% 65,78% 29,15%
2e&#768;me score 25,05% 29,15% 14,22%
3e&#768;me score 18% 28,29% 14,13%
(N-2)e&#768;me score 5,90% 0,55% 0,55%
(N-1)e&#768;me score 2,60% 0,19% 0,19%
Ne&#768;me score 1,75% 0,08% 0,08%
Notre syst&#232;me &#8211; 17,72% 17,72%
Moyenne 13,43% 17,49% 9,71%
M&#233;diane 13,93% 14,13% 12,27%
</p>
<p>TAB. 4 &#8211; R&#233;sultats sur les donn&#233;es TAC-KBP (f1-mesure)
</p>
<p>4 Travaux associ&#233;s
</p>
<p>L&#8217;extraction de relations &#224; large &#233;chelle, au sens o&#249; nous l&#8217;avons d&#233;finie &#224; la section 2, est une probl&#233;matique
encore r&#233;cente. N&#233;anmoins, au travers notamment des &#233;valuations TAC-KBP, elle a &#233;t&#233; l&#8217;objet d&#8217;un certain nombre
de travaux proposant diff&#233;rentes approches. Concernant sp&#233;cifiquement l&#8217;extraction des relations, les travaux se
r&#233;partissent entre l&#8217;utilisation de l&#8217;apprentissage statistique (Agirre et al., 2009; Li et al., 2009b; Chen et al.,
2010b), l&#8217;induction de patrons lexicaux (Li et al., 2009a; de Pablo-S&#225;nchez et al., 2009; McNamee et al., 2009;
Chen et al., 2010b) et enfin, l&#8217;adaptation de syst&#232;mes existants pour la d&#233;tection de relations (Schone et al., 2009;
Bikel et al., 2009). On note pour KBP 2010 l&#8217;introduction d&#8217;approches &#224; base de r&#232;gles, par exemple (Byrne &amp;
Dunnion, 2010), et d&#8217;approches reposant sur le principe de &#171; Distant supervision &#187; &#224; partir de classifieurs, dont
celle de (Surdeanu et al., 2010). Notre approche rel&#232;ve de l&#8217;induction de patrons lexicaux et fait l&#8217;hypoth&#232;se,
comme (Mintz et al., 2009), que la seule pr&#233;sence d&#8217;un couple d&#8217;entit&#233;s dans une phrase est suffisante pour
marquer la pr&#233;sence effective d&#8217;une relation entre ces entit&#233;s. Ce n&#8217;est cependant pas toujours le cas et nous
pensons ainsi qu&#8217;il est important de filtrer en amont les exemples utilis&#233;s pour l&#8217;induction des patrons, &#224; l&#8217;instar
de ce que propose (Riedel et al., 2010).
Comme notre syst&#232;me, ceux &#233;labor&#233;s pour KBP 2009 n&#8217;exploitent pas les liens de d&#233;pendance entre les types
de relations, &#224; l&#8217;image du lien entre la date de naissance et l&#8217;&#226;ge par exemple. Dans (Chen et al., 2010a), les
auteurs montrent que les r&#233;sultats obtenus dans (Li et al., 2009a) (31,96% de f1-mesure) peuvent &#234;tre am&#233;lior&#233;s
(ils obtiennent 34,81% de f1-mesure) par l&#8217;int&#233;gration des d&#233;pendances entre les relations en utilisant des r&#232;gles
d&#8217;inf&#233;rence fond&#233;es sur une extension de la logique du premier ordre. Plus g&#233;n&#233;ralement, Chada et al. (2010) ont
montr&#233; dans le cadre de KBP 2010 une augmentation tr&#232;s significative des performances en int&#233;grant des m&#233;ca-
nismes permettant d&#8217;extraire des relations au-del&#224; de la phrase. Sur un autre plan, Li et al. (2009a) se distinguent
dans KBP 2009 en utilisant deux &#233;tapes d&#8217;extraction de relations : la premi&#232;re vise &#224; retrouver dans les documents
du corpus des entit&#233;s cibles potentielles en utilisant des patrons de relations ; la seconde applique le m&#234;me proces-
sus &#224; une version r&#233;cente de Wikip&#233;dia pour trouver des entit&#233;s cibles potentielles suppl&#233;mentaires qui n&#8217;auraient
pas &#233;t&#233; identifi&#233;es lors de la premi&#232;re &#233;tape. Les entit&#233;s cibles ainsi acquises ne sont finalement conserv&#233;es que
si elles sont retrouv&#233;es dans un document du corpus. Cette r&#233;cup&#233;ration d&#8217;entit&#233;s am&#233;liore les performances de
fa&#231;on significative (+9% de f1-mesure par rapport &#224; (Bikel et al., 2009)) mais ajoute l&#8217;utilisation d&#8217;un corpus
externe que l&#8217;on peut consid&#233;rer comme trop li&#233; &#224; la KB. Les r&#233;sultats sur KBP 2010 ont d&#8217;ailleurs montr&#233; que</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>EXTRACTION DE RELATIONS &#192; LARGE &#201;CHELLE
</p>
<p>les performances globales pouvaient &#234;tre am&#233;lior&#233;es sans cette ressource suppl&#233;mentaire et que son impact sur les
r&#233;sultats est plus limit&#233; que pour KBP 2009 (une baisse des r&#233;sultats a m&#234;me &#233;t&#233; observ&#233;e).
</p>
<p>5 Conclusion et perspectives
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; un syst&#232;me d&#8217;extraction d&#8217;information &#224; large &#233;chelle permettant d&#8217;extraire
des relations de type attributive entre entit&#233;s nomm&#233;es. Le qualificatif &#171; &#224; large &#233;chelle &#187; recouvre &#224; la fois la
prise en compte d&#8217;un grand nombre de types de relations et la recherche de ces relations dans un large corpus.
Ce syst&#232;me se fonde sur une approche faiblement supervis&#233;e dans laquelle les exemples se limitent &#224; des couples
d&#8217;entit&#233;s en relation. L&#8217;extraction des relations s&#8217;effectue par l&#8217;application de patrons lexico-syntaxiques caract&#233;-
ristiques des types de relations consid&#233;r&#233;s et appris &#224; partir de phrases issues de la projection des couples d&#8217;entit&#233;s
exemples dans un corpus. Nous avons &#233;valu&#233; les r&#233;sultats de cette approche en utilisant le cadre d&#8217;&#233;valuation offert
par la t&#226;che Slot Filling de l&#8217;&#233;valuation KBP en nous concentrant sur la probl&#233;matique de l&#8217;extraction des relations
proprement dite, sans nous attacher &#224; la d&#233;tection de l&#8217;absence d&#8217;une relation dans un corpus. Les r&#233;sultats obtenus
dans ce contexte se situent dans la moyenne des r&#233;sultats obtenus par les participants de l&#8217;&#233;dition 2010, ce que
nous pouvons consid&#233;rer comme un point de d&#233;part int&#233;ressant dans la mesure o&#249; notre syst&#232;me repose sur une
approche volontairement g&#233;n&#233;rique et n&#8217;exploite que tr&#232;s faiblement les sp&#233;cificit&#233;s des types de relations trait&#233;s.
Nous avons aussi pu montrer que des techniques permettant de prendre en compte certains aspects d&#8217;un passage &#224;
une &#171; large &#233;chelle &#187;, comme le filtrage des couples de phrases exemples &#224; g&#233;n&#233;raliser par l&#8217;utilisation de l&#8217;APSS,
ne d&#233;gradent pas les performances et peuvent m&#234;me contribuer &#224; les am&#233;liorer.
</p>
<p>Nous travaillons par ailleurs sur l&#8217;am&#233;lioration de notre syst&#232;me en conservant l&#8217;id&#233;e de garder une certaine g&#233;-
n&#233;ricit&#233; par rapport au type des relations consid&#233;r&#233;es. Pour ce faire, nous nous focalisons particuli&#232;rement sur
l&#8217;apprentissage des patrons d&#8217;extraction. Un premier pas dans cette direction vise &#224; disposer &#224; la fois d&#8217;un nombre
plus important d&#8217;exemples mais &#233;galement d&#8217;exemples de meilleure qualit&#233;. Ces deux points sont li&#233;s dans la
mesure o&#249; l&#8217;obtention d&#8217;un ensemble plus large d&#8217;exemples passe par le rel&#226;chement des contraintes touchant la
s&#233;lection des phrases exemples. Or, si l&#8217;on peut esp&#233;rer qu&#8217;un tel rel&#226;chement permettra l&#8217;obtention de nouveaux
bons exemples, il sera aussi source de nouveaux mauvais exemples. Nous souhaitons donc coupler un tel rel&#226;che-
ment avec l&#8217;utilisation d&#8217;un module de filtrage de relations qui, &#224; l&#8217;instar de (Banko &amp; Etzioni, 2008), est capable
de d&#233;terminer si une phrase contient une relation entre deux entit&#233;s sans a priori sur la nature de cette relation.
</p>
<p>R&#233;f&#233;rences
AGICHTEIN E. &amp; GRAVANO L. (2000). Snowball : Extracting relations from large plain-text collections. In 5th
ACM International Conference on Digital Libraries, p. 85&#8211;94, San Antonio, Texas, USA.
AGIRRE E., CHANG A., JURAFSKY D., MANNING C., SPITKOVSKY V. &amp; YEH E. (2009). Stanford-UBC at
TAC-KBP. In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.
BANKO M. &amp; ETZIONI O. (2008). The tradeoffs between open and traditional relation extraction. In ACL-08 :
HLT, p. 28&#8211;36, Columbus, Ohio.
BAYARDO R., MA Y. &amp; SRIKANT R. (2007). Scaling up all pairs similarity search. In 16th International
Conference on World Wide Web (WWW&#8217;07), p. 131&#8211;140, Banff, Alberta, Canada.
BIKEL D., CASTELLI V., RADU F. &amp; JUNG HAN D. (2009). Entity Linking and Slot Filling through Statistical
Processing and Inference Rules. In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.
BIZER C., LEHMANN J., KOBILAROV G., AUER S., BECKER C., CYGANIAK R. &amp; HELLMANN S. (2009).
DBpedia - A crystallization point for the Web of Data. Journal of Web Semantics, 7, 154&#8211;165.
BYRNE L. &amp; DUNNION J. (2010). UCD IIRG at TAC 2010 KBP Slot Filling Task. In Third Text Analysis
Conference (TAC 2010), Gaithersburg, Maryland, USA.
CHADA D., ARANHA C. &amp; MONTE C. (2010). An Analysis of The Cortex Method at TAC 2010 KBP Slot-
Filling. In Third Text Analysis Conference (TAC 2010), Gaithersburg, Maryland, USA.
CHEN Z., TAMANG S., LEE A., LI X., PASSANTINO M. &amp; JI H. (2010a). Top-down and Bottom-up : A
Combined Approach to Slot Filling. In 6th Asia Information Retrieval Symposium on Information Retrieval
Technology, Gaithersburg, Maryland, USA : Springer-Verlag.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LUDOVIC JEAN-LOUIS, ROMARIC BESAN&#199;ON, OLIVIER FERRET, ADRIEN DURAND
</p>
<p>CHEN Z., TAMANG S., LEE A., LI X., SNOVER M., PASSANTINO M., LIN W.-P. &amp; JI H. (2010b). CUNY-
BLENDER TAC-KBP2010 Slot Filling System Description. In Text Analysis Conference (TAC 2010), Gaithers-
burg, Maryland, USA.
CLAVEAU V. &amp; S&#201;BILLOT P. (2004). From efficiency to portability : acquisition of semantic relations by semi-
supervised machine learning. In 20th International Conference on Computational Linguistics (COLING 2004),
p. 261&#8211;267, Geneva, Switzerland.
DE PABLO-S&#193;NCHEZ C., PEREA J., SEGURA-BEDMAR I. &amp; MART&#205;NEZ P. (2009). The UC3M team at the
Knowledge Base Population task. In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland,
USA.
EMBAREK M. &amp; FERRET O. (2008). Learning patterns for building resources about semantic relations in the
medical domain. In 6th Conference on Language Resources and Evaluation (LREC&#8217;08), Marrakech, Morocco.
GIONIS A., INDYK P. &amp; MOTWANI R. (1999). Similarity search in high dimensions via hashing. In 25th
International Conference on Very Large Data Bases (VLDB&#8217;99), p. 518&#8211;529, Edinburgh, Scotland, UK.
HEARST M. (1992). Automatic acquisition of hyponyms from large text corpora. In 14th International Confe-
rence on Computational linguistics (COLING&#8217;92), p. 539&#8211;545, Nantes, France.
JI H., GRISHMAN R. &amp; TRANG DANG H. (2010). Overview of the TAC 2010 Knowledge Base Population
Track. In Third Text Analysis Conference (TAC 2010), Gaithersburg, Maryland, USA.
LI F., ZHENG Z., BU F., TANG Y., ZHU X. &amp; HUANG M. (2009a). THU QUANTA at TAC 2009 KBP and
RTE Track. In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.
LI S., GAO S., ZHANG Z., LI X., GUAN J., XU W. &amp; GUO J. (2009b). PRIS at TAC 2009 : Experiments in
KBP Track. In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.
MCNAMEE P., DREDZE M., GERBER A., GARERA N., FININ T., MAYFIELD J., PIATKO C., RAO D., YA-
ROWSKY D. &amp; DREYER M. (2009). HLTCOE Approaches to Knowledge Base Population at TAC 2009. In
Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.
MINTZ M., BILLS S., SNOW R. &amp; JURAFSKY D. (2009). Distant supervision for relation extraction without
labeled data. In ACL-IJCNLP&#8217;09, p. 1003&#8211;1011, Suntec, Singapore.
PANTEL P., RAVICHANDRAN D. &amp; HOVY E. (2004). Towards terascale knowledge acquisition. In 20th Inter-
national Conference on Computational Linguistics (COLING&#8217;04), p. 771&#8211;777, Geneva, Switzerland.
RAVICHANDRAN D. (2005). Terascale knowledge acquisition. PhD thesis, Faculty of the Graduate School
University of Southern California, Los Angeles, CA, USA.
RIEDEL S., YAO L. &amp; MCCALLUM A. (2010). Modeling relations and their mentions without labeled text. In
J. BALC&#193;ZAR, F. BONCHI, A. GIONIS &amp; M. SEBAG, Eds., Machine Learning and Knowledge Discovery in
Databases, volume 6323 of Lecture Notes in Computer Science, p. 148&#8211;163. Springer Berlin / Heidelberg.
RUIZ-CASADO M., ALFONSECA E. &amp; CASTELLS P. (2007). Automatising the learning of lexical patterns : An
application to the enrichment of wordnet by extracting semantic relationships from wikipedia. Data Knowledge
Engineering, 61, 484&#8211;499.
SCHLAEFER N., GIESELMANN P., SCHAAF T. &amp; WAIBEL A. (2006). A pattern learning approach to question
answering within the ephyra framework. In P. SOJKA, I. KOPECEK &amp; K. PALA, Eds., Text, Speech and Dialogue,
volume 4188 of Lecture Notes in Computer Science, p. 687&#8211;694. Springer Berlin / Heidelberg.
SCHONE P., GOLDSCHEN A., LANGLEY C., LEWIS S., ONYSHKEVYCH B., CUTTS R., DAWSON B., MAC-
BRIDE J., MATRANGOLA G., MCDONOUGH C., PFEIFER C. &amp; URSIAK M. (2009). TCAR at TAC-KBP 2009.
In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.
SHINYAMA Y. &amp; SEKINE S. (2006). Preemptive information extraction using unrestricted relation discovery. In
HLT-NAACL 2006, p. 304&#8211;311, New York City, USA.
SURDEANU M., MCCLOSKY D., TIBSHIRANI J., BAUER J., CHANG A., SPITKOVSKY V. &amp; MANNING C.
(2010). A Simple Distant Supervision Approach for the TAC-KBP Slot Filling Task. In Text Analysis Conference
(TAC 2010), Gaithersburg, Maryland, USA.
TAC-KBP (2010). Preliminary task description for knowledge-base population at TAC 2010.
ZHOU G., SU J., ZHANG J. &amp; ZHANG M. (2005). Exploring various knowledge in relation extraction. In 43rd
Annual Meeting of the Association for Computational Linguistics (ACL 2005), p. 427&#8211;434, Ann Arbor, USA.
ZHOU G., ZHANG M., JI D. &amp; ZHU Q. (2007). Tree kernel-based relation extraction with context-sensitive
structured parse tree information. In EMNLP - CoNLL&#8217;07, p. 728&#8211;736, Prague, Czech Republic.</p>

</div></div>
</body></html>