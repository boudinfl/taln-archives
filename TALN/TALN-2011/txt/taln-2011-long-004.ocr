TALN 2011, Montpellier, 27juin — 1"'ju1'11et 2011

Une approche faiblement supervisée pour l’extraction de relations £1 large
échelle

Ludovic J ean-Louis Romaric Besancon Olivier Ferret Adrien Durand
CEA, LIST, Laboratoire Vision et Ingénierie des Contenus
Fontenay-aux-Roses, F-92265, France.

{ ludovic.jean-louis,romaric.besancon,o1ivier.ferret,adrien.durand} @cea.fr

Résllnlé. Les systemes d’extraction d’information traditionnels se focalisent sur un domaine speciﬁque et
un nombre lirnite de relations. Les travaux recents dans ce domaine ont cependant vu emerger la problematique
des systemes d’extraction d’information a large echelle. A l’instar des systemes de question—reponse en domaine
ouvert, ces systemes se caracterisent a la fois par le traitement d’un grand nombre de relations et par une absence
de restriction quant aux domaines abordes. Dans cet article, nous presentons un systeme d’extraction d’infor—
mation a large echelle fonde sur un apprentissage faiblement supervise de patrons d’extraction de relations. Cet
apprentissage repose sur la donnee de couples d’entites en relation dont la projection dans un corpus de reference
permet de constituer la base d’exemples de relations support de l’induction des patrons d’ extraction. Nous presen-
tons egalement les resultats de l’application de cette approche dans le cadre d’evaluation deﬁni par la tache KBP
de l’evaluation TAC 2010.

Abstract. Standard Information Extraction (IE) systems are designed for a speciﬁc domain and a hunted
number of relations. Recent work has been undertaken to deal with large-scale IE systems. Such systems are
characterized by a large number of relations and no restriction on the domain, which makes difﬁcult the deﬁnition
of manual resources or the use of supervised techniques. In this paper, we present a large-scale IE system based
on a weakly supervised method of pattern learning. This method uses pairs of entities known to be in relation to
automatically extract example sentences from which the patterns are learned. We present the results of this system
on the data from the KBP task of the TAC 2010 evaluation campaign.

M0tS-CléS 3 extraction d’information, extraction de relations.

Keywords: information extraction, relation extraction.

LUDOVIC JEAN-LOUIS, ROMARIC BESANCON, OLIVIER FERRET, ADRIEN DURAND

1 Introduction

Dans le cadre de l’extraction d’information, l’extraction de relations est un processus dont l’objectif est de deter-
miner l’existence d’un lien sémantique er1tre deux entités et lorsque cela est possible, de caracteriser la nature de
ce lien. Nous nous interessons plus particulierement dans cette etude a l’extraction de relations entre entites nom-
mées en vue de la collecte et de la construction d’une base de connaissances a large echelle. En effet, on trouve
dans des sources d’informations ouvertes, en particulier dans le contexte du Web sémantique, un grand nombre
d’informations disponibles sous forme semi—structurée : par exemple, l’encyclopédie Wikipédia contient des in-
formations qui peuvent etre structurées sous forme d’une base de donnees, comme le montre le proj et DBpedia1
(Bizer et al., 2009). Cette structuration premiere des informations semi—structurées peut alors etre complétee par
l’extraction automatique de relations entre entites a partir de texte brut.

Les travaux ayant pour objet l’extraction de relations peuvent etre considéres selon l’angle du degré de supervision
qu’ils requierent. Au degré le plus faible, que l’on qualiﬁe d’ approche non supervisée, le type des relations a
extraire n’est pas déﬁni a priori, que ce soit par le biais d’exemples ou d’un modele. Tout au plus peuvent etre
ﬁxees certaines contraintes sur les entités reliées, comme leur type par exemple. Le type des relations extraites
est quant a lui deﬁni a posteriori, en regroupant les relations jugées similaires. Une telle approche est Inise en
oeuvre dans (Shinyama & Sekine, 2006) ou dans (Banko & Etzioni, 2008) par exemple. A l’autre extreme de
cette échelle, le type des relations visees mais aussi les moyens de les extraire a partir des textes sont déﬁnis
a priori. Cette approche dite supervisée se caractérise soit par la donnee d’un modele élaboré manuellement,
typiquement sous la forme de regles, soit par l’association d’un ensemble d’exemples de relations en contexte
issus de l’annotation d’un corpus et d’ un algorithme d’ apprentissage permettant d’ en construire automatiquement
un modele. Cette seconde option est dominée par les modeles d’apprentissage statistique, qui se focalisent sur la
prise en compte d’un large spectre de caracteristiques de différents types (lexicales, syntaxiques, sémantiques ...)
(Zhou et al., 2005) et sur l’élaboration de fonctions noyaux permettant de prendre en compte ces caractéristiques,
en particulier lorsqu’elles ont des structures complexes comme celles produites par l’analyse syntaxique (Zhou
et al., 2007).

Entre ces deux poles se trouvent les approches dites faiblement supervisées, vocable recouvrant l’idee que des
exemples ou un modele sont fournis pour le développement du systeme d’extraction de relations mais que cette
seule contribution 11’ est pas sufﬁ sante pour la realisation d’ un systeme pleinement opérationnel. De ce fait, elle doit
etre etendue de maniere automatique, généralement en exploitant un corpus non annoté. Les travaux existant en la
matiere font apparaitre deux cas de sous—determination de la contribution initiale, cas pouvant etre éventuellement
assoc1es :

— une sous—determination liée au volume de cette contribution. Seul un petit ensemble de relations exemples ou
un modele incomplet sont fournis ;

— une sous—determination liee a la nature de la contribution initiale, ce qui se produit lorsque les exemples ou le
modele doivent etre instanciés pour etre utilises.

Le premier cas de ﬁgure est typiquement traité suivant la methodologie initiee par Hearst (1992) grace a un me-
canisme d’ amorgage exploitant le petit ensemble initial d’exemples de relations ou de regles d’ extraction pour
acquérir de nouveaux exemples a partir d’ un corpus et Venir ainsi enrichir progressivement le modele des relations
visees au ﬁl de cycles successifs d’ application de ces deux etapes. (Agichtein & Gravano, 2000) en est un repre-
sentant typique pour les relations entre entités nommées. Bien qu’opérant dans un champ different — l’extraction
de structures qualia — (Claveau & Sébillot, 2004) offre un autre exemple d’amorgage pour l’induction de patrons
linguistiques en combinant deux systemes aux caractéristiques differentes.

Le second cas de ﬁgure est quant a lui illustré par la notion récente de << Distant supervision », introduite formel—
lement par (Mintz et al., 2009) mais déja présente dans certains travaux sur l’amorgage. Les exemples sont ici
donnes sous une forme sous—determinée puisque reduite a un couple d’entités : ils sont donc a la fois privés de
contexte et de caractérisation linguistiques. Le developpement de ce type d’approches est favorisé par la Inise a
disposition de larges bases de connaissances extraites de ressources telles que Wikipédia.

Dans cet article, nous presentons un systeme d’extraction d’information a large echelle fondé sur un apprentissage
faiblement supervise de patrons d’ extraction de relations reposant sur des exemples sous la forme de couples d’en—
tites. Ces couples sont proj etés dans un corpus de reference pour constituer la base d’ exemples de relations a partir

lhttp : //dbpedia . org/About

EXTRACTION DE RELATIONS A LARGE ECHELLE

Apprentissage des patrons de relations Extraction des relations

Relations connues *7" //7G\\ ,/""77 Relationsacompléter ‘ B ?)
rel(E1,E2) L  \ COFPUSJ  J rel(E1,?) ,°°"""Y( e"“"""’ ,

\

 

r . ‘ /
‘ K \ , i /
/’ \ \ /
f‘f’;'f;‘,‘§f§1(Vﬁ,ﬁ§“,§”;;§33§§ i Recherche d‘occurrences \ Recherche’ de phrases
_/ I y de relations V ‘ candidates

K

._;

 
   

 relat.ions between Malaysia and Britain,
the state Bernama news agency 

News agency Bernama says Malaysian
prime minister will 

V *" , r\/

,,_ / » \ A Bernama
i_ Expanslon  Malaysaian Nat.ional news agency

ii  network was HDNet, foimded in 2001 by Dallas..
Metaweb, foimded i.n 2005 is a spinoff company.

ii Induction de patrons
‘‘  relations between Malaysia and Britain,

<E1> founded in <E2> W \\l l// /( Apphcanon des Patrons the state Bernama news agency  W
’ ,/ \ V’

 

 

/ /  . , . \ .

/,/ Extraction-selection des “ Mala Sm

‘ ‘ reponses /

 ——— jL j\
Patrons de relations I Filtrage des réponses  MUM!

\ /

Relations extraites

FIG. 1 — Architecture generale du systeme

de laquelle les patrons d’extraction sont appris. Ce travail se rattache donc au concept de << Distant supervision ».
Nous presentons egalement les resultats de l’application d’une telle approche dans le cadre d’ evaluation deﬁni par
la tache KBP (Knowledge Based Population) de l’evaluation TAC 2010 (Text Analysis Conference).

2 Presentation de l’approche

Nous nous concentrons dans notre approche sur l’extraction de relations a large echelle en supposant la preexis-
tence d’une base de connaissances partiellement remplie, extraite automatiquement a partir de donnees se1ni—
structurees. Nous nous limitons ici aux relations entre entites nommees etant donne que, n’intervenant pas en
domaine de specialite ou la recherche des entites peut etre guidee par une terminologie existante, nous avons
Volontairement choisi de nous focaliser sur des entites aisement identiﬁables. La notion de << large echelle » se
decline quant a elle selon plusieurs dimensions. La premiere reside dans le grand nombre de types de relations
differents consideres, induisant une Inise en oeuvre difﬁcile pour une approche a bases de regles ecrites manuel—
lement. La deuxieme est liee a la prise en compte initiale d’un grand nombre de relations existantes (c’est—a—dire
l’association de deux valeurs d’entites a un type de relation) ; ces relations foumissent un bon ensemble de depart
pour l’apprentissage automatique d’un modele de ces types de relations. Enﬁn, le corpus dans lequel de nouvelles
relations sont recherchees est lui—meme important, ce qui implique l’utilisation de techniques d’indexation et de
recherche pour extraire des bons candidats (on ne peut pas envisager l’application directe de patrons sur toutes les
phrases du corpus). Cette approche, illustree par la ﬁgure 1, s’articule en deux phases : une phase d’apprentissage
de patrons a partir d’occurrences de relations connues et une phase d’extraction de relations pour la decouverte
de nouvelles relations. La premiere phase part des relations connues R(El,E2) pour trouver des occurrences de
ces relations dans un corpus, c’est—a—dire les differentes expressions de cette relation dans les textes et utiliser ces
occurrences pour induire des patrons de reconnaissance pour le type de relation conceme. La seconde phase part
de relations incompletes R(El,x), ou l’entite source El est connue et l’entite cible x est a trouver, cherche des
occurrences de relations impliquant El dans un corpus, puis extrait l’entite x en utilisant les patrons induits dans
la premiere phase. Ces deux phases sont detaillees dans les sections suivantes.

2.1 Apprentissage des patrons

L’ apprentissage des patrons de relations repose sur l’induction (ou generalisation) de patrons lexicaux a partir
de phrases exemples contenant des occurrences des relations considerees. L’ objectif de cet apprentissage est de

LUDOVIC JEAN-LOUIS, ROMARIC BESANCON, OLIVIER FERRET, ADRIEN DURAND

capturer les differentes expressions d’une relation sémantique entre deux entités. Par exemple, les deux extraits de
phrases ci—dessous contiennent des occurrences de relations pour le type founded_by, instancie pour les couples
d’ entites (Charles Revson; Revlon Cosmetics) et (Mayer Lehman; Lehman Brothers investment).

The glamourous cabaret chanteuse reportedly had had a romantic liaison with
<source>Charles Revson</source>, the founder of <cible>Revlon Cosmetics</cible>  — Lehman was a great-
grandson of <source>Mayer Lehman</source>, a founder of the <cible>Lehman Brothers investment</cible>
house 

Plusieurs travaux presentent des algorithmes de generalisation de patrons lexicaux (Ravichandran, 2005; Schlaefer
et al., 2006; Ruiz-Casado et al., 2007). Notre approche est similaire a celle de (Pantel et al., 2004) et reprend plus
directement encore la méthode de (Embarek & Ferret, 2008). L’ idée genérale de l’approche est de trouver, dans
le contexte entre les entites cible et source, des points communs er1tre deux phrases exprimant la relation que l’on
veut capturer. Ici, nous cherchons ces points communs parmi trois niveaux d’ information linguistique : forme de
surface, lemme et categorie morpho—syntaxique. Ces informations linguistiques sont mises en evidence grace a
l’outil OpenNLP2, qui est plus globalement également utilise pour la reconnaissance des entités nommées. La
presence de ces trois niveaux d’information donne une plus grande expressivité aux patrons construits et permet
ainsi de trouver un compromis intéressant en termes de niveau de generalisation entre la spéciﬁcité des elements
lexicalisés et le caractere plus general des categories morpho-syntaxiques.

L’induction d’un patron a partir de deux occurrences de relation est plus precisement composée des trois etapes
suivantes :

— le calcul de la distance d’édition er1tre les deux phrases exemples, c’est—a—dire le nombre minimal d’opera—
tions d’editions (insertion, suppression, substitution) a effectuer pour passer d’une phrase a l’autre. Toutes les
operations ont ici le meme poids ;

— l’alignement optimal des phrases exemples a partir de la matrice des distances er1tre sous—sequences issue du
calcul de la distance d’ edition. L’ algorithme classique pour trouver un tel alignement est ici étendu en permettant
la Inise en correspondance de deux mots lors d’ une substitution selon les trois niveaux d’information possibles ;

— construction des patrons en completant si necessaire les alignements par des opérateurs jokers ( *s *), represen-
tant 0 ou 1 mot quelconque, et ( *g *), représentant exactement un mot quelconque.

Le tableau 1 montre un exemple d’induction de patron pour le type de relation founded_by a partir des deux
extraits de phrases ci—dessus. On peut noter la presence de la catégorie DET (determinant) comme generalisation
pour (althe), ce qui rend le patron pertinent pour d’autres extraits tels que "Charles Kettering, another founder of
DELCO  ".

Charles Revson , the founder of Revlon Cosmetics
Mayer Lehman , a founder of the Lehman Brothers investment
<source> , DET founder of (*s*) <cible>

TAB. 1 — Exemple d’induction de patron de relation

Cet exemple illustre également le fait que la generalisation peut aller jusqu’a l’utilisation de jokers pouvant se sub-
stituer a n’importe quel mot. Comme il est toujours possible de generaliser deux phrases en un patron ne contenant
que des jokers, il est necessaire de ﬁxer une limite superieure au nombre de jokers pouvant etre introduits dans
une operation de generalisation pour conserver un niveau de spéciﬁcité raisonnable des patrons. Par ailleurs, tra-
vaillant en domaine ouvert et avec des entités nommées assez genérales, nous souhaitons plutot induire un nombre
important de patrons speciﬁques qu’un ensemble restreint de patrons tres généraux, ceci aﬁn de privilégier la pre-
cision. C’est egalement pour cette raison que nous ne cherchons pas a generaliser les patrons en leur reappliquant
la procedure d’induction décrite. Dans l’évaluation presentée en section 3, le nombre maximal de jokers dans un
patron est donc ﬁxe a 1.

Dans le contexte de supervision distante dans lequel nous nous placons, les phrases exemples ne sont pas direc-
tement foumies en tant que telles mais résultent de la projection dans un corpus de relations se presentant sous la
forme de couples d’entités (par exemple le couple (Ray Charles, Albany) pour le type de relation city_of_birth).
Plus concretement dans notre cas, elles sont recuperees en soumettant a un moteur de recherche des requetes conte-

Zhttp : //opennlp . sourceforge . net/index .html

EXTRACTION DE RELATIONS A LARGE ECHELLE

nant des couples d’entites pour un type de relations donne et en restreignant les resultats du moteur aux phrases
contenant effectivement les deux valeurs des entites. On peut souligner que la nature des restrictions appliquees a
un impact direct sur la quantite et la precision des patrons induits. Plus on impose de contraintes, moins on obtient
de phrases exemples, mais meilleurs seront les patrons induits. Par exemple, les auteurs de (Agirre et al., 2009) ne
retiennent que les phrases exemples dans lesquelles les paires d’entites apparaissent dans un voisinage de zero a
dix mots.

11 est important de noter que le processus d’induction de patrons s’effectue en comparant les phrases exemples
deux a deux. Il peut donc etre coﬁteux (en temps de calcul) lorsque le nombre de phrases exemples est important :
pour 10 000 exemples, on a environ 50 millions de couples distincts de phrases a comparer (n(n — 1) / 2 exacte-
ment). Pour traiter ce probleme, la solution immediate consiste a reduire de fagon drastique le nombre de phrases
exemples en amont du processus d’induction, la consequence etant une reduction de la couverture des djfferentes
forme d’ expression des types de relations. Une autre solution consiste a faire une reduction selective du nombre
de couples de phrases exemples a generaliser en évitant de considerer les couples de phrases dont la distance est
Visiblement trop grande pour induire des patrons interessants. Meme si la distance utilisee pour cette induction
est une distance d’edition, donc tenant compte de l’ordre des mots, il est evident qu’un faible recoupement des
phrases en termes de mots conduira a une valeur élevee de la distance d’edition. Le ﬁltrage a priori des couples
de phrases peut donc se fonder sur une mesure s’appliquant a une representation de type << sac de mots », telle que
la mesure cosinus, en ﬁxant une valeur minimale en dessous de laquelle la generalisation des couples de phrases
n’est pas realisée. Or, la mesure cosinus peut etre evaluee de maniere efﬁcace, soit avec une bonne approximation,
comme dans le cas du Local Sensitive Hashing (Gionis et al., 1999), soit de maniere exacte mais en ﬁxant un seuil
de similarite minimale, ce qui correspond a notre cas de ﬁgure. Nous avons donc retenu pour notre ﬁltrage l’al—
gorithme All Pairs Similarity Search (APSS), propose dans (Bayardo et al., 2007), qui calcule la mesure cosinus
pour les seules paires d’objets consideres — ici, les phrases exemples — dont la similarite est superieure ou egale
a un seuil ﬁxe a priori. Cet algorithme se fonde plus precisement sur une serie d’optimisations dans l’indexation
des objets tenant compte des informations recueillies sur leurs caractéristiques et d’un tri applique a ces objets en
fonction de ces memes caracteristiques.

Notons que lors de l’induction de patrons a partir d’ un grand volume de phrases exemples, on retrouve de nom-
breux doublons, soit parce que la meme phrase exemple se trouve dans plusieurs documents, soit parce que l’on
retrouve la meme forme d’ expression d’un type de relations avec des valeurs differentes (Obama ’s height is 1.87m ;
Sarkozy ’s height is 1.65m). Ainsi, nous proposons de ﬁltrer les phrases exemples a deux niveaux : d’ abord avec un
seuil de similarite fort aﬁn d’identiﬁer et eliminer les phrases identiques ; puis avec un seuil de similarité faible
pour s’assurer d’un niveau minimal de similarite entre les phrases en vue du processus d’induction.

2.2 Extraction des relations

L’ extraction de nouvelles relations se fait a partir des types de relations existants et d’ entités connues : on cherche
a completer une base de connaissances existante en completant les informations concemant les entites qu’elle
contient. La premiere etape de l’extraction de relations est la recherche de phrases candidates pouvant contenir
l’expression d’une relation. Elle prend comme point de depart des requetes contenant une entite nommée associée
a son type et le type de l’information recherchee. La recherche proprement dite est realisée, comme dans le cas
de l’apprentissage de patrons, grace a un moteur de recherche ayant prealablement indexe le corpus cible pour
l’extraction des relations. Nous nous sommes appuyes dans notre cas sur le moteur Lucene3, avec une indexation
adaptee aux caracteristiques de notre recherche : les documents initiaux sont decoupes en unites d’ indexation de
petite taille, trois phrases, grace a une fenetre glissante et au sein de ces unites, sont indexes les mots pleins sous
leur forme normalisee et les entités nommees, avec leur type. L’ interrogation du corpus presente en outre la par-
ticularite d’inclure une phase d’expansion de l’entite source. En effet, on retrouve souvent dans les documents
des formes plus ou moins developpees des entites nommees : par exemple Bill Clinton est genéralement utilise au
lieu de William Jeﬂerson Blythe III Clinton. 11 est donc interessant de savoir que ces deux mentions d’entités sont
equivalentes et associees a la meme entite, en particulier lors de la recherche de documents. Nous utilisons donc
une etape d’expansion des entités visant a associer a une entité donnée les formes alternatives lui faisant reference.
Pour l’entite "Barack Obama", on a ainsi : {B. Hussein Obama, Barack H. Obama Junior, Barack Obama Jr, Ba-
rack Hussein Obama Jr., etc. } . L’ interet est de pouvoir augmenter les chances de retrouver des phrases candidates

3http://lucene.apache.org/java/docs/index.html

LUDOVIC JEAN-LOUIS, ROMARIC BESANCON, OLIVIER FERRET, ADRIEN DURAND

liees a l’entité puisque l’on considere tous les documents dans lesquels apparaissent ses differentes expressions.
Une base d’expansion des entités a eté constituée de fagon automatique a partir du corpus Wikipédia4 en collectant
pour chaque entité les formulations extraites des pages de redirection de Wikipedia vers cette entité. Au total, la
base d’ expansion contient des formes etendues pour environ 2,4 millions d’entrées.

Nous appliquons ensuite sur les phrases candidates sélectionnées les patrons induits lors de la phase d’apprentis—
sage. Les entités cibles extraites par ces patrons sont cumulées pour ne retenir ﬁnalement que les plus fréquentes :
notre hypothese est que les entites cibles les plus pertinentes apparaissent plus souvent dans les documents que
les moins pertinentes. Pour les relations mono—valuees (ex. : date de naissance), une seule valeur est conservee.
Pour les relations multi—valuees (ex. : lieux de residence), un nombre arbitraire de trois valeurs sont conservées
a defaut de connaissances foumies a priori ou extraites des textes quant a ce point. Enﬁn, un demier ﬁltre est
applique sur les entités cibles pour veriﬁer la compatibilité des valeurs obtenues avec les contraintes relatives au
type d’ information recherche qu’elle représentent, déﬁnies par des listes de valeurs ou d’ expressions régulieres :
on veriﬁe par exemple que le pays de naissance d’une personne fasse bien partie de la liste des pays connus.

3 Evaluation

Nous présentons dans cette section les resultats de 1’ evaluation de notre systeme en utilisant les données de la tache
Slot Filling de la campagne d’évaluation TAC-KBP 2010 (TAC-KBP, 2010). Nos expérimentations ont donc été
réalisees pour l’anglais. La tache Slot Filling correspond aux speciﬁcations de notre contexte de travail telles que
nous les avons déﬁnies a la section 2 : son objectif est d’extraire a partir d’un vaste corpus l’entité cible d’une
relation ayant comme source une entité présente dans une base de connaissances abritant un ensemble important
d’ exemples du type de relation vise. Les types de relations consideres dans ce cadre sont au nombre de 42, repartis
en 16 relations pour des entités de type ORGANISATION (ORG) et 26 relations pour les entités de type PERSONNE
(PERS). La liste des types de relations traités est presentée dans le tableau 2. Nous précisons que les experiences
ont eté realisées sur un cluster de 24 noeuds (4 processeurs/noeud) avec une parallelisation par type de relations.

3.1 Cadre d’évaluation

Les données d’évaluation issues de TAC-KBP sont les suivantes :

— un corpus de textes compose d’ environ 1,8 millions de documents (1 780 980 exactement) répartis en 0,04% de
transcriptions (conversations téléphoniques, joumaux radio, conversations radio), 72,24% d’articles de presse
et 27,72% de pages Web;

— une base de connaissances (KB) reposant sur une image de Wikipedia d’ octobre 2008. Un identiﬁant unique et
un type d’entité sont attribués a chaque page contenant des infobox. Le type d’ entité personne, organisation,
entite’ géopolitique ou inconnu est associé a chaque page en fonction des champs contenus dans les infobox.
Typiquement, les infobox Infobox_Actor sont ainsi liées a des personnes. Au ﬁnal 818 741 entités ont eté
retenues pour former la KB, chacune d’elles etant associée a un ensemble de proprietes (champs des infobox)
ainsi qu’a un texte la décrivant. Ainsi les relations sont représentées dans la KB par des tuples (identiﬁant,
type infobox, nom, type, propriété, valeurs), ex. : (E0000437 ; Infobox_Actor ; Julia Roberts; PER ; birthplace;
Atlanta) ;

— une table de correspondance entre les propriétés issues de Wikipedia et les types de relations retenus pour
l’évaluation. Par exemple, Infobox_Actor:birthplace est convertie en per:city_of_birth. Cette correspondance
permet de prendre en compte une certaine heterogéneite de designation des propriétés dans Wikipédia;

— une liste de 100 entités sources pour lesquelles on cherche a extraire toutes les entités en relation pour tous les
types de relations considerés. On dénombre parmi ces entités 15 entités présentes dans la KB et 85 inconnues
de la KB. Par ailleurs, toutes les relations considérees ne trouvent pas d’entités cibles dans le corpus pour ces
100 entités. Dans le cadre de cette etude, nous nous focalisons uniquement sur les relations pour lesquelles il
existe une entité cible dans le corpus5, ce qui représente au total 2069 relations. Le detail par type de relations
est presente dans la colonne Nb Ref du tableau 2.

4Plus précisément, la version misc a disposition par l’université dc New York : http : / /nlp . cs . nyu . edu /wikipedia— data
5Les entités cibles existantes dans le corpus sont établies par la référence fournie par les organisateurs de la campagne, construite a partir
des résultats des participants.

EXTRACTION DE RELATIONS A LARGE ECHELLE

.ooNNoN$wN ow NNNNNNNNNNNNN ow oNQNN.NoNN N Rum Q2 NNNNNENN Nnobsm New o.:5.No>.Doo N u.=D.&Bn~ E80 .«NNoNNNNoN ow «8NNoNNNN8o New NNNNNNN N NNNNNENN Nnobam ow oNQNN.NoNN N u.=D.2Bn~ Q2 .«NNobN& New NNoNNoN6NNN.N

Son «NNou£oN ow «ooNNoN.NNN8o «ow N§NNBNNoo momﬁam ow oNQ:.NoNN N .9332 Q2 .«NNob«m «Bu NNou§NE>w.N Nsom mNNoNN£oN Bu oNQ:.NoNN N News Q2 .«NNob«m «ow ow8mNNNNoN.E«.N Naom «NNou£oN ow oNQ:.NoNN N :N~N~N.. Q2 .ooNNoNwwwN

ow «BaEu§o Nomaﬁm «ow o.:5.N®>.DOo N NNN 5:90 Nomaim ow oNNoNoNN8N 3 ow NNSNNNNNNN «NN mﬁwﬁ ooNNoNw«wN ow «NNNo:.NNNoou New oNBNo>NNoo N .25 E80 .038 BNNNNPN No>NNoNNoN Son NNNENNN oNN.N«N§owNN.N N NQQ.N.N ME MNMKH
NNNENENN ow Numb. N2 N58 Nsom Nomﬁw NoNNNoNw.N.EN New Nﬁmzsmwm I N .m<.H

«N.« ..NNo.NN. NNN «NN N NNN N NNN NN N.NN N« ..NNN.NN .NNNN.N.N NNNNN NNNNNNNNNN
N« ..NoN.NN NNN. NNN NNN N NNN. N NNN N. NNNN .NNNN.N.NN NNNNN + ooN 88N.NNe.No-88N8N.N.No.NNNN:NNN.N
N .NNNN.NN NNN NNN New NNN N NNNNN §ooN NNNNN + uoN NNN8N..No.8NNN>oN.NN8NsN:N.N
oN ..NNN..NN NNN NN NNN N «NN « NN.N N NNNN NNNN NNNNN + ooN NNNNNN.No.8NNN>oN.NNoNNsNNNN.N
NN. NNNN NN« N.N« N.NN « «NN N NN« N ..NNN.N« NNNN mmm NNNNNNNNNNNNN
NN N.NN o o N N. ..NNN.oN ..NNN.NN mmm mwESNNNNom
NN ..NNN.N. NNN NN «NN N NN.N N ..NoN.N« .NNoN.NNN NNNNN + 95 uoENoN.NN|NNooNNo«NNom
N NNNNN NNN N NNN N.«N NNN. N ..NN.N.NN NNNNNN NNNNN NNNNNNNNNNNNN
N.N ..NNN.NN N.oN N« NNN N.N« N ..NN«.N ..N«N.NN mmm NNNNNENNNNNN
o« N.NN N N N N. ..N««.«« NNNNNNN mmm NNNNENINNNNNNNNNNN
NN ..NNN..N.N «NN NNN NNN N «NN wN NNN N« .NNNN.NN. ..NN«.NN NNNNN NNNNNNNNNNNN
NN .NNNN.NN NNN NN.N NNN « NNN «N «NN NN ..NNN.N« .NNNN..NNN wmo NNJNNENENNNNN
««N ..N«N.NN ««NN N.NN N«N. N NN« NN NNN N.N ..NN«.NN ..NNN.N.N wmo NNIBNNNNNNNNNNNNNN
N .N««.«« «N N.N NN.« N NNN N. N.NN §ooN mH<Q NNN8N..No.NNN.N.NN2N
NN N.NN NN o« NN.N N Nwo NN NNNN NNNN mF<Q NNNNNINNINNNNNNNN
o ._NNw.NN N.N« NN wNo N N«N. N «NNN N BNNN + DOA NNN8N.uNo:N._NNNNNooNNNNN
NN NNNQNN NN« NN.N N NNN NN NN.N N NNN NN ..NNN.N ..NN«.NN NNNNN + ooN NNNNNN.No.N._NNNNN8NN2N
N.« NNNo.oN N.N.« NNN :2 N NN.N N. NNN N ..NNN.oN ..N«N.«N NNNNN + ooN 8NNNN.N8N.No.8N.NNNNN8NNN.N
N ..NNN.oN NNN N NNN NNN N«N N ..N8N §ooN NNNNN + 03 NNN8N..No.NNNNNN2N
«N NNN.«.«N NNN. NN NNN N «N« N NN.N N. ..NN«.NN .NN«N.NN NNNNN + ooN NNNNNNINNINNNNNNNNN
mm ..NNN.NN NNN N.N NNN mNw N N«N « ..NNN..N.« ..NNN.NN NNNNN + ooN 8NNNN.N8N.No-8NNNNNN2N
NN N.NN N«N NN.N N8 N oNo N NNNN NNNN mmm NNNNNNNNNNNNNN
«N N.NN N N NN N.wN N.NN ..NN.N.NN NNNNN NNNENNNNNNN
N N.NN N N N N N.NN ..N8N NNNNN NNN8N..No.8NN8NN2N
ow NNNN.NN wNw N NNN NNN N NNN wN .NN«N.NN NN«N.NN mmm NNNNNNNNNINNNNNNNNNNNNNNNNN
NNN N.NN N « NN NNN N.NN N.N« ..NN«.NN NNNNN + NNENNN NNNNNNNN
«N N.NN NNN N« NNN. NN «NN o« ..N«N..o« ..NNN.NN NNNNNN BN«Qo3NwNo
«NN ..NNN.oN 90 N woN N.NN. oN NNN oN. ..NNN.N« ..NNN..NN mmm NNNNNNNENINNNNENEINNNNNNN
NN .NNNN..NN N.NN « NNN. N.NN N NNN N ..NNN.NN ..NNN.NN 95 NoNNNNENQNNNNwNo
NNN NN«N.NN NNN wN.N NNN. N N«N N. NNN N ..NN.N.«N ..NNN.NN NNNNN + ooN NNNNENNNNNNNNNNINNINNNNNNNNNNNNNNSNNNNN
« N.NN N N N « ..N««.«« .NNNN.NN ~NmnNN9No NNNNNNNNNENNNNNN
N.N .NNN«.NN NNN « NNN. «NN N NNN. « ..NNN.N.N N.\NNm.wN wmo NNoNNN.NNNNN..-NN_oNN.NNNN.N8NNNNo.NNNNN
o« .NNN.o.NN NN.N NNN. «No « NNN NN NN« NN ..N««.«N. .NNNN.NN wmo mNNNo.:~mNw.No
NN ..NooN NNN « NNN NNN « «NN N ..NNN.«N ..NNN..oN NNNNN + NNENB NNNNNNNNNNN.NNNNNNNNNNNNINNINNNNNNNNNNNNNN
N NNNNN NNN «NN NNN N«N N.NN N.NN ..NNN.NN wmo «NoQ:.No:.NNwNo
N NNNN «NN NNN NNN « NNN N NNNNN NNNNN wmo NNINNNENENNNN
NN ..NN.«.NN NNN. NN NNN N.N.w N NNN «N ..NNN.«N NNNN.NN mN<.N N.NNaNNoNNNNo
NNN ..NNN.NN NN« N. NNN NNN N.NN N ..NNN.N« NNNN..NN ~NmnNN9No NNINNNNNNNNNNN
N. N.NN NNN NNN NNN N«N NNNN §ooN mF<Q N.N>N8NNN.NNNo
NN .NNNN.NN wmN NNN NNN N 8N N N9. M2 ..NNN.NN ..NN.o.NN NNNNN + ooN NNNENNNNNNNINNINNNSNNNNNN
Nw NNNNNN NN.N oNo N «NN N. «NN. « NN.N N ..NNN.NN ..NNN.oN NNNNN + 03 NNNNN.NNNN.N.N§N.No.NNNNNNNo
NNN .NNoN.NN N8 N N.NN N8 9 «No NN ..N««.«« NNNN.NN wmo «o:.aNNIB§NNBQaNwNo
«om QZ «NNoNN«m .>NNoU maobam QZ .oN6E QZ N88 QZ .N.E< QZ Nam .350 .25 .350 296 ow 09¢. «NNou3oN ow momma.

LUDOVIC JEAN-LOUIS, ROMARIC BESANCON, OLIVIER FERRET, ADRIEN DURAND

3.2 Evaluation de l’apprentissage des patrons

Les patrons servent a conﬁrmer/inﬁrmer la presence d’une relation e11tre deux entités. 11 est donc important de
veriﬁer que les patrons appris aie11t une couverture sufﬁsamment large pour retrouver le plus possible de Variantes
parmi les occurrences de relations. Pour evaluer la qualité des patrons, nous avons séparé les relations connues
en deux ensembles : un ensemble d’apprentissage (2/3 des relations) et un ensemble de test (1/3 des relations).
Nous mesurons la qualite de la couverture des patrons en calculant le pourcentage des occurrences de relations
de l’ensemble de test que l’on retrouve en appliquant les patrons appris a partir des occurrences de relations de
l’ensemble d’apprentissage. Le corpus utilise pour realiser cette evaluation est le corpus TAC-KBP 2010 décrit
ci—dessus. Précisons que l’utilisation de ce corpus pour evaluer l’extraction des relations n’empeche pas son utili-
sation pour l’apprentissage des patrons, les relations etant differentes pour les deux taches.

Nous indiquons dans le tableau 2 le nombre de relations de l’ensemble d’apprentissage et de l’ensemble de test
respectivement dans les colonnes Nb. Appr et Nb. Test. Le nombre de phrases trouvees contenant des occurrences
des relations du corpus d’entrainement, et qui ont donc servi pour l’induction des patrons, est indiqué dans la
colonne Nb. Induc. Le nombre de patrons généres a partir de ces phrases candidates est indiqué dans la colonne
Nb. Patrons de ce meme tableau.

Par exemple, pour le type de relation org:altemate_names, a partir des 20 013 relations de l’ensemble d’appren—
tissage, seules 214 phrases candidates contenant l’expression d’une de ces relations sont selectionnées. Ces 214
phrases servent a generer 6 007 patrons, qui ont une couverture de 66,10% (i. e. on retrouve 66,10% des phrases
contenant des occurrences des 10 006 relations de test). L’ écart consequent entre les 20 013 relations et les 214
phrases trouvées est dﬁ a deux facteurs :

— une contrainte reductrice imposée lors de la selection des phrases candidates. Seules les phrases dont tous les
mots des entités nommees sont correctement identiﬁes sont en effet conservees. Or, les entités peuvent etre
partiellement (ou mal) reconnues lors des traitements linguistiques;

— la nature des documents du corpus : 72% des documents sont des articles de presse édités e11tre janvier 2008 et
aoﬁt 2009, ce qui explique le peu de documents, voir aucun, concemant certaines personnes ou organisations
pourtant présentes dans la KB.

Les résultats de la couverture des patrons sont présentes dans le tableau 2 pour chaque type de relations dans la co-
lonne Couv. Patrons. A titre indicatif, le temps d’induction des patrons pour le type de relations per:country_of_birth
(11 192 phrases exemples a comparer) passe de 690mn et 5s pour la version sans ﬁltrage a 0mn et 30s pour la
version avec ﬁltrageé, ce qui illustre l’intéret de celui—ci en termes de temps de calcul.

3.3 Evaluation de l’extraction des relations

L’ extraction des relations comprenant plusieurs étapes, chacune d’entre elles peut inﬂuer sur le résultat global.
Nous proposons donc de faire une evaluation séparée de la recherche des phrases candidates et de l’extraction des
relations proprement dite.

3.3.1 Recherche des phrases candidates

Une condition nécessaire pour des extraire relations pertinentes est de s’assurer que le moteur de recherche ren-
voie sufﬁsamment de documents pertinents pour nous permettre de retrouver des entités cibles. Nous avons donc
mesure la couverture en documents de notre recherche de phrases candidates, a savoir le pourcentage de docu-
ments renvoyes par l’index que l’on retrouve effectivement dans la reference. Nous avons testé de ce point de vue
différentes strategies en faisant varier des parametres comme le nombre de resultats retoumés et l’utilisation ou
non de l’expansion pour la requete. Les resultats de cette evaluation nous ont ainsi conduit a utiliser les entités
sources et leurs formes étendues pour interrogation de l’index et prendre en compte les 1000 premiers resultats
retoumés : ces parametres permettent de retrouver 84,24% des documents de reference. Le résultat détaillé par
type de relations est donné par la colonne Couv. Doc du tableau 2.

A partir des documents ainsi selectionnes, les phrases candidates a l’extraction d’une relation pour un type donné

6La version avec ﬁltrage étantpara1lélisée,le temps donné est une somme des temps comptabilisés au niveau de chaque processeur.

EXTRACTION DE RELATIONS A LARGE ECHELLE

sont extraites en retenant les phrases contenant a la fois l’entité source et le type de l’entité cible. La qualité et la
quantité des phrases candidates sont largement inﬂuencées par la qualité de la reconnaissance des entités nommées.
Comme nous ne disposons pas d’annotation de reference pour les entités nommées du corpus, il n’est pas possible
de mesurer les pertes causées par la mauvaise reconnaissance des entites. En revanche, nous avons evalué la
proportion de documents de reference dans lesquels nous retrouvons des phrases candidates. Cette donnée permet
de ﬁxer une borne maxirnale pour le pourcentage de relations qu’il serait possible d’extraire si les etapes a la
suite se déroulaient idéalement. Nous obtenons au total une couverture de 37,55% des phrases appartenant aux
documents de reference. Le detail par type de relations est présente a la colonne Couv. Rel du tableau 2.

3.3.2 Extraction de relations

Pour evaluer les relations extraites, nous avons reutilise les mesures et les outils d’éValuation fournis par la carn-
pagne TAC—KBP7 sans nous limiter aux seuls documents presents dans la reference pour accepter une relation
correcte8. Le tableau 3 fournit les resultats de cette evaluation en agglomérant tous les types de relations et en
caracterisant l’impact du ﬁltrage a posteriori des entites cibles sur les relations extraites en termes de rappel (R. ),
precision (P. ) et f1—mesure ( F I . ). Pour mémoire, ce ﬁltrage consiste a s’assurer que l’entité cible Valide des ex-
pressions régulieres et/ou une liste fermee de Valeurs. Nous indiquons dans la colonne Type de cible du tableau 2
le mécanisme utilise pour chaque type de relations.

Les resultats du tableau 3 montrent d’une part, que ce ﬁltrage améliore les performances (en moyenne +2,74% de
fl -mesure) et d’autre part, Valident l’hypothese que les patrons induits a partir de l’APSS sont aussi pertinents que
ceux induits en considérant tous les exemples de relations deux a deux (dans ce cas, il y a meme une amelioration
de +l,72% de la f1—mesure en moyenne).

Avant ﬁltrage Apres ﬁltrage
R. (%) P. (%) F1. (%) R. (%) P. (%) F1. (%)
Tous les couples d’entités 16,28 11,20 13,26 18,07 13,66 15,56
APSS 16,90 12,76 14,54 18,67 16,87 17,72

TAB. 3 — Evaluation de l’impact du ﬁltrage des reponses

Le tableau 4 presente les resultats de différents systemes sur deux corpus tres sirnilaires, les corpus KBP 2009 et
KBP 2010, ce demier ajoutant au premier des documents Web et des transcriptions, a priori plus difﬁciles. Bien
que ces chiffres ne portent que sur les relations effectivement présentes dans le corpus, ils integrent la contrainte
pour les systemes ayant participé a la tache Slot Filling de devoir decider si la relation existe ou non dans le
corpus, ce que notre systeme, developpé en dehors du contexte de ces carnpagnes, ne fait pas. Dans ce tableau,
les colonnes 2009 et 2010 designent les scores des trois systemes les plus et les moins performants de KBP
2009 et 2010. Ji et al. (2010) ont montré que sur 492 relations de reference, 60,4% se trouvaient dans la meme
phrase tandis que les 39,6% restantes dépassaient l’espace phrastique dans leur expression et nécessitaient pour
leur extraction la resolution de coreférences ou l’application de mécanismes d’inference impliquant par exemple
la composition de plusieurs relations ou l’utilisation de connaissances a priori sur les types de relations. De ce
fait, nous avons distingue dans la colonne 2010 (a) du tableau 4 les scores des systemes qui nous sont les plus
directement comparables, c’est—a—dire ceux se lirnitant a l’extraction de relations au niveau phrastique.

On peut noter que le meilleur systeme de KBP 2010 (Chada et al., 2010) se detache tres nettement : +36,63%
par rapport au deuxieme et +4,68% par rapport a un annotateur humain. Cette predominance s’appuie a la fois
sur l’utilisation d’un corpus armote manuellement (different du corpus KBP) de 3 millions de documents et la
presence de plusieurs mécanismes d’extraction de relations au niveau inter—phrastique : coreference pronominale,
métonymie entre entites, resolution de dépendances semantiques entre les mots et les entités, etc. L’ utilisation du
corpus supplementaire semble etre l’élément determinant par rapport aux systemes Venant a la suite immediate,
ceux-ci se distinguant de systemes plus medians par la prise en compte des relations inter—phrastiques. Les plus
mauvais resultats, plus faibles en 2010, sont dﬁs pour une bonne part a des systemes en cours de développement.

7http://nlp.cs.qc.cuny.edu/kbp/2010/scoring.html
8La référence du point dc vue des documents n’étant constituée qu’a partir des résultats des participants a l’évaluation TAC-KBP, elle n’est
en effet pas compléte.

LUDOVIC JEAN-LOUIS, ROMARIC BESANCON, OLIVIER FERRET, ADRIEN DURAND

Concemant notre systeme, le tableau 4 permet de situer nos résultats dans la moyenne des resultats obtenus par
les participants de l’évaluation KBP 2010 et parrni les trois premiers systemes pour les approches faisant de
l’extraction de relations au niveau de la phrase. Dans ce demier cas, l’approche la plus performante (29,15% de
f1—mesure) (Byme & Dunnion, 2010) utilise des regles construites manuellement permettant d’atteindre un score
de precision (66,55%) equivalent au meilleur score de la carnpagne (66,80%) et un score de rappel (l8,67%) se
situant dans la moyenne de la carnpagne (l5,33%). Ce fort désequilibre entre precision et rappel est d’ailleurs
assez syrnptomatique des approches manuelles.

Systemes TAC KBP 2009 2010 2010 (a)
Nb. sournissions (N) / participants N=16/ 8 N=3l / 15 N=l8
Annotateur hurnain 58,99% 61,10% 61,10%
1” score 34,35% 65,78% 29,15%
29"” score 25,05% 29,15% 14,22%
39mg score 18% 28,29% 14,13%
(N—2)eme score 5,90% 0,55% 0,55%
(N—1)eme score 2,60% 0,19% 0,19%
Name score 1,75% 0,08% 0,08%
| Notre systeme | — | 17,72%  17,72% |
Moyenne 13,43% 17,49% 9,71%
Mediane 13,93% 14,13% 12,27%

TAB. 4 — Résultats sur les donnees TAC—KBP (f1—mesure)

4 Travaux associés

L’extraction de relations a large échelle, au sens ou nous l’avons déﬁnie a la section 2, est une problématique
encore récente. Néanmoins, au travers notarnment des evaluations TAC—KBP, elle a été 1’ obj et d’un certain nombre
de travaux proposant differentes approches. Concemant spéciﬁquement l’extraction des relations, les travaux se
répartissent entre l’utilisation de l’apprentissage statistique (Agirre et al., 2009; Li et al., 2009b; Chen et al.,
2010b), l’induction de patrons lexicaux (Li et al., 2009a; de Pablo—Sanchez et al., 2009; McNarnee et al., 2009;
Chen et al., 2010b) et enﬁn, l’adaptation de systemes existants pour la detection de relations (Schone et al., 2009;
Bikel et al., 2009). On note pour KBP 2010 l’introduction d’approches a base de regles, par exemple (Byme &
Dunnion, 2010), et d’approches reposant sur le principe de << Distant supervision » a partir de classiﬁeurs, dont
celle de (Surdeanu et al., 2010). Notre approche releve de l’induction de patrons lexicaux et fait l’hypothese,
comme (Mintz et al., 2009), que la seule presence d’un couple d’entités dans une phrase est sufﬁsante pour
marquer la presence effective d’une relation entre ces entités. Ce n’est cependant pas toujours le cas et nous
pensons ainsi qu’il est important de ﬁltrer en amont les exemples utilises pour l’induction des patrons, a l’instar
de ce que propose (Riedel et al., 2010).

Come notre systeme, ceux elaborés pour KBP 2009 n’exploitent pas les liens de dépendance entre les types
de relations, a l’irnage du lien entre la date de naissance et l’age par exemple. Dans (Chen et al., 2010a), les
auteurs montrent que les résultats obtenus dans (Li et al., 2009a) (31,96% de f1—mesure) peuvent etre améliorés
(ils obtiennent 34,81% de f1—mesure) par l’intégration des dépendances entre les relations en utilisant des regles
d’inference fondées sur une extension de la logique du premier ordre. Plus généralement, Chada et al. (2010) ont
montré dans le cadre de KBP 2010 une augmentation tres signiﬁcative des performances en intégrant des méca-
nismes permettant d’extraire des relations au—dela de la phrase. Sur un autre plan, Li et al. (2009a) se distinguent
dans KBP 2009 en utilisant deux etapes d’ extraction de relations : la premiere vise a retrouver dans les documents
du corpus des entités cibles potentielles en utilisant des patrons de relations ; la seconde applique le meme proces-
sus a une version recente de Wikipédia pour trouver des entites cibles potentielles supplémentaires qui n’auraient
pas eté identiﬁees lors de la premiere étape. Les entités cibles ainsi acquises ne sont ﬁnalement conservées que
si elles sont retrouvées dans un document du corpus. Cette recuperation d’entités ameliore les performances de
fagon signiﬁcative (+9% de f1—mesure par rapport a (Bikel et al., 2009)) mais ajoute l’utilisation d’un corpus
exteme que l’on peut considérer comme trop lie a la KB. Les resultats sur KBP 2010 ont d’ailleurs montré que

EXTRACTION DE RELATIONS A LARGE ECHELLE

les performances globales pouvaient etre ameliorées sans cette ressource supplémentaire et que son impact sur les
resultats est plus limité que pour KBP 2009 (une baisse des résultats a meme ete observée).

5 Conclusion et perspectives

Dans cet article, nous avons presenté un systeme d’extraction d’information a large échelle permettant d’extraire
des relations de type attributive entre entites nommées. Le qualiﬁcatif << a large echelle » recouvre a la fois la
prise en compte d’un grand nombre de types de relations et la recherche de ces relations dans un large corpus.
Ce systeme se fonde sur une approche faiblement supervisée dans laquelle les exemples se lirnitent a des couples
d’ entités en relation. L’ extraction des relations s’effectue par l’application de patrons lexico—syntaxiques caracte—
ristiques des types de relations consideres et appris a partir de phrases issues de la projection des couples d’ entités
exemples dans un corpus. Nous avons évalué les résultats de cette approche en utilisant le cadre d’éValuation offert
par la tache Slot Filling de l’eValuation KBP en nous concentrant sur la problematique de l’extraction des relations
proprement dite, sans nous attacher a la detection de l’absence d’une relation dans un corpus. Les resultats obtenus
dans ce contexte se situent dans la moyenne des resultats obtenus par les participants de l’edition 2010, ce que
nous pouvons considerer comme un point de depart interessant dans la mesure ou notre systeme repose sur une
approche Volontairement generique et n’exploite que tres faiblement les spéciﬁcités des types de relations traités.
Nous avons aussi pu montrer que des techniques permettant de prendre en compte certains aspects d’un passage a
une << large echelle », comme le ﬁltrage des couples de phrases exemples a generaliser par l’utilisation de l’APSS,
ne dégradent pas les performances et peuvent meme contribuer ales ameliorer.

Nous travaillons par ailleurs sur l’amélioration de notre systeme en conservant l’idee de garder une certaine ge-
nericité par rapport au type des relations considerees. Pour ce faire, nous nous focalisons particulierement sur
l’apprentissage des patrons d’ extraction. Un premier pas dans cette direction Vise a disposer a la fois d’un nombre
plus important d’exemples mais également d’exemples de meilleure qualité. Ces deux points sont lies dans la
mesure ou l’obtention d’un ensemble plus large d’exemples passe par le relachement des contraintes touchant la
selection des phrases exemples. Or, si l’on peut espérer qu’un tel relachement permettra l’obtention de nouveaux
bons exemples, il sera aussi source de nouveaux mauvais exemples. Nous souhaitons donc coupler un tel relache—
ment avec l’utilisation d’un module de ﬁltrage de relations qui, a l’instar de (Banko & Etzioni, 2008), est capable
de determiner si une phrase contient une relation entre deux entités sans a priori sur la nature de cette relation.

Références

AGICHTEIN E. & GRAVANO L. (2000). Snowball : Extracting relations from large plain—text collections. In 5”‘
ACM International Conference on Digital Libraries, p. 85-94, San Antonio, Texas, USA.

AGIRRE E., CHANG A., J URAFSKY D., MANNING C., SPITKOVSKY V. & YEH E. (2009). Stanford—UBC at
TAC—KBP. In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.

BANKO M. & ETZIONI O. (2008). The tradeoffs between open and traditional relation extraction. In ACL—08 :
HLT, p. 28-36, Columbus, Ohio.

BAYARDO R., MA Y. & SRIKANT R. (2007). Scaling up all pairs similarity search. In 16”‘ International
Conference on World Wide Web (WWW’07), p. 131-140, Banff, Alberta, Canada.

BIKEL D., CASTELLI V., RADU F. & JUNG HAN D. (2009). Entity Linking and Slot Filling through Statistical
Processing and Inference Rules. In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.
B1zER C., LEHMANN J ., KOBILAROV G., AUER S., BECKER C., CYGANIAK R. & HELLMANN S. (2009).
DBpedia — A crystallization point for the Web of Data. Journal of Web Semantics, 7, 154-165.

BYRNE L. & DUNNION J . (2010). UCD IIRG at TAC 2010 KBP Slot Filling Task. In Third Text Analysis
Conference (TAC 2010), Gaithersburg, Maryland, USA.

CHADA D., ARANHA C. & MONTE C. (2010). An Analysis of The Cortex Method at TAC 2010 KBP Slot-
Filling. In Third Text Analysis Conference (TAC 2010), Gaithersburg, Maryland, USA.

CHEN Z., TAMANG S., LEE A., LI X., PASSANTINO M. & JI H. (2010a). Top—down and Bottom—up : A
Combined Approach to Slot Filling. In 6th Asia Information Retrieval Symposium on Information Retrieval
Technology, Gaithersburg, Maryland, USA : Springer—Verlag.

LUDOVIC JEAN—LOUIs, ROMARIC BEsANg0N, OLIVIER FERRET, ADRIEN DURAND

CHEN Z., TAMANG S., LEE A., LI X., SN0vER M., PASSANTINO M., LIN W.—P. & JI H. (2010b). CUNY—
BLENDER TAC—KBP2010 Slot Filling System Description. In Text Analysis Conference (TAC 2010), Gaithers-
burg, Maryland, USA.

CLAVEAU V. & SEBILLOT P. (2004). From efﬁciency to portability : acquisition of semantic relations by semi-
supervised machine learning. In 20”‘ International Conference on Computational Linguistics (COLING 2004 ),
p. 261-267, Geneva, Switzerland.

DE PABLO—SANcHEz C., PEREA J ., SEGURA—BEDMAR I. & MARTINEZ P. (2009). The UC3M team at the
Knowledge Base Population task. In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland,
USA.

EMBAREK M. & FERRET O. (2008). Learning patterns for building resources about semantic relations in the
medical domain. In 6”‘ Conference on language Resources and Evaluation (LREC’08), Marrakech, Morocco.

GIONIS A., INDYK P. & MOTWANI R. (1999). Similarity search in high dimensions via hashing. In 25”‘
International Conference on Very Large Data Bases (VLDB ’99), p. 518-529, Edinburgh, Scotland, UK.
HEARST M. (1992). Automatic acquisition of hyponyms from large text corpora. In 14”‘ International Confe-
rence on Computational linguistics (COLING’92), p. 539-545, Nantes, France.

J I H., GRISHMAN R. & TRANG DANG H. (2010). Overview of the TAC 2010 Knowledge Base Population
Track. In Third Text Analysis Conference (TAC 2010), Gaithersburg, Maryland, USA.

LI F., ZHENG Z., BU F., TANG Y., ZHU X. & HUANG M. (2009a). THU QUANTA at TAC 2009 KBP and
RTE Track. In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.

LI S., GAO S., ZHANG Z., LI X., GUAN J ., XU W. & GUO J . (2009b). PRIS at TAC 2009 : Experiments in
KBP Track. In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.

MCNAMEE P., DREDZE M., GERBER A., GARERA N., FININ T., MAYFIELD J ., PIATKO C., RAO D., YA-
ROWSKY D. & DREYER M. (2009). HLTCOE Approaches to Knowledge Base Population at TAC 2009. In
Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.

MINTZ M., BILLS S., SNOW R. & J URAFSKY D. (2009). Distant supervision for relation extraction without
labeled data. In ACL—IJCNLP’09, p. 1003-1011, Suntec, Singapore.

PANTEL P., RAVICHANDRAN D. & HOVY E. (2004). Towards terascale knowledge acquisition. In 20th Inter-
national Conference on Computational Linguistics (COLING’04), p. 771-777, Geneva, Switzerland.

RAVICHANDRAN D. (2005). Terascale knowledge acquisition. PhD thesis, Faculty of the Graduate School
University of Southern California, Los Angeles, CA, USA.

RIEDEL S., YAO L. & MCCALLUM A. (2010). Modeling relations and their mentions without labeled text. In
J . BALCAZAR, F. BONCHI, A. GIONIS & M. SEBAG, Eds., Machine Learning and Knowledge Discovery in
Databases, volume 6323 of Lecture Notes in Computer Science, p. 148-163. Springer Berlin / Heidelberg.

RUIZ-CASADO M., ALFONSECA E. & CASTELLS P. (2007). Automatising the learning of lexical patterns : An
application to the enrichment of wordnet by extracting semantic relationships from wikipedia. Data Knowledge
Engineering, 61, 484-499.

SCHLAEFER N., GIESELMANN P., SCHAAF T. & WAIBEL A. (2006). A pattern learning approach to question
answering within the ephyra framework. In P. SOJKA, I. KOPECEK & K. PALA, Eds., Text, Speech and Dialogue,
volume 4188 of lecture Notes in Computer Science, p. 687-694. Springer Berlin / Heidelberg.

SCHONE P., G0LDscHEN A., LANGLEY C., LEWIS S., ONYSHKEVYCH B., CUTTS R., DAWSON B., MAC-
BRIDE J ., MATRANGOLA G., McD0N0UGH C., PFEIFER C. & URSIAK M. (2009). TCAR at TAC—KBP 2009.
In Second Text Analysis Conference (TAC 2009), Gaithersburg, Maryland, USA.

SHINYAMA Y. & SEKINE S. (2006). Preemptive information extraction using unrestricted relation discovery. In
HLT—NAACL 2006, p. 304-311, New York City, USA.

SURDEANU M., MCCLOSKY D., TIBSHIRANI J ., BAUER J ., CHANG A., SPITKOVSKY V. & MANNING C.
(2010). A Simple Distant Supervision Approach for the TAC—KBP Slot Filling Task. In Text Analysis Conference
(TAC 2010), Gaithersburg, Maryland, USA.

TAC—KBP (2010). Preliminary task description for knowledge—base population at TAC 2010.

ZHOU G., SU J ., ZHANG J . & ZHANG M. (2005). Exploring various knowledge in relation extraction. In 43”‘
Annual Meeting of the Association for Computational Linguistics (ACL 2005 ), p. 427-434, Ann Arbor, USA.
ZHOU G., ZHANG M., J I D. & ZHU Q. (2007). Tree kemel—based relation extraction with context-sensitive
structured parse tree information. In EMNLP — CoNLL’07, p. 728-736, Prague, Czech Republic.

