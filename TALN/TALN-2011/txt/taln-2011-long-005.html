<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Utilisation d&#8217;un score de qualit&#233; de traduction pour le r&#233;sum&#233; multi-document cross-lingue</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Utilisation d&#8217;un score de qualit&#233; de traduction
pour le r&#233;sum&#233; multi-document cross-lingue
</p>
<p>St&#233;phane Huet1 Florian Boudin1 Juan-Manuel Torres-Moreno1,2,3
(1) LIA, Universit&#233; d&#8217;Avignon, France
</p>
<p>(2) &#201;cole Polytechnique de Montr&#233;al, Canada
(3) GIL-IINGEN, Universidad Nacional Aut&#243;noma de M&#233;xico, Mexique
</p>
<p>{stephane.huet,florian.boudin,juan-manuel.torres}@univ-avignon.fr
</p>
<p>R&#233;sum&#233;. Le r&#233;sum&#233; automatique cross-lingue consiste &#224; g&#233;n&#233;rer un r&#233;sum&#233; r&#233;dig&#233; dans une langue dif-
f&#233;rente de celle utilis&#233;e dans les documents sources. Dans cet article, nous proposons une approche de r&#233;sum&#233;
automatique multi-document, bas&#233;e sur une repr&#233;sentation par graphe, qui prend en compte des scores de qualit&#233;
de traduction lors du processus de s&#233;lection des phrases. Nous &#233;valuons notre m&#233;thode sur un sous-ensemble ma-
nuellement traduit des donn&#233;es utilis&#233;es lors de la campagne d&#8217;&#233;valuation internationale DUC 2004. Les r&#233;sultats
exp&#233;rimentaux indiquent que notre approche permet d&#8217;am&#233;liorer la lisibilit&#233; des r&#233;sum&#233;s g&#233;n&#233;r&#233;s, sans pour autant
d&#233;grader leur informativit&#233;.
</p>
<p>Abstract. Cross-language summarization is the task of generating a summary in a language different from
the language of the source documents. In this paper, we propose a graph-based approach to multi-document
summarization that integrates machine translation quality scores in the sentence selection process. We evaluate
our method on a manually translated subset of the DUC 2004 evaluation campaign. Results indicate that our
approach improves the readability of the generated summaries without degrading their informativity.
</p>
<p>Mots-cl&#233;s : R&#233;sum&#233; cross-lingue, qualit&#233; de traduction, graphe.
</p>
<p>Keywords: Cross-lingual summary, translation quality, graph.
</p>
<p>1 Introduction
</p>
<p>La multiplication des documents dans de nombreuses langues, en particulier sur le Web, a rendu n&#233;cessaire la mise
au point de m&#233;thodes de recherche et d&#8217;extraction d&#8217;information cross-lingue. Le r&#233;sum&#233; automatique cross-lingue
vise &#224; donner &#224; l&#8217;utilisateur un acc&#232;s rapide &#224; des contenus exprim&#233;s dans une ou plusieurs langues qu&#8217;il ma&#238;trise
mal ou ne conna&#238;t pas. Plus pr&#233;cis&#233;ment, cette t&#226;che consiste &#224; g&#233;n&#233;rer un r&#233;sum&#233; dans une langue cible diff&#233;-
rente de celle utilis&#233;e dans les documents sources. Dans cette &#233;tude, nous nous int&#233;ressons au r&#233;sum&#233; automatique
multi-document de l&#8217;anglais vers le fran&#231;ais, la motivation premi&#232;re &#233;tant de permettre aux utilisateurs franco-
phones d&#8217;acc&#233;der &#224; la masse toujours croissante d&#8217;actualit&#233;s disponibles &#224; travers des sources majoritairement
anglophones.
</p>
<p>Plusieurs &#233;tudes r&#233;centes se sont int&#233;ress&#233;es aux mod&#232;les de graphes pour repr&#233;senter l&#8217;information dans des
applications de Traitement Automatique des Langues Naturelles (TALN) (Banea et al., 2010). Dans ces mod&#232;les,
les entit&#233;s &#8212; qui peuvent &#234;tre par exemple les mots, les phrases ou m&#234;me les documents &#8212; sont repr&#233;sent&#233;es
sous la forme de n&#339;uds et les relations entre elles par des ar&#234;tes. Ce type d&#8217;approche a d&#233;j&#224; &#233;t&#233; utilis&#233; dans des
applications TALN diverses tel que l&#8217;&#233;tiquetage en parties du discours, l&#8217;extraction d&#8217;information, l&#8217;analyse de
sentiments ou le r&#233;sum&#233; automatique auquel nous nous int&#233;ressons ici.
</p>
<p>Une m&#233;thodologie simple pour aborder le r&#233;sum&#233; automatique cross-lingue serait d&#8217;appliquer un syst&#232;me de
traduction automatique (TA) directement sur les sorties d&#8217;un syst&#232;me de r&#233;sum&#233; automatique classique. Toutefois,
cette approche n&#8217;est pas sans inconv&#233;nients puisqu&#8217;elle devient d&#233;pendante de la qualit&#233; du syst&#232;me de TA. Dans
cet article, nous proposons de prendre en compte la qualit&#233; de traduction des phrases en fran&#231;ais lors de la s&#233;lection
des phrases retenues pour assembler le r&#233;sum&#233;, l&#8217;id&#233;e &#233;tant de minimiser l&#8217;impact des erreurs commises par le
syst&#232;me de TA. Les phrases ainsi s&#233;lectionn&#233;es pour construire le r&#233;sum&#233; seront celles jug&#233;es &#224; la fois informatives</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ST&#201;PHANE HUET, FLORIAN BOUDIN ET JUAN-MANUEL TORRES-MORENO
</p>
<p>par le syst&#232;me de r&#233;sum&#233; automatique et faciles &#224; traduire par le syst&#232;me de TA. Pour ce faire, nous recourons &#224;
une m&#233;thode d&#8217;apprentissage supervis&#233; pour pr&#233;dire les scores de qualit&#233; de la traduction et int&#233;grons ces scores
durant la construction du graphe utilis&#233; pour s&#233;lectionner les phrases informatives.
</p>
<p>Dans la suite de cet article, nous commen&#231;ons par pr&#233;senter les travaux connexes aux n&#244;tres. La section 3 est
consacr&#233;e &#224; la description de la m&#233;thode que nous proposons. Nous d&#233;crivons ensuite en section 4 nos r&#233;sultats
exp&#233;rimentaux avant de conclure et de montrer quelques perspectives.
</p>
<p>2 Travaux connexes
</p>
<p>Dans cette section, nous pr&#233;sentons dans un premier temps les travaux existants sur la pr&#233;diction de la qualit&#233; de
traduction automatique. Nous d&#233;crivons ensuite les approches de r&#233;sum&#233; automatique bas&#233;es sur les mod&#232;les de
graphes ainsi que les &#233;tudes sur le r&#233;sum&#233; automatique cross-lingue.
</p>
<p>2.1 Pr&#233;diction de la qualit&#233; de traduction automatique
</p>
<p>La traduction automatique est un composant naturel d&#8217;un syst&#232;me automatique de r&#233;sum&#233; cross-lingue de docu-
ments. Malheureusement, bien que des progr&#232;s importants aient &#233;t&#233; r&#233;alis&#233;s depuis une d&#233;cennie, les syst&#232;mes de
TA restent sujets &#224; des erreurs qui peuvent d&#233;grader fortement la qualit&#233; des r&#233;sum&#233;s produits, en introduisant en
particulier des informations erron&#233;es ou en rendant les phrases g&#233;n&#233;r&#233;es difficiles &#224; lire. Afin de r&#233;duire ces effets,
il est int&#233;ressant de prendre en compte un score jugeant de la qualit&#233; de la traduction pour filtrer les traductions
incorrectes lors du r&#233;sum&#233;.
</p>
<p>La pr&#233;diction de la qualit&#233; de la traduction a tout d&#8217;abord &#233;t&#233; vue comme un probl&#232;me de classification binaire
pour distinguer les bonnes traductions des mauvaises (Blatz et al., 2003). Des &#233;tudes plus r&#233;centes ont estim&#233; une
valeur continue de score soit au niveau du mot (Raybaud et al., 2009), soit au niveau de la phrase (Raybaud et al.,
2009; Specia et al., 2009). Dans cet article, nous employons des scores calcul&#233;s au niveau de la phrase, ceux-ci
&#233;tant plus faciles &#224; int&#233;grer dans le processus de s&#233;lection de phrases pour le r&#233;sum&#233;.
</p>
<p>Plusieurs classificateurs ont &#233;t&#233; construits pour estimer la qualit&#233; de traduction. Ces mod&#232;les statistiques ont
&#233;t&#233; utilis&#233;s sur des traductions &#233;tiquet&#233;es manuellement comme correctes ou non (Quirk, 2004; Specia et al.,
2009), ou &#233;tiquet&#233;es par des m&#233;triques automatiques comme le taux d&#8217;erreur de mots (Blatz et al., 2003), le score
NIST (Blatz et al., 2003; Specia et al., 2009) ou BLEU (Raybaud et al., 2009). Parmi les diff&#233;rentes caract&#233;ris-
tiques utilis&#233;es pour le calcul des valeurs de qualit&#233;, on retrouve des traits linguistiques &#8212; d&#233;pendant ou non de
ressources telles que des analyseurs syntaxiques ou Wordnet &#8212;, des mesures de similarit&#233; entre la phrase source
et la phrase cible, et des caract&#233;ristiques internes au syst&#232;me de traduction utilis&#233;es &#8212; comme le nombre de tra-
ductions propos&#233;es par mots sources ou les scores de segments (phrases) des meilleures hypoth&#232;ses de traduction.
</p>
<p>2.2 R&#233;sum&#233; automatique fond&#233; sur les mod&#232;les de graphes
</p>
<p>Ces derni&#232;res ann&#233;es, de nombreuses &#233;valuations ont &#233;t&#233; conduites sur la t&#226;che du r&#233;sum&#233; automatique multi-
document, en particulier dans le cadre des campagnes internationales Document Understanding Conference 1
</p>
<p>(DUC) et Text Analysis Conference 2 (TAC) organis&#233;es par le National Institute of Standards and Technology 3
</p>
<p>(NIST). La quasi-totalit&#233; des approches propos&#233;es recourent &#224; des m&#233;thodes d&#8217;extraction o&#249; il s&#8217;agit d&#8217;identifier
les unit&#233;s textuelles &#8212; le plus souvent des phrases &#8212; les plus importantes des documents. Les phrases contenant
les concepts les plus importants sont s&#233;lectionn&#233;es puis assembl&#233;es selon leur degr&#233; de pertinence afin de g&#233;n&#233;rer
les r&#233;sum&#233;s. Ce type d&#8217;approche donne de bons r&#233;sultats et permet de contourner les probl&#233;matiques difficiles de
compr&#233;hension s&#233;mantique du texte ou de g&#233;n&#233;ration de texte en langue naturelle.
</p>
<p>Les travaux men&#233;s jusqu&#8217;&#224; pr&#233;sent sur la t&#226;che du r&#233;sum&#233; automatique multi-document sont bas&#233;s, entre autres,
sur l&#8217;utilisation du centro&#239;de pour la s&#233;lection de phrases (Radev et al., 2004), sur l&#8217;apprentissage supervis&#233; des
crit&#232;res d&#8217;informativit&#233; (Wong et al., 2008) ou sur la fusion d&#8217;information (Barzilay et al., 1999). Dans cet article,
</p>
<p>1. http://duc.nist.gov
2. http://www.nist.gov/tac/
3. http://www.nist.gov</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE BAS&#201;E SUR LES GRAPHES POUR LE R&#201;SUM&#201; MULTI-DOCUMENT CROSS-LINGUE
</p>
<p>nous employons une approche bas&#233;e sur les mod&#232;les de graphes introduite dans (Mihalcea, 2004; Erkan &amp; Radev,
2004). Les algorithmes de classement bas&#233;s sur les graphes tels que PAGERANK (Page et al., 1998) ont &#233;t&#233; utilis&#233;s
avec succ&#232;s dans les r&#233;seaux sociaux, l&#8217;analyse du nombre de citations ou l&#8217;&#233;tude de la structure du Web. Appliqu&#233;
au r&#233;sum&#233; automatique, ce type d&#8217;approche sugg&#232;re de repr&#233;senter les documents par un graphe d&#8217;unit&#233;s textuelles
(phrases) inter-connect&#233;es par des relations issues de calculs de similarit&#233;. Les phrases sont ensuite s&#233;lectionn&#233;es
selon des crit&#232;res de centralit&#233; ou de prestige dans le graphe puis assembl&#233;es pour produire des extraits. Cette
approche a deux principaux avantages. Premi&#232;rement, contrairement &#224; la plupart des autres m&#233;thodes, elle ne
n&#233;cessite pas de donn&#233;es d&#8217;apprentissage. Deuxi&#232;mement, du fait qu&#8217;elle se base sur des traitements linguistiques
minimaux (segmentation en phrases et similarit&#233; inter-phrases), cette approche est facilement adaptable &#224; d&#8217;autres
langues (Mihalcea &amp; Tarau, 2005).
</p>
<p>2.3 R&#233;sum&#233; automatique cross-lingue
</p>
<p>Quelques &#233;tudes se sont r&#233;cemment int&#233;ress&#233;es &#224; la probl&#233;matique du r&#233;sum&#233; automatique cross-lingue. Deux
solutions simples &#224; ce probl&#232;me consistent soit &#224; traduire les documents avant la phase d&#8217;extraction, soit &#224; traduire
les r&#233;sum&#233;s g&#233;n&#233;r&#233;s. Cette seconde approche est g&#233;n&#233;ralement pr&#233;f&#233;r&#233;e &#224; la premi&#232;re car la traduction au pr&#233;alable
des documents rend le processus de s&#233;lection de phrases plus risqu&#233; de part les erreurs potentiellement introduites
par le syst&#232;me de TA. Ora&#774;san &amp; Chiorean (2008) ont ainsi propos&#233; d&#8217;utiliser la m&#233;thode Maximal Marginal
Relevance (MMR) (Carbonell &amp; Goldstein, 1998) pour produire des r&#233;sum&#233;s d&#8217;actualit&#233;s exprim&#233;s en roumain et
ensuite de les traduire automatiquement en anglais.
</p>
<p>Plus r&#233;cemment, Wan et al. (2010) se sont int&#233;ress&#233;s au r&#233;sum&#233; automatique mono-document, depuis l&#8217;anglais
vers le chinois, en employant des m&#233;thodes supervis&#233;es pour estimer la qualit&#233; de traduction automatique. Leur
&#233;tude a montr&#233; que la prise en compte de scores de qualit&#233; de traduction permet d&#8217;am&#233;liorer &#224; la fois le contenu
et la lisibilit&#233; des r&#233;sum&#233;s g&#233;n&#233;r&#233;s. Dans notre article, nous utilisons une approche similaire en nous int&#233;ressant
cette fois au r&#233;sum&#233; automatique multi-document. Contrairement aux travaux de Wan et al., notre approche utilise
un algorithme non supervis&#233; et ind&#233;pendant de la langue pour s&#233;lectionner des phrases (Mihalcea &amp; Tarau, 2005).
De plus, nous n&#8217;utilisons pas de corpus annot&#233;s manuellement selon leur qualit&#233; de traduction mais un indicateur
calcul&#233; automatiquement &#224; partir de traductions de r&#233;f&#233;rences produites par des humains, ce type de corpus &#233;tant
long et parfois d&#233;licat &#224; construire.
</p>
<p>3 Notre m&#233;thode pour le r&#233;sum&#233; cross-lingue
</p>
<p>Notre approche pour r&#233;sumer un ensemble de documents depuis l&#8217;anglais vers le fran&#231;ais se fait en trois &#233;tapes.
Chaque phrase est tout d&#8217;abord traduite automatiquement et la qualit&#233; de la traduction est estim&#233;e (section 3.1).
Chaque phrase se trouve ensuite &#233;valu&#233;e en fonction de son contenu informatif (section 3.2) et de son score de
qualit&#233; de traduction (section 3.3). Puis, les phrases de plus haut score sont s&#233;lectionn&#233;es pour les inclure dans le
r&#233;sum&#233; (section 3.4). La figure 1 pr&#233;sente un aper&#231;u de l&#8217;architecture de notre m&#233;thode.
</p>
<p>Phrases
en anglais
</p>
<p>Pr&#233;diction de la
qualit&#233; de TA
</p>
<p>Pond&#233;ration
 des phrases
</p>
<p>G&#233;n&#233;ration 
du r&#233;sum&#233;
</p>
<p>Traduction 
automatique
</p>
<p>R&#233;sum&#233;
en 
</p>
<p>fran&#231;ais
</p>
<p>FIGURE 1 &#8211; Architecture de notre syst&#232;me de r&#233;sum&#233; automatique cross-lingue.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ST&#201;PHANE HUET, FLORIAN BOUDIN ET JUAN-MANUEL TORRES-MORENO
</p>
<p>3.1 Pr&#233;traitement de documents et pr&#233;diction de la qualit&#233; de traduction
</p>
<p>Chaque document de l&#8217;ensemble &#224; r&#233;sumer est segment&#233; en phrases en utilisant la m&#233;thode PUNKT de d&#233;tection
de changement de phrases (Kiss &amp; Strunk, 2006) mise en &#339;uvre dans la bo&#238;te &#224; outils NLTK (Bird &amp; Loper, 2004).
Toutes les phrases en anglais ont &#233;t&#233; automatiquement traduites en fran&#231;ais en utilisant le syst&#232;me de traduction
de Google 4.
</p>
<p>Un score de TA est calcul&#233; pour chaque phrase pour estimer la justesse et la fluidit&#233; des phrases g&#233;n&#233;r&#233;es en
fran&#231;ais. Pour ce faire, nous calculons pour chaque phrase 8 caract&#233;ristiques, qui donnent des informations sur la
difficult&#233; de traduction et sur la lisibilit&#233; des traductions g&#233;n&#233;r&#233;es :
</p>
<p>&#8211; la longueur de la phrase source en terme de mots ;
&#8211; le ratio des longueurs des phrases source et cible ;
&#8211; le nombre de signes de ponctuation dans la phrase source ;
&#8211; la proportion des nombres et des signes de ponctuation pr&#233;sentes dans la phrase source qui sont retrouv&#233;es dans
</p>
<p>la phrase cible ;
&#8211; les perplexit&#233;s des phrases source et cible calcul&#233;es &#224; l&#8217;aide de mod&#232;le de langue (ML) 5-grammes en avant ;
&#8211; les perplexit&#233;s des phrases source et cible calcul&#233;es par des ML bigrammes en arri&#232;re, i. e. en inversant l&#8217;ordre
</p>
<p>des mots des phrases.
</p>
<p>Ces quatre premi&#232;res caract&#233;ristiques sont parmi les traits les plus pertinents mis en exergue dans (Specia et al.,
2009), parmi 84 caract&#233;ristiques &#233;tudi&#233;es ; les quatre derni&#232;res ont d&#233;j&#224; montr&#233; leur efficacit&#233; dans le calcul de
mesure de confiance au niveau des mots (Raybaud et al., 2009). Des ML sont construits &#224; partir des corpus
monolingues du domaine des actualit&#233;s, rendus disponible pour l&#8217;atelier WMT 2010 (Callison-Burch et al., 2010)
et constitu&#233;s respectivement de 991 et 325 millions de mots en anglais et en fran&#231;ais. Les scores de perplexit&#233;
visent &#224; estimer la fluidit&#233;. Contrairement &#224; d&#8217;autres &#233;tudes, nous nous sommes concentr&#233;s sur des caract&#233;ristiques
simples ne requ&#233;rant pas de ressources linguistiques comme des analyseurs syntaxiques ou des dictionnaires. En
outre, nous nous sommes restreints &#224; des scores ne d&#233;pendant par du syst&#232;me de traduction utilis&#233;.
</p>
<p>Pour pr&#233;dire la qualit&#233; de la traduction, nous avons employ&#233; la m&#233;thode &#15;-SVR, qui est une extension des s&#233;para-
teurs &#224; vaste marge pour faire de la r&#233;gression et qui a d&#233;j&#224; &#233;t&#233; utilis&#233;e dans le m&#234;me cadre applicatif (Wan et al.,
2010; Raybaud et al., 2009). Nous avons employ&#233; la librairie LIBSVM (Chang &amp; Lin, 2001), en nous restreignant
aux noyaux gaussiens comme recommand&#233; par les auteurs. Le mod&#232;le de r&#233;gression a deux param&#232;tres : une erreur
de co&#251;t c et le coefficient &#947; de la fonction noyau ; leur valeur a &#233;t&#233; optimis&#233;e par recherche par quadrillage et par
validation crois&#233;e.
</p>
<p>Le mod&#232;le &#15;-SVR devrait id&#233;alement &#234;tre appris sur un corpus &#233;tiquet&#233; manuellement du point de vue de la qualit&#233;
de traduction. Malheureusement, nous ne connaissons pas de corpus de ce genre ayant une taille suffisante pour
la paire anglais-fran&#231;ais et la production de jugements de la TA reste un processus tr&#232;s lent. Nous nous sommes
par cons&#233;quent tourn&#233;s vers un indicateur calcul&#233; automatiquement &#224; partir de traductions de r&#233;f&#233;rence produites
par des humains : le score NIST (Doddington, 2002). Cette m&#233;trique a en effet d&#233;j&#224; &#233;t&#233; utilis&#233;e dans le pass&#233;
dans le m&#234;me objectif (Blatz et al., 2003; Specia et al., 2009) et s&#8217;est r&#233;v&#233;l&#233;e plus corr&#233;l&#233;e avec des jugements
humains au niveau de la phrase que BLEU (Blatz et al., 2003). Notre corpus d&#8217;apprentissage a &#233;t&#233; obtenu &#224; partir
des traductions de r&#233;f&#233;rence fournies dans le domaine des actualit&#233;s pour les ateliers WMT (Callison-Burch et al.,
2010) de 2008 &#224; 2010, ce qui repr&#233;sente un ensemble de 7 112 phrases. Pour contr&#244;ler la qualit&#233; du mod&#232;le ainsi
obtenu, nous avons calcul&#233; la m&#233;trique MSE (Mean Squared Error) : 1N
</p>
<p>&#8721;N
j=1(yj &#8722; y&#770;j)2, N &#233;tant le nombre de
</p>
<p>phrases, y&#770; la pr&#233;diction estim&#233;e par le mod&#232;le et y la valeur r&#233;elle. Sur les 2 007 phrases de WMT 2007 gard&#233;es &#224;
cette fin, le MSE mesur&#233; a &#233;t&#233; de 0,456.
</p>
<p>3.2 Pond&#233;ration des phrases
</p>
<p>Notre syst&#232;me de r&#233;sum&#233; multi-document est fond&#233; sur un graphe dirig&#233; G = (V,E) construit pour chaque en-
semble de textes, V &#233;tant l&#8217;ensemble de n&#339;uds et E les arcs (ar&#234;tes) dirig&#233;s. Un n&#339;ud est ajout&#233; au graphe pour
chaque phrase de l&#8217;ensemble de documents ; les ar&#234;tes sont d&#233;finies entre ces n&#339;uds en fonction de la mesure de
similarit&#233; d&#233;finie dans (Mihalcea, 2004). Cette mesure d&#233;termine le nombre de mots communs entre les repr&#233;sen-
tations lexicales des deux phrases, les mots outils ayant &#233;t&#233; au pr&#233;alable supprim&#233;s et les autres mots ayant &#233;t&#233;
</p>
<p>4. http://translate.google.com</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE BAS&#201;E SUR LES GRAPHES POUR LE R&#201;SUM&#201; MULTI-DOCUMENT CROSS-LINGUE
</p>
<p>stemm&#233;s avec le stemmeur de Porter. Pour &#233;viter de favoriser les phrases longues, cette valeur est normalis&#233;e par
les longueurs des phrases. Si freq(w, S) repr&#233;sente la fr&#233;quence du mot w dans la phrase S, la similarit&#233; entre les
phrases Si et Sj est d&#233;finie par :
</p>
<p>Sim(Si, Sj) =
</p>
<p>&#8721;
w&#8712;Si,Sj freq(w, Si) + freq(w, Sj)
</p>
<p>log(|Si|) + log(|Sj |) (1)
</p>
<p>Les algorithmes de classement bas&#233;s sur les mod&#232;les de graphes mettent en &#339;uvre le concept de recommandation.
Les phrases sont &#233;valu&#233;es selon des scores calcul&#233;s r&#233;cursivement sur l&#8217;int&#233;gralit&#233; du graphe. Dans notre &#233;tude,
nous utilisons une adaptation de l&#8217;algorithme PAGERANK de Google (Page et al., 1998) qui inclut les poids des
ar&#234;tes :
</p>
<p>p(Vi) = (1&#8722; d) + d&#215;
&#8721;
</p>
<p>Vj&#8712;pred(Vi)
</p>
<p>Sim(Si, Sj)&#8721;
Vk&#8712;succ(Vi) Sim(Sk, Si)
</p>
<p>p(Vi) (2)
</p>
<p>o&#249; d est un &#171; facteur d&#8217;amortissement &#187; (typiquement dans l&#8217;intervalle [0.8, 0.9]), pred(Vi) repr&#233;sente l&#8217;ensemble
des n&#339;uds qui ont une ar&#234;te en direction de Vi et succ(Vi) l&#8217;ensemble des n&#339;uds connect&#233;s &#224; Vi par une ar&#234;te
sortante. La m&#233;thode employ&#233;e ici, d&#233;crite dans (Mihalcea, 2004), est tr&#232;s similaire au PAGERANK lexical, appel&#233;
LEXRANK (Erkan &amp; Radev, 2004).
</p>
<p>3.3 Inclusion des scores de qualit&#233; de traduction
</p>
<p>Pour prendre en compte l&#8217;aspect cross-lingue, la mesure de similarit&#233; inter-phrases, d&#233;finie dans l&#8217;&#233;quation 1 pour
les phrases d&#8217;origine en anglais, est modifi&#233;e pour inclure les scores de qualit&#233; de traduction :
</p>
<p>Sim2(Si, Sj) = Sim(Si, Sj)&#215; Prediction(Si) (3)
</p>
<p>o&#249; Prediction(Si) est le score de qualit&#233; de TA de la phrase Si calcul&#233;e comme d&#233;crit en section 3.1. Cette m&#233;trique
est asym&#233;trique, contrairement &#224; celle d&#233;finie par l&#8217;&#233;quation 1. Une phrase traduite correctement et fluide voit ainsi
les poids de ses ar&#234;tes sortantes renforc&#233;s et jouera par cons&#233;quent un r&#244;le plus central dans le graphe.
</p>
<p>Nous avons modifi&#233; l&#8217;algorithme de classement afin de tirer profit des sp&#233;cificit&#233;s des documents. Comme la
position d&#8217;une phrase au sein d&#8217;un document est un indicateur fort sur l&#8217;importance de son contenu &#8212; les articles
de journaux pr&#233;sentant g&#233;n&#233;ralement au d&#233;but une description concise du sujet &#8212; le poids des arcs sortant du
n&#339;ud correspondant &#224; la premi&#232;re phrase a &#233;t&#233; doubl&#233;. En outre, les phrases dupliqu&#233;es ainsi que les phrases
contenant moins de 5 mots ont &#233;t&#233; mises de c&#244;t&#233;.
</p>
<p>3.4 G&#233;n&#233;ration de r&#233;sum&#233;
</p>
<p>Bien souvent, les documents regroup&#233;s sous une th&#233;matique contiennent des phrases tr&#232;s similaires, voire m&#234;me
identiques. Il est donc possible que deux phrases tr&#232;s redondantes se retrouvent dans un r&#233;sum&#233;, d&#233;gradant &#224; la
fois sa lisibilit&#233; et son contenu informatif. Pour pallier ce probl&#232;me, Carbonell &amp; Goldstein (1998) ont propos&#233;
la m&#233;thode d&#8217;assemblage it&#233;ratif Maximal Marginal Relevance (MMR). Cette technique, probablement la plus
utilis&#233;e, consiste &#224; r&#233;ordonner les phrases en fonction de deux crit&#232;res qui sont l&#8217;importance de la phrase et la
redondance par rapport aux phrases d&#233;j&#224; s&#233;lectionn&#233;es. Le r&#233;sum&#233; est ensuite construit it&#233;rativement par l&#8217;ajout
des phrases maximisant l&#8217;informativit&#233; tout en minimisant la redondance.
</p>
<p>Dans cette &#233;tude, nous avons utilis&#233; une approche diff&#233;rente. Suivant la m&#233;thode propos&#233;e dans (Mihalcea &amp;
Tarau, 2005) pour la construction de graphes, aucun arc n&#8217;est ajout&#233; entre deux n&#339;uds dont la similarit&#233; exc&#232;de un
seuil maximal. De fa&#231;on &#224; r&#233;duire la redondance, une &#233;tape suppl&#233;mentaire est ajout&#233;e lors de la g&#233;n&#233;ration des
r&#233;sum&#233;s (Genest et al., 2009). Nous g&#233;n&#233;rons pour ce faire tous les r&#233;sum&#233;s candidats &#224; partir des combinaisons
des N phrases ayant les meilleurs scores, en veillant &#224; ce que le nombre total de caract&#232;res soit optimal (i. e. en
dessous d&#8217;un seuil donn&#233; et qu&#8217;il soit impossible d&#8217;ajouter une autre phrase sans d&#233;passer ce seuil). Le r&#233;sum&#233;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ST&#201;PHANE HUET, FLORIAN BOUDIN ET JUAN-MANUEL TORRES-MORENO
</p>
<p>retenu au final est celui poss&#233;dant le score global le plus &#233;lev&#233;, ce score &#233;tant calcul&#233; comme le produit du score de
la diversit&#233; du r&#233;sum&#233; &#8212; estim&#233; par le nombre de n-grammes diff&#233;rents &#8212; et de la somme des scores des phrases.
</p>
<p>Afin d&#8217;am&#233;liorer la lisibilit&#233; du r&#233;sum&#233; produit, les phrases sont tri&#233;es dans l&#8217;ordre chronologique de publication
des documents o&#249; ils apparaissent, ce qui maximise la coh&#233;rence temporelle ; si deux phrases sont extraites &#224; partir
d&#8217;un m&#234;me document, l&#8217;ordre original du document est conserv&#233;.
</p>
<p>4 R&#233;sultats
</p>
<p>Cette section d&#233;crit les donn&#233;es utilis&#233;es, les m&#233;triques d&#8217;&#233;valuation et les r&#233;sultats de notre syst&#232;me.
</p>
<p>4.1 Cadre exp&#233;rimental
</p>
<p>Nous avons employ&#233; dans notre &#233;tude les ensembles de documents mis &#224; disposition pour l&#8217;&#233;valuation DUC 2004,
ce qui repr&#233;sente 50 ensembles de documents en anglais. Chaque ensemble traite d&#8217;une m&#234;me th&#233;matique et com-
porte en moyenne 10 articles de journaux produits par Associated Press ou le New York Times. La t&#226;che consiste &#224;
g&#233;n&#233;rer des r&#233;sum&#233;s d&#8217;au plus 665 caract&#232;res &#8212; incluant les caract&#232;res alphanum&#233;riques, les espaces et les ponc-
tuations &#8212; contenant l&#8217;essentiel du contenu de l&#8217;ensemble de documents correspondants. Nous avons effectu&#233;
sur ces donn&#233;es une &#233;valuation automatique du contenu. Une &#233;valuation manuelle de la lisibilit&#233; a &#233;galement &#233;t&#233;
men&#233;e sur un &#233;chantillon constitu&#233; de 16 ensembles de documents tir&#233;s al&#233;atoirement.
</p>
<p>4.1.1 &#201;valuation automatique
</p>
<p>La plupart des m&#233;thodes d&#8217;&#233;valuation automatique op&#232;rent en comparant les r&#233;sum&#233;s g&#233;n&#233;r&#233;s avec un ou plusieurs
r&#233;sum&#233;s de r&#233;f&#233;rence. La m&#233;trique que nous avons employ&#233;e ici est ROUGE (Recall-Oriented Understudy for Gis-
ting Evaluation), dont on sait qu&#8217;elle est bien corr&#233;l&#233;e avec les jugements humains (Lin, 2004). ROUGE correspond
en fait &#224; plusieurs mesures, calcul&#233;es &#224; partir du nombre de n-grammes commun entre le r&#233;sum&#233; candidat et le(s)
r&#233;sum&#233;(s) de r&#233;f&#233;rence. Nous avons calcul&#233; trois m&#233;triques au cours de nos exp&#233;riences : ROUGE-1 (bas&#233;e sur les
unigrammes), ROUGE-2 (bigrammes) et ROUGE-SU4 (bigrammes &#224; trou, i. e. des couples de deux mots contenant
au plus quatre mots entre eux) 5.
</p>
<p>Quatre r&#233;sum&#233;s de r&#233;f&#233;rence en anglais &#233;taient fournis pour chacun des ensembles de documents de DUC 2004.
Pour &#233;valuer notre m&#233;thode, nous avons demand&#233; &#224; trois annotateurs de traduire les r&#233;sum&#233;s disponibles pour le
sous-ensemble de 16 groupes de documents, en veillant &#224; ce que chaque phrase du r&#233;sum&#233; soit traduite phrase
par phrase sans introduire d&#8217;information suppl&#233;mentaire comme la g&#233;n&#233;ration d&#8217;anaphores, la d&#233;sambiguisation
des noms propres ou la r&#233;duction des informations redondantes. 64 r&#233;sum&#233;s de r&#233;f&#233;rence ont &#233;t&#233; ainsi produits,
chaque annotateur traduisant en moyenne un r&#233;sum&#233; en 15 minutes.
</p>
<p>L&#8217;&#233;valuation par ROUGE &#233;tant ici r&#233;alis&#233;e dans un cadre diff&#233;rent des t&#226;ches habituelles &#8212; produisant des r&#233;sum&#233;s
en anglais &#224; partir de documents exprim&#233;s dans la m&#234;me langue &#8212;, nous avons effectu&#233; quelques modifications.
Aucune contrainte stricte n&#8217;a &#233;t&#233; impos&#233;e sur la taille des r&#233;sum&#233;s traduits produits en fran&#231;ais. En revanche, nous
avons fait en sorte que notre algorithme de g&#233;n&#233;ration construise des r&#233;sum&#233;s pour lesquelles la longueur totale
des phrases correspondantes en anglais respecte la contrainte impos&#233;e &#224; DUC 2004 sur le nombre de caract&#232;res.
La longueur des r&#233;sum&#233;s de r&#233;f&#233;rence en fran&#231;ais se trouve ainsi accrue de 25 % en moyenne par rapport aux
r&#233;sum&#233;s correspondants en anglais. Notons enfin que le stemmer de Porter utilis&#233; dans l&#8217;&#233;valuation ROUGE a &#233;t&#233;
adapt&#233; au fran&#231;ais.
</p>
<p>4.1.2 &#201;valuation manuelle
</p>
<p>L&#8217;&#233;valuation de la qualit&#233; linguistique des r&#233;sum&#233;s a &#233;t&#233; effectu&#233;e selon un protocole similaire &#224; celui utilis&#233; lors
des campagnes DUC. Nous avons &#233;valu&#233; la lisibilit&#233; des r&#233;sum&#233;s sur une &#233;chelle de 1 &#224; 5, o&#249; 5 est attribu&#233; aux
r&#233;sum&#233;s &#171; faciles &#224; lire &#187; et 1 aux r&#233;sum&#233;s &#171; difficiles &#224; lire &#187;. Cinq annotateurs ont particip&#233; &#224; cette exp&#233;rience.
</p>
<p>5. Nous avons utilis&#233; la version 1.5.5 de ROUGE avec les param&#232;tres par d&#233;faut indiqu&#233;s pour DUC 2004.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE BAS&#201;E SUR LES GRAPHES POUR LE R&#201;SUM&#201; MULTI-DOCUMENT CROSS-LINGUE
</p>
<p>Afin de comparer notre approche, nous avons g&#233;n&#233;r&#233; deux r&#233;sum&#233;s pour chaque ensemble de documents, i. e. pour
chacune des th&#233;matiques. Le premier r&#233;sum&#233; est produit par la m&#233;thode que nous proposons tandis que le second
(baseline) est obtenu en traduisant directement un r&#233;sum&#233; en fran&#231;ais (obtenu par la fonction de pond&#233;ration
d&#233;crite en section 3.2). La t&#226;che qui leur a &#233;t&#233; confi&#233;e &#233;tait d&#8217;attribuer une note aux deux r&#233;sum&#233;s d&#8217;une m&#234;me
th&#233;matique, l&#8217;ordre d&#8217;apparition des r&#233;sum&#233;s &#233;tant al&#233;atoire afin d&#8217;&#233;viter tout biais.
</p>
<p>4.2 Exp&#233;riences monolingues
</p>
<p>Les performances de notre m&#233;thode ont tout d&#8217;abord &#233;t&#233; &#233;valu&#233;es sur une t&#226;che de r&#233;sum&#233; monolingue. Le ta-
bleau 1 indique les scores d&#8217;&#233;valuation automatique obtenus sur l&#8217;ensemble des donn&#233;es de DUC 2004 pour
diff&#233;rentes m&#233;thodes : le plus haut score atteint lors de la campagne en 2004 (ligne 1), le score obtenu avec la
m&#233;thode GRAPH-SUM d&#233;crite en section 3.2 bas&#233;e sur les graphes (ligne 2) et un score calcul&#233; pour une m&#233;thode
na&#239;ve prenant la premi&#232;re phrase des documents les plus r&#233;cents de chaque ensemble &#224; traduire. L&#8217;approche ba-
s&#233;e sur les graphes obtient de bons r&#233;sultats, la diff&#233;rence avec le meilleur syst&#232;me n&#8217;&#233;tant pas statistiquement
significative 6.
</p>
<p>Syst&#232;me ROUGE-1 Rang ROUGE-2 Rang ROUGE-SU4 Rang
</p>
<p>1er syst&#232;me 0,38244&#8224; 1 0,09218&#8224; 1 0,13323&#8224; 1
GRAPH-SUM 0,38052&#8224; 2 0,08566&#8224; 4 0,13114&#8224; 3
M&#233;thode na&#239;ve 0,32381 26 0,06406 25 0,10291 29
</p>
<p>TABLE 1 &#8211; Scores ROUGE moyens mesur&#233;s sur les donn&#233;es de DUC 2004 et rangs obtenus par rapport aux
35 participants de la campagne. Les scores indiqu&#233;s par &#8224; sont statistiquement significatifs par rapport au mod&#232;le
de base (&#961; &lt; 0.001 avec un t-test de Student).
</p>
<p>4.3 Exp&#233;riences cross-lingues
</p>
<p>Dans cette seconde s&#233;rie d&#8217;exp&#233;riences, nous &#233;valuons notre approche pour le r&#233;sum&#233; automatique multi-document
cross-lingue. La premi&#232;re partie de cette &#233;valuation est r&#233;alis&#233;e automatiquement &#224; l&#8217;aide des mesures ROUGE et
concerne le contenu des r&#233;sum&#233;s. Il s&#8217;agit d&#8217;&#233;valuer si les r&#233;sum&#233;s produits contiennent les informations les plus
importantes des documents sources. Les r&#233;sultats de r&#233;f&#233;rence sont obtenus en traduisant le r&#233;sum&#233; en anglais
produit par l&#8217;approche bas&#233;e sur les mod&#232;les de graphes (m&#233;thode GRAPH-SUM). Les scores ROUGE calcul&#233;s
avec cette m&#233;thode sont pr&#233;sent&#233;s &#224; la ligne 1 du tableau 2. En utilisant notre m&#233;thode faisant intervenir la qualit&#233;
des traductions automatiques (ligne 2), nous observons une l&#233;g&#232;re am&#233;lioration en terme de ROUGE-2 et ROUGE-
SU4. Cependant, cette &#233;volution des scores n&#8217;est pas statistiquement significative. Ceci peut s&#8217;expliquer par le
fait que notre m&#233;thode favorise les phrases dont la qualit&#233; de TA est bonne. Ainsi des phrases ayant un contenu
informationnel plus faible peuvent &#234;tre introduites dans le r&#233;sum&#233;, ce qui limite l&#8217;am&#233;lioration des r&#233;sultats.
</p>
<p>Syst&#232;me ROUGE-1 ROUGE-2 ROUGE-SU4
</p>
<p>M&#233;thode de r&#233;ference 0,39704 0,10249 0,13711
Notre m&#233;thode 0,39624 0,10687 0,13877
</p>
<p>TABLE 2 &#8211; Scores ROUGE moyens calcul&#233;s sur le sous-ensemble de DUC 2004 traduit en fran&#231;ais.
</p>
<p>La seconde partie de cette &#233;valuation concerne la qualit&#233; linguistique des r&#233;sum&#233;s g&#233;n&#233;r&#233;s. Il s&#8217;agit d&#8217;&#233;valuer
manuellement si les r&#233;sum&#233;s produits sont lisibles mais &#233;galement compr&#233;hensibles. Le tableau 3 montre les
r&#233;sultats de l&#8217;&#233;valuation manuelle obtenus sur le sous-ensemble de 16 groupes de documents. Le score moyen
donn&#233; par chaque annotateur est &#233;galement indiqu&#233;. Tous les annotateurs ont jug&#233; que notre m&#233;thode conduisait &#224;
une am&#233;lioration de la lisibilit&#233; des r&#233;sum&#233;s produits, ce qui montre ainsi l&#8217;int&#233;r&#234;t d&#8217;utiliser des scores de qualit&#233;
de TA pour am&#233;liorer la qualit&#233; linguistique des r&#233;sum&#233;s.
</p>
<p>6. Le t-test de Student est de &#961; = 0.77 pour ROUGE-1, &#961; = 0.17 pour ROUGE-2 et &#961; = 0.57 pour ROUGE-SU4.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ST&#201;PHANE HUET, FLORIAN BOUDIN ET JUAN-MANUEL TORRES-MORENO
</p>
<p>N&#233;anmoins, il faut noter que les scores moyens sont relativement bas. Ceci indique que les r&#233;sum&#233;s g&#233;n&#233;r&#233;s par
notre m&#233;thode, bien qu&#8217;&#233;tant meilleurs du point de vue de la lisibilit&#233; par rapport &#224; l&#8217;approche de r&#233;f&#233;rence, ne sont
pas encore satisfaisants. Un exemple des sorties de notre syst&#232;me de r&#233;sum&#233; automatique est donn&#233; en annexe.
Plusieurs types d&#8217;erreurs ont &#233;t&#233; identifi&#233;es comme r&#233;currentes. La qualit&#233; de la TA est d&#233;pendante de la difficult&#233;
de la phrase &#224; traduire. Ainsi, par des traitements simples comme la suppression des r&#233;f&#233;rences temporelles, la
r&#233;solution des acronymes ou la normalisation des noms propres, nous esp&#233;rons pouvoir r&#233;duire la difficult&#233; des
phrases sources et par cons&#233;quent r&#233;duire le nombre d&#8217;erreurs de traduction.
</p>
<p>Annotateur Lisibilit&#233;
</p>
<p>M&#233;thode de r&#233;f&#233;rence Notre m&#233;thode
</p>
<p>Annotateur 1 2,44 2,50
Annotateur 2 1,56 1,63
Annotateur 3 1,75 2,31
Annotateur 4 3,06 3,31
Annotateur 5 1,50 1,63
</p>
<p>Moyenne 2,06 2,28
</p>
<p>TABLE 3 &#8211; Scores moyens de lisibilit&#233; de notre m&#233;thode compar&#233;s avec une approche standard bas&#233;e sur les
graphes. Les scores varient selon une &#233;chelle de 1 &#224; 5, 5 &#233;tant le plus haut score possible.
</p>
<p>5 Conclusions et perspectives
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; une approche bas&#233;e sur les mod&#232;les de graphes pour le r&#233;sum&#233; automatique
multi-document cross-lingue. Nous avons propos&#233; d&#8217;introduire des scores de qualit&#233; de traduction automatique au
moment de l&#8217;&#233;tape de construction du graphe repr&#233;sentant les unit&#233;s textuelles, un algorithme de classement par
popularit&#233; &#233;tant ensuite charg&#233; de s&#233;lectionner les phrases traduites qui sont &#224; la fois les plus informatives mais
&#233;galement les plus lisibles. Cette approche a &#233;t&#233; &#233;valu&#233;e sur un corpus de 16 ensembles de documents traduits
manuellement parmi les documents mis &#224; disposition dans le cadre de la campagne d&#8217;&#233;valuation internationale
DUC 2004. Les r&#233;sultats exp&#233;rimentaux montrent que notre m&#233;thode am&#233;liore sensiblement la lisibilit&#233; (i. e. la
qualit&#233; linguistique) des r&#233;sum&#233;s g&#233;n&#233;r&#233;s tout en maintenant un contenu informatif au niveau de l&#8217;&#233;tat de l&#8217;art.
</p>
<p>En perspectives de nos travaux, nous souhaitons dans un premier temps mener une &#233;valuation plus compl&#232;te en
produisant des r&#233;sum&#233;s de r&#233;f&#233;rence sur l&#8217;ensemble des donn&#233;es de la comp&#233;tition DUC 2004 et en &#233;tendant
l&#8217;&#233;valuation &#224; d&#8217;autres langues. Ceci permettra de renforcer l&#8217;importance des r&#233;sultats que nous avons obtenus
mais aussi d&#8217;envisager un apprentissage supervis&#233; de la r&#233;partition entre l&#8217;informativit&#233; et &#224; la lisibilit&#233; des phrases.
Dans un deuxi&#232;me temps, nous souhaitons travailler sur la r&#233;&#233;criture des phrases sources et en &#233;tudier l&#8217;impact
sur la qualit&#233; de traduction, l&#8217;id&#233;e &#233;tant de simplifier au maximum les phrases sources &#224; l&#8217;aide de traitement
linguistiques comme la r&#233;solution d&#8217;anaphores afin de faciliter le travail du syst&#232;me de TA. Nous souhaitons
&#233;galement suivre la piste de la fusion non supervis&#233;e de phrases (Filippova, 2010) afin de g&#233;n&#233;rer des phrases
courtes et linguistiquement simples. Une derni&#232;re perspective que nous voulons &#233;tudier concerne l&#8217;utilisation de
notre propre mod&#232;le de traduction automatique, ce qui permettra &#224; la fois d&#8217;adapter ce syst&#232;me pour le type de
documents &#224; r&#233;sumer et de prendre en compte de nouveaux indices pour pr&#233;dire la qualit&#233; de la traduction.
</p>
<p>R&#233;f&#233;rences
</p>
<p>C. BANEA, A. MOSCHITTI, S. SOMASUNDARAN &amp; F. M. ZANZOTTO, Eds. (2010). TextGraphs-5 Workshop.
Uppsala, Su&#232;de.
</p>
<p>BARZILAY R., MCKEOWN K. R. &amp; ELHADAD M. (1999). Information fusion in the context of multi-document
summarization. In ACL, College Park, MD, USA.
</p>
<p>BIRD S. &amp; LOPER E. (2004). NLTK : The natural language toolkit. In ACL, Barcelone, Espagne.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>UNE APPROCHE BAS&#201;E SUR LES GRAPHES POUR LE R&#201;SUM&#201; MULTI-DOCUMENT CROSS-LINGUE
</p>
<p>BLATZ J., FITZGERALD E., FOSTER G., GANDRABUR S., GOUTTE C., KULESZA A., SANCHIS A. &amp; UEF-
FING N. (2003). Confidence Estimation for Machine Translation. Rapport interne, Johns Hopkins University,
Batimore, MD, USA.
</p>
<p>CALLISON-BURCH C., KOEHN P., MONZ C., PETERSON K., PRZYBOCKI M. &amp; ZAIDAN O. (2010). Findings
of the 2010 joint workshop on statistical machine translation and metrics for machine translation. In Workshop
on Statistical Machine Translation and Metrics (WMT), Uppsala, Su&#232;de.
</p>
<p>CARBONELL J. &amp; GOLDSTEIN J. (1998). The use of MMR, diversity-based reranking for reordering documents
and producing summaries. In SIGIR, Melbourne, Australie.
</p>
<p>CHANG C.-C. &amp; LIN C.-J. (2001). LIBSVM : a library for support vector machines. Software available at
http://www.csie.ntu.edu.tw/~cjlin/libsvm.
</p>
<p>DODDINGTON G. (2002). Automatic evaluation of machine translation quality using n-gram co-occurrence
statistics. In HLT, San Diego, CA, USA.
</p>
<p>ERKAN G. &amp; RADEV D. (2004). LexRank : Graph-based lexical centrality as salience in text summarization.
JAIR, 22(1), 457&#8211;479.
FILIPPOVA K. (2010). Multi-sentence compression : Finding shortest paths in word graphs. In Coling, P&#233;kin,
Chine.
</p>
<p>GENEST P., LAPALME G., NERIMA L. &amp; WEHRLI E. (2009). A symbolic summarizer with 2 steps of sentence
selection for TAC 2009. In TAC Workshop, Gaithersburg, MD, USA.
</p>
<p>KISS T. &amp; STRUNK J. (2006). Unsupervised multilingual sentence boundary detection. Computational Linguis-
tics, 32(4), 485&#8211;525.
LIN C.-Y. (2004). Rouge : A package for automatic evaluation of summaries. In ACL Workshop on Text
Summarization Branches Out, Barcelone, Espagne.
</p>
<p>MIHALCEA R. (2004). Graph-based ranking algorithms for sentence extraction, applied to text summarization.
In ACL, Barcelone, Espagne.
</p>
<p>MIHALCEA R. &amp; TARAU P. (2005). A language independent algorithm for single and multiple document
summarization. In IJCNLP, Jeju Island, Cor&#233;e du Sud.
</p>
<p>ORA&#774;SAN C. &amp; CHIOREAN O. A. (2008). Evaluation of a cross-lingual romanian-english multi-document sum-
mariser. In LREC.
</p>
<p>PAGE L., BRIN S., MOTWANI R. &amp; WINOGRAD T. (1998). The pagerank citation ranking : Bringing order to
the web. Rapport interne, Stanford Digital Library Technologies Project.
</p>
<p>QUIRK C. B. (2004). Training a sentence-level machine translation confidence measure. In LREC, Lisbonne,
Portugal.
</p>
<p>RADEV D., JING H., STY M. &amp; TAM D. (2004). Centroid-based summarization of multiple documents. Infor-
mation Processing &amp; Management, 40(6), 919&#8211;938.
RAYBAUD S., LANGLOIS D. &amp; SMA&#207;LI K. (2009). Efficient combination of confidence measures for machine
translation. In Interspeech, Brighton, UK.
</p>
<p>SPECIA L., CANCEDDA N., DYMETMAN M., TURCHI M. &amp; CRISTIANINI N. (2009). Estimating the sentence-
level quality of machine translation systems. In EAMT, Barcelone, Espagne.
</p>
<p>WAN X., LI H. &amp; XIAO J. (2010). Cross-language document summarization based on machine translation
quality prediction. In ACL, Uppsala, Su&#232;ede.
</p>
<p>WONG K.-F., WU M. &amp; LI W. (2008). Extractive summarization using supervised and semi-supervised lear-
ning. In Coling, Manchester, UK.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ST&#201;PHANE HUET, FLORIAN BOUDIN ET JUAN-MANUEL TORRES-MORENO
</p>
<p>Annexe
</p>
<p>M&#233;thode de r&#233;f&#233;rence (Score de lisibilit&#233; moyenne de 2,6)
</p>
<p>Leaders de l&#8217;opposition du prince Norodom Ranariddh et Sam Rainsy, invoquant des menaces de Hun Sen &#224;
l&#8217;arrestation de l&#8217;opposition, apr&#232;s deux tentatives pr&#233;sum&#233;es sur sa vie, a dit qu&#8217;ils ne pouvaient pas n&#233;gocier
librement au Cambodge et a appel&#233; &#224; des pourparlers &#224; la r&#233;sidence de Sihanouk &#224; P&#233;kin. (Opposition leaders Prince
Norodom Ranariddh and Sam Rainsy, citing Hun Sen&#8217;s threats to arrest opposition figures after two alleged attempts on his life, said they could not negotiate
</p>
<p>freely in Cambodia and called for talks at Sihanouk&#8217;s residence in Beijing.) Le parti de Hun Sen a r&#233;cemment demand&#233; &#224; Ranariddh
pour retourner &#224; la table des n&#233;gociations et a d&#233;clar&#233; qu&#8217;il &#233;tait dispos&#233; &#224; faire une &#8220;concession appropri&#233;es&#8221; pour
sortir de l&#8217;impasse de former un gouvernement. (Hun Sen&#8217;s party recently called on Ranariddh to return to the negotiation table and said
it was willing to make an &#8220;appropriate concession&#8221; to break the deadlock over forming a government.) La semaine derni&#232;re, Hun Sen Parti du
peuple cambodgien et le parti Ranariddh FUNCINPEC ont convenu de former une coalition qui laisserait Hun
Sen comme Premier ministre seul et faire le prince pr&#233;sident de l&#8217;Assembl&#233;e nationale. (Last week, Hun Sen&#8217;s Cambodian
People&#8217;s Party and Ranariddh&#8217;s FUNCINPEC party agreed to form a coalition that would leave Hun Sen as sole prime minister and make the prince president of
</p>
<p>the National Assembly.)
</p>
<p>Notre m&#233;thode (Score de lisibilit&#233; moyenne de 3,2)
</p>
<p>Le parti au pouvoir a soutenu l&#8217;action de la police dans sa d&#233;claration, en notant que les biens publics ont &#233;t&#233;
endommag&#233;s par des manifestants et que des grenades ont &#233;t&#233; lanc&#233;es sur la maison de Hun Sen apr&#232;s Sam Rainsy
a sugg&#233;r&#233; dans un discours que le gouvernement am&#233;ricain devrait tirer des missiles de croisi&#232;re &#224; Hun Sen. (The
ruling party supported the police action in its statement, noting that public property was damaged by protesters and that grenades were thrown at Hun Sen&#8217;s
</p>
<p>home after Sam Rainsy suggested in a speech that the U.S. government should fire cruise missiles at Hun Sen.) Politiciens cambodgiens a exprim&#233;
l&#8217;espoir lundi qu&#8217;un nouveau partenariat entre les parties de l&#8217;homme fort Hun Sen et son rival, le prince Norodom
Ranariddh, dans un gouvernement de coalition ne mettrait pas fin &#224; plus de violence. (Cambodian politicians expressed hope
Monday that a new partnership between the parties of strongman Hun Sen and his rival, Prince Norodom Ranariddh, in a coalition government would not end
</p>
<p>in more violence.) Le roi Norodom Sihanouk a salu&#233; mardi les accords sur le Cambodge les deux principaux partis
politiques pr&#233;c&#233;demment am&#232;re rivaux pour former un gouvernement de coalition dirig&#233; par l&#8217;homme fort Hun
Sen. (King Norodom Sihanouk on Tuesday praised agreements by Cambodia&#8217;s top two political parties previously bitter rivals to form a coalition government
led by strongman Hun Sen.)
</p>
<p>TABLE 4 &#8211; Example de r&#233;sum&#233;s en fran&#231;ais g&#233;n&#233;r&#233; pour l&#8217;ensemble D30001T de DUC 2004 par la m&#233;thode de
r&#233;f&#233;rence et notre approche.</p>

</div></div>
</body></html>