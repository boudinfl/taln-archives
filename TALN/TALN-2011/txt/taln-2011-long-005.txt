TALN 2011, Montpellier, 27 juin ‚Äì 1er juillet 2011
Utilisation d‚Äôun score de qualit√© de traduction
pour le r√©sum√© multi-document cross-lingue
St√©phane Huet1 Florian Boudin1 Juan-Manuel Torres-Moreno1,2,3
(1) LIA, Universit√© d‚ÄôAvignon, France
(2) √âcole Polytechnique de Montr√©al, Canada
(3) GIL-IINGEN, Universidad Nacional Aut√≥noma de M√©xico, Mexique
{stephane.huet,florian.boudin,juan-manuel.torres}@univ-avignon.fr
R√©sum√©. Le r√©sum√© automatique cross-lingue consiste √† g√©n√©rer un r√©sum√© r√©dig√© dans une langue dif-
f√©rente de celle utilis√©e dans les documents sources. Dans cet article, nous proposons une approche de r√©sum√©
automatique multi-document, bas√©e sur une repr√©sentation par graphe, qui prend en compte des scores de qualit√©
de traduction lors du processus de s√©lection des phrases. Nous √©valuons notre m√©thode sur un sous-ensemble ma-
nuellement traduit des donn√©es utilis√©es lors de la campagne d‚Äô√©valuation internationale DUC 2004. Les r√©sultats
exp√©rimentaux indiquent que notre approche permet d‚Äôam√©liorer la lisibilit√© des r√©sum√©s g√©n√©r√©s, sans pour autant
d√©grader leur informativit√©.
Abstract. Cross-language summarization is the task of generating a summary in a language different from
the language of the source documents. In this paper, we propose a graph-based approach to multi-document
summarization that integrates machine translation quality scores in the sentence selection process. We evaluate
our method on a manually translated subset of the DUC 2004 evaluation campaign. Results indicate that our
approach improves the readability of the generated summaries without degrading their informativity.
Mots-cl√©s : R√©sum√© cross-lingue, qualit√© de traduction, graphe.
Keywords: Cross-lingual summary, translation quality, graph.
1 Introduction
La multiplication des documents dans de nombreuses langues, en particulier sur le Web, a rendu n√©cessaire la mise
au point de m√©thodes de recherche et d‚Äôextraction d‚Äôinformation cross-lingue. Le r√©sum√© automatique cross-lingue
vise √† donner √† l‚Äôutilisateur un acc√®s rapide √† des contenus exprim√©s dans une ou plusieurs langues qu‚Äôil ma√Ætrise
mal ou ne conna√Æt pas. Plus pr√©cis√©ment, cette t√¢che consiste √† g√©n√©rer un r√©sum√© dans une langue cible diff√©-
rente de celle utilis√©e dans les documents sources. Dans cette √©tude, nous nous int√©ressons au r√©sum√© automatique
multi-document de l‚Äôanglais vers le fran√ßais, la motivation premi√®re √©tant de permettre aux utilisateurs franco-
phones d‚Äôacc√©der √† la masse toujours croissante d‚Äôactualit√©s disponibles √† travers des sources majoritairement
anglophones.
Plusieurs √©tudes r√©centes se sont int√©ress√©es aux mod√®les de graphes pour repr√©senter l‚Äôinformation dans des
applications de Traitement Automatique des Langues Naturelles (TALN) (Banea et al., 2010). Dans ces mod√®les,
les entit√©s ‚Äî qui peuvent √™tre par exemple les mots, les phrases ou m√™me les documents ‚Äî sont repr√©sent√©es
sous la forme de n≈ìuds et les relations entre elles par des ar√™tes. Ce type d‚Äôapproche a d√©j√† √©t√© utilis√© dans des
applications TALN diverses tel que l‚Äô√©tiquetage en parties du discours, l‚Äôextraction d‚Äôinformation, l‚Äôanalyse de
sentiments ou le r√©sum√© automatique auquel nous nous int√©ressons ici.
Une m√©thodologie simple pour aborder le r√©sum√© automatique cross-lingue serait d‚Äôappliquer un syst√®me de
traduction automatique (TA) directement sur les sorties d‚Äôun syst√®me de r√©sum√© automatique classique. Toutefois,
cette approche n‚Äôest pas sans inconv√©nients puisqu‚Äôelle devient d√©pendante de la qualit√© du syst√®me de TA. Dans
cet article, nous proposons de prendre en compte la qualit√© de traduction des phrases en fran√ßais lors de la s√©lection
des phrases retenues pour assembler le r√©sum√©, l‚Äôid√©e √©tant de minimiser l‚Äôimpact des erreurs commises par le
syst√®me de TA. Les phrases ainsi s√©lectionn√©es pour construire le r√©sum√© seront celles jug√©es √† la fois informatives
ST√âPHANE HUET, FLORIAN BOUDIN ET JUAN-MANUEL TORRES-MORENO
par le syst√®me de r√©sum√© automatique et faciles √† traduire par le syst√®me de TA. Pour ce faire, nous recourons √†
une m√©thode d‚Äôapprentissage supervis√© pour pr√©dire les scores de qualit√© de la traduction et int√©grons ces scores
durant la construction du graphe utilis√© pour s√©lectionner les phrases informatives.
Dans la suite de cet article, nous commen√ßons par pr√©senter les travaux connexes aux n√¥tres. La section 3 est
consacr√©e √† la description de la m√©thode que nous proposons. Nous d√©crivons ensuite en section 4 nos r√©sultats
exp√©rimentaux avant de conclure et de montrer quelques perspectives.
2 Travaux connexes
Dans cette section, nous pr√©sentons dans un premier temps les travaux existants sur la pr√©diction de la qualit√© de
traduction automatique. Nous d√©crivons ensuite les approches de r√©sum√© automatique bas√©es sur les mod√®les de
graphes ainsi que les √©tudes sur le r√©sum√© automatique cross-lingue.
2.1 Pr√©diction de la qualit√© de traduction automatique
La traduction automatique est un composant naturel d‚Äôun syst√®me automatique de r√©sum√© cross-lingue de docu-
ments. Malheureusement, bien que des progr√®s importants aient √©t√© r√©alis√©s depuis une d√©cennie, les syst√®mes de
TA restent sujets √† des erreurs qui peuvent d√©grader fortement la qualit√© des r√©sum√©s produits, en introduisant en
particulier des informations erron√©es ou en rendant les phrases g√©n√©r√©es difficiles √† lire. Afin de r√©duire ces effets,
il est int√©ressant de prendre en compte un score jugeant de la qualit√© de la traduction pour filtrer les traductions
incorrectes lors du r√©sum√©.
La pr√©diction de la qualit√© de la traduction a tout d‚Äôabord √©t√© vue comme un probl√®me de classification binaire
pour distinguer les bonnes traductions des mauvaises (Blatz et al., 2003). Des √©tudes plus r√©centes ont estim√© une
valeur continue de score soit au niveau du mot (Raybaud et al., 2009), soit au niveau de la phrase (Raybaud et al.,
2009; Specia et al., 2009). Dans cet article, nous employons des scores calcul√©s au niveau de la phrase, ceux-ci
√©tant plus faciles √† int√©grer dans le processus de s√©lection de phrases pour le r√©sum√©.
Plusieurs classificateurs ont √©t√© construits pour estimer la qualit√© de traduction. Ces mod√®les statistiques ont
√©t√© utilis√©s sur des traductions √©tiquet√©es manuellement comme correctes ou non (Quirk, 2004; Specia et al.,
2009), ou √©tiquet√©es par des m√©triques automatiques comme le taux d‚Äôerreur de mots (Blatz et al., 2003), le score
NIST (Blatz et al., 2003; Specia et al., 2009) ou BLEU (Raybaud et al., 2009). Parmi les diff√©rentes caract√©ris-
tiques utilis√©es pour le calcul des valeurs de qualit√©, on retrouve des traits linguistiques ‚Äî d√©pendant ou non de
ressources telles que des analyseurs syntaxiques ou Wordnet ‚Äî, des mesures de similarit√© entre la phrase source
et la phrase cible, et des caract√©ristiques internes au syst√®me de traduction utilis√©es ‚Äî comme le nombre de tra-
ductions propos√©es par mots sources ou les scores de segments (phrases) des meilleures hypoth√®ses de traduction.
2.2 R√©sum√© automatique fond√© sur les mod√®les de graphes
Ces derni√®res ann√©es, de nombreuses √©valuations ont √©t√© conduites sur la t√¢che du r√©sum√© automatique multi-
document, en particulier dans le cadre des campagnes internationales Document Understanding Conference 1
(DUC) et Text Analysis Conference 2 (TAC) organis√©es par le National Institute of Standards and Technology 3
(NIST). La quasi-totalit√© des approches propos√©es recourent √† des m√©thodes d‚Äôextraction o√π il s‚Äôagit d‚Äôidentifier
les unit√©s textuelles ‚Äî le plus souvent des phrases ‚Äî les plus importantes des documents. Les phrases contenant
les concepts les plus importants sont s√©lectionn√©es puis assembl√©es selon leur degr√© de pertinence afin de g√©n√©rer
les r√©sum√©s. Ce type d‚Äôapproche donne de bons r√©sultats et permet de contourner les probl√©matiques difficiles de
compr√©hension s√©mantique du texte ou de g√©n√©ration de texte en langue naturelle.
Les travaux men√©s jusqu‚Äô√† pr√©sent sur la t√¢che du r√©sum√© automatique multi-document sont bas√©s, entre autres,
sur l‚Äôutilisation du centro√Øde pour la s√©lection de phrases (Radev et al., 2004), sur l‚Äôapprentissage supervis√© des
crit√®res d‚Äôinformativit√© (Wong et al., 2008) ou sur la fusion d‚Äôinformation (Barzilay et al., 1999). Dans cet article,
1. http://duc.nist.gov
2. http://www.nist.gov/tac/
3. http://www.nist.gov
UNE APPROCHE BAS√âE SUR LES GRAPHES POUR LE R√âSUM√â MULTI-DOCUMENT CROSS-LINGUE
nous employons une approche bas√©e sur les mod√®les de graphes introduite dans (Mihalcea, 2004; Erkan & Radev,
2004). Les algorithmes de classement bas√©s sur les graphes tels que PAGERANK (Page et al., 1998) ont √©t√© utilis√©s
avec succ√®s dans les r√©seaux sociaux, l‚Äôanalyse du nombre de citations ou l‚Äô√©tude de la structure du Web. Appliqu√©
au r√©sum√© automatique, ce type d‚Äôapproche sugg√®re de repr√©senter les documents par un graphe d‚Äôunit√©s textuelles
(phrases) inter-connect√©es par des relations issues de calculs de similarit√©. Les phrases sont ensuite s√©lectionn√©es
selon des crit√®res de centralit√© ou de prestige dans le graphe puis assembl√©es pour produire des extraits. Cette
approche a deux principaux avantages. Premi√®rement, contrairement √† la plupart des autres m√©thodes, elle ne
n√©cessite pas de donn√©es d‚Äôapprentissage. Deuxi√®mement, du fait qu‚Äôelle se base sur des traitements linguistiques
minimaux (segmentation en phrases et similarit√© inter-phrases), cette approche est facilement adaptable √† d‚Äôautres
langues (Mihalcea & Tarau, 2005).
2.3 R√©sum√© automatique cross-lingue
Quelques √©tudes se sont r√©cemment int√©ress√©es √† la probl√©matique du r√©sum√© automatique cross-lingue. Deux
solutions simples √† ce probl√®me consistent soit √† traduire les documents avant la phase d‚Äôextraction, soit √† traduire
les r√©sum√©s g√©n√©r√©s. Cette seconde approche est g√©n√©ralement pr√©f√©r√©e √† la premi√®re car la traduction au pr√©alable
des documents rend le processus de s√©lection de phrases plus risqu√© de part les erreurs potentiellement introduites
par le syst√®me de TA. OraÃÜsan & Chiorean (2008) ont ainsi propos√© d‚Äôutiliser la m√©thode Maximal Marginal
Relevance (MMR) (Carbonell & Goldstein, 1998) pour produire des r√©sum√©s d‚Äôactualit√©s exprim√©s en roumain et
ensuite de les traduire automatiquement en anglais.
Plus r√©cemment, Wan et al. (2010) se sont int√©ress√©s au r√©sum√© automatique mono-document, depuis l‚Äôanglais
vers le chinois, en employant des m√©thodes supervis√©es pour estimer la qualit√© de traduction automatique. Leur
√©tude a montr√© que la prise en compte de scores de qualit√© de traduction permet d‚Äôam√©liorer √† la fois le contenu
et la lisibilit√© des r√©sum√©s g√©n√©r√©s. Dans notre article, nous utilisons une approche similaire en nous int√©ressant
cette fois au r√©sum√© automatique multi-document. Contrairement aux travaux de Wan et al., notre approche utilise
un algorithme non supervis√© et ind√©pendant de la langue pour s√©lectionner des phrases (Mihalcea & Tarau, 2005).
De plus, nous n‚Äôutilisons pas de corpus annot√©s manuellement selon leur qualit√© de traduction mais un indicateur
calcul√© automatiquement √† partir de traductions de r√©f√©rences produites par des humains, ce type de corpus √©tant
long et parfois d√©licat √† construire.
3 Notre m√©thode pour le r√©sum√© cross-lingue
Notre approche pour r√©sumer un ensemble de documents depuis l‚Äôanglais vers le fran√ßais se fait en trois √©tapes.
Chaque phrase est tout d‚Äôabord traduite automatiquement et la qualit√© de la traduction est estim√©e (section 3.1).
Chaque phrase se trouve ensuite √©valu√©e en fonction de son contenu informatif (section 3.2) et de son score de
qualit√© de traduction (section 3.3). Puis, les phrases de plus haut score sont s√©lectionn√©es pour les inclure dans le
r√©sum√© (section 3.4). La figure 1 pr√©sente un aper√ßu de l‚Äôarchitecture de notre m√©thode.
Pond√©ration
 des phrases
R√©sum√©
Phrases Pr√©diction de la G√©n√©ration en 
en anglais qualit√© de TA du r√©sum√© fran√ßais
Traduction 
automatique
FIGURE 1 ‚Äì Architecture de notre syst√®me de r√©sum√© automatique cross-lingue.
ST√âPHANE HUET, FLORIAN BOUDIN ET JUAN-MANUEL TORRES-MORENO
3.1 Pr√©traitement de documents et pr√©diction de la qualit√© de traduction
Chaque document de l‚Äôensemble √† r√©sumer est segment√© en phrases en utilisant la m√©thode PUNKT de d√©tection
de changement de phrases (Kiss & Strunk, 2006) mise en ≈ìuvre dans la bo√Æte √† outils NLTK (Bird & Loper, 2004).
Toutes les phrases en anglais ont √©t√© automatiquement traduites en fran√ßais en utilisant le syst√®me de traduction
de Google 4.
Un score de TA est calcul√© pour chaque phrase pour estimer la justesse et la fluidit√© des phrases g√©n√©r√©es en
fran√ßais. Pour ce faire, nous calculons pour chaque phrase 8 caract√©ristiques, qui donnent des informations sur la
difficult√© de traduction et sur la lisibilit√© des traductions g√©n√©r√©es :
‚Äì la longueur de la phrase source en terme de mots ;
‚Äì le ratio des longueurs des phrases source et cible ;
‚Äì le nombre de signes de ponctuation dans la phrase source ;
‚Äì la proportion des nombres et des signes de ponctuation pr√©sentes dans la phrase source qui sont retrouv√©es dans
la phrase cible ;
‚Äì les perplexit√©s des phrases source et cible calcul√©es √† l‚Äôaide de mod√®le de langue (ML) 5-grammes en avant ;
‚Äì les perplexit√©s des phrases source et cible calcul√©es par des ML bigrammes en arri√®re, i. e. en inversant l‚Äôordre
des mots des phrases.
Ces quatre premi√®res caract√©ristiques sont parmi les traits les plus pertinents mis en exergue dans (Specia et al.,
2009), parmi 84 caract√©ristiques √©tudi√©es ; les quatre derni√®res ont d√©j√† montr√© leur efficacit√© dans le calcul de
mesure de confiance au niveau des mots (Raybaud et al., 2009). Des ML sont construits √† partir des corpus
monolingues du domaine des actualit√©s, rendus disponible pour l‚Äôatelier WMT 2010 (Callison-Burch et al., 2010)
et constitu√©s respectivement de 991 et 325 millions de mots en anglais et en fran√ßais. Les scores de perplexit√©
visent √† estimer la fluidit√©. Contrairement √† d‚Äôautres √©tudes, nous nous sommes concentr√©s sur des caract√©ristiques
simples ne requ√©rant pas de ressources linguistiques comme des analyseurs syntaxiques ou des dictionnaires. En
outre, nous nous sommes restreints √† des scores ne d√©pendant par du syst√®me de traduction utilis√©.
Pour pr√©dire la qualit√© de la traduction, nous avons employ√© la m√©thode -SVR, qui est une extension des s√©para-
teurs √† vaste marge pour faire de la r√©gression et qui a d√©j√† √©t√© utilis√©e dans le m√™me cadre applicatif (Wan et al.,
2010; Raybaud et al., 2009). Nous avons employ√© la librairie LIBSVM (Chang & Lin, 2001), en nous restreignant
aux noyaux gaussiens comme recommand√© par les auteurs. Le mod√®le de r√©gression a deux param√®tres : une erreur
de co√ªt c et le coefficient Œ≥ de la fonction noyau ; leur valeur a √©t√© optimis√©e par recherche par quadrillage et par
validation crois√©e.
Le mod√®le -SVR devrait id√©alement √™tre appris sur un corpus √©tiquet√© manuellement du point de vue de la qualit√©
de traduction. Malheureusement, nous ne connaissons pas de corpus de ce genre ayant une taille suffisante pour
la paire anglais-fran√ßais et la production de jugements de la TA reste un processus tr√®s lent. Nous nous sommes
par cons√©quent tourn√©s vers un indicateur calcul√© automatiquement √† partir de traductions de r√©f√©rence produites
par des humains : le score NIST (Doddington, 2002). Cette m√©trique a en effet d√©j√† √©t√© utilis√©e dans le pass√©
dans le m√™me objectif (Blatz et al., 2003; Specia et al., 2009) et s‚Äôest r√©v√©l√©e plus corr√©l√©e avec des jugements
humains au niveau de la phrase que BLEU (Blatz et al., 2003). Notre corpus d‚Äôapprentissage a √©t√© obtenu √† partir
des traductions de r√©f√©rence fournies dans le domaine des actualit√©s pour l‚àëes ateliers WMT (Callison-Burch et al.,2010) de 2008 √† 2010, ce qui repr√©sente un ensemble de 7 112 phrases. Pour contr√¥ler la qualit√© du mod√®le ainsi
obtenu, nous avons calcul√© la m√©trique MSE (Mean Squared Error) : 1 NN j=1(yj ‚àí yÃÇj)2, N √©tant le nombre de
phrases, yÃÇ la pr√©diction estim√©e par le mod√®le et y la valeur r√©elle. Sur les 2 007 phrases de WMT 2007 gard√©es √†
cette fin, le MSE mesur√© a √©t√© de 0,456.
3.2 Pond√©ration des phrases
Notre syst√®me de r√©sum√© multi-document est fond√© sur un graphe dirig√© G = (V,E) construit pour chaque en-
semble de textes, V √©tant l‚Äôensemble de n≈ìuds et E les arcs (ar√™tes) dirig√©s. Un n≈ìud est ajout√© au graphe pour
chaque phrase de l‚Äôensemble de documents ; les ar√™tes sont d√©finies entre ces n≈ìuds en fonction de la mesure de
similarit√© d√©finie dans (Mihalcea, 2004). Cette mesure d√©termine le nombre de mots communs entre les repr√©sen-
tations lexicales des deux phrases, les mots outils ayant √©t√© au pr√©alable supprim√©s et les autres mots ayant √©t√©
4. http://translate.google.com
UNE APPROCHE BAS√âE SUR LES GRAPHES POUR LE R√âSUM√â MULTI-DOCUMENT CROSS-LINGUE
stemm√©s avec le stemmeur de Porter. Pour √©viter de favoriser les phrases longues, cette valeur est normalis√©e par
les longueurs des phrases. Si freq(w, S) repr√©sente la fr√©quence du mot w dans la phrase S, la similarit√© entre les
phrases Si et Sj est d√©finie par : ‚àë
Sim w‚ààS
freq(w, Si) + freq(w, Sj)
(S i
,Sj
i, Sj) = (1)
log(|Si|) + log(|Sj |)
Les algorithmes de classement bas√©s sur les mod√®les de graphes mettent en ≈ìuvre le concept de recommandation.
Les phrases sont √©valu√©es selon des scores calcul√©s r√©cursivement sur l‚Äôint√©gralit√© du graphe. Dans notre √©tude,
nous utilisons une adaptation de l‚Äôalgorithme PAGERANK de Google (Page et al., 1998) qui inclut les poids des
ar√™tes :
‚àë
p(Vi) = (1‚àí ‚àë Sim(Si, Sj)d) + d√ó p(Vi) (2)
V V
Sk, Si)
j‚ààpred(Vi) k‚ààsucc(Vi)
Sim(
o√π d est un ¬´ facteur d‚Äôamortissement ¬ª (typiquement dans l‚Äôintervalle [0.8, 0.9]), pred(Vi) repr√©sente l‚Äôensemble
des n≈ìuds qui ont une ar√™te en direction de Vi et succ(Vi) l‚Äôensemble des n≈ìuds connect√©s √† Vi par une ar√™te
sortante. La m√©thode employ√©e ici, d√©crite dans (Mihalcea, 2004), est tr√®s similaire au PAGERANK lexical, appel√©
LEXRANK (Erkan & Radev, 2004).
3.3 Inclusion des scores de qualit√© de traduction
Pour prendre en compte l‚Äôaspect cross-lingue, la mesure de similarit√© inter-phrases, d√©finie dans l‚Äô√©quation 1 pour
les phrases d‚Äôorigine en anglais, est modifi√©e pour inclure les scores de qualit√© de traduction :
Sim2(Si, Sj) = Sim(Si, Sj)√ó Prediction(Si) (3)
o√π Prediction(Si) est le score de qualit√© de TA de la phrase Si calcul√©e comme d√©crit en section 3.1. Cette m√©trique
est asym√©trique, contrairement √† celle d√©finie par l‚Äô√©quation 1. Une phrase traduite correctement et fluide voit ainsi
les poids de ses ar√™tes sortantes renforc√©s et jouera par cons√©quent un r√¥le plus central dans le graphe.
Nous avons modifi√© l‚Äôalgorithme de classement afin de tirer profit des sp√©cificit√©s des documents. Comme la
position d‚Äôune phrase au sein d‚Äôun document est un indicateur fort sur l‚Äôimportance de son contenu ‚Äî les articles
de journaux pr√©sentant g√©n√©ralement au d√©but une description concise du sujet ‚Äî le poids des arcs sortant du
n≈ìud correspondant √† la premi√®re phrase a √©t√© doubl√©. En outre, les phrases dupliqu√©es ainsi que les phrases
contenant moins de 5 mots ont √©t√© mises de c√¥t√©.
3.4 G√©n√©ration de r√©sum√©
Bien souvent, les documents regroup√©s sous une th√©matique contiennent des phrases tr√®s similaires, voire m√™me
identiques. Il est donc possible que deux phrases tr√®s redondantes se retrouvent dans un r√©sum√©, d√©gradant √† la
fois sa lisibilit√© et son contenu informatif. Pour pallier ce probl√®me, Carbonell & Goldstein (1998) ont propos√©
la m√©thode d‚Äôassemblage it√©ratif Maximal Marginal Relevance (MMR). Cette technique, probablement la plus
utilis√©e, consiste √† r√©ordonner les phrases en fonction de deux crit√®res qui sont l‚Äôimportance de la phrase et la
redondance par rapport aux phrases d√©j√† s√©lectionn√©es. Le r√©sum√© est ensuite construit it√©rativement par l‚Äôajout
des phrases maximisant l‚Äôinformativit√© tout en minimisant la redondance.
Dans cette √©tude, nous avons utilis√© une approche diff√©rente. Suivant la m√©thode propos√©e dans (Mihalcea &
Tarau, 2005) pour la construction de graphes, aucun arc n‚Äôest ajout√© entre deux n≈ìuds dont la similarit√© exc√®de un
seuil maximal. De fa√ßon √† r√©duire la redondance, une √©tape suppl√©mentaire est ajout√©e lors de la g√©n√©ration des
r√©sum√©s (Genest et al., 2009). Nous g√©n√©rons pour ce faire tous les r√©sum√©s candidats √† partir des combinaisons
des N phrases ayant les meilleurs scores, en veillant √† ce que le nombre total de caract√®res soit optimal (i. e. en
dessous d‚Äôun seuil donn√© et qu‚Äôil soit impossible d‚Äôajouter une autre phrase sans d√©passer ce seuil). Le r√©sum√©
ST√âPHANE HUET, FLORIAN BOUDIN ET JUAN-MANUEL TORRES-MORENO
retenu au final est celui poss√©dant le score global le plus √©lev√©, ce score √©tant calcul√© comme le produit du score de
la diversit√© du r√©sum√© ‚Äî estim√© par le nombre de n-grammes diff√©rents ‚Äî et de la somme des scores des phrases.
Afin d‚Äôam√©liorer la lisibilit√© du r√©sum√© produit, les phrases sont tri√©es dans l‚Äôordre chronologique de publication
des documents o√π ils apparaissent, ce qui maximise la coh√©rence temporelle ; si deux phrases sont extraites √† partir
d‚Äôun m√™me document, l‚Äôordre original du document est conserv√©.
4 R√©sultats
Cette section d√©crit les donn√©es utilis√©es, les m√©triques d‚Äô√©valuation et les r√©sultats de notre syst√®me.
4.1 Cadre exp√©rimental
Nous avons employ√© dans notre √©tude les ensembles de documents mis √† disposition pour l‚Äô√©valuation DUC 2004,
ce qui repr√©sente 50 ensembles de documents en anglais. Chaque ensemble traite d‚Äôune m√™me th√©matique et com-
porte en moyenne 10 articles de journaux produits par Associated Press ou le New York Times. La t√¢che consiste √†
g√©n√©rer des r√©sum√©s d‚Äôau plus 665 caract√®res ‚Äî incluant les caract√®res alphanum√©riques, les espaces et les ponc-
tuations ‚Äî contenant l‚Äôessentiel du contenu de l‚Äôensemble de documents correspondants. Nous avons effectu√©
sur ces donn√©es une √©valuation automatique du contenu. Une √©valuation manuelle de la lisibilit√© a √©galement √©t√©
men√©e sur un √©chantillon constitu√© de 16 ensembles de documents tir√©s al√©atoirement.
4.1.1 √âvaluation automatique
La plupart des m√©thodes d‚Äô√©valuation automatique op√®rent en comparant les r√©sum√©s g√©n√©r√©s avec un ou plusieurs
r√©sum√©s de r√©f√©rence. La m√©trique que nous avons employ√©e ici est ROUGE (Recall-Oriented Understudy for Gis-
ting Evaluation), dont on sait qu‚Äôelle est bien corr√©l√©e avec les jugements humains (Lin, 2004). ROUGE correspond
en fait √† plusieurs mesures, calcul√©es √† partir du nombre de n-grammes commun entre le r√©sum√© candidat et le(s)
r√©sum√©(s) de r√©f√©rence. Nous avons calcul√© trois m√©triques au cours de nos exp√©riences : ROUGE-1 (bas√©e sur les
unigrammes), ROUGE-2 (bigrammes) et ROUGE-SU4 (bigrammes √† trou, i. e. des couples de deux mots contenant
au plus quatre mots entre eux) 5.
Quatre r√©sum√©s de r√©f√©rence en anglais √©taient fournis pour chacun des ensembles de documents de DUC 2004.
Pour √©valuer notre m√©thode, nous avons demand√© √† trois annotateurs de traduire les r√©sum√©s disponibles pour le
sous-ensemble de 16 groupes de documents, en veillant √† ce que chaque phrase du r√©sum√© soit traduite phrase
par phrase sans introduire d‚Äôinformation suppl√©mentaire comme la g√©n√©ration d‚Äôanaphores, la d√©sambiguisation
des noms propres ou la r√©duction des informations redondantes. 64 r√©sum√©s de r√©f√©rence ont √©t√© ainsi produits,
chaque annotateur traduisant en moyenne un r√©sum√© en 15 minutes.
L‚Äô√©valuation par ROUGE √©tant ici r√©alis√©e dans un cadre diff√©rent des t√¢ches habituelles ‚Äî produisant des r√©sum√©s
en anglais √† partir de documents exprim√©s dans la m√™me langue ‚Äî, nous avons effectu√© quelques modifications.
Aucune contrainte stricte n‚Äôa √©t√© impos√©e sur la taille des r√©sum√©s traduits produits en fran√ßais. En revanche, nous
avons fait en sorte que notre algorithme de g√©n√©ration construise des r√©sum√©s pour lesquelles la longueur totale
des phrases correspondantes en anglais respecte la contrainte impos√©e √† DUC 2004 sur le nombre de caract√®res.
La longueur des r√©sum√©s de r√©f√©rence en fran√ßais se trouve ainsi accrue de 25 % en moyenne par rapport aux
r√©sum√©s correspondants en anglais. Notons enfin que le stemmer de Porter utilis√© dans l‚Äô√©valuation ROUGE a √©t√©
adapt√© au fran√ßais.
4.1.2 √âvaluation manuelle
L‚Äô√©valuation de la qualit√© linguistique des r√©sum√©s a √©t√© effectu√©e selon un protocole similaire √† celui utilis√© lors
des campagnes DUC. Nous avons √©valu√© la lisibilit√© des r√©sum√©s sur une √©chelle de 1 √† 5, o√π 5 est attribu√© aux
r√©sum√©s ¬´ faciles √† lire ¬ª et 1 aux r√©sum√©s ¬´ difficiles √† lire ¬ª. Cinq annotateurs ont particip√© √† cette exp√©rience.
5. Nous avons utilis√© la version 1.5.5 de ROUGE avec les param√®tres par d√©faut indiqu√©s pour DUC 2004.
UNE APPROCHE BAS√âE SUR LES GRAPHES POUR LE R√âSUM√â MULTI-DOCUMENT CROSS-LINGUE
Afin de comparer notre approche, nous avons g√©n√©r√© deux r√©sum√©s pour chaque ensemble de documents, i. e. pour
chacune des th√©matiques. Le premier r√©sum√© est produit par la m√©thode que nous proposons tandis que le second
(baseline) est obtenu en traduisant directement un r√©sum√© en fran√ßais (obtenu par la fonction de pond√©ration
d√©crite en section 3.2). La t√¢che qui leur a √©t√© confi√©e √©tait d‚Äôattribuer une note aux deux r√©sum√©s d‚Äôune m√™me
th√©matique, l‚Äôordre d‚Äôapparition des r√©sum√©s √©tant al√©atoire afin d‚Äô√©viter tout biais.
4.2 Exp√©riences monolingues
Les performances de notre m√©thode ont tout d‚Äôabord √©t√© √©valu√©es sur une t√¢che de r√©sum√© monolingue. Le ta-
bleau 1 indique les scores d‚Äô√©valuation automatique obtenus sur l‚Äôensemble des donn√©es de DUC 2004 pour
diff√©rentes m√©thodes : le plus haut score atteint lors de la campagne en 2004 (ligne 1), le score obtenu avec la
m√©thode GRAPH-SUM d√©crite en section 3.2 bas√©e sur les graphes (ligne 2) et un score calcul√© pour une m√©thode
na√Øve prenant la premi√®re phrase des documents les plus r√©cents de chaque ensemble √† traduire. L‚Äôapproche ba-
s√©e sur les graphes obtient de bons r√©sultats, la diff√©rence avec le meilleur syst√®me n‚Äô√©tant pas statistiquement
significative 6.
Syst√®me ROUGE-1 Rang ROUGE-2 Rang ROUGE-SU4 Rang
1er syst√®me 0,38244‚Ä† 1 0,09218‚Ä† 1 0,13323‚Ä† 1
GRAPH-SUM 0,38052‚Ä† 2 0,08566‚Ä† 4 0,13114‚Ä† 3
M√©thode na√Øve 0,32381 26 0,06406 25 0,10291 29
TABLE 1 ‚Äì Scores ROUGE moyens mesur√©s sur les donn√©es de DUC 2004 et rangs obtenus par rapport aux
35 participants de la campagne. Les scores indiqu√©s par ‚Ä† sont statistiquement significatifs par rapport au mod√®le
de base (œÅ < 0.001 avec un t-test de Student).
4.3 Exp√©riences cross-lingues
Dans cette seconde s√©rie d‚Äôexp√©riences, nous √©valuons notre approche pour le r√©sum√© automatique multi-document
cross-lingue. La premi√®re partie de cette √©valuation est r√©alis√©e automatiquement √† l‚Äôaide des mesures ROUGE et
concerne le contenu des r√©sum√©s. Il s‚Äôagit d‚Äô√©valuer si les r√©sum√©s produits contiennent les informations les plus
importantes des documents sources. Les r√©sultats de r√©f√©rence sont obtenus en traduisant le r√©sum√© en anglais
produit par l‚Äôapproche bas√©e sur les mod√®les de graphes (m√©thode GRAPH-SUM). Les scores ROUGE calcul√©s
avec cette m√©thode sont pr√©sent√©s √† la ligne 1 du tableau 2. En utilisant notre m√©thode faisant intervenir la qualit√©
des traductions automatiques (ligne 2), nous observons une l√©g√®re am√©lioration en terme de ROUGE-2 et ROUGE-
SU4. Cependant, cette √©volution des scores n‚Äôest pas statistiquement significative. Ceci peut s‚Äôexpliquer par le
fait que notre m√©thode favorise les phrases dont la qualit√© de TA est bonne. Ainsi des phrases ayant un contenu
informationnel plus faible peuvent √™tre introduites dans le r√©sum√©, ce qui limite l‚Äôam√©lioration des r√©sultats.
Syst√®me ROUGE-1 ROUGE-2 ROUGE-SU4
M√©thode de r√©ference 0,39704 0,10249 0,13711
Notre m√©thode 0,39624 0,10687 0,13877
TABLE 2 ‚Äì Scores ROUGE moyens calcul√©s sur le sous-ensemble de DUC 2004 traduit en fran√ßais.
La seconde partie de cette √©valuation concerne la qualit√© linguistique des r√©sum√©s g√©n√©r√©s. Il s‚Äôagit d‚Äô√©valuer
manuellement si les r√©sum√©s produits sont lisibles mais √©galement compr√©hensibles. Le tableau 3 montre les
r√©sultats de l‚Äô√©valuation manuelle obtenus sur le sous-ensemble de 16 groupes de documents. Le score moyen
donn√© par chaque annotateur est √©galement indiqu√©. Tous les annotateurs ont jug√© que notre m√©thode conduisait √†
une am√©lioration de la lisibilit√© des r√©sum√©s produits, ce qui montre ainsi l‚Äôint√©r√™t d‚Äôutiliser des scores de qualit√©
de TA pour am√©liorer la qualit√© linguistique des r√©sum√©s.
6. Le t-test de Student est de œÅ = 0.77 pour ROUGE-1, œÅ = 0.17 pour ROUGE-2 et œÅ = 0.57 pour ROUGE-SU4.
ST√âPHANE HUET, FLORIAN BOUDIN ET JUAN-MANUEL TORRES-MORENO
N√©anmoins, il faut noter que les scores moyens sont relativement bas. Ceci indique que les r√©sum√©s g√©n√©r√©s par
notre m√©thode, bien qu‚Äô√©tant meilleurs du point de vue de la lisibilit√© par rapport √† l‚Äôapproche de r√©f√©rence, ne sont
pas encore satisfaisants. Un exemple des sorties de notre syst√®me de r√©sum√© automatique est donn√© en annexe.
Plusieurs types d‚Äôerreurs ont √©t√© identifi√©es comme r√©currentes. La qualit√© de la TA est d√©pendante de la difficult√©
de la phrase √† traduire. Ainsi, par des traitements simples comme la suppression des r√©f√©rences temporelles, la
r√©solution des acronymes ou la normalisation des noms propres, nous esp√©rons pouvoir r√©duire la difficult√© des
phrases sources et par cons√©quent r√©duire le nombre d‚Äôerreurs de traduction.
Annotateur Lisibilit√©
M√©thode de r√©f√©rence Notre m√©thode
Annotateur 1 2,44 2,50
Annotateur 2 1,56 1,63
Annotateur 3 1,75 2,31
Annotateur 4 3,06 3,31
Annotateur 5 1,50 1,63
Moyenne 2,06 2,28
TABLE 3 ‚Äì Scores moyens de lisibilit√© de notre m√©thode compar√©s avec une approche standard bas√©e sur les
graphes. Les scores varient selon une √©chelle de 1 √† 5, 5 √©tant le plus haut score possible.
5 Conclusions et perspectives
Dans cet article, nous avons pr√©sent√© une approche bas√©e sur les mod√®les de graphes pour le r√©sum√© automatique
multi-document cross-lingue. Nous avons propos√© d‚Äôintroduire des scores de qualit√© de traduction automatique au
moment de l‚Äô√©tape de construction du graphe repr√©sentant les unit√©s textuelles, un algorithme de classement par
popularit√© √©tant ensuite charg√© de s√©lectionner les phrases traduites qui sont √† la fois les plus informatives mais
√©galement les plus lisibles. Cette approche a √©t√© √©valu√©e sur un corpus de 16 ensembles de documents traduits
manuellement parmi les documents mis √† disposition dans le cadre de la campagne d‚Äô√©valuation internationale
DUC 2004. Les r√©sultats exp√©rimentaux montrent que notre m√©thode am√©liore sensiblement la lisibilit√© (i. e. la
qualit√© linguistique) des r√©sum√©s g√©n√©r√©s tout en maintenant un contenu informatif au niveau de l‚Äô√©tat de l‚Äôart.
En perspectives de nos travaux, nous souhaitons dans un premier temps mener une √©valuation plus compl√®te en
produisant des r√©sum√©s de r√©f√©rence sur l‚Äôensemble des donn√©es de la comp√©tition DUC 2004 et en √©tendant
l‚Äô√©valuation √† d‚Äôautres langues. Ceci permettra de renforcer l‚Äôimportance des r√©sultats que nous avons obtenus
mais aussi d‚Äôenvisager un apprentissage supervis√© de la r√©partition entre l‚Äôinformativit√© et √† la lisibilit√© des phrases.
Dans un deuxi√®me temps, nous souhaitons travailler sur la r√©√©criture des phrases sources et en √©tudier l‚Äôimpact
sur la qualit√© de traduction, l‚Äôid√©e √©tant de simplifier au maximum les phrases sources √† l‚Äôaide de traitement
linguistiques comme la r√©solution d‚Äôanaphores afin de faciliter le travail du syst√®me de TA. Nous souhaitons
√©galement suivre la piste de la fusion non supervis√©e de phrases (Filippova, 2010) afin de g√©n√©rer des phrases
courtes et linguistiquement simples. Une derni√®re perspective que nous voulons √©tudier concerne l‚Äôutilisation de
notre propre mod√®le de traduction automatique, ce qui permettra √† la fois d‚Äôadapter ce syst√®me pour le type de
documents √† r√©sumer et de prendre en compte de nouveaux indices pour pr√©dire la qualit√© de la traduction.
R√©f√©rences
C. BANEA, A. MOSCHITTI, S. SOMASUNDARAN & F. M. ZANZOTTO, Eds. (2010). TextGraphs-5 Workshop.
Uppsala, Su√®de.
BARZILAY R., MCKEOWN K. R. & ELHADAD M. (1999). Information fusion in the context of multi-document
summarization. In ACL, College Park, MD, USA.
BIRD S. & LOPER E. (2004). NLTK : The natural language toolkit. In ACL, Barcelone, Espagne.
UNE APPROCHE BAS√âE SUR LES GRAPHES POUR LE R√âSUM√â MULTI-DOCUMENT CROSS-LINGUE
BLATZ J., FITZGERALD E., FOSTER G., GANDRABUR S., GOUTTE C., KULESZA A., SANCHIS A. & UEF-
FING N. (2003). Confidence Estimation for Machine Translation. Rapport interne, Johns Hopkins University,
Batimore, MD, USA.
CALLISON-BURCH C., KOEHN P., MONZ C., PETERSON K., PRZYBOCKI M. & ZAIDAN O. (2010). Findings
of the 2010 joint workshop on statistical machine translation and metrics for machine translation. In Workshop
on Statistical Machine Translation and Metrics (WMT), Uppsala, Su√®de.
CARBONELL J. & GOLDSTEIN J. (1998). The use of MMR, diversity-based reranking for reordering documents
and producing summaries. In SIGIR, Melbourne, Australie.
CHANG C.-C. & LIN C.-J. (2001). LIBSVM : a library for support vector machines. Software available at
http://www.csie.ntu.edu.tw/~cjlin/libsvm.
DODDINGTON G. (2002). Automatic evaluation of machine translation quality using n-gram co-occurrence
statistics. In HLT, San Diego, CA, USA.
ERKAN G. & RADEV D. (2004). LexRank : Graph-based lexical centrality as salience in text summarization.
JAIR, 22(1), 457‚Äì479.
FILIPPOVA K. (2010). Multi-sentence compression : Finding shortest paths in word graphs. In Coling, P√©kin,
Chine.
GENEST P., LAPALME G., NERIMA L. & WEHRLI E. (2009). A symbolic summarizer with 2 steps of sentence
selection for TAC 2009. In TAC Workshop, Gaithersburg, MD, USA.
KISS T. & STRUNK J. (2006). Unsupervised multilingual sentence boundary detection. Computational Linguis-
tics, 32(4), 485‚Äì525.
LIN C.-Y. (2004). Rouge : A package for automatic evaluation of summaries. In ACL Workshop on Text
Summarization Branches Out, Barcelone, Espagne.
MIHALCEA R. (2004). Graph-based ranking algorithms for sentence extraction, applied to text summarization.
In ACL, Barcelone, Espagne.
MIHALCEA R. & TARAU P. (2005). A language independent algorithm for single and multiple document
summarization. In IJCNLP, Jeju Island, Cor√©e du Sud.
ORAÃÜSAN C. & CHIOREAN O. A. (2008). Evaluation of a cross-lingual romanian-english multi-document sum-
mariser. In LREC.
PAGE L., BRIN S., MOTWANI R. & WINOGRAD T. (1998). The pagerank citation ranking : Bringing order to
the web. Rapport interne, Stanford Digital Library Technologies Project.
QUIRK C. B. (2004). Training a sentence-level machine translation confidence measure. In LREC, Lisbonne,
Portugal.
RADEV D., JING H., STY M. & TAM D. (2004). Centroid-based summarization of multiple documents. Infor-
mation Processing & Management, 40(6), 919‚Äì938.
RAYBAUD S., LANGLOIS D. & SMA√èLI K. (2009). Efficient combination of confidence measures for machine
translation. In Interspeech, Brighton, UK.
SPECIA L., CANCEDDA N., DYMETMAN M., TURCHI M. & CRISTIANINI N. (2009). Estimating the sentence-
level quality of machine translation systems. In EAMT, Barcelone, Espagne.
WAN X., LI H. & XIAO J. (2010). Cross-language document summarization based on machine translation
quality prediction. In ACL, Uppsala, Su√®ede.
WONG K.-F., WU M. & LI W. (2008). Extractive summarization using supervised and semi-supervised lear-
ning. In Coling, Manchester, UK.
ST√âPHANE HUET, FLORIAN BOUDIN ET JUAN-MANUEL TORRES-MORENO
Annexe
M√©thode de r√©f√©rence (Score de lisibilit√© moyenne de 2,6)
Leaders de l‚Äôopposition du prince Norodom Ranariddh et Sam Rainsy, invoquant des menaces de Hun Sen √†
l‚Äôarrestation de l‚Äôopposition, apr√®s deux tentatives pr√©sum√©es sur sa vie, a dit qu‚Äôils ne pouvaient pas n√©gocier
librement au Cambodge et a appel√© √† des pourparlers √† la r√©sidence de Sihanouk √† P√©kin. (Opposition leaders Prince
Norodom Ranariddh and Sam Rainsy, citing Hun Sen‚Äôs threats to arrest opposition figures after two alleged attempts on his life, said they could not negotiate
freely in Cambodia and called for talks at Sihanouk‚Äôs residence in Beijing.) Le parti de Hun Sen a r√©cemment demand√© √† Ranariddh
pour retourner √† la table des n√©gociations et a d√©clar√© qu‚Äôil √©tait dispos√© √† faire une ‚Äúconcession appropri√©es‚Äù pour
sortir de l‚Äôimpasse de former un gouvernement. (Hun Sen‚Äôs party recently called on Ranariddh to return to the negotiation table and said
it was willing to make an ‚Äúappropriate concession‚Äù to break the deadlock over forming a government.) La semaine derni√®re, Hun Sen Parti du
peuple cambodgien et le parti Ranariddh FUNCINPEC ont convenu de former une coalition qui laisserait Hun
Sen comme Premier ministre seul et faire le prince pr√©sident de l‚ÄôAssembl√©e nationale. (Last week, Hun Sen‚Äôs Cambodian
People‚Äôs Party and Ranariddh‚Äôs FUNCINPEC party agreed to form a coalition that would leave Hun Sen as sole prime minister and make the prince president of
the National Assembly.)
Notre m√©thode (Score de lisibilit√© moyenne de 3,2)
Le parti au pouvoir a soutenu l‚Äôaction de la police dans sa d√©claration, en notant que les biens publics ont √©t√©
endommag√©s par des manifestants et que des grenades ont √©t√© lanc√©es sur la maison de Hun Sen apr√®s Sam Rainsy
a sugg√©r√© dans un discours que le gouvernement am√©ricain devrait tirer des missiles de croisi√®re √† Hun Sen. (The
ruling party supported the police action in its statement, noting that public property was damaged by protesters and that grenades were thrown at Hun Sen‚Äôs
home after Sam Rainsy suggested in a speech that the U.S. government should fire cruise missiles at Hun Sen.) Politiciens cambodgiens a exprim√©
l‚Äôespoir lundi qu‚Äôun nouveau partenariat entre les parties de l‚Äôhomme fort Hun Sen et son rival, le prince Norodom
Ranariddh, dans un gouvernement de coalition ne mettrait pas fin √† plus de violence. (Cambodian politicians expressed hope
Monday that a new partnership between the parties of strongman Hun Sen and his rival, Prince Norodom Ranariddh, in a coalition government would not end
in more violence.) Le roi Norodom Sihanouk a salu√© mardi les accords sur le Cambodge les deux principaux partis
politiques pr√©c√©demment am√®re rivaux pour former un gouvernement de coalition dirig√© par l‚Äôhomme fort Hun
Sen. (King Norodom Sihanouk on Tuesday praised agreements by Cambodia‚Äôs top two political parties previously bitter rivals to form a coalition government
led by strongman Hun Sen.)
TABLE 4 ‚Äì Example de r√©sum√©s en fran√ßais g√©n√©r√© pour l‚Äôensemble D30001T de DUC 2004 par la m√©thode de
r√©f√©rence et notre approche.
