<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Comparaison et combinaison d&#8217;approches pour la portabilit&#233; vers une nouvelle langue d&#8217;un syst&#232;me de compr&#233;hension de l&#8217;oral</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin - 1er juillet 2011 
</p>
<p>Comparaison et combinaison d&#8217;approches pour la portabilit&#233; vers une nouvelle 
langue d&#8217;un syst&#232;me de compr&#233;hension de l&#8217;oral  
</p>
<p>Bassam Jabaian 
1,2
</p>
<p>, Laurent Besacier 
1
, Fabrice Lef&#232;vre 
</p>
<p>2 
</p>
<p> 
</p>
<p>(1)  LIG, University Joseph Fourier, Grenoble - France 
(2) LIA, University of Avignon, Avignon - France 
</p>
<p> 
</p>
<p>{bassam.jabaian,laurent.besacier}@imag.fr , fabrice.lefevre@univ-avignon.fr 
</p>
<p>R&#233;sum&#233; 
</p>
<p>Dans cet article, nous proposons plusieurs approches pour la portabilit&#233; du module de compr&#233;hension de la parole (SLU) 
</p>
<p>d&#8217;un syst&#232;me de dialogue d&#8217;une langue vers une autre. On montre que l&#8217;utilisation des traductions automatiques 
statistiques (SMT) aide &#224; r&#233;duire le temps et le cout de la portabilit&#233; d&#8217;un tel syst&#232;me d&#8217;une langue source vers une 
langue cible. Pour la tache d&#8217;&#233;tiquetage s&#233;mantique on propose d&#8217;utiliser soit les champs al&#233;atoires conditionnels (CRF), 
soit l&#8217;approche &#224; base de s&#233;quences (PH-SMT). Les r&#233;sultats exp&#233;rimentaux montrent l&#8217;efficacit&#233; des m&#233;thodes 
propos&#233;es pour une portabilit&#233; rapide du SLU vers une nouvelle langue. On propose aussi deux m&#233;thodes pour accro&#238;tre 
</p>
<p>la robustesse du SLU aux erreurs de traduction. Enfin on montre que la combinaison de ces approches r&#233;duit les erreurs 
</p>
<p>du syst&#232;me. Ces travaux sont motiv&#233;s par la disponibilit&#233; du corpus MEDIA fran&#231;ais et de la traduction manuelle vers 
</p>
<p>l&#8217;italien d&#8217;une sous partie de ce corpus.   
</p>
<p>Abstract  
</p>
<p>In this paper we investigate several approaches for language portability of the spoken language understanding (SLU) 
</p>
<p>module of a dialogue system. We show that the use of statistical machine translation (SMT) can reduce the time and the 
</p>
<p>cost of porting a system from a source to a target language. For conceptual decoding we propose to use even conditional 
</p>
<p>random fields (CRF) or phrase based statistical machine translation PB-SMT). The experimental results show the 
</p>
<p>efficiency of the proposed methods for a fast and low cost SLU language portability. Also we proposed two methods to 
</p>
<p>increase SLU robustness to translation errors. Overall we show that the combination of all these approaches reduce the 
</p>
<p>concept error rate. This work was motivated by the availability of the MEDIA French corpus and the manual translation 
</p>
<p>of a subset of this corpus into Italian.  
</p>
<p>Mots-cl&#233;s : Syst&#232;me de dialogue, compr&#233;hension de la parole, portabilit&#233; &#224; travers les langues, traduction automatique 
statistique  
</p>
<p>Keywords: Spoken Dialogue Systems, Spoken Language Understanding, Language Portability, Statistical Machine 
Translation. 
</p>
<p> </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE 
</p>
<p> 
</p>
<p>1 Introduction 
</p>
<p>La portabilit&#233; d&#8217;un syst&#232;me de dialogue d&#8217;une langue vers une autre est une t&#226;che difficile qui a fait l&#8217;objet, 
r&#233;cemment, de plusieurs recherches. Certains composants d&#8217;un syst&#232;me de dialogue, tel que le gestionnaire de 
dialogue, sont relativement ind&#233;pendants de la langue, ce qui n&#8217;affectent pas le processus de portabilit&#233;. 
Cependant, d&#8217;autres modules tel que le module de compr&#233;hension automatique de la parole (Spoken Language 
Understanding, SLU), doivent &#234;tre r&#233;adapt&#233;s pour chaque nouvelle langue cible consid&#233;r&#233;e. Dans cette &#233;tude, 
</p>
<p>nous nous int&#233;ressons particuli&#232;rement &#224; la portabilit&#233; d&#8217;un syst&#232;me de compr&#233;hension automatique de la parole 
vers une nouvelle langue. 
</p>
<p>Des travaux r&#233;cents ont propos&#233; d&#8217;utiliser des m&#233;thodes stochastiques pour la compr&#233;hension automatique de la 
parole. Ces m&#233;thodes sont des alternatives efficaces aux m&#233;thodes &#224; base de r&#232;gles; elles r&#233;duisent les besoins en 
</p>
<p>expertise humaine tout en ayant la capacit&#233; de produire efficacement des r&#233;seaux d'hypoth&#232;ses ou des listes de 
</p>
<p>N-meilleures (N-best) (Suenderman, Liscombe, 2009) (Hahn, Lehnen, Raymond, Ney, 2008) (Raymond, 
</p>
<p>Riccardi, 2007) (Wang, Acero, 2006) (Schwartz, Miller, Stallard, Makhoul, 1996). L&#8217;apprentissage de tels 
mod&#232;les n&#233;cessite un corpus annot&#233; qui repr&#233;sente une couverture compl&#232;te de la s&#233;mantique du domaine. Le 
</p>
<p>portage d'un tel mod&#232;le vers une nouvelle langue consiste &#224; transf&#233;rer les connaissances pr&#233;sentes dans le corpus 
</p>
<p>annot&#233; en langue source vers une nouvelle langue avec un minimum de temps et d'effort humain. Par la suite, 
</p>
<p>nous nommerons &#171;langue source &#187; la langue d&#8217;origine du syst&#232;me NLU et &#171; langue cible &#187;, la langue vers 
laquelle le syst&#232;me doit &#234;tre port&#233;. 
</p>
<p>R&#233;cemment, quelques &#233;tudes ont montr&#233; que l'utilisation de la traduction automatique &#224; diff&#233;rents niveaux du 
</p>
<p>processus de compr&#233;hension peut aider au portage d&#8217;un syst&#232;me SLU vers une nouvelle langue (Suenderman, 
Liscombe, 2009) (Servan, Camelin, Raymond, Bechet, De Mori, 2010) (Lef&#232;vre, Mairesse, Young, 2010) 
</p>
<p>(Jabaian, Besacier, Lef&#232;vre, 2010). Par exemple, dans (Suenderman, Liscombe, 2009) les auteurs proposent de 
</p>
<p>traduire automatiquement les donn&#233;es de la langue source vers la langue cible, puis de re-apprendre une 
</p>
<p>grammaire stochastique pour effectuer l'interpr&#233;tation dans la langue cible. Une autre possibilit&#233; est de 
</p>
<p>consid&#233;rer que la s&#233;mantique d'un domaine est ind&#233;pendante de la langue. Dans ce cas, une solution est de 
</p>
<p>traduire le corpus d'apprentissage vers la langue cible et d&#8217;inf&#233;rer les balises s&#233;mantiques associ&#233;es au corpus 
traduit. Un syst&#232;me SLU stochastique peut ensuite &#234;tre re-entra&#238;n&#233; sur ce nouveau corpus annot&#233; en langue cible. 
</p>
<p>Comme d&#233;crit dans (Servan, Camelin, Raymond, Bechet, De Mori, 2010), les phrases du corpus d&#8217;apprentissage 
sont compos&#233;es d'un ou plusieurs segments annot&#233;s s&#233;mantiquement. Traduire le corpus d'apprentissage en 
</p>
<p>conservant l&#8217;information de segmentation en segments permet alors un appariement direct des segments traduits 
avec les &#233;tiquettes s&#233;mantiques. Les auteurs de (Servan, Camelin, Raymond, Bechet, De Mori, 2010) montrent 
</p>
<p>qu&#8217;un portage du fran&#231;ais vers l&#8217;italien est possible en utilisant cette approche, avec une traduction manuelle ou 
automatique. Le portage de l'annotation est encore moins difficile lorsqu&#8217;on utilise des m&#233;thodes qui n&#8217;ont pas 
besoin d&#8217;annotation s&#233;mantique au niveau mot ou segment. Par exemple, dans (Lef&#232;vre, Mairesse, Young, 
2010), le mod&#232;le propos&#233; ne n&#233;cessite pas d'informations d'alignement. 
</p>
<p>Le choix d'une approche d&#233;pend de consid&#233;rations techniques et &#233;galement des caract&#233;ristiques du domaine ainsi 
</p>
<p>que des donn&#233;es disponibles. Disposer de donn&#233;es manuellement traduites ou annot&#233;es, disposer d&#8217;annotateurs 
ou d&#8217;outils sp&#233;cifiques pour la langue cible, peut faire la diff&#233;rence quant au choix de l'approche. Dans cet 
article, nous proposons plusieurs approches pour le portage d&#8217;un syst&#232;me de compr&#233;hension automatique de la 
parole vers une nouvelle langue. La langue source est le fran&#231;ais &#233;tant donn&#233; que nous travaillons sur le corpus 
</p>
<p>MEDIA (Bonneau -Maynard, Rosset, Ayache, Kuhn, Mostefa, 2005) et la langue cible consid&#233;r&#233;e est l&#8217;italien 
puisque nous disposons &#233;galement, au d&#233;part, d&#8217;une partie du corpus MEDIA traduite en italien. Nous sommes 
conscients de la proximit&#233; des langues source et cibles dans cette &#233;tude, mais ce choix est guid&#233; par les donn&#233;es 
</p>
<p>disponibles au d&#233;part. Le portage vers l&#8217;arabe est aussi envisag&#233; et fait l&#8217;objet de travaux en cours. Les 
approches propos&#233;es dans cet article sont compl&#232;tement automatiques et sans aucune supervision humaine lors 
</p>
<p>du processus de portage.  
</p>
<p>Plus pr&#233;cis&#233;ment, le but de cet article est de : 
</p>
<p>- proposer et &#233;valuer diff&#233;rentes approches utilisant la traduction automatique pour porter un syst&#232;me 
</p>
<p>SLU vers une nouvelle langue, 
</p>
<p>- consid&#233;rant ensuite la meilleure approche obtenue, accro&#238;tre sa robustesse aux erreurs de traduction. 
</p>
<p>Dans ces travaux, les mod&#232;les utilis&#233;s sont les champs al&#233;atoires conditionnels (Conditional Random Fields, 
</p>
<p>CRF) pour la compr&#233;hension automatique et l&#8217;approche &#224; base de s&#233;quences (phrase-based statistical machine </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMPARAISON ET COMBINAISON D&#8217;APPROCHES POUR LA PORTABILITE VERS UNE NOUVELLE 
LANGUE D&#8217;UN SYSTEME DE COMPREHENSION DE L&#8217;ORAL 
</p>
<p>translation) pour la traduction automatique. Les CRF (Lafferty, McCallum, Pereira, 2001) sont connus pour &#234;tre 
</p>
<p>tr&#232;s performants sur des t&#226;ches d&#8217;&#233;tiquetage temporel (annotation en entit&#233;s nomm&#233;es, &#233;tiquetage syntaxique, 
etc). Ils n&#233;cessitent un corpus annot&#233; au niveau mots. Pour porter notre syst&#232;me vers une nouvelle langue, nous 
</p>
<p>avons propos&#233; plusieurs m&#233;thodes qui diff&#232;rent selon le moment o&#249; est utilis&#233; le module de traduction. En effet, 
</p>
<p>un syst&#232;me de compr&#233;hension peut &#234;tre port&#233; soit au niveau du test (TestOnSource), en conservant le syst&#232;me 
</p>
<p>SLU en langue source et en traduisant simplement les donn&#233;es de test en langue cible vers la langue source. La 
</p>
<p>seconde possibilit&#233; consiste &#224; porter le syst&#232;me au niveau de l&#8217;apprentissage (TrainOnTarget) en construisant un 
nouvel &#233;tiqueteur s&#233;mantique dans la langue cible. Pour cela, nous traduisons automatiquement l&#8217;int&#233;gralit&#233; du 
corpus d'apprentissage de la langue source vers la langue cible, puis nous inf&#233;rons l'annotation s&#233;mantique de ce 
</p>
<p>corpus pour les donn&#233;es traduites. Pour ce faire, nous proposons deux m&#233;thodes diff&#233;rentes. La premi&#232;re 
</p>
<p>consiste &#224; l'aide d&#8217;un syst&#232;me de traduction probabiliste source-cible, &#224; traduire chaque phrase source annot&#233;e, 
segment&#233;e en segments, et d&#8217;utiliser les segments traduits, associ&#233;s aux &#233;tiquettes s&#233;mantiques, pour construire 
un nouveau syst&#232;me SLU en langue cible. La seconde approche utilise les informations extraites des alignements 
</p>
<p>mot-&#224;-mot pour inf&#233;rer une relation mot_cible-&#233;tiquette_s&#233;mantique (plus de d&#233;tails seront donn&#233;es dans la 
</p>
<p>section 2). 
</p>
<p>Une autre approche, compl&#232;tement diff&#233;rente, consiste &#224; voir le processus de compr&#233;hension comme une t&#226;che 
</p>
<p>de traduction automatique d&#8217;une cha&#238;ne de mots vers une cha&#238;ne d&#8217;&#233;tiquettes s&#233;mantiques. Dans ce cas, le 
mod&#232;le de compr&#233;hension est une table de traduction mots-concepts. L&#8217;approche &#224; base de s&#233;quences (phrase-
based) (Koehn, Och, Marcu, 2003) n&#233;cessite des donn&#233;es align&#233;es au niveau phrase avant le processus 
</p>
<p>d&#8217;apprentissage (dont la premi&#232;re &#233;tape sera un alignement automatique en mots utilisant les mod&#232;les IBM). 
Dans ce cas, la portabilit&#233; vers une nouvelle langue consiste simplement &#224; traduire en langue cible la partie 
</p>
<p>&#8220;mots&#8221; du corpus d&#8217;apprentissage mots-concept sans modifier les concepts. 
</p>
<p>Pour r&#233;pondre au deuxi&#232;me point (robustesse), et puisque nous allons voir que la m&#233;thode TestOnSource donne 
</p>
<p>les meilleures performances, nous proposons quelques m&#233;thodes pour augmenter la robustesse aux erreurs de 
</p>
<p>traduction du syst&#232;me port&#233;. Pour cela, une premi&#232;re approche pr&#233;sent&#233;e consiste &#224; re-entrainer le syst&#232;me de 
</p>
<p>compr&#233;hension, fond&#233; sur les CRF, sur des donn&#233;es bruit&#233;es repr&#233;sentant les erreurs potentielles de traduction. 
</p>
<p>La deuxi&#232;me approche consiste &#224; utiliser une post-&#233;dition automatique statistique (Statistical Post Edition, SPE) 
</p>
<p>dans la langue-source pour tenter de corriger automatiquement les sorties issues du syst&#232;me de traduction 
</p>
<p>automatique, avant de les envoyer &#224; l'&#233;tiqueteur s&#233;mantique. Pour finir, nous proposons aussi dans cet article de 
</p>
<p>combiner toutes les approches propos&#233;es dans cette &#233;tude, afin de r&#233;duire le taux d'erreurs de compr&#233;hension.  
</p>
<p>Cet article est structur&#233; de la fa&#231;on suivante : la section 2 pr&#233;sente en d&#233;tail les approches que nous proposons 
</p>
<p>pour porter un syst&#232;me de compr&#233;hension vers une nouvelle langue. La section 3 d&#233;crit deux solutions pour 
</p>
<p>am&#233;liorer la robustesse de notre meilleur syst&#232;me port&#233;, aux erreurs de traduction automatique. Le corpus 
</p>
<p>MEDIA et les outils utilis&#233;s sont d&#233;crits dans la section 4 tandis que la section 5 pr&#233;sente les r&#233;sultats 
</p>
<p>exp&#233;rimentaux obtenus. Finalement, conclusion et perspectives sont pr&#233;sent&#233;es dans la section 6. 
</p>
<p>2 Diff&#233;rentes m&#233;thodes pour porter un syst&#232;me de compr&#233;hension d&#8217;une langue vers une 
autre 
</p>
<p>Dans un syst&#232;me de dialogue, le r&#244;le du processus de compr&#233;hension est d'extraire une liste d'hypoth&#232;ses 
</p>
<p>d&#8217;&#233;tiquettes de concepts &#224; partir d'une phrase en entr&#233;e. Ces concepts repr&#233;sentent la s&#233;mantique de l'information 
existant dans la phrase en entr&#233;e. Les mod&#232;les de compr&#233;hension d&#233;velopp&#233;s dans cette &#233;tude sont entra&#238;n&#233;s sur 
</p>
<p>le corpus MEDIA, annot&#233; en concepts s&#233;mantiques (voir section 4). 
</p>
<p>La g&#233;n&#233;ration automatique de ces concepts &#224; partir d&#8217;une s&#233;quence de mots par des m&#233;thodes stochastiques telle 
que d&#233;crite dans (Raymond, Riccardi, 2007), peut &#234;tre r&#233;sum&#233;e de la fa&#231;on suivante : 
</p>
<p>Soit C=   ,...,   une s&#233;quence d&#8217;&#233;tiquettes s&#233;mantiques qui peut &#234;tre associ&#233;e initialement &#224; la s&#233;quence de mots 
W=   ,&#8230;,   ; pour chaque concept, une s&#233;quence de mots de W est associ&#233;e et une &#233;tiquette est attribu&#233;e &#224; 
chaque mot. Cette &#233;tiquette correspond au concept s&#233;mantique    et &#224; la position de   . 
</p>
<p>Plusieurs &#233;tudes ont propos&#233; de comparer diff&#233;rentes m&#233;thodes pour entra&#238;ner un mod&#232;le de compr&#233;hension de 
</p>
<p>la parole (Hahn, Lehnen, Raymond, Ney, 2008) (Raymond, Riccardi, 2007). Dans cet article, nous proposons 
</p>
<p>d&#8217;utiliser et d&#8217;&#233;valuer deux approches &#233;tat-de-l&#8217;art. 
</p>
<p>La premi&#232;re est fond&#233;e sur les champs al&#233;atoires conditionnels (Conditional Random Fields, CRF), qui ont 
</p>
<p>besoin d&#8217;un corpus annot&#233; au niveau mot pour &#234;tre entra&#238;n&#233;s. La seconde utilise une approche de traduction </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE 
</p>
<p> 
</p>
<p>probabiliste fond&#233;e sur les s&#233;quences (Phrase-Based Statistical Machine Translation, PB-SMT) et n&#233;cessite un 
</p>
<p>corpus d&#8217;apprentissage annot&#233; au niveau des phrases. 
</p>
<p>2.1 Champs al&#233;atoires conditionnels (CRF) 
</p>
<p>Les CRF (&quot;Conditional Random Fields&quot; ou &quot;Champs Al&#233;atoires (Markoviens) Conditionnels&quot;) sont une famille 
</p>
<p>de mod&#232;les graphiques introduits r&#233;cemment (Lafferty, McCallum, Pereira, 2001). Ils permettent d&#8217;apprendre &#224; 
annoter des donn&#233;es, en se basant sur un ensemble d&#8217;exemples d&#233;j&#224; annot&#233;s. Les CRF ont le plus souvent &#233;t&#233; 
utilis&#233;s dans le domaine du TAL, pour &#233;tiqueter des s&#233;quences d&#8217;unit&#233;s linguistiques. Ces mod&#232;les poss&#232;dent les 
avantages des mod&#232;les g&#233;n&#233;ratifs et discriminants. En effet, comme les classifieurs discriminants, ils peuvent 
</p>
<p>manipuler un grand nombre de descripteurs, et comme les mod&#232;les g&#233;n&#233;ratifs, ils int&#232;grent des d&#233;pendances 
</p>
<p>entre les &#233;tiquettes de sortie et prennent une d&#233;cision globale sur la s&#233;quence. Par rapport aux mod&#232;les de 
</p>
<p>Markov Cach&#233;s (HMMs), les CRF ont par ailleurs l&#8217;avantage de rel&#226;cher certaines hypoth&#232;ses d&#8217;ind&#233;pendance. 
</p>
<p>Dans notre cas, pour apprendre notre mod&#232;le CRF, les donn&#233;es d&#8217;apprentissage doivent &#234;tre repr&#233;sent&#233;es selon 
le formalisme BIO d&#233;crit dans (Raymond, Riccardi, 2007), qui indique les fronti&#232;res entre les concepts 
</p>
<p>s&#233;mantiques selon l&#8217;exemple ci-dessous : 
</p>
<p> &#8220;Je voudrais r&#233;server un h&#244;tel &#224; Paris &#8221; 
</p>
<p>Sera repr&#233;sent&#233; par la s&#233;quence de couples (w,c): 
</p>
<p>(je, B_command-tache) (voudrais, I_command-tache) (r&#233;server, I_command-tache) (un, B_Objet) (h&#244;tel, 
</p>
<p>I_objet) (&#224;, B_loc-ville) (Paris,  I_loc-ville) 
</p>
<p>La probabilit&#233; d&#8217;une sequence de concepts, &#233;tant donn&#233;e une s&#233;quence de mots est alors calcul&#233;e par :  
</p>
<p>    
    
</p>
<p>     
 
</p>
<p> 
            
</p>
<p> 
</p>
<p>    
</p>
<p>     
     
</p>
<p>avec 
</p>
<p>                
              
</p>
<p> 
</p>
<p>   
</p>
<p>               
     
</p>
<p>H est un mod&#232;le log-lin&#233;aire fond&#233; sur des fonctions caract&#233;ristiques                   
     qui repr&#233;sentent 
</p>
<p>l&#8217;information extraite du corpus d&#8217;apprentissage ; les poids &#955; du mod&#232;le log-lin&#233;aire sont estim&#233;s lors de 
l&#8217;apprentissage et Z est un terme de normalisation d&#233;finit tel que : 
</p>
<p>      
</p>
<p> 
</p>
<p>   
</p>
<p>           
</p>
<p> 
</p>
<p>    
</p>
<p>     
     
</p>
<p>Afin de porter notre syst&#232;me de compr&#233;hension fond&#233; sur les CRF (note SLU/CRF par la suite) d&#8217;une langue &#224; 
une autre, nous avons propos&#233; plusieurs approches qui diff&#232;rent selon le moment o&#249; est appliqu&#233; le processus de 
</p>
<p>transfert entre les langues. 
</p>
<p>2.1.1 Portage au niveau du test (Test On Source) 
</p>
<p>Dans cette approche, nous supposons qu&#8217;un syst&#232;me SLU est disponible en langue source, et nous utilisons un 
syst&#232;me de traduction automatique probabiliste pour traduire les phrases de test en langue cible vers la langue 
</p>
<p>source. Ces traductions sont ensuite les entr&#233;es du syst&#232;me SLU original. En d&#8217;autres termes, nous portons le 
syst&#232;me &#171; au niveau du test &#187; sans modifier le processus d&#8217;apprentissage du syst&#232;me SLU. Cette technique sera 
d&#233;nomm&#233;e TestOnSource dans la suite de cet article. Elle a l&#8217;avantage d&#8217;&#234;tre tr&#232;s simple mais ses performances 
d&#233;pendront, bien &#233;videmment, des performances du syst&#232;me de traduction automatique utilis&#233; pour revenir de la 
</p>
<p>langue cible &#224; la langue source. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMPARAISON ET COMBINAISON D&#8217;APPROCHES POUR LA PORTABILITE VERS UNE NOUVELLE 
LANGUE D&#8217;UN SYSTEME DE COMPREHENSION DE L&#8217;ORAL 
</p>
<p>2.1.2 Portage au niveau de l&#8217;apprentissage (Train On Target) 
</p>
<p>Cette approche consiste &#224; re-entra&#238;ner un syst&#232;me SLU en langue cible. L&#8217;id&#233;e g&#233;n&#233;rale est de traduire le corpus 
d&#8217;apprentissage de la langue source vers la langue cible et d&#8217;inf&#233;rer les &#233;tiquettes s&#233;mantiques associ&#233;es. Pour 
inf&#233;rer l&#8217;annotation s&#233;mantique, nous proposons deux approches diff&#233;rentes : 
 
</p>
<p>1. Traduire avec des tags XML (Tagged Translation): 
Dans cette approche, le corpus d&#8217;apprentissage est traduit en prenant en compte la segmentation en 
&#171; segments s&#233;mantiques &#187; (un &#171; segment &#187; est compos&#233; potentiellement de plusieurs mots mais 
</p>
<p>correspond &#224; une et une seule &#233;tiquette s&#233;mantique). Pour cela, nous utilisons une option (-xml-input) 
</p>
<p>du d&#233;codeur MOSES (Koehn, Hoang, Birch, Callisonburch, Federico, Bertoldi, Cowan, Shen, Moran, 
</p>
<p>Zens, Dyer, Bojar, Constantin, Herbst, 2007), qui force la segmentation d&#8217;une phrase &#224; traduire, cette 
segmentation &#233;tant d&#233;crite par des tags XML. Ainsi, en sortie, nous obtenons chaque phrase du corpus 
</p>
<p>d&#8217;apprentissage traduite, ainsi qu&#8217;une projection des tags XML de la source vers la cible. L&#8217;exemple 
donn&#233; pr&#233;c&#233;demment peut alors &#234;tre repr&#233;sent&#233; sous la forme suivante : 
</p>
<p> 
</p>
<p>&lt;tag c=command_tache &gt; Je voudrais r&#233;server &lt;/tag&gt; &lt;tag c=objet &gt; un h&#244;tel &lt;/tag&gt; &lt;tag 
</p>
<p>c=localisation_ville&gt; &#224; Paris &lt;/tag&gt; 
</p>
<p> 
</p>
<p>En utilisant l&#8217;option de MOSES qui prend en compte les tags XML comme information de 
segmentation, nous obtenons la sortie traduite suivante : 
</p>
<p> 
</p>
<p>&lt;tag c= command_tache &gt; vorrei prenotare &lt;/tag&gt; &lt;tag c=objet&gt; un hotel &lt;/tag&gt; &lt;tag c= 
</p>
<p>localisation_ville&gt; a Parigi &lt;/tag&gt; 
</p>
<p> 
</p>
<p>Tout le corpus d&#8217;apprentissage est traduit de cette fa&#231;on puis re-format&#233; au format BIO avant un nouvel 
apprentissage du mod&#232;le CRF de compr&#233;hension en langue cible. 
</p>
<p> 
</p>
<p>2. Projections des concepts s&#233;mantiques d&#8217;une langue &#224; l&#8217;autre en utilisant un alignement en mots 
(Alignment): 
</p>
<p>L&#8217;alignement automatique en mots est une &#233;tape importante dans le processus de construction d&#8217;un 
mod&#232;le de traduction probabiliste. Plusieurs boites &#224; outils existent pour cette t&#226;che telles que GIZA++ 
</p>
<p>(Och, Ney, 2000) qui utilise les mod&#232;les IBM et HMM, ou Berkeley aligner (Liang, Taskar, Klein, 
</p>
<p>2006) qui repose sur une m&#233;thode d&#8217;alignement par consensus (alignment by agreement).  
</p>
<p>Pour projeter les concepts s&#233;mantiques d&#8217;une langue &#224; l&#8217;autre, on peut utiliser les informations 
d&#8217;alignement bilingue en mots. Plus pr&#233;cis&#233;ment, la premi&#232;re phase consiste &#224; aligner automatiquement 
le corpus parall&#232;le source-cible. Ensuite, comme le corpus source est d&#233;j&#224; annot&#233; s&#233;mantiquement, il est 
</p>
<p>possible d&#8217;apparier les &#233;tiquettes s&#233;mantiques aux mots en langue cible en utilisant l&#8217;information 
d&#8217;alignement. Certains cas ambigus demeurent cependant, comme illustr&#233; dans la figure 2 (alors que la 
figure 1 pr&#233;sente un cas o&#249; la projection est &#233;vidente). Dans cet article, l&#8217;aligneur utilis&#233; est Berkeley 
Aligner. 
</p>
<p> Command-tache             objet       loc-ville 
</p>
<p>Je   voudrais   r&#233;server   un   h&#244;tel   &#224;   Paris 
</p>
<p>Vorrei   prenotare   un   hotel   a   Parigi 
</p>
<p>Figure 1 : Exemple de projection des tags s&#233;mantiques du fran&#231;ais vers l&#8217;italien 
</p>
<p>Pour faire cette projection, nous avons d&#233;velopp&#233; un algorithme qui parcourt la phrase en langue cible 
</p>
<p>et associe aux mots la bonne &#233;tiquette s&#233;mantique. Pour les cas ambigus o&#249; un mot cible est align&#233; avec 
</p>
<p>plusieurs mots sources correspondent &#224; deux concepts diff&#233;rents (voir figure 2), nous devons prendre 
</p>
<p>une d&#233;cision sur quel concept doit &#234;tre associ&#233; au mot cible. Pour cela, notre proposition est de 
</p>
<p>simplement associer le mot cible au premier concept rencontr&#233;. Par exemple, sur la figure 2, le mot 
</p>
<p>italien alla sera associ&#233; au concept loc-dis et pas au concept loc-lieu. Cette d&#233;cision, bien qu&#8217;arbitraire, 
a l&#8217;avantage d&#8217;&#234;tre coh&#233;rente d&#8217;un bout &#224; l&#8217;autre du corpus si le m&#234;me cas est rencontr&#233; &#224; nouveau. 
</p>
<p> </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE 
</p>
<p> 
</p>
<p>         loc-dis       loc-lieu 
</p>
<p>Pr&#232;s   de   la   bastille 
</p>
<p>Vicino   alla   bastilia 
</p>
<p>Figure 2 : Exemple de cas ambigu pour la projection des concepts sur les mots cible 
</p>
<p>2.2 Compr&#233;hension par une approche de traduction (PB-SMT) 
</p>
<p>Afin d&#8217;&#233;viter de recourir &#224; un corpus d&#8217;entrainement annot&#233; au niveau mot, nous proposons d&#8217;utiliser l&#8217;approche 
PB-SMP qui ne n&#233;cessite qu&#8217;un alignement au niveau des phrases compl&#232;tes. Dans cette approche, nous 
consid&#233;rons que les s&#233;quences de concepts sont les traductions des s&#233;quences de mots initiales. Ainsi 
</p>
<p>l&#8217;&#233;tiquetage s&#233;mantique est vu comme une t&#226;che de traduction : la meilleure s&#233;quence C &#224; partir des mots W est 
d&#233;finie par : 
</p>
<p>                                    
</p>
<p>Pour r&#233;soudre cette &#233;quation sont requis : un mod&#232;le de langage de concepts P(C) (qui peut &#234;tre appris &#224; l&#8217;aide 
de SRILM (Stolcke, 2002) sur le corpus de concepts) et d&#8217;un model de traduction P(W|C) (qui peut &#234;tre un 
mod&#232;le PB-SMT par exemple). Nous avons utilis&#233; MOSES pour entra&#238;ner un tel mod&#232;le PB-SMT &#224; partir d&#8217;un 
corpus &#171; parall&#232;le &#187;. Les poids associ&#233;s &#224; ce mod&#232;le sont optimis&#233;s par un apprentissage &#224; taux d&#8217;erreur 
minimum (MERT) qui est traditionnellement utilis&#233; pour optimiser le score BLEU. Puis les performances de 
</p>
<p>cette approche PB-SMT de base ont &#233;t&#233; am&#233;lior&#233;es en utilisant des caract&#233;ristiques de la t&#226;che de compr&#233;hension 
</p>
<p>s&#233;mantique. 
</p>
<p>D&#8217;abord, en suivant l&#8217;hypoth&#232;se raisonnable que la s&#233;mantique d&#8217;une phrase respecte l&#8217;ordre dans lequel les 
mots sont &#233;mis, la table de segments est re-entrain&#233;e en utilisant une contrainte de monotonie durant 
</p>
<p>l&#8217;alignement automatique en mots. Puis, dans la mesure o&#249; une difficult&#233; majeure du processus de traduction est 
l&#8217;alignement automatique correct d&#8217;un mot du langage source avec le mot correspondant dans le langage cible, 
nous avons tent&#233; d&#8217;aider le processus d&#8217;alignement par l&#8217;utilisation du formalisme BIO. De cette fa&#231;on, 
l&#8217;extraction de la table de segments a &#233;t&#233; obtenue sur un corpus avec un alignement de meilleure qualit&#233;. Enfin, 
la mesure d&#8217;&#233;valuation du SLU &#233;tant le CER et non le score BLEU, nous avons modifi&#233; l&#8217;optimisation MERT 
pour optimiser le CER directement. Finalement, pour &#233;viter les mots hors-vocabulaire (venant principalement de 
</p>
<p>noms de ville absents des donn&#233;es d&#8217;entrainement), une liste de villes est ajout&#233;e aux donn&#233;es d&#8217;apprentissage et 
le syst&#232;me SLU/PB-SMT est re-entrain&#233;. 
</p>
<p>3 Accro&#238;tre la robustesse du SLU aux erreurs de traduction 
</p>
<p>Nos exp&#233;riences, ainsi que d&#8217;autres travaux (Lef&#232;vre, Mairesse, Young, 2010) (Jabaian, Besacier, Lef&#232;vre, 
2010), ont montr&#233; que la meilleure m&#233;thode pour la portabilit&#233; SLU est aussi la plus simple, le TestOnSource. La 
</p>
<p>faiblesse principale de cette m&#233;thode est que la qualit&#233; de l&#8217;&#233;tiquetage d&#233;pend grandement de la qualit&#233; de la 
traduction pr&#233;alable. Ainsi, le syst&#232;me SLU doit prendre en compte des entr&#233;es bruit&#233;es par les erreurs de 
</p>
<p>traduction. 
</p>
<p>De sorte &#224; am&#233;liorer la robustesse de l&#8217;approche, nous proposons deux m&#233;thodes dans ce papier. La premi&#232;re 
prend en compte le bruit venant de la traduction durant le processus d&#8217;apprentissage des mod&#232;les SLU ; la 
seconde corrige automatiquement la sortie du syst&#232;me de traduction avant de la transf&#233;rer au syst&#232;me SLU. Il est 
</p>
<p>notable que, bien que pas encore &#233;valu&#233;es dans ce cadre (par manque de donn&#233;es audio dans la langue cible), les 
</p>
<p>deux m&#233;thodes seront tout &#224; fait adapt&#233;es pour traiter aussi les erreurs dues &#224; la reconnaissance de la parole dans 
</p>
<p>une tache de compr&#233;hension r&#233;elle. 
</p>
<p>3.1 Apprentissage sur des donn&#233;es bruit&#233;  
</p>
<p>Le principe de cette m&#233;thode est d&#8217;entrainer un mod&#232;le SLU (dans le langage source) avec des donn&#233;es 
additionnelles provenant de la sortie d&#8217;un syst&#232;me de traduction automatique. En pratique, nous traduisons les 
donn&#233;es d&#8217;apprentissage disponibles entre les langues cible et source et nous inf&#233;rons les concepts associ&#233;s aux 
donn&#233;es bruit&#233;es (en suivant la m&#234;me m&#233;thode que TrainOnTarget). Puis nous ajoutons les donn&#233;es corrompues 
</p>
<p>(maintenant annot&#233;es s&#233;mantiquement) aux donn&#233;es originales et l&#8217;ensemble est utilis&#233; pour entrainer le nouveau 
mod&#232;le SLU (dans la langue source) qui alors int&#233;grera le bruit pr&#233;sent dans les donn&#233;es traduites. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMPARAISON ET COMBINAISON D&#8217;APPROCHES POUR LA PORTABILITE VERS UNE NOUVELLE 
LANGUE D&#8217;UN SYSTEME DE COMPREHENSION DE L&#8217;ORAL 
</p>
<p>3.2 Post-&#233;dition statistique 
</p>
<p>Plusieurs travaux r&#233;cents en traduction automatique comme (Simard, Goutte, Isabelle, 2007) (Diaz de Ilarraza, 
</p>
<p>Labaka, Sarasola, 2008) ont utilis&#233; une approche bas&#233;e sur un syst&#232;me de traduction pour post-&#233;diter les sorties 
</p>
<p>d&#8217;un autre syst&#232;me de traduction. Un tel syst&#232;me, malgr&#233; une d&#233;marche qui peut paraitre contre-intuitive, a &#233;t&#233; 
propos&#233; pour am&#233;liorer la qualit&#233; des donn&#233;es traduites avant leur envoi &#224; des post-&#233;diteurs humains. Pour 
</p>
<p>entrainer un tel post-&#233;diteur, (Simard, Goutte, Isabelle, 2007) (Diaz de Ilarraza, Labaka, Sarasola, 2008) utilisent 
</p>
<p>les sorties d&#8217;un syst&#232;me SMT avec comme donn&#233;es parall&#232;les leur post-&#233;dition manuelle. 
</p>
<p>Dans notre cas, dans la mesure o&#249; la sortie du syst&#232;me SMT sera utilis&#233;e comme entr&#233;e du syst&#232;me SLU 
</p>
<p>entrain&#233; sur les donn&#233;es du langage source, nous proposons de post-&#233;diter cette sortie afin de diminuer le bruit 
</p>
<p>du &#224; la traduction des entr&#233;es utilisateurs. 
</p>
<p>Pour apprendre un SPE, notre choix a &#233;t&#233; de traduire automatiquement l&#8217;ensemble de donn&#233;es disponibles pour 
la langue cible, puis d&#8217;utiliser les sorties traduites avec les parties correspondantes transcrites manuellement, 
comme corpus parall&#232;le. Nous pensons que le module de post-&#233;dition permettra ainsi de r&#233;ordonner quelques 
</p>
<p>mots ou de retrouver des mots manquants dans un certain nombre de phrases. 
</p>
<p>4 Description du corpus et d&#8217;outils 
</p>
<p>Toutes les exp&#233;riences d&#233;crites dans le papier ont &#233;t&#233; r&#233;alis&#233;es sur le corpus fran&#231;ais MEDIA. Ce travail a &#233;t&#233; 
</p>
<p>motive par la disponibilit&#233; d&#8217;une traduction manuelle en italien d&#8217;une sous-partie de ce corpus. 
</p>
<p>4.1 Le corpus MEDIA 
</p>
<p>Comme d&#233;crit dans (Bonneau -Maynard, Rosset, Ayache, Kuhn, Mostefa, 2005), ce corpus couvre un domaine 
</p>
<p>li&#233; aux r&#233;servations de chambres d&#8217;h&#244;tels et aux informations touristiques. Le corpus est constitu&#233; de 1257 
dialogues enregistr&#233;s par 250 locuteurs, collect&#233;s en situation de Wizard-of-Oz (un humain simule le syst&#232;me de 
</p>
<p>dialogue). 
</p>
<p>Les dialogues sont regroup&#233;s en 3 parties : un ensemble d&#8217;apprentissage (environ 13k phrases), un ensemble de 
d&#233;veloppement (1,3k phrases) et un ensemble d&#8217;&#233;valuation (3k phrases). Dans nos exp&#233;riences, nous ne prenons 
en compte que les phrases utilisateurs. 
</p>
<p>Le corpus est &#233;tiquet&#233; avec 99 concepts diff&#233;rents. Ces &#233;tiquettes peuvent &#234;tre simples comme les dates ou les 
</p>
<p>noms de ville ou peuvent &#234;tre plus complexes comme les cor&#233;f&#233;rences. A titre d&#8217;illustration, voici une phrase de 
MEDIA : 
</p>
<p>Je voudrais une chambre double &#224; Marseille  
</p>
<p>L&#8217;annotation s&#233;mantique de cette phrase aura la forme : 
</p>
<p>Je voudrais [null], une [nombre-chambre], chambre double [chambre-type], &#224; Paris [localization-ville].  
</p>
<p>Cette annotation s&#233;mantique d&#233;coupe chaque phrase en plusieurs segments. Chaque segment est non seulement 
</p>
<p>annot&#233; avec le nom du concept mais aussi par une valeur, une modalit&#233; et un specifieur. Les exp&#233;riences 
</p>
<p>pr&#233;sent&#233;es dans le papier prennent en compte uniquement le nom du concept et la modalit&#233; du segment. 
</p>
<p>Un sous-ensemble de l&#8217;apprentissage (environ 5.6k phrases), de m&#234;me que les ensembles de test et de 
d&#233;veloppement, ont &#233;t&#233; manuellement traduit en italien dans le contexte du projet europ&#233;en LUNA (Servan, 
</p>
<p>Camelin, Raymond, Bechet, De Mori, 2010). 
</p>
<p>4.2 Les SMTs apprit 
</p>
<p>Dans cette &#233;tude, nous utilisons deux syst&#232;mes de traduction automatique pour obtenir les traductions du 
</p>
<p>fran&#231;ais vers l&#8217;italien et de l&#8217;italien vers le fran&#231;ais. Pour r&#233;aliser ces traductions, la boite &#224; outils Moses (Koehn, 
Hoang, Birch, Callisonburch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 
</p>
<p>2007) est utilis&#233;e. Moses impl&#233;mente l&#8217;&#233;tat-de-l&#8217;art des syst&#232;mes de traduction par segments utilisant des 
mod&#232;les log-lin&#233;aires. 
</p>
<p>Nous utilisons la partie manuellement traduite en italien de l&#8217;ensemble d&#8217;apprentissage du corpus MEDIA 
comme corpus parall&#232;le pour Moses dans les deux directions pour entrainer les mod&#232;les. Chacune des parties 
</p>
<p>s&#233;par&#233;ment permet l&#8217;apprentissage d&#8217;un mod&#232;le de langage. Aussi l&#8217;ensemble de d&#233;veloppement avec sa 
traduction est utilis&#233; comme corpus parall&#232;le pour ajuster les poids du mod&#232;le log-lin&#233;aire des syst&#232;mes SMT. 
</p>
<p>Finalement, nous obtenons un syst&#232;me de fran&#231;ais vers l&#8217;italien avec un score BLEU de 43,62 et de l&#8217;italien vers </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE 
</p>
<p> 
</p>
<p>le fran&#231;ais avec un score de 47,18. Ces scores sont mesur&#233;s sur l&#8217;ensemble de test de MEDIA manuellement 
traduit. Dans la mesure o&#249; une seule r&#233;f&#233;rence par phrase est utilis&#233;e pour &#233;valuer le score BLEU, de m&#234;me que 
</p>
<p>l&#8217;ensemble d&#8217;apprentissage est r&#233;duit (5,6k), ces performances peuvent &#234;tre consid&#233;r&#233;es comme tr&#232;s acceptables. 
</p>
<p>Nous avons aussi re-traduit automatiquement en fran&#231;ais la version manuelle en italien du corpus, de sorte &#224; 
</p>
<p>utiliser cette traduction en parall&#232;le de la partie originale pour entrainer le SPE et fournir les donn&#233;es bruit&#233;es 
</p>
<p>pour le SCTD. Du point de vue de la performance de traduction exclusivement, l&#8217;utilisation de la post-&#233;dition 
automatique am&#233;liore le score BLEU du syst&#232;me de 47,18 &#224; 49,25. 
</p>
<p>4.3 Compl&#233;ter la traduction de MEDIA 
</p>
<p>Le syst&#232;me de traduction fran&#231;ais-italien est utilis&#233; pour obtenir une traduction automatique de la partie restante 
</p>
<p>(non traduite manuellement) du corpus d&#8217;apprentissage, ainsi une traduction int&#233;grale (manuelle + automatique) 
est disponible. Le syst&#232;me italien-fran&#231;ais est utilis&#233; pour traduire le test italien en fran&#231;ais, qui sera utilis&#233; pour 
</p>
<p>l&#8217;approche TestOnSource. Le tableau 1 donne un aper&#231;u des ensembles disponibles pour les exp&#233;riences. 
</p>
<p>MEDIA data Train Dev Test 
</p>
<p>French MEDIA 13K 1,3K 3,5K 
</p>
<p>Italian manual 5,6K 1,3K 3,5K 
</p>
<p>Italian automatic 7,4K - - 
</p>
<p>Tableau 1: aper&#231;u du corpus MEDIA et de sa traduction vers l&#8217;italien  (# phrases). 
</p>
<p>5 Exp&#233;riences et r&#233;sultats   
</p>
<p>Afin d&#8217;&#233;valuer les performances des approches propos&#233;s, la traduction manuelle en italien des donn&#233;es de test 
est utilis&#233;e. Le CER est le crit&#232;re d&#8217;&#233;valuation retenu pour cette &#233;tude. Le CER est l&#8217;&#233;quivalent du taux d&#8217;erreur 
en mots (WER), et peut &#234;tre d&#233;fini comme le ratio de la somme des concepts omis, ins&#233;r&#233;s et subtilis&#233;s sur le 
</p>
<p>nombre de concepts dans la r&#233;f&#233;rence. Premi&#232;rement nous &#233;valuons et comparons SLU/CRF et SLU/PB-SMT, 
</p>
<p>nous &#233;valuons de m&#234;me notre proposition de robustesse, puis les syst&#232;mes sont combin&#233;s. Pour finir, nous 
</p>
<p>validons nos approches en utilisant les traductions obtenues par un syst&#232;me de traduction en ligne (ie sans 
</p>
<p>utiliser de traduction manuelle). 
</p>
<p>5.1 Les strat&#233;gies de portabilit&#233; SLU/CRF 
</p>
<p>La totalit&#233; de l&#8217;ensemble d&#8217;apprentissage de MEDIA est utilis&#233; pour apprendre un &#233;tiqueteur fran&#231;ais de base 
utilisant des uni- et bi-grammes. Cette base atteint de bonnes performances (12,9% CER) et peut &#234;tre consid&#233;r&#233;e 
</p>
<p>comme une r&#233;f&#233;rence pour les m&#233;thodes propos&#233;es. Pour &#233;valuer les performances de l&#8217;approche TestOnSource 
la traduction automatique en fran&#231;ais du test italien (comme d&#233;crit en 4) est fournie &#224; l&#8217;&#233;tiqueteur de base. 
</p>
<p>La m&#233;thode TrainOnTarget d&#233;crite dans 2.1.2 a &#233;t&#233; appliqu&#233;e. Nous utilisons le syst&#232;me fran&#231;ais-italien (d&#233;crit 
</p>
<p>en 4) pour traduire le corpus d&#8217;entrainement int&#233;grant des balises XML correspondant aux segments conceptuels 
afin d&#8217;&#233;valuer la m&#233;thode TaggedTranslation, et la totalit&#233; des traductions en italien de MEDIA (manuelle et 
automatique) avec la version fran&#231;aise comme corpus parall&#232;le pour obtenir l&#8217;alignement mot-a-mot. 
L&#8217;information d&#8217;alignement telle que d&#233;fini en 2.1.2 est utilis&#233;e, pour &#233;valuer la performance de la m&#233;thode 
Alignement. Toutes les exp&#233;riences utilisent l&#8217;outil CRF++ (https://crfpp.sourceforge.net). L&#8217;ensemble des 
r&#233;sultats est regroup&#233;s dans le tableau 2. 
</p>
<p>Il apparait clairement &#224; la lecture des r&#233;sultants que la m&#233;thode Alignement est meilleure que 
</p>
<p>TaggedTranslation. Ceci peut &#234;tre expliqu&#233; par le fait que Alignement est seulement influenc&#233; par les erreurs 
</p>
<p>d&#8217;alignement, tandis que TaggedTranslation est influenc&#233; par les erreurs de traduction automatique qui sont plus 
importantes. On note aussi que la m&#233;thode TestOnSource est plus performante que les m&#233;thodes 
</p>
<p>TrainOnTarget.les performances de toutes les m&#233;thodes sont consid&#233;r&#233;es come bonne en comparaison avec la 
</p>
<p>r&#233;f&#233;rence fran&#231;aise. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMPARAISON ET COMBINAISON D&#8217;APPROCHES POUR LA PORTABILITE VERS UNE NOUVELLE 
LANGUE D&#8217;UN SYSTEME DE COMPREHENSION DE L&#8217;ORAL 
</p>
<p>Model Sub Del Ins CER 
</p>
<p>FR 3,1 8,1 1,8 12,9 
</p>
<p>SLU/CRF(TestOnSource) 5,2 12,1 2,6 19,9 
</p>
<p>SLU/CRF(TaggedTranslation) 3,7 16,9 2,1 22,7 
</p>
<p>SLU/CRF(Alignment) 3,1 15,0 2,3 20,5 
</p>
<p>Tableau 2 : Evaluation (CER %) de diff&#233;rentes strat&#233;gies de portabilit&#233; du SLU utilisant les m&#233;thodes SLU/CRF 
</p>
<p>5.2 SLU/PB-SMT 
</p>
<p>Nos premi&#232;res tentatives pour construire le mod&#232;le PB-SMT pour le SLU italien ont clairement montr&#233; des 
</p>
<p>performances inf&#233;rieures aux CRF (CER=28,1% apr&#232;s r&#233;glage MERT pour le PB-SMT compar&#233; aux ~20% pour 
</p>
<p>les CRF). Les am&#233;liorations progressives du mod&#232;le propos&#233;es en Section 2.2 sont &#233;valu&#233;es dans le tableau 3. 
</p>
<p>L&#8217;utilisation de la contrainte de monotonie durant l&#8217;alignement en mot permet une r&#233;duction de 0,6% absolu. 
Convertir les donn&#233;es selon le formalisme BIO avant la phase d&#8217;apprentissage r&#233;duit le CER de fa&#231;on 
significative de 2,8%. Enfin optimiser le CER &#224; la place du BLEU r&#233;duit le CER de 0,3% suppl&#233;mentaire. 
</p>
<p>L&#8217;ajout d&#8217;une liste de villes &#224; l&#8217;ensemble d&#8217;apprentissage avant r&#233;apprentissage du mod&#232;le PB-SMT permet une 
r&#233;duction finale de 0,5%. 
</p>
<p>Les r&#233;sultats montrent qu&#8217;en d&#233;pit de r&#233;glages fins de l&#8217;approche SMT, les approches &#224; base de CRF obtiennent 
toujours les meilleures performances. De plus, dans une exp&#233;rience parall&#232;le, un mod&#232;le PB-SMT a &#233;t&#233; construit 
</p>
<p>pour le SLU Fran&#231;ais afin de le tester dans l&#8217;approche TestOnSource. Mais les performances de l&#8217;approche sont 
d&#233;cevantes et bien en-de&#231;a de celles des autres m&#233;thodes. Elle a donc &#233;t&#233; &#233;cart&#233;e pour le reste de l&#8217;&#233;tude. 
</p>
<p>A partir d&#8217;une analyse rapide du type d&#8217;erreurs de chaque mod&#232;le, nous pouvons observer que les m&#233;thodes 
utilisant des CRF ont un haut niveau de suppressions comparativement aux autres types d&#8217;erreurs, tandis que la 
m&#233;thode PB-SMT pr&#233;sente un meilleur compromis entre les erreurs de suppression et d&#8217;insertion, et ce bien 
qu&#8217;elle abouti &#224; un CER plus &#233;lev&#233;. 
</p>
<p>SLU/PB-SMT Sub Del Ins CER 
</p>
<p>Initial 6,5 4,0 18,6 29,1 
</p>
<p>+ MERT (BLEU) 6,3 9,3 12,5 28,1 
</p>
<p>+ Monotone align 7,4 8,4 11,8 27,5 
</p>
<p>+ BIO format 6,5 10,6 7,7 24,7 
</p>
<p>+ MERT (CER) 6,4 10,9 7,2 24,4 
</p>
<p>+ City list 7,2 10,5 6,1 23,9 
</p>
<p>Tableau 3 : am&#233;liorations it&#233;ratives de la m&#233;thode SLU/PB-SMT sur le test italien de MEDIA (CER%) 
</p>
<p>5.3 SLU/CRF TestOnSource robuste 
</p>
<p>Nous avons tent&#233; d&#8217;am&#233;liorer les performances de la m&#233;thode TestOnSource SLU/CRF en renfor&#231;ant sa 
robustesse aux erreurs de traduction. Premi&#232;rement nous traduisons automatiquement la partie manuelle en 
</p>
<p>italien. Ensuite nous apprenons un nouvel &#233;tiqueteur CRF simultan&#233;ment sur les donn&#233;es d&#8217;apprentissage en 
fran&#231;ais et traduites (approche +SCTD, d&#233;crite en 3.1). La m&#233;thode de la section 3.2 (SPE) a aussi &#233;t&#233; &#233;valu&#233;e, 
</p>
<p>dans laquelle le test traduit post-&#233;dit&#233; a &#233;t&#233; transmis aux CRF de base (+SPE) ou aux CRF appris sur les donn&#233;es 
</p>
<p>corrompues (+SCTD+SPE). </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE 
</p>
<p> 
</p>
<p>L&#8217;&#233;valuation des performances de ces approches sont rapport&#233;es dans le tableau 4. Les deux m&#233;thodes, 
d&#8217;apprentissage sur donn&#233;es bruit&#233;es et SPE, am&#233;liorent les performances de l&#8217;&#233;tiqueteur s&#233;mantique. Leur mise 
en s&#233;rie donne les meilleures performances. 
</p>
<p>SLU/CRF Sub Del Ins CER 
</p>
<p>TestOnSource 5,2 12,1 2,6 19,9 
</p>
<p>+SCTD 5,9 11,4 2,3 19,6 
</p>
<p>+SPE 6,5 10,6 2,5 19,7 
</p>
<p>+SCTD +SPE 6,4 9,9 2,9 19,3 
</p>
<p>Tableau 4 : Evaluation (CER %) des approches propos&#233;es pour la robustesse des syst&#232;mes au bruit de traduction 
</p>
<p>5.4 Combinaison de syst&#232;mes 
</p>
<p>Nous proposons de combiner les trois approches principales (TestOnTarget et TrainOnTarget SLU/CRF, et 
</p>
<p>SLU/PB-SMT) afin de b&#233;n&#233;ficier de leurs caract&#233;ristiques respectives pour am&#233;liorer la performance globale. La 
</p>
<p>combinaison (d&#233;not&#233;e BASIC dans le tableau 5) est simple : un r&#233;seau de confusion est construit &#224; partir des 
</p>
<p>trois hypoth&#232;ses et la s&#233;quence de concept correspondant &#224; la plus grande probabilit&#233; a posteriori est calcul&#233;e. La 
</p>
<p>performance est am&#233;lior&#233;e de fa&#231;on significative (-1,3% CER) ce qui confirme la compl&#233;mentarit&#233; des 
</p>
<p>m&#233;thodes. 
</p>
<p>Finalement nous combinons toutes les m&#233;thodes propos&#233;es dans ce papier (SLU/CRF TrainOnTarge, SLU/CRF 
</p>
<p>TestOnSource, +SCTD, +SPE, +SCTD+SPE, SLU/PB-SMT). Ce qui permet d&#8217;atteindre les meilleures 
performances rapport&#233;es sur ce test (18,2%). Afin de mesurer l&#8217;influence de la m&#233;thode SLU/PB-SMT sur les 
performances de la combinaison, nous avons aussi &#233;valu&#233; les performances de la combinaison diminu&#233;e de 
</p>
<p>SLU/PB-SMT. Cette exp&#233;rience a montr&#233; qu&#8217;en d&#233;pit de ses mauvais r&#233;sultats individuels, la m&#233;thode PB-SMT 
a une influence importante sur la combinaison. 
</p>
<p>Model Sub Del Ins CER 
</p>
<p>BASIC 6,2 9,7 2,7 18,6 
</p>
<p>ALL 5,4 10,5 2,3 18,2 
</p>
<p>ALL &#8211; SLU/PB-SMT 6,6 10,2 2,7 19,4 
</p>
<p>Tableau 5 : combinaison de syst&#232;mes avec et sans l&#8217;approche PB-SMT 
</p>
<p>5.5 Validation des strat&#233;gies de portabilit&#233; SLU/CRF en utilisant des traductions en ligne uniquement 
</p>
<p>Les exp&#233;riences pr&#233;sent&#233;es dans cet article ne sont pas totalement non-supervis&#233;es, dans tous les cas nous avons 
</p>
<p>utilis&#233; des donn&#233;es traduites manuellement pour obtenir le syst&#232;me de traduction pour TestOnSource ou pour 
</p>
<p>compl&#233;ter la traduction de l&#8217;apprentissage et obtenir les informations d&#8217;alignement pour la m&#233;thode 
TrainOnTraget. 
</p>
<p>Le co&#251;t associ&#233; &#224; cette traduction manuelle est relativement bas compar&#233; &#224; celui de collecter et d&#8217;annoter un 
nouveau corpus d&#8217;apprentissage, mais il reste non n&#233;gligeable. Nous voulons v&#233;rifier qu&#8217;un tel co&#251;t est justifi&#233; 
par comparaison &#224; une approche totalement non-supervis&#233;e et donc (potentiellement) &#171; gratuite &#187;. 
</p>
<p>Afin de r&#233;pondre &#224; cette interrogation nous proposons de reproduire les exp&#233;riences en utilisant un syst&#232;me de 
</p>
<p>traduction gratuit en ligne &#224; la place de notre syst&#232;me de traduction appris sur la t&#226;che. 
</p>
<p>Pour &#233;valuer la m&#233;thode TestOnSource nous traduisons le test MEDIA en italien &#224; l&#8217;aide d&#8217;une solution gratuite 
en ligne puis nous utilisons cette traduction comme entr&#233;e de l&#8217;&#233;tiqueteur CRF de base. Pour la m&#233;thode 
TrainOnTarget deux approches ont &#233;t&#233; test&#233;es. Pour permettre la comparaison avec la m&#233;thode </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMPARAISON ET COMBINAISON D&#8217;APPROCHES POUR LA PORTABILITE VERS UNE NOUVELLE 
LANGUE D&#8217;UN SYSTEME DE COMPREHENSION DE L&#8217;ORAL 
</p>
<p>TaggedTranslation, nous proposons de traduire les donn&#233;es d&#8217;entrainement de MEDIA, segment par segment, 
au moyen du traducteur en ligne, puis ces traductions sont associ&#233;es aux &#233;tiquettes s&#233;mantiques initiales. Dans 
</p>
<p>une seconde version, les donn&#233;es sont traduites int&#233;gralement puis utilis&#233;es comme corpus parall&#232;le pour 
</p>
<p>l&#8217;approche Alignement. 
</p>
<p>Pour choisir un traducteur automatique dans le cadre de nos exp&#233;riences nous avons compar&#233; les performances 
</p>
<p>de deux traducteurs r&#233;put&#233;s. Le test MEDIA et sa traduction manuelle ont &#233;t&#233; utilis&#233; comme couple 
</p>
<p>test/r&#233;f&#233;rence dans chacune des directions de traduction. Pour l&#8217;Italien vers le fran&#231;ais un traducteur de score 
BLEU 42,58 a &#233;t&#233; s&#233;lectionn&#233; (&#224; comparer &#224; 47,18 obtenu par le syst&#232;me SMT appris sur les traductions 
</p>
<p>manuelles), et pour le fran&#231;ais vers l&#8217;italien un traducteur de score 39,75 a &#233;t&#233; retenu (&#224; comparer avec 43,62). 
Les r&#233;sultats de cette exp&#233;rience sont report&#233;s dans le tableau 6. 
</p>
<p>De mani&#232;re attendue les performances des syst&#232;mes obtenus par cette approche non-supervis&#233;e sont inferieures &#224; 
</p>
<p>celle des syst&#232;mes semi-supervis&#233;s. Toutefois malgr&#233; la d&#233;gradation du CER pour toutes les approches son 
</p>
<p>niveau absolu reste tout &#224; fait acceptable consid&#233;rant les besoins de la tache et la r&#233;duction substantielle du co&#251;t 
</p>
<p>de d&#233;veloppement. 
</p>
<p>La m&#233;thode Alignement est la plus perturb&#233;e et devient presque &#233;quivalente &#224; TaggedTranslation en version 
</p>
<p>non-supervis&#233;e. Le CER augmente de 22,7% &#224; 26,6% (+3,9% absolu) pour TaggedTranslation et de 20,5% &#224; 
</p>
<p>26,5% (+6%) pour Alignement. TestOnSource perd 3,2% mais reste la plus performante. Ces r&#233;sultats nous 
</p>
<p>engagent &#224; tester de nouvelles langues pour lesquelles nous ne disposons pas de traductions manuelles. 
</p>
<p>Model Sub Del Ins CER 
</p>
<p>Semi supervis&#233; 
</p>
<p>SLU/CRF(TestOnSource) 5,2 12,1 2,6 19,9 
</p>
<p>SLU/CRF(TaggedTranslation) 3,7 16,9 2,1 22,7 
</p>
<p>SLU/CRF(Alignment) 3,1 15,0 2,3 20,5 
</p>
<p>Non supervis&#233; 
</p>
<p>SLU/CRF(TestOnSource) 6,1 14,5 2,5 23,1 
</p>
<p>SLU/CRF(TaggedTranslation) 5,5 15,4 5,7 26,6 
</p>
<p>SLU/CRF(Alignment) 6,3 14,8 5,4 26,5 
</p>
<p>Tableau 6 : Evaluation (CER %) des strat&#233;gies de portabilit&#233; SLU/CRF en utilisant des traductions en ligne  
</p>
<p>6 Conclusion 
</p>
<p>Dans cet article on a propos&#233; et compar&#233; plusieurs approches pour la portabilit&#233; d&#8217;un SLU a travers les langues. 
Les CRFs et le PB-SMT on &#233;t&#233; utilis&#233; pour cette tache et les r&#233;sultats montrent que l&#8217;utilisation d&#8217;un &#233;tiqueteur a 
base de CRF avec des donn&#233;es de test traduites donne la meilleur performance. On a aussi montr&#233; l&#8217;int&#233;r&#234;t de 
l&#8217;utilisation de deux m&#233;thodes diff&#233;rentes pour accroitre la robustesse du SLU aux erreurs de traduction. Enfin 
on a montr&#233; que la combinaison de toutes les m&#233;thodes propos&#233;es augmente la performance du syst&#232;me.          
</p>
<p>Remerciements  
</p>
<p>Ce travail est support&#233; par le projet ANR PORT-MEDIA (ANR 08 CORD 026 01). Plus d&#8217;information 
disponible sur le site du projet : www.port-media.org </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE 
</p>
<p> 
</p>
<p>R&#233;f&#233;rences  
</p>
<p>Suenderman K., Liscombe J. (2009). From rule-based to statistical grammars: Continuous improvement of large-
</p>
<p>scale spoken dialog system. Actes de ICASSP. 
</p>
<p>Hahn S., Lehnen S., Raymond C., Ney H. (2008). A comparison of various methods for concept tagging for 
</p>
<p>spoken language understanding. Actes de LREC. 
</p>
<p>Raymond C., Riccardi G. (2007). Generative and discriminative algorithms for spoken language understanding. 
</p>
<p>Actes de Interspeech. 
</p>
<p>Wang Y., Acero A. (2006). Discriminative models for spoken language understanding. Actes de ICSLP. 
</p>
<p>Schwartz R., Miller S., Stallard D., Makhoul J. (1996). Language understanding using hidden understanding 
</p>
<p>models. Actes de ICSLP. 
</p>
<p>Suenderman K., Liscombe J. (2009). Localization of speech recognition in spoken dialog systems: How machine 
</p>
<p>translation can make our lives. Actes de Interspeech.  
</p>
<p>Servan C., Camelin N., Raymond C., Bechet F., De Mori R. (2010). On the use of machine translation for 
</p>
<p>spoken language understanding portability. Actes de ICASSP. 
</p>
<p>Lef&#232;vre F., Mairesse F., Young S. (2010). Cross-lingual spoken language understanding from unaligned data 
</p>
<p>using discriminative classification models and machine translation. Actes de Interspeech. 
</p>
<p>Jabaian B., Besacier L., Lef&#232;vre F. (2010). Investigating multiple approaches for SLU portability to a new 
</p>
<p>language. Actes de Interspeech. 
</p>
<p>Bonneau-Maynard H., Rosset S., Ayache C., Kuhn A., Mostefa D. (2005). Semantic annotation of the French 
</p>
<p>media dialog corpus. Actes de Eurospeech. 
</p>
<p>Lafferty J., McCallum A., Pereira F. (2001). Conditional random fields: Probabilistic models for segmenting and 
</p>
<p>labelling sequence data. Actes de ICML. 
</p>
<p>Koehn P., Och F., Marcu D. (2003). Statistical phrase_based translation. Actes de HLT/NAACL. 
</p>
<p>Koehn P., Hoang H., Birch A., Callisonburch C., Federico M., Bertoldi N., Cowan B., Shen W., Moran C., Zens 
</p>
<p>R., Dyer C., Bojar O., Constantin A., Herbst E. (2007). Moses: Open source toolkit for statistical machine 
</p>
<p>translation. Actes de ACL. 
</p>
<p>Och F., Ney H. (2000). Improved Statistical Alignment Models. Actes de ACL. 
</p>
<p>Liang P., Taskar B., Klein D. (2006). Alignment by agreement. Actes de HLT. 
</p>
<p>Stolcke A. (2002). SRILM an extensible language modeling toolkit. Actes de SLP. 
</p>
<p>Simard M., Goutte C., Isabelle P. (2007). Statistical phrase-based post-editing. Actes de NAACL. 
</p>
<p>Diaz de Ilarraza A., Labaka G., Sarasola K. (2008). Statistical post-editing: A valuable method in domain 
</p>
<p>adaptation of RBMT systems for less-resourced languages. Actes de MATMT. </p>

</div></div>
</body></html>