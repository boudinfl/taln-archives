TALN 2011, Montpellier, 27juin - Ierjuillet 2011

Comparaison et combinaison d’approches pour la portabilité vers une nouvelle
langue d’un systéme de compréhension de l’oral

Bassam Jabaian L2, Laurent Besacier 1, Fabrice Lefevre 2

(1) LIG, University Joseph Fourier, Grenoble - France
(2) LIA, University of Avignon, Avignon - France

{bassam.j abaian,laurent.besacier}@iInag.fr , fab1ice.lefevre@univ-avignon.fr

Résumé

Dans cet article, nous proposons plusieurs approches pour la portabilité du module de compréhension de la parole (SLU)
d’un systeme de dialogue d’une langue vers une autre. On montre que l’utilisation des traductions automatiques
statistiques (SMT) aide a réduire le temps et le cout de la portabilité d’un tel systeme d’une langue source vers une
langue cible. Pour la tache d’étiquetage sémantique on propose d’utiliser soit les champs aléatoires conditionnels (CRF),
soit l’approche a base de séquences (PH-SMT). Les résultats expérimentaux montrent l’efficacité des méthodes
proposées pour une portabilité rapide du SLU vers une nouvelle langue. On propose aussi deux méthodes pour accroitre
la robustesse du SLU aux erreurs de traduction. Enﬁn on montre que la combinaison de ces approches réduit les erreurs
du systeme. Ces travaux sont motivés par la disponibilité du corpus MEDIA francais et de la traduction manuelle vers
l’italien d’une sous partie de ce corpus.

Abstract

In this paper we investigate several approaches for language portability of the spoken language understanding (SLU)
module of a dialogue system. We show that the use of statistical machine translation (SMT) can reduce the time and the
cost of porting a system from a source to a target language. For conceptual decoding we propose to use even conditional
random fields (CRF) or phrase based statistical machine translation PB-SMT). The experimental results show the
efficiency of the proposed methods for a fast and low cost SLU language portability. Also we proposed two methods to
increase SLU robustness to translation errors. Overall we show that the combination of all these approaches reduce the
concept error rate. This work was motivated by the availability of the MEDIA French corpus and the manual translation
of a subset of this corpus into Italian.

Mots-clés : Systeme de dialogue, compréhension de la parole, portabilité a travers les langues, traduction automatique
statistique

Keywords: Spoken Dialogue Systems, Spoken Language Understanding, Language Portability, Statistical Machine
Translation.

BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE

1 Introduction

La portabilite d’un systeme de dialogue d’une langue vers une autre est une tache difficile qui a fait l’objet,
recemment, de plusieurs recherches. Certains composants d’un systeme de dialogue, tel que le gestionnaire de
dialogue, sont relativement independants de la langue, ce qui n’affectent pas le processus de portabilite.
Cependant, d’autres modules tel que le module de comprehension automatique de la parole (Spoken Language
Understanding, SLU), doivent etre readaptes pour chaque nouvelle langue cible consideree. Dans cette etude,
nous nous interessons particulierement a la portabilite d’un systeme de comprehension automatique de la parole
vers une nouvelle langue.

Des travaux recents ont propose d’utiliser des methodes stochastiques pour la comprehension automatique de la
parole. Ces methodes sont des alternatives efficaces aux methodes a base de regles; elles reduisent les besoins en
expertise humaine tout en ayant la capacite de produire efﬁcacement des reseaux d'hypotheses ou des listes de
N-meilleures (N-best) (Suenderman, Liscombe, 2009) (Hahn, Lehnen, Raymond, Ney, 2008) (Raymond,
Riccardi, 2007) (Wang, Acero, 2006) (Schwartz, Miller, Stallard, Makhoul, 1996). L’apprentissage de tels
modeles necessite un corpus annote qui represente une couverture complete de la semantique du domaine. Le
portage d'un tel modele vers une nouvelle langue consiste a transferer les connaissances presentes dans le corpus
annote en langue source vers une nouvelle langue avec un minimum de temps et d'effort humain. Par la suite,
nous nommerons <<langue source» la langue d’origine du systeme NLU et << langue cible », la langue vers
laquelle le systeme doit etre porte.

Recemment, quelques etudes ont montre que l'utilisation de la traduction automatique a differents niveaux du
processus de comprehension peut aider au portage d’un systeme SLU vers une nouvelle langue (Suenderman,
Liscombe, 2009) (Servan, Camelin, Raymond, Bechet, De Mori, 2010) (Lefevre, Mairesse, Young, 2010)
(Jabaian, Besacier, Lefevre, 2010). Par exemple, dans (Suenderman, Liscombe, 2009) les auteurs proposent de
traduire automatiquement les donnees de la langue source vers la langue cible, puis de re-apprendre une
grammaire stochastique pour effectuer l'interpretation dans la langue cible. Une autre possibilite est de
considerer que la semantique d'un domaine est independante de la langue. Dans ce cas, une solution est de
traduire le corpus d'apprentissage vers la langue cible et d’inferer les balises semantiques associees au corpus
traduit. Un systeme SLU stochastique peut ensuite étre re-entraine sur ce nouveau corpus armote en langue cible.
Comme decrit dans (Servan, Camelin, Raymond, Bechet, De Mori, 2010), les phrases du corpus d’apprentissage
sont composees d'un ou plusieurs segments armotes semantiquement. Traduire le corpus d'apprentissage en
conservant l’information de segmentation en segments permet alors un appariement direct des segments traduits
avec les etiquettes semantiques. Les auteurs de (Servan, Camelin, Raymond, Bechet, De Mori, 2010) montrent
qu’un portage du francais vers l’italien est possible en utilisant cette approche, avec une traduction manuelle ou
automatique. Le portage de l'annotation est encore moins difﬁcile lorsqu’on utilise des methodes qui n’ont pas
besoin d’annotation semantique au niveau mot ou segment. Par exemple, dans (Lefevre, Mairesse, Young,
2010), le modele propose ne necessite pas d'inforn1ations d'alignement.

Le choix d'une approche depend de considerations techniques et egalement des caracteristiques du domaine ainsi
que des donnees disponibles. Disposer de donnees manuellement traduites ou armotees, disposer d’annotateurs
ou d’outils speciﬁques pour la langue cible, peut faire la difference quant au choix de l'approche. Dans cet
article, nous proposons plusieurs approches pour le portage d’un systeme de comprehension automatique de la
parole vers une nouvelle langue. La langue source est le francais etant donne que nous travaillons sur le corpus
MEDIA (Bonneau -Maynard, Rosset, Ayache, Kulm, Mostefa, 2005) et la langue cible consideree est l’italien
puisque nous disposons egalement, au depart, d’une partie du corpus MEDIA traduite en italien. Nous sommes
conscients de la proximite des langues source et cibles dans cette etude, mais ce choix est guide’ par les donnees
disponibles au depart. Le portage vers l’arabe est aussi envisage et fait l’objet de travaux en cours. Les
approches proposees dans cet article sont completement automatiques et sans aucune supervision humaine lors
du processus de portage.

Plus precisement, le but de cet article est de :

- proposer et evaluer differentes approches utilisant la traduction automatique pour porter un systeme
SLU vers une nouvelle langue,

- considerant ensuite la meilleure approche obtenue, accroitre sa robustesse aux erreurs de traduction.

Dans ces travaux, les modeles utilises sont les champs aleatoires conditionnels (Conditional Random Fields,
CRF) pour la comprehension automatique et l’approche a base de sequences (phrase—based statistical machine

COMPARAISON ET COMBINAISON D ’APPROCHES POUR LA PORTABILI T E VERS UNE N0 UVELLE
LANGUE D ’UN SYSTEME DE COA/IPREHENSION DE L ’0RAL

TaggedTranslati0n, nous proposons de traduire les donnees d’entrainement de MEDIA, segment par segment,
au moyen du traducteur en ligne, puis ces traductions sont associees aux etiquettes semantiques initiales. Dans
une seconde version, les donnees sont traduites integralement puis utilisees comme corpus parallele pour
l’approche Alignement.

Pour choisir un traducteur automatique dans le cadre de nos experiences nous avons compare les performances
de deux traducteurs reputes. Le test MEDIA et sa traduction manuelle ont ete utilise’ comme couple
test/reference dans chacune des directions de traduction. Pour l’Italien vers le francais un traducteur de score
BLEU 42,58 a ete selectionne (a comparer a 47,18 obtenu par le systeme SMT appris sur les traductions
manuelles), et pour le francais vers l’italien un traducteur de score 39,75 a ete retenu (a comparer avec 43,62).
Les resultats de cette experience sont reportes dans le tableau 6.

De maniere attendue les performances des systemes obtenus par cette approche non-supervisee sont inferieures a
celle des systemes semi-supervises. Toutefois malgre la degradation du CER pour toutes les approches son
niveau absolu reste tout a fait acceptable considerant les besoins de la tache et la reduction substantielle du coﬁt
de developpement.

La methode Alignement est la plus perturbee et devient presque equivalente a T aggedT ranslation en version
non-supervisee. Le CER augmente de 22,7% a 26,6% (+3,9% absolu) pour T aggedTranslati0n et de 20,5% a
26,5% (+6%) pour Alignement. T est0nSource perd 3,2% mais reste la plus perforn1ante. Ces resultats nous
engagent a tester de nouvelles langues pour lesquelles nous ne disposons pas de traductions manuelles.

Model Sub Del Ins CER

Semi supervise

SLU/CRF(Test0nSource) 5,2 12,1 2,6 19,9

SLU/CRF(TaggedTranslation) 3,7 16,9 2,1 22,7

SLU/CRF(Alignment) 3,1 15,0 2,3 20,5

Non supervise

SLU/CRF(Test0nSource) 6,1 14,5 2,5 23,1

SLU/CRF(TaggedTranslation) 5,5 15,4 5,7 26,6

SLU/CRF(Alignment) 6,3 14,8 5,4 26,5

Tableau 6 : Evaluation (CER %) des strategies de portabilite SLU/CRF en utilisant des traductions en ligne
6 Conclusion

Dans cet article on a propose et compare plusieurs approches pour la portabilite d’un SLU a travers les langues.
Les CRFs et le PB -SMT on ete utilise pour cette tache et les resultats montrent que l’utilisation d’un etiqueteur a
base de CRF avec des donnees de test traduites donne la meilleur performance. On a aussi montre l’interét de
l’utilisation de deux methodes differentes pour accroitre la robustesse du SLU aux erreurs de traduction. Enﬁn
on a montre que la combinaison de toutes les methodes proposees augmente la performance du systeme.

Remerciements

Ce travail est supporte par le projet ANR PORT-1V[ED1A (ANR 08 CORD 026 01). Plus d’information
disponible sur le site du projet : www.port-media.org

BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE

Références

Suenderman K., Liscon1be J. (2009). From rule-based to statistical gran1mars: Continuous improvement of large-
scale spoken dialog system. Actes de ICASSP.

Hahn S., Lehnen S., Raymond C., Ney H. (2008). A comparison of various methods for concept tagging for
spoken language understanding. Actes de LREC.

Raymond C., Riccardi G. (2007). Generative and discriminative algorithms for spoken language understanding.
Actes de Interspeech.

Wang Y., Acero A. (2006). Discriminative models for spoken language understanding. Actes de ICSLP.

Schwartz R., l\/Iiller S., Stallard D., Makhoul J. (1996). Language understanding using hidden understanding
models. Actes de ICSLP.

Suenderman K., Liscon1be J. (2009). Localization of speech recognition in spoken dialog systems: How machine
translation can make our lives. Actes de Interspeech.

Servan C., Camelin N., Raymond C., Bechet F., De Mori R. (2010). On the use of machine translation for
spoken language understanding portability. Actes de ICASSP.

Lefevre F., Mairesse F., Young S. (2010). Cross-lingual spoken language understanding from unaligned data
using discriminative classiﬁcation models and machine translation. Actes de Interspeech.

Jabaian B., Besacier L., Lefevre F. (2010). Investigating multiple approaches for SLU portability to a new
language. Actes de Interspeech.

Bonneau-Maynard H., Rosset S., Ayache C., Kuhn A., Mostefa D. (2005). Semantic annotation of the French
media dialog corpus. Actes de Eurospeech.

Lafferty J ., McCallum A., Pereira F. (2001). Conditional random fields: Probabilistic models for segmenting and
labelling sequence data. Actes de ICML.

Koehn P., Och F., Marcu D. (2003). Statistical phrase_based translation. Actes de HLT/NAA CL.

Koehn P., Hoang H., Birch A., Callisonburch C., Federico M., Bertoldi N., Cowan B., Shen W., Moran C., Zens
R., Dyer C., Bojar O., Constantin A., Herbst E. (2007). Moses: Open source toolkit for statistical machine
translation Actes de ACL.

Och F., Ney H. (2000). Improved Statistical Alignment Models. Actes de ACL.

Liang P., Taskar B., Klein D. (2006). Alignment by agreement. Actes de HLT.

Stolcke A. (2002). SRILM an extensible language modeling toolkit. Actes de SLP.

Simard M., Goutte C., Isabelle P. (2007). Statistical phrase-based post-editing. Actes de NAACL.

Diaz de Ilarraza A., Labaka G., Sarasola K. (2008). Statistical post-editing: A valuable method in domain
adaptation of RBMT systems for less-resourced languages. Actes de A/MTMT.

COMPARAISON ET COMBINAISON D ’APPROCHES POUR LA PORTABILI T E VERS UNE N0 UVELLE
LANGUE D ’UN SYSTEME DE COA/IPREHENSION DE L ’0RAL

translation) pour la traduction automatique. Les CRF (Lafferty, McCallum, Pereira, 2001) sont connus pour étre
tres performants sur des taches d’et:iquetage temporel (annotation en entites nommees, etiquetage syntaxique,
etc). Ils necessitent un corpus annote au niveau mots. Pour porter notre systeme vers une nouvelle langue, nous
avons propose’ plusieurs méthodes qui different selon le moment ou est utilise le module de traduction. En effet,
un systeme de comprehension peut étre porte soit au niveau du test (T est0nSource), en conservant le systeme
SLU en langue source et en traduisant simplement les donnees de test en langue cible vers la langue source. La
seconde possibilite consiste a porter le systeme au niveau de l’apprentissage (Train0nTarget) en construisant un
nouvel etiqueteur semantique dans la langue cible. Pour cela, nous traduisons automatiquement l’integralite du
corpus d'apprentissage de la langue source vers la langue cible, puis nous inferons l'annotat:ion semantique de ce
corpus pour les donnees traduites. Pour ce faire, nous proposons deux méthodes differentes. La premiere
consiste a l'aide d’un systeme de traduction probabiliste source-cible, a traduire chaque phrase source armotee,
segmentee en segments, et d’utiliser les segments traduits, associes aux etiquettes semantiques, pour construire
un nouveau systeme SLU en langue cible. La seconde approche utilise les informations extraites des alignements
mot-a-mot pour inferer une relation mot_cible-etiquette_semantique (plus de details seront donnees dans la
section 2).

Une autre approche, completement differente, consiste :31 voir le processus de comprehension comme une tache
de traduction automatique d’une chaine de mots vers une chaine d’etiquettes semantiques. Dans ce cas, le
modele de comprehension est une table de traduction mots-concepts. L’approche a base de sequences (phrase-
based) (Koehn, Och, Marcu, 2003) necessite des donnees alignees au niveau phrase avant le processus
d’apprent:issage (dont la premiere etape sera un alignement automatique en mots utilisant les modeles IBl\/I).
Dans ce cas, la portabilite vers une nouvelle langue consiste simplement a traduire en langue cible la partie
“mots” du corpus d’apprentissage mots-concept sans modiﬁer les concepts.

Pour repondre au deuxieme point (robustesse), et puisque nous allons voir que la methode T est0nSource donne
les meilleures performances, nous proposons quelques méthodes pour augmenter la robustesse aux erreurs de
traduction du systeme porte. Pour cela, une premiere approche presentee consiste a re-entrainer le systeme de
comprehension, fonde sur les CRF, sur des donnees bruitees representant les erreurs potentielles de traduction.
La deuxieme approche consiste a utiliser une post-edition automatique statistique (Statistical Post Edition, SPE)
dans la langue-source pour tenter de corriger automatiquement les sorties issues du systeme de traduction
automatique, avant de les envoyer a l'etiqueteur semantique. Pour finir, nous proposons aussi dans cet article de
combiner toutes les approches proposees dans cette etude, afin de reduire le taux d'erreurs de comprehension.

Cet article est structure’ de la facon suivante : la section 2 presente en detail les approches que nous proposons
pour porter un systeme de comprehension vers une nouvelle langue. La section 3 decrit deux solutions pour
ameliorer la robustesse de notre meilleur systeme porte, aux erreurs de traduction automatique. Le corpus
MEDIA et les outils utilises sont decrits dans la section 4 tandis que la section 5 presente les resultats
experimentaux obtenus. Finalement, conclusion et perspectives sont presentees dans la section 6.

2 Différentes méthodes pour porter un systéme de compréhension d’une langue vers une
autre

Dans un systeme de dialogue, le role du processus de comprehension est d'extraire une liste d'hypotheses
d’étiquettes de concepts a partir d'une phrase en entree. Ces concepts representent la semantique de l'inforn1ation
existant dans la phrase en entree. Les modeles de comprehension developpes dans cette etude sont entraines sur
le corpus MEDIA, annote en concepts semantiques (voir section 4).

La generation automatique de ces concepts a partir d’une sequence de mots par des méthodes stochastiques telle
que decrite dans (Raymond, Riccardi, 2007), peut étre resumee de la facon suivante :

Soit C= c1,...,cn une sequence d’etiquettes semantiques qui peut étre associee initialement a la sequence de mots
W= w1,...,wn ; pour chaque concept, une sequence de mots de W est associee et une etiquette est attribuee a
chaque mot. Cette etiquette correspond au concept semantique ci et a la position de wi.

Plusieurs etudes ont propose de comparer differentes méthodes pour entrainer un modele de comprehension de
la parole (Hahn, Lehnen, Raymond, Ney, 2008) (Raymond, Riccardi, 2007). Dans cet article, nous proposons
d’utiliser et d’evaluer deux approches etat-de-l’art.

La premiere est fondee sur les champs aleatoires conditionnels (Conditional Random Fields, CRF), qui ont
besoin d’un corpus annote au niveau mot pour étre entraines. La seconde utilise une approche de traduction

BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE

probabiliste fondee sur les sequences (Phrase—Based Statistical Machine Translation, PB—SMT) et necessite un
corpus d’apprentissage annote au niveau des phrases.

2.1 Champs aléatoires conditionnels (CRF)

Les CRF ("Conditional Random Fields" ou "Champs Aleatoires (Markoviens) Conditionnels") sont une fan1ille
de modeles graphiques introduits recemment (Lafferty, McCallum, Pereira, 2001). Ils perrnettent d’apprendre a
annoter des donnees, en se basant sur un ensemble d’exemples deja annotes. Les CRF ont le plus souvent ete
utilises dans le domaine du TAL, pour etiqueter des sequences d’unites linguistiques. Ces modeles possedent les
avantages des modeles generatifs et discriminants. En effet, comme les classiﬁeurs discriminants, ils peuvent
manipuler un grand nombre de descripteurs, et comme les modeles generatifs, ils integrent des dependances
entre les etiquettes de sortie et prennent une decision globale sur la sequence. Par rapport aux modeles de
Markov Caches (HMMs), les CRF ont par ailleurs l’avantage de relacher certaines hypotheses d’independance.

Dans notre cas, pour apprendre notre modele CRF, les donnees d’apprentissage doivent etre representees selon
le formalisme BIO decrit dans (Raymond, Riccardi, 2007), qui indique les frontieres entre les concepts
semantiques selon l’exemple ci-dessous :

“J e voudrais reserver un hotel a Paris ”
Sera represente par la sequence de couples (w,c):

(je, B_comn1and-tache) (voudrais, I_comn1and-tache) (reserver, I_comn1and-tache) (un, B_Objet) (hotel,
I_objet) (a, B_loc-ville) (Paris, I_loc-ville)

La probabilite d’une sequence de concepts, etant donnee une sequence de mots est alors calculee par :
1 N
p(ci"|wi“ > = 3 1_[H(c..-..c..w:.L+§
n=1
avec

M
H(c..-..c.. .w::§> = Z A... .h... cc.-. . c...w.':.+22>
m=1

H est un modele log-lineaire fonde sur des fonctions caracteristiques hm (cn_1,cn,w,’{f22) qui representent
l’information extraite du corpus d’apprentissage ; les poids it du modele log-lineaire sont estimes lors de
l’apprentissage et Z est un terrne de normalisation definit tel que :

M N

_ +2

Z _ 2 H (Cn—1:CnrW111l—2
1

=1 11:

Afin de porter notre systeme de comprehension fonde sur les CRF (note SLU/CRF par la suite) d’une langue a
une autre, nous avons propose plusieurs approches qui different selon le moment ou est applique le processus de
transfert entre les langues.

2.1.1 Portage au niveau du test (Test On Source)

Dans cette approche, nous supposons qu’un systeme SLU est disponible en langue source, et nous utilisons un
systeme de traduction automatique probabiliste pour traduire les phrases de test en langue cible vers la langue
source. Ces traductions sont ensuite les entrees du systeme SLU original. En d’autres termes, nous portons le
systeme << au niveau du test » sans modifier le processus d’apprentissage du systeme SLU. Cette technique sera
denommee T est0nSource dans la suite de cet article. Elle a l’avantage d’etre tres simple mais ses performances
dependront, bien evidemment, des performances du systeme de traduction automatique utilise pour revenir de la
langue cible a la langue source.

COMPARAISON ET COMBINAISON D ’APPROCHES POUR LA PORTABILI T E VERS UNE N0 UVELLE

LANGUE D ’UN SYSTEME DE COJI/IPREHENSION DE L ’0RAL

2.1.2 Portage au niveau de l’apprentissage (Train On Target)

Cette approche consiste a re-entrainer un systeme SLU en langue cible. L’idée générale est de traduire le corpus
d’apprentissage de la langue source vers la langue cible et d’inférer les étiquettes sémantiques associées. Pour
inferer l’armotation semantique, nous proposons deux approches différentes :

1.

Traduire avec des tags XML (Tagged Translation):

Dans cette approche, le corpus d’apprentissage est traduit en prenant en compte la segmentation en
<< segments sémantiques » (un << segment» est compose potentiellement de plusieurs mots mais
correspond a une et une seule etiquette sémantique). Pour cela, nous utilisons une option (-xml—input)
du décodeur MOSES (Koehn, Hoang, Birch, Callisonburch, Federico, Bertoldi, Cowan, Shen, Moran,
Zens, Dyer, Bojar, Constantin, Herbst, 2007), qui force la segmentation d’une phrase a traduire, cette
segmentation étant décrite par des tags XML. Ainsi, en sortie, nous obtenons chaque phrase du corpus
d’apprentissage traduite, ainsi qu’une projection des tags XML de la source vers la cible. L’exemple
donné précédemment peut alors etre représente sous la forme suivante :

<tag c:c0mmanditache > Je voudrais réserver </tag> <tag c:0bjet > un h0‘tel </tag> <tag
c:l0calisati0niville> a Paris </tag>

En utilisant l’option de MOSES qui prend en compte les tags XML comme information de
segmentation, nous obtenons la sortie traduite suivante :

<tag c: commanditache > vorrei prenotare </tag> <tag c:0bjet> un hotel </tag> <tag c:
l0calisati0niville> aParigi </tag>

Tout le corpus d’apprentissage est traduit de cette facon puis re-formaté au format BIO avant un nouvel
apprentissage du modele CRF de comprehension en langue cible.

Projections des concepts sémantiques d’une langue a l’autre en utilisant un alignement en mots
(Alignment):

L’alignement automatique en mots est une étape importante dans le processus de construction d’un
modele de traduction probabiliste. Plusieurs boites a outils existent pour cette tache telles que GIZA++
(Och, Ney, 2000) qui utilise les modeles IBM et Hl\/[l\/I, ou Berkeley aligner (Liang, Taskar, Klein,
2006) qui repose sur une méthode d’alignement par consensus (alignment by agreement).

Pour projeter les concepts sémantiques d’une langue a l’autre, on peut utiliser les informations
d’alignement bilingue en mots. Plus précisement, la premiere phase consiste a aligner automatiquement
le coipus parallele source-cible. Ensuite, comme le corpus source est déja armote sémantiquement, il est
possible d’apparier les étiquettes sémantiques aux mots en langue cible en utilisant l’information
d’alignement. Certains cas ambigus demeurent cependant, comme illustré dans la figure 2 (alors que la
figure 1 présente un cas ou la projection est évidente). Dans cet article, l’aligneur utilise est Berkeley
Aligner.

Command-tache obj et loc-ville

I I I I
Je voudrais réserver un hotel a Paris

\//////

Vorrei prenotare un hotel a Parigi

Figure 1 : Exemple de projection des tags sémantiques du francais vers l’italien

Pour faire cette projection, nous avons développe un algorithme qui parcourt la phrase en langue cible
et associe aux mots la bonne etiquette semantique. Pour les cas ambigus ou un mot cible est aligné avec
plusieurs mots sources correspondent a deux concepts différents (voir figure 2), nous devons prendre
une decision sur quel concept doit etre associe au mot cible. Pour cela, notre proposition est de
simplement associer le mot cible au premier concept rencontre. Par exemple, sur la figure 2, le mot
italien alla sera associe au concept loc—dis et pas au concept loc—lieu. Cette decision, bien qu’arbitraire,
a l’avantage d’€:tre cohérente d’un bout a l’autre du corpus si le meme cas est rencontré a nouveau.

BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE

loc-dis loc-lieu
Pres de la bastille

\ \%

Vicino alla bastilia
Figure 2 : Exemple de cas ambigu pour la projection des concepts sur les mots cible

2.2 Compréhension par une approche de traduction (PB-SMT)

Afin d’eviter de recourir a un corpus d’entrainement annote au niveau mot, nous proposons d’utiliser l’approche
PB-S1\/[P qui ne necessite qu’un alignement au niveau des phrases completes. Dans cette approche, nous
considerons que les sequences de concepts sont les traductions des sequences de mots initiales. Ainsi
l’etiquetage semantique est vu comme une tache de traduction : la meilleure sequence C a partir des mots W est
de'finie par :

A

C = argmaxCP(C|W) = argmaxCP(W|C).P(C)

Pour resoudre cette equation sont requis : un modele de langage de concepts P(C) (qui peut étre appris a l’aide
de SRILM (Stolcke, 2002) sur le corpus de concepts) et d’un model de traduction P(Wl C) (qui peut étre un
modele PB-SMT par exemple). Nous avons utilise MOSES pour entrainer un tel modele PB -SMT :31 partir d’un
corpus «parallele ». Les poids associes a ce modele sont optimises par un apprentissage a taux d’erreur
minimum (MERT) qui est traditionnellement utilise pour optimiser le score BLEU. Puis les performances de
cette approche PB-SMT de base ont ete ameliorees en utilisant des caracteristiques de la tache de comprehension
se’mantique.

D’abord, en suivant l’hypothese raisom1able que la semantique d’une phrase respecte l’ordre dans lequel les
mots sont emis, la table de segments est re-entrainee en utilisant une contrainte de monotonie durant
l’alignement automatique en mots. Puis, dans la mesure ou une difficulte maj eure du processus de traduction est
l’alignement automatique correct d’un mot du langage source avec le mot correspondant dans le langage cible,
nous avons tente d’aider le processus d’alignement par l’utilisation du formalisme BIO. De cette facon,
l’extraction de la table de segments a ete obtenue sur un corpus avec un alignement de meilleure qualite. Enﬁn,
la mesure d’evaluation du SLU etant le CER et non le score BLEU, nous avons modifie l’optimisation 1\/[ERT
pour optin1iser le CER directement. Finalement, pour éviter les mots hors-vocabulaire (venant principalement de
noms de ville absents des données d’entrainement), une liste de villes est ajoutee aux données d’apprentissage et
le systeme SL U/PB-SMT est re-entraine.

3 Accroitre la robustesse du SLU aux erreurs de traduction

Nos experiences, ainsi que d’autres travaux (Lefevre, Mairesse, Young, 2010) (Jabaian, Besacier, Lefevre,
2010), ont montre que la meilleure methode pour la portabilite SLU est aussi la plus simple, le T est0nSource. La
faiblesse principale de cette methode est que la qualite de l’etiquetage depend grandement de la qualite de la
traduction prealable. Ainsi, le systeme SLU doit prendre en compte des entrees bruitees par les erreurs de
traduction.

De sorte a ameliorer la robustesse de l’approche, nous proposons deux methodes dans ce papier. La premiere
prend en compte le bruit venant de la traduction durant le processus d’apprentissage des modeles SLU; la
seconde corrige automatiquement la sortie du systeme de traduction avant de la transferer au systeme SLU. Il est
notable que, bien que pas encore evaluées dans ce cadre (par manque de données audio dans la langue cible), les
deux methodes seront tout a fait adaptees pour traiter aussi les erreurs dues a la reconnaissance de la parole dans
une tache de comprehension reelle.

3.1 Apprentissage sur des données bruité

Le principe de cette methode est d’entrainer un modele SLU (dans le langage source) avec des données
additionnelles provenant de la sortie d’un systeme de traduction automatique. En pratique, nous traduisons les
données d’apprentissage disponibles entre les langues cible et source et nous inferons les concepts associes aux
données bruitees (en suivant la meme methode que T rain0nT arget). Puis nous ajoutons les données corrompues
(maintenant annotees semantiquement) aux données originales et l’ensemble est utilise pour entrainer le nouveau
modele SLU (dans la langue source) qui alors integrera le bruit present dans les données traduites.

COMPARAISON ET COMBINAISON D ’APPROCHES POUR LA PORTABILI T E VERS UNE N0 UVELLE
LANGUE D ’UN SYSTEME DE COA/IPREHENSION DE L ’0RAL

3.2 Post-édition statistique

Plusieurs travaux recents en traduction automatique comme (Simard, Goutte, Isabelle, 2007) (Diaz de Ilarraza,
Labaka, Sarasola, 2008) ont utilise’ une approche basee sur un systeme de traduction pour post-editer les sorties
d’un autre systeme de traduction. Un tel systeme, malgre une demarche qui peut paraitre contre-intuitive, a ete
propose pour ameliorer la qualite des donnees traduites avant leur envoi a des post-editeurs humains. Pour
entrainer un tel post-editeur, (Simard, Goutte, Isabelle, 2007) (Diaz de Ilarraza, Labaka, Sarasola, 2008) utilisent
les sorties d’un systeme SMT avec comme donnees paralleles leur post-edition manuelle.

Dans notre cas, dans la mesure ou la sortie du systeme SMT sera utilisee comme entree du systeme SLU
entraine sur les donnees du langage source, nous proposons de post-editer cette sortie afin de din1inuer le bruit
du a la traduction des entrees utilisateurs.

Pour apprendre un SPE, notre choix a ete de traduire automatiquement l’ensemble de donnees disponibles pour
la langue cible, puis d’utiliser les sorties traduites avec les parties correspondantes transcrites manuellement,
comme corpus parallele. Nous pensons que le module de post-edition permettra ainsi de reordonner quelques
mots ou de retrouver des mots manquants dans un certain nombre de phrases.

4 Description du corpus et d’outils

Toutes les experiences decrites dans le papier ont ete realisees sur le corpus francais MEDIA. Ce travail a ete
motive par la disponibilite d’une traduction manuelle en italien d’une sous-partie de ce corpus.

4.1 Le corpus MEDIA

Comme decrit dans (Bonneau -Maynard, Rosset, Ayache, Kuhn, Mostefa, 2005), ce corpus couvre un domaine
lie aux reservations de chambres d’h6tels et aux informations touristiques. Le corpus est constitue de 1257
dialogues enregistres par 250 locuteurs, collectes en situation de Wizard-of-Oz (un humain simule le systeme de
dialogue).

Les dialogues sont regroupes en 3 parties : un ensemble d’apprentissage (environ 13k phrases), un ensemble de
developpement (1,3k phrases) et un ensemble d’evaluation (3k phrases). Dans nos experiences, nous ne prenons
en compte que les phrases utilisateurs.

Le corpus est etiquete avec 99 concepts differents. Ces etiquettes peuvent étre simples comme les dates ou les
noms de ville ou peuvent étre plus complexes comme les coreferences. A titre d’illustration, voici une phrase de
MEDIA :

Je voudrais une chambre double a Marseille

L’armotation semantique de cette phrase aura la forme :
Je voudrais [null], une [nombre-chambre], chambre double [chambre-type], a Paris [localization-ville].

Cette annotation semantique découpe chaque phrase en plusieurs segments. Chaque segment est non seulement
armote avec le nom du concept mais aussi par une valeur, une modalite et un specifieur. Les experiences
presentees dans le papier prennent en compte uniquement le nom du concept et la modalite du segment.

Un sous-ensemble de l’apprentissage (environ 5.6k phrases), de meme que les ensembles de test et de
developpement, ont ete manuellement traduit en italien dans le contexte du projet europeen LUNA (Servan,
Camelin, Raymond, Bechet, De Mon, 2010).

4.2 Les SMTs apprit

Dans cette etude, nous utilisons deux systemes de traduction automatique pour obtenir les traductions du
francais vers l’italien et de l’italien vers le francais. Pour realiser ces traductions, la boite a outils Moses (Koehn,
Hoang, Birch, Callisonburch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst,
2007) est utilisee. Moses implemente l’etat-de-l’art des systemes de traduction par segments utilisant des
modeles log-lineaires.

Nous utilisons la partie manuellement traduite en italien de l’ensemble d’apprentissage du corpus MEDIA
comme corpus parallele pour Moses dans les deux directions pour entrainer les modeles. Chacune des parties
separement permet l’apprentissage d’un modele de langage. Aussi l’ensemble de developpement avec sa
traduction est utilise comme corpus parallele pour ajuster les poids du modele log-lineaire des systemes SMT.
Finalement, nous obtenons un systeme de francais vers l’italien avec un score BLEU de 43,62 et de l’italien vers

BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE

le francais avec un score de 47,18. Ces scores sont mesures sur l’ensemble de test de MEDIA manuellement
traduit. Dans la mesure ou une seule reference par phrase est utilisee pour evaluer le score BLEU, de meme que
l’ensemble d’apprentissage est reduit (5,6k), ces performances peuvent etre considerees comme tres acceptables.

Nous avons aussi re-traduit automatiquement en francais la version manuelle en italien du corpus, de sorte a
utiliser cette traduction en parallele de la partie originale pour entrainer le SPE et fournir les donnees bruitees
pour le SCTD. Du point de vue de la performance de traduction exclusivement, l’utilisation de la post-edition
automatique ameliore le score BLEU du systeme de 47,18 a 49,25.

4.3 Compléter la traduction de MEDIA

Le systeme de traduction francais-italien est utilise pour obtenir une traduction automatique de la partie restante
(non traduite manuellement) du corpus d’apprentissage, ainsi une traduction integrale (manuelle + automatique)
est disponible. Le systeme italien-francais est utilise pour traduire le test italien en francais, qui sera utilise pour
l’approche T est0nSource. Le tableau 1 donne un apercu des ensembles disponibles pour les experiences.

MEDIA data Train Dev Test

French MEDIA 13K 1,3K 3,5K

Italian manual 5,6K 1,3K 3,5K
Italian automatic 7,4K - -

Tableau 1: apercu du corpus MEDIA et de sa traduction vers l’italien (# phrases).
5 Experiences et résultats

Afin d’evaluer les performances des approches proposes, la traduction manuelle en italien des donnees de test
est utilisee. Le CER est le critere d’evaluation retenu pour cette etude. Le CER est l’equivalent du taux d’erreur
en mots (WER), et peut etre defini comme le ratio de la somme des concepts on1is, inseres et subtilises sur le
nombre de concepts dans la reference. Premierement nous evaluons et comparons SLU/CRF et SLU/PB-SMT,
nous evaluons de meme notre proposition de robustesse, puis les systemes sont combines. Pour finir, nous
validons nos approches en utilisant les traductions obtenues par un systeme de traduction en ligne (ie sans
utiliser de traduction manuelle).

5.1 Les strategies de portabilité SLU/CRF

La totalite de l’ensemble d’apprentissage de MEDIA est utilise pour apprendre un etiqueteur francais de base
utilisant des uni- et bi-grammes. Cette base atteint de bonnes performances (12,9% CER) et peut etre consideree
comme une reference pour les methodes proposees. Pour evaluer les performances de l’approche T est0nSource
la traduction automatique en francais du test italien (comme decrit en 4) est fournie a l’etiqueteur de base.

La methode T rain0nT arget decrite dans 2.1.2 a ete appliquee. Nous utilisons le systeme francais-italien (decrit
en 4) pour traduire le corpus d’entrainement integrant des balises XML correspondant aux segments conceptuels
aﬁn d’evaluer la methode T aggedT ranslation, et la totalite des traductions en italien de MEDIA (manuelle et
automatique) avec la version francaise comme corpus parallele pour obtenir l’alignement mot-a-mot.
L’information d’alignement telle que defini en 2.1.2 est utilisee, pour evaluer la performance de la methode
Alignement. Toutes les experiences utilisent l’outil CRF++ (httpss//crjfvp.sourceforganev. L’ensemble des
résultats est regroupes dans le tableau 2.

Il apparait clairement a la lecture des resultants que la methode Alignement est meilleure que
T aggedT ranslation. Ceci peut étre explique par le fait que Alignement est seulement inﬂuence par les erreurs
d’alignement, tandis que T aggedT ranslation est inﬂuence par les erreurs de traduction automatique qui sont plus
importantes. On note aussi que la methode T est0nSource est plus perforn1ante que les methodes
T rain0nT arget.les performances de toutes les methodes sont considerees come bonne en comparaison avec la
reference francaise.

COMPARAISON ET COMBINAISON D ’APPROCHES POUR LA PORTABILI T E VERS UNE N0 UVELLE
LANGUE D ’UN SYSTEME DE COA/IPREHENSION DE L ’0RAL

Model Sub Del Ins CER

FR 3,1 8,1 1,8 12,9

SLU/CRF(Test0nSource) 5,2 12,1 2,6 19,9

SLU/CRF(TaggedTranslation) 3,7 16,9 2,1 22,7

SLU/CRF(Alignment) 3,1 15,0 2,3 20,5

Tableau 2 : Evaluation (CER %) de différentes strategies de portabilite du SLU utilisant les méthodes SLU/CRF

5.2 SLU/PB-SMT

Nos premieres tentatives pour construire le modele PB-SMT pour le SLU italien ont clairement montré des
performances inferieures aux CRF (CER=28, 1% apres réglage 1\/[ERT pour le PB -SMT compare aux ~20% pour
les CRF). Les ameliorations progressives du modele proposées en Section 2.2 sont évaluées dans le tableau 3.
L’utilisation de la contrainte de monotonie durant l’alignement en mot perrnet une reduction de 0,6% absolu.
Convertir les données selon le formalisme BIO avant la phase d’apprentissage réduit le CER de facon
significative de 2,8%. Enfin optimiser le CER a la place du BLEU réduit le CER de 0,3% supplementaire.
L’ajout d’une liste de villes a l’ensemble d’apprentissage avant reapprentissage du modele PB -SMT perrnet une
reduction ﬁnale de 0,5%.

Les résultats montrent qu’en depit de réglages ﬁns de l’approche SMT, les approches a base de CRF obtiennent
toujours les meilleures performances. De plus, dans une experience parallele, un modele PB-SMT a été construit
pour le SLU Francais aﬁn de le tester dans l’approche T est0nSource. Mais les performances de l’approche sont
décevantes et bien en-deca de celles des autres méthodes. Elle a donc éte écartee pour le reste de l’étude.

A partir d’une analyse rapide du type d’erreurs de chaque modele, nous pouvons observer que les méthodes
utilisant des CRF ont un haut niveau de suppressions comparativement aux autres types d’erreurs, tandis que la
méthode PB-SMT présente un meilleur compromis entre les erreurs de suppression et d’insertion, et ce bien
qu’elle abouti a un CER plus éleve.

SLU/PB-SMT Sub Del Ins CER
Initial 6,5 4,0 18,6 29,1
+ MERT (BLEU) 6,3 9,3 12,5 28,1
+ Monotone align 7,4 8,4 11,8 27,5
+ BIO format 6,5 10,6 7,7 24,7
+ MERT (CER) 6,4 10,9 7,2 24,4
+ City list 7,2 10,5 6,1 23,9

Tableau 3 : améliorations iteratives de la méthode SLU/PB-SMT sur le test italien de MEDIA (CER%)

5.3 SLU/CRF T est0nS0urce robuste

Nous avons tente d’améliorer les performances de la méthode T est0nS0urce SLU/CRF en renforcant sa
robustesse aux erreurs de traduction. Premierement nous traduisons automatiquement la partie manuelle en
italien. Ensuite nous apprenons un nouvel etiqueteur CRF simultanément sur les donnees d’apprentissage en
francais et traduites (approche +SCTD, décrite en 3.1). La méthode de la section 3.2 (SPE) a aussi été évaluée,
dans laquelle le test traduit post-edite a éte transn1is aux CRF de base (+SPE) ou aux CRF appris sur les donnees
corrompues (+SCTD+SPE).

BASSAM JABAIAN, LAURENT BESACIER, FABRICE LEFEVRE

L’evaluation des performances de ces approches sont rapportees dans le tableau 4. Les deux methodes,
d’apprentissage sur donnees bruitees et SPE, ameliorent les performances de l’etiqueteur semantique. Leur n1ise
en serie donne les meilleures performances.

SLU/CRF Sub Del Ins CER
Test0nSource 5,2 12,1 2,6 19,9
+SCTD 5,9 11,4 2,3 19,6
+SPE 6,5 10,6 2,5 19,7
+SCTD +SPE 6,4 9,9 2,9 19,3

Tableau 4 : Evaluation (CER %) des approches proposees pour la robustesse des systemes au bruit de traduction

5.4 Combinaison de systemes

Nous proposons de combiner les trois approches principales (T est0nT arget et Train0nTarget SLU/CRF, et
SLU/PB-SMT) afin de beneficier de leurs caracteristiques respectives pour ameliorer la performance globale. La
con1binaison (denotee BASIC dans le tableau 5) est simple : un reseau de confusion est construit a partir des
trois hypotheses et la sequence de concept correspondant a la plus grande probabilite a posteriori est calculee. La
performance est amelioree de facon significative (-1,3% CER) ce qui confirme la complementarite des
methodes.

Finalement nous combinons toutes les methodes proposees dans ce papier (SLU/CRF T rain0nT arge, SLU/CRF
Test0nSource, +SCTD, +SPE, +SCTD+SPE, SLU/PB-SMT). Ce qui permet d’atteindre les meilleures
performances rapportees sur ce test (18,2%). Afin de mesurer l’inﬂuence de la methode SLU/PB-SMT sur les
performances de la con1binaison, nous avons aussi evalue les performances de la combinaison diminuee de
SLU/PB-SMT. Cette experience a montre qu’en depit de ses mauvais resultats individuels, la methode PB -SMT
a une inﬂuence importante sur la con1binaison.

Model Sub Del Ins CER
BASIC 6,2 9,7 2,7 18,6

ALL 5,4 10,5 2,3 18,2

ALL — SLU/PB-SMT 6,6 10,2 2,7 19,4

Tableau 5 : con1binaison de systemes avec et sans l’approche PB-SMT

5.5 Validation des stratégies de portabilité SLU/CRF en utilisant des traductions en ligne uniquement

Les experiences presentees dans cet article ne sont pas totalement non-supervisees, dans tous les cas nous avons
utilise des donnees traduites manuellement pour obtenir le systeme de traduction pour T estOnS0urce ou pour
completer la traduction de l’apprentissage et obtenir les informations d’alignement pour la methode
T rainOnT raget.

Le coﬁt associe a cette traduction manuelle est relativement bas compare a celui de collecter et d’armoter un
nouveau corpus d’apprentissage, mais il reste non negligeable. Nous voulons veriﬁer qu’un tel coﬁt est justifie
par comparaison a une approche totalement non-supervisee et donc (potentiellement) << gratuite ».

Afin de repondre a cette interrogation nous proposons de reproduire les experiences en utilisant un systeme de
traduction gratuit en ligne a la place de notre systeme de traduction appris sur la tache.

Pour evaluer la methode T est0nS0urce nous traduisons le test MEDIA en italien a l’aide d’une solution gratuite
en ligne puis nous utilisons cette traduction comme entree de l’etiqueteur CRF de base. Pour la methode
Train0nTarget deux approches ont ete testees. Pour permettre la comparaison avec la me’thode

