TALN 2011, Montpellier, 27 juin -1” jui11et2011

Désambiguisation lexicale par propagation de mesures sémantiques
locales par algorithmes £1 colonies de fourmis

Didier Schwab, J ér6me Goulian, Nathan Guillaume
LIG-GETALP (Laboratoire d’Inforrnatique de Grenoble, Groupe d’l-/Etude pour la
Traduction/le Traitement Automatique des Langues et de la Parole)
Université Pierre Mendes France, Grenoble 2
{ didier. schwab, jerome. goulian } @ imag.fr

Résumé. Effectuer une tache de désarnbiguisation lexicale peut permettre d’améliorer de nombreuses ap-
plications du traitement automatique des langues comme l’extraction d’informations multilingues, ou la traduction
automatique. Schématiquement, il s’agit de choisir quel est le sens le plus approprié pour chaque mot d’un texte.
Une des approches classiques consiste a estirner la proximité sémantique qui existe entre deux sens de mots puis
de l’étendre a l’ensemble du texte. La méthode la plus directe donne un score a toutes les paires de sens de
mots puis choisit la chaine de sens qui a le meilleur score. La complexité de cet algorithrne est exponentielle et
le contexte qu’il est calculatoirement possible d’utiliser s’en trouve réduit. Il ne s’agit donc pas d’une solution
viable. Dans cet article, nous nous intéressons a une autre méthode, l’adaptation d’un algorithme a colonies de
fourmis. Nous présentons ses caractéristiques et montrons qu’il permet de propager a un niveau global les résultats
des algorithmes locaux et de tenir compte d’un contexte plus long et plus approprié en un temps raisonnable.

Abstract. Word sense disambiguation can lead to signiﬁcant improvement in many Natural Language Pro-
cessing applications as Machine Translation or Multilingual Information Retrieval. Basically, the aim is to choose
for each word in a text its best sense. One of the most popular method estimates local semantic relatedness bet-
ween two word senses and then extends it to the whole text. The most direct method computes a rough score for
every pair of word senses and chooses the lexical chain that has the best score. The complexity of this algorithm
is exponential and the context that it is computationally possible to use is reduced. Brute force is therefore not a
viable solution. In this paper, we focus on another method : the adaptation of an ant colony algorithm. We present
its features and show that it can spread at a global level the results of local algorithms and consider a longer and
more appropriate context in a reasonable time.

M0tS-CléS 3 Désarnbiguisation lexicale, Algorithrnes a colonies de fourmis, Mesures sémantiques.

Keywords: Lexical Disambiguation, Ant colony algorithms, Semantic relatedness.

1 Introduction

Effectuer une tache de désarnbiguisation lexicale peut permettre d’améliorer de nombreuses applications du traite—
ment automatique des langues comme l’extraction d’informations multilingues, le résumé automatique ou encore
la traduction automatique. Schématiquement, il s’agit de choisir quel est le sens le plus approprié pour chaque mot
d’un texte dans un inventaire pré—déﬁni. Par exemple, dans "La souris mange le fromage.", l’anirnal devrait etre

DIDIER SCHWAB, JEROME GOULIAN, NATHAN GUILLAUME

prefére au dispositif électronique. De nombreux travaux existent sur le sujet, que l’on sépare habituellement en
approches supervisees et non—supervisées. Les premieres utilisent des apprentissages realises grace a des corpus
manuellement annotés, les secondes n’utilisent pas de telles donnees. Une catégorie intermédiaire, constituée des
approches semi—supervisées, utilise quelques données armotées comme, par exemple, un sens par defaut issu d’un
corpus armoté lorsque l’algorith1ne principal echoue (Navigli & Lapata, 2010). Le lecteur pourra consulter (Ide &
Veronis, 1998) pour les travaux anterieurs a 1998 et (Agirre & Edmonds, 2006) ou (Navigli, 2009) pour un état
de l’art complet.

La creation de données armotées est une operation compliquée puisqu’elle nécessite une importante main d’oeuVre
et qu’ elle doit etre realisée pour chaque inventaire de sens, pour chaque langue et meme pour chaque domaine spe-
ciﬁque (sport, ﬁnance, . . .). Cette constatation, que nous partageons avec (Navigli & Lapata, 2010), nous conduit
a nous intéresser plus particulierement a des approches non—superVisees. Une de ces approches classiques consiste
a estimer la proximité sémantique qui existe er1tre deux sens de mots puis de l’etendre a l’ensemble du texte. En
d’autres tennes, il s’agit de donner des scores locaux et de les propager au niveau global (phrase, paragraphe,
texte, . . .). La methode la plus directe, utilisée par exemple par (Pedersen et al., 2005) utilise un algorithme brutal
qui donne un score a toutes les paires de sens de mots puis choisit la chaine de sens qui a le meilleur score. La
complexité de cet algorithme est exponentielle et le contexte qu’il est calculatoirement possible d’utiliser s’en
trouve réduit. Ainsi, alors qu’une analyse au niveau de la phrase n’est deja pas toujours possible, un contexte
linguistiquement plus pertinent comme, par exemple, le paragraphe l’est encore moins.

Les applications que nous Visons doivent pouvoir etre utilisées en temps reel. Lorsque l’on recherche une image
et encore plus lorsque l’on appelle quelqu’un qui parle une autre langue au telephone, les reponses doivent etre
immédiates. Il ne s’agit donc pas une solution Viable et nous étudions d’autres methodes.

Dans cet article, nous nous intéressons a la propagation de mesures de proximité sémantique locales grace a une
adaptation d’ un algorithme a colonies de fourmis. Nous présentons dans un premier temps les mesures locales que
nous utilisons puis quelques unes des caractéristiques de notre algorithme de propagation. Enﬁn, a titre d’exemple,
nous évaluons notre approche sur la tache gros grain de la campagne d’eValuation Semeval 2007 (Navigli et al.,
2007). Nous comparons en particulier notre algorithme de propagation a l’algorithme exhaustif classique et mon-
trons qu’il permet d’obtenir efﬁcacement une meilleure F—mesure.

2 Algorithmes locaux

2.1 Mesures de proximité sémantique

Ces méthodes consistent a donner un score censé reﬂéter la proximité des obj ets linguistiques (géneralement des
mots ou des sens de mots) compares. Ces scores peuvent etre des similarités, donc avoir une Valeur entre 0 et
1, des distances, et donc respecter leurs trois propriétés (separation, symétrie et inégalite triangulaire) ou plus
généralement, etre une Valeur positive non bomée.

Parmi elles, on peut citer Hirst & Saint—Honge basée sur la distance en terme de graphe entre deux sens dans un
reseau lexical; Rada et al. ainsi que Leacock and Chodorow similaires a la précédente mais ne considérant que
les liens de type hyperonymie; les mesures ou distances entre Vecteurs (LSA (Deerwester et al., 1990), Vecteurs
conceptuels (Schwab, 2005)). On pourra consulter (Pedersen et al., 2005), (Cramer et al., 2010) ou (Navigli, 2009)
pour un panorama plus complet.

En desambiguisation lexicale, ces methodes sont utilisees de fagon locale entre deux sens de mots, et sont ensuite

PROPAGATION DE MESURES SEMANTIQUES LOCALES PAR ALGORITHMES A COLONIES DE FOURMIS

| Algorithme local | Sous-corpus | Algorithme global | Etiquetés | Rappel | Diﬁérenﬁel |
A + B Exhaustif 77,30 53,50
Fourrnis 100,0 64,43 - 67,83 + 10,93 3 + 14,33
Lesk A Exhaustif 100,0 69,21
Fourrnis 100,0 65,45 - 68,99 - 3,76 3 - 0,22
B Exhaustif 00,00 00,00
Fourrnis 100,0 60,97 - 63,88 + 60,97 3 + 63,88
A + B Exhaustif 77,30 60,16
Fourrnis 100,0 72,54 - 75,5 + 12,38 3 + 15,34
Exhaustif 100,0 77,82
RS1‘ émd“ A Fourrnis 100,0 74,69 — 77,25 — 3,13 a — 0,57
B Exhaustif 00,00 00,00
Fourrnis 100,0 65,24 - 69,52 + 65,24 3 + 69,52

6 Conclusions et Perspectives

Dans cet article, nous avons présenté un algorithme a colonies de fourmis destiné a la désambiguisation lexicale et
base sur des mesures de proximité sémantique. Cet algorithme, non supervise, est Volontairement simple puisqu’il
n’utilise qu’une seule ressource lexicale (WordNet) et aucune analyse morphologique ou morpho—syntaxique. Il
permet pourtant de choisir un sens, pour chaque mot d’un texte, d’une maniere plus rapide que l’algorithme
exhaustif et en atteignant une bonne F—mesure pour un systeme non supervise. Nous considérons ces résultats
comme une ligne de base G)aseline) a partir de laquelle nous allons poursuivre nos recherches. Outre l’ajout
d’informations morphologiques et/ou syntaxiques, nous travaillons actuellement sur la combinaison de mesures
locales et l’utilisation de WordNet dans l’enVironnement des fourmis. Nos travaux portent également sur d’autres
algorithmes locaux et leur impact sur l’utilisation dans d’autres langues notarmnent ﬂexionnelles. Enﬁn, nous
travaillons a la comparaison des algorithmes a colonies de fourmis avec d’ autres algorithmes globaux comme les
algorithmes génétiques ou le recuit simulé.

Références

AGIRRE E. & EDMONDS P. (2006). Word Sense Disambiguation : Algorithms and Applications (Text, Speech
and language Technology). Secaucus, NJ, USA : Springer—Verlag New York, Inc.

BANERJEE S. & PEDERSEN T. (2002). An adapted lesk algorithm for word sense disambiguation using wordnet.
In the Third International Conference on Intelligent Text Processing and Computational Linguistics, CICLing
2002, Mexico City.

BONABEAU E. & THERAULAZ G. (2000). L’intelligence en essaim. Pour la science, (271), 66-73.

COWIE J ., GUTHRIE J . & GUTHRIE L. (1992). Lexical disambiguation using simulated annealing. In COLING
I 992, International Conference on Computational Linguistics, Volume 1, p. 359-365, Nantes, France.

CRAMER I., WANDMACHER T. & WALTINGER U. (2010). WordNet : An electronic lexical database, chapter
Modeling, Learning and Processing of Text Technological Data Structures. Springer.

DEERWESTER S. C., DUMAIS S. T., LANDAUER T. K., FURNAS G. W. & HARSHMAN R. A. (1990). Indexing
by latent semantic analysis. Journal of the American Society of Information Science, 41(6).

DENEUBOURG J .—L., GROSS S., FRANKS N. & PASTEELS J (1989). The blind leading the blind : Mode-
ling chemically mediated army ant raid pattems. Journal of Insect Behavior, 2, 719-725.

DORIGO & STUTZLE (2004). Ant Colony Optimization. lVlIT—Press.

DIDIER SCHWAB, JEROME GOULIAN, NATHAN GUILLAUME

DORIGO M. & GAMBARDELLA L. (1997). Ant colony system : A cooperative learning approach to the traveling
salesman problem. IEEE Transactions on Evolutionary Computation, 1, 53-66.

DROGOUL A. (1993). When ants play chess (or can strategies emerge from tactical behaviors). In Maa-
maw’l993.

FELLBAUM C. (1998). WordNet : An Electronic Lexical Database (Language, Speech, and Communication).
The MIT Press.

GALE W., CHURCH K. & YAROWSKY D. (1992). One sense per discourse. In Fifth DARPA Speech and Natural
Language Workshop, p. 233-237, Harriman, New—York, Etats—Unis.

GELBUKH A., SIDOROV G. & HAN S. Y. (2003). Evolutionary approach to natural language word sense
disambiguation through global coherence optimization. WSEAS Transactions on Communications, 2(1), 11-19.
GUINAND F. & LAFOURCADE M. (2009). Fourmis Artiﬁcielles 2. Nouvelles Directions pour une Intelligence
Collective, chapter Fourmis Artiﬁcielles et Traitement de la Langue Naturelle, p. 225-267. Lavoisier.

IDE N. & VERONIS J. (1998). Word sense disambiguation : the state of the art. Computational Linguistics,
28(1), 1-41.

LESK M. (1986). Automatic sense disambiguation using machine readable dictionaries : how to tell a pine cone
from an ice cream cone. In Proceedings of the 5th annual international conference on Systems documentation,
SIGDOC ’86, p. 24-26, New York, NY, USA : ACM.

N. MONMARCHE, F. GUINAND & P. SIARRY, Eds. (2009). Fourmis Artiﬁcielles et Traitement de la Langue
Naturelle. Prague, Czech Republic : Lavoisier.

NAVIGLI R. (2009). Word sense disambiguation : a survey. ACM Computing Surveys, 41(2), 1-69.

NAVIGLI R. & LAPATA M. (2010). An experimental study of graph connectivity for unsupervised word sense
disambiguation. IEEE Trans. Pattern Anal. Mach. Intell., p. 678-692.

NAVIGLI R., LITKOWSKI K. C. & HARGRAVES O. (2007). Semeval—2007 task 07 : Coarse—grained english
all-words task. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval—2007),
p. 30-35, Prague, Czech Republic : Association for Computational Linguistics.

PEDERSEN T., BANERJEE S. & PATWARDHAN S. (2005). Maximizing Semantic Relatedness to Perform Word
Sense Disambiguation. Research Report UMSI 2005/25, University of Minnesota Supercomputing Institute.

PONZETTO S. P. & NAVIGLI R. (2010). Knowledge-rich word sense disambiguation rivaling supervised sys-
tems. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, p.
1522-1531, Stroudsburg, PA, USA : Association for Computational Linguistics.

ROUQUET D., FALA1sE A., SCHWAB D., BOITET C., BELLYNCK V., NGUYEN H.—T., MANGEOT M. &
GUILBAUD J .—P. (2010). Rapport ﬁnal de synthese, passage a l’e’chelle et imple’mentation : Extraction de
contenu se’mantique dans des masses de données textuelles multilingues. Rapport inteme, Agence Nationale
de la Recherche.

SCHWAB D. (2005). Approche hybride — lexicale et the’matique - pour la mode’lisation, la detection et l’ex-
ploitation des fonctions lexicales en vue de l’analyse se’mantique de texte. PhD thesis, Université Montpellier
2.

SCHWAB D. & LAFOURCADE M. (2007). Lexical functions for ants based semantic analysis. In ICAI’07- The
2007 International Conference on Artiﬁcial Intelligence, Las Vegas, Nevada, USA.

VASILESCU F., LANGLAIS P. & LAPALME G. (2004). Evaluating variants of the lesk approach for disa1nbi—

guating words. In Proceedings of LREC 2004, the 4th International Conference On Language Resources And
Evaluation, p. 633-636, Lisbon, Portugal.

PROPAGATION DE MESURES SEMANTIQUES LOCALES PAR ALGORITHMES A COLONIES DE FOURMIS

appliquées a un niveau global. Dans cet article, nous nous concentrons sur l’algorith1ne global et, a des ﬁns de
comparaison, nous présentons deux algorithmes locaux bases sur l’algorith1ne de Lesk.

2.2 Algorithmes locaux de cette expérience
2.2.1 Des algorithmes inspirés par Lesk

Nous utilisons dans cet article deux Variantes de l’algorith1ne de Lesk (Lesk, 1986). Proposées il y a plus de 25
ans, il se caractérise par sa simplicité. Il ne nécessite qu’un dictionnaire et aucun apprentissage. Le score donné
a une paire de sens est le nombre de mots — ici simplement les suites de caracteres séparées par des espaces — en
commun dans leur deﬁnition, sans tenir compte ni de leur ordre, ni de sous—séquences communes (approche sac de
mots), ni d’informations morphologiques ou syntaxiques. Les Variantes de cet algorithme sont encore auj ourd’hui
parmi les meilleures sur l’anglais (Ponzetto & Navigli, 2010). Ce premier algorithme local est nommé dans la
suite Lesk.

Nous utilisons WordNet (Fellbaum, 1998), une base lexicale pour l’anglais, dans laquelle les sens de mots (les
synsets) sont relies par des relations Giyperonymie, hyponymie, antonymie, etc.). Notre second algorithme local
exploite ces liens. Au lieu d’utiliser uniquement la deﬁnition d’un sens, elle utilise également la deﬁnition des
différents sens qui lui sont lies. Cette idée est similaire a celle de (Banerjee & Pedersen, 2002) 1. Ce second
algorithme local est nommé dans la suite Lesk étendu.

2.2.2 Efﬁcacité algorithmique

L’ algorithme de base pour comparer le nombre de mots communs a deux deﬁnitions a une complexité en O(n x
m) avec n et m, les longueurs en mots des déﬁnitions. De plus, la comparaison de chaines de caracteres est
une operation relativement chere. On pourrait penser qu’il sufﬁrait de précalculer la matrice de similarités avec
l’ensemble des déﬁnitions. Cette idée est utopique Vu la taille que peuvent atteindre les dictionnaires (iusqu’a
plusieurs millions de deﬁnitions) 2 mais aussi parce qu’on a touj ours besoin de faire des calculs sur de nouvelles
données puisque (1) les données et les sens peuvent évoluer au cours du temps comme dans (Schwab, 2005), (2)
notre algorithme de propagation utilise des pseudo—déﬁnitions crées a la Volée (Voir partie 4.2.2).

Nous avons amélioré ce calcul en utilisant un prétraitement qui se déroule en deux étapes. Dans la premiere,
nous affectons a chacun des mots trouvés dans le dictionnaire un nombre entier tandis que, dans la seconde, nous
convertissons chacune des deﬁnitions en un Vecteur de nombres correspondant aux mots qu’elle contient, tries du
plus petit au plus grand. Nous appelons ces Vecteurs, vecteurs de déﬁnitions.

Par exemple, si notre premiere étape a donné “kind”: 1; “of”: 2; <<evergreen=== 3; “tree”: 4; “with”: 5
<<need1e—shaped=== 6; “leaves”: 7; “fruit”: 8; “Certain”: 9 avec la deﬁnition A, "kind of evergreen tree with
needle-shaped leaves", nous obtenons le Vecteur [1, 2, 3, 4, 5, 6, 7] et avec B, "fruit of certain evergreen tree",
nous obtenons [2, 3, 4, 8, 9].

Cette conversion a deux avantages : (1) la comparaison de nombres est bien plus efﬁcace que la comparaison
de chaines de caracteres, (2) ordonner ces nombres permet d’éViter des comparaisons inutiles et de gagner en

1. (Banerjee & Pedersen, 2002) introduit également une notion de sous-séquence identique dans les déﬁnitions. Nous n’avons pas encore
testé cette variante dont la complexité algorithmique est nettement supérieure 51 celle de notre algorithme.
2. Une forme de cache pourrait en partie régler ce probleme.

DIDIER SCHWAB, JEROME GOULIAN, NATHAN GUILLAUME

efﬁcacite. Ainsi, avec ce prétraitement, la complexite passe de O(n x m) a O(n) ou n et m (n 2 m) sont les
longueurs (en nombre de mots) des deﬁnitions.

Pour les deﬁnitions A et B, calculer cette meme proximité sémantique avec l’algorith1ne sur les deﬁnitions brutes
se fait en 7 x 5 = 35 operations (qui plus est sur des chaines de caracteres) tandis que si les deﬁnitions sont
converties en Vecteurs, nous n’aVons plus que 7 operations.

3 Algorithmes globaux

L’ algorithme global est l’algorithme qui Va permettre de propager les resultats d’un ou plusieurs algorithmes
locaux a l’ensemble du texte aﬁn de pouvoir en deduire un sens pour chaque mot. La methode la plus directe
est la recherche exhaustive utilisée par exemple dans (Banerjee & Pedersen, 2002). ll s’agit de considérer les
combinaisons de l’ensemble des sens des mots dans le meme contexte (fenetre de mots, phrase, texte, etc.), de
donner un score a chacune de ces combinaisons et de choisir celle qui ale meilleur score. Le principal probleme
de cette methode est la rapide explosion combinatoire qu’elle engendre. Considérons la phrase suivante tiree du
corpus d’eValuation que nous utilisons dans la partie 5, "The pictures they painted were ﬁat, not round as a ﬁgure
should be, and very often the feet did not look as if they were standing on the ground at all, but pointed downwards
as they were hanging in the air.", ‘picture’ a 9 sens, ‘paint’ 4, ‘be’ 13, ‘flat’ l7, ‘figure’ 13, ‘very’ 2, ‘often’ 2, ‘foot’
ll, ‘look’ 10, ‘stand’ 12, ‘ground’ ll, ‘at all’ 1, ‘point’ 13, ‘downwards’ I, ‘hang’ 15 et ‘air’ 9 sens, il y a alors 137 051
946 345 600 combinaisons de sens possibles a analyser. Ce nombre est comparable a la quantite d’opérations (et
le calcul d’une combinaison necessite des dizaines Voire des centaines d’operations) que peuvent theoriquement
effectuer 3300 processeurs Core i7—990X (2,43GHz, 6 coeurs, 12 ﬁls d’executions) sortis par Intel au premier
trimestre 2011 en une seconde. Le calcul exhaustif est donc tres complique a realiser dans des conditions réelles
et, surtout, rend impossible l’utilisation d’un contexte d’analyse plus important.

Pour contoumer ce probleme, plusieurs solutions ont eté proposees. Par exemple, des approches utilisant un corpus
pour dimjnuer le nombre de combinaisons a examiner comme la recherche des chaines lexicales compatibles (Gale
et al., 1992; Vasilescu et al., 2004) ou encore des approches issues de l’intelligence artiﬁcielle comme le recuit
simule (Cowie et al., 1992) ou les algorithmes génetiques (Gelbukh et al., 2003).

Ces methodes ont en commun de ne pas permettre l’exploitation de fagon directe et simple d’une structure lin-
guistique sous forme de graphe que ce soit une analyse morphologique ou une analyse syntaxique. Nous utilisons,
au contraire, une methode a colonies de fourmis pour l’analyse sémantique inspirée de (Schwab & Lafourcade,
2007) aﬁn de pouvoir a terme utiliser de telles structures 3.

4 Notre algorithme global : un algorithme £1 colonies de fourmis

4.1 Les algorithmes :71 colonies de fourmis

Les algorithmes a fourmis ont pour origine la biologie et les observations realisées sur le comportement social des
fourmis. En effet, ces insectes ont collectivement la capacité de trouver le plus court chemin entre leur fourmiliere
et une source d’énergie. Il a pu etre démontré que la cooperation au sein de la colonie est auto-organisée et
resulte d’interactions entre individus autonomes. Ces interactions, souvent tres simples, permettent a la colonie

3. Dans un premier temps, nous utiliserons ici une structure linguistique extrémement simpl(ist)e.

PROPAGATION DE MESURES SEMANTIQUES LOCALES PAR ALGORITHMES A COLONIES DE FOURMIS

de resoudre des problemes compliqués. Ce phénomene est appele intelligence en essaim (Bonabeau & Théraulaz,
2000). Il est de plus en plus utilise en informatique ou des systemes de controle centralisés gagnent souvent a etre
remplacés par d’autres, fondes sur les interactions d’ elements simples.

En 1989, Jean-Louis Deneubourg etudie le comportement des fourmis biologiques dans le but de comprendre la
methode avec laquelle elles choisissent le plus court chemin et le retrouvent en cas d’obstacle. Il elabore ainsi le
modele stochastique dit de Deneubourg (Deneubourg et al., 1989), conforme a ce qui est observe statistiquement
sur les fourmis réelles quant a leur partage entre les chemins. Ce modele stochastique est a l’origine des travaux
sur les algorithmes a fourmis.

Le concept principal de l’intelligence en essaim est la stygmergie, c.-a-d. l’interaction entre agents par modiﬁ-
cation de l’environnement. Une des premieres méthodes que l’on peut apparenter aux algorithmes a fourmis est
l’ecorésolution qui a montré la puissance d’une heuristique de resolution collective basee sur la perception locale,
evitant tout parcours explicite de graphe d’états (Drogoul, 1993).

En 1992, Marco Dorigo et Luca Maria Gambardella congoivent le premier algorithme base sur ce paradigme pour
le celebre probleme combinatoire du Voyageur de commerce (Dorigo & Gambardella, 1997). Dans les algorithmes
a base de fourmis artiﬁcielles, l’environnement est généralement representé par un graphe et les fourmis Virtuelles
utilisent l’information accumulée sous la forme de chemins de pheromone déposée sur les arcs du graphe. De
fagon simple, une fourmi se contente de suivre les traces de pheromones deposées précédemment ou explore au
hasard dans le but de trouver un chemin optimal, fonction du probleme posé, dans le graphe.

Ces algorithmes offrent une bonne alternative a tout type de resolution de problemes modelisables sous forme
d’un graphe. Ils permettent un parcours rapide et efﬁcace et offrent des résultats comparables a ceux obtenus par
les djfférentes methodes de resolution. Leur grand interet reside dans leur capacité a s’adapter a un changement
de l’environnement. Le lecteur trouvera dans (Dorigo & Stiitzle, 2004) ou (Monmarche et al., 2009) de bons états
de l’art sur la question.

4.2 Algorithme :71 colonies de fourmis et désambiguisation lexicale
4.2.1 Vue d’ensemble

L’ environnement des fourmis est un graphe. ll peut etre linguistique — morphologique comme dans (Rouquet et al.,
2010) ou morpho-syntaxique comme dans (Schwab & Lafourcade, 2007; Guinand & Lafourcade, 2009) — ou etre
simplement organise en fonction des elements du texte. En fonction de l’environnement choisi, les résultats de
l’algorithme ne sont évidemment pas les memes. Des recherches sont actuellement menées a ce sujet mais, dans
cet article, nous ne nous intéressons qu’a un cas de base c.—a—d. un graphe simple (voir ﬁg.l), sans information
linguistique exteme, aﬁn de mieux comprendre la mécanique de nos algorithmes.

Dans ce graphe, nous distinguons deux types de noeuds : les fourmiliéres et les mruds normaux. Suivant les idees
developpées dans (Schwab, 2005) et (Guinand & Lafourcade, 2009), chaque sens possible d’un mot est associé a
une fourmiliere. Les fourmilieres produisent des fourmis. Ces fourmis se deplacent dans le graphe a la recherche
d’ énergie puis la rapportent a leur fourmiliere mere qui pourra alors créer de nouvelles fourmis. Pour une fourmi,
un noeud peut etre : (1) la fourmiliére maison ou elle est nee; (2) une fourmiliére ermemie qui correspond a un
autre sens du meme mot; (3) unefourmiliére potentiellement amie, toutes celles qui ne sont pas ennemies; (4) un
mrud qui n’est pas une fourmiliére, les noeuds normaux.

Par exemple, dans la ﬁgure 1, pour une fourmi nee dans la foumnliere 19, 1e noeud 18 est un ennemi comme il a

DIDIER SCHWAB, JEROME GOULIAN, NATHAN GUILLAUME

  
     

 
   

    
  

. //J
5.  ll:
 Mot \; 61/ M01 )1» 7  Mot  10/ M01 is
\_i/’ \\ 7/’ / ‘ /
41 I   - 1  

/r  12/ x1?’/ .11,» \_ _ \1,7» M?‘ \‘19/ 
3 S6115 3‘ \ Sens ll Sens ‘ Sens H Sens Sens I ‘L Sens J‘ S9115 5 ‘ S6115 3‘
“_ ,/ \_ /’ \\ / K / \_ /’ \\ /’ ‘\ 1,/\\ i,/ X 7,/'

FIGURE 1 — Environnement utilise dans cette experience : texte, phrases et mots correspondent aux noeuds dits
normaux 1 a 10, un sens de mot correspond a a une fourmiliere (noeuds 11 a 19).

1e meme pere (10), les fourmilieres potentiellement amies sont les noeuds 11 a 17 et les noeuds normaux sont les
noeuds 1 a 10.

Les déplacements des fourmis se déroulent en fonction des scores locaux (cf. section 2.2), de la presence d’énergie,
et du passage des autres fourmis (Les fourmis laissent des traces sur les arcs ou elles passent sous la forme de
phéromone). Une fois arrivée sur la fourmiliere d’un autre terme, une fourmi peut choisir de revenir directement
a sa fourmiliere mere. Elle établit alors, entre les deux foumiilieres, un pont que les autres fourmis sont, a leur
tour, susceptibles d’emprunter et de renforcer grace a leur pheromone. Ce renforcement a lieu si les informations
lexicales conduisent les autres fourmis a emprunter le pont et disparait dans le cas inverse. Ainsi, les fourmis
établissent de nombreux liens entre fourmilieres de sens compatibles.

Les ponts correspondent ainsi a des interpretations de la phrase. L’émergence de tels circuits dans le graphe
contribue a la monopolisation des ressources de la colonie (fourmis et énergie) et a l’épuisement des ressources
associées aux autres foumiilieres (ces cas correspondent donc aux sens incompatibles dans le contexte et avec les
ressources considérés).

4.2.2 Détails de Palgorithme

Energie Au debut de la simulation, le systeme possede une certaine énergie qui est répartie équitablement sur
chacun des noeuds. Les fourmilieres utilisent celle qu’elles possedent pour fabriquer des fourmis avec une probabi-
lité fonction de cette meme énergie et suivant une courbe sigmo'1'de (cf. ﬁg. 2). On peut remarquer que l’utilisation
de cette fonction permet aux fourmilieres qui n’ont plus d’ énergie de fabriquer quelques fourmis supplemen-
taires (et ainsi d’ avoir une quantité d’énergie negative). L’idée est de leur donner une demiere chance au cas ou
ces fourmis, trouvant des informations lexicales pertinentes, rapportent de l’énergie et relancent la production de
fourmis.

Les fourmis ont une durée de vie (nombre de cycles identique pour toutes et paramétré (cf. tableau 4.2.2)). Lors—
qu’une fourmi meurt, l’énergie qu’elle porte ainsi que l’énergie utilisée par la fourmiliere pour la produire est
déposée sur le noeud ou elle se trouve. Il n’y a donc ni perte ni apport d’énergie a aucun moment que ce soit. Si
on excepte l’emprunt a la nature que peuvent faire de fagon tres limitée les fourmilieres, le systeme fonctionne
completement en vase clos. La quantité d’énergie est un element fondamental de la convergence du systeme vers
une solution. En effet, puisque l’énergie globale est limitée, les fourmilieres sont en concurrence les unes avec les

PROPAGATION DE MESURES SEMANTIQUES LOCALES PAR ALGORITHMES A COLONIES DE FOURMIS

FIGURE 2 — Courbe de la fonction sigmo'1'de  ) + % qui permet de calculer la probabilite de la naissance

d’ une fourmi a partir de la quantite d’energie presente sur le noeud.
autres et seules des alliances peuvent permettre de faire emerger des solutions.

Phéromone de passage Les fourmis ont deux types de comportement. Elles peuvent soit chercher de l’energie,
soit chercher a revenir a leur fourmiliere mere. Lorsqu’ elles se deplacent dans le graphe, elles laissent des traces sur
les arcs ou elles passent sous la forme de pheromone. La pheromone inﬂue sur les deplacements des fourmis qui
preferent l’eviter lorsqu’elles cherchent de l’energie et preferent la suivre lorsqu’elles tentent de revenir deposer
cette energie a leur fourmiliere mere.

Lors d’un deplacement, une fourmi laisse une trace en deposant sur l’arc A traverse une quantite de pheromone
0 E ]R+. On a alors got+1(A) = got(A) + 0.

A chaque cycle, il y a une legere evaporation des pheromones. Cette baisse se fait de fagon lineaire jusqu’a la
disparition totale de la pheromone. Nous avons ainsi, goc+1(A) = goc(A) x (1 — 6) ou 6 est la proportion de
pheromone qui s’evapore a chaque cycle.

Création, suppression et type de ponts Un pont peut etre cree lorsqu’une fourmi atteint une fourmiliere po-
tentiellement amie, c.—a—d. lorsqu’elle arrive sur un noeud qui correspond a un sens d’un autre mot que celui de
la fourmiliere mere. Dans ce cas, la fourmi evalue non seulement les noeuds lies a cette fourmiliere mais aussi le
noeud correspondant a sa fourmiliere mere. Si ce demier est selectionne, il y a creation d’un pont er1tre les deux
fourmilieres. Ce pont est ensuite considere comme un arc standard par les fourmis, c.—a—d. que les noeuds qu’il lie
sont consideres comme voisins. Si le pont ne porte plus de pheromone, il disparait.

Odeur L’ odeur d’une foumliliere est la representation vectorielle que nous avons introduite dans la partie 2.2.2.
Elle correspond donc a la deﬁnition du sens sous forme de vecteur de nombres entiers. Chaque fourmi nee dans
cette fourmiliere porte la meme odeur, le meme vecteur. Lors de son deplacement sur les noeuds normaux du
graphe, une fourmi propage son vecteur. Le vecteur V(N) porte par un noeud normal N est modiﬁe lors du passage
d’une fourmi. La fourmi depose une partie de son vecteur, un pourcentage des composantes prises au hasard qui
remplace la meme quantite d’anciennes valeurs elles aussi choisies au hasard.

Cette propagation intervient dans le deplacement des fourmis. Laisser une partie de son vecteur, c’est laisser une
trace de passage. Ainsi plus un noeud est proche d’une fourmiliere plus il y a de chance que les fourmis de cette
fourmiliere y soient passees. Ce phenomene permet aux fourmis de revenir a leur fourmiliere, ou eventuellement de
se tromper et de se diriger vers des fourmilieres amies. Cette erreur est ainsi potentiellement beneﬁque puisqu’elle

DIDIER SCHWAB, JEROME GOULIAN, NATHAN GUILLAUME

peut permettre de créer un pont entre les deux foumnlieres (cf. 4.2.2). En revanche, lorsqu’une fourmi se trouve
sur une fourmiliere, le vecteur n’est pas modiﬁé. Ces noeuds conservent ainsi un Vecteur constant tout au long de
la simulation.

La table suivante presente les parametres, les notations et les Valeurs utilisees dans l’algorithme presente et expe-
rimenté ici. Cet article ne présente pas les experiences realisées pour trouver ces Valeurs.

| 1" ‘ “‘ | Description | Valeuls |
an sens
est un ou une
A
utilisée une fourrniliere une fourmi
X. X est un nwud ou une fourmi
maximale une fourmi
sur arc
une are
de la entre
de X selon la fourmi f. X est un are on un nwud
du nwud N en l’arc selon la fourmi f

S111‘

une fourmi ‘elle arrive sur un nwud
vecteur
une sur un

 

4.2.3 Déroulement de l’algorithme

L’ algorithme consiste en une iteration potentiellement inﬁnie de cycles. A tout moment, la simulation peut etre
interrompue et l’etat courant observe. Durant un cycle, on effectue les taches suivantes : (1) éliminer les fourmis
trop Vieilles (la durée de Vie est un parametre) ; (2) pour chaque foumiiliere, solliciter la production d’ une fourmi
(une fourmi peut ou non Voir le jour, de fagon probabiliste) ; (3) pour chaque arc, diminuer le taux de pheromone
(evaporation des traces) ; (4) pour chaque fourmi : determiner son mode (recherche d’energie, retour a la fourmi-
liere, le changement est fait de maniere probabiliste) et la déplacer. Créer un pont interprétatif le cas echeant; (5)
calculer les consequences du déplacement des fourmis (sur l’actiVation des arcs et l’énergie des noeuds).

Les déplacements d’ une fourmi sont aléatoires mais inﬂuences par son environnement. Lorsqu’une fourmi est sur
un noeud, elle estime tous les noeuds Voisins et tous les arcs qui les lient. La probabilité d’emprunter un arc Aj pour

aller a un noeud Ni est P(N,-, Aj) = mam( , 6) ou Eval f (N, A) est l’éValuation du noeud

N en prenant l’arc A, c.—a—d. la somme de Evalf (N) et de Evalf(A). 6 permet a certaines fourmis de choisir
des destinations évaluées comme improbables mais qui permettraient d’atteindre des informations lexicales et des
ressources qui s’aVereraient interessantes ensuite.

Une fourmi qui Vient de naitre (c.-a—d. etre produite par sa fourmiliere) part a la recherche d’ énergie. Elle est attirée
par les noeuds qui portent beaucoup d’ energie (Evalf (N) =  ) et évite les arcs qui portent beaucoup de
pheromone (Evalf(A) = 1 — go(A)) aﬁn de permettre l’exploration de plus de solutions. Elle continue a collecter
de l’énergie jusqu’au cycle ou un tirage aleatoire avec la probabilité P(1"etour) = gﬂ la fera passer en mode

retour. Dans ce mode, elle Va (statistiquement) suivre les arcs avec beaucoup de phérorniione (Evalf (A) = go(A))
et Vers les noeuds dont l’odeur est proche de la leur (Evalf (N) = 

PROPAGATION DE MESURES SEMANTIQUES LOCALES PAR ALGORITHMES A COLONIES DE FOURMIS
I I
5 Evaluation

Nous avons testé notre methode sur le corpus de la tache gros grain de la campagne d’eValuation Semeval
2007 (Navigli et al., 2007) dans laquelle les organisateurs foumissent un inventaire de sens plus grossiers que
ceux de WordNet. Pour chaque terme, les sens considérés comme proches (par exemple, "neige/pre’cipitation" et
"neige/couverture" ou "pore/animal" et "porc/iziande") sont groupés. Le corpus est compose de 5 textes de genres
divers (ioumalisme, critique littéraire, Voyage, informatique, biographies) dont il faut annoter les 2269 mots. Le
nombre moyen de sens par mot est de 6,19; ramené a 3,1 pour l’inVentaire de sens grossiers. Les compétiteurs
étaient libres de se servir de cet inventaire (sens grossiers connus a priori) ou non (sens grossiers connus a paste-
riori). Dans le premier cas, le nombre de choix a faire pour chaque mot est réduit et la tache moins compliquée.
Dans le second cas, les sens annotés sont jugés corrects s’ils sont dans le bon groupement, une sorte d’erreur
acceptable. Notre objectif est de tester un systeme en Vue d’une utilisation dans un cadre applicatif reel or l’in—
Ventaire de sens grossiers n’est disponible que pour les 2269 mots utilises dans le corpus d’eValuation, nous ne
l’utilisons donc pas. Dans les experiences presentees ici, nous nous situons ainsi dans un cas de sens connus a
posteriori. Les résultats sont analyses par les formules classiques :

precision p =  enta% Rappel R =  enta%

, F—mesure F = E
sens annotes

sens (‘L annoter P+R

Dans le corpus, les mots sont annotés avec leur partie du discours (Verbe, nom, adverbe, adjectit). A partir de ces
informations, nous construisons l’enVironnement des fourmis : un noeud au niveau du texte, un noeud pour chaque
phrase, un noeud pour chaque mot et une fourmiliere pour chaque sens (Voir ﬁg. 1). A la ﬁn d’un cycle, le sens
sélectionné pour chaque mot correspond a la fourmiliere qui a la plus grande quantité d’ énergie.

5.1 Exécution de l’algorithme

L’ algorithme a colonies de fourmis garantit la realisation d’un choix entre les differentes possibilités pour chaque
terme. Ainsi, 100% du corpus est annoté et P=R=F puisque les sens annotés sont egaux aux sens a annoter (P=R)
et dans ce cas F = % = 2331,32 = P. De plus, un algorithme a colonies de fourmis est un algorithme
stochastique, il ne sélectionne donc pas exactement les memes sens a chaque execution ni meme a chaque cycle.
Nous avons execute cet algorithme des centaines de fois et avons note qu’apres 70-80 cycles, les résultats restaient
globalement constants comme l’illustre la ﬁgure suivante.

— Lesk
— Lesk étendu

Precision/Rappel/F-mesure (%)

FIGURE 3 — Evolution de la precision/rappel/F—mesure dans les 100 cycles d’une execution de l’algorith1ne a
colonies de fourmis utilise avec l’algorith1ne local Lesk et avec l’algorith1ne local Lesk étendu

DIDIER SCHWAB, JEROME GOULIAN, NATHAN GUILLAUME
5.2 Comparaison d’exécutions

De la meme maniere que les résultats évoluent entre deux cycles, les résultats peuvent etre différents entre deux
executions. Pour donner une idée de cette difference, nous avons répété notre experience, arretée au bout de 100
cycles, sur chacun des algorithmes locaux, 100 fois. La table suivante en présente les résultats. Nous obtenons
seulement 2, 95% d’écart entre le meilleur et le moins bon résultat (soit 67 termes mal annotes sur 2269) pour
Lesk étendu et 3,39% (soit 77 termes mal annotés sur 2269) pour Lesk.

Algorithme local Minimum Maximum Moyenne Médiane Etendue Ecart—type
Lesk 64,43 67,83 66,34 66,35 3,39 0,66
Lesk étendu 72,54 75,5 74,01 74,04 2,95 0,58

5.3 Comparaisons avec l’algorithme exhaustif

A titre de comparaison avec notre approche, nous présentons les résultats obtenus par l’algorithme global exhaustif
(Banerjee & Pedersen, 2002). Nous avons choisi comme contexte la phrase, excluant de facto les phrases d’un mot
(au nombre de quatre, soit moins de 0, 002% du corpus). Pour des raisons calculatoires, nous avons également
exclu les phrases de plus de 10 milliards de combinaisons. Nous pouvons voir que seulement 77, 3% du corpus a

| Algorithme global | Algorithme local | Etiquetés | Précision | Rappel | F—mesure | Temps |
. Lesk 77,30 69,21 53,50 50,35 8 40h

| C“1°“1°"h““S"f | Lesk étendu i 77,30 ‘ 77,82 | 50,15 | 67,86 m 30011 |
F0 .s Lesk 100,0 64,43 - 67,83 64,43 - 67,83 64,43 - 67,83 8 3m
Lesk étendu 100,0 72,54 - 75,5 72,54 - 75,5 72,54 - 75,5 8 8111

été annoté au prix d’une durée de plusieurs heures incompatible avec des applications en temps reel 4.

Pour les deux algorithmes locaux, la F—mesure est clairement supérieure a celle du calcul brut pour un temps
nettement moins long (800 fois plus court pour Lesk et 2250 fois pour Lesk étendu). Le tableau suivant présente
pour les memes executions les résultats sur les différentes sous-parties du corpus : A, la partie annoté par les 2
algorithmes globaux et B celle qui n’est annotée que par l’algorith1ne fourmis. Sur la partie A, les fourmis sont,
come on pouvait s’en douter, légerement en dessous de l’algorithme exhaustif et leur meilleur résultat s’explique
par la possibilité d’annoter la sous—partie B.

Pour conclure cette evaluation, nous avons compare nos résultats avec les résultats obtenus par les différents
systemes qui participaient a la campagne Semeval 2007. Avec Lesk étendu, nous serions arrives 8éme/ 15 en tenant
compte de tous les participants, Séme/8 sur ceux qui ne connaissent pas a priori les sens grossiers, 1”/7 sur
les approches non supervisées. Ces résultats sont tres encourageants vu les temps de calcul (aucun article des
participants n’aborde ce point), les possibilités d’extension qu’offrent les algorithmes a fourmis et la simplicité
des algorithmes locaux envisages ici.

4. Expériences réalisées sur des processeurs Intel Xeon X5550, 4 coeurs 51 2.66Ghz (durées converties en temps monoprocesseurs).

