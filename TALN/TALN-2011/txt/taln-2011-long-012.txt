TALN 2011, Montpellier, 27juin — 1"'ju1'11et 2011

Un turc mécanique pour les ressources linguistiques :
critique de la myriadisation du travail parcellise

Benoit Sagotl Karen Fort2=3 Gilles Adda4 Joseph Mariani4r5 Bernard Lang6
(1) Alpage, INRIA Paris—Rocquencourt & Université Paris 7,
Rocquencourt, BP 105, 78153 Le Chesnay Cedex, France
(2) INIST-CNRS, 2 allee de Brabois, 54500 Vandoeuvre-les-Nancy, France
(3) LIPN, Université Paris Nord, 99 av J-B Clement, 93430 Villetaneuse, France
(4) LIMSI-CNRS, Bat. 508, rue John Von Neumann, Université Paris-Sud BP 133, 91403 Orsay Cedex, France
(5) IMMI-CNRS, Bat. 508, rue John Von Neumarm, Université Paris-Sud BP 133, 91403 Orsay Cedex, France
(6) INRIA Paris—Rocquencourt, Rocquencourt, BP 105, 78153 Le Chesnay Cedex, France

{benoit.sagot, bernard.1ang}@inria.fr, karen.fort@inist.fr, {gi11es.adda,j oseph.mariar1i} @limsi.fr

Résllnlé. Cet article est une prise de position concemant les plate—formes de type Amazon Mechanical Turk,
dont l’uti1isation est en plein essor depuis quelques annees dans le traitement automatique des langues. Ces plate-
formes de travail en ligne permettent, selon le discours qui prevaut dans les articles du domaine, de faire developper
toutes sortes de ressources linguistiques de qualite, pour un prix imbattable et en un temps tres reduit, par des gens
pour qui il s’agit d’un passe—temps. Nous allons ici demontrer que la situation est loin d’etre aussi ideale, que
ce soit sur le plan de la qualite, du prix, du statut des travailleurs ou de l’ethique. Nous rappellerons ensuite les
solutions alternatives deja existantes ou proposees. Notre but est ici double : informer les chercheurs, aﬁn qu’ils
fassent leur choix en toute connaissance de cause, et proposer des solutions pratiques et organisationnelles pour
arneliorer le developpement de nouvelles ressources linguistiques en lirnitant les risques de derives ethiques et
legales, sans que cela se fasse au prix de leur coﬁt ou de leur qualite.

Abstract. This article is a position paper concerning Amazon Mechanical Turk—like systems, the use of
which has been steadily growing in natural language processing in the past few years. According to the mainstream
opinion expressed in the articles of the domain, these online working platforms allow to develop very quickly all
sorts of quality language resources, for a very low price, by people doing that as a hobby. We shall demonstrate
here that the situation is far from being that ideal, be it from the point of view of quality, price, workers’ status or
ethics. We shall then bring back to mind already existing or proposed alternatives. Our goal here is twofold : to
inform researchers, so that they can make their own choices with all the elements of the reﬂection in mind, and
propose practical and organizational solutions in order to improve new language resources development, while
limiting the risks of ethical and legal issues without letting go price or quality.

M0tS-CléS 3 Amazon Mechanical Turk, ressources linguistiques.

Keywords: Amazon Mechanical Turk, language resources.

1 Introduction

Le traitement des langues a grandement evolue au cours des ces vingt demieres annees, tant dans le traitement
de l’ecrit que de la parole. Stirnule par le paradigme de l’evaluation, le role des ressources linguistiques dans
ce developpement a ete et reste crucial : elles sont a la fois matiere premiere, objet d’etude et ressource pour
l’evaluation de systemes. Nous proposons ici une critiqued’un outil nouveau de constitution de ces ressources, le
microworking par le biais du crowdsourcing. Microworking fait reference au fait que le travail est segmente en
petites taches, crowdsourcing au fait que le travail est delocalise (outsourced) et est effectue par un grand nombre
de personnes (crowd), payees ou non. Nous neologiserons crowdsourcing en << myriadisation » et rnicroworking
en << travail parcellise », et la conj onction des deux par << myriadisation du travail parcellise ».

Nous aborderons en details le cas d’un systeme de myriadisation du travail parcellise (m.t.p. dans la suite) qui
a fait ﬂores ces demiers temps, Amazon Mechanical Turk (MTurk), notarnment pour sa capacite a produire des
corpus annotes a un coﬁt tres faible. Les auteurs de cet article ont contribue, a des degres divers, a la mise en
place du paradigme de l’evaluation et au developpement de nombreux outils et ressources dans le domaine du

B.SAGOT K. FORT G.ADDA J. MARIANI B.LANG

traitement du langage. Nous sommes a ce titre conscients de l’irnportance du developpement et de la diffusion
de celles—ci et du frein que represente leur coﬁt, souvent redhibitoire. Cependant, nous voulons mettre en avant
le fait que le coﬁt du developpement est un argument non fondé en ce qui conceme la m.t.p., tout d’ abord parce
qu’il masque des problemes economiques complexes, ensuite parce qu’il met sous le boisseau le probleme de la
qualite des ressources ainsi obtenues, enﬁn parce qu’il omet la question de l’éthique et du droit du travail. Nous
aborderons ici l’ensemble de ces questions, sans pour autant remettre en cause l’utilite de la m.t.p., a condition
que son fonctionnement et son utilisation se fassent selon certains principes.

2 Que sont les systémes de myriadisation ?

Le concept de myriadisation est venu de l’idee qu’un certain nombre de taches pouvaient etre effectuees par des
utilisateurs d’Intemet, en utilisant les atouts propres a celui—ci, c’est—a—dire pouvoir acceder a un grand nombre de
personnes, de maniere quasi—instantanée, partout dans le monde. La participation de ces intemautes peut etre be-
nevole ou rétribuée, suivant les taches et les systemes. Parmi les systemes benevoles, nous pouvons citer l’exemple
farneux de Wikipedia et, parmi ceux avec retribution, RentACoder (o1‘1l’on peut soumettre un projet de program-
mation a une communauté de programmeurs) ou LiveOps (qui est un centre d’appels virtuel, les operateurs étant
des intemautes). A la suite de ces systemes est apparu le concept de Human computing. Dans ce demier cas, on
ne fait plus appel a des competences particulieres d’intemautes, mais on utilise deux propriétes tres elémentaires :
etre un humain et avoir du temps libre. C’est l’application des grilles de calcul aux humains : chaque utilisateur, a
la maniere d’un processeur, effectue une tache elementaire en n’ayant acces qu’a la seule information necessaire
pour la mener a bien. Dans ce type de systemes, seules des taches tres simples sont effectuees par les humains,
soit parce qu’elles sont intrinsequement simples (par exemple, mettre une etiquette sur une image), soit parce
que la tache est découpable en micro—taches elementaires. Ce sont les systemes de myriadisation du travail par-
cellisé, qui sont le coeur de cet article. Dans ce concept, il y a souvent retribution 1, mais celle—ci peut—etre non
monetaire, comme dans certains GWAP (Games with a purpose) (von Ahn, 2006; Chamberlain et al., 2008). La
creation d’Amazon Mechanical Turk en 2005 s’inscrit dans cette derniere catégorie de systemes de m.t.p. avec
remuneration, qui a ete suivie par un grand nombre d’autres systemes (Biewald, 2010), ceux—ci n’ayant pas acquis
la meme importance, en particulier en raison du nombre de personnes inscrites. Comme souvent pour les nou-
veaux usages issus du Web, on ressent a la fois une fascination pour la potentialité des m.t.p. et une méﬁance en
face de ces pratiques qui ne semblent pas avoir de reelles considerations pour le droit du travail. L’ apparition des
systemes de myriadisation pose de nombreux problemes, légaux, ethiques et philosophiques, abordes par exemple
dans (Zittrain, 2008). Elle souleve d’irnportantes questions : qu’est—ce que le travail? qu’est—ce qu’une retribution
juste ? un etre humain est—il assirnilable a un ordinateur ? Ces questions essentielles débordent largement a la fois
le cadre d’un article de conference et nos competences. C’est pourquoi nous nous lirniterons, autant que possible,
aux problemes précis que pose l’introduction de MTurk comme moyen de produire des ressources linguistiques,
car nous jugeons cela a la fois urgent et crucial.

3 Amazon Mechanical Turk : légendes et réalité

Amazon Mechanical Turk (MTurk) permet, selon de nombreux auteurs dont le premier est Snow et al. (2008),
de produire a peu de frais et rapidement des ressources linguistiques de qualité. Cette découverte est d’une telle
importance pour la communauté qui manque toujours cruellement de moyens pour developper lesdites ressources,
qu’elle a entraine un important effet de mode. Ce phenomene est, nous allons le voir, ni totalement justiﬁe, ni sans
consequences pour le developpement futur de telles ressources. Par ailleurs, pour de nombreux chercheurs, les
Turkers 2 utilisent MTurk comme un hobby, il n’est donc pas scandaleux de tres mal les remunerer. Nous allons
voir ici que la situation est loin d’etre aussi simplement idéale.

1. mais pas toujours, par exemple dans le systéme reCAPTCHA http : //www . google . com/recaptcha/learnmore, o1‘1 les
CAPTCHAs proviennent de mots mal reconnus lors de la numérisation dc Google books

2. 11 est d’usage d’appeler les personnes effectuant des taches au sein du « turc mécanique » des Turkers, ct celles qui fournissent les taches
des Requesters.

MYRIADISATION DU TRAVAIL PARCELLISE.

COHN D. A., GHAHRAMANI Z. & JORDAN M. I. (1995). Active learning with statistical models. In G.
TESAURO, D. TOURETZKY & T. LEEN, Eds., Advances in Neural Information Processing Systems, volume 7,
p. 705-712 : The MIT Press.

COOK P. & STEVENSON S. (2010). Automatically identifying changes in the semantic orientation of words.
In N. C. C. CHAIR), K. CHOUKRI, B. MAEGAARD, J. MARIANI, J. ODIJK, S. PIPERIDIS, M. ROSNER &
D. TAPIAS, Eds., Proceedings of the Seventh conference on International Language Resources and Evaluation
(LREC’I0) : European Language Resources Association (ELRA).

ERK K., KOWALSKI A. & PADO S. (2003). The salsa annotation tool. In D. DUCHIER & G.-J. M. KRUIJFF,
Eds., Proceedings of the Workshop on Prospects and Advances in the Syntax/Semantics Interface, Nancy, France.

FININ T., MURNANE W., KARANDIKAR A., KELLER N., MARTINEAU J. & DREDZE M. (2010). Annotating
named entities in twitter data with crowdsourcing. In Proceedings of the NAACL HLT 2010 Workshop on Crea-
ting Speech and Language Data with Amazon ’s Mechanical Turk, CSLDAMT ’10, p. 80-88, Stroudsburg, PA,
USA : Association for Computational Linguistics.

FORT K., ADDA G. & COHEN K. B. (2011). Amazon mechanical turk : Gold mine or coal mine ‘.7 Computatio-
nal Linguistics (editorial), 37(2).

FORT K. & SAGOT B. (2010). Inﬂuence of Pre—annotation on POS—tagged Corpus Development. In Proc. of the
Fourth ACL Linguistic Annotation Workshop, Uppsala, Suede.

GILLICK D. & LIU Y. (2010). Non—expert evaluation of summarization systems is risky. In Proceedings of
the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon ’s Mechanical Turk,
CSLDAMT ’10, p. 148-151, Stroudsburg, PA, USA : Association for Computational Linguistics.

GOLDWATER S. & GRIFFITHS T. (2007). A fully bayesian approach to unsupervised part—of—speech tagging. In
Proceedings of ACL, Prague, République tcheque.

HANIG C. (2010). Improvements in unsupervised co—occurrence based parsing. In Proceedings of the Four-
teenth Conference on Computational Natural Language Learning, CoNLL ’10, p. 1-8, Stroudsburg, PA, USA :
Association for Computational Linguistics.

HUGHES T., NAKAJIMA K., HA L., VASU A., MORENO P. & LEBEAU M. (2010). Building transcribed speech
corpora quickly and cheaply for many languages. In Proceedings of Interspeech, p. 1914-1917.

IPEIROTIS P. (2010a). Analyzing the amazon mechanical turk marketplace. CeDER Working Papers,
http ://l1dl.handle.net/2451/29801. CeDER—10—04.

IPEIROTIS P. (2010b). Demographics of mechanical turk. CeDER Working Papers,
http ://l1dl.handle.net/2451/29585. CeDER—10—01.

IPEIROTIS P. (2010c). A plea to amazon : Fix mechanical turk! http ://behind-the-enemy-
lines.blogspot.com/2010/10/plea—to—amazon-ﬁx-mechanical—turk.ht1nl.

KAISSER M. & LOWE J. B. (2008). Creating a research collection of question answer sentence pairs with
amazon’s mechanical turk. In Proceedings of the International Language Resources and Evaluation (LREC—
2008).

KOCHHAR S., MAZZOCCHI S. & PARITOSH P. (2010). The anatomy of a large-scale human computation
engine. In Proceedings of Human Computation Workshop at the 16th ACM SIKDD Conference on Knowledge
Discovery and Data Mining, KDD 2010, Washington D.C.

LAFOURCADE M. & J OUBERT A. (2008). JeuxDeMots : un prototype ludique pour l’emergence de relations
entre termes. In JADT’08 : Journe’es internationales d ’Analyse statistiques des Donne’es Textuelles, p. 657-666.

LAMBERT B ., SINGH R. & RAJ B. (2010). Creating a linguistic plausibility dataset with non—expert annotators.
In Proceedings of Interspeech, p. 1906-1909.

LAWSON N., EUSTICE K., PERKOWITZ M. & YETISGEN-YILDIZ M. (2010). Annotating large email datasets
for naIned entity recognition with mechanical turk. In Proceedings of the NAACL HLT 2010 Workshop on
Creating Speech and Language Data with Amazon ’s Mechanical Turk, CSLDAMT ’10, p. 71-79, Stroudsburg,
PA, USA : Association for Computational Linguistics.

MARGE M., BANERJEE S. & RUDNICKY A. I. (2010). Using the amazon mechanical turk for transcription of
spoken language. In IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP), p.
5270-5273, Dallas, TX.

MCGRAW 1., YING LEE C., HETHERINGTON L., SENEFF S. & GLASS J . (2010). Collecting voices from the
cloud. In Proceedings of the International Language Resources and Evaluation (LREC—20I0), p. 1576-1583.

B.SAGOT K. FORT G.ADDA J.MAR1AN1 B.LANG

NOTHMAN J ., CURRAN J . R. & MURPHY T. (2008). Transforming Wikipedia into Named Entity Training
Data. In Proceedings of the Australian Language Technology Workshop, p. 124-132.

NOVOTNEY S. & CALLISON—BURCH C. (2010). Cheap, fast and good enough : automatic speech recognition
with non—expert transcription. In Human Language Technologies : The 2010 Annual Conference of the North
American Chapter of the Association for Computational Linguistics, HLT ’10, p. 207-215, Stroudsburg, PA,
USA : Association for Computational Linguistics.

PAK A. & PAROUBEK P. (2010). Twitter as a corpus for sentiment analysis and opinion mining. In Proceedings
of the Seventh conference on International Language Resources and Evaluation (LREC’I0), La Valette, Malte :
European Language Resources Association (ELRA).

Ross J ., IRANI L., SILBERMAN M. S., ZALDIVAR A. & TOMLINSON B. (2010). Who are the crowdworkers ? :
shifting demographics in mechanical turk. In Proceedings of the 28th of the international conference extended
abstracts on Human factors in computing systems, CHI EA ’10, p. 2863-2872, New York, NY, USA : ACM.

ROSS J ., ZALDIVAR A., IRANI L. & TOMLINSON B. (2009). Who are the turkers ? worker demographics in
amazon mechanical turk. Social Code Report 2009-01, http ://www.ics.uci.edu/ jwross/pubs/SocialCode—2009—
01.pdf.

SAGOT B. (2005). Automatic acquisition of a Slovak lexicon from a raw corpus. In Lecture Notes in Artiﬁcial
Intelligence 3658 ( (c) Springer—Verlag), Proceedings of TSD ’05, p. 156-163, Karlovy Vary, République tcheque.

SMITH N. & EISNER J . (2005). Contrastive estimation : Training log-linear models on unlabeled data. In
Proceedings of the 43th Annual Meeting of the Association for Computational Linguistics (ACL’05), p. 354-362,
nn Arbor, Michigan, USA.

SNOW R., O’CONNOR B., JURAFSKY D. & NG. A. Y. (2008). Cheap and fast — but is it good? evaluating
non—expert annotations for natural language tasks. In Proceedings of EMNLP 2008, p. 254-263.

STURENBERG M., GOECKE D., DIE-WALD N., CRAMER I. & MEHLER A. (2007). Web—based annotation of
anaphoric relations and lexical chains. In ACL Workshop on Linguistic Annotation Workshop (LAW), Prague,
République tcheque.

TRATZ S. & HOVY E. (2010). A taxonomy, dataset, and classiﬁer for automatic noun compound interpreta-
tion. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, p. 678-687,
Uppsala, Suede : Association for Computational Linguistics.

VON AHN L. (2006). Games with a purpose. IEEE Computer Magazine, p. 96-98.

VON AHN L. & DABBISH L. (2008). General techniques for designing games with a purpose. Communications
of the ACM, p. 58-67.

WAIS P., LINGAMNENI S., COOK D., FENNELL J ., GOLDENBERG B., LUBAROV D., MARIN D. & SIMONS
H. (2010). Towards building a high—qualityworkforce with mechanical turk. In Proceedings of Computational
Social Science and the Wisdom of Crowds (NIPS).

WATSON R., BRISCOE T. & CARROLL J . (2007). Se1ni—supervised training of a statistical parser from unlabeled
partially—bracketed data. In Proceedings of the 10th International Conference on Parsing Technologies, IWPT
’07, p. 23-32, Stroudsburg, PA, USA : Association for Computational Linguistics.

WELINDER P., BRANSON S., BELONGIE S. & PERONA P. (2010). The multidimensional wisdom of crowds.
In Neural Information Processing Systems Conference (NIPS).

XU F. & KLAKOW D. (2010). Paragraph acquisition and selection for list question using amazon’s mechanical
turk. In Proceedings of the International Language Resources and Evaluation (LREC—20I0), p. 2340-2345, La
Valette, Malte.

YAROWSKY D. (1995). Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings
of the 33rd Annual Meeting of the Association for Computational Linguistics, p. 189-196, Cambridge, MA.
YETISGEN-YILDIZ M., SOLTI I., XIA F. & HALGRIM S. R. (2010). Preliminary experience with amazon’s
mechanical turk for annotating medical named entities. In Proceedings of the NAACL HLT 2010 Workshop on
Creating Speech and Language Data with Amazon ’s Mechanical Turk, CSLDAMT ’ 10, p. 180-183, Stroudsburg,
PA, USA : Association for Computational Linguistics.

ZITTRAIN J . (2008). Ubiquitous human computing. Phil. Trans. R. Soc. A 28, 366(1881), 3813-3821.

MYRIADISATION DU TRAVAIL PARCELLISE

Nb Articles
6
5 I ACL
I COLING
4 u LREC
3 =1 LAW
EMNLP
2 MT Summit
Imerspeech
1 an IEEE-ICASSP

2005 2007 2008 2009 2010 Année

FIGURE 1 — Evolution de l’utilisation réelle de MTurk dans les publications TAL et parole

3.1 Etat des lieux

Créé en 2005, le systéme de m.t.p. MTurk est aujourd’hui de plus en plus utilisé pour la création ou la validation
de ressources linguistiques pour le TAL (Traitement Automatique des Langues), et la plupart des conférences
intemationales du domaine ont vu la présentation de proj ets de recherche utilisant MTurk.

La ﬁgure 1, reprise de (Fort et al., 2011), montre l’évolution rapide du phénoméne. Elle comptabilise le nombre
de publications dans les principales conférences intemationales décrivant des expériences utilisant MTurk.

Aﬁn de compléter cette étude, nous avons également réalisé une recherche plus globale, Cette fois dans l’an—
thologie de l’ACL. 3 Cette recherche, effectuée le 5 novembre 2010, a ramené 124 résultats, dont, aprés ﬁltrage
manuel, 86 papiers utilisant effectivement MTurk (Fort et al., 2011). Ces résultats incluent un atelier spécialisé,
foumissant 35 des 86 publications, le NAACL—HLT 2010 Workshop on Amazon Mechanical Turk, dont l’exis—
tence méme est le signe de l’i1nportance grandissante de MTurk dans le domaine. Mentionnons enﬁn que certaines
expériences relatées dans des articles ont utilisé MTurk sans le mentionner explicitement (Fort et al., 2011). Ainsi,
Kevin B. Cohen, co-auteur de l’article précité, a remarqué qu’un article (Biadsy et al., 2008) dont il avait vu la
présentation en conférence, utilisait MTurk et n’en faisait pas mention. Coté francophone, nous ne trouvons aucun
article utilisant MTurk dans les actes des précédents TALN, ni dans les numéros publiés a ce jour de la revue TAL.

3.2 MTurk est un hobby pour les Turkers ?

Aﬁn de pouvoir efﬁcacement juger de l’éthique et de la légalité de MTurk, il est fondamental de pouvoir qualiﬁer
l’activité que ménent les Turkers lorsqu’ils effectuent des taches dans MTurk. S’agit—il d’une activité bénévole,
comme celle effectuée par les participants a Wikipedia ? Clairement non, lorsque l’on regarde la page d’accueil o1‘1
MTurk met directement l’accent sur l’argent gagné. Peut—elle étre assimilée a un hobby, la rétribution étant alors
assimilable a un bonus ne correspondant pas a un salaire, comme cela est suggéré dans quelques articles (Novotney
& Callison-Burch, 2010) ?

Un certain nombre d’études (Ross et al., 2009, 2010; Ipeirotis, 2010b), foumissent, grace a des questionnaires
soumis aux Turkers via MTurk, des chiffres déclarés sur un certain nombre de facteurs socio-économiques (pays,
age, revenu, éducation. . .), sur la fagon dont ils utilisent MTurk (nombre detaches effectuées par semaine, revenu
acquis, date d’entrée dans MTurk ...)4 et dont ils qualiﬁent leur activité. La motivation ﬁnanciére (déclarée)
est minoritaire chez les Turkers américains (38%), mais majoritaire chez les Turkers indiens (69%). Si 60% des
Turkers pensent que MTurk est un moyen utile de gagner de l’argent sur leur temps libre, ils ne sont que 30% a
motiver leur participation par l’intérét des taches, et 20% (5% des travailleurs indiens) disent l’utiliser pour tuer
le temps. Enﬁn, ils sont 20% (30% des Indiens) a dire que MTurk leur est nécessaire pour vivre, et a peu pres le
méme pourcentage a dire que MTurk constitue leur principale source de revenus.

3. Association for Computational Linguistics, http : / /www . aclweb . org/anthology/

4. On pourra se reporter par exemple a (Adda & Mariani, 2010) pour un résumé de celles-ci. On y apprend par exemple (Ross et al.,
2010) que les Turkers en provenance d’Inde représentaient 5% a la ﬁn de 2008, 36% ﬁn 2009, plus de 50% en mai 2010 selon http:
//blog . crowdflower . com/2 010/05/amazon—mechanical—turk— survey/ et, selon (Biewald, 2010) sont responsables de
plus de 60% de l’activité dans MTurk.

B.SAGOT K. FORT G. ADDA J. MARIANI B.LANG

Un autre moyen de veriﬁer la nature de l’activité des Turkers est d’examiner la nature de la tache. Certaines
taches actuellement proposées sur MTurk correspondent a de nouveaux usages (par exemple, des experiences
artistiques comme http : / /www . the sheepmarket . com / ), mais d’ autres sont effectuées habituellement par
des employés (ce qui peut donc assimiler MTurk a une forme de délocalisation sur le web, pour faire baisser les
coﬁts de production), et constituent donc un travail. Tel est le cas des activites de transcription ou de traduction,
qui sont (pour ce qui concerne les ressources les plus signiﬁcatives) produites par des employés d’entités comme
le LDC ou ELDA. Pour les 20% des Turkers qui passent plus de 15h par semaine sur MTurk (Adda & Mariani,
2010) et contribuent a hauteur de 80% des taches, la durée d’activité est signiﬁcative, et est assimilable a un travail.

Nous ne pouvons pas conclure de maniere deﬁnitive sur la nature de l’activité de tous les Turkers, car la nature
des taches sur MTurk et la motivation des Turkers est composite. Cependant, nous pensons que pour les 20%
des Turkers pour qui MTurk constitue la source principale de revenus, ainsi que pour les taches assimilables a un
travail (qui ont 8 chances sur 10 d’etre effectuées par des Turkers travaillant plus de 15 heures par semaine), la
nature de l’activité est assimilable a un travail.

3.3 MTurk permet de réduire les coiits ?

Dans la plupart des articles ayant utilise MTurk, le faible coﬁt de développement de la ressource est mis en avant.
11 est vrai que MTurk permet de proposer des rétributions si faibles aux Turkers que le coﬁt en est forcément
reduit, par exemple 0.005$ pour transcrire un segment d’environ 5 secondes de parole téléphonique (Novotney
& Callison—Burch, 2010). Il faut cependant nuancer ces chiffres. Tout d’abord, le coﬁt effectif n’est pas toujours
calculé avec rigueur. En effet, le temps de développement de l’interface et de mise en place des garde—fous est
non nul (Callison-Burch & Dredze, 2010). De meme, le coﬁt de validation (Kaisser & Lowe, 2008) ou de de-
veloppement (Xu & Klakow, 2010) post—MTurk permettant de compenser la mauvaise qualité des résultats (voir
section 3.4) n’est genéralement pas precisement évalue. Or, ces coﬁts supplémentaires ne sont jamais pris en
compte dans le calcul ﬁnal. De plus, certaines taches peuvent se revéler plus coﬁteuses que prévues. Ainsi, si l’on
ne trouve pas de Turkers pour faire la tache, on peut etre oblige d’augmenter la remuneration, comme Novotney
& Callison—Burch (2010), qui, partant d’un coﬁt tres bas (5 dollars de l’heure transcrite), ont eté obliges de le
multiplier par 7 (37 dollars de l’heure) pour transcrire du coréen, par manque de Turkers qualiﬁes.

3.4 MTurk permet de produire une qualité équivalente ?
3.4.1 Limitations liées :71 la non expertise

Les Turkers étant des non experts, le Requester (fournisseur de taches) doit découper les taches complexes en
taches plus simples (HIT, Human Intelligence Task), aﬁn de les rendre réalisables. Ce faisant, le chercheur est
amené a faire des choix qui peuvent biaiser les resultats. Un exemple de ce type de biais est analyse dans (Cook
& Stevenson, 2010), ou les auteurs reconnaissent que le fait de ne proposer qu’une phrase par type d’evolution
lexicale (amelioration ou pejoration) inﬂuence le résultat.

Plus grave encore que ces biais potentiels, certains chercheurs ont observe que, lorsque la complexité de la tache
augmente, la qualité produite sous MTurk est insufﬁsante. C’est notamment le cas dans (Bhardwaj et al., 2010), qui
démontre que, pour leur tache de désambiguisation lexicale, un petit nombre d’annotateurs bien formés produit de
bien meilleurs resultats qu’un grand nombre de Turkers (le nombre étant suppose contrebalancer la non expertise).
De ce point de vue, leurs résultats contredisent ceux de Snow et al. (2008) dont la tache etait semblable mais
beaucoup plus simple.Cette meme djfﬁculte d’obtenir une qualité sufﬁsante sur des taches complexes apparait
dans (Gillick & Liu, 2010), qui démontre que l’évaluation par des non experts de systemes de resume automatique
est « risquée », les Turkers n’étant pas capables d’ obtenir des resultats comparables a ceux des experts. On retrouve
ce probleme de qualité dans de nombreux articles, dans lesquels les auteurs ont dﬁ faire valider les resultats
des Turkers par des spécialistes (des étudiants en these pour (Kaisser & Lowe, 2008)) ou leur faire subir un
post—traitement assez lourd (Xu & Klakow, 2010). Enﬁn, la qualite du travail des annotateurs non experts varie
considerablement (Tratz & Hovy, 2010).

ll existe également un effet << boule de neige » qui tend a surestimer la qualité signalée dans les articles : des
chercheurs louent MTurk (Xu & Klakow, 2010), citant des recherches qui ont fait usage de MTurk, mais qui
n’auraient pas donne de resultats utilisables sans une intervention postérieure plus ou moins lourde (Kaisser &
Lowe, 2008). On pourrait en conclure que MTurk ne devrait etre utilise que pour des taches simples, or, outre le

MYRIADISATION DU TRAVAIL PARCELLISE

fait que son fonctionnement meme induit d’i1nportantes limitations (voir section 3.4.2), il est intéressant de noter
que dans certains cas simples, des outils de TAL font d’ores et déja mieux que les Turkers (Wais et al., 2010).

3.4.2 Limitations liées au fonctionnement méme de M'Ii1rk

Une premiere limitation est l’interface de MTurk. Tratz & Hovy (2010) notent ainsi que les limites de l’interface
constituent << le premier et le plus important des defauts » de MTurk. Les auteurs regrettent par ailleurs l’impos-
sibilité d’avoir la certitude que les Turkers participant a la tache sont bien de langue matemelle anglaise. Cette
impossibilité de connaitre les capacités réelles des Turkers, notamment de connaitre leur langue matemelle (bien
que leurs adresses IP soient geolocalisables), est un probleme bien reel. S’il est possible de mettre en place des
tests préalables, qui, la encore, représentent un coﬁt supplémentaire a prendre en compte, il est tres facile de
tricher (Callison—Burch & Dredze, 2010). Bien entendu, il est toujours possible de mettre en place des garde-
fous (Callison—Burch & Dredze, 2010; Welinder et al., 2010), mais, encore une fois, cela demande du temps
et represente donc un coﬁt supplémentaire que peu de Requesters sont prets a investir. Ainsi, dans (Xu & Kla-
kow, 2010), les auteurs ont identiﬁé des spammeurs mais n’ont pas réussi ales éliminer. Pour certaines taches, il
peut s’avérer difﬁcile de trouver des Turkers ayant les competences necessaires en raison de la complexite de la
tache (Gillick & Liu, 2010; Lambert et al., 2010), ou de la langue a maitriser (Novotney & Callison-Burch, 2010).

Par ailleurs, il ne faut pas negliger l’i1npact du paiement a la tache, qui induit comme comportement logique de
placer le nombre de taches realisées au-dessus de la qualité de la realisation, et ce, quelle que soit la retribution.
Kochhar et al. (2010) sont ainsi arrives a la conclusion qu’i1 valait mieux payer a l’heure (avec, bien sur, des
procedures de veriﬁcation et de justiﬁcation du temps passe).

4 Quelques réﬂexions sur le statut de MTurk

4.1 Que] est le statut de l’activité dans MTurk ?

En obscurcissant la relation entre Turkers et Requesters, et entre les Turkers eux—memes, MTurk empeche de fait
la possibilité de s’organiser en syndicats, de protester contre d’éventuelles pratiques douteuses des Requesters ou
d’ester en justice. Au—dela des problemes de droit du travail, il faut parler des problemes des taxes et cotisations
sociales : Amazon considere (selon l’accord de licence de MTurk) que les Turkers sont assimilables a des tra-
vailleurs indépendants,et donc qu’il leur incombe de payer toutes les taxes et charges afférant a leur activité. Etant
donné la hauteur des remunerations prises individuellement, il est parfaitement hypocrite de penser que cela est
possible. 11 est donc fortement probable que les Turkers ne déclarent pas ces revenus et ne cotisent pas non plus a
une quelconque caisse de retraite ou de securite sociale. 11 en Va bien entendu de meme pour les foumisseurs de
travail. Les états sont donc privés d’ un revenu légitime.

ll faut souligner également que la nature de la relation er1tre les trois partenaires, Turker, Requester et MTurk,
vague pour le droit américain, est encore plus douteuse en regard du droit frangais. En effet, selon la legislation
frangaise du travail, en dehors du fait que le travail a la tache est illegal, soit il s’agit de travail salarié, qui serait, en
l’occurrence, non declare par l’employeur, donc illegal (article 8200 et suivants du Code du Travail), soit il s’agit
d’ un rapport de prestation de service, dont le donneur d’ordre serait MTurk et le prestataire le Turker et, dans ce
cas, le Turker doit etre enregistré au registre du commerce (article 8222-1 du Code du Travail).

4.2 Le modéle économique de MTurk est-il fondé ?

Comme souligné dans la partie 2, lorsque l’on aborde pour la premiere fois MTurk, on est sidéré devant les condi-
tions ﬁnancieres imposées aux Turkers, qui amenent a des remunerations horaires ridiculement basses (inférieures
a 2 dollars, soit 1,46 euros (Ross et al., 2009; Ipeirotis, 2010b)). Ce coﬁt fabuleusement bas correspond—il a une
réalite économique saine (comme suggere par Marge et al. (2010) et McGraw et al. (2010), qui considerent que
cette retribution n’est qu’une sorte de bonus pour une tache par ailleurs effectuee avec plaisir) ?

Nous l’avons vu dans la partie 3.2, l’assertion que les Turkers considerent MTurk comme un hobby est fausse, au
moins pour une partie signiﬁcative d’entre eux. Des lors, pourquoi, si cela constitue pour eux un travail, acceptent-
ils un salaire horaire aussi bas ? La loi de l’offre et la demande n’est pas sufﬁsante pour l’expliquer, tout d’abord

B.SAGOT K. FORT G. ADDA J. MARIANI B.LANG

parce que le nombre reel de Turkers n’est pas si important (Fort et al., 2011), ensuite, parce qu’il est souvent
difﬁcile de faire exécuter des taches de grande taille en un temps limité pour un coﬁt standard (Ipeirotis, 2010a).

Un fait peut nous mettre sur la voie d’une explication credible : beaucoup d’articles (par exemple (Marge et al.,
2010)) soulignent que la qualité n’est pas liee au coﬁt associe a chaque tache. Cela est dﬁ en particulier a la
presence de spammeurs (c’est—a—dire de Turkers qui repondent au hasard ou en utilisant un systeme automatique),
attires par les taches bien rémunérées, et qui sont en grand nombre dans le systeme MTurk, le systeme de reputation
mis en place par Amazon étant notoirement facile a mettre en defaut5. Cela conduit a une situation semblable
au << marché des tacots », decrit par le prix Nobel Georges Akerlof (Akerlof, 1970) : l’acheteur d’une voiture
d’ occasion prend en compte dans le prix qu’il offre le risque que le vendeur lui << fourgue » un tacot. Les vendeurs
propriétaires d’une bonne voiture ne peuvent donc obtenir un bon prix et quittent le systeme, ce qui accroit en
retour la deﬁance de l’acheteur, car cela augmente le risque d’ acheter un tacot. La presence des spammeurs, de par
le laxisme du systeme mis en oeuvre par Amazon, conduit a une stabilisation a un prix tres bas, les bons travailleurs
quittant donc le systeme (70% des Turkers utilisent MTurk depuis moins de 6 mois (Ross et al., 2009)).

De plus, il est indéniable qu’un certain nombre de Turkers utilisent MTurk comme moyen de divertissement :
ceux—ci sont attires par les taches interessantes, quelle que soit leur remuneration. Sur ces taches, ils sont en
concurrence avec les Turkers-travailleurs (qui, naturellement, souhaitent également faire des taches intéressantes),
ce qui conduit egalement a faire baisser le taux horaire moyen << acceptable », c’est—a—dire le taux horaire seuil, en
dessous duquel un travailleur n’acceptera pas d’effectuer la tache.

Demier facteur qui tend a faire accepter un taux horaire ﬁnalement inacceptable : le travail a la tache. Un Turker,
fait bien sur une relation entre la difﬁculte de la tache et la retribution, mais n’a pas une idee claire du salaire
horaire avant de commencer a travailler. De plus, le travail a la tache induit un comportement que l’on peut voir
également dans des jeux en ligne ou a chaque fois que l’on effectue une tache contre une retribution absolue :
la personne a tendance a regarder grossir son compteur d’argent, ou de points, et a se ﬁxer des objectifs absolus,
deconnectés d’un quelconque taux horaire : << aujourd’hui, je reste dans le systeme, jusqu’a ce que j’ai gagné 5
dollars ». Ce qui n’est bien sﬁr pas le meilleur moyen d’ optimiser le taux horaire. Si le travail a la tache est interdit
en France, c’est bien pour empecher que des travailleurs gagnent moins que le salaire minimum.

Comme le souligne (Ipeirotis, 2010c), les defauts de la plateforme MTurk remettent en cause sa viabilité a moyen
terme, si elle n’évolue pas fondamentalement, en particulier sur les problemes de remuneration et de systemes de
reputation ﬁables pour les Turkers et les Requesters.

4.3 Quelle est la situation par rapport :71 la propriété intellectuelle sur MTurk ?

Au regard du droit européen, la problématique de la propriété intellectuelle pour des données telles que l’on peut
en produire via MTurk se pose le plus souvent en termes de protection associée aux bases de données, au sens
de la directive européenne du 11 mars 1996. Cette directive, qui conceme les ensembles d’informations de toutes
natures, offre une double protection : (1) par le droit d’ auteur concemant la structure de la base, conditionné au
fait qu’il y ait la une cre’ation originale, et (2) par un droit spéciﬁque couvrant le contenu, droit proche de celui
du droit d’auteur mais conditionné a la valeur économique des données (et non a leur originalite), au sens ou ces
données doivent avoir eté obtenues grace a un investissement substantiel du point de vue qualitatif ou quantitatif.
Cette deuxieme protection est indépendante du caractere public ou non des donnees, l’obj et de la protection étant
la base dans son ensemble (c’est—a—dire l’assemblage des donnees).

Dans le cas de MTurk, les droits semblent devoir etre la propriéte du Requester, soit en tant qu’auteur (pour les
HIT eux—memes et ce qu’ils pourraient contenir, sauf lorsque sont utilisées des données elles—memes soumises a
des droits d’auteurs propres, comme, par exemple, si l’on fait transcrire ou traduire des contenus existants), soit
en tant qu’organisateur de ce qui est une (euvre collective 5 (pour les productions des Turkers).

Cela dit, il n’est pas clair, avec MTurk relevant des Etats—Unis et des Requesters et des Turkers relevant souvent
d’ autres pays, qu’il y ait un droit applicable, la situation ne semblant pas envisagee dans les traites intemationaux.

5. http ://behind-the-enemy-lines.blogspot.com/2010/10/be-top-mechanical-turk-worker-you-need.html

6. L’oeuvre collective est déﬁnie par l’article L. 113-2 alinéa 3 du Code de la propriété intellectuelle comme étant une oeuvre créée
sur l’initiative d ’une personne physique ou morale qui l’e’dite, la publie et la divulgue sous sa direction et son nom et dans laquelle la
contribution personnelle des divers auteurs participant a son élaboration se fond dans l ’ensemble en vue duquel elle est concue, sans qu’il
soit possible d ’attribuer a chacun d ’eux un droit distinct sur l’ensemble réalise’. L’article 113-5 stipule alors que L’aeuvre collective est, sauf
preuve contraire, la propriété de la personne physique ou morale sous le nom de laquelle elle est divulguée. [. . . ] .

MYRIADISATION DU TRAVAIL PARCELLISE

5 Alternatives existantes ou proposées

Comme indiqué ci—dessus, les objectifs principaux des développeurs de ressources linguistiques faisant appel
£1 MTurk sont l’obtention de résultats de bonne qualité, £1 un faible coﬁt et dans un délai tres bref. Mais ces
obj ectifs ne sont pas nécessairement faciles £1 atteindre avec MTurk, alors que des approches alternatives existent.
Tout d’abord, bien qu’une comparaison systématique entre MTurk et des algorithrnes état—de—l’art irnpliquant un
échantillon varié detaches liées au TAL reste £1 faire, il semble que certains auteurs aboutissent £1 la conclusion que
les annotateurs automatiques déj£1 disponibles pour certaines t£1ches font aussi bien voire rnieux que les Turkers
(Wais et al., 2010) : les outils automatiques peuvent faire rnieux que les non experts. La réutilisation intelligente
de ressources existantes peut également étre une alternative simple et peu coﬁteuse £1 MTurk. Enﬁn, MTurk n’est
qu’une des nombreuses possibilités de m.t.p.

5.1 Approches non supervisées et semi-supervisées pour le développement de ressources
linguistiques £1 faible coiit

La communauté du TAL s’intéresse depuis longtemps £1 des approches dites non supervisées d’apprentissage
automatique, pour un large éventail de t£1ches parfois complexes. De la segmentation en mots £1 l’analyse syn-
taxique (Hanig, 2010) en passant par l’annotation morphosyntaxique (Goldwater & Grifﬁths, 2007), le dévelop-
pement de ressources lexicales (y compris de niveau sémantique ou pragmatique, cf. (Pak & Paroubek, 2010)) ou la
categorisation de documents, nombreuses sont les t£1ches pour lesquelles des techniques existent qui ne nécessitent
aucune ressource préalable. Bien que les résultats obtenus soient souvent inférieurs aux résultats des approches
supervisées (utilisant un corpus d’apprentissage) ou symboliques avancées (utilisant des ressources symboliques
également coﬁteuses £1 développer), on peut penser que, pour certaines t£1ches, ils ne sont pas inférieurs £1 ce que
l’on peut attendre de MTurk. C’est notarnment le cas pour des t£1ches complexes comme l’analyse syntaxique.

Pour améliorer £1 faible coﬁt la qualité des outils statistiques ainsi développés et/ou pour les faire correspondre
£1 des modeles préexistants (par exemple, £1 un inventaire préétabli de categories dans le cadre de l’annotation
morphosyntaxique), il n’est pas forcément nécessaire de recourir £1 des techniques totalement supervisées. Une
utilisation optimale d’un ensemble limité d’informations (annotations, ressources extemes) peut donner de bons
résultats : c’est le paradigme de Papprentissage semi—supervise’ (Abney, 2007). Dans le cas du développement de
ressources linguistiques, on peut identiﬁer deux types (non mutuellement exclusifs) de serni-supervision.

La premiere idée que l’on peut avoir est d’ entrainer des modeles sur les quelques données armotées, puis d’an-
noter automatiquement les autres données : on peut alors choisir parrni les données armotées automatiquement
celles pour lesquelles le modele a un niveau de conﬁance optimal, et les considérer comme de nouvelles données
annotées pour l’apprentissage d’un nouveau modele, et ainsi de suite : c’est le self—traim'ng, utilisé en TAL depuis
longtemps (Yarowsky, 1995). Cette idée peut étre généralisée en utilisant deux modeles les plus différents pos-
sible, et £1 compléter les données d’apprentissage de l’un par les annotations automatiques les plus sﬁres produites
par l’autre. C’est le co—traim'ng (Blum & Mitchell, 1998), qui cherche £1 éliminer au maximum les biais speci-
ﬁques £1 chaque modele par la confrontation £1 un autre. A ce stade, on reste dans une situation ou une annotation
manuelle peu coﬁteuse sert de graine pour la construction successive, mais automatisée, de modeles qui vont en
s’améliorant, jusqu’£1 obtenir des performances satisfaisantes. Si l’on accepte de continuer £1 annoter des données
manuellement au cours des étapes de construction successive de modeles, on peut faire en sorte que soient choi-
sies et présentées aux annotateurs les données telles que disposer d’une annotation de reference pour elles soit de
nature £1 améliorer au rnieux la qualité des outils. C’est l’idée au coeur de l’active learning (Cohn et al., 1995).

La deuxieme idée, combinable avec la premiere, consiste £1 utiliser au rnieux des données annotées d’une fa-
gon moins complete que l’annotation visée. Par exemple, pour l’armotation morphosyntaxique, on peut disposer
d’un lexique exteme mais pas d’un corpus d’apprentissage : projeter le lexique sur le corpus correspond alors
£1 une annotation ambigue, qu’il faut désambigu'1'ser (Smith & Eisner, 2005). Pour le développement de lexiques
morphologiques, disposer d’une description formalisée de la morphologie de la langue permet l’utilisation de
techniques efﬁcaces de suggestion d’entrées lexicales (Sagot, 2005). De meme, on peut chercher £1 exploiter un
corpus partiellement parenthésé pour guider des modeles d’analyse syntaxique complets (Watson et al., 2007).

B.SAGOT K. FORT G.ADDA J.MARIANI B.LANG

5.2 Réutilisation de ressources existantes

Moins coﬁteux encore, la construction de ressources linguistiques peut se faire en reutilisant des ressources exis-
tantes. Considerons par exemple la tache de detection d’entités nommées. Nothman et al. (2008) montrent qu’il
est possible de transformer Wikipedia en une ressource annotée en entités nommées de large couverture et de
tres bonne qualité. De tels corpus ont pourtant eté construits au moyen de MTurk, notamment sur des corpus non
standard, en particulier médicaux (Yetisgen—Yildiz et al., 2010), twitter (Finin et al., 2010), e—mails (Lawson et al.,
2010). Naturellement, ces corpus sont tres différents de ce que l’on peut obtenir au moyen de Wikipedia. Mais la
taille des données extraites, ainsi que les caractéristiques de Wikipedia en tant que corpus, font que les détecteurs
d’ entités nommées entrainés sur un corpus construit a partir de Wikipedia tendent a avoir de tres bons resultats
lorsqu’ils sont utilises sur d’autres types de corpus (Balasuriya et al., 2009).

ll ne s’agit la que d’un exemple, mais nombreuses sont les ressources susceptibles de fournir des données de
toutes natures : Wikipedia7 et autres projets wiki, notamment wiktionary, corpus (annotés ou non, oraux ou tex-
tuels) et ressources lexicales (phonétiques, morphologiques, syntaxiques, semantiques), pour peu qu’elles soient
disponibles pour la communauté. Il s’agit ici d’un autre débat, sur lequel nous n’insisterons donc pas plus avant.

5.3 Développement collaboratif ou myriadisé de ressources linguistiques au-delﬁ de MTurk

Toutes les méthodes alternatives décrites jusqu’a present ont prouvé leur utilité et leur efﬁcacité, mais elles re-
quierent des competences expertes, ne serait—ce que pour concevoir et developper les outils automatiques, mais
egalement pour effectuer, si besoin est, les taches d’a1motation optimisées. Il existe des methodes de développe—
ment de ressources linguistiques qui ne font pas necessairement appel a des experts, sans etre pour autant touchees
par tous les problemes décrits pour MTurk. Il s’agit en particulier des approches collaboratives, des approches lu-
diques mais également de certaines plateformes de m.t.p., qui se sont données les moyens d’ en éviter les écueils.

Les approches collaboratives de developpement de ressources lexicales reposent sur la strategie mise en place
par le projet Wikipedia, les autres projets de la constellation Wikimedia, et d’autres types de wiki comme les
Semantic Wiki (Freebase, OntoWiki. . .). Différents participants volontaires, experts ou non, enrichissent progres-
sivement une meme ressource, soit sous forme d’annotations soit sous forme de bases de données (lexicales,
ontologiques. . .). C’est une premiere etape vers la m.t.p. : ici, le travail n’est pas parcellisé, et il n’est que fai-
blement myriadisé. Les annotations des uns sont << controlées » par les autres, et des divergences de vues er1tre
différents participants se manifestent le plus souvent par des discussions, conduisant éventuellement a ce que
l’ad1ninistrateur tranche et decide. C’est ainsi qu’un tres haut niveau de qualité peut etre ﬁnalement atteint. Une
des premieres plateformes wiki dediée au developpement d’une ressource TAL est l’outil Serengeti, développe
a l’Universite de Bielefeld (Stiirenberg et al., 2007), a des ﬁns d’annotation semantique des textes. Cet outil est
utilise actuellement dans le cadre du projet AnaWiki (http: / /www . anawiki . org).

Toutefois, ces approches restent plus adaptées pour le developpement de ressources de tajlle raisonnable avec une
bonne qualité (gold standard). Elles sont moins indiquées pour le développement rapide de ressources a grande
échelle. Une autre strategie, qui repose egalement sur le Web, est d’attirer de grand nombres de non experts au
moyen de jeux en ligne dits ayant un but (en anglais games with a purpose, ou GWAP). Cette idee, initiée par (von
Ahn, 2006; von Ahn & Dabbish, 2008) avec le jeu en ligne ESP (http : / /www . espgame . org/) consiste a
faire étiqueter des images par des joueurs qui rentrent en competition : ceux—ci regoivent des credits lorsque leurs
reponses co'1'ncident avec celles d’autres joueurs 8. ESP a connu un succes important en mobilisant 13 500 utilisa-
teurs, creant 1, 3 million d’ étiquettes dans les premiers mois suivant son apparition sur la Toile. Cette idée a eté par
la suite déclinée pour divers types detaches, y compris en TAL. Des exemples en sont le jeu JeuxDeMots (Lafour—
cade & Joubert, 2008, http: / /www . lirmm . f r/ jeuxdemot s), qui vise a collecter des relations entre mots,
et son alter ego PtiClic (ibid., http: / /www . lirmm . f r/ pticlic), qui vise a typer explicitement ces rela-
tions. Le jeu PhraseDetective (Chamberlain et al., 2008, http : / /www . phrasedetectives . org), quant
a lui, a pour objectif l’armotation de liens anaphoriques, tache pourtant reputée complexe. L’idee est alors que
l’on peut aussi utiliser le jeu pour former les utilisateurs a la tache. Phrase Detective comprend ainsi une phase
d’ entrainement o1‘1l’on apprend la tache au nouveau joueur, par le biais de tests de plus en plus durs bases sur un
petit ensemble de données venant de corpus existants (annotés par des experts).

7. ll faut notamment citer le projet DBpedia (http : / / dbpedia . org), qui cherche a extraire des informations ontologiques structurées
a partir de Wikipedia, constituant ainsi une ressource aux potentialités multiples ct déja largement utilisée.

8. Différentes procédures sont prévues pour exclure les utilisateurs malveillants, notamment le controle des adresses IP, la vériﬁcation
aléatoires des étiquetages pour des réponses connues, etc. (von Ahn & Dabbish, 2008)

MYRIADISATION DU TRAVAIL PARCELLISE

Toutefois, la frontiere er1tre jeu de type GWAP et m.t.p. a la MTurk n’est pas nette. On ne peut pas distinguer
facilement les GWAP, qui seraient plus ludiques, et MTurk, qui serait stricto sensu du travail : meme contribuer a
Wikipedia est un travail, certes bénevole. On ne peut pas non plus distinguer les GWAP de MTurk en tant qu’ils
ne donneraient lieu a aucune recompense tangible : certains jeux en ligne sont des GWAP mais proposent des
remunerations non—monetaires (ainsi, PhraseDetective permet de gagner des bons a depenser sur le site d’achat
en ligne Amazon). Enﬁn, on ne peut pas distinguer la m.t.p. a la MTurk par le caractere << éthique » des premiers.
ll existe en effet des alternatives a MTurk pour développer des ressources linguistiques dans le paradigme de la
m.t.p., tout en evitant les écueils évoqués tout au long de cet article.

Pour le recueil de données langagieres, en particulier pour les langues peu dotées, des alternatives a MTurk
semblent etre plus appropriées. Ainsi, l’utilisation d’applications sur des telephones portables de nouvelle ge-
neration est un moyen plus efﬁcace de pouvoir accéder a toute une population. Hughes et al. (2010) ont ainsi
embauché des locuteurs locaux et leur ont preté des telephones sur lesquels toumait une application dédiée. Les
auteurs ont ainsi recueilli 3 000 heures en 17 langues. Un exemple de m.t.p. ethique est Samasource, une ONG qui
utilise ce type de methode pour faire effectuer des taches 9 a des personnes reellement necessiteuses formees et re-
munerees équitablement selon des baremes dependant du pays. 11 s’agit la d’ une alternative éthique a l’utilisation
de MTurk qui permet également de tirer parti des avantages de la m.t.p.

5.4 Optimiser le coiit de l’annotation manuelle : pré-annotation et interfaces dédiées

Independamment de la fagon dont on s’en sert, l’annotation manuelle par des experts peut etre considerable-
ment accélérée voire ameliorée au moyen d’outils d’annotation automatique utilises comme pre—annotateurs. Par
exemple, Fort & Sagot (2010) ont demontré que, dans le cas de l’étiquetage morphosyntaxique, une préannotation,
meme de pietre qualité et donc développable a faible coﬁt, permet d’améliorer tres largement le temps et la qualité
des annotations manuelles. Ainsi, les auteurs ont montre que 50 phrases annotees a la main sans pré-annotation,
ce qui prend environ 40 minutes 1°, permettent de construire un preannotateur tel que la vitesse de l’annotation
manuelle par un expert est quasiment identique a ce que l’on obtient avec un préannotateur de niveau etat—de—
l’art, c’est—a—dire que l’on peut construire un corpus complet de taille standard (10 000 phrases) en environ 6 000
minutes (100 heures). Des annotateurs experts et coﬁteux, pour peu que leur travail soit prepare puis utilise de
fagon optimale, permettent donc le développement de ressources de tres bonne qualite a un coﬁt qui reste limité. A
l’inverse, sur cette tache d’apparence simple, des Turkers seraient bien en peine de suivre correctement un guide
d’ armotation detaille, necessairement complexe s’il est linguistiquement sérieux.

Par ailleurs, les remarques de Tratz & Hovy (2010) mentionnées ci-dessus concemant les limitations des interfaces
déployables dans MTurk s’appliquent de maniere generale. L’experience acquise, par exemple, dans le develop-
pement de corpus annotes syntaxiquement ou sémantiquement montre que la rapidité et la qualité l’annotation, de
quelque nature qu’elle soit, est fortement inﬂuencée par l’interface d’ armotation elle—meme (cf. par exemple (Erk
et al., 2003)). Il y a donc la aussi matiere a accélérer et améliorer toute etape d’annotation manuelle, au point
qu’une interface adaptée a une tache donnée pourrait permettre de reduire les coﬁts dans des proportions compa-
rables a celles obtenues par l’utilisation de MTurk, sans en presenter les inconvenients.

6 Conclusion et perspectives

MTurk illustre la complexite et la difﬁculte d’appréhender les relations (commerciales, de travail et autres) dans
les nouveaux modes d’ activités sur Internet. Les chercheurs qui ont utilise MTurk l’ont fait souvent de bonne foi,
par manque de moyens ﬁnanciers, pour produire plus de données et les redistribuer a la communauté. Pour ceux
qui ont eu des doutes sur de possibles problemes d’éthique et de droit du travail, une recherche superﬁcielle les a
convaincus que MTurk est une sorte d’avatar de Wikipedia, et que les Turkers sont motives surtout par le plaisir
d’ effectuer des taches arnusantes.

Nous pensons avoir montre que MTurk n’est pas une panacée et que d’autres solutions existent aujourd’hui pour
réduire les coﬁts de construction de ressources linguistiques de qualite, tout en respectant ceux qui travaillent sur
ces ressources et en tirant un meilleur parti de leurs competences. Car derriere le debat autour de MTurk se trouve

9. Come traduire des SMS en créole, lors du tremblement de terre a Haiti aﬁn de permettre aux secours intemationaux d’a11er a leur
secours, en liaison avec le site CrowdFlower. http : / /www . samasource . org/hait i /.
10. Les estimations proposées dans ce paragraphe, tres grossieres, reposent sur celles de (Fort & Sagot, 2010).

B.SAGOT K. FORT G.ADDA J.MARIANI B.LANG

ﬁnalement la question de la consideration due aux armotateurs, aux traducteurs, aux spécialistes de la transcription.

Nous aimerions, en conclusion, aller au—dela des faits actuels et mettre l’accent sur les consequences a plus ou
moins long terme de cette << mode ». En effet, sous la pression de ce type de systemes a bas coﬁt, les agences de
moyens pourraient bientot etre plus reticentes a ﬁnancer des projets de développement de ressources linguistiques
a des coﬁts << normaux » (ou plutot réalistes). Le coﬁt a la MTurk deviendrait alors une norme de fait et nous
n’aurions plus le choix de nos methodes de développement.

Nous avons vu, dans la partie 5.3, qu’un systeme de m.t.p. peut permettre de faire produire des taches rémunérées
en preservant l’ethique, cela peut meme etre une chance pour des personnes qui ne peuvent se trouver sur le
marché du travail, de par leur isolement, leur handicap, etc ; mais cela necessite un encadrement legal strict aﬁn de
s’assurer que ce systeme n’est pas une remise en cause des droits des travailleurs. On peut penser a moyen terme
au développement d’une plateforme m.t.p. operée par les acteurs de recherche au niveau europeen, et un guide des
bonnes pratiques concernant l’utilisation des m.t.p., comme cela se fait dans d’autres secteurs de recherches, par
exemple en sciences sociales. Mais ces solutions risquent de ne pas freiner le développement actuel de l’utilisation
de MTurk, au nom du “pragmatisme” et de la concurrence avec les equipes (par exemple) outre—Atlantique; c’est
pourquoi nous proposons la creation d’un label de qualite et d’éthique, qui pourrait etre decemé aux ressources
par les associations savantes concemées, l’ATALA“ pour le TAL et l’AFCP 12 pour la parole. Les questions
d’ ethique sont des a present un critere de selection pour les proj ets europeens, ce label permettrait de préciser le
statut des ressources comme critere de selection pour l’ensemble des agences de moyens, tout en Valorisant les
bonnes pratiques de développement.

Remerciements

Ce travail a ete realise en partie dans le cadre du programme Quaero, ﬁnance par OSEO, agence nationale de
Valorisation de la recherche, et dans celui du proj et ANR EDyLex (ANR—09—CORD—008).

Références

AB NEY S. (2007). Semisupervised Learning for Computational Linguistics. Chapman & Hall/CRC, lere edition.

ADDA G. & MARIANI J. (2010). Language resources and amazon mechanical turk : legal, ethical and other
issues. In LISLR20l 0, “Legal Issues for Sharing Language Resources workshop”, LREC20l0.

AKERLOF G. A. (1970). The market for ’lemons’ : Quality uncertainty and the market mechanism. Quarterly
Journal of Economics, 84(3), 488-500.

BALASURIYA D., RINGLAND N., NOTHMAN J ., MURPHY T. & CURRAN J . R. (2009). Named entity recog-
nition in Wikipedia. In People ’s Web ’09 : Proceedings of the 2009 Workshop on The People ’s Web Meets NLP,
p. 10-18, Morristown, NJ, USA : Association for Computational Linguistics.

BHARDWAJ V., PASSONNEAU R., SALLEB-AOUISSI A. & IDE N. (2010). Anveshan : A tool for analysis of
multiple annotators’ labeling behavior. In Proceedings of The fourth linguistic annotation workshop (LAW I V),
Uppsala, Suede.

BIADSY F., HIRSCHBERG J . & FILATOVA E. (2008). An unsupervised approach to biography production using
Wikipedia. In Proceedings of ACL 2008, p. 807-815 : Association for Computational Linguistics.

BIEWALD L. (2010). Better crowdsourcing through automated methods for quality control. SIGIR 2010 Work-
shop on Crowdsourcing for Search Evaluation.

BLUM A. & MITCHELL T. (1998). Combining labeled and unlabeled data with co-training. In COLT: Procee-
dings of the Workshop on Computational Learning Theory : Morgan Kaufmarm Publishers.

CALLISON—BURCH C. & DREDZE M. (2010). Creating speech and language data with amazon’s mechanical
turk. In CSLDAMT ’l0 : Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language
Data with Amazon ’s Mechanical Turk, Morristown, NJ, USA : Association for Computational Linguistics.
CHAMBERLAIN J ., POESIO M. & KRUSCHWITZ U. (2008). Phrase Detectives : a Web—based Collaborative
Annotation Game. In Proceedings of the International Conference on Semantic Systems (I—Semantics’08), Graz.

ll. http: //www. atala .org/
12. http: //www . afcp—parole . org/

