<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Identification de mots germes pour la construction d'un lexique de valence au moyen d'une proc&#233;dure supervis&#233;e</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin - 1er juillet 2011 
</p>
<p>Identification de mots germes pour la construction d'un lexique de valence 
au moyen d'une proc&#233;dure supervis&#233;e 
</p>
<p>Nadja Vincze1   Yves Bestgen2 
</p>
<p>(1)  UCLouvain, Cental, Place Blaise Pascal, 1, B-1348 Louvain-la-Neuve, Belgique 
(2) UCLouvain, CECL, B-1348 Louvain-la-Neuve, Belgique 
</p>
<p>nadja.vincze@uclouvain.be, yves.bestgen@uclouvain.be 
</p>
<p> 
</p>
<p>R&#233;sum&#233;  
</p>
<p>De nombreuses m&#233;thodes automatiques de classification de textes selon les sentiments qui y sont exprim&#233;s s'appuient sur 
un lexique dans lequel &#224; chaque entr&#233;e est associ&#233;e une valence. Le plus souvent, ce lexique est construit &#224; partir d'un 
petit nombre de mots, choisis arbitrairement, qui servent de germes pour d&#233;terminer automatiquement la valence d'autres 
mots. La question de l'optimalit&#233; de ces mots germes a bien peu retenu l'attention. Sur la base de la comparaison de cinq 
m&#233;thodes automatiques de construction de lexiques de valence, dont une qui, &#224; notre connaissance, n'a jamais &#233;t&#233; adapt&#233;e 
au fran&#231;ais et une autre d&#233;velopp&#233;e sp&#233;cifiquement pour la pr&#233;sente &#233;tude, nous montrons l'importance du choix de ces 
mots germes et l'int&#233;r&#234;t de les identifier au moyen d'une proc&#233;dure d'apprentissage supervis&#233;e. 
</p>
<p>Abstract  
</p>
<p>Many methods of automatic sentiment classification of texts are based on a lexicon in which each entry is associated with 
a semantic orientation. These entries serve as seeds for automatically determining the semantic orientation of other 
words. Most often, this lexicon is built from a small number of words, chosen arbitrarily. The optimality of these seed 
words has received little attention. In this study, we compare five automatic methods to build a semantic orientation 
lexicon. One among them, to our knowledge, has never been adapted to French and another was developed specifically 
for this study. Based on them, we show that choosing good seed words is very important and identifying them with a 
supervised learning procedure brings a benefit.  
</p>
<p>Mots-cl&#233;s :   Analyse de sentiments, lexique de valence, apprentissage supervis&#233;, analyse s&#233;mantique latente 
Keywords:  Sentiment analysis, semantic orientation lexicon, supervised learning, latent semantic analysis 
</p>
<p> </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADJA VINCZE, YVES BESTGEN 
 
</p>
<p>1 Introduction 
</p>
<p>La classification de textes consiste &#224; classer automatiquement les textes dans un ensemble pr&#233;d&#233;fini de 
cat&#233;gories. Ce sont initialement les classifications th&#233;matiques et par genre qui ont motiv&#233; les recherches, 
mais, depuis une dizaine d'ann&#233;es, ce champ d'&#233;tudes s'est &#233;largi et int&#232;gre la classification de textes en 
fonction des sentiments qui y sont exprim&#233;s : d&#233;tection de la subjectivit&#233;, avec une classification objectif / 
subjectif (Wiebe et al., 2004 ;Yu, Hatzivassiloglou, 2003) et d&#233;termination de la valence des documents, 
avec une classification binaire positif / n&#233;gatif, parfois multi-classes selon le degr&#233; de polarit&#233; (Abbasi et 
al., 2008 ; Pang et al., 2002). La plupart des impl&#233;mentations de ces classifieurs requi&#232;rent des lexiques 
porteurs de valence, c'est-&#224;-dire des lexiques o&#249; &#224; chaque entr&#233;e est associ&#233;e une polarit&#233; ou un degr&#233; de 
polarit&#233;. Une s&#233;rie d'approches attribuent une valence globale aux textes selon des statistiques sur la 
pr&#233;sence de mots subjectifs (Bestgen, 2006 ; Turney, 2002). Les approches dites symboliques int&#232;grent la 
prise en compte de ph&#233;nom&#232;nes syntaxiques qui viennent modifier l'orientation s&#233;mantique de mots ou de 
groupes de mots (Harb et al., 2008 ; Vernier et al., 2009 ; Wilson et al., 2005). Enfin, quelques tentatives 
d'apprentissages supervis&#233;s ont &#233;galement pris en compte des mots, dont la valence est connue, comme 
caract&#233;ristiques de leurs vecteurs (Chesley et al., 2006). Ces lexiques constituent donc des ressources 
s&#233;mantiques capitales au d&#233;veloppement de classifieurs efficaces. 
</p>
<p>Dans un premier temps, ces lexiques ont &#233;t&#233; construits manuellement par des juges (Nasukawa, Yi, 2003 ; 
Wiebe et al., 2005), mais le travail &#233;tant lent et couteux, des proc&#233;dures automatiques ou semi-automatiques 
ont vu le jour et constituent aujourd'hui un sous-domaine de recherche important. Comme le souligne la 
pr&#233;sentation des travaux ant&#233;rieurs (section 2), une sp&#233;cificit&#233; des recherches men&#233;es dans ce champ est 
qu'elles portent presque exclusivement sur l'anglais, langue pour laquelle de nombreuses ressources 
linguistiques ont &#233;t&#233; d&#233;velopp&#233;es comme WordNet (Miller, 1990). Un des deux objectifs principaux de 
notre &#233;tude est de d&#233;terminer dans quelle mesure ces m&#233;thodes sont applicables au fran&#231;ais. Une autre 
sp&#233;cificit&#233; des recherches men&#233;es dans ce champ est que la quasi-totalit&#233; des m&#233;thodes propos&#233;es utilise un 
petit nombre de mots, comme bon, mauvais, gentil, afin de servir de germes (seed) pour d&#233;terminer 
automatiquement la valence d'autres mots (voir par exemple Hu, Liu, 2004; Kamps, Marx, 2002 ; Turney, 
Littman, 2003). La question de l'optimalit&#233; de ces mots germes a bien peu retenu l'attention, le plus souvent 
les chercheurs reprenant ceux propos&#233;s dans des travaux ant&#233;rieurs (Esuli, Sebastiani, 2006 ; Harb et al., 
2008). Notre second objectif est de proposer une m&#233;thode permettant d'identifier automatiquement ces 
germes au moyen d'une technique d'apprentissage supervis&#233;e. 
</p>
<p>Apr&#232;s une br&#232;ve pr&#233;sentation des travaux ant&#233;rieurs, la section 3 d&#233;crit les diff&#233;rentes m&#233;thodes compar&#233;es 
dans le cadre de cette &#233;tude. Une s&#233;rie d'exp&#233;riences visant &#224; &#233;valuer leur efficacit&#233; sont pr&#233;sent&#233;es dans la 
section 4. La section 5 rapporte les principaux r&#233;sultats, dont les implications et les d&#233;veloppements 
possibles sont discut&#233;s dans la conclusion. 
</p>
<p>2 Travaux ant&#233;rieurs 
</p>
<p>Parmi les m&#233;thodes automatiques ou semi-automatiques propos&#233;es pour construire des lexiques porteurs de 
valences, on peut distinguer deux types d'approches : celles bas&#233;es sur des ressources linguistiques comme 
WordNet et celles bas&#233;es sur des corpus de textes.  
</p>
<p>Les approches qui s'appuient sur des bases de connaissances linguistiques calculent g&#233;n&#233;ralement la 
similarit&#233; entre les mots &#224; partir de leur relation de synonymie. Une m&#233;thode de base consiste &#224; partir de 
quelques mots dont la valence est connue et &#224; lancer un algorithme d'amor&#231;age (bootstrapping) qui parcourt 
les liens synonymiques et antonymiques de la base, en attribuant la m&#234;me orientation aux mots synonymes 
et vice-versa (Hu, Liu, 2004 ; Kim, Hovy, 2004). Kamps et Marx (2002) ont probablement &#233;t&#233; les premiers 
&#224; proposer une telle proc&#233;dure en d&#233;rivant de WordNet un graphe dans lequel chaque n&#339;ud repr&#233;sente un 
terme et un lien est pr&#233;sent entre deux n&#339;uds s'ils sont synonymes. &#192; partir de ce graphe, ils calculent une 
valeur normalis&#233;e pour les n&#339;uds li&#233;s aux mots good et bad. Esuli et Sebastiani (2006) ont &#233;tendu cette 
approche pour d&#233;velopper SentiWordNet, une ressource bas&#233;e sur WordNet, qui assigne &#224; chaque synset 
trois valeurs normalis&#233;es : une positive, une n&#233;gative et une objective. La sp&#233;cificit&#233; principale de leur 
approche est qu'elle s'appuie sur un apprentissage semi-supervis&#233; bas&#233; sur les d&#233;finitions de mots germes 
s&#233;lectionn&#233;s manuellement.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CONSTRUCTION AUTOMATIQUE D'UN LEXIQUE DE VALENCE 
 
</p>
<p>Ne disposant pas d'informations sur les liens synonymiques, les approches qui s'appuient sur des corpus 
calculent les similarit&#233;s diff&#233;remment. Hatzivassiloglou et McKeown (1997) ont propos&#233; un algorithme 
capable de d&#233;terminer l&#8217;orientation s&#233;mantique d&#8217;adjectifs &#224; partir de l'analyse de leurs cooccurrences avec 
des conjonctions. Turney et Littman (2003 ; Turney, 2002) et Bestgen (2002, 2008) ont propos&#233; des 
m&#233;thodes plus g&#233;n&#233;rales puisqu&#8217;elles permettent d&#8217;estimer la valence de n&#8217;importe quel terme pr&#233;sent dans 
un corpus. Ils utilisent l'analyse s&#233;mantique latente (ASL, Latent Semantic Analysis, Deerwester et al., 
1990) pour construire un espace s&#233;mantique &#224; partir d'informations statistiques sur les cooccurrences de 
termes dans des textes. Turney et Littman l'emploient pour estimer la distance s&#233;mantique entre des mots et 
14 mots germes, 7 positifs (good, nice, excellent, positive, fortunate, correct, superior) et 7 n&#233;gatifs (bad, 
nasty, poor, negative, unfortunate, wrong, inferior). Un mot est d'autant plus positif qu'il est plus proche des 
germes positifs et plus &#233;loign&#233; des germes n&#233;gatifs. Pour sa part, Bestgen (2002) a recours &#224; l'ASL pour 
identifier les mots fr&#233;quemment associ&#233;s aux mots dont il veut d&#233;terminer la valence affective. Il attribue &#224; 
chaque mot la valence moyenne de ses plus proches voisins dont la valence est connue. Pour cela, il 
s'appuie sur un dictionnaire de 3000 mots dont la valence a &#233;t&#233; &#233;valu&#233;e par des juges. On notera que les 
similarit&#233;s peuvent &#234;tre calcul&#233;es sans passer par l'analyse s&#233;mantique latente, mais que, dans ce cas, des 
corpus de tr&#232;s grande taille semblent n&#233;cessaires (Turney, Littman, 2003; Velikovich et al., 2010), sauf si, &#224; 
la mani&#232;re de Harb et al. (2008), on emploie un corpus tr&#232;s sp&#233;cifique et des r&#232;gles d'associations. 
</p>
<p>Peu d'initiatives de construction automatique de lexiques ont eu lieu en fran&#231;ais, compar&#233; &#224; l'effervescence 
dans le milieu anglophone. Nous pouvons citer Bestgen (2002) et Chardon (2010) qui a d&#233;velopp&#233; une 
m&#233;thode pour &#233;laborer une ressource lexicale d'adjectifs d'opinion &#224; partir d'une liste de mots germes et 
d'une taxinomie des mots du fran&#231;ais. Pak et Paroubek (2010) ont propos&#233; une m&#233;thode de construction 
automatique d'un lexique affectif &#224; partir de messages disponibles sur Twitter. Leur proc&#233;dure est bas&#233;e sur la 
comparaison de la fr&#233;quence d'occurrence d'un mot dans les messages contenant une &#233;motic&#244;ne positive et 
dans ceux contenant une &#233;motic&#244;ne n&#233;gative. Vernier et Monceaux (2010) ont propos&#233; une m&#233;thode 
d'apprentissage pour enrichir automatiquement un lexique subjectif &#224; partir d'un corpus annot&#233;. 
L'apprentissage automatique se base sur des tests s&#233;mantiques, qui permettent de mesurer le degr&#233; de 
subjectivit&#233; des termes, ainsi que leur valence s'il s'agit d'adjectifs, et qui sont effectu&#233;s &#224; l'aide du moteur 
de recherche Yahoo!.   
</p>
<p>3 M&#233;thodes &#233;valu&#233;es pour estimer la valence de mots 
</p>
<p>Cinq m&#233;thodes pour estimer automatiquement la valence de mots ont &#233;t&#233; compar&#233;es, deux de celles-ci 
consistant en une transposition de m&#233;thodes efficaces pour la langue anglaise : celle de Turney et Littman 
(2002, 2003) et celle de Kamps et Marx (2002 ; Kamps et al., 2004). Nous avons &#233;galement repris la 
m&#233;thode de Bestgen (2002, 2008). Ces trois m&#233;thodes serviront de r&#233;f&#233;rence pour &#233;valuer deux nouvelles 
approches : une extension de la m&#233;thode de Kamps et Marx et une m&#233;thode d'apprentissage supervis&#233; de 
mots germes. La pr&#233;sente section d&#233;crit les principes &#224; la base de ces diff&#233;rentes m&#233;thodes. Des pr&#233;cisions &#224; 
propos de leur impl&#233;mentation et des ressources linguistiques qu'elles requi&#232;rent sont donn&#233;es dans la 
section suivante.  
</p>
<p>3.1 Niveaux de base : SO-ASL et DIC-ASL 
</p>
<p>Ces deux m&#233;thodes se basent sur l'analyse s&#233;mantique latente d'une collection de textes pour d&#233;terminer la 
proximit&#233; entre des mots et des germes dont la valence est connue. 
</p>
<p>&#8226; SO-ASL : il s&#8217;agit de la m&#233;thode propos&#233;e par Turney et Littman (2003) d&#233;crite ci-dessus. Elle 
est bas&#233;e sur 14 mots germes choisis en raison de leur valence extr&#234;me sur la dimension positif-
n&#233;gatif. La valence d&#8217;un mot correspond &#224; la somme des cosinus entre ce mot et les germes 
positifs dont on soustrait la somme des cosinus entre ce mot et les germes n&#233;gatifs. 
</p>
<p>&#8226; DIC-ASL : il s&#8217;agit de la m&#233;thode propos&#233;e par Bestgen (2002) d&#233;crite ci-dessus. Pour chaque 
mot dont on veut d&#233;terminer la valence, on identifie les 30 plus proches voisins dont la valence 
est connue et on lui affecte la valence moyenne de ceux-ci.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADJA VINCZE, YVES BESTGEN 
 
</p>
<p>3.2 Estimation sur la base de relations de synonymie : KA1 et KA7 
</p>
<p>Ces deux m&#233;thodes sont bas&#233;es sur la fonction d'&#233;valuation d&#233;finie par Kamps et Marx (2002). 
</p>
<p>&#8226; KA1 : cette m&#233;thode est bas&#233;e sur les liens synonymiques entre les adjectifs. Le principe consiste 
&#224; mesurer la distance minimale, c'est-&#224;-dire le plus court chemin, entre le mot auquel on veut 
attribuer une valeur et les mots germes good et bad. La valence d'un terme t est alors &#233;gale &#224; sa 
distance relative avec les deux germes : 
</p>
<p> 
o&#249; d (i, j) repr&#233;sente la distance du plus court chemin synonymique entre les mots i et j.  
</p>
<p>&#8226; KA7 est une adaptation de KA1 dans laquelle le nombre de paires d'adjectifs de r&#233;f&#233;rence est 
multipli&#233; par 7. Nous avons repris les 7 paires de r&#233;f&#233;rence de Turney et Littman (2003), que 
nous avons traduites comme suit : bon, gentil, excellent, positif, heureux, correct, sup&#233;rieur et 
mauvais, m&#233;chant, m&#233;diocre, n&#233;gatif, malheureux, faux, inf&#233;rieur. La fonction d'&#233;valuation 
adapt&#233;e reprend alors la somme des &#233;valuations pour chaque paire :  
</p>
<p> 
o&#249; ik et jk forment une paire d&#8217;adjectifs positif et n&#233;gatif des n paires prises en compte.  
</p>
<p>3.3 Apprentissage supervis&#233; de mots germes : ASG 
</p>
<p>Un des objectifs de cette recherche est de proposer et d'&#233;valuer une m&#233;thode d&#233;riv&#233;e de celles de Turney et 
Littman (2003) et de Bestgen (2002) dans laquelle les mots germes originaux, s&#233;lectionn&#233;s arbitrairement, 
sont remplac&#233;s par des germes optimaux obtenus par une proc&#233;dure d'apprentissage supervis&#233;e bas&#233;e sur la 
r&#233;gression. Pour ce faire, nous employons comme mat&#233;riel d'apprentissage une norme lexicale pour la 
dimension &#233;valuative obtenue en demandant &#224; des juges d'&#233;valuer un grand nombre de mots sur cette 
dimension. &#192; la suite de Heise (1965), une s&#233;rie de normes de ce type ont &#233;t&#233; d&#233;velopp&#233;es, principalement 
en psycholinguistique (Syssau, Font, 2005). La m&#233;thode propos&#233;e est compos&#233;e des quatre &#233;tapes 
suivantes : 
</p>
<p>1. S&#233;lectionner comme germes potentiels les mots qui sont les plus extr&#234;mes sur la dimension 
positif-n&#233;gatif selon une norme &#233;valuative comme celle employ&#233;e dans DIC-ASL. 
</p>
<p>2. Sur la base d'un espace s&#233;mantique obtenu par l'ASL d'une collection de textes, calculer le 
cosinus entre chacun de ces germes potentiels et tous les mots qui se trouvent dans la norme. 
</p>
<p>3. Utiliser une proc&#233;dure de r&#233;gression afin de construire un mod&#232;le pr&#233;dictif bas&#233; sur les germes 
les plus efficaces pour pr&#233;dire la valence. 
</p>
<p>4. Employer le mod&#232;le construit &#224; l'&#233;tape pr&#233;c&#233;dente pour estimer la valence de termes pr&#233;sents 
dans l'espace s&#233;mantique, mais non dans la norme initiale. 
</p>
<p>Le crit&#232;re de s&#233;lection des germes potentiels propos&#233; &#224; la premi&#232;re &#233;tape devrait permettre l'identification de 
mots germes similaires &#224; ceux originellement choisis par Turney et Littman (2003). Toutefois, lorsqu'on 
consid&#232;re le fait que le seuil pour s&#233;lectionner les mots les plus extr&#234;mes est par d&#233;finition arbitraire, il 
devient imm&#233;diatement &#233;vident que la proc&#233;dure propos&#233;e n'est qu'un cas particulier d'une proc&#233;dure plus 
g&#233;n&#233;rale dans laquelle les germes potentiels sont compos&#233;s de l'ensemble des mots pr&#233;sents dans la norme. 
Et, d'une mani&#232;re tout aussi &#233;vidente, cette premi&#232;re g&#233;n&#233;ralisation n'est, elle-m&#234;me, qu'un cas particulier 
d'une seconde g&#233;n&#233;ralisation, qui emploie comme germes potentiels tous les mots pour lesquels il est 
possible de calculer un cosinus avec les mots qui se trouvent dans la norme, soit tous les mots pr&#233;sents dans 
l'espace s&#233;mantique, que leur valence soit connue ou non. &#201;tant donn&#233; que les candidats germes pour 
l'approche la plus restrictive forment un sous-ensemble des candidats germes employ&#233;s dans les approches 
plus g&#233;n&#233;rales, on doit s'attendre &#224; ce que la qualit&#233; de la pr&#233;diction de la valence des mots du dictionnaire </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CONSTRUCTION AUTOMATIQUE D'UN LEXIQUE DE VALENCE 
 
</p>
<p>initial soit d'autant meilleure que l'approche est la plus g&#233;n&#233;rale. Par contre, les capacit&#233;s de g&#233;n&#233;ralisation 
des diff&#233;rents mod&#232;les pourraient &#234;tre &#233;quivalentes si ceux bas&#233;s sur le plus grand nombre de germes 
potentiels pr&#233;sentent un d&#233;faut de surapprentissage. 
</p>
<p>4 Exp&#233;riences 
</p>
<p>4.1 Ressources linguistiques pour l'impl&#233;mentation des m&#233;thodes 
</p>
<p>Les diff&#233;rentes m&#233;thodes propos&#233;es ci-dessus n&#233;cessitent des ressources linguistiques sp&#233;cifiques comme 
un dictionnaire de synonymes ou une collection de textes pour extraire l'espace s&#233;mantique. Les ressources 
que nous avons employ&#233;es sont d&#233;crites dans la pr&#233;sente section. 
</p>
<p>4.1.1 Dictionnaire de synonymes 
</p>
<p>L'adaptation de la m&#233;thode de Kamps et Marx (2002) au fran&#231;ais n&#233;cessite une ressource plus ou moins 
&#233;quivalente au WordNet anglais. En raison de la trop faible couverture de WOLF (WordNet Libre du 
Fran&#231;ais) et du WordNet fran&#231;ais d&#233;velopp&#233; dans le cadre du projet EuroWordNet1, nous avons employ&#233; le 
dictionnaire de synonymes d&#233;velopp&#233; par le laboratoire CRISCO de l'universit&#233; de Caen (Manquin et al., 
2004)2. Celui-ci a &#233;t&#233; constitu&#233; &#224; partir de sept dictionnaires fran&#231;ais et comprend plus de 49 000 entr&#233;es et 
396 000 relations synonymiques. De mani&#232;re similaire &#224; Kamps et Marx (2002), nous avons r&#233;cup&#233;r&#233; 
r&#233;cursivement tous les mots li&#233;s &#224; la paire d'adjectifs bon et mauvais, avec des restrictions sur la cat&#233;gorie 
grammaticale pour &#233;viter de g&#233;n&#233;rer trop de bruit. Une petite adaptation a d&#251; &#234;tre faite pour rendre la liste 
des synonymes r&#233;cup&#233;r&#233;s sym&#233;trique (Kamps et al., 2004 : 1115). 
</p>
<p>4.1.2 Norme de valence : Nev 
</p>
<p>La norme de valence employ&#233;e pour les m&#233;thodes DIC-ASL et ASG est compos&#233;e de 3252 mots &#233;valu&#233;s 
sur une &#233;chelle &#224; 7 points allant de tr&#232;s d&#233;sagr&#233;able (1) &#224; tr&#232;s agr&#233;able (7) par un minimum de 30 juges 
(Hogenraad et al., 1995). &#192; titre d'exemple, la liste suivante donne les valeurs attribu&#233;es &#224; quelques mots 
extraits al&#233;atoirement de ce dictionnaire : d&#233;tresse = 1.4, impassible = 2.6, ambigu = 3.2, outil = 4.3, revenir 
= 5.0, admiratif = 5.7, doux = 6.0.  
</p>
<p>4.1.3 Constitution de l'espace s&#233;mantique 
</p>
<p>L'espace s&#233;mantique, utilis&#233; pour calculer les cosinus entre les mots n&#233;cessaires pour SO-ASL, DIC-ASL et 
ASG, a &#233;t&#233; construit sur la base d'une collection de textes litt&#233;raires compos&#233;e de romans, nouvelles et 
contes disponibles sur le Web (principalement dans les bases litt&#233;raires ABU et Frantext). Elle contient 
approximativement 5 300 000 mots. Chaque texte a &#233;t&#233; subdivis&#233; en segments de 125 mots. Pour construire 
le tableau lexical, les pr&#233;traitements suivants ont &#233;t&#233; effectu&#233;s : lemmatisation par le logiciel TreeTagger 
(Schmid, 1994), suppression de mots outils et suppression des mots de fr&#233;quence totale inf&#233;rieure &#224; 10. La 
matrice de cooccurrences des 12 285 termes dans les 40 635 segments a &#233;t&#233; soumise &#224; une d&#233;composition 
en valeurs singuli&#232;res et les 300 premiers vecteurs propres ont &#233;t&#233; conserv&#233;s. 
</p>
<p>4.2 M&#233;thode pour l'&#233;valuation 
</p>
<p>Pour &#233;valuer l'efficacit&#233; de m&#233;thodes visant &#224; d&#233;terminer automatiquement la valence de mots, le test 
classique, lorsque l'&#233;tude est r&#233;alis&#233;e en anglais, se base sur les listes de mots positifs et n&#233;gatifs incluses 
dans le General Inquirer (p.e., Dragut et al., 2010 ; Kamps et al., 2004 ; Turney, Littman, 2003). Ces listes 
n'&#233;tant pas, &#224; notre connaissance, disponibles en fran&#231;ais, nous avons recherch&#233; un mat&#233;riel &#233;quivalent dans 
                                                           
1 Le WOLF couvre 30 % du WordNet de Princeton (Mouton &amp; Chalendar, 2010) et, selon nos calculs, le 
</p>
<p>WordNet fran&#231;ais couvre environ 25 % des synsets de la version 1.5 de WordNet. 
2  www.crisco.unicaen.fr/cgi-bin/cherches.cgi </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADJA VINCZE, YVES BESTGEN 
 
</p>
<p>cette langue. La section 4.2.1 d&#233;crit les normes de valence de Syssau et Font (2005). Ces normes pr&#233;sentent 
l'avantage d'avoir &#233;t&#233; r&#233;colt&#233;es dans des conditions rigoureuses et bien document&#233;es, alors qu'on ne dispose 
de pratiquement aucune information sur la proc&#233;dure suivie pour constituer les deux listes du General 
Inquirer. Cependant, elles ne portent que sur 735 mots alors que les listes originales du General Inquirer en 
contiennent plusieurs milliers. &#192; titre comparatif, nous avons r&#233;alis&#233; une premi&#232;re adaptation fran&#231;aise des 
listes du General Inquirer. 
</p>
<p>4.2.1 Valemo : V80, V50 et Vscore 
</p>
<p>Syssau et Font (2005) ont demand&#233; &#224; 600 juges d'&#233;valuer 735 mots3 sur deux &#233;chelles : une &#233;chelle 
nominale &#224; trois modalit&#233;s (n&#233;gatif, neutre et positif) et une &#233;chelle bipolaire en 11 points allant de tr&#232;s 
n&#233;gatif (-5) &#224; tr&#232;s positif (+5) (voir Syssau et Font pour une discussion des avantages et inconv&#233;nients de 
ces deux types d'&#233;valuation). Chaque mot a &#233;t&#233; &#233;valu&#233; par 100 juges et un m&#234;me juge n'a effectu&#233; qu'un seul 
des deux types d'&#233;valuation. Les mots ont &#233;t&#233; s&#233;lectionn&#233;s sur la base de deux normes d&#8217;associations 
verbales de mani&#232;re &#224; constituer &quot;un ensemble de mots suffisamment diversifi&#233; pour &#234;tre repr&#233;sentatif de la 
langue fran&#231;aise&quot; (Syssau, Font, 2005). De la premi&#232;re &#233;valuation, Syssau et Font ont d&#233;riv&#233; deux normes 
cat&#233;gorielles : les mots &quot;indubitablement&quot; positifs ou n&#233;gatifs qui ont &#233;t&#233; class&#233;s dans la cat&#233;gorie 
correspondante par au moins 80% des juges (V80) et les mots &quot;majoritairement&quot; positifs ou n&#233;gatifs qui ont 
&#233;t&#233; class&#233;s ainsi par au moins 50% des juges (V50). La seconde &#233;valuation a produit une norme valenc&#233;e 
(Vscore) avec pour chaque entr&#233;e un score compris entre -5 et +5.  
</p>
<p>4.2.2 General Inquirer (version francis&#233;e) : GI 
</p>
<p>Le General Inquirer est un projet n&#233; en 1961 qui visait &#224; d&#233;velopper un programme d'analyse objective de 
contenu (Stone et al., 1966) bas&#233; sur un dictionnaire compos&#233; de 182 cat&#233;gories s&#233;mantiques. Les deux 
derni&#232;res cat&#233;gories ajout&#233;es sont les cat&#233;gories positive et n&#233;gative, qui r&#233;pertorient respectivement 1915 et 
2291 mots. Ces listes n'&#233;tant pas, &#224; notre connaissance, disponibles en fran&#231;ais, nous les avons traduites 
automatiquement &#224; l'aide du traducteur en ligne Systran. Apr&#232;s avoir &#233;t&#233; lemmatis&#233;es avec TreeTagger, ces 
deux listes ont &#233;t&#233; contr&#244;l&#233;es par deux juges. Apr&#232;s suppression des doublons et des mots pr&#233;sents dans les 
deux listes &#8211; probl&#232;mes pr&#233;sents dans la version originale, mais &#233;galement dus &#224; la traduction &#8211; , nous avons 
obtenu 1246 mots positifs et 1527 mots n&#233;gatifs. 
</p>
<p>5 R&#233;sultats 
</p>
<p>Cinq normes ont &#233;t&#233; employ&#233;es pour comparer l'efficacit&#233; des m&#233;thodes de construction automatique de 
lexiques dans l'estimation de la valence de mots : la norme Nev, les trois normes issues du projet Valemo 
(Vscore, V50 et V80) et notre traduction des listes positive et n&#233;gative du General Inquirer (GI). Pour les 
deux normes qui d&#233;finissent la valence comme une variable continue (Nev et Vscore), nous avons &#233;valu&#233; la 
qualit&#233; de la pr&#233;diction en calculant le coefficient de corr&#233;lation de Pearson entre les valences pr&#233;dites par 
les m&#233;thodes automatiques et les valeurs moyennes attribu&#233;es par les juges. Lorsque la variable &#224; pr&#233;dire est 
dichotomique (positif versus n&#233;gatif : V50, V80 et GI), nous avons employ&#233; comme mesure d'efficacit&#233; le 
pourcentage de mots class&#233;s par les proc&#233;dures automatiques dans la cat&#233;gorie d&#233;termin&#233;e par la norme. 
Pour chacune des m&#233;thodes &#233;valu&#233;es, un mot est consid&#233;r&#233; comme n&#233;gatif lorsque sa valence pr&#233;dite est 
inf&#233;rieure &#224; la moyenne et comme positif dans le cas contraire4.  
</p>
<p>La principale difficult&#233; que nous avons rencontr&#233;e lors de ces analyses trouve son origine dans le fait que 
les diff&#233;rentes m&#233;thodes test&#233;es ne donnent pas des valeurs de valence aux m&#234;mes mots : celles d&#233;riv&#233;es de 
Kamps et Marx (2002) en proposent un nombre nettement plus restreint que celles qui s'appuient sur l'ASL. 
Ceci nous a conduits &#224; pr&#233;senter s&#233;par&#233;ment les r&#233;sultats de ces deux groupes de m&#233;thodes. 
</p>
<p>                                                           
3  La norme initiale portait sur 605 mots, mais elle a &#233;t&#233; ult&#233;rieurement &#233;tendue &#224; 735 mots. Elle est 
</p>
<p>disponible &#224; l'adresse : http://www.lexique.org/ 
4  Des analyses compl&#233;mentaires ont montr&#233; que ce seuil &#233;tait proche de la valeur optimale obtenue par 
</p>
<p>r&#233;gression logistique. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CONSTRUCTION AUTOMATIQUE D'UN LEXIQUE DE VALENCE 
 
</p>
<p>5.1 Approche bas&#233;e sur le dictionnaire de synonymes : KA1 et KA7 
</p>
<p>Le tableau 1 pr&#233;sente les performances des m&#233;thodes KA1 et KA7 pour les diff&#233;rentes normes. Pour tous 
les tests, KA7, la version bas&#233;e sur les 7 paires de mots germes de Turney et Litman (2003), est sup&#233;rieure &#224; 
KA1 qui n'emploie qu'une seule de ces paires, celle s&#233;lectionn&#233;e par Kamps et Marx (2004). Les 
corr&#233;lations entre la valence pr&#233;dite par les m&#233;thodes et la valence moyenne selon les juges sont &#233;lev&#233;es et 
m&#234;me tr&#232;s &#233;lev&#233;es pour Vscore. Pour la pr&#233;diction de la cat&#233;gorie des mots, les performances sont 
&#233;galement impressionnantes pour les trois tests. Dans leur &#233;tude sur l'anglais, Kamps et al. (2004) 
rapportent un pourcentage de mots bien class&#233;s par leur proc&#233;dure de 67 % pour les 667 adjectifs pour 
lesquels ils ont pu calculer un score d'&#233;valuation &#224; partir de WordNet et qui se trouvent dans la liste du 
General Inquirer (Evaluation II, Table 1 dans Kamps et al., 2004). Cette valeur est nettement inf&#233;rieure &#224; 
celle que nous avons obtenue. S'il est difficile d'identifier pr&#233;cis&#233;ment l'origine de l'am&#233;lioration, force est 
de constater que l'impl&#233;mentation de la technique de Kamps et Marx sur la base d'un dictionnaire de 
synonymes plut&#244;t que de WordNet est une alternative viable. 
</p>
<p> Nev Vscore V80 V50 GI 
</p>
<p>N 663 76 20 43 688 
</p>
<p>KA1 0.55 0.64 90% 84% 80% 
</p>
<p>KA7 0.61 0.72 100% 88% 84% 
</p>
<p>Tableau 1 : Performances (corr&#233;lation et pourcentage de classification correcte)  
</p>
<p>5.2 Approches bas&#233;es sur l'ASL 
</p>
<p>Dans cette section, nous comparons la nouvelle m&#233;thode ASG &#224; celles de Turney et Littman (2003) et de 
Bestgen (2002). Quatre versions diff&#233;rentes de ASG ont &#233;t&#233; test&#233;es. Elles se distinguent par l'&#233;tendue des 
germes potentiels pris en compte : ASG0.5 limite ceux-ci aux valeurs les plus extr&#234;mes de la norme (de 1 &#224; 
1.5 et de 6.5 &#224; 7), ASG1.0 est moins stricte et prend en compte celles comprises entre 1 et 2 et entre 6 et 7, 
ASGnorme prend en compte l'ensemble des mots repris dans la norme Nev et ASGtout s&#233;lectionne les 
germes parmi l'ensemble des termes pr&#233;sents dans l'espace s&#233;mantique. Pour construire le mod&#232;le pr&#233;dictif 
sur la base de ces ensembles de germes potentiels, nous avons employ&#233; une r&#233;gression lin&#233;aire multiple5 
avec s&#233;lection des pr&#233;dicteurs par la technique ascendante (forward) et un seuil de probabilit&#233; pour la 
s&#233;lection fix&#233; &#224; 0.01. 
</p>
<p>5.2.1 Performances pour le mat&#233;riel d'apprentissage : Nev 
</p>
<p>La premi&#232;re ligne du tableau 2 pr&#233;sente les corr&#233;lations entre les valeurs donn&#233;es dans la norme Nev, qui a 
servi pour l'apprentissage, et les valeurs pr&#233;dites par les diff&#233;rentes m&#233;thodes. Comme on pouvait s'y 
attendre, SO-ASL, la seule des m&#233;thodes qui ne s'appuie pas sur la norme, obtient le moins bon r&#233;sultat. 
Tout aussi attendus sont les b&#233;n&#233;fices apport&#233;s par l'apprentissage supervis&#233; (ASG versus DIC-ASL) et par 
la possibilit&#233; de choisir les germes parmi un nombre plus important de candidats. On note n&#233;anmoins que la 
diff&#233;rence principale se situe entre ASG0.5 et ASG1.0. 
</p>
<p>5.2.2 Performances pour Vscore 
</p>
<p>L'analyse de Vscore, deuxi&#232;me ligne du tableau 2, donne comme attendu, des valeurs inf&#233;rieures &#224; celles 
obtenues pour la norme ayant servi &#224; l'apprentissage, mais la diff&#233;rence est assez faible. On note tout 
particuli&#232;rement que les m&#233;thodes ASG sont nettement plus performantes que SO-ASL, ce qui confirme 
l'hypoth&#232;se que les mots germes employ&#233;s par cette derni&#232;re sont loin d'&#234;tre optimaux.  
                                                           
5  Toutes les analyses ont &#233;galement &#233;t&#233; effectu&#233;es en employant la SVR (SVM appliqu&#233; &#224; la r&#233;gression), 
</p>
<p>mais ils ne sont pas pr&#233;sent&#233;s, car les deux techniques ont produit des r&#233;sultats tr&#232;s similaires. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADJA VINCZE, YVES BESTGEN 
 
</p>
<p>Normes N SO-ASL DIC-ASL ASG0.5 ASG1.0 ASGnorme ASG,tout 
</p>
<p>Nev 2685 0.38 0.60 0.60 0.65 0.66 0.67 
</p>
<p>Vscore 631 0.32 0.60 0.56 0.61 0.61 0.60 
</p>
<p>Tableau 2 : Corr&#233;lation entre les valeurs pr&#233;dites par les m&#233;thodes et les normes  
</p>
<p>5.2.3 Performances pour les cat&#233;gories : V80, V50 et GI 
</p>
<p>Le tableau 3 pr&#233;sente le pourcentage de mots bien class&#233;s pour les diff&#233;rentes normes cat&#233;gorielles. Les 
performances pour V80 et V50 sont tr&#232;s &#233;lev&#233;es, mais il faut prendre en compte le fait que ces deux normes 
ne contiennent qu'un nombre r&#233;duit de mots. Pour l'adaptation fran&#231;aise du General Inquirer, les 
performances sont moins bonnes. Elles d&#233;passent toutefois largement la performance de SO-ASL rapport&#233;e 
par Turney et Littman (2003) pour le General Inquirer en version anglaise (65%), valeur tr&#232;s proche de 
celle que nous avons obtenue pour l'adaptation fran&#231;aise (64%). On observe aussi que DIC-ASL fait 
presque aussi bien que les m&#233;thodes bas&#233;es sur une proc&#233;dure d'apprentissage automatique.  
</p>
<p>Test SO-ASL DIC-ASL ASG0.5 ASG1.0 ASGnorme ASG,tout 
</p>
<p>V80 (N=128) 73% 88% 83% 87% 88% 91% 
</p>
<p>V50 (N=280) 63% 82% 78% 82% 84% 82% 
</p>
<p>GI (N=1992) 64% 71% 70% 72% 73% 72% 
</p>
<p>Tableau 3 : Pourcentage de classification correcte 
</p>
<p>Dans le tableau 3, tous les mots mentionn&#233;s dans les normes sont pris en compte, m&#234;me ceux qui sont 
pr&#233;sents dans la norme Nev qui a servi &#224; l'apprentissage supervis&#233;. Il s'ensuit qu'il est probl&#233;matique de se 
baser sur ces donn&#233;es pour &#233;valuer les capacit&#233;s de g&#233;n&#233;ralisation de la m&#233;thode ASG &#224; des mots qui ne 
font pas partie du mat&#233;riel d'apprentissage. Pour cette raison, les m&#234;mes analyses que celles rapport&#233;es ci-
dessus ont &#233;t&#233; effectu&#233;es apr&#232;s suppression dans les normes cat&#233;gorielles de tous les mots pr&#233;sents dans 
Nev. Les r&#233;sultats sont pr&#233;sent&#233;s dans le tableau 4. Pour GI, on observe une diminution assez faible et 
relativement &#233;gale des performances pour toutes les m&#233;thodes, y compris celles qui n'ont pas recours &#224; 
l'apprentissage supervis&#233;. Pour V50 et surtout V80, les diff&#233;rences sont plus nettes et s'observent m&#234;me 
pour SO-ASL, alors que cette m&#233;thode ne s'appuie pas sur la norme Nev. L'explication la plus probable est 
que les mots qui ont &#233;t&#233; supprim&#233;s sont particuli&#232;rement faciles &#224; classer par toutes les m&#233;thodes.  
</p>
<p>Test SO-ASL DIC-ASL ASG0.5 ASG1.0 ASGnorme ASG,tout 
</p>
<p>V80 (N=25) 60% 80% 68% 72% 72% 76% 
</p>
<p>V50 (N=82) 60% 82% 72% 73% 78% 74% 
</p>
<p>GI (N=1130) 62% 68% 68% 71% 71% 70% 
</p>
<p>Tableau 4 : Pourcentage de classification correcte pour les mots non inclus dans Nev  
</p>
<p>D'une mani&#232;re g&#233;n&#233;rale, ces tests confirment le caract&#232;re non optimal des mots germes employ&#233;s dans 
l'approche SO-ASL, cette m&#233;thode atteignant un niveau de performance nettement inf&#233;rieur &#224; celui atteint 
par toutes celles bas&#233;es sur l'apprentissage supervis&#233; de germes.  </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CONSTRUCTION AUTOMATIQUE D'UN LEXIQUE DE VALENCE 
 
</p>
<p>5.3 Comparaison globale 
</p>
<p>Une derni&#232;re s&#233;rie d'analyses visent &#224; comparer le plus rigoureusement possible les performances de toutes 
les proc&#233;dures test&#233;es, y compris KA1 et KA7, sur une m&#234;me t&#226;che afin de les rendre comparables. On a 
donc calcul&#233; le pourcentage de termes bien class&#233;s pour les mots de GI trait&#233;s par toutes les m&#233;thodes. Le 
tableau 5, qui pr&#233;sente ces r&#233;sultats, souligne la sup&#233;riorit&#233; de KA7 sur toutes les autres m&#233;thodes. Il faut 
toutefois garder &#224; l'esprit que KA7 propose au maximum des valeurs pour 688 mots du GI  alors que les 
m&#233;thodes bas&#233;es sur l'ASL traitent 1992 mots de cette m&#234;me liste. De plus, nous n'avons employ&#233; qu'un 
seul espace s&#233;mantique d'un genre tr&#232;s sp&#233;cifique (voir discussion). Les m&#234;mes analyses ont &#233;t&#233; r&#233;alis&#233;es en 
supprimant, en plus, les mots qui sont dans la norme NEV, sans que les conclusions ne soient modifi&#233;es 
(diff&#233;rences plus petites ou &#233;gales &#224; 2%).  
</p>
<p>N SO-ASL DIC-ASL ASG0.5 ASG1.0 ASGnorme ASGtout KA1 KA7 
</p>
<p>550 64% 70% 75% 75% 76% 75% 80% 83% 
</p>
<p>Tableau 5 : Pourcentage de classification correcte pour les mots de GI trait&#233;s par toutes les m&#233;thodes 
</p>
<p>5.4 Mots germes les plus importants pour pr&#233;dire la valence 
</p>
<p>Si la m&#233;thode ASG n'apparait pas comme nettement sup&#233;rieure &#224; DIC-ASL, elle pr&#233;sente un avantage 
potentiellement tr&#232;s important en termes d'identification de mots germes. Alors que DIC-ASL s&#233;lectionne 
les germes localement puisqu'un ensemble diff&#233;rent de germes est employ&#233; pour chaque mot, ASG 
s&#233;lectionne les germes globalement : un seul et m&#234;me ensemble de germes est employ&#233; pour pr&#233;dire la 
valence de tous les mots. Il reste cependant &#224; montrer que les germes choisis par ASG sont bien pertinents.  
</p>
<p>Une premi&#232;re mani&#232;re de r&#233;pondre &#224; cette question consiste &#224; s'int&#233;resser au mod&#232;le pr&#233;dictif construit par 
la r&#233;gression multiple. Faute de place, il n'est pas possible de reprendre ici tous les mots germes 
s&#233;lectionn&#233;s par les diff&#233;rentes versions de ASG. La liste suivante pr&#233;sente l'ensemble des germes 
s&#233;lectionn&#233;s par ASG1.0, suivant l'ordre dans lequel ils ont &#233;t&#233; introduits dans le mod&#232;le (chaque fois suivi 
par la valence selon la norme Nev) : &#233;pouvantable (1.8), d&#233;licieux (6.2), irriter (1.9), admiration (6.1), 
affectueux (6.2), atroce (1.5), heureux (6.5), monstrueux (1.4), magnifique (6.5), embrasser (6.4), lugubre 
(1.8), r&#234;ver (6.3), libre (6.3), savourer (6.0), ennui (1.7), int&#233;ressant (6.0), indiff&#233;rence (2.0), espoir (6.1), 
pire (1.4), fid&#232;lement (6.1), gaiet&#233; (6.4), rat (1.9), insulte (1.6), maladie (1.5), laideur (1.6), enlacer (6.4), 
enfant (6.3), crasse (1.8), voyage (6.2), malchance (1.6), admirable (6.1).  
</p>
<p>L'analyse qui pr&#233;c&#232;de repose sur le mod&#232;le pr&#233;dictif construit par la r&#233;gression multiple. Celui-ci 
correspond &#224; la meilleure combinaison possible de mots germes pour pr&#233;dire la norme et non aux mots 
germes qui apportent individuellement la contribution la plus importante &#224; la pr&#233;diction de celle-ci. Tout 
particuli&#232;rement, la r&#233;gression multiple ne s&#233;lectionnera qu'un seul de deux mots s&#233;mantiquement tr&#232;s li&#233;s, 
m&#234;me si tous les deux sont d'excellents pr&#233;dicteurs (cf. rage et col&#232;re dans le tableau 6). Or, comme notre 
objectif prioritaire est d'identifier des mots germes sp&#233;cifiques qui pourraient &#234;tre ensuite employ&#233;s dans 
d'autres m&#233;thodes, comme celle de Kamps et Marx (2002), il semble pr&#233;f&#233;rable de s'int&#233;resser &#224; ces derniers 
et donc &#224; ceux dont le vecteur de cosinus (avec les mots pr&#233;sents dans la norme) est le plus corr&#233;l&#233; avec la 
valence de ces mots. Le tableau 6 pr&#233;sente, &#224; titre d'exemple, une petite fraction des germes les plus 
importants pour pr&#233;dire la valence, class&#233;s par ordre d'efficacit&#233;, lorsqu'on prend en compte l'ensemble des 
mots pr&#233;sents dans l'espace s&#233;mantique. La partie gauche reprend les 30 germes les plus corr&#233;l&#233;s 
n&#233;gativement avec la valence et la partie droite les 30 germes les plus corr&#233;l&#233;s positivement. La quasi-
totalit&#233; des germes n&#233;gatifs mentionn&#233;s dans ce tableau correspond &#224; ce qu'on entend habituellement par 
mots germes pour la valence6. La grande majorit&#233; des germes positifs sont aussi pertinents et plus de la 
moiti&#233; d'entre eux ne se trouve pas dans la norme ayant servi &#224; l'apprentissage (signal&#233; par un &quot;-&quot; &#224; la place 
du score de valence). Cette observation souligne la valeur heuristique de la m&#233;thode propos&#233;e. On y trouve 
n&#233;anmoins quelques mots sp&#233;cifiques &#224; la collection de textes employ&#233;e pour l'ASL (mythologique, 
nymphe, pampre). Il est &#224; noter que les germes qui suivent, par ordre d'importance, ceux pr&#233;sent&#233;s dans le 
                                                           
6  Il n'est pas possible, &#224; ce stade de l'analyse, de d&#233;terminer le nombre de cas dans lesquels d&#233;battre 
</p>
<p>correspond &#224; se d&#233;battre. Il s'agit l&#224; d'une limite &#233;vidente des pr&#233;traitements effectu&#233;s avant l'extraction 
de l'espace s&#233;mantique </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADJA VINCZE, YVES BESTGEN 
 
</p>
<p>tableau semblent tout aussi pertinents. &#192; titre d'exemple, on trouve de 10 en 10 pour l'orientation n&#233;gative : 
31. brute, 41. monstrueux, 51. ex&#233;cration, 61. exasp&#233;ration, 71. d&#233;sesp&#233;rer, 81. sourd, 91. &#233;gorgement, 101. 
r&#226;le. 
</p>
<p> N&#233;gatif Nev  N&#233;gatif Nev  Positif Nev  Positif Nev 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
</p>
<p>rage 
col&#232;re 
&#233;pouvantable 
fureur 
atroce 
horrible 
abominable 
&#233;craser 
horreur 
crachat 
exasp&#233;rer 
mis&#233;rable 
&#233;trangler 
affreux 
assassin 
</p>
<p>2.1 
2.2 
1.8 
2.8 
1.5 
1.8 
1.9 
1.9 
2.1 
1.3 
2.4 
1.8 
- 
</p>
<p>1.9 
- 
</p>
<p>16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 
28 
29 
30 
</p>
<p>infamie 
impr&#233;cation 
tourmenteur 
l&#226;che 
mena&#231;ant 
menace 
&#233;pouvanter 
saigner 
cracher 
d&#233;battre 
effrayant 
plainte 
crever 
meurtre 
injurier 
</p>
<p>- 
- 
- 
</p>
<p>1.1 
- 
- 
</p>
<p>2.0 
- 
- 
- 
</p>
<p>2.4 
- 
</p>
<p>1.7 
1.4 
1.9 
</p>
<p>1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
</p>
<p>charmant 
charmer 
ravissant 
d&#233;licieux 
gracieux 
merveille 
magnifique 
brillant 
aimable 
harmoniser 
&#233;l&#233;gant 
riant 
splendide 
mythologique 
composer 
</p>
<p>5.7 
5.8 
6.4 
6.2 
5.9 
6.1 
6.5 
- 
</p>
<p>5.9 
- 
- 
- 
- 
- 
- 
</p>
<p>16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 
28 
29 
30 
</p>
<p>charme 
description 
modeste 
ravir 
admirable 
romance 
nymphe 
exquis 
distingu&#233; 
pampre 
enchanter 
exotique 
raffoler 
modestement 
fra&#238;cheur 
</p>
<p>6.1 
- 
- 
</p>
<p>5.6 
6.1 
4.4 
- 
- 
- 
- 
- 
- 
- 
- 
- 
</p>
<p>Tableau 6 : Mots germes s&#233;lectionn&#233;s par la m&#233;thode ASG 
</p>
<p>6 Conclusion 
</p>
<p>Pour conclure, nous avons transpos&#233; au fran&#231;ais deux m&#233;thodes de construction automatique de lexiques 
porteurs de valences bien &#233;tablies dans le monde anglo-saxon : celles de Turney et Littman (2003) et de 
Kamps et Marx (2002). Cette derni&#232;re montrant des r&#233;sultats encourageants, nous l'avons &#233;tendue en 
augmentant le nombre de paires de mots germes. Cette modification nous a permis d'obtenir les meilleurs 
r&#233;sultats, avec plus de 80 % de termes bien class&#233;s. Ce pourcentage doit cependant &#234;tre relativis&#233; dans la 
mesure o&#249; il est calcul&#233; sur un nombre restreint de mots. Nous avons &#233;galement d&#233;velopp&#233; une m&#233;thode qui 
s&#233;lectionne les mots germes par apprentissage supervis&#233;. Avec une efficacit&#233; d'environ 75 %, elle surpasse 
nettement la m&#233;thode SO-ASL dont elle est d&#233;riv&#233;e. Il est, h&#233;las, impossible de d&#233;terminer si les valeurs 
obtenues refl&#232;tent un niveau de performance proche de celui atteint par des annotateurs parce qu'on ne 
dispose pas d'information &#224; propos du degr&#233; d'accord entre ceux-ci. L'analyse des mots apportant la plus 
grande contribution individuelle &#224; la pr&#233;diction de la valence souligne l'int&#233;r&#234;t de cette m&#233;thode pour 
l'identification de mots germes. Un des principaux d&#233;veloppements envisag&#233;s est d'utiliser ces mots germes 
dans des m&#233;thodes comme celles de Kamps et Marx (2002) ou d'Esuli et Sebastiani (2006). Des adaptations 
seront n&#233;cessaires puisque, dans la version actuelle, les mots germes identifi&#233;s ne forment pas des couples 
comme requis par la m&#233;thode de Kamps et Marx. Il sera tout particuli&#232;rement int&#233;ressant de d&#233;terminer si la 
m&#233;thode propos&#233;e, qui ne requiert pas WordNet, est plus efficace que celle d&#233;velopp&#233;e par Esuli et 
Sebastiani et, surtout, si l'emploi dans leur m&#233;thode des mots germes identifi&#233;s par ASG am&#233;liore encore les 
performances. Enfin, il sera n&#233;cessaire d'&#233;valuer les b&#233;n&#233;fices apport&#233;s par l'apprentissage supervis&#233; de 
germes pour l'objectif principal de ce genre d'&#233;tudes : d&#233;terminer l'orientation de textes (Harb et al., 2008). 
</p>
<p>Cette &#233;tude comporte plusieurs limitations qui sont autant de pistes pour des recherches futures. Tout 
d'abord, un seul espace s&#233;mantique, extrait de textes litt&#233;raires, a &#233;t&#233; exploit&#233;. Les implications de cette 
limitation sont particuli&#232;rement mises en &#233;vidence par la s&#233;lection de mots germes sp&#233;cifiques &#224; ce genre de 
textes. Il serait int&#233;ressant d'effectuer ces analyses sur un corpus plus diversifi&#233; ou, s&#233;par&#233;ment, sur des 
corpus de genres diff&#233;rents. Dans ce dernier cas, il devrait &#234;tre possible d'attribuer aux mots germes un 
indice qui traduit leur degr&#233; de g&#233;n&#233;ralit&#233;. Ensuite, les germes identifi&#233;s par la m&#233;thode ASG consistent en 
des formes (lemmes) isol&#233;es, ce qui r&#233;duit fortement la qualit&#233; linguistique de l'analyse (voir d&#233;battre). La 
prise en compte de mots compos&#233;s ou d'expressions fig&#233;es serait &#233;galement un d&#233;veloppement int&#233;ressant 
(Vernier, Monceaux, 2010). D'autres m&#233;thodes pour mesurer les proximit&#233;s s&#233;mantiques devraient 
&#233;galement &#234;tre test&#233;es. Il est en effet loin d'&#234;tre &#233;vident que le passage par l'ASL am&#233;liore l'efficacit&#233; 
(Bestgen, 2006). Enfin, notre traduction des listes du General Inquirer pourrait sans aucun doute &#234;tre 
am&#233;lior&#233;e afin de r&#233;cup&#233;rer un certain nombre de mots perdus. Cependant, on peut s'interroger sur l'utilit&#233; 
d'un tel travail, &#233;tant donn&#233; le peu d'information disponible sur la proc&#233;dure de construction de ces listes. Il </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CONSTRUCTION AUTOMATIQUE D'UN LEXIQUE DE VALENCE 
 
</p>
<p>nous semble plus int&#233;ressant pour la communaut&#233; scientifique d'&#233;tendre les normes V50 et V80, dont la 
rigueur et les proc&#233;d&#233;s de construction sont bien &#233;tablis. 
</p>
<p>Remerciements 
</p>
<p>Yves Bestgen est chercheur qualifi&#233; du F.R.S-FNRS. Les auteurs remercient vivement A. Syssau pour les 
explications compl&#233;mentaires &#224; propos de la norme Valemo et l&#8217;&#233;quipe du CRISCO pour l'autorisation 
d'extraction des informations incluses dans le dictionnaire de synonymes. 
</p>
<p>R&#233;f&#233;rences 
</p>
<p>ABBSASI, A., CHEN, H., SALEM, A. (2008). Sentiment analysis in multiple languages: Feature selection for 
opinion classification in Web forums. ACM Transactions on Information Systems 26.   
</p>
<p>BESTGEN, Y. (2002). D&#233;termination de la valence affective de termes dans de grands corpus de textes. 
Actes de CIFT'02, 81-94. 
</p>
<p>BESTGEN, Y. (2006). D&#233;terminer automatiquement la valence affective de phrases : Am&#233;lioration de 
l'approche lexicale. Actes des JADT 2006, 179-188. 
</p>
<p>BESTGEN, Y. (2008). Building affective lexicons from specific corpora for automatic sentiment analysis. 
Proceedings of LREC 2008, 496-500. 
</p>
<p>CHARDON, B. (2010). Cat&#233;gorisation automatique d'adjectifs d'opinion &#224; partir d'une ressource linguistique 
g&#233;n&#233;rique, Actes de RECITAL 2010. 
</p>
<p>CHESLEY, P., VINCENT, B., XU, L., SRIHARI, R.K. (2006). Using verbs and adjectives to automatically 
classify blog sentiment. Proceedings of AAAI-CAAW-06, 27-29. 
</p>
<p>DEERWESTER, S., DUMAIS, S.T., FURNAS, G.W., LANDAUER, T.K., HARSHMAN, R. (1990). Indexing by 
Latent Semantic Analysis, Journal of the American Society for Information Science 41, 391-407. 
</p>
<p>DRAGUT, E.C., YU, C., SISTLA, P., MENG, W. (2010). Construction of a sentimental word dictionary. 
Proceedings of ACM ICIKM, 1761-1764. 
</p>
<p>ESULI, A., SEBASTIANI, F. (2006). SENTIWORDNET: A publicly available lexical resource for opinion 
mining. Proceedings of LREC&#8217;06, 417&#8211;422,.   
</p>
<p>HARB, A., PLANTIE, M., ROCHE, M., DRAY, G., TROUSSET, F., PONCELET, P. (2008). D&#233;tection d'opinion. 
Comment d&#233;terminer les adjectifs d'opinion d'un domaine donn&#233;? Document num&#233;rique 11, 37-61. 
</p>
<p>HATZIVASSILOGLOU, V., MCKEOWN, K.R. (1997). Predicting the semantic orientation of adjectives. 
Proceedings of EACL 1997, 174-181. 
</p>
<p>HEISE, D.R. (1965). Semantic differential profiles for 1000 most frequent english words. Psychological 
Monographs 79, 1-31. 
</p>
<p>HOGENRAAD, R., BESTGEN, Y., NYSTEN, J.L. (1995). Terrorist Rhetoric : Texture and Architecture, In 
Nissan et Schmidt (Eds.), From Information to Knowledge,48-59, Intellect 
</p>
<p>HU, M., LIU, B. (2004). Mining Opinion Features in Customer Reviews. Proceedings of AAAI, 755-760. 
</p>
<p>KAMPS, J., MARX, M. (2002). Words with Attitude. Proceedings of the 1st Interational Conference on 
Global WordNet, 332-341. 
</p>
<p>KAMPS, J., MARX, M., MOKKEN, R.J., DE RIJKE, M. (2004). Using WordNet To Measure Semantic 
Orientations Of Adjectives. Proceedings of LREC 2004, 1115-1118. </p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADJA VINCZE, YVES BESTGEN 
 
</p>
<p>KIM, S.M., HOVY, E. (2004). Determining the sentiment of opinions. Proceedings of COLING, 1367-1373. 
</p>
<p>MANQUIN, J.L., FRAN&#199;OIS, J., EUFE, R., FESENMEIER, L., OZOUF, C., SENECHAL, M. (2004). Le 
dictionnaire &#233;lectronique des synonymes du CRISCO : un mode d&#8217;emploi &#224; trois niveaux. Les Cahiers du 
CRISCO 17, 1-64. 
</p>
<p>MILLER, G.A. (1990). WordNet: An on-line lexical database. International Journal of Lexicography 3, 
235&#8211;312.  
</p>
<p>MOUTON, C., CHALENDAR, G. (2010). JAWS : Just AnotherWordNet Subset. Actes de TALN 2010. 
</p>
<p>NASUKAWA, T., YI, J. (2003). Sentiment analysis: capturing favorability using natural language processing. 
Proceedings of the 2nd international conference on Knowledge capture (K-CAP), 70-77. 
</p>
<p>PAK, A., PAROUBEK, P. (2010). Construction d&#8217;un lexique affectif pour le fran&#231;ais &#224; partir de Twitter. Actes 
de TALN 2010. 
</p>
<p>PANG, B., LEE, L., VAITHYANATHAN, S. (2002). Thumbs up? Sentiment classification using machine 
learning techniques. Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language 
Processing, 79-86.  
</p>
<p>SCHMID, H., (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. Proceedings of the 
International Conference on New Methods in Language Processing, 44-49.  
</p>
<p>STONE, P.J., DUNPHY, D.C., SMITH, M.S., OGILVIE, D.M. (1966). The General Inquirer: A Computer 
Approach to Content Analysis. Cambridge : MIT Press. 
</p>
<p>SYSSAU, A., FONT, N. (2005). Evaluations des caract&#233;ristiques &#233;motionnelles d&#8217;un corpus de 604 mots. 
Bulletin de Psychologie 58, 361-367. 
</p>
<p>TURNEY, P.D., (2002). Thumbs up or thumbs down?: semantic orientation applied to unsupervised 
classification of reviews. Proceedings of the 40th Annual ACL Meeting, 417-424. 
</p>
<p>TURNEY, P.D., LITTMAN, M. (2002). Unsupervised learning of semantic orientation from a hundred-billion-
word corpus. Technical Report, National Research Council Canada. 
</p>
<p>TURNEY, P.D., LITTMAN, M. (2003). Measuring Praise and Criticism: Inference of Semantic Orientation 
from Association. ACM Transactions on Information Systems 21, pp. 315--346 
</p>
<p>VELIKOVICH, L., BLAIR-GOLDENSOHN, S., HANNAN, K., MCDONALD, R. (2010). The Viability of Web-
derived Polarity Lexicons. Proceedings of NAACL 2010, 777-785. 
</p>
<p>VERNIER, M., MONCEAUX, L. (2010). Enrichissement d&#8217;un lexique de termes subjectifs &#224; partir de tests 
s&#233;mantiques. Traitement automatique des langues 51, 125-149.  
</p>
<p>VERNIER, M., MONCEAUX, L., DAILLE, B., DUBREIL, E. (2009). Cat&#233;gorisation s&#233;mantico-discursives des 
&#233;valuations exprim&#233;es dans la blogosph&#232;re. Actes de TALN 2009.  
</p>
<p>WIEBE, J., WILSON, T., BRUCE, R., BELL, M., MARTIN, M. (2004). Learning subjective language. 
Computational Linguistics 30, 277-308.  
</p>
<p>WIEBE, J., WILSON, T., CARDIE, C. (2005). Annotating expressions of opinions and emotions in language. 
Language Resources and Evaluation 39, 165-210. 
</p>
<p>WILSON, T., WIEBE, J., HOFFMANN, P. (2005). Recognizing contextual polarity in phrase-level sentiment 
analysis. Proceedings of HLT-EMNLP 2005, 347-354. 
</p>
<p>YU, H., HATZIVASSILOGLOU, V. (2003). Toward answering opinion questions : Separating facts from 
opinions and identifying the polarity of opinion sentences. Proceedings of EMNLP 2003, 129-136. </p>

</div></div>
</body></html>