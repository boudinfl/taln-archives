TALN2011, Monlpellier, 27 juin - 1 er juillet 2011

Identification de mots germes pour la construction d'un lexique de valence
au moyen d'une procédure supervisée

Nadja Vinczel Yves Bestgenz

(1) UCLouvain, Cental, Place Blaise Pascal, 1, B-1348 Louvain-la-Neuve, Belgique
(2) UCLouvain, CECL, B-1348 Louvain-la-Neuve, Belgique
nadja.vincze@uclouvain.be, yves.bestgen@uclouvain.be

Résumé

De nombreuses méthodes automatiques de classification de textes selon les sentiments qui y sont exprimés s'appuient sur
un lexique dans lequel a chaque entrée est associée une valence. Le plus souvent, ce lexique est construit a partir d'un
petit nombre de mots, choisis arbitrairement, qui servent de germes pour déterminer automatiquement la valence d‘autres
mots. La question de l'optimalité de ces mots germes a bien peu retenu l‘attention. Sur la base de la comparaison de cinq
méthodes automatiques de construction de lexiques de valence, dont une qui, a notre connaissance, n‘a jamais été adaptée
au frangais et une autre développée spécifiquement pour la présente ét11de, nous montrons l'importance du choix de ces
mots germes et l‘intérét de les identifier au moyen d'une procédure d'apprentissage supervisée.

Abstract

Many methods of automatic sentiment classification of texts are based on a lexicon in which each entry is associated with
a semantic orientation. These entries serve as seeds for automatically determining the semantic orientation of other
words. Most often, this lexicon is built from a small number of words, chosen arbitrarily. The optimality of these seed
words has received little attention. In this study, we compare five automatic methods to build a semantic orientation
lexicon. One among them, to our knowledge, has never been adapted to French and another was developed specifically
for this study. Based on them, we show that choosing good seed words is very important and identifying them with a
supervised learning procedure brings a benefit.

Mots-clés : Analyse de sentiments, lexique de valence, apprentissage supervise, analyse sémantique latente
Keywords: Sentiment analysis, semantic orientation lexicon, supervised learning, latent semantic analysis

NADJA VINCZE, YVES BESTGEN

1 Introduction

La classification de textes consiste a classer automatiquement les textes dans un ensemble predefini de
categories. Ce sont initialement les classifications thematiques et par genre qui ont motive les recherches,
mais, depuis une dizaine d'annees, ce champ d‘etudes s‘est elargi et integre la classification de textes en
fonction des sentiments qui y sont exprimes : detection de la subjectivite, avec une classification objectif /
subjectif (W iebe et al., 2004 ',Yu, Hatzivassiloglou, 2003) et determination de la valence des documents,
avec une classification binaire positif / negatif, parfois multi-classes selon le degre de polarite (Abbasi et
al., 2008', Pang et al., 2002). La plupart des implementations de ces classifieurs requierent des lexiques
porteurs de valence, c'est-a-dire des lexiques oil a chaque entree est associee une polarite ou un degre de
polarite. Une serie d'approches attribuent une valence globale aux textes selon des statistiques sur la
presence de mots subjectifs (Bestgen, 2006 ; Turney, 2002). Les approches dites symboliques integrent la
prise en compte de phenomenes syntaxiques qui viennent modifier l‘orientation semantique de mots ou de
groupes de mots (Harb et al., 2008 ; Vernier et al., 2009 ; Wilson et al., 2005). Enfin, quelques tentatives
d‘apprentissages supervises ont egalement pris en compte des mots, dont la valence est connue, comme
caracteristiques de leurs vecteurs (Chesley et al., 2006). Ces lexiques constituent donc des ressources
semantiques capitales au developpement de classifieurs efficaces.

Dans un premier temps, ces lexiques ont ete construits manuellement par des juges (Nasukawa, Yi, 2003 ;
Wiebe et al., 2005), mais le travail etant lent et couteux, des procedures automatiques ou semi-automatiques
ont vu le jour et constituent aujourd'hui un sous-domaine de recherche important. Comme le souligne la
presentation des travaux anterieurs (section 2), une specificite des recherches menees dans ce champ est
qu'elles portent presque exclusivement sur l'anglais, langue pour laquelle de nombreuses ressources
linguistiques ont ete developpees comme WordNet (Miller, 1990). Un des deux objectifs principaux de
notre etude est de determiner dans quelle mesure ces methodes sont applicables au frangais. Une autre
specificite des recherches menees dans ce champ est que la quasi-totalite des methodes proposees utilise un
petit nombre de mots, comme bon, mauvais, gentil, afin de servir de germes (seed) pour determiner
automatiquement la valence d‘autres mots (voir par exemple Hu, Liu, 2004', Kamps, Marx, 2002 ; Turney,
Littman, 2003). La question de l'optimalite de ces mots germes a bien peu retenu l‘attention, le plus souvent
les chercheurs reprenant ceux proposes dans des travaux anterie11rs (Esuli, Sebastiani, 2006 ; Harb et al.,
2008). Notre second objectif est de proposer une methode permettant d‘identifier automatiquement ces
germes au moyen d'une technique d'apprentissage supervisee.

Apres une breve presentation des travaux anterieurs, la section 3 decrit les differentes methodes comparees
dans le cadre de cette etude. Une serie d'experiences visant a evaluer leur efficacite sont presentees dans la
section 4. La section 5 rapporte les principaux resultats, dont les implications et les developpements
possibles sont discutes dans la conclusion.

2 Travaux anterieurs

Parmi les methodes automatiques ou semi-automatiques proposees pour construire des lexiques porteurs de
valences, on peut distinguer deux types d'approches : celles basees sur des ressources linguistiques comme
WordNet et celles basees sur des corpus de textes.

Les approches qui s'appuient sur des bases de connaissances linguistiques calculent generalement la
similarite entre les mots a partir de leur relation de synonymie. Une methode de base consiste a partir de
quelques mots dont la valence est connue et a lancer un algorithme d'amor9age (bootstrapping) qui parcourt
les liens synonymiques et antonymiques de la base, en attribuant la meme orientation aux mots synonymes
et vice-versa (Hu, Liu, 2004 ; Kim, Hovy, 2004). Kamps et Marx (2002) ont probablement ete les premiers
a proposer une telle procedure en derivant de WordNet un graphe dans lequel chaque noeud represente un
terme et un lien est present entre deux noeuds s‘ils sont synonymes. A partir de ce graphe, ils calculent une
valeur normalisee pour les noeuds lies aux mots good et bad. Esuli et Sebastiani (2006) ont etendu cette
approche pour developper SentiWordNet, une ressource basee sur WordNet, qui assigne a chaque synset
trois valeurs normalisees : une positive, une negative et une objective. La specificite principale de leur
approche est qu‘elle s‘appuie sur un apprentissage semi-supervise base sur les definitions de mots germes
selectionnes manuellement.

CONSTRUCTION AUTOMATIQUE D'UN LEXIQUE DE VALENCE

nous semble plus intéressant pour la communauté scientifique d'étendre les normes V50 et V80, dont la
rigueur et les procédés de construction sont bien établis.

Remerciements

Yves Bestgen est chercheur qualifié du F.R.S-FNRS. Les auteurs remercient vivement A. Syssau pour les
explications complémentaires a propos de la norme Valemo et l’équipe du CRISCO pour l'autorisation
d‘extraction des informations incluses dans le dictionnaire de synonymes.

Références

ABBSASI, A., CHEN, H., SALEM, A. (2008). Sentiment analysis in multiple languages: Feature selection for
opinion classification in Web forums. ACM Transactions on Information Systems 26.

BESTGEN, Y. (2002). Determination de la valence affective de termes dans de grands corpus de textes.
Actes de CIF T '02, 81-94.

BESTGEN, Y. (2006). Déterminer automatiquement la valence affective de phrases: Amélioration de
l'approche lexicale. Actes des JADT 2006, 179-188.

BESTGEN, Y. (2008). Building affective lexicons from specific corpora for automatic sentiment analysis.
Proceedings of LREC 2008, 496-500.

CHARDON, B. (2010). Categorisation automatique d‘adjectifs d'opinion a partir d‘une ressource linguistique
générique, Actes de RECI T AL 2010.

CHESLEY, P., VINCENT, B., XU,L., SRIHARI, R.K. (2006). Using verbs and adjectives to automatically
classify blog sentiment. Proceedings of AAAI-CAAW-06, 27-29.

DEERWESTER, S., DUMAIS, S.T., FURNAS, G.W., LANDAUER, T.K., HARSHMAN, R. (1990). Indexing by
Latent Semantic Analysis, Journal of the American Society for Information Science 41, 391-407.

DRAGUT, E.C., YU, C., SISTLA, P., MENG, W. (2010). Construction of a sentimental word dictionary.
Proceedings of ACMICIKA/I, 1761-1764.

ESULI, A., SEBASTIANI, F. (2006). SENTIWORDNET: A publicly available lexical resource for opinion
mining. Proceedings of LREC’06, 417-422,.

HARB, A., PLANTIE, M., ROCHE, M., DRAY, G., TROUSSET, F., PONCELET, P. (2008). Detection d'opinion.
Comment déterminer les adj ectif s d'opinion d‘un domaine donné? Document nume’rique 11, 37-61.

HATZIVASSILOGLOU, V., MCKEOWN, K.R. (1997). Predicting the semantic orientation of adjectives.
Proceedings of EACL 1997, 174-181.

HEISE, D.R. (1965). Semantic differential profiles for 1000 most frequent english words. Psychological
Monographs 79, 1-31.

HOGENRAAD, R., BESTGEN, Y., NYSTEN, J.L. (1995). Terrorist Rhetoric : Texture and Architecture, In
Nissan et Schmidt (Eds.), From Information to Knowledge,48-59, Intellect

HU, M., LIU, B. (2004). Mining Opinion Features in Customer Reviews. Proceedings of AAAI, 755-760.

KAMPS, J., MARX, M. (2002). Words with Attitude. Proceedings of the 1st Interational Conference on
Global WordNet, 332-341.

KAMPS, J., MARX, M., MOKKEN, R.J., DE RUKE, M. (2004). Using WordNet To Measure Semantic
Orientations Of Adjectives. Proceedings of LREC 2004, 1115-1118.

NADJA VINCZE, YVES BESTGEN

KIM, S.M., HOVY, E. (2004). Determining the sentiment of opinions. Proceedings of COLING, 1367-1373.

MANQUIN, J.L., FRANCOIS, J., EUFE, R., FESENMEIER, L., OZOUF, C., SENECHAL, M. (2004). Le
dictionnaire électronique des synonymes du CRISCO : un mode d’emploi a trois niveaux. Les Cahiers du
CRISCO 17, 1-64.

MILLER, G.A. (1990). WordNet: An on-line lexical database. International Journal of Lexicography 3,
235-312.

MOUTON, C., CHALENDAR, G. (2010). JAWS : Just AnotherWordNet Subset. Actes de TALN 2010.

NASUKAWA, T., YI, J. (2003). Sentiment analysis: capturing favorability using natural language processing.
Proceedings of the 2nd international conference on Knowledge capture (K-CAP), 70-77.

PAK, A., PAROUBEK, P. (2010). Construction d’un lexique affectif pour le francais a partir de Twitter. Actes
de T ALN 2010.

PANG, B., LEE, L., VAITHYANATHAN, S. (2002). Thumbs up? Sentiment classification using machine
learning techniques. Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language
Processing, 79-86.

SCHMID,H., (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. Proceedings of the
International Conference on New Methods in Language Processing, 44-49.

STONE, P.J., DUNPHY, D.C., SMITH, M.S., OGILVIE, D.M. (1966). The General Inquirer: A Computer
Approach to Content Analysis. Cambridge : MIT Press.

SYSSAU, A., FONT, N. (2005). Evaluations des caractéristiques émotionnelles d’un corpus de 604 mots.
Bulletin de Psychologie 58, 361-367.

TURNEY,P.D., (2002). Thumbs up or thumbs down?: semantic orientation applied to unsupervised
classification of reviews. Proceedings of the 40th Annual ACL Meeting, 417-424.

TURNEY, P.D., LITTMAN, M. (2002). Unsupervised learning of semantic orientation from a hundred-billion-
word corpus. Technical Report, National Research Council Canada.

TURNEY, P.D., LITTMAN, M. (2003). Measuring Praise and Criticism: Inference of Semantic Orientation
from Association. ACM Transactions on Information Systems 21, pp. 315--346

VELIKOVICH, L., BLAIR-GOLDENSOHN, S., HANNAN,K., MCDONALD, R. (2010). The Viability of Web-
derived Polarity Lexicons. Proceedings of NAACL 2010, 777-785.

VERNIER, M., MONCEAUX, L. (2010). Enrichissement d’un lexique de termes subjectifs a partir de tests
sémantiques. T raitement automatique des langues 51, 125-149.

VERNIER, M., MONCEAUX, L., DAILLE, B., DUBREIL, E. (2009). Categorisation sémantico-discursives des
évaluations exprimées dans la blogosphere. Actes de T ALN 2009.

WIEBE, J., WILSON, T., BRUCE, R., BELL, M., MARTIN, M. (2004). Learning subjective language.
Computational Linguistics 30, 277-308.

WIEBE, J., WILSON, T., CARDIE, C. (2005). Annotating expressions of opinions and emotions in language.
Language Resources and Evaluation 39, 165-210.

WILSON, T., WIEBE, J., HOFFMANN, P. (2005). Recognizing contextual polarity in phrase-level sentiment
analysis. Proceedings of HLT-EA/HVLP 2005, 347-354.

YU, H., HATZIVASSILOGLOU, V. (2003). Toward answering opinion questions : Separating facts from
opinions and identifying the polarity of opinion sentences. Proceedings of EMNLP 2003, 129-136.

CONSTRUCTION AUTOMATIQUE D'UN LEXIQUE DE VALENCE

Ne disposant pas d‘informations sur les liens synonymiques, les approches qui s'appuient sur des corpus
calculent les similarites differemment. Hatzivassiloglou et McKeown (1997) ont propose un algorithme
capable de determiner l’orientation semantique d’adjectifs a partir de l‘analyse de leurs cooccurrences avec
des conjonctions. Turney et Littman (2003; Turney, 2002) et Bestgen (2002, 2008) ont propose des
methodes plus generales puisqu’elles permettent d’estimer la valence de n’importe quel terme present dans
un corpus. Ils utilisent l‘analyse semantique latente (ASL, Latent Semantic Analysis, Deerwester et al.,
1990) pour construire un espace semantique a partir d‘informations statistiques sur les cooccurrences de
termes dans des textes. Turney et Littman l‘emploient pour estimer la distance semantique e11tre des mots et
14 mots germes, 7 positifs (good, nice, excellent, positive, fortunate, correct, superior) et 7 negatifs (bad,
nasty, poor, negative, unfortunate, wrong, inferior). Un mot est d'autant plus positif qu‘il est plus proche des
germes positifs et plus eloigne des germes negatifs. Pour sa part, Bestgen (2002) a recours a l'ASL pour
identifier les mots frequemment associes aux mots dont il veut determiner la valence affective. Il attribue a
chaque mot la valence moyenne de ses plus proches voisins dont la valence est connue. Pour cela, il
s‘appuie sur un dictionnaire de 3000 mots dont la valence a ete evaluee par des juges. On notera que les
similarites peuvent etre calculees sans passer par l‘analyse semantique latente, mais que, dans ce cas, des
corpus de tres grande taille semblent necessaires (Turney, Littman, 2003', Velikovich et al., 2010), sauf si, a
la maniere de Harb et al. (2008), on emploie un corpus tres specifique et des regles d‘associations.

Peu d‘initiatives de construction automatique de lexiques ont eu lieu en francais, compare a l'effervescence
dans le milieu anglophone. Nous pouvons citer Bestgen (2002) et Chardon (2010) qui a developpe une
methode pour élaborer une ressource lexicale d'adjectifs d'opinion a partir d'une liste de mots germes et
d'une taxinomie des mots du francais. Pak et Paroubek (2010) ont propose une methode de construction
automatique d‘un lexique affectif a partir de messages disponibles sur Twitter. Le11r procedure est basee s11r la
comparaison de la frequence d‘occurrence d‘un mot dans les messages contenant une emotic6ne positive et
dans ceux contenant une emotic6ne negative. Vernier et Monceaux (2010) ont propose une methode
d‘apprentissage pour enrichir automatiquement un lexique subjectif a partir d‘un corpus annote.
L'apprentissage automatique se base sur des tests semantiques, qui permettent de mesurer le degre de
subjectivite des termes, ainsi que leur valence s‘il s'agit d'adjectifs, et qui sont effectues a l‘aide du moteur
de recherche Yahoo!.

3 Méthodes évaluées pour estimer la valence de mots

Cinq methodes pour estimer automatiquement la valence de mots ont ete comparees, deux de celles-ci
consistant en une transposition de methodes efficaces pour la langue anglaise : celle de Turney et Littman
(2002, 2003) et celle de Kamps et Marx (2002; Kamps et al., 2004). Nous avons egalement repris la
methode de Bestgen (2002, 2008). Ces trois methodes serviront de reference pour evaluer deux nouvelles
approches : une extension de la methode de Kamps et Marx et une methode d‘apprentissage supervise de
mots germes. La presente section decrit les principes a la base de ces differentes methodes. Des precisions a
propos de leur implementation et des ressources linguistiques qu'elles requierent sont donnees dans la
section suivante.

3.1 Niveaux de base : SO-ASL et DIC-ASL

Ces deux methodes se basent sur l‘analyse semantique latente d'une collection de textes pour determiner la
proximite e11tre des mots et des germes dont la valence est connue.

0 SO-ASL : il s’agit de la methode proposee par Turney et Littman (2003) decrite ci-dessus. Elle
est basee sur 14 mots germes choisis en raison de leur valence extreme sur la dimension positif-
negatif. La valence d’un mot correspond a la somme des cosinus e11tre ce mot et les germes
positifs dont on soustrait la somme des cosinus e11tre ce mot et les germes negatifs.

0 DIC-ASL: il s’agit de la methode proposee par Bestgen (2002) decrite ci-dessus. Pour chaque
mot dont on veut determiner la valence, on identifie les 30 plus proches voisins dont la valence
est connue et on lui affecte la valence moyenne de ceux-ci.

NADJA VINCZE, YVES BESTGEN

3.2 Estimation sur la base de relations de synonymie : KA1 et KA7

Ces deux méthodes sont basées sur la fonction d'évaluation définie par Kamps et Marx (2002).

0 KA1 : cette méthode est basée sur les liens synonymiques entre les adjectifs. Le principe consiste
5. mesurer la distance minimale, c'est-a-dire le plus court chemin, entre le mot auquel on veut
attribuer une valeur et les mots germes good et bad. La valence d‘un terme t est alors égale 5. sa
distance relative avec les deux germes :

d(t, mauvais) — d(t, ban)

HA 1“) Z d (ban, mauvais)

ou d (i, j) représente la distance du plus court chemin synonymique entre les mots i et j.

0 KA7 est une adaptation de KA1 dans laquelle le nombre de paires d‘adjectifs de référence est
multiplié par 7. Nous avons repris les 7 paires de référence de Turney et Littman (2003), que
nous avons traduites comme suit: ban, gentil, excellent, positif, heureux, correct, supe’rieur et
mauvais, me’chant, mediocre, négatif, malheureux, faux, infe’rieur. La fonction d‘évaluation
adaptée reprend alors la somme des évaluations pour chaque paire :

23:1 510» in) ‘ 23:1 d(trjk)
3:1 dlixuik)

ou ik etjk forment une paire d’adjectifs positif et négatif des 11 paires prises en compte.

KA7(t) =

3.3 Apprentissage supervisé de mots germes : ASG

U11 des objectifs de cette recherche est de proposer et d‘évaluer une méthode dérivée de celles de Turney et
Littman (2003) et de Bestgen (2002) dans laquelle les mots germes originaux, sélectionnés arbitrairement,
sont remplacés par des germes optimaux obtenus par une procédure d'apprentissage supervisée basée sur la
régression. Pour ce faire, nous employons comme matériel d'apprentissage une norme lexicale pour la
dimension évaluative obtenue en demandant 5. des juges d'évaluer un grand nombre de mots sur cette
dimension. A la suite de Heise (1965), une série de normes de ce type ont été développées, principalement
en psycholinguistique (Syssau, Font, 2005). La méthode proposée est composée des quatre étapes
suivantes :

1. Sélectionner comme germes potentiels les mots qui sont les plus extrémes sur la dimension
positif-négatif selon une norme évaluative comme celle employée dans DIC-ASL.

2. Sur la base d‘un espace sémantique obtenu par l'ASL d'une collection de textes, calculer le
cosinus entre chacun de ces germes potentiels et tous les mots qui se trouvent dans la norme.

3. Utiliser une procédure de régression afin de construire un modele prédictif basé sur les germes
les plus efficaces pour prédire la valence.

4. Employer le modele construit 5. l‘étape précédente pour estimer la valence de termes présents
dans l'espace sémantique, mais non dans la norme initiale.

Le critere de sélection des germes potentiels proposé 5. la premiere étape devrait permettre l‘identification de
mots germes similaires 5. ceux originellement choisis par Turney et Littman (2003). Toutefois, lorsqu‘on
considere le fait que le seuil pour sélectionner les mots les plus extrémes est par définition arbitraire, il
devient immédiatement évident que la procédure proposée n'est qu'un cas particulier d'une procédure plus
générale dans laquelle les germes potentiels sont composés de l'ensemble des mots présents dans la norme.
Et, d'une maniere tout aussi évidente, cette premiere généralisation n'est, elle-méme, qu'un cas particulier
d'une seconde généralisation, qui emploie comme germes potentiels tous les mots pour lesquels il est
possible de calculer un cosinus avec les mots qui se trouvent dans la norme, soit tous les mots présents dans
l'espace sémantique, que leur valence soit connue ou non. Etant donné que les candidats germes pour
l'approche la plus restrictive forment un sous-ensemble des candidats germes employés dans les approches
plus générales, on doit s'attendre 5. ce que la qualité de la prédiction de la valence des mots du dictionnaire

CONSTRUCTION AUTOMATIQUE D'UN LEXIQUE DE VALENCE

initial soit d'autant meilleure que l'approche est la plus generale. Par contre, les capacites de generalisation
des differents modeles pourraient etre equivalentes si ceux bases sur le plus grand nombre de germes
potentiels presentent un def aut de surapprentissage.

4 Experiences

4.1 Ressources linguistiques pour l'implementation des methodes

Les differentes methodes proposees ci-dessus necessitent des ressources linguistiques specifiques comme
un dictionnaire de synonymes ou une collection de textes pour extraire l'espace semantique. Les ressources
que nous avons employees sont decrites dans la presente section.

4.1.1 Dictionnaire de synonymes

L‘adaptation de la methode de Kamps et Marx (2002) au francais necessite une ressource plus ou moins
equivalente au WordNet anglais. En raison de la trop faible couverture de WOLF (W ordNet Libre du
Francais) et du WordNet francais developpe dans le cadre du projet EuroWordNet1, nous avons employe le
dictionnaire de synonymes developpe par le laboratoire CRISCO de l'universite de Caen (Manquin et al.,
2004)2. Celui-ci a ete constitue a partir de sept dictionnaires francais et comprend plus de 49 000 entrees et
396 000 relations synonymiques. De maniere similaire a Kamps et Marx (2002), nous avons recupere
recursivement tous les mots lies a la paire d'adjectifs ban et mauvais, avec des restrictions sur la categorie
grammaticale pour eviter de generer trop de bruit. Une petite adaptation a dﬁ etre faite pour rendre la liste
des synonymes recuperes symetrique (Kamps et al., 2004 : 1115).

4.1.2 Norme de valence : Nev

La norme de valence employee pour les methodes DIC-ASL et ASG est composee de 3252 mots evalues
sur une echelle a 7 points allant de tres de’sagre’able (1) a tres agreable (7) par un minimum de 30 juges
(Hogenraad et al., 1995). A titre d'exemple, la liste suivante donne les valeurs attribuees a quelques mots
extraits aleatoirement de ce dictionnaire : detresse = 1.4, impassible = 2.6, ambigu = 3.2, outil = 4.3, revenir
= 5.0, admiratif = 5.7, doux = 6.0.

4.1.3 Constitution de l'espace sémantique

L‘espace semantique, utilise pour calculer les cosinus e11tre les mots necessaires pour SO-ASL, DIC-ASL et
ASG, a ete construit sur la base d‘une collection de textes litteraires composee de romans, nouvelles et
contes disponibles sur le Web (principalement dans les bases litteraires ABU et Frantext). Elle contient
approximativement 5 300 000 mots. Chaque texte a ete subdivise en segments de 125 mots. Pour construire
le tableau lexical, les pretraitements suivants ont ete effectues : lemmatisation par le logiciel TreeTagger
(Schmid, 1994), suppression de mots outils et suppression des mots de frequence totale inferieure a 10. La
matrice de cooccurrences des 12 285 termes dans les 40 635 segments a ete soumise a une decomposition
en valeurs singulieres et les 300 premiers vecteurs propres ont ete conserves.

4.2 Methode pour l'evaluation

Pour evaluer l‘efficacite de methodes visant a determiner automatiquement la valence de mots, le test
classique, lorsque l‘etude est realisee en anglais, se base sur les listes de mots positifs et negatifs incluses
dans le General Inquirer (p.e., Dragut et al., 2010 ; Kamps et al., 2004 ; Turney, Littman, 2003). Ces listes
n‘etant pas, a notre connaissance, disponibles en francais, nous avons recherche un materiel equivalent dans

1 Le WOLF couvre 30 % du WordNet de Princeton (Mouton & Chalendar, 2010) et, selon nos calculs, le
WordNet francais couvre environ 25 % des synsets de la version 1.5 de WordNet.

2 www.crisco.unicaen.fr/cgi-bin/cherches.cgi

NADJA VINCZE, YVES BESTGEN

cette langue. La section 4.2.1 decrit les normes de valence de Syssau et Font (2005). Ces normes presentent
l'avantage d'avoir ete recoltees dans des conditions rigoureuses et bien documentees, alors qu'on ne dispose
de pratiquement aucune information sur la procedure suivie pour constituer les deux listes du General
Inquirer. Cependant, elles ne portent que sur 735 mots alors que les listes originales du General Inquirer en
contiennent plusieurs milliers. A titre comparatif, nous avons realise une premiere adaptation francaise des
listes du General Inquirer.

4.2.1 Valemo : V80, V50 et Vscore

Syssau et Font (2005) ont demande a 600 juges d'evaluer 735 mots3 sur deux echelles: une echelle
nominale a trois modalites (negatif, neutre et positif) et une echelle bipolaire en 11 points allant de tres
negatif (-5) a tres positif (+5) (voir Syssau et Font pour une discussion des avantages et inconvenients de
ces deux types d'evaluation). Chaque mot a ete evalue par 100 juges et un meme juge n‘a effectue qu'un seul
des deux types d'evaluation. Les mots ont ete selectionnes sur la base de deux normes d’associations
verbales de maniere a constituer "un ensemble de mots suffisamment diversifie pour etre representatif de la
langue francaise" (Syssau, Font, 2005). De la premiere evaluation, Syssau et Font ont derive deux normes
categorielles : les mots "indubitablement" positifs ou négaﬁfs qui ont été classes dans la categorie
correspondante par au moins 80% des juges (V80) et les mots "majoritairement" positifs ou négatifs qui ont
été classes ainsi par au moins 50% des juges (V50). La seconde evaluation a produit une norme valencee
(Vscore) avec pour chaque entree un score compris e11tre -5 et +5.

4.2.2 General Inquirer (version francisée) : GI

Le General Inquirer est un projet ne en 1961 qui visait a developper un programme d'analyse objective de
contenu (Stone et al., 1966) base sur un dictionnaire compose de 182 categories semantiques. Les deux
dernieres categories ajoutees sont les categories positive et negative, qui repertorient respectivement 1915 et
2291 mots. Ces listes n'etant pas, a notre connaissance, disponibles en francais, nous les avons traduites
automatiquement a l‘aide du traducteur en ligne Systran. Apres avoir ete lemmatisees avec TreeTagger, ces
deux listes ont ete contr6lees par deux juges. Apres suppression des doublons et des mots presents dans les
deux listes — problemes presents dans la version originale, mais egalement dus a la traduction — , nous avons
obtenu 1246 mots positifs et 1527 mots negatifs.

5 Résultats

Cinq normes ont ete employees pour comparer l'efficacite des methodes de construction automatique de
lexiques dans l‘estimation de la valence de mots : la norme Nev, les trois normes issues du projet Valemo
(Vscore, V50 et V80) et notre traduction des listes positive et negative du General Inquirer (GI). Pour les
deux normes qui definissent la valence comme une variable continue (Nev et Vscore), nous avons evalue la
qualite de la prediction en calculant le coefficient de correlation de Pearson e11tre les valences prédites par
les methodes automatiques et les valeurs moyennes attribuées par les juges. Lorsque la variable a predire est
dichotomique (positif versus negatif : V50, V80 et GI), nous avons employe comme mesure d'efficacite le
pourcentage de mots classes par les procedures automatiques dans la categorie determinee par la norme.
Pour chacune des methodes evaluees, un mot est considere comme negatif lorsque sa valence predite est
inferieure a la moyenne et comme positif dans le cas contraire4.

La principale difficulte que nous avons rencontree lors de ces analyses trouve son origine dans le fait que
les differentes methodes testees ne donnent pas des valeurs de valence aux memes mots : celles derivees de
Kamps et Marx (2002) en proposent un nombre nettement plus restreint que celles qui s'appuient sur l‘ASL.
Ceci nous a conduits a presenter separement les resultats de ces deux groupes de methodes.

3 La norme initiale portait sur 605 mots, mais elle a ete ulterieurement etendue a 735 mots. Elle est

disponible a l‘adresse : http://www.lexique.org/

4 Des analyses complementaires ont montre que ce seuil etait proche de la valeur optimale obtenue par

regression logistique.

CONSTRUCTION AUTOMATIQUE D'UN LEXIQUE DE VALENCE

5.1 Approche basee sur le dictionnaire de synonymes : KA1 et KA7

Le tableau 1 presente les performances des methodes KA1 et KA7 pour les differentes normes. Pour tous
les tests, KA7, la version basee sur les 7 paires de mots germes de Turney et Litman (2003), est superieure a
KA1 qui n'emploie qu‘une seule de ces paires, celle selectionnee par Kamps et Marx (2004). Les
correlations e11tre la valence predite par les methodes et la valence moyenne selon les juges sont elevees et
meme tres elevees pour Vscore. Pour la prediction de la categorie des mots, les performances sont
egalement impressionnantes pour les trois tests. Dans leur etude sur l'anglais, Kamps et al. (2004)
rapportent un pourcentage de mots bien classes par leur procedure de 67 % pour les 667 adjectifs pour
lesquels ils ont pu calculer un score d'evaluation a partir de WordNet et qui se trouvent dans la liste du
General Inquirer (Evaluation II, Table 1 dans Kamps et al., 2004). Cette valeur est nettement inferieure a
celle que nous avons obtenue. S‘il est difficile d‘identifier precisement l‘origine de l‘amelioration, force est
de constater que l‘implementation de la technique de Kamps et Marx sur la base d‘un dictionnaire de
synonymes plut6t que de WordNet est une alternative viable.

Nev Vscore V80 V50 GI
N 663 76 20 43 688
KA1 0.55 0.64 90% 84% 80%
KA7 0.61 0.72 100% 88% 84%

Tableau 1 : Performances (correlation et pourcentage de classification correcte)

5.2 Approches basees sur l'ASL

Dans cette section, nous comparons la nouvelle methode ASG a celles de Turney et Littman (2003) et de
Bestgen (2002). Quatre versions differentes de ASG ont ete testees. Elles se distinguent par l‘etendue des
germes potentiels pris en compte : ASGO.5 limite ceux-ci aux valeurs les plus extremes de la norme (de 1 a
1.5 et de 6.5 a 7), ASG1.0 est moins stricte et prend en compte celles comprises e11tre 1 et 2 et e11tre 6 et 7,
ASGnorme prend en compte l‘ensemble des mots repris dans la norme Nev et ASGtout selectionne les
germes parmi l‘ensemble des termes presents dans l‘espace semantique. Pour construire le modele predictif
sur la base de ces ensembles de germes potentiels, nous avons employe une regression lineaire multiples
avec selection des predicteurs par la technique ascendante (forward) et un seuil de probabilite pour la
selection fixe a 0.01.

5.2.1 Performances pour le materiel d'apprentissage : Nev

La premiere ligne du tableau 2 presente les correlations e11tre les valeurs donnees dans la norme Nev, qui a
servi pour l‘apprentissage, et les valeurs predites par les differentes methodes. Comme on pouvait s‘y
attendre, SO-ASL, la seule des methodes qui ne s'appuie pas sur la norme, obtient le moins bon resultat.
Tout aussi attendus sont les benefices apportes par l'apprentissage supervise (ASG versus DIC-ASL) et par
la possibilite de choisir les germes parmi un nombre plus important de candidats. On note neanmoins que la
difference principale se situe e11tre ASGO.5 et ASG1.0.

5.2.2 Performances pour Vscore

L‘analyse de Vscore, deuxieme ligne du tableau 2, donne comme attendu, des valeurs inferieures a celles
obtenues pour la norme ayant servi a l‘apprentissage, mais la difference est assez faible. On note tout
particulierement que les methodes ASG sont nettement plus performantes que SO-ASL, ce qui confirme
l'hypothese que les mots germes employes par cette derniere sont loin d‘etre optimaux.

5 Toutes les analyses ont egalement ete effectuees en employant la SVR (SVM applique a la regression),

mais ils ne sont pas presentes, car les deux techniques ont produit des resultats tres similaires.

NADJA VINCZE, YVES BESTGEN

Normes N SO-ASL DIC-ASL ASGO.5 ASG1.0 ASGnorme ASG,tout

Nev 2685 0.38 0.60 0.60 0.65 0.66 0.67

Vscore 631 0.32 0.60 0.56 0.61 0.61 0.60

Tableau 2 : Correlation er1tre les valeurs predites par les methodes et les normes

5.2.3 Performances pour les categories : V80, V50 et GI

Le tableau 3 presente le pourcentage de mots bien classes pour les differentes normes categorielles. Les
performances pour V80 et V50 sont tres elevees, mais il faut prendre en compte le fait que ces deux normes
ne contiennent qu‘un nombre reduit de mots. Pour l‘adaptation francaise du General Inquirer, les
performances sont moins bonnes. Elles depassent toutefois largement la performance de SO-ASL rapportee
par Turney et Littman (2003) pour le General Inquirer en version anglaise (65%), valeur tres proche de
celle que nous avons obtenue pour l‘adaptation frangaise (64%). On observe aussi que DIC-ASL fait
presque aussi bien que les methodes basees sur une procedure d'apprentissage automatique.

Test SO-ASL DIC-ASL ASGO.5 ASG1.0 ASGnorme ASG,tout

V80 (N=128) 73% 88% 83% 87% 88% 91%
V50 (N=280) 63% 82% 78% 82% 84% 82%
G1 (N=1992) 64% 71% 70% 72% 73% 72%

Tableau 3 : Pourcentage de classification correcte

Dans le tableau 3, tous les mots mentionnes dans les normes sont pris en compte, meme ceux qui sont
presents dans la norme Nev qui a servi a l'apprentissage supervise. Il s'ensuit qu‘il est problematique de se
baser sur ces donnees pour evaluer les capacites de generalisation de la methode ASG a des mots qui ne
font pas partie du materiel d'apprentissage. Pour cette raison, les memes analyses que celles rapportees ci-
dessus ont ete effectuees apres suppression dans les normes categorielles de tous les mots presents dans
Nev. Les resultats sont presentes dans le tableau 4. Pour GI, on observe une diminution assez faible et
relativement egale des performances pour toutes les methodes, y compris celles qui n'ont pas recours a
l'apprentissage supervise. Pour V50 et surtout V80, les differences sont plus nettes et s‘observent meme
pour SO-ASL, alors que cette methode ne s'appuie pas sur la norme Nev. L'explication la plus probable est
que les mots qui ont ete supprimes sont particulierement faciles a classer par toutes les methodes.

Test SO-ASL DIC-ASL ASGO.5 ASG1.0 ASGnorme ASG,tout

V80 (N=25) 60% 80% 68% 72% 72% 76%
V50 (N=82) 60% 82% 72% 73 % 78% 74%
G1 (N=1130) 62% 68% 68% 71% 71% 70%

Tableau 4 : Pourcentage de classification correcte pour les mots non inclus dans Nev

D‘une maniere generale, ces tests confirment le caractere non optimal des mots germes employes dans
l'approche SO-ASL, cette methode atteignant un niveau de performance nettement inferieur a celui atteint
par toutes celles basees sur l'apprentissage supervise de germes.

CONSTRUCTION AUTOMATIQUE D'UN LEXIQUE DE VALENCE

5.3 Comparaison globale

Une derniere serie d‘analyses visent a comparer le plus rigoureusement possible les performances de toutes
les procedures testees, y compris KA1 et KA7, sur une meme tache afin de les rendre comparables. On a
donc calcule le pourcentage de termes bien classes pour les mots de GI traites par toutes les methodes. Le
tableau 5, qui presente ces resultats, souligne la superiorite de KA7 sur toutes les autres methodes. Il faut
toutefois garder a l‘esprit que KA7 propose au maximum des valeurs pour 688 mots du GI alors que les
methodes basees sur l'ASL traitent 1992 mots de cette meme liste. De plus, nous n‘avons employe qu'un
seul espace semantique d‘un genre tres specifique (voir discussion). Les memes analyses ont ete realisees en
supprimant, en plus, les mots qui sont dans la norme NEV, sans que les conclusions ne soient modifiees
(differences plus petites ou egales a 2%).

N SO-ASL DIC-ASL ASGO.5 ASG1.0 ASGnorme ASGtout KA1 KA7

550 64% 70% 75% 75% 76% 75% 80% 83%

Tableau 5 : Pourcentage de classification correcte pour les mots de GI traites par toutes les methodes

5.4 Mots germes les plus importants pour predire la valence

Si la methode ASG n'apparait pas comme nettement superieure a DIC-ASL, elle presente un avantage
potentiellement tres important en termes d'identification de mots germes. Alors que DIC-ASL selectionne
les germes localement puisqu'un ensemble different de germes est employe pour chaque mot, ASG
selectionne les germes globalement: un seul et meme ensemble de germes est employe pour predire la
valence de tous les mots. Il reste cependant a montrer que les germes choisis par ASG sont bien pertinents.

Une premiere maniere de repondre a cette question consiste a s‘interesser au modele predictif construit par
la regression multiple. Faute de place, il n‘est pas possible de reprendre ici tous les mots germes
selectionnes par les differentes versions de ASG. La liste suivante presente l'ensemble des germes
selectionnes par ASG1.0, suivant l'ordre dans lequel ils ont ete introduits dans le modele (chaque fois suivi
par la valence selon la norme Nev): épouvantable (1.8), délicieux (6.2), irriter (1.9), admiration (6.1),
aﬂectueux (6.2), atroce (1.5), heureux (6.5), monstrueux (1.4), magnifique (6.5), embrasser (6.4), lugubre
(1.8), réver (6.3), libre (6.3), savourer (6.0), ennui (1.7), intéressant (6.0), indifference (2.0), espoir (6.1),
pire (1.4),fide‘lement (6.1), gaieté (6.4), rat (1.9), insulte (1.6), maladie (1.5), laideur (1.6), enlacer (6.4),
enfant (6.3), crasse (1.8), voyage (6.2), malchance (1.6), admirable (6.1).

L‘analyse qui precede repose sur le modele predictif construit par la regression multiple. Celui-ci
correspond a la meilleure combinaison possible de mots germes pour predire la norme et non aux mots
germes qui apportent individuellement la contribution la plus importante a la prediction de celle-ci. Tout
particulierement, la regression multiple ne selectionnera qu'un seul de deux mots semantiquement tres lies,
meme si tous les deux sont d'excellents predicteurs (cf. rage et colére dans le tableau 6). Or, comme notre
objectif prioritaire est d‘identifier des mots germes specifiques qui pourraient etre ensuite employes dans
d'autres methodes, comme celle de Kamps et Marx (2002), i1 semble preferable de s‘interesser a ces demiers
et donc a ceux dont le vecteur de cosinus (avec les mots presents dans la norme) est le plus correle avec la
valence de ces mots. Le tableau 6 presente, a titre d'exemple, une petite fraction des germes les plus
importants pour predire la valence, classes par ordre d'efficacite, lorsqu‘on prend en compte l'ensemble des
mots presents dans l‘espace semantique. La partie gauche reprend les 30 germes les plus correles
negativement avec la valence et la partie droite les 30 germes les plus correles positivement. La quasi-
totalite des germes negatifs mentionnes dans ce tableau correspond a ce qu'on entend habit11ellement par
mots germes pour la valenceé. La grande majorite des germes positifs sont aussi pertinents et plus de la
moitie d'entre eux ne se trouve pas dans la norme ayant servi a l'apprentissage (signale par un "-" a la place
du score de valence). Cette observation souligne la valeur heuristique de la methode proposee. On y trouve
neanmoins quelques mots specifiques a la collection de textes employee pour l'ASL (mythologique,
nymphe, pampre). Il est a noter que les germes qui suivent, par ordre d'importance, ceux presentes dans le

6 Il n‘est pas possible, a ce stade de l‘analyse, de determiner le nombre de cas dans lesquels débattre

correspond a se débattre. Il s'agit la d'une limite evidente des pretraitements effectues avant l‘extraction
de l‘espace semantique

NADJA VINCZE, YVES BESTGEN

tableau semblent tout aussi pertinents. A titre d'exemple, on trouve de 10 en 10 pour l‘orientation négative :
31. brute, 41. monstrueux, 51. exe’crati0n, 61. exasperation, 71. de’sespe’rer, 81. sourd, 91. e’g0rgement, 101.
rdle.

Négatif Nev Négatif Nev Positif Nev Positif Nev
1 rage 2. 1 16 inf amie - 1 charmant 5.7 16 charme 6. 1
2 colere 2.2 17 imprécation - 2 charmer 5.8 17 description -
3 épouvantable 1.8 18 tourmenteur - 3 ravissant 6.4 18 modeste -
4 fureur 2.8 19 lache 1. 1 4 délicieux 6.2 19 ravir 5.6
5 atroce 1.5 20 menacant - 5 gracieux 5.9 20 admirable 6. 1
6 horrible 1.8 21 menace - 6 merveille 6.1 21 romance 4.4
7 abominable 1.9 22 épouvanter 2.0 7 magnifique 6.5 22 nymphe -
8 écraser 1.9 23 saigner - 8 brillant - 23 exquis -
9 horreur 2. 1 24 cracher - 9 aimable 5.9 24 distingué -
10 crachat 1.3 25 débattre - 10 harmoniser - 25 pampre -
1 1 exaspérer 2.4 26 effrayant 2.4 1 1 élégant - 26 enchanter -
12 misérable 1.8 27 plainte - 12 riant - 27 exotique -
13 étrangler - 28 crever 1.7 13 splendide - 28 raffoler -
14 affreux 1.9 29 meurtre 1.4 14 mythologique - 29 modestement -
15 assassin - 30 injurier 1.9 15 composer - 30 fraicheur -

Tableau 6 : Mots germes sélectionnés par la méthode ASG

6 Conclusion

Pour conclure, nous avons transposé au francais deux méthodes de construction automatique de lexiques
porteurs de valences bien établies dans le monde anglo-saxon: celles de Turney et Littman (2003) et de
Kamps et Marx (2002). Cette derniere montrant des résultats encourageants, nous l'avons étendue en
augmentant le nombre de paires de mots germes. Cette modification nous a permis d‘obtenir les meilleurs
résultats, avec plus de 80 % de termes bien classés. Ce pourcentage doit cependant étre relativisé dans la
mesure ou il est calculé sur un nombre restreint de mots. Nous avons également développé une méthode qui
sélectionne les mots germes par apprentissage supervisé. Avec une efficacité d'environ 75 %, elle surpasse
nettement la méthode SO-ASL dont elle est dérivée. Il est, hélas, impossible de déterminer si les valeurs
obtenues refletent un niveau de performance proche de celui atteint par des annotateurs parce qu'on ne
dispose pas d'information a propos du degré d'accord er1tre ceux-ci. L‘analyse des mots apportant la plus
grande contribution individuelle a la prédiction de la valence souligne l‘intérét de cette méthode pour
l‘identification de mots germes. Un des principaux développements envisagés est d'utiliser ces mots germes
dans des méthodes comme celles de Kamps et Marx (2002) ou d'Esuli et Sebastiani (2006). Des adaptations
seront nécessaires puisque, dans la version actuelle, les mots germes identifiés ne forment pas des couples
comme requis par la méthode de Kamps et Marx. Il sera tout particulierement intéressant de déterminer si la
méthode proposée, qui ne requiert pas WordNet, est plus efficace que celle développée par Esuli et
Sebastiani et, surtout, si l‘emploi dans leur méthode des mots germes identifiés par ASG améliore encore les
performances. Enfin, il sera nécessaire d‘évaluer les bénéfices apportés par l'apprentissage supervisé de
germes pour l‘objectif principal de ce genre d'études : déterminer l‘orientation de textes (Harb et al., 2008).

Cette étude comporte plusieurs limitations qui sont autant de pistes pour des recherches futures. Tout
d‘abord, un seul espace sémantique, extrait de textes littéraires, a été exploité. Les implications de cette
limitation sont particulierement mises en évidence par la sélection de mots germes spécifiques a ce genre de
textes. Il serait intéressant d'effectuer ces analyses sur un corpus plus diversifié ou, séparément, sur des
corpus de genres différents. Dans ce dernier cas, il devrait étre possible d‘attribuer aux mots germes un
indice qui traduit leur degré de généralité. Ensuite, les germes identifies par la méthode ASG consistent en
des formes (lemmes) isolées, ce qui réduit fortement la qualité linguistique de l‘analyse (voir débattre). La
prise en compte de mots composés ou d'expressions figées serait également un développement intéressant
(Vernier, Monceaux, 2010). D‘autres méthodes pour mesurer les proximités sémantiques devraient
également étre testées. Il est en effet loin d‘étre évident que le passage par l‘ASL améliore l‘efficacité
(Bestgen, 2006). Enfin, notre traduction des listes du General Inquirer pourrait sans aucun doute étre
améliorée afin de récupérer un certain nombre de mots perdus. Cependant, on peut s‘interroger sur l‘utilité
d‘un tel travail, étant donné le peu d'information disponible sur la procédure de construction de ces listes. Il

