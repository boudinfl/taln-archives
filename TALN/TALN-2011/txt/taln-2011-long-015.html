<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Comparaison d&#8217;une approche miroir et d&#8217;une approche distributionnelle pour l&#8217;extraction de mots s&#233;mantiquement reli&#233;s</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Comparaison d&#8217;une approche miroir et d&#8217;une approche distributionnelle
pour l&#8217;extraction de mots s&#233;mantiquement reli&#233;s
</p>
<p>Philippe Muller1, 2 Philippe Langlais3
(1) IRIT, Universit&#233; Paul Sabatier
</p>
<p>(2) Alpage, INRIA Paris-Rocquencourt
(3) RALI / DIRO / Universit&#233; de Montr&#233;al
</p>
<p>muller@irit.fr, felipe@iro.umontreal.ca
</p>
<p>R&#233;sum&#233;. Dans (Muller &amp; Langlais, 2010), nous avons compar&#233; une approche distributionnelle et une va-
riante de l&#8217;approche miroir propos&#233;e par Dyvik (2002) sur une t&#226;che d&#8217;extraction de synonymes &#224; partir d&#8217;un
corpus en fran&#231;ais. Nous pr&#233;sentons ici une analyse plus fine des relations extraites automatiquement en nous
int&#233;ressant cette fois-ci &#224; la langue anglaise pour laquelle de plus amples ressources sont disponibles. Diff&#233;rentes
fa&#231;ons d&#8217;&#233;valuer notre approche corroborent le fait que l&#8217;approche miroir se comporte globalement mieux que
l&#8217;approche distributionnelle d&#233;crite dans (Lin, 1998), une approche de r&#233;f&#233;rence dans le domaine.
</p>
<p>Abstract. In (Muller &amp; Langlais, 2010), we compared a distributional approach to a variant of the mir-
ror approach described by Dyvik (2002) on a task of synonym extraction. This was conducted on a corpus of
the French language. In the present work, we propose a more precise and systematic evaluation of the relations
extracted by a mirror and a distributional approaches. This evaluation is conducted on the English language for
which widespread resources are available. All the evaluations we conducted in this study concur to the observation
that our mirror approach globally outperforms the distributional one described by Lin (1998), which we believe to
be a fair reference in the domain.
</p>
<p>Mots-cl&#233;s : S&#233;mantique lexicale, similarit&#233; distributionnelle, similarit&#233; traductionnelle.
</p>
<p>Keywords: Lexical Semantics, distributional similarity, mirror approach.
</p>
<p>1 Introduction
</p>
<p>Collecter les relations entre les entit&#233;s lexicales en vue de construire ou de consolider un th&#233;saurus est une activit&#233;
qui poss&#232;de une longue tradition en traitement des langues. Les efforts les plus importants ont &#233;t&#233; d&#233;di&#233;s &#224; la
recherche de synonymes, ou plus exactement des &#8220;quasi-synonymes&#8221; (Edmonds &amp; Hirst, 2002), c&#8217;est-&#224;-dire des
entr&#233;es lexicales ayant un sens similaire dans un contexte donn&#233;. D&#8217;autres relations comme l&#8217;antonymie, l&#8217;hyper-
onymie, l&#8217;hyponymie, la m&#233;ronymie ou l&#8217;holonymie ont &#233;galement &#233;t&#233; &#233;tudi&#233;es. Certains th&#233;saurus, comme Moby
que nous utilisons ici, listent de plus des relations qui sont difficiles &#224; caract&#233;riser.
</p>
<p>De nombreuses ressources ont &#233;t&#233; utilis&#233;es pour parvenir &#224; acqu&#233;rir de tels th&#233;saurus. Les dictionnaires &#233;lectro-
niques ont tout d&#8217;abord &#233;t&#233; investis, soit pour en extraire des relations s&#233;mantiques au niveau lexical (Michiels &amp;
Noel, 1982), soit pour d&#233;finir des mesures de similarit&#233; s&#233;mantiques entre les entit&#233;s lexicales (Kozima &amp; Furu-
gori, 1993). L&#8217;analyse distributionnelle, qui compare les mots &#224; travers leur contexte d&#8217;usage, est &#233;galement une
ressource populaire pour la r&#233;alisation d&#8217;une mesure de similarit&#233; s&#233;mantique (Niwa &amp; Nitta, 1994; Lin, 1998).
</p>
<p>Plusieurs approches ont montr&#233; l&#8217;int&#233;r&#234;t d&#8217;utiliser des corpus dans plusieurs langues et plus particuli&#232;rement des
corpus parall&#232;les. Dans ces travaux, les entr&#233;es lexicales sont dites similaires lorsqu&#8217;elles sont align&#233;es avec les
m&#234;mes traductions dans une autre langue (van der Plas &amp; Tiedemann, 2006; Wu &amp; Zhou, 2003). Une variante
de ce principe propos&#233;e par Dyvik (2002) consid&#232;re comme s&#233;mantiquement reli&#233;s les mots d&#8217;une langue qui
sont traduction d&#8217;un m&#234;me mot dans une autre langue ; ces mots sont appel&#233;s par l&#8217;auteur des traductions miroir.
Des variantes de cette approche ont &#233;t&#233; &#233;tudi&#233;es pour l&#8217;acquisition de paraphrases, qui porte sur des associations
d&#8217;expressions de plusieurs mots : voir par exemple (Bannard &amp; Callison-Burch, 2005) et (Max &amp; Zock, 2008).
</p>
<p>Les &#233;valuations des travaux &#224; base de similarit&#233; lexicale sont souvent d&#233;cevantes : diff&#233;rents types de relations
lexicales sont typiquement identifi&#233;s, qu&#8217;il est difficile de distinguer automatiquement. Des travaux comme ceux</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE {MULLER,LANGLAIS}
</p>
<p>de Zhitomirsky-Geffet &amp; Dagan (2009) tentent dans une &#233;tape de post-traitement de s&#233;lectionner les relations les
plus pertinentes qui caract&#233;risent des paires de mots similaires. D&#8217;autres, comme Wu &amp; Zhou (2003) tentent de
combiner le r&#233;sultat de diff&#233;rents processus d&#8217;extraction de mots reli&#233;s (approche distributionnelle, dictionnaires,
etc.).
</p>
<p>Notre &#233;tude s&#8217;inscrit dans ce dernier courant. Nous poursuivons l&#8217;&#233;tude amorc&#233;e par Muller &amp; Langlais (2010)
o&#249; une variante de Dyvik, faisant usage de mod&#232;les de traduction statistiques entra&#238;n&#233;s sur de grands volumes de
donn&#233;es, est combin&#233;e &#224; une approche distributionnelle. Contrairement &#224; ce travail, nous nous int&#233;ressons ici &#224; la
langue anglaise pour laquelle des ressources sont disponibles en plus grand nombre. Ceci nous permet de mener
une &#233;valuation &#224; l&#8217;&#233;tat de l&#8217;art de l&#8217;approche miroir, que nous comparons au th&#233;saurus produit par l&#8217;approche
d&#233;crite dans (Lin, 1998) et que Lin tient &#224; la disposition de la communaut&#233;. Nous montrons que l&#8217;approche miroir
se comporte favorablement par rapport &#224; l&#8217;approche distributionnelle, et ce, selon diff&#233;rentes &#233;valuations que nous
avons men&#233;es.
</p>
<p>Dans la suite de cet article, nous pr&#233;sentons les ressources mises &#224; profit en section 2 et notre protocole exp&#233;ri-
mental en section 3. Nous analysons nos r&#233;sultats en section 4 et discutons les travaux reli&#233;s en section 5. Nous
concluons cette &#233;tude et en dressons les perspectives en section 6.
</p>
<p>2 Ressources
</p>
<p>Nous avons utilis&#233; deux bases lexicales dans ce travail :
&#8211; La base lexicale WordNet 1 que nous interrogeons &#224; travers l&#8217;API de NLTK 2. WordNet encode les relations de
</p>
<p>synonymie (gain / acquire), d&#8217;antonymie (gain / lose), d&#8217;hyperonymie/hyponymie (odor / stench)
et d&#8217;holonymie/m&#233;ronymie (wood / tree). Chaque entr&#233;e lexicale dans WordNet poss&#232;de une moyenne de 5
&#224; 6 synonymes et de 8 &#224; 10 termes reli&#233;s, toutes relations confondues.
</p>
<p>&#8211; Le th&#233;saurus Moby 3 est une ressource plus &#233;toff&#233;e que WordNet : chaque mot dispose en effet d&#8217;environ 80
mots reli&#233;s en moyenne. La nature des relations n&#8217;est cependant pas annot&#233;e.
</p>
<p>Afin de comparer les approches miroir et distributionnelle, nous avons s&#233;lectionn&#233; de mani&#232;re al&#233;atoire deux
ensembles de 1000 mots, un pour les noms et un pour les verbes. Nous appelons ces mots les &#8220;cibles&#8221; dans la suite.
Nous avons impos&#233; arbitrairement un seuil minimal de fr&#233;quence sur les mots cibles (&gt; 1000). La fr&#233;quence des
mots a &#233;t&#233; calcul&#233;e &#224; l&#8217;aide du corpus libre de droit Wacky 4, qui compte 2 milliards de mots. Les caract&#233;ristiques
des deux ensembles de cibles ainsi construits sont d&#233;crites en table 1.
</p>
<p>nombre d&#8217;associations
</p>
<p>Pos fr&#233;quence m&#233;diane r&#233;f&#233;rence moyen m&#233;dian min max
</p>
<p>Noms 3 538 WordNet syns 3,63 2 1 36
Noms 3 538 Moby 73,87 57 3 509
Verbes 11 136 WordNet syns 5,57 4 1 47
Verbes 11 136 Moby 113,23 90 6 499
</p>
<p>TABLE 1 &#8211; Caract&#233;ristiques des deux ensembles de cibles (noms et verbes) : fr&#233;quence m&#233;diane dans Wacky,
nombre moyen de termes associ&#233;s selon la r&#233;f&#233;rence sp&#233;cifi&#233;e, nombre m&#233;dian, minimum et maximum.
</p>
<p>3 Protocole
</p>
<p>Nous comparons les termes similaires produits soit par l&#8217;approche des miroirs (section 3.1), soit par l&#8217;approche
distributionnelle (section 3.2). Chaque approche produit un ensemble de termes associ&#233;s ou candidats, class&#233;s
selon leur degr&#233; de similarit&#233;. Ces candidats ordonn&#233;s sont alors &#233;valu&#233;s au regard d&#8217;une ressource de r&#233;f&#233;rence
</p>
<p>1. wordnet.princeton.edu/wordnet
2. www.nltk.org
3. www.gutenberg.org/dirs/etext02/mthes10.zip
4. http://wacky.sslmit.unibo.it/doku.php</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMPARAISON D&#8217;UNE APPROCHE MIROIR ET D&#8217;UNE APPROCHE DISTRIBUTIONNELLE POUR L&#8217;EXTRACTION
DE MOTS RELI&#201;S
</p>
<p>(WordNet ou Moby), soit en gardant les n-meilleurs candidats, soit en gardant ceux dont le score de similarit&#233;
d&#233;passe un certain seuil (voir les d&#233;tails plus loin).
</p>
<p>&#192; titre d&#8217;exemple, la figure 1 montre les candidats propos&#233;s par les deux approches pour le mot cible choisi
al&#233;atoirement groundwork. On observe la grande diff&#233;rence de couverture de WordNet et de Moby.
</p>
<p>Candidats Miroir Candidats Lin WordNet Moby
</p>
<p>base preparation base arrangement
basis framework basis base
foundation timetable cornerstone basement
land rationale foot basis
ground impetus fundament bed
job modality foundation bedding
field foundation substructure bedrock
plan prerequisite understructure bottom
force precondition briefing
development blueprint cornerstone
</p>
<p>... [47 de plus]
</p>
<p>FIGURE 1 &#8211; Dix premiers candidats propos&#233;s par les approches miroirs et distributionnelles pour le mot cible
groundwork. Les synonymes selon WordNet ainsi qu&#8217;un sous ensemble des mots reli&#233;s selon Moby sont indi-
qu&#233;s. Les candidats soulign&#233;s appartiennent &#224; WordNet, tandis que ceux en gras sont pr&#233;sents dans Moby.
</p>
<p>3.1 Approche miroir
</p>
<p>L&#8217;approche miroir est fond&#233;e sur l&#8217;hypoth&#232;se que des mots d&#8217;une langue E qui sont fr&#233;quemment align&#233;s avec
le m&#234;me mot dans une autre langue F sont s&#233;mantiquement proches. Dans l&#8217;exemple de la figure 2, les mots
fran&#231;ais manger et consommer sont tous les deux align&#233;s avec le mot anglais eat et sont donc candidats &#224;
l&#8217;appariement s&#233;mantique.
</p>
<p>Un b&#233;b&#233; mange toutes les deux heures.
Babies eat every two hours.
</p>
<p>Canadians eat too much poutine.
Les Canadiens consomment trop de poutine.
</p>
<p>FIGURE 2 &#8211; Exemple de traductions miroir.
</p>
<p>Notre variante de l&#8217;approche miroir repose sur la consultation de deux mod&#232;les de traduction statistique pe2f et
pf2e qui donnent respectivement la probabilit&#233; qu&#8217;un mot fran&#231;ais soit la traduction d&#8217;un mot anglais et la proba-
bilit&#233; inverse. Nous calculons la vraisemblance qu&#8217;un mot anglais s (pour synonyme) soit reli&#233; s&#233;mantiquement &#224;
un mot anglais w, soit p(s|w) :
</p>
<p>p(s|w) &#8776;
&#8721;
</p>
<p>f&#8712;&#964;e2f (w)
p&#948;1e2f (f|w)&#215; p&#948;2f2e(s|f) &#964;e2f (w) = {f : pe2f (f|w) &gt; 0}
</p>
<p>Ici &#964;e2f (w) d&#233;signe l&#8217;ensemble des mots fran&#231;ais associ&#233;s par le mod&#232;le pe2f au mot anglais w. En pratique,
les distributions lexicales utilis&#233;es &#233;tant bruit&#233;es, nous appliquons deux seuils &#948;1 et &#948;2 (fix&#233;s &#224; 0.001 dans cette
exp&#233;rience) qui filtrent les associations peu probables d&#8217;un mod&#232;le :
</p>
<p>p&#948;&#8226;(t|s) =
{
p&#8226;(t|s) si p&#8226;(t|s) &#8805; &#948;
0 sinon
</p>
<p>D&#8217;autres fa&#231;ons de filtrer les tables de transfert pourraient &#234;tre d&#233;ploy&#233;es. Nous pourrions par exemple utiliser un
test de significativit&#233; afin de retenir les associations les plus pertinentes. Notre approche au filtrage est certainement
perfectible mais pr&#233;sente l&#8217;avantage d&#8217;&#234;tre particuli&#232;rement simple &#224; mettre en &#339;uvre.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE {MULLER,LANGLAIS}
</p>
<p>Les mod&#232;les lexicaux pe2f et pf2e ont &#233;t&#233; entra&#238;n&#233;s sur un bitexte anglais-fran&#231;ais de 8,3 millions de paires de
phrases extraites des transcriptions des d&#233;bats parlementaires canadiens (Hansard). Ce bitexte est exploit&#233; par le
concordancier bilingue TSRali 5. Nous avons lemmatis&#233; les phrases anglaises et fran&#231;aises du corpus &#224; l&#8217;aide de
TreeTager 6 avant d&#8217;entra&#238;ner dans les deux directions 7 (anglais&#8594;fran&#231;ais et fran&#231;ais&#8594;anglais) des mod&#232;les
IBM 4 &#224; l&#8217;aide de Giza++ 8 utilis&#233; dans sa configuration par d&#233;faut.
</p>
<p>Dans l&#8217;&#233;valuation qui suit, nous avons consid&#233;r&#233; les 200 premiers lemmes associ&#233;s &#224; chaque mot cible par cette
approche car c&#8217;est le nombre de candidats que produit l&#8217;approche distributionnelle que nous avons test&#233;e (voir la
section suivante).
</p>
<p>3.2 Similarit&#233; distributionnelle
</p>
<p>L&#8217;approche distributionnelle que nous utilisons est celle d&#233;crite par Lin (1998). Elle repr&#233;sente selon nous une
approche de r&#233;f&#233;rence dans le domaine. Un th&#233;saurus calcul&#233; par l&#8217;auteur &#224; l&#8217;aide de cette m&#233;thode est disponible
gratuitement 9.
</p>
<p>Pour l&#8217;obtenir, Lin a fait usage d&#8217;un analyseur grammatical en d&#233;pendance afin de comptabiliser les occurrences
de triplets (lemme_de_t&#234;te, relation, lemme_d&#233;pendant) o&#249; relation est une relation (syn-
taxique) de d&#233;pendance. &#192; chaque lemme w est associ&#233; un vecteur de compte pour l&#8217;ensemble F (w) des traits
(rel, autre_lemme) o&#249; autre_lemme est soit un d&#233;pendant de w, soit un gouverneur de w.
</p>
<p>Par exemple, le verbe eat est caract&#233;ris&#233; par un ensemble de traits F (eat) contenant (has_subj,man),
(has_obj,fries), (has_obj,pie), etc qui correspondent aux contextes syntaxiques de eat. Appelons
c la fonction de comptage d&#8217;occurrence d&#8217;un triplet (w, rel, w&#8242;) et V l&#8217;ensemble du vocabulaire, on pose :
</p>
<p>c(_, rel, w) =
&#8721;
w&#8242;&#8712;V
</p>
<p>c(w&#8242;, rel, w) I(w, rel, w&#8242;) = log
c(w, rel, w&#8242;)&#215; c(_, rel, _)
c(w, rel, _)&#215; c(_, rel, w&#8242;)
</p>
<p>c(w, rel, _) =
&#8721;
w&#8242;&#8712;V
</p>
<p>c(w, rel, w&#8242;)
</p>
<p>c(_, rel, _) =
&#8721;
w&#8242;&#8712;V
</p>
<p>c(_, rel, w&#8242;) ||w|| =
&#8721;
</p>
<p>(r,w&#8242;)&#8712;F (w)
I(w, r, w&#8242;)
</p>
<p>I(w, rel, w&#8242;) est alors la sp&#233;cificit&#233; d&#8217;une relation (w, rel, w&#8242;), d&#233;finie comme l&#8217;information mutuelle entre les
&#233;l&#233;ments du triplet (Lin, 1998). On note ||w|| la quantit&#233; d&#8217;information totale associ&#233;e &#224; w. La similarit&#233; entre
deux lemmes w1 et w2 mesure alors &#224; quel point ils partagent des contextes syntaxiques sp&#233;cifiques, en utilisant la
quantit&#233; d&#8217;information des contextes qu&#8217;ils partagent, normalis&#233;e par la quantit&#233; d&#8217;information totale qu&#8217;on peut
leur associer s&#233;par&#233;ment.
</p>
<p>sim(w1, w2) =
</p>
<p>&#8721;
(r,w)&#8712;F (w1)&#8745;F (w2)[I(w1, r, w) + I(w2, r, w)]
</p>
<p>||w1||+ ||w2||
</p>
<p>D&#8217;apr&#232;s (Lin et al., 2003), le corpus utilis&#233; pour obtenir le th&#233;saurus que nous avons utilis&#233; ici serait de 3 milliards
de mots, c&#8217;est-&#224;-dire plus de 10 fois la taille du corpus que nous avons utilis&#233; pour d&#233;velopper l&#8217;approche miroir.
Il nous est apparu pr&#233;f&#233;rable de prendre ce th&#233;saurus plut&#244;t que de tester notre impl&#233;mentation de l&#8217;approche
que nous venons de d&#233;crire en particulier parce que nous ne disposons pas d&#8217;information sur les r&#233;glages des
param&#232;tres utilis&#233;s par les auteurs pour optimiser leurs sorties. En fait, notre impl&#233;mentation de l&#8217;approche est
de moins bonne qualit&#233; sur les jeux de tests que nous pr&#233;sentons que ceux obtenus &#224; l&#8217;aide du th&#233;saurus com-
pil&#233; par les auteurs. &#192; tout le moins, nous soulignons que la comparaison de l&#8217;approche miroir avec l&#8217;approche
distributionnelle n&#8217;est pas biais&#233;e en faveur de l&#8217;approche miroir.
</p>
<p>Le th&#233;saurus calcul&#233; par Lin pr&#233;sente pour chaque mot cible les 200 lemmes les plus proches au sens de cette
mesure de similarit&#233;.
</p>
<p>5. http://www.tsrali.com/
6. www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
7. Les mod&#232;les IBM ne sont pas sym&#233;triques.
8. fjoch.com/GIZA++.html
9. webdocs.cs.ualberta.ca/~lindek/Downloads/sim.tgz</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMPARAISON D&#8217;UNE APPROCHE MIROIR ET D&#8217;UNE APPROCHE DISTRIBUTIONNELLE POUR L&#8217;EXTRACTION
DE MOTS RELI&#201;S
</p>
<p>4 Exp&#233;riences
</p>
<p>En suivant le protocole d&#233;crit plus haut, nous avons &#233;valu&#233; la sortie des deux similarit&#233;s (miroir et distribution-
nelle) en consid&#233;rant soit les n-meilleurs candidats de chaque approche, soit en consid&#233;rant ceux dont le score de
similarit&#233; d&#233;passe un seuil donn&#233; (que nous faisons varier). Nous avons s&#233;par&#233; notre jeu de test en deux ensembles
de mani&#232;re &#224; mesurer les diff&#233;rences entre les noms et les verbes : comme le montre la table 1, le nombre de
synonymes et autres entit&#233;s lexicales reli&#233;es varie fortement en fonction de la cat&#233;gorie morpho-syntaxique.
</p>
<p>Nous avons consid&#233;r&#233; lors de l&#8217;&#233;valuation les seuls items communs &#224; la r&#233;f&#233;rence et au lexique de la ressource
utilis&#233;e pour le d&#233;veloppement d&#8217;une mesure de similarit&#233;. Par exemple, WordNet contient des synonymes qui
ne sont pas pr&#233;sents dans les Hansards que nous avons mis &#224; profit pour d&#233;velopper l&#8217;approche miroir : ils sont
simplement &#233;cart&#233;s de notre &#233;valuation.
</p>
<p>Les deux approches que nous comparons sont sensibles &#224; la fr&#233;quence des mots cibles consid&#233;r&#233;s. Dans les deux
approches d&#233;crites, tous les sens d&#8217;un mot sont regroup&#233;s lors des calculs de la similarit&#233; et il est vraisemblable
que les usages les plus fr&#233;quents dominent les autres dans ces calculs. Sachant qu&#8217;un mot fr&#233;quent a plus de chance
d&#8217;&#234;tre polys&#233;mique qu&#8217;un autre, nous souhaitions prendre en consid&#233;ration dans notre &#233;valuation l&#8217;influence de la
fr&#233;quence des mots cibles &#233;tudi&#233;s. Nous filtrons &#224; cet effet les candidats dont la fr&#233;quence (telle que calcul&#233;e &#224;
l&#8217;aide de Wacky) est inf&#233;rieure &#224; un seuil donn&#233;, pour un ensemble de ces valeurs seuils.
</p>
<p>Il a &#233;t&#233; montr&#233; (Weeds, 2003) que la plupart des m&#233;thodes de similarit&#233; lexicale se comportent de fa&#231;on tr&#232;s
diff&#233;rente par rapport &#224; ce crit&#232;re, s&#233;lectionnant selon les r&#233;glages plut&#244;t des mots fr&#233;quents ou plut&#244;t des mots
rares.
</p>
<p>Nous avons remarqu&#233; la tendance de l&#8217;approche miroir &#224; souvent proposer des mots &#8220;vides&#8221;. Cela s&#8217;explique par
le fait que ces mots sont souvent biens not&#233;s par les distributions lexicales que nous utilisons. Ce ph&#233;nom&#232;ne a
&#233;t&#233; analys&#233; notamment dans (Moore, 2004). Nous avons arbitrairement &#233;limin&#233; des listes de candidats miroirs les
termes apparus dans plus de 25% des listes (ce seuil pourrait &#234;tre ajust&#233; &#224; l&#8217;aide d&#8217;un corpus de d&#233;veloppement).
Ce filtre &#233;limine des noms courants comme thing ou way, des verbes comme have, be ou come, ainsi que des
mots sur-repr&#233;sent&#233;s dans les Hansards (ex. : house).
</p>
<p>Au final, nous avons combin&#233; les listes candidates produites par les deux approches en prenant l&#8217;intersection des
deux listes. D&#8217;autres sch&#233;mas de combinaison seront &#233;tudi&#233;s dans des travaux ult&#233;rieurs.
</p>
<p>Deux aspects nous int&#233;ressent plus particuli&#232;rement dans cette exp&#233;rience : la quantit&#233; de mots reli&#233;s dans la
r&#233;f&#233;rence que nous sommes capables d&#8217;identifier par l&#8217;une des approches et la fiabilit&#233; avec laquelle ils sont
identifi&#233;s. En d&#8217;autres termes, nous voulons que la t&#234;te de liste des candidats soit la meilleure possible au regard
d&#8217;une liste de r&#233;f&#233;rence. Nous &#233;valuons donc les deux approches &#224; l&#8217;aide des taux de pr&#233;cision et de rappel 10 que
nous mesurons en diff&#233;rents points. Nous r&#233;sumons ces taux &#224; l&#8217;aide des taux MAP (Mean Average Precision) et
MRR (Mean Reciprocal Rank) couramment employ&#233;s en recherche d&#8217;information. MAP calcule la pr&#233;cision en
chaque point de la liste o&#249; un candidat pertinent est identifi&#233; ; MRR est calcul&#233; comme la moyenne de l&#8217;inverse
des rangs du premier terme pertinent dans la liste.
</p>
<p>Enfin, nous avons &#233;galement calcul&#233; la pr&#233;cision de chaque approche en faisant l&#8217;hypoth&#232;se d&#8217;un &#8220;oracle&#8221; qui
indique le nombre exact de candidats &#224; proposer pour chaque mot cible (il s&#8217;agit dans notre cas du nombre de
mots reli&#233;s dans la r&#233;f&#233;rence). Cette mesure est semblable &#224; ce que l&#8217;on appelle la R-pr&#233;cision. Par exemple, les 10
candidats de la m&#233;thode des miroirs de la figure 1, &#233;valu&#233;s &#224; l&#8217;aide de la r&#233;f&#233;rence WordNet, re&#231;oivent une pr&#233;cision
de 3/10, un rappel de 3/5 (et pas 3/8 car les mots understructure, substructure et fundament sont
absents des Hansards). La R-pr&#233;cision est &#233;galement de 3/5 car tous les candidats corrects sont propos&#233;s &#224; un rang
inf&#233;rieur au nombre de mots reli&#233;s dans la r&#233;f&#233;rence (5 synonymes). La pr&#233;cision au rang 1 est de 1, alors que la
pr&#233;cision au rang 5 est de 3/5. Finalement, le taux MAP est de 0,63 = 6,29/10 = (1/1 + 2/2 + 3/3 + 3/4 + . . .+ 3/10)
/ 10 alors que MRR est de 1 car le premier candidat est correct ; il serait de 1/2 si seulement le second candidat
avait &#233;t&#233; correct, etc.
</p>
<p>Il est apparu empiriquement qu&#8217;il &#233;tait pr&#233;f&#233;rable de couper une liste candidate &#224; un rang donn&#233; que d&#8217;essayer de
seuiller en fonction d&#8217;un score de similarit&#233;, et nous d&#233;taillons donc uniquement par la suite les r&#233;sultats avec la
premi&#232;re m&#233;thode, en faisant varier le rang.
</p>
<p>10. Que nous pr&#233;sentons sous forme de pourcentage pour plus de lisibilit&#233;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE {MULLER,LANGLAIS}
</p>
<p>4.1 WordNet
</p>
<p>La table 2 montre les r&#233;sultats pour les noms &#233;valu&#233;s selon les synonymes de WordNet. Pour chaque approche,
nous indiquons les pr&#233;cisions aux rangs n=1, ..., 100 dans les listes candidates, les taux MAP, MRR, la R-pr&#233;cision,
le nombre de synonymes dans la r&#233;f&#233;rence (||ref ||) et le rappel global, pour les 200 premiers candidats de
chaque m&#233;thode 11. Nous rapportons &#233;galement l&#8217;influence de diff&#233;rents filtres de fr&#233;quence. La ligne f&gt;1000,
par exemple, indique que nous retenons des listes candidates et de la r&#233;f&#233;rence les seuls mots dont la fr&#233;quence
(dans Wacky) est sup&#233;rieure &#224; 1000.
</p>
<p>n-meilleur(s) P1 P5 P10 P20 P100 MAP MRR R-prec &#8214;ref&#8214; rappel
</p>
<p>Miroir
</p>
<p>f&gt;1 16,4 5,1 3,8 2,7 1,3 11,9 15,1 16,6 2342 50,0
f&gt;5000 19,1 5,4 3,8 2,6 1,2 11,3 13,2 17,5 1570 54,8
f&gt;20000 22,1 5,7 3,9 2,5 1,1 9,8 11,4 22,7 1052 60,6
</p>
<p>Lin
</p>
<p>f&gt;1 17,4 5,2 3,5 2,5 1,5 11,7 14,3 14,7 2342 35,9
f&gt;5000 16,5 5,0 3,5 2,5 1,6 9,2 10,8 16,7 1570 36,6
f&gt;20000 17,5 4,5 3,3 2,5 1,6 7,3 8,4 20,1 1052 36,9
</p>
<p>M/L
</p>
<p>f&gt;1 25,8 7,5 5,7 4,4 3,8 15,9 17,6 22,0 2342 29,3
f&gt;5000 27,4 7,4 5,5 4,3 3,8 12,7 13,6 24,6 1570 31,1
f&gt;20000 26,1 6,4 4,7 3,5 2,6 9,7 10,4 28,9 1052 32,7
</p>
<p>TABLE 2 &#8211; R&#233;sultats pour les noms, micro-moyenn&#233;s, avec les synonymes de WordNet pour r&#233;f&#233;rence.
</p>
<p>Comme WordNet r&#233;pertorie peu de synonymes, les pr&#233;cisions &#224; faible rang (1 et 5) sont les plus pertinentes, ainsi
que la R-pr&#233;cision : les autres sont n&#233;cessairement tr&#232;s basses. Les autres mesures sont donn&#233;es &#224; des fins de
comparaison car elles sont plus pertinentes pour la r&#233;f&#233;rence Moby. Ceci &#233;tant not&#233;, la table 2 am&#232;ne plusieurs
commentaires 12.
</p>
<p>Premi&#232;rement, nous observons que la pr&#233;cision de l&#8217;approche miroir au rang 1 culmine &#224; 22% alors que le rappel
plafonne &#224; un peu plus de 60% : un bien meilleur r&#233;sultat combin&#233; que l&#8217;approche distributionnelle que nous avons
test&#233;e (moins de 18% de pr&#233;cision au rang 1 et moins de 37% de rappel). Deuxi&#232;mement, il appara&#238;t clairement
que filtrer les candidats les moins fr&#233;quents est beaucoup plus payant pour l&#8217;approche miroir 13. C&#8217;est sans doute la
cons&#233;quence d&#8217;un corpus de d&#233;part plus petit, pour lequel les occurrences rares de mots peu fr&#233;quents entra&#238;nent
des probabilit&#233;s d&#8217;alignement peu fiables. Troisi&#232;mement, nous observons que notre combinaison des deux ap-
proches, aussi simpliste soit-elle, s&#8217;accompagne d&#8217;une augmentation significative de la pr&#233;cision, notamment la
R-pr&#233;cision (au d&#233;triment cependant du rappel).
</p>
<p>Enfin, les r&#233;sultats sur les verbes sont similaires &#224; ceux pr&#233;sent&#233;s ici pour les noms, avec cependant une meilleure
pr&#233;cision &#224; rang faible et un compromis sur la fr&#233;quence de coupure plus &#233;lev&#233;, et ce, m&#234;me si la pr&#233;cision oracle
est globalement la m&#234;me pour toutes les configurations. Combiner les deux m&#233;thodes am&#233;liore la pr&#233;cision de
mani&#232;re similaire &#224; ce que nous observons sur les noms, avec une pr&#233;cision oracle qui varie cette fois entre 20%
et 27%. Les diff&#233;rences sont toutes significatives sauf cette fois sur P1 &#224; fr&#233;quence &#233;lev&#233;e.
</p>
<p>Nous ne montrons pas le d&#233;tail des scores si on ajoute dans la r&#233;f&#233;rence les relations issues de toutes les fonctions
lexicales de WordNet, mais on peut noter que les r&#233;sultats sont tr&#232;s proches entre les deux m&#233;thodes sur les noms
(R-prec&#8776;13% et P@1=23% quand f&gt;1). En revanche, les traductions miroirs sont l&#233;g&#232;rement meilleures sur les
verbes en R-pr&#233;cision (16% contre 18% pour f&gt;1 et 17% contre 21% pour f&gt;20000 ), et inf&#233;rieures en terme de
pr&#233;cision au rang 1 (41% contre 37% pour f&gt;1 &#224; 33% contre 34%).
</p>
<p>Nous montrerons en section 4.3 que la diff&#233;rence semble se jouer essentiellement sur les relations de synonymie
et d&#8217;hyperonymie (et hyponymie).
</p>
<p>11. Les candidats de Lin &#233;tant limit&#233;s &#224; ce nombre.
12. Sauf pr&#233;cision contraire, les diff&#233;rences entre m&#233;thodes discut&#233;es plus bas sont tous significatives &#224; p&lt;0.05. Pour toutes les mesures sauf
</p>
<p>P1 et le rappel global, nous avons utilis&#233; le test de Wilcoxon sur les r&#233;sultats mot par mot. Dans le cas de P1 qui donne un r&#233;sultat binaire par
cible, nous avons fait un test binomial.
</p>
<p>13. Les diff&#233;rences significatives de pr&#233;cision et MAP entre les deux m&#233;thodes n&#8217;apparaissent que pour les valeurs de fr&#233;quence &#233;lev&#233;e.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMPARAISON D&#8217;UNE APPROCHE MIROIR ET D&#8217;UNE APPROCHE DISTRIBUTIONNELLE POUR L&#8217;EXTRACTION
DE MOTS RELI&#201;S
</p>
<p>4.2 Moby
</p>
<p>La table 3 r&#233;sume les r&#233;sultats des deux approches pour les noms, en prenant cette fois-ci Moby pour r&#233;f&#233;rence.
Les relations list&#233;es dans ce th&#233;saurus &#233;tant du tout venant, nous nous attendions &#224; ce que la r&#233;f&#233;rence soit plus
proche des sorties produites par une approche distributionnelle. Nous observons que c&#8217;est bien le cas sur les noms :
la pr&#233;cision de l&#8217;approche de Lin est syst&#233;matiquement sup&#233;rieure &#224; celle des miroirs, avec presque 10 points de
plus au rang 1 ; et ce, m&#234;me si le rappel est l&#233;g&#232;rement en faveur de l&#8217;approche miroir. Sur les verbes, cependant,
les deux approches se comportent de mani&#232;re comparable. En observant la diff&#233;rence de scores de pr&#233;cision entre
</p>
<p>n-meilleur(s) P1 P5 P10 P20 P100 MAP MRR R-prec &#8214;ref&#8214; rappel
</p>
<p>Miroir
</p>
<p>f&gt;1 33,7 15,8 13,3 11,0 7,0 18,5 40,1 11,0 60774 18,1
f&gt;5000 32,7 14,5 12,1 9,8 6,1 18,7 38,1 11,8 43294 21,6
f&gt;20000 30,3 13,2 10,7 8,6 5,3 18,1 34,9 12,8 28488 26,7
</p>
<p>Lin
</p>
<p>f&gt;1 44,8 19,9 16,4 13,4 9,5 26,6 46,8 14,7 60774 15,4
f&gt;5000 40,7 18,5 15,0 12,5 9,3 25,6 41,6 15,0 43294 16,3
f&gt;20000 39,4 16,1 13,5 11,2 8,4 23,3 35,2 16,8 28488 16,8
</p>
<p>M/L
</p>
<p>f&gt;1 53,1 25,1 21,4 18,1 35,2 46,6 22,9 25,0 60774 9,4
f&gt;5000 52,4 23,0 19,3 16,6 13,7 30,7 41,2 23,4 43294 10,9
f&gt;20000 45,9 19,4 16,5 14,0 11,2 24,6 32,6 21,6 28488 12,5
</p>
<p>TABLE 3 &#8211; R&#233;sultats pour les noms, micro-moyenn&#233;s, avec les mots reli&#233;s de Moby pour r&#233;f&#233;rence.
</p>
<p>la table 3 et la table 2, il semble que les approches miroir et distributionnelle ram&#232;nent bien d&#8217;autres entit&#233;s que des
synonymes dans leurs meilleurs candidats. Cela peut sembler un peu surprenant pour l&#8217;approche miroir puisque
cette approche capitalise &#224; priori sur des relations de traduction. Nous devons analyser cela de fa&#231;on plus pr&#233;cise
afin de savoir si nous sommes en pr&#233;sence de bruit dans les mod&#232;les de traduction (ce qui est tr&#232;s probable) ou si
Moby contient plus de synonymes que WordNet, ou les deux.
</p>
<p>Nous observons &#233;galement que le rappel de l&#8217;approche miroir est plus grand que celui de l&#8217;approche distribution-
nelle, une observation en accord avec notre &#233;valuation sur WordNet, et qui est peut-&#234;tre due &#224; la diff&#233;rence de
performance des deux approches sur les synonymes (qui sont nombreux dans Moby).
</p>
<p>Le filtre des entit&#233;s lexicales offre un rendement mitig&#233; : la pr&#233;cision de la variante f&gt;20000 est l&#233;g&#232;rement
inf&#233;rieure &#224; celle de la variante f&gt;1 pour les deux approches. Le rappel de l&#8217;approche miroir augmente cependant
de mani&#232;re notable et consistante dans les cas o&#249; l&#8217;on s&#8217;int&#233;resse aux mots tr&#232;s fr&#233;quents.
</p>
<p>4.3 Analyse des erreurs produites par l&#8217;approche miroir
</p>
<p>Les exp&#233;riences que nous venons de d&#233;crire poss&#232;dent quelques limites. La r&#233;f&#233;rence WordNet que nous utilisons
pour la synonymie poss&#232;de un nombre relativement restreint de synonymes par mot candidat, ce qui ne permet pas
de rendre compte avec pr&#233;cision de la pertinence des autres candidats propos&#233;s. Le fait d&#8217;utiliser un th&#233;saurus plus
vaste comme Moby ne r&#233;sout que partiellement le probl&#232;me car la nature des relations encod&#233;es dans Moby n&#8217;est
pas &#233;tiquet&#233;e et certaines relations pr&#233;sentes dans cette ressource ne correspondent pas &#224; des relations lexicales
typiques (ex : raging / abandoned).
</p>
<p>On peut mener une premi&#232;re analyse &#224; l&#8217;aide de WordNet afin d&#8217;&#233;valuer la pr&#233;sence de termes reli&#233;s par d&#8217;autres
relations que la synonymie. Si l&#8217;on regarde les premiers candidats produits pour chaque cible (voir la table 4), on
constate que pour les verbes, 19% sont recens&#233;s comme hyperonymes et 6% comme hyponymes, les proportions
&#233;tant de 7% et 4% pour les noms. Les autres fonctions (holonymes, m&#233;ronymes et antonymes) apparaissent de
fa&#231;on marginale. En regardant les 5 premiers candidats produits par les deux approches, on observe que ceux
produits pour les verbes correspondent davantage &#224; des relations pr&#233;sentes dans WordNet. En grande majorit&#233;, les
candidats identifi&#233;s ne correspondent pas &#224; une relation &#233;tiquet&#233;e dans WordNet. Un peu moins de la moiti&#233; des
cibles ne re&#231;oit d&#8217;ailleurs aucun candidat valid&#233; par WordNet (&#216;).
</p>
<p>Les probl&#232;mes de couverture de WordNet se posent malheureusement pour toutes les fonctions lexicales et ceci
ne peut &#234;tre qu&#8217;indicatif. Nous avons donc conduit une &#233;valuation manuelle de la sortie produite par l&#8217;approche</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE {MULLER,LANGLAIS}
</p>
<p>top 5 top 1
</p>
<p>&#216; S He Ho Hl A M &#216; S He Ho Hl A M
</p>
<p>nom Miroir 3146 181 175 98 13 5 1 570 64 58 28 5 1 1
Lin 3078 186 161 123 12 11 2 565 65 49 31 6 4 1
</p>
<p>verbe Miroir 2807 406 428 216 0 7 0 466 95 139 42 0 3 0
Lin 2882 414 272 212 0 20 0 444 140 106 50 0 5 0
</p>
<p>TABLE 4 &#8211; Nombre de fonctions lexicales correspondant aux 5 (colonne de gauche) ou 1 (colonne de droite)
premiers candidats propos&#233;s par chaque approche sans filtre de fr&#233;quence, selon WordNet. &#216; signifie qu&#8217;aucune
relation selon WordNet n&#8217;est associ&#233;e &#224; un candidat. Ces occurrences sont comptabilis&#233;es pour les cibles trai-
t&#233;es par les deux approches, soit 724 noms et 743 verbes. S=synonymes, He=hyperonymes, Ho=hyponymes,
Hl=holonymes, A=antonymes, M=m&#233;ronymes.
</p>
<p>miroir en s&#233;lectionnant al&#233;atoirement 100 paires de mots cible / candidat o&#249; le candidat est le premier
propos&#233; par l&#8217;approche miroir, bien qu&#8217;il ne soit pas valid&#233; comme synonyme par WordNet. Nous avons observ&#233;
les ph&#233;nom&#232;nes suivants :
</p>
<p>&#8211; 25% des mots candidats constituent une partie d&#8217;une unit&#233; compos&#233;e de plusieurs mots, comme le mot sea
dans la paire sea / urchin ;
</p>
<p>&#8211; 18% des mots candidats non valid&#233;s par WordNet sont en fait des synonymes selon d&#8217;autres th&#233;saurus que nous
avons consult&#233; manuellement 14. C&#8217;est par exemple le cas de la paire torso / chest ;
</p>
<p>&#8211; 13% des candidats sont en fait des hyperonymes list&#233;s dans WordNet ou dans www.thesaurus.com, comme
la paire twitch / movement ;
</p>
<p>&#8211; 6% des paires mettent en relation des mots morphologiquement reli&#233;s, comme accountant / accounting,
probablement en raison d&#8217;un probl&#232;me d&#8217;&#233;tiquetage en partie du discours dans la langue pivot o&#249; un mot fran&#231;ais
comme ici comptable peut &#234;tre aussi bien &#234;tre un nom qu&#8217;un adjectif.
</p>
<p>Parmi les erreurs (au sens de WordNet) fr&#233;quentes restantes, certaines sont dues &#224; la polys&#233;mie d&#8217;une traduction
pivot, comme par exemple le mot anglais aplomb traduit en fran&#231;ais par assurance qui veut &#233;galement dire
insurance en anglais. Ce type de probl&#232;me est cependant difficile &#224; analyser sans retracer m&#233;ticuleusement les
nombreuses associations utilis&#233;es par les mod&#232;les de traduction dans notre approche.
</p>
<p>D&#8217;autres erreurs sont plut&#244;t imputables &#224; des termes peu fr&#233;quents dans le corpus des Hansards que nous avons
utilis&#233; et que nous aurions d&#251; filtrer au pr&#233;alable.
</p>
<p>Cette analyse sugg&#232;re que tous les candidats rejet&#233;s ne sont pas n&#233;cessairement mauvais et qu&#8217;il y a donc place
&#224; am&#233;lioration. La polys&#233;mie demeure le probl&#232;me le plus difficile &#224; r&#233;soudre, que ce soit pour notre approche
miroir ou pour l&#8217;approche distributionnelle.
</p>
<p>Nous avons &#233;galement regard&#233; de mani&#232;re tr&#232;s informelle les mots cibles pour lesquels WordNet ne propose
aucun synonyme alors que l&#8217;approche miroir propose des candidats. Dans une proportion non n&#233;gligeable de cas,
les traductions miroir sont pertinentes comme whopper / lie. Une analyse plus fine est cependant requise pour
quantifier plus pr&#233;cis&#233;ment cette observation.
</p>
<p>4.4 Tests de synonymie
</p>
<p>Comme &#233;valuation secondaire, plusieurs auteurs utilisent, pour &#233;valuer la pertinence d&#8217;une mesure de similarit&#233;
s&#233;mantique, des tests de synonymie semblables &#224; ceux pos&#233;s dans les examens du TOEFL (Turney, 2008) o&#249; la
t&#226;che consiste &#224; distinguer parmi quatre candidats, le synonyme d&#8217;un mot dans un contexte donn&#233;. On peut voir
cet exercice comme une version simplifi&#233;e d&#8217;une t&#226;che de d&#233;sambigu&#239;sation, o&#249; le but est de reconna&#238;tre le bon
terme dans un ensemble de distracteurs (termes &#224; priori sans rapport), au lieu de distinguer les sens d&#8217;un m&#234;me
mot. On teste alors la similarit&#233; s&#233;mantique en prenant celui des candidats qui a le score de similarit&#233; le plus &#233;lev&#233;
avec la cible.
</p>
<p>14. Comme par exemple le Roget&#8217;s 21st Century Thesaurus, http://www.thesaurus.com</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMPARAISON D&#8217;UNE APPROCHE MIROIR ET D&#8217;UNE APPROCHE DISTRIBUTIONNELLE POUR L&#8217;EXTRACTION
DE MOTS RELI&#201;S
</p>
<p>Les donn&#233;es TOEFL ne sont pas librement disponibles, aussi avons nous utilis&#233; ici un test g&#233;n&#233;r&#233; artificiellement
&#224; partir des donn&#233;es de WordNet par Freitag et al. (2005) 15. Les auteurs le consid&#232;rent comme plus difficile que
les &#233;quivalents du TOEFL. Ce test est notamment utilis&#233; par Ferret (2010) afin d&#8217;ordonner diff&#233;rentes mesures de
similarit&#233; entre vecteurs de cooccurrences. Le meilleur score qu&#8217;il obtient sur ce test est de 71.6% de r&#233;ponses
correctes, ce qui est proche du score de 72% d&#8217;exactitude obtenu par (Freitag et al., 2005) &#224; l&#8217;aide d&#8217;autres
m&#233;thodes distributionnelles. Les syst&#232;mes r&#233;pondent &#224; toutes les questions.
</p>
<p>Les instances de test sont de la forme house: family obstacle filing surgeon le premier terme
&#233;tant la cible, le second un synonyme d&#8217;un des sens de la cible selon WordNet, les trois autres sont des distracteurs.
Quelques restrictions sont ajout&#233;es pour ne pas rendre le test trop facile : les synonymes dont la forme est proche
de la cible (group/grouping) sont &#233;limin&#233;s. Par ailleurs les cibles sont choisies avec une fr&#233;quence minimale.
Les distracteurs sont choisis compl&#232;tement au hasard, mais les termes associ&#233;s sont choisis parmi les synsets de
WordNet et privil&#233;gient donc les termes polys&#233;miques.
</p>
<p>Nous avons appliqu&#233; ce test &#224; nos deux approches en choisissant, comme les autres travaux mentionn&#233;s, celui
des candidats ayant le meilleur rang dans la liste de similarit&#233;s. Si aucun des candidats du test n&#8217;est pr&#233;sent dans
les candidats d&#8217;une m&#233;thode, le syst&#232;me ne r&#233;pond rien. Nous pouvons donc &#233;valuer l&#8217;aptitude d&#8217;une mesure de
similarit&#233; &#224; identifier le bon terme, ce que nous mesurons en terme de pr&#233;cision, rappel et F-score.
</p>
<p>La table 5 r&#233;sume les r&#233;sultats pour les 200 premiers candidats de chaque m&#233;thode. Dans les cas o&#249; les candidats
sont tous absents de la r&#233;ponse du syst&#232;me, (Ferret, 2010) renvoie une r&#233;ponse au hasard, mais cela arrive rarement
vue la couverture de son syst&#232;me. Nous avons ici fait le choix de consid&#233;rer que le syst&#232;me ne r&#233;pond pas faute
de donn&#233;es fiables, car c&#8217;est un cas beaucoup plus courant ici. Ceci a pour effet de faire baisser le rappel, et la
pr&#233;cision &#233;value r&#233;ellement la m&#233;thode des miroirs.
</p>
<p>Comme nous disposons pour l&#8217;approche miroir d&#8217;une liste de candidats plus &#233;tendue, nous avons aussi &#233;valu&#233; cette
m&#233;thode sans coupure. On constate un nombre important de non-r&#233;ponses &#233;galement, cette fois due sans doute &#224;
une couverture lexicale limit&#233;e de la ressource de d&#233;part (les Hansards). Noms et verbes regroup&#233;s, cette variante
obtient un F-score de 0,73, avec 3908/17285 cibles sans r&#233;ponse (22%), majoritairement des noms.
</p>
<p>&#192; nombres de candidats &#233;gaux, on constate donc que la m&#233;thode miroir a une pr&#233;cision &#233;quivalente &#224; celle de
Lin mais un rappel bien sup&#233;rieur. Sans limite de candidats, elle atteint un F-score comparable aux meilleures
m&#233;thodes distributionnelles test&#233;es dans les travaux susmentionn&#233;s.
</p>
<p>Noms F1 P R sans r&#233;ponse
</p>
<p>Lin[200] 0,55 0,95 0,38 5885/9887
Miroir[200] 0,63 0,95 0,47 4975/9887
Miroir 0,72 0,87 0,61 2995/9887
</p>
<p>Verbes F1 P R sans r&#233;ponse
</p>
<p>Lin[200] 0,55 0,87 0,40 3983/7398
Miroir[200] 0,69 0,89 0,56 2694/7398
Miroir 0,74 0,79 0,70 913/7398
</p>
<p>TABLE 5 &#8211; &#201;valuation pour le test de synonymie bas&#233; sur WordNet de (Freitag et al., 2005)
</p>
<p>Faute de place, nous ne ferons que d&#233;crire bri&#232;vement une autre fa&#231;on d&#8217;analyser le test effectu&#233;, propos&#233;e par
(Freitag et al., 2005), consistant &#224; mettre les r&#233;sultats en rapport avec le niveau de polys&#233;mie des termes cibles, et
qui semblait mettre en &#233;vidence que les cibles polys&#233;miques &#233;taient les plus dures &#224; r&#233;soudre. Nous n&#8217;avons pas
constat&#233; ce ph&#233;nom&#232;ne ici, la pr&#233;cision reste constante pour les verbes et ne baisse que tr&#232;s l&#233;g&#232;rement pour les
noms, quelle que soit la polys&#233;mie des cibles, alors que le rappel augmente, sans doute parce que les miroirs sont
plus susceptibles d&#8217;avoir une r&#233;ponse &#224; fournir sur les mots plus fr&#233;quents.
</p>
<p>5 Travaux reli&#233;s
</p>
<p>Plusieurs types de travaux peuvent &#234;tre compar&#233;s &#224; la pr&#233;sente &#233;tude, ayant des objectifs, des donn&#233;es en entr&#233;e et
des m&#233;thodologies d&#8217;&#233;valuation plus ou moins vari&#233;s. L&#8217;extraction de paraphrases partage certains de nos objectifs
et ressources, m&#234;me si elle concerne le rapprochement de termes comportant plus d&#8217;une unit&#233; lexicale. L&#8217;extraction
de synonymes, la construction de th&#233;saurus recouvrent aussi nos buts et peuvent &#234;tre &#233;valu&#233;s de fa&#231;on similaire.
</p>
<p>15. Ce test et est librement disponible &#224; l&#8217;URL http://www.cs.cmu.edu/~dayne/wbst-nanews.tar.gz</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE {MULLER,LANGLAIS}
</p>
<p>De fa&#231;on plus large, les nombreux travaux r&#233;cents sur la conception et la r&#233;alisation de mesures de similarit&#233;
s&#233;mantique peuvent &#234;tre rapproch&#233;s naturellement de la m&#233;thode pr&#233;sent&#233;e, m&#234;me si les objectifs sont diff&#233;rents.
</p>
<p>L&#8217;&#233;valuation de l&#8217;acquisition de paraphrases est souvent &#233;valu&#233;e par des jugements humains d&#8217;acceptabilit&#233; des
substitutions en contexte, ce qui limite &#224; des petits jeux de test. Barzilay &amp; McKeown (2001) rapportent que 90%
des paraphrases extraites par patrons (sur un corpus monolingue de traductions litt&#233;raires) sont acceptables, m&#233;-
langeant synonymes, hyperonymes et termes coordonn&#233;s, sans bien s&#251;r pouvoir donner une id&#233;e de la couverture
d&#8217;une telle m&#233;thode. En se fondant sur des alignements bilingues et une m&#233;thode similaire &#224; la n&#244;tre mais sur
plusieurs unit&#233;s lexicales, Bannard &amp; Callison-Burch (2005) estiment que les meilleurs paraphrases extraites pour
chaque cible sont valides dans 75% des cas avec un alignement parfait (48% avec un alignement automatique).
De m&#234;me Lin et al. (2003) ou Curran &amp; Moens (2002) &#233;valuent pr&#233;cis&#233;ment la pr&#233;sence de synonymes dans des
listes de similarit&#233; dans des petits ensembles de paires de synonymes ou antonymes, ce qui rend difficile une
extrapolation sur le genre de donn&#233;es que nous utilisons afin d&#8217;atteindre une large couverture.
</p>
<p>Plus proche de la m&#233;thodologie que nous avons suivie, on trouve des &#233;tudes qui &#233;valuent la classification de paires
de mots en synonymes ou non-synonymes. Cela peut &#234;tre fait directement sur les candidats s&#233;lectionn&#233;s pour un
ensemble de cibles, comme dans l&#8217;&#233;tude pr&#233;sente, ou sur des ensembles de test r&#233;&#233;chantillonn&#233;s pour augmenter
artificiellement la pr&#233;sence de paires positives et pouvoir appliquer des techniques standards de classification avec
une fiabilit&#233; raisonnable. Ne pas r&#233;&#233;chantillonner est plus r&#233;aliste mais donne des scores assez bas, comme nous
l&#8217;avons constat&#233; : (van der Plas &amp; Tiedemann, 2006) partent de vecteurs d&#8217;alignement &#224; la place des vecteurs
d&#8217;arguments syntaxiques de Lin, en d&#233;finissant la m&#234;me similarit&#233; et atteignent 12% de F-score par rapport &#224; leur
r&#233;f&#233;rence ; (Wu &amp; Zhou, 2003) fait de m&#234;me, ajoutant aussi une distance calcul&#233;e dans un graphe lexical issu
d&#8217;un dictionnaire, et apprend des r&#233;gressions lin&#233;aires des diff&#233;rents scores de similarit&#233;, tout en restreignant la
fr&#233;quence des cibles jusqu&#8217;&#224; obtenir un maximum de 23% sur les noms et 30% sur les verbes. On peut aussi men-
tionner (Heylen et al., 2008), qui analysent la r&#233;partition des fonctions lexicales dans des listes de similarit&#233;s de
mot en n&#233;erlandais. La seconde option, o&#249; l&#8217;on r&#233;&#233;chantillone &#224; l&#8217;entra&#238;nement et au test, est pertinente seulement
si l&#8217;on conna&#238;t un moyen de pr&#233;s&#233;lectionner naturellement les candidats pour atteindre la proportion suppos&#233;e, ce
qui n&#8217;est pas le cas pour les &#233;tudes existantes (Hagiwara et al., 2009). Notre &#233;tude peut en fait &#234;tre consid&#233;r&#233;e
comme une entr&#233;e pour des exp&#233;riences de ce genre.
</p>
<p>L&#8217;&#233;tude des similarit&#233;s distributionnelles faite par (Ferret, 2010), qui utilise de la cooccurrence simple, montre des
r&#233;sultats proches de ce que l&#8217;on obtient avec les miroirs, plus bas sur WordNet et comparables ou meilleurs sur
Moby. Il op&#232;re sur un jeu de test beaucoup plus large, sans distinguer les parties de discours, et le jeu de test est
d&#233;coup&#233; diff&#233;remment par rapport aux fr&#233;quences lexicales puisqu&#8217;il s&#233;lectionne les cibles et les candidats. Sur
WordNet il obtient au mieux 11% de R-pr&#233;cision et 17% pour la meilleure P@1 (sur les mots les plus fr&#233;quents).
Sur Moby, la meilleure R-pr&#233;cision est de 10% et la meilleure P@1 est de 41%, P@5 de 28%. Le rappel est
syst&#233;matiquement inf&#233;rieur (25% sur WordNet et 10% sur Moby), mais seuls 100 candidats sont gard&#233;s par cible.
Les r&#233;sultats sont plus bas que ce que l&#8217;on obtient ici avec les donn&#233;es de Lin, et nous pouvons donc supposer que la
comparaison que nous faisons est repr&#233;sentative de l&#8217;approche distributionnelle dans ce contexte. La combinaison
miroir et distribution est par contre sup&#233;rieure sur tous les scores sauf le rappel.
</p>
<p>Avec assez peu de r&#233;glage, on voit donc que l&#8217;approche des miroirs atteint des r&#233;sultats comparables ou meilleurs
que les similarit&#233;s d&#8217;alignement ou distributionnelle pour isoler des synonymes dans certaines configurations. Les
approches distributionnelles peuvent sans doute &#234;tre am&#233;lior&#233;es mais l&#8217;approche choisie semble repr&#233;sentative. Il
faut noter que le calcul qui sous-tend les traductions miroirs est computationnellement bien plus simple que les
calculs de similarit&#233; entre n&#215; n vecteurs d&#8217;alignement ou de cooccurrences, o&#249; n est la taille du vocabulaire.
On peut estimer que l&#8217;on peut atteindre un niveau de filtrage des candidats qui rend possible de tenter ensuite
la classification des paires restantes. D&#8217;apr&#232;s (Hagiwara et al., 2009) 16 , on peut associer (par classification) une
fonction lexicale de fa&#231;on fiable &#224; des paires de mots si la proportion de candidats effectivement &#224; relier par rapport
&#224; ceux qui n&#8217;ont aucun lien peut atteindre un ratio de 1 pour 6. Une conclusion similaire est tir&#233;e par (Piasecki et al.,
2008) dans le cas de la d&#233;tection d&#8217;hyperonymie. Nos r&#233;sultats nous encouragent &#224; penser que l&#8217;on peut atteindre
une proportion de 1 pour 4 ou 5. L&#8217;&#233;tude cit&#233;e ne pr&#233;cise pas la proportion de paires de mots synonymes/non
synonymes de d&#233;part, mais si on prend les chiffres de (Ferret, 2010), il y a 30000 paires de synonymes sur un
vocabulaire de r&#233;f&#233;rence de 10000 mots, donc pour environ 50M de paires possibles, soit une proportion de 0,06%
de paires de synonymes ou un ratio de 1 pour 1600.
</p>
<p>16. (Hagiwara et al., 2009) utilise comme descripteurs des sch&#233;mas syntaxiques et des vecteurs de cooccurrence.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMPARAISON D&#8217;UNE APPROCHE MIROIR ET D&#8217;UNE APPROCHE DISTRIBUTIONNELLE POUR L&#8217;EXTRACTION
DE MOTS RELI&#201;S
</p>
<p>Une autre fa&#231;on de juger de la pertinence des mesures de similarit&#233; s&#233;mantique entre mots d&#233;rive des donn&#233;es
collect&#233;es par (Miller &amp; Charles, 1991) o&#249; on demande &#224; des sujets de juger la similarit&#233; ou le lien entre des items
lexicaux, sur une &#233;chelle num&#233;rique. C&#8217;est une fa&#231;on int&#233;ressante de fournir une &#233;valuation intrins&#232;que de ces
associations, mais le jeu de test ne peut couvrir qu&#8217;une part tr&#232;s limit&#233;e du vocabulaire (300 mots environ, avec 2
ou 3 associations par mot au plus).
</p>
<p>6 Conclusion
</p>
<p>Nos exp&#233;riences confirment la vari&#233;t&#233; des relations lexicales que l&#8217;on peut r&#233;cup&#233;rer en appliquant ce que l&#8217;on a
usage d&#8217;appeler des mesures de similarit&#233; s&#233;mantique. Les deux approches que nous avons &#233;tudi&#233;es ici semblent
corr&#233;l&#233;es aux ressources de r&#233;f&#233;rence que nous avons consid&#233;r&#233;es.
</p>
<p>En ce qui concerne les synonymes, nos exp&#233;riences indiquent que les traductions miroir offrent des candidats plus
pertinents que l&#8217;approche distributionnelle de Lin (1998). Dans la mesure o&#249; les approches miroir ne sont pas aussi
pris&#233;es que les approches distributionnelles, nous esp&#233;rons que cette &#233;tude contribuera &#224; en montrer l&#8217;int&#233;r&#234;t pour
l&#8217;acquisition de relations lexicales. Nous soulignons de plus que l&#8217;approche miroir est beaucoup moins co&#251;teuse
&#224; d&#233;velopper et &#224; appliquer, pour autant que l&#8217;on soit en mesure de trouver des bitextes de taille suffisante mettant
en jeu la langue d&#8217;int&#233;r&#234;t. Patry &amp; Langlais (2011) dressent un portrait des bitextes existants qui indique que de
telles ressources sont de plus en plus disponibles pour de nombreuses paires de langues.
</p>
<p>L&#8217;approche miroir que nous avons mise en place ne tire pas profit du fait que plusieurs bitextes mettant en jeu la
langue d&#8217;int&#233;r&#234;t sont disponibles. C&#8217;est par exemple le cas pour la langue fran&#231;aise pour laquelle les bitextes des
d&#233;bats parlementaires europ&#233;ens sont disponibles en plus du bitexte que nous avons mis profit ici. L&#8217;ajout de telles
ressources devrait &#234;tre en mesure d&#8217;augmenter les performances (et la pr&#233;cision en particulier) de notre approche.
</p>
<p>La compl&#233;mentarit&#233; des approches test&#233;es dans cette &#233;tude am&#232;ne &#224; nous interroger sur la mani&#232;re optimale de les
combiner. La simple intersection que nous avons &#233;tudi&#233;e ici am&#233;liore nettement la pr&#233;cision des listes candidates.
Une approche plus originale consisterait &#224; combiner ces approches avec une approche par patron telle que celle
de (Barzilay &amp; McKeown, 2001). Le probl&#232;me de la polys&#233;mie discut&#233; en section 4.3 demeure un probl&#232;me pour
toutes les approches dont nous avons discut&#233;, en particulier lorsque deux sens d&#8217;une entit&#233; lexicale sont fr&#233;quents
en corpus. Il semble souhaitable d&#8217;int&#233;grer l&#8217;apport de m&#233;thodes qui vise &#224; rep&#233;rer des groupes de sens &#233;quivalents
multilingues, comme par exemple dans (Apidianaki, 2008).
</p>
<p>Il n&#8217;en reste pas moins que notre objectif &#224; moyen terme est de distinguer automatiquement la nature des diff&#233;-
rentes relations lexicales identifi&#233;es. Cette information est pertinente dans bon nombre d&#8217;applications (paraphra-
sage, choix d&#8217;une traduction, etc.). Des travaux comme ceux de (Hagiwara et al., 2009) tendent &#224; indiquer qu&#8217;il
est envisageable d&#8217;entra&#238;ner de mani&#232;re supervis&#233;e un classificateur &#224; reconna&#238;tre certaines fonctions lexicales,
pour autant que la proportion de candidats d&#8217;une classe particuli&#232;re soit plus &#233;quilibr&#233;e que dans les distributions
naturelles. Ceci indique qu&#8217;il faut &#234;tre en mesure d&#8217;affiner la liste de candidats, ce que notre approche par filtrage
ou combinaison r&#233;alise.
</p>
<p>Remerciements
</p>
<p>Nous remercions les relecteurs pour la pertinence de leurs commentaires.
</p>
<p>R&#233;f&#233;rences
</p>
<p>APIDIANAKI M. (2008). Translation-oriented Word Sense Induction Based on Parallel Corpora. In Actes de
LREC Language Resources and Evaluation (LREC), p. 3269&#8211;3275, Marrakech Maroc.
</p>
<p>BANNARD C. &amp; CALLISON-BURCH C. (2005). Paraphrasing with bilingual parallel corpora. In Proceedings of
the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&#8217;05), p. 597&#8211;604.
</p>
<p>BARZILAY R. &amp; MCKEOWN K. R. (2001). Extracting paraphrases from a parallel corpus. In Proceedings of
the 39th Annual Meeting of the Association for Computational Linguistics.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>PHILIPPE {MULLER,LANGLAIS}
</p>
<p>CURRAN J. R. &amp; MOENS M. (2002). Improvements in automatic thesaurus extraction. In Proceedings of the
ACL-02 Workshop on Unsupervised Lexical Acquisition, p. 59&#8211;66.
</p>
<p>DYVIK H. (2002). Translations as semantic mirrors : From parallel corpus to wordnet. In The Theory and Use
of English Language Corpora, ICAME 2002. http ://www.hf.uib.no/i/LiLi/SLF/Dyvik/ICAMEpaper.pdf.
</p>
<p>EDMONDS P. &amp; HIRST G. (2002). Near-Synonymy and lexical choice. Computational Linguistics, 28(2),
105&#8211;144.
</p>
<p>FERRET O. (2010). Testing semantic similarity measures for extracting synonyms from a corpus. In Proceedings
of LREC 2010.
</p>
<p>FREITAG D., BLUME M., BYRNES J., CHOW E., KAPADIA S., ROHWER R. &amp; WANG Z. (2005). New expe-
riments in distributional representations of synonymy. In Proceedings of CoNLL, p. 25&#8211;32.
</p>
<p>HAGIWARA M., OGAWA Y. &amp; TOYAMA K. (2009). Supervised synonym acquisition using distributional fea-
tures and syntactic patterns. Journal of Natural Language Processing, 16(2), 59&#8211;83.
HEYLEN K., PEIRSMAN Y., GEERAERTS D. &amp; SPEELMAN D. (2008). Modelling Word Similarity. An Evalua-
tion of Automatic Synonymy Extraction Algorithms. In Proceedings of LREC 2008, p. 3243&#8211;3249 : ELRA.
</p>
<p>KOZIMA H. &amp; FURUGORI T. (1993). Similarity between words computed by spreading activation on an english
dictionary. In Proceedings of the conference of the European chapter of the ACL, p. 232&#8211;239.
</p>
<p>LIN D. (1998). Automatic retrieval and clustering of similar words. In COLING/ACL98, volume 2, p. 768&#8211;774,
Montreal.
</p>
<p>LIN D., ZHAO S., QIN L. &amp; ZHOU M. (2003). Identifying synonyms among distributionally similar words. In
Proceedings of IJCAI&#8217;03, p. 1492&#8211;1493.
</p>
<p>MAX A. &amp; ZOCK M. (2008). Looking up phrase rephrasings via a pivot language. In Coling 2008 : Proceedings
of the Workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), p. 77&#8211;85.
</p>
<p>MICHIELS A. &amp; NOEL J. (1982). Approaches to thesaurus production. In Proceedings of Coling&#8217;82.
</p>
<p>MILLER G. &amp; CHARLES W. (1991). Contextual correlates of semantic similarity. Language and Cognitive
Processes, 6(1), 1&#8211;28.
MOORE R. C. (2004). Improving IBM word alignment model 1. In 42nd Meeting of the Association for
Computational Linguistics (ACL), p. 518&#8211;525.
</p>
<p>MULLER P. &amp; LANGLAIS P. (2010). Comparaison de ressources lexicales pour l&#8217;extraction de synonymes. In
Article court au 17e TALN, Montr&#233;al, Canada.
</p>
<p>NIWA Y. &amp; NITTA Y. (1994). Co-occurrence vectors from corpora vs. distance vectors from dictionaries. In
Proceedings of Coling 1994.
</p>
<p>PATRY A. &amp; LANGLAIS P. (2011). PARADOCS : l&#8217;entremetteur de documents parall&#232;les ind&#233;pendant de la
langue. TAL, 51-2, pp. 41-63.
PIASECKI M., SZPAKOWICZ S., MARCIN&#769;CZUK M. &amp; BRODA B. (2008). Classification-based filtering of
semantic relatedness in hypernymy extraction. In A. RANTA &amp; B. NORDSTR&#214;M, Eds., GoTAL 2008, number
5221 in LNAI, p. 393&#8211;404 : Springer.
</p>
<p>TURNEY P. (2008). A uniform approach to analogies, synonyms, antonyms, and associations. In Proceedings of
the 22nd International Conference on Computational Linguistics (Coling 2008).
</p>
<p>VAN DER PLAS L. &amp; TIEDEMANN J. (2006). Finding synonyms using automatic word alignment and measures
of distributional similarity. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, p. 866&#8211;
873.
</p>
<p>WEEDS J. E. (2003). Measures and Applications of Lexical Distributional Similarity. PhD thesis, University of
Sussex.
</p>
<p>WU H. &amp; ZHOU M. (2003). Optimizing synonyms extraction with mono and bilingual resources. In Proceedings
of the Second International Workshop on Paraphrasing.
</p>
<p>ZHITOMIRSKY-GEFFET M. &amp; DAGAN I. (2009). Bootstrapping distributional feature vector quality. Computa-
tional Linguistics, 35(3), 435&#8211;461.</p>

</div></div>
</body></html>