TALN 2011, Montpellier, 27juin — 1"'jui11et 2011

Comparaison d’une approche miroir et d’une approche distributionnelle
pour l’extraction de mots sémantiquement reliés

Philippe Mullerlr 2 Philippe Langlais3
(1) IRIT, Université Paul Sabatier
(2) Alpage, INRIA Paris-Rocquencourt
(3) RALI / DIRO / Université de Montréal
muller@irit.fr, felipe@iro.umontreal.ca

Résumé. Dans (Muller & Langlais, 2010), nous avons compare une approche distributionnelle et une va-
riante de l’approche miroir proposée par Dyvik (2002) sur une tache d’extraction de synonymes a partir d’un
corpus en francais. Nous présentons ici une analyse plus ﬁne des relations extraites automatiquement en nous
intéressant cette fois—ci a la langue anglaise pour laquelle de plus amples ressources sont disponibles. Différentes
fagons d’évaluer notre approche corroborent le fait que l’approche miroir se comporte globalement mieux que
l’approche distributionnelle décrite dans (Lin, 1998), une approche de reference dans le domaine.

Abstract. In (Muller & Langlais, 2010), we compared a distributional approach to a variant of the mir-
ror approach described by Dyvik (2002) on a task of synonym extraction. This was conducted on a corpus of
the French language. In the present work, we propose a more precise and systematic evaluation of the relations
extracted by a mirror and a distributional approaches. This evaluation is conducted on the English language for
which widespread resources are available. All the evaluations we conducted in this study concur to the observation
that our mirror approach globally outperforms the distributional one described by Lin (1998), which we believe to
be a fair reference in the domain.

M0tS-CléS 3 Sémantique lexicale, similarité distributionnelle, similarité traductionnelle.

Keywords: Lexical Semantics, distributional similarity, mirror approach.

1 Introduction

Collecter les relations entre les entités lexicales en vue de construire ou de consolider un thesaurus est une activité
qui possede une longue tradition en traitement des langues. Les efforts les plus importants ont été dédiés a la
recherche de synonymes, ou plus exactement des “quasi—synonymes” (Edmonds & Hirst, 2002), c’est—a—dire des
entrees lexicales ayant un sens similaire dans un contexte donné. D’autres relations comme l’antonymie, l’hyper—
onymie, l’hyponymie, la méronymie ou l’holonymie ont également été étudiées. Certains thesaurus, comme Moby
que nous utilisons ici, listent de plus des relations qui sont difﬁciles a caractériser.

De nombreuses ressources ont été utilisées pour parvenir a acquérir de tels thesaurus. Les dictionnaires electro-
niques ont tout d’abord été investis, soit pour en extraire des relations sémantiques au niveau lexical (Michiels &
Noel, 1982), soit pour déﬁnir des mesures de similarité sémantiques entre les entités lexicales (Kozima & Furu-
gori, 1993). L’analyse distributionnelle, qui compare les mots a travers leur contexte d’usage, est également une
ressource populaire pour la realisation d’une mesure de similarité sémantique (Niwa & Nitta, 1994; Lin, 1998).

Plusieurs approches ont montré l’intéret d’utiliser des corpus dans plusieurs langues et plus particulierement des
corpus paralleles. Dans ces travaux, les entrees lexicales sont dites similaires lorsqu’elles sont alignées avec les
memes traductions dans une autre langue (van der Plas & Tiedemann, 2006; Wu & Zhou, 2003). Une variante
de ce principe proposée par Dyvik (2002) considere comme sémantiquement reliés les mots d’une langue qui
sont traduction d’un meme mot dans une autre langue; ces mots sont appelés par l’auteur des traductions miroir.
Des variantes de cette approche ont été étudiées pour l’acquisition de paraphrases, qui porte sur des associations
d’ expressions de plusieurs mots : voir par exemple (Bannard & Callison—Burch, 2005) et (Max & Zock, 2008).

Les evaluations des travaux a base de similarité lexicale sont souvent décevantes : différents types de relations
lexicales sont typiquement identiﬁes, qu’il est difﬁcile de distinguer automatiquement. Des travaux comme ceux

PHILIPPE {MULLER,LANGLAIS }

de Zhitomirsky-Geffet & Dagan (2009) tentent dans une étape de post—traitement de selectionner les relations les
plus pertinentes qui caracterisent des paires de mots similaires. D’autres, comme Wu & Zhou (2003) tentent de
combiner le résultat de différents processus d’ extraction de mots relies (approche distributionnelle, dictionnaires,
etc.).

Notre etude s’inscrit dans ce demier courant. Nous poursuivons l’etude amorcée par Muller & Langlais (2010)
ou une variante de Dyvik, faisant usage de modeles de traduction statistiques entrainés sur de grands volumes de
données, est combinée a une approche distributionnelle. Contrairement a ce travail, nous nous intéressons ici a la
langue anglaise pour laquelle des ressources sont disponibles en plus grand nombre. Ceci nous permet de mener
une evaluation a l’état de l’art de l’approche miroir, que nous comparons au thesaurus produit par l’approche
decrite dans (Lin, 1998) et que Lin tient a la disposition de la communauté. Nous montrons que l’approche miroir
se comporte favorablement par rapport a l’approche distributionnelle, et ce, selon differentes evaluations que nous
avons menées.

Dans la suite de cet article, nous presentons les ressources mises a proﬁt en section 2 et notre protocole experi-
mental en section 3. Nous analysons nos resultats en section 4 et discutons les travaux relies en section 5. Nous
concluons cette etude et en dressons les perspectives en section 6.

2 Ressources

Nous avons utilise deux bases lexicales dans ce travail :

— La base lexicale WordNet1 que nous interrogeons a travers l’API de NLTK2. WordNet encode les relations de
synonymie (gain / acquire), d’antonymie (gain / lose), d’hyperonymie/l1yponymie (odor / stench)
et d’holonymie/méronymie (wood / tree). Chaque entree lexicale dans WordNet possede une moyenne de 5
a 6 synonymes et de 8 a 10 termes relies, toutes relations confondues.

— Le thesaurus Moby 3 est une ressource plus étoffée que WordNet : chaque mot dispose en effet d’environ 80
mots relies en moyenne. La nature des relations n’est cependant pas armotée.

Aﬁn de comparer les approches miroir et distributionnelle, nous avons sélectionné de maniere aléatoire deux

ensembles de 1000 mots, un pour les noms et un pour les verbes. Nous appelons ces mots les “cibles” dans la suite.

Nous avons impose arbitrairement un seuil minimal de fréquence sur les mots cibles (> 1000). La frequence des

mots a eté calculée a l’aide du corpus libre de droit Wacky 4, qui compte 2 milliards de mots. Les caracteristiques

des deux ensembles de cibles ainsi constr11its sont decrites en table 1.

nombre d’associations

Pos fréquence médiane reference moyen median min max
Noms 3 538 WordNet syns 3,63 2 1 36
Noms 3 538 Moby 73,87 57 3 509
Verbes 11 136 WordNet syns 5,57 4 1 47
Verbes 11 136 Moby 113,23 90 6 499

TABLE 1 — Caracteristiques des deux ensembles de cibles (noms et verbes) : frequence médiane dans Wacky,
nombre moyen de termes associés selon la reference speciﬁee, nombre median, minimum et maximum.

3 Protocole

Nous comparons les termes similaires produits soit par l’approche des miroirs (section 3.1), soit par l’approche
distributionnelle (section 3.2). Chaque approche produit un ensemble de termes associés ou candidats, classes
selon leur degré de similarite. Ces candidats ordonnés sont alors évalués au regard d’une ressource de reference

. wordnet .princeton . edu/wordnet

. www .nltk . org

. www . gutenberg . org/dirs/etext02/mtheslo . zip
. http: //wacky . sslmit . unibo . it/Cloku .php

-BU)l\)>—A

COMPARAISON D’UNE APPROCHE MIROIR ET D’UNE APPROCHE DISTRIBUTIONNELLE POUR L’ExTRAcT10N
DE MOTS RELIES

(WordNet ou Moby), soit en gardant les n—meilleurs candidats, soit en gardant ceux dont le score de similarité
dépasse un certain seuil (voir les details plus loin).

A titre d’exemple, la ﬁgure l montre les candidats proposes par les deux approches pour le mot cible choisi
aléatoirement groundwork. On observe la grande difference de couverture de WordNet et de Moby.

Candidats Miroir Candidats Lin WordNet Moby

Q preparation lg arrangement
Q framework % base
foundation timetable cornerstone basement
land rationale foot basis
ground impetus fundament bed

job modality foundation bedding
ﬁeld foundation substructure bedrock
plan prerequisite understructure bottom
force precondition brieﬁng
development blueprint cornerstone

 [47 de plus]

FIGURE 1 — Dix premiers candidats proposes par les approches miroirs et distributionnelles pour le mot cible
groundwork. Les synonymes selon WordNet ainsi qu’un sous ensemble des mots relies selon Moby sont indi-
ques. Les candidats soulignés appartiennent a WordNet, tandis que ceux en gras sont presents dans Moby.

3.1 Approche miroir

L’ approche miroir est fondée sur l’hypothese que des mots d’une langue 8 qui sont frequemment alignés avec
le meme mot dans une autre langue .7-‘ sont semantiquement proches. Dans l’exemple de la ﬁgure 2, les mots
francais manger et consommer sont tous les deux alignes avec le mot anglais eat et sont donc candidats a
l’appariement semantique.

Un bebe mange toutes les deux heures.
Babies eat every two hours.
Canadians eat too much poutine.

Les Canadiens consomment trop de poutine.

FIGURE 2 — Exemple de traductions miroir.

Notre variante de l’approche miroir repose sur la consultation de deux modeles de traduction statistique peg; et
p fge qui donnent respectivement la probabilité qu’un mot frangais soit la traduction d’un mot anglais et la proba-
bilité inverse. Nous calculons la vraisemblance qu’un mot anglais s (pour synonyme) soit relié sémantiquement a
un mot anglais W, soit p(s|w) :

P(S|W) W Z P§§f(f|W) >< P‘,s%e(S|f) 7'e2f(W) = if I Pe2f(f|W) > 0}
fE7'e2f(w)

Ici 7'e2f(w) désigne l’ensemble des mots frangais associes par le modele peg; au mot anglais w. En pratique,
les distributions lexicales utilisées étant bruitees, nous appliquons deux seuils 61 et 62 (ﬁxes a 0.001 dans cette
experience) qui ﬁltrent les associations peu probables d’un modele :

pfms) = { 3-W8) :;::,-SW Z 5

D’autres facons de ﬁltrer les tables de transfert pourraient etre deployees. Nous pourrions par exemple utiliser un
test de signiﬁcativité aﬁn de retenir les associations les plus pertinentes. Notre approche au ﬁltrage est certainement
perfectible mais présente l’avantage d’etre particulierement simple a mettre en oeuvre.

PHILIPPE {MULLER,LANGLAIS }

Les modeles lexicaux pegf et p fge ont eté entrainés sur un bitexte anglais—frangais de 8,3 millions de paires de
phrases extraites des transcriptions des debats parlementaires canadiens (Hansard). Ce bitexte est exploité par le
concordancier bilingue TSRali 5. Nous avons lemmatisé les phrases anglaises et frangaises du corpus a l’aide de
TreeTager 5 avant d’ entrainer dans les deux directions7 (anglais—>frangais et frangais—>anglais) des modeles
IBM 4 a l’aide de Gi za++ 8 utilise dans sa conﬁguration par defaut.

Dans l’éValuation qui suit, nous avons considére les 200 premiers lemmes associés a chaque mot cible par cette
approche car c’est le nombre de candidats que produit l’approche distributionnelle que nous avons testee (Voir la
section suivante).

3.2 Similarité distributionnelle

L’ approche distributionnelle que nous utilisons est celle décrite par Lin (1998). Elle représente selon nous une
approche de reference dans le domaine. Un thesaurus calculé par l’auteur a l’aide de cette méthode est disponible
gratuitement 9 .

Pour l’obtenir, Lin a fait usage d’ un analyseur grammatical en dependance aﬁn de comptabiliser les occurrences
de triplets (lemme_de_téte, relation, lemme_dépendant) ou relation est une relation (syn-
taxique) de dependance. A chaque lemme w est associe un Vecteur de compte pour l’ensemble F(w) des traits
(rel , autre_l emme) ou autre_l emme est soit un dependant de w, soit un gouvemeur de w.

Par exemple, le Verbe eat est caractérisé par un ensemble de traits F(eat) contenant (ha s_subj , man) ,
(has_obj , fries) , (has_obj , pie) , etc qui correspondent aux contextes syntaxiques de eat. Appelons
c la fonction de comptage d’occurrence d’un triplet (w, rel, w’) et V l’ensemble du Vocabulaire, on pose :

c(w,rel,w’) x c(_, rel,_)
cbreliw) = wgVc(wl,T.el,w) I(w’Tel’wl) = log c(w,rel,—) >< c(_,rel,w’)
c(w,1"el,_) = Z c(w,1"el,w')
w’EV
c(_,1"el,_) = Z c(_,rel,w')  = Z I(w, 1", w’)
w’EV (r,w’)EF'(w)

I (w, rel, w’ ) est alors la spéciﬁcité d’une relation (w, rel, w’), deﬁnie comme l’information mutuelle e11tre les
elements du triplet (Lin, 1998). On note  la quantité d’information totale associée a W. La similarité entre
deux lemmes w1 et ’LU2 mesure alors a quel point ils partagent des contextes syntaxiques spéciﬁques, en utilisant la
quantité d’information des contextes qu’ils partagent, normalisée par la quantite d’information totale qu’on peut
leur associer séparément.

Z(T,w)EF(w1)nF(w2) [I(w1, 1", w) + I(w2,1",w)]

simw w =
‘ 1’ 2) ||w1||+||w2||

D’apres (Lin et al., 2003), le corpus utilise pour obtenir le thesaurus que nous avons utilise ici serait de 3 milliards
de mots, c’est—a-dire plus de 10 fois la taille du corpus que nous avons utilise pour developper l’approche miroir.
ll nous est apparu preferable de prendre ce thesaurus plutot que de tester notre implementation de l’approche
que nous Venons de decrire en particulier parce que nous ne disposons pas d’information sur les reglages des
parametres utilises par les auteurs pour optimiser leurs sorties. En fait, notre implementation de l’approche est
de moins bonne qualité sur les jeux de tests que nous présentons que ceux obtenus a l’aide du thesaurus com-
pile par les auteurs. A tout le moins, nous soulignons que la comparaison de l’approche miroir avec l’approche
distributionnelle n’est pas biaisée en faveur de l’approche miroir.

Le thesaurus calculé par Lin presente pour chaque mot cible les 200 lemmes les plus proches au sens de cette
mesure de similarité.

.http://www.tsrali.com/
.www.ims.uni—stuttgart.de/projekte/corplex/TreeTagger/
. Les modéles [BM ne sont pas symétriques.

. fjoch . com/GIZA++ . html
.webdocs.cs.ualberta.ca/~lindek/Downloads/sim.tgz

\OOO\lO\UI

COMPARAISON D’UNE APPROCHE MIROIR ET D’UNE APPROCHE DISTRIBUTIONNELLE POUR L’EXTRACTION
DE MOTS RELIES

4 Expériences

En suivant le protocole décrit plus haut, nous avons évalué la sortie des deux similarités (miroir et distribution-
nelle) en considérant soit les n—meilleurs candidats de chaque approche, soit en considerant ceux dont le score de
similarité dépasse un seuil donné (que nous faisons varier). Nous avons séparé notre jeu de test en deux ensembles
de maniere a mesurer les differences entre les noms et les verbes : comme le montre la table 1, le nombre de
synonymes et autres entités lexicales reliées varie fortement en fonction de la catégorie morpho—syntaxique.

Nous avons considéré lors de l’évaluation les seuls items communs a la reference et au lexique de la ressource
utilisée pour le développement d’une mesure de similarite. Par exemple, WordNet contient des synonymes qui
ne sont pas presents dans les Hansards que nous avons mis a proﬁt pour développer l’approche miroir : ils sont
simplement écartés de notre evaluation.

Les deux approches que nous comparons sont sensibles a la fréquence des mots cibles considérés. Dans les deux
approches décrites, tous les sens d’un mot sont regroupés lors des calculs de la similarité et il est Vraisemblable
que les usages les plus frequents dominent les autres dans ces calculs. Sachant qu’un mot frequent a plus de chance
d’etre polysémique qu’un autre, nous souhaitions prendre en consideration dans notre evaluation l’inﬂuence de la
fréquence des mots cibles étudiés. Nous ﬁltrons a cet effet les candidats dont la fréquence (telle que calculée a
l’aide de Wacky) est inférieure a un seuil donné, pour un ensemble de ces valeurs seuils.

11 a été montré (Weeds, 2003) que la plupart des méthodes de similarite lexicale se comportent de fagon tres
différente par rapport a ce critere, sélectionnant selon les réglages plutot des mots frequents ou plutot des mots
rares.

Nous avons remarqué la tendance de l’approche miroir a souvent proposer des mots “vides”. Cela s’explique par
le fait que ces mots sont souvent biens notes par les distributions lexicales que nous utilisons. Ce phénomene a
été analyse notarmnent dans (Moore, 2004). Nous avons arbitrairement éliminé des listes de candidats miroirs les
termes apparus dans plus de 25% des listes (ce seuil pourrait etre ajusté a l’aide d’un corpus de développement).
Ce ﬁltre élimine des noms courants comme thing ou way, des verbes comme have, be ou come, ainsi que des
mots sur—représentés dans les Hansards (ex. : house).

Au ﬁnal, nous avons combine les listes candidates produites par les deux approches en prenant l’intersection des
deux listes. D’autres schémas de combinaison seront étudiés dans des travaux ultérieurs.

Deux aspects nous intéressent plus particulierement dans cette experience : la quantité de mots relies dans la
reference que nous sommes capables d’identiﬁer par l’une des approches et la ﬁabilité avec laquelle ils sont
identiﬁes. En d’autres termes, nous voulons que la tete de liste des candidats soit la meilleure possible au regard
d’une liste de reference. Nous évaluons donc les deux approches a l’aide des taux de precision et de rappel 10 que
nous mesurons en différents points. Nous résumons ces taux a l’aide des taux MAP (Mean Average Precision) et
MRR (Mean Reciprocal Rank) couramment employés en recherche d’information. MAP calcule la precision en
chaque point de la liste ou un candidat pertinent est identiﬁé; MRR est calcule comme la moyenne de l’inverse
des rangs du premier terme pertinent dans la liste.

Enﬁn, nous avons egalement calcule la precision de chaque approche en faisant l’hypothese d’un “oracle” qui
indique le nombre exact de candidats a proposer pour chaque mot cible (il s’agit dans notre cas du nombre de
mots relies dans la reference). Cette mesure est semblable a ce que l’on appelle la R—précision. Par exemple, les 10
candidats de la méthode des miroirs de la ﬁgure 1, évalués a 1’ aide de la reference WordNet, regoivent une precision
de 3/10, un rappel de 3/5 (et pas 3/8 car les mots understructure, substructure et fundament sont
absents des Hansards). La R—précision est également de 3/5 car tous les candidats corrects sont proposes a un rang
inférieur au nombre de mots relies dans la reference (5 synonymes). La precision au rang 1 est de 1, alors que la
precision au rang 5 est de 3/5. Finalement, le taux MAP est de 0,63 = 6,29/10 = (1/1 + 2/2 + 3/3 + 3/4 + . . .+ 3/10)
/ 10 alors que MRR est de 1 car le premier candidat est correct; il serait de 1/2 si seulement le second candidat
avait été correct, etc.

11 est apparu empiriquement qu’il était preferable de couper une liste candidate a un rang donné que d’essayer de
seuiller en fonction d’un score de similarité, et nous détaillons donc uniquement par la suite les résultats avec la
premiere méthode, en faisant varier le rang.

10. Que nous présentons sous forme de pourcentage pour plus de lisibilité.

PHILIPPE {MULLER,LANGLAIS }

4.1 WordNet

La table 2 montre les résultats pour les noms evalues selon les synonymes de WordNet. Pour chaque approche,
nous indiquons les précisions aux rangs n=l, ..., 100 dans les listes candidates, les taux MAP, MRR, la R—precision,
le nombre de synonymes dans la reference (||ref||) et le rappel global, pour les 200 premiers candidats de
chaque methode 11. Nous rapportons également l’inﬂuence de djfférents ﬁltres de fréquence. La ligne f>1000,
par exemple, indique que nous retenons des listes candidates et de la reference les seuls mots dont la fréquence
(dans Wacky) est superieure a 1000.

n—meilleur(s) P1 P5 P10 P20 P100 MAP MRR R—prec ||ref rappel

f>l 16,4 5,1 3,8 2,7 1,3 11,9 15,1 16,6 2342 50,0
f>5000 19,1 5,4 3,8 2,6 1,2 11,3 13,2 17,5 1570 54,8

Miroir f>20000 22,1 5,7 3,9 2,5 1,1 9,8 11,4 22,7 1052 60,6
f>l 17,4 5,2 3,5 2,5 1,5 11,7 14,3 14,7 2342 35,9
Lin f>5000 16,5 5,0 3,5 2,5 1,6 9,2 10,8 16,7 1570 36,6
f>20000 17,5 4,5 3,3 2,5 1,6 7,3 8,4 20,1 1052 36,9
f>l 25,8 7,5 5,7 4,4 3,8 15,9 17,6 22,0 2342 29,3
M/L f>5000 27,4 7,4 5,5 4,3 3,8 12,7 13,6 24,6 1570 31,1

f>20000 26,1 6,4 4,7 3,5 2,6 9,7 10,4 28,9 1052 32,7

TAB LE 2 — Résultats pour les noms, micro—moyennés, avec les synonymes de WordNet pour reference.

Comme WordNet repertorie peu de synonymes, les precisions a faible rang (1 et 5) sont les plus pertinentes, ainsi
que la R—precision : les autres sont necessairement tres basses. Les autres mesures sont données a des ﬁns de
comparaison car elles sont plus pertinentes pour la reference Moby. Ceci étant note, la table 2 amene plusieurs
commentaires 12.

Premierement, nous observons que la precision de l’approche miroir au rang 1 culmine a 22% alors que le rappel
plafonne a un peu plus de 60% : un bien meilleur résultat combine que 1’ approche distributionnelle que nous avons
testée (moins de 18% de précision au rang 1 et moins de 37% de rappel). Deuxiemement, il apparait clairement
que ﬁltrer les candidats les moins frequents est beaucoup plus payant pour l’approche miroir 13. C’est sans doute la
consequence d’un corpus de depart plus petit, pour lequel les occurrences rares de mots peu frequents entrainent
des probabilités d’alignement peu ﬁables. Troisiemement, nous observons que notre combinaison des deux ap-
proches, aussi simpliste soit—elle, s’accompagne d’une augmentation signiﬁcative de la précision, notamment la
R-precision (au detriment cependant du rappel).

Enﬁn, les résultats sur les Verbes sont similaires a ceux présentes ici pour les noms, avec cependant une meilleure
precision a rang faible et un compromis sur la frequence de coupure plus elevé, et ce, meme si la precision oracle
est globalement la meme pour toutes les conﬁgurations. Combiner les deux méthodes ameliore la précision de
maniere similaire a ce que nous observons sur les noms, avec une precision oracle qui Varie cette fois entre 20%
et 27%. Les differences sont toutes signiﬁcatives sauf cette fois sur P1 a frequence elevee.

Nous ne montrons pas le detail des scores si on ajoute dans la reference les relations issues de toutes les fonctions
lexicales de WordNet, mais on peut noter que les resultats sont tres proches entre les deux méthodes sur les noms
(R—precw13% et P@1=23% quand f>l). En revanche, les traductions miroirs sont légerement meilleures sur les
Verbes en R—précision (16% contre 18% pour f>1 et 17% contre 21% pour f>20000 ), et inférieures en terme de
precision au rang 1 (41% contre 37% pour f>1 a 33% contre 34%).

Nous montrerons en section 4.3 que la difference semble se jouer essentiellement sur les relations de synonymie
et d’hyperony1nie (et hyponymie).

11. Les candidats dc Lin étant limités 5. cc nombre.

12. Sauf précision contraire, les différences entre méthodcs discutées plus bas sont tous signiﬁcatives 5 p<0.05. Pour toutes les mesures sauf
P1 et le rappel global, nous avons utilisé le test de Wilcoxon sur les résultats mot par mot. Dans le cas de P1 qui donne un résultat binaire par
cible, nous avons fait un test binomial.

13. Les différences signiﬁcatives dc précision ct MAP entre les deux méthodes n’apparaissent que pour les valeurs dc fréquence élevée.

COMPARAISON D’UNE APPROCHE MIROIR ET D’UNE APPROCHE DISTRIBUTIONNELLE POUR L’EXTRACTION
DE MOTS RELIES

4.2 Moby

La table 3 resume les résultats des deux approches pour les noms, en prenant cette fois-ci Moby pour reference.
Les relations listées dans ce thesaurus étant du tout venant, nous nous attendions a ce que la reference soit plus
proche des sorties produites par une approche distributionnelle. Nous observons que c’est bien le cas sur les noms :
la precision de l’approche de Lin est systématiquement supérieure a celle des n1iroirs, avec presque 10 points de
plus au rang 1 ; et ce, meme si le rappel est legerement en faveur de l’approche miroir. Sur les verbes, cependant,
les deux approches se comportent de maniere comparable. En observant la difference de scores de precision entre

n—meilleur(s) P1 P5 P10 P20 P100 MAP MRR R—prec ||ref rappel

f>1 33,7 15,8 13,3 11,0 7,0 18,5 40,1 11,0 60774 18,1
f>5000 32,7 14,5 12,1 9,8 6,1 18,7 38,1 11,8 43294 21,6

Mimi‘ f>20000 30,3 13,2 10,7 8,6 5,3 18,1 34,9 12,8 28488 26,7
f>1 44,8 19,9 16,4 13,4 9,5 26,6 46,8 14,7 60774 15,4
Lin f>5000 40,7 18,5 15,0 12,5 9,3 25,6 41,6 15,0 43294 16,3
f>20000 39,4 16,1 13,5 11,2 8,4 23,3 35,2 16,8 28488 16,8
f>1 53,1 25,1 21,4 18,1 35,2 46,6 22,9 25,0 60774 9,4
M/L f>5000 52,4 23,0 19,3 16,6 13,7 30,7 41,2 23,4 43294 10,9

f>20000 45,9 19,4 16,5 14,0 11,2 24,6 32,6 21,6 28488 12,5

TABLE 3 — Résultats pour les noms, micro—moyennes, avec les mots relies de Moby pour reference.

la table 3 et la table 2, il semble que les approches miroir et distributionnelle ramenent bien d’autres entités que des
synonymes dans leurs meilleurs candidats. Cela peut sembler un peu surprenant pour l’approche miroir puisque
cette approche capitalise a priori sur des relations de traduction. Nous devons analyser cela de facon plus precise
aﬁn de savoir si nous sommes en presence de bruit dans les modeles de traduction (ce qui est tres probable) ou si
Moby contient plus de synonymes que WordNet, ou les deux.

Nous observons également que le rappel de l’approche miroir est plus grand que celui de l’approche distribution-
nelle, une observation en accord avec notre evaluation sur WordNet, et qui est peut—etre due a la difference de
performance des deux approches sur les synonymes (qui sont nombreux dans Moby).

Le ﬁltre des entités lexicales offre un rendement mitige : la precision de la variante f>20000 est légerement
inferieure a celle de la variante f>1 pour les deux approches. Le rappel de l’approche n1iroir augmente cependant
de maniere notable et consistante dans les cas ou l’on s’interesse aux mots tres frequents.

4.3 Analyse des erreurs produites par l’approche miroir

Les experiences que nous venons de décrire possedent quelques limites. La reference WordNet que nous utilisons
pour la synonymie possede un nombre relativement restreint de synonymes par mot candidat, ce qui ne permet pas
de rendre compte avec precision de la pertinence des autres candidats proposes. Le fait d’utiliser un thesaurus plus
vaste comme Moby ne resout que partiellement le probleme car la nature des relations encodées dans Moby n’est
pas étiquetée et certaines relations présentes dans cette ressource ne correspondent pas a des relations lexicales
typiques (ex : ragingl abandoned).

On peut mener une premiere analyse a l’aide de WordNet aﬁn d’évaluer la presence de termes relies par d’autres
relations que la synonyn1ie. Si l’on regarde les premiers candidats produits pour chaque cible (voir la table 4), on
constate que pour les verbes, 19% sont recensés comme hyperonymes et 6% come hyponymes, les proportions
étant de 7% et 4% pour les noms. Les autres fonctions (holonymes, meronymes et antonymes) apparaissent de
fagon marginale. En regardant les 5 premiers candidats produits par les deux approches, on observe que ceux
produits pour les verbes correspondent davantage a des relations presentes dans WordNet. En grande majorité, les
candidats identiﬁes ne correspondent pas a une relation étiquetée dans WordNet. Un peu moins de la moitié des
cibles ne recoit d’ailleurs aucun candidat validé par WordNet (0).

Les problemes de couverture de WordNet se posent malheureusement pour toutes les fonctions lexicales et ceci
ne peut etre qu’indicatif. Nous avons donc conduit une evaluation manuelle de la sortie produite par l’approche

PHILIPPE {MULLER,LANGLAIS }

top 5 top 1

0 S He Ho H1 A M 0 S He Ho H1 A M

nom Miroir 3146 181 175 98 13 5 1 570 64 58 28 5 1 1
Lin 3078 186 161 123 12 11 2 565 65 49 31 6 4 1

verbe Miroir 2807 406 428 216 0 7 0 466 95 139 42 0 3 0
Lin 2882 414 272 212 0 20 0 444 140 106 50 0 5 0

TABLE 4 — Nombre de fonctions lexicales correspondant aux 5 (colonne de gauche) ou 1 (colonne de droite)
premiers candidats proposes par chaque approche sans ﬁltre de fréquence, selon WordNet. 0 signiﬁe qu’aucune
relation selon WordNet n’est associée a un candidat. Ces occurrences sont comptabilisées pour les cibles trai-
tées par les deux approches, soit 724 noms et 743 verbes. S=synonymes, He=hyperonymes, Ho=hypony1nes,
Hl=holonymes, A=antonymes, M=meronymes.

miroir en sélectionnant aléatoirement 100 paires de mots cible / candidat ou le candidat est le premier
propose par l’approche miroir, bien qu’il ne soit pas validé comme synonyme par WordNet. Nous avons observe
les phénomenes suivants :

— 25% des mots candidats constituent une partie d’une unite composée de plusieurs mots, comme le mot sea
dans la paire sea / urchin;

— 18% des mots candidats non validés par WordNet sont en fait des synonymes selon d’autres thesaurus que nous
avons consulté manuellement 14. C’est par exemple le cas de la paire tors o / che st ;

— 13% des candidats sont en fait des hyperonymes listés dans WordNet ou dans www . the s aurus . com, comme
la paire twitch / movement ;

— 6% des paires mettent en relation des mots morphologiquement relies, comme account ant / account ing,
probablement en raison d’un probleme d’ étiquetage en partie du discours dans la langue pivot ou un mot frangais
comme ici compt able peut etre aussi bien etre un nom qu’un adjectif.

Parmi les erreurs (au sens de WordNet) fréquentes restantes, certaines sont dues a la polysémie d’une traduction
pivot, comme par exemple le mot anglais aplomb traduit en francais par as surance qui veut également dire
insurance en anglais. Ce type de probleme est cependant difﬁcile a analyser sans retracer méticuleusement les
nombreuses associations utilisées par les modeles de traduction dans notre approche.

D’autres erreurs sont plutot imputables a des termes peu frequents dans le corpus des Hansards que nous avons
utilise et que nous aurions dﬁ ﬁltrer au préalable.

Cette analyse suggere que tous les candidats rejetés ne sont pas nécessairement mauvais et qu’il y a donc place
a amelioration. La polysémie demeure le probleme le plus difﬁcile a résoudre, que ce soit pour notre approche
miroir ou pour l’approche distributionnelle.

Nous avons également regardé de maniere tres informelle les mots cibles pour lesquels WordNet ne propose
aucun synonyme alors que l’approche miroir propose des candidats. Dans une proportion non négligeable de cas,
les traductions miroir sont pertinentes comme whopper / 1 ie. Une analyse plus ﬁne est cependant requise pour
quantiﬁer plus précisément cette observation.

4.4 Tests de synonymie

Comme evaluation secondaire, plusieurs auteurs utilisent, pour évaluer la pertinence d’une mesure de similarité
sémantique, des tests de synonymie semblables a ceux poses dans les examens du TOEFL (Tumey, 2008) ou la
tache consiste a distinguer parmi quatre candidats, le synonyme d’un mot dans un contexte donné. On peut voir
cet exercice comme une version simpliﬁée d’une tache de désambiguisation, ou le but est de reconnaitre le bon
terme dans un ensemble de distracteurs (termes a priori sans rapport), au lieu de distinguer les sens d’un meme
mot. On teste alors la similarité sémantique en prenant celui des candidats qui ale score de similarité le plus élevé
avec la cible.

14. Come par exemple le Roget’s 21st Century Thesaurus, http : / /www . thesaurus . com

COMPARAISON D’UNE APPROCHE MIROIR ET D’UNE APPROCHE DISTRIBUTIONNELLE POUR L’EXTRACTION
DE MOTS RELIES

Les donnees TOEFL ne sont pas librement disponibles, aussi avons nous utilise ici un test genére artiﬁciellement
a partir des données de WordNet par Freitag et al. (2005) 15. Les auteurs le considerent comme plus difﬁcile que
les equivalents du TOEFL. Ce test est notamment utilise par Ferret (2010) aﬁn d’ordonner djfférentes mesures de
similarité entre vecteurs de cooccurrences. Le meilleur score qu’il obtient sur ce test est de 71.6% de réponses
correctes, ce qui est proche du score de 72% d’exactitude obtenu par (Freitag et al., 2005) a l’aide d’autres
methodes distributionnelles. Les systemes repondent a toutes les questions.

Les instances de test sont de la forme house: family obstacle filing surgeon le premier terme
etant la cible, le second un synonyme d’un des sens de la cible selon WordNet, les trois autres sont des distracteurs.
Quelques restrictions sont ajoutées pour ne pas rendre le test trop facile : les synonymes dont la forme est proche
de la cible (group/grouping) sont élimines. Par ailleurs les cibles sont choisies avec une fréquence minimale.
Les distracteurs sont choisis completement au hasard, mais les termes associés sont choisis parmi les synsets de
WordNet et privilegient donc les termes polysémiques.

Nous avons applique ce test a nos deux approches en choisissant, comme les autres travaux mentionnés, celui
des candidats ayant le meilleur rang dans la liste de similarites. Si aucun des candidats du test n’est present dans
les candidats d’ une méthode, le systeme ne repond rien. Nous pouvons donc evaluer l’aptitude d’une mesure de
similarité a identiﬁer le bon terme, ce que nous mesurons en terme de precision, rappel et F—score.

La table 5 resume les résultats pour les 200 premiers candidats de chaque méthode. Dans les cas ou les candidats
sont tous absents de la reponse du systeme, (Ferret, 2010) renvoie une réponse au hasard, mais cela arrive rarement
vue la couverture de son systeme. Nous avons ici fait le choix de considérer que le systeme ne repond pas faute
de données ﬁables, car c’est un cas beaucoup plus courant ici. Ceci a pour effet de faire baisser le rappel, et la
precision evalue réellement la methode des miroirs.

Comme nous disposons pour l’approche miroir d’une liste de candidats plus etendue, nous avons aussi evalué cette
méthode sans coupure. On constate un nombre important de non—réponses egalement, cette fois due sans doute a
une couverture lexicale limitée de la ressource de depart (les Hansards). Noms et verbes regroupés, cette variante
obtient un F—score de 0,73, avec 3908/17285 cibles sans réponse (22%), majoritairement des noms.

A nombres de candidats egaux, on constate donc que la methode miroir a une precision équivalente a celle de
Lin mais un rappel bien supérieur. Sans limite de candidats, elle atteint un F—score comparable aux meilleures
méthodes distributionnelles testées dans les travaux susmentionnés.

Noms F1 P R sans reponse Verbes F1 P R sans réponse
Lin[200] 0,55 0,95 0,38 5885/9887 Lin[200] 0,55 0,87 0,40 3983/7398
Miroir[200] 0,63 0,95 0,47 4975/9887 Miroir[200] 0,69 0,89 0,56 2694/7398
Miroir 0,72 0, 87 0,61 2995/9887 Miroir 0,74 0,79 0,70 913/7398

TAB LE 5 — Evaluation pour le test de synonymie base sur WordNet de (Freitag et al., 2005)

Faute de place, nous ne ferons que decrire brievement une autre fagon d’ analyser le test effectué, proposee par
(Freitag et al., 2005), consistant a mettre les resultats en rapport avec le niveau de polysémie des terrnes cibles, et
qui semblait mettre en evidence que les cibles polysemiques étaient les plus dures a resoudre. Nous n’avons pas
constate ce phenomene ici, la precision reste constante pour les verbes et ne baisse que tres legerement pour les
noms, quelle que soit la polysémie des cibles, alors que le rappel augmente, sans doute parce que les miroirs sont
plus susceptibles d’avoir une réponse a foumir sur les mots plus frequents.

5 Travaux reliés

Plusieurs types de travaux peuvent etre compares a la presente etude, ayant des obj ectifs, des données en entree et
des methodologies d’evaluation plus ou moins varies. L’ extraction de paraphrases partage certains de nos obj ectifs
et ressources, meme si elle conceme le rapprochement de termes comportant plus d’une unite lexicale. L’ extraction
de synonymes, la construction de thesaurus recouvrent aussi nos buts et peuvent etre évalués de fagon similaire.

15. Ce test ct est librement disponible a1’URL http : //www . cs . cmu . edu/~dayne/wbst—nanews . tar . gz

PHILIPPE {MULLER,LANGLAIS }

De fagon plus large, les nombreux travaux recents sur la conception et la realisation de mesures de similarité
sémantique peuvent etre rapprochés naturellement de la methode présentée, meme si les obj ectifs sont djfferents.

L’ evaluation de l’acquisition de paraphrases est souvent évaluée par des jugements humains d’acceptabilité des
substitutions en contexte, ce qui limite a des petits jeux detest. Barzilay & McKeown (2001) rapportent que 90%
des paraphrases extraites par patrons (sur un corpus monolingue de traductions littéraires) sont acceptables, me-
langeant synonymes, hyperonymes et termes coordonnés, sans bien sur pouvoir donner une idée de la couverture
d’une telle méthode. En se fondant sur des alignements bilingues et une méthode similaire a la notre mais sur
plusieurs unites lexicales, Bannard & Callison—Burch (2005) estiment que les meilleurs paraphrases extraites pour
chaque cible sont valides dans 75% des cas avec un alignement parfait (48% avec un alignement automatique).
De meme Lin et al. (2003) ou Curran & Moens (2002) évaluent précisément la presence de synonymes dans des
listes de similarité dans des petits ensembles de paires de synonymes ou antonymes, ce qui rend difﬁcile une
extrapolation sur le genre de données que nous utilisons aﬁn d’atteindre une large couverture.

Plus proche de la methodologie que nous avons suivie, on trouve des études qui évaluent la classiﬁcation de paires
de mots en synonymes ou non—synonymes. Cela peut etre fait directement sur les candidats sélectionnés pour un
ensemble de cibles, comme dans l’étude presente, ou sur des ensembles de test reechantillonnés pour augmenter
artiﬁciellement la presence de paires positives et pouvoir appliquer des techniques standards de classiﬁcation avec
une ﬁabilité raisonnable. Ne pas rééchantillonner est plus réaliste mais donne des scores assez bas, comme nous
l’avons constaté : (van der Plas & Tiedemann, 2006) partent de vecteurs d’ alignement a la place des vecteurs
d’ arguments syntaxiques de Lin, en déﬁnissant la meme similarité et atteignent 12% de F-score par rapport a leur
reference; (Wu & Zhou, 2003) fait de meme, ajoutant aussi une distance calculée dans un graphe lexical issu
d’un dictionnaire, et apprend des regressions lineaires des djfférents scores de similarité, tout en restreignant la
frequence des cibles jusqu’a obtenir un maximum de 23% sur les noms et 30% sur les verbes. On peut aussi men-
tionner (Heylen et al., 2008), qui analysent la repartition des fonctions lexicales dans des listes de similarités de
mot en néerlandais. La seconde option, o1‘1l’on rééchantillone a l’entrainement et au test, est pertinente seulement
si l’on connait un moyen de presélectionner naturellement les candidats pour atteindre la proportion supposée, ce
qui n’est pas le cas pour les études existantes (Hagiwara et al., 2009). Notre etude peut en fait etre considérée
comme une entree pour des experiences de ce genre.

L’ etude des similarités distributionnelles faite par (Ferret, 2010), qui utilise de la cooccurrence simple, montre des
résultats proches de ce que l’on obtient avec les miroirs, plus bas sur WordNet et comparables ou meilleurs sur
Moby. Il opere sur un jeu de test beaucoup plus large, sans distinguer les parties de discours, et le jeu de test est
decoupé djfferemment par rapport aux frequences lexicales puisqu’il sélectionne les cibles et les candidats. Sur
WordNet il obtient au mieux 11% de R—précision et 17% pour la meilleure P@1 (sur les mots les plus frequents).
Sur Moby, la meilleure R—precision est de 10% et la meilleure P@1 est de 41%, P@5 de 28%. Le rappel est
systematiquement inférieur (25% sur WordNet et 10% sur Moby), mais seuls 100 candidats sont gardés par cible.
Les résultats sont plus bas que ce que 1’ on obtient ici avec les données de Lin, et nous pouvons donc supposer que la
comparaison que nous faisons est representative de l’approche distributionnelle dans ce contexte. La combinaison
miroir et distribution est par contre supérieure sur tous les scores sauf le rappel.

Avec assez peu de reglage, on voit donc que l’approche des miroirs atteint des résultats comparables ou meilleurs
que les similarités d’alignement ou distributionnelle pour isoler des synonymes dans certaines conﬁgurations. Les
approches distributionnelles peuvent sans doute etre ameliorees mais l’approche choisie semble representative. Il
faut noter que le calcul qui sous—tend les traductions miroirs est computationnellement bien plus simple que les
calculs de similarité entre n x n vecteurs d’alignement ou de cooccurrences, ou 11 est la taille du vocabulaire.

On peut estimer que l’on peut atteindre un niveau de ﬁltrage des candidats qui rend possible de tenter ensuite
la classiﬁcation des paires restantes. D’apres (Hagiwara et al., 2009) 15 , on peut associer (par classiﬁcation) une
fonction lexicale de fagon ﬁable a des paires de mots si la proportion de candidats effectivement a relier par rapport
a ceux qui n’ ont aucun lien peut atteindre un ratio de 1 pour 6. Une conclusion similaire est tiree par (Piasecki et al.,
2008) dans le cas de la detection d’ hyperonymie. Nos resultats nous encouragent a penser que l’on peut atteindre
une proportion de 1 pour 4 ou 5. L’étude citée ne precise pas la proportion de paires de mots synonymes/non
synonymes de depart, mais si on prend les chiffres de (Ferret, 2010), i1 y a 30000 paires de synonymes sur un
vocabulaire de reference de 10000 mots, donc pour environ 50M de paires possibles, soit une proportion de 0,06%
de paires de synonymes ou un ratio de 1 pour 1600.

16. (Hagiwara et al., 2009) utilise comme descripteurs des schémas syntaxiques et des Vecteurs dc cooccurrence.

COMPARAISON D’UNE APPROCHE MIROIR ET D’UNE APPROCHE DISTRIBUTIONNELLE POUR L’EXTRACTION
DE MOTS RELIES

Une autre fagon de juger de la pertinence des mesures de similarité semantique entre mots derive des donnees
collectees par (Miller & Charles, 1991) ou on demande a des sujets de juger la similarité ou le lien entre des items
lexicaux, sur une echelle numerique. C’est une fagon intéressante de fournir une evaluation intrinseque de ces
associations, mais le jeu de test ne peut couvrir qu’une part tres limitée du vocabulaire (300 mots environ, avec 2
ou 3 associations par mot au plus).

6 Conclusion

Nos experiences conﬁrment la variété des relations lexicales que l’on peut récupérer en appliquant ce que l’on a
usage d’ appeler des mesures de similarite semantique. Les deux approches que nous avons étudiées ici semblent
correlees aux ressources de reference que nous avons considérées.

En ce qui conceme les synonymes, nos experiences indiquent que les traductions miroir offrent des candidats plus
pertinents que l’approche distributionnelle de Lin (1998). Dans la mesure ou les approches miroir ne sont pas aussi
prisées que les approches distributionnelles, nous esperons que cette etude contribuera a en montrer l’interet pour
l’acquisition de relations lexicales. Nous soulignons de plus que l’approche miroir est beaucoup moins coﬁteuse
a developper eta appliquer, pour autant que l’on soit en mesure de trouver des bitextes de tajlle sufﬁsante mettant
en jeu la langue d’intéret. Patry & Langlais (2011) dressent un portrait des bitextes existants qui indique que de
telles ressources sont de plus en plus disponibles pour de nombreuses paires de langues.

L’ approche miroir que nous avons mise en place ne tire pas proﬁt du fait que plusieurs bitextes mettant en jeu la
langue d’intéret sont disponibles. C’est par exemple le cas pour la langue frangaise pour laquelle les bitextes des
débats parlementaires européens sont disponibles en plus du bitexte que nous avons mis proﬁt ici. L’ aj out de telles
ressources devrait etre en mesure d’ augmenter les performances (et la precision en particulier) de notre approche.

La complémentarite des approches testées dans cette etude amene a nous interroger sur la maniere optimale de les
combiner. La simple intersection que nous avons étudiée ici améliore nettement la precision des listes candidates.
Une approche plus originale consisterait a combiner ces approches avec une approche par patron telle que celle
de (Barzilay & McKeown, 2001). Le probleme de la polysémie discuté en section 4.3 demeure un probleme pour
toutes les approches dont nous avons discuté, en particulier lorsque deux sens d’une entité lexicale sont frequents
en corpus. I1 semble souhaitable d’intégrer l’apport de methodes qui vise a reperer des groupes de sens equivalents
multilingues, comme par exemple dans (Apidianaki, 2008).

ll n’en reste pas moins que notre obj ectif a moyen terme est de distinguer automatiquement la nature des diffe-
rentes relations lexicales identiﬁées. Cette information est pertinente dans bon nombre d’ applications (paraphra-
sage, choix d’une traduction, etc.). Des travaux comme ceux de (Hagiwara et al., 2009) tendent a indiquer qu’il
est envisageable d’ entrainer de maniere supervisée un classiﬁcateur a reconnaitre certaines fonctions lexicales,
pour autant que la proportion de candidats d’une classe particuliere soit plus équilibree que dans les distributions
naturelles. Ceci indique qu’il faut etre en mesure d’afﬁner la liste de candidats, ce que notre approche par ﬁltrage
ou combinaison realise.

Remerciements

Nous remercions les relecteurs pour la pertinence de leurs commentaires.

Références

APIDIANAKI M. (2008). Translation—oriented Word Sense Induction Based on Parallel Corpora. In Actes de
LREC language Resources and Evaluation (LREC), p. 3269-3275, Marrakech Maroc.

BANNARD C. & CALLISON—BURCH C. (2005). Paraphrasing with bilingual parallel corpora. In Proceedings of
the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), p. 597-604.

BARZILAY R. & MCKEOWN K. R. (2001). Extracting paraphrases from a parallel corpus. In Proceedings of
the 39th Annual Meeting of the Association for Computational Linguistics.

PHILIPPE {MULLER,LANGLAIS }

CURRAN J. R. & MOENS M. (2002). Improvements in automatic thesaurus extraction. In Proceedings of the
ACL—02 Workshop on Unsupervised Lexical Acquisition, p. 59-66.

DYVIK H. (2002). Translations as semantic mirrors : From parallel corpus to wordnet. In The Theory and Use
of English Language Corpora, ICAME 2002. http ://www.hf.uib.no/i/LiLi/SLF/Dyvik/ICAMEpaper.pdf.
EDMONDS P. & HIRST G. (2002). Near-Synonymy and lexical choice. Computational Linguistics, 28(2),
105-144.

FERRET O. (2010). Testing semantic similarity measures for extracting synonyms from a corpus. In Proceedings
of LREC 201 0.

FREITAG D., BLUME M., BYRNES J ., CHOW E., KAPADIA S., ROHWER R. & WANG Z. (2005). New expe-
riments in distributional representations of synonymy. In Proceedings of CoNLL, p. 25-32.

HAGIWARA M., OGAWA Y. & TOYAMA K. (2009). Supervised synonym acquisition using distributional fea-
tures and syntactic patterns. Journal of Natural Language Processing, 16(2), 59-83.

HEYLEN K., PEIRSMAN Y., GEERAERTS D. & SPEELMAN D. (2008). Modelling Word Similarity. An Evalua-
tion of Automatic Synonymy Extraction Algorithms. In Proceedings of LREC 2008, p. 3243-3249 : ELRA.
KOZIMA H. & FURUGORI T. (1993). Similarity between words computed by spreading activation on an english
dictionary. In Proceedings of the conference of the European chapter of the ACL, p. 232-239.

LIN D. (1998). Automatic retrieval and clustering of similar words. In COLING/ACL98, volume 2, p. 768-774,
Montreal.

LIN D., ZHAO S., QIN L. & ZHOU M. (2003). Identifying synonyms among distributionally similar words. In
Proceedings of IJCAI ’03, p. 1492-1493.

MAX A. & ZOCK M. (2008). Looking up phrase rephrasings via a pivot language. In Coling 2008 : Proceedings
of the Workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), p. 77-85.

MICHIELS A. & NOEL J . (1982). Approaches to thesaurus production. In Proceedings of Coling’82.

MILLER G. & CHARLES W. (1991). Contextual correlates of semantic similarity. Language and Cognitive
Processes, 6(1), 1-28.

MOORE R. C. (2004). hnproving IBM word alignment model 1. In 42nd Meeting of the Association for
Computational Linguistics (ACL), p. 518-525.

MULLER P. & LANGLAIS P. (2010). Comparaison de ressources lexicales pour l’extraction de synonymes. In
Article court au 17e TALN, Montreal, Canada.

NIWA Y. & NITTA Y. (1994). Co—occurrence vectors from corpora vs. distance vectors from dictionaries. In
Proceedings of Coling I994.

PATRY A. & LANGLAIS P. (2011). PARADOCS : l’entremetteur de documents paralleles indépendant de la
langue. TAL, 51-2, pp. 41-63.

PIASECKI M., SZPAKOWICZ S., MARCINCZUK M. & BRODA B. (2008). Classiﬁcation—based ﬁltering of
semantic relatedness in hypemymy extraction. In A. RANTA & B. NORDSTROM, Eds., GoTAL 2008, number
5221 in LNAI, p. 393-404 : Springer.

TURNEY P. (2008). A uniform approach to analogies, synonyms, antonyms, and associations. In Proceedings of
the 22nd International Conference on Computational Linguistics (Coling 2008).

VAN DER PLAS L. & TIEDEMANN J . (2006). Finding synonyms using automatic word alignment and measures
of distributional similarity. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, p. 866-
873.

WEEDS J . E. (2003). Measures and Applications of Lexical Distributional Similarity. PhD thesis, University of
Sussex.

WU H. & ZHOU M. (2003). Optimizing synonyms extraction with mono and bilingual resources. In Proceedings
of the Second International Workshop on Paraphrasing.

ZHITOMIRSKY—GEFFET M. & DAGAN I. (2009). Bootstrapping distributional feature vector quality. Computa-
tional Linguistics, 35(3), 435-461.

