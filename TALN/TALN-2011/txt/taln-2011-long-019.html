<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>M&#233;tarecherche pour l&#8217;extraction lexicale bilingue &#224; partir de corpus comparables</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>M&#233;tarecherche pour l&#8217;extraction lexicale bilingue &#224; partir de corpus
comparables
</p>
<p>Amir Hazem1 Emmanuel Morin1 Sebasti&#225;n Pe&#241;a Saldarriaga2
(1) Universit&#233; de Nantes, LINA - UMR CNRS 6241
</p>
<p>2 rue de la Houssini&#232;re, BP 92208, 44322 Nantes Cedex 03
(2) Synchromedia, &#201;cole de technologie sup&#233;rieure
</p>
<p>1100 rue Notre-Dame Ouest, Montr&#233;al, Qu&#233;bec, Canada H3C 1K3
amir.hazem@univ-nantes.fr, emmanuel.morin@univ-nantes.fr, spena@synchromedia.ca
</p>
<p>R&#233;sum&#233;. Nous pr&#233;sentons dans cet article une nouvelle mani&#232;re d&#8217;aborder le probl&#232;me de l&#8217;acquisition
automatique de paires de mots en relation de traduction &#224; partir de corpus comparables. Nous d&#233;crivons tout
d&#8217;abord les approches standard et par similarit&#233; interlangue traditionnellement d&#233;di&#233;es &#224; cette t&#226;che. Nous r&#233;-
interpr&#233;tons ensuite la m&#233;thode par similarit&#233; interlangue et motivons un nouveau mod&#232;le pour reformuler cette
approche inspir&#233;e par les m&#233;tamoteurs de recherche d&#8217;information. Les r&#233;sultats empiriques que nous obtenons
montrent que les performances de notre mod&#232;le sont toujours sup&#233;rieures &#224; celles obtenues avec l&#8217;approche par
similarit&#233; interlangue, mais aussi comme &#233;tant comp&#233;titives par rapport &#224; l&#8217;approche standard.
</p>
<p>Abstract. In this article we present a novel way of looking at the problem of automatic acquisition of pairs of
translationally equivalent words from comparable corpora. We first describe the standard and extended approaches
traditionally dedicated to this task. We then re-interpret the extended method, and motivate a novel model to
reformulate this approach inspired by the metasearch engines in information retrieval. The empirical results show
that performances of our model are always better than the baseline obtained with the extended approach and also
competitive with the standard approach.
</p>
<p>Mots-cl&#233;s : Corpus comparables, lexiques bilingues, m&#233;tarecherche.
</p>
<p>Keywords: Comparable corpora, bilingual lexicon, metasearch.
</p>
<p>1 Introduction
</p>
<p>L&#8217;extraction de lexiques bilingues &#224; partir de corpus comparables est un domaine de recherche en pleine efferves-
cence qui vise notamment &#224; offrir une alternative cr&#233;dible &#224; l&#8217;exploitation de corpus parall&#232;les. En effet, les corpus
parall&#232;les sont par nature des ressources rares notamment pour les domaines sp&#233;cialis&#233;s et pour des couples de
langues ne faisant pas intervenir l&#8217;anglais, l&#224; ou les corpus comparables sont par essence des ressources abon-
dantes puisque compos&#233;s de documents partageant diff&#233;rentes caract&#233;ristiques telles que le domaine, le genre, la
p&#233;riode, etc. sans &#234;tre en correspondance de traduction. Les lexiques bilingues extraits &#224; partir de corpus compa-
rables sont n&#233;anmoins d&#8217;une qualit&#233; bien inf&#233;rieure &#224; ce qui peut &#234;tre obtenu &#224; partir de corpus parall&#232;les. Cette
difficult&#233; &#224; extraire des lexiques bilingues peu bruit&#233;s &#224; partir de corpus comparables explique pourquoi ce champ
de recherche n&#8217;a pas encore franchi le cap de l&#8217;industrialisation &#224; la diff&#233;rence des corpus parall&#232;les et reste encore
majoritairement cantonn&#233; &#224; une activit&#233; de recherche prometteuse. La principale difficult&#233; des approches li&#233;es &#224;
l&#8217;exploitation de corpus comparables par rapport aux corpus parall&#232;les pour l&#8217;extraction de lexiques bilingues,
est l&#8217;absence d&#8217;&#233;l&#233;ments d&#8217;ancrage entre les documents des langues source et cible composant le corpus compa-
rable. Face &#224; cette difficult&#233; les diff&#233;rentes approches li&#233;es &#224; l&#8217;exploitation de corpus comparables reposent sur la
simple observation qu&#8217;un mot et sa traduction ont tendance &#224; appara&#238;tre dans les m&#234;mes environnements lexicaux.
La mise en &#339;uvre de cette observation repose sur l&#8217;identification d&#8217;affinit&#233;s du premier ordre (i.e. identifier les
mots qui sont susceptibles d&#8217;&#234;tre trouv&#233;s dans le voisinage imm&#233;diat d&#8217;un mot donn&#233;) ou d&#8217;affinit&#233;s du second
ordre (i.e. identifier les mots qui partagent les m&#234;mes environnements lexicaux sans n&#233;cessairement appara&#238;tre
ensemble) (Grefenstette, 1994a, p. 279). Les approches associ&#233;es &#224; l&#8217;identification de ces affinit&#233;s sont, d&#8217;une</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AMIR HAZEM, EMMANUEL MORIN ET SEBASTI&#193;N PE&#209;A SALDARRIAGA
</p>
<p>part, l&#8217;approche standard (Rapp, 1995; Fung &amp; McKeown, 1997) qui est l&#8217;approche majoritairement exploit&#233;e, et
d&#8217;autre part, l&#8217;approche par similarit&#233; interlangue (D&#233;jean &amp; Gaussier, 2002).
</p>
<p>Dans cette article, nous reprenons &#224; notre compte l&#8217;id&#233;e de (Fung, 1998) qui indique que l&#8217;extraction de lexiques
bilingues &#224; partir de corpus comparables peut &#234;tre approch&#233;e comme un probl&#232;me de recherche d&#8217;information.
Dans cette repr&#233;sentation, la requ&#234;te serait alors les mots &#224; traduire et les documents retourn&#233;s par le moteur
de recherche les candidats &#224; la traduction de ce mot. Et de la m&#234;me mani&#232;re que les documents retourn&#233;s sont
ordonn&#233;s suivant leur ad&#233;quation avec la requ&#234;te, les traductions candidates sont class&#233;es en fonction de leur per-
tinence par rapport au mot &#224; traduire. Nous souhaitons donc poursuivre plus en avant cette analogie et proposer
une am&#233;lioration significative &#224; l&#8217;approche par similarit&#233; interlangue en consid&#233;rant l&#8217;extraction de lexiques bi-
lingues comme un probl&#232;me de fusion de r&#233;sultats analogue &#224; celui rencontr&#233; par les m&#233;tamoteurs de recherche
d&#8217;information. Nous faisons ainsi l&#8217;hypoth&#232;se que le fait de combiner diff&#233;rentes sources d&#8217;information permet de
renforcer globalement la m&#233;thode par similarit&#233; interlangue.
</p>
<p>Dans la suite de cet article, nous commen&#231;ons par rappeler en section 2 les deux m&#233;thodes phares en extraction de
lexiques bilingues &#224; partir de corpus comparables, &#224; savoir les m&#233;thodes dites standard et par similarit&#233; interlangue.
La section 3 est quant &#224; elle d&#233;di&#233;e &#224; la pr&#233;sentation de notre approche par m&#233;tarecherche qui revisite l&#8217;approche
par similarit&#233; interlangue. La section 4 se concentre sur l&#8217;&#233;valuation des trois m&#233;thodes mises en &#339;uvre et ouvre
une discussion sur les limites de notre approche. Enfin la section 5 vient conclure ce travail.
</p>
<p>2 Principales approches en extraction lexicale bilingue &#224; partir de corpus
comparables
</p>
<p>Dans cette section, nous allons d&#233;crire les deux principales approches d&#233;di&#233;es &#224; l&#8217;extraction de lexiques bilingues
&#224; partir de corpus comparables, &#224; savoir : l&#8217;approche standard, puis l&#8217;approche par similarit&#233; interlangue.
</p>
<p>2.1 Approche standard
</p>
<p>Les principaux travaux en extraction de lexiques bilingues &#224; partir de corpus comparables sont bas&#233;s sur une
analyse du contexte lexical des mots et reposent sur la simple observation qu&#8217;un mot et sa traduction tendent &#224;
appara&#238;tre dans les m&#234;mes contextes lexicaux. La mise en &#339;uvre de cette observation repose sur l&#8217;identification
d&#8217;affinit&#233;s du premier ordre : &#171; Les affinit&#233;s du premier ordre d&#233;crivent les mots qui sont susceptibles d&#8217;&#234;tre trouv&#233;s
dans le voisinage imm&#233;diat d&#8217;un mot donn&#233;. 1 &#187; (Grefenstette, 1994a, p. 279). Elles peuvent &#234;tre repr&#233;sent&#233;es sous
la forme d&#8217;un vecteur de contexte, o&#249; chaque &#233;l&#233;ment du vecteur repr&#233;sente un mot qui appara&#238;t dans diff&#233;rentes
fen&#234;tres contextuelles.
</p>
<p>L&#8217;impl&#233;mentation de l&#8217;approche standard peut &#234;tre d&#233;crite par les quatre &#233;tapes suivantes (Rapp, 1995; Fung &amp;
McKeown, 1997) :
</p>
<p>1. Identification des contextes lexicaux
Pour chaque partie du corpus comparable, le contexte de chaque mot plein i est extrait en rep&#233;rant les mots
qui apparaissent autour de lui dans une fen&#234;tre contextuelle de n mots. Pour chaque mot i des langues
source et cible, un vecteur de contexte i est ainsi obtenu. &#192; chaque entr&#233;e ij du vecteur est associ&#233;e un
score de cooccurrence des mots i et j. Habituellement, les mesures d&#8217;association comme l&#8217;information
mutuelle (Fano, 1961), ou le taux de vraisemblance (Dunning, 1993) sont utilis&#233;es pour d&#233;finir les entr&#233;es
des vecteurs de contextes.
</p>
<p>2. Transfert d&#8217;un mot &#224; traduire
Les mots d&#8217;un vecteur de contexte i, pour lequel une traduction est recherch&#233;e, sont ensuite traduits en
s&#8217;appuyant sur un dictionnaire bilingue. Si le dictionnaire propose plusieurs traductions pour un &#233;l&#233;ment,
nous ajoutons au vecteur de contexte de i l&#8217;ensemble des traductions propos&#233;es (lesquelles sont pond&#233;r&#233;es
par la fr&#233;quence de la traduction en langue cible). Les entr&#233;es n&#8217;ayant pas de traductions dans le dictionnaire
bilingue seront quant &#224; elle tout simplement ignor&#233;es.
</p>
<p>1. First-order affinities describe what other words are likely to be found in the immediate vicinity of a given word</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#201;TARECHERCHE POUR L&#8217;EXTRACTION LEXICALE BILINGUE
</p>
<p>3. Identification des vecteurs proches du mot &#224; traduire
Une mesure de similarit&#233;, sim(i, t), est utilis&#233;e pour calculer le score entre chaque mot, t, de la langue cible
et le vecteur de contexte traduit du mot i. Parmi les mesures de similarit&#233; les plus souvent usit&#233;es pour cette
t&#226;che, nous retrouvons le cosinus (Salton &amp; Lesk, 1968) ou le jaccard pond&#233;r&#233; (Grefenstette, 1994b).
</p>
<p>4. Obtention des traductions candidates
Les candidats &#224; la traduction d&#8217;un mot i &#224; traduire sont finalement ordonn&#233;s par ordre d&#233;croissant suivant
leur score de similarit&#233;.
</p>
<p>Deux remarques s&#8217;imposent ici en ce qui concerne cette approche standard. D&#8217;une part, cette approche met en
&#339;uvre diff&#233;rents param&#232;tres (taille de la fen&#234;tre contextuelle, choix des mesures d&#8217;association et de similarit&#233;...)
dont il est parfois peu ais&#233; d&#8217;identifier les valeurs ad&#233;quates pour une recherche optimum (voir par exemple le
travail de (Laroche &amp; Langlais, 2010) pour l&#8217;influence de ces param&#232;tres sur la qualit&#233; des r&#233;sultats). D&#8217;autre part,
l&#8217;approche standard qui repose originellement sur des cooccurrences graphiques peut aussi &#234;tre impl&#233;ment&#233;e avec
des cooccurrences syntaxiques (Yu &amp; Tsujii, 2009; Otero, 2007).
</p>
<p>mot Identifier kvecteurs similaires
</p>
<p>Langue source Langue cible
mot mot
mot mot
mot mot
mot mot
mot mot
</p>
<p>... ...
</p>
<p>mot
mot
mot
</p>
<p>Identifierles candidats ...
</p>
<p>Dictionnaire Bilingue
</p>
<p>1
</p>
<p>FIGURE 1 &#8211; Illustration de la m&#233;thode par similarit&#233; interlangue.
</p>
<p>2.2 Approche par similarit&#233; interlangue
</p>
<p>Le principal inconv&#233;nient de l&#8217;approche standard est que ses performances d&#233;pendent grandement de la couverture
du dictionnaire bilingue par rapport au corpus comparable. En effet, en traduisant un maximum d&#8217;entr&#233;es du
vecteur de contexte du mot &#224; traduire, on maximise les chances de retrouver sa traduction. Bien que la couverture
du dictionnaire puisse &#234;tre &#233;tendue en utilisant des dictionnaires sp&#233;cialis&#233;s ou des th&#233;saurus multilingues (Chiao
&amp; Zweigenbaum, 2003; D&#233;jean et al., 2002), la traduction des &#233;l&#233;ments du vecteur de contexte reste le c&#339;ur de
cette approche.
</p>
<p>Dans le but d&#8217;&#234;tre moins d&#233;pendants de ce dictionnaire, (D&#233;jean &amp; Gaussier, 2002) ont propos&#233; une extension de
l&#8217;approche standard connue sous le nom d&#8217;approche par similarit&#233; interlangue. Cette approche se base sur l&#8217;id&#233;e
que les mots ayant le m&#234;me sens, partagent les m&#234;mes environnements lexicaux. Elle repose sur l&#8217;identification
d&#8217;affinit&#233;s du second ordre : &#171; Les affinit&#233;s du second ordre d&#233;voilent quels mots partagent les m&#234;mes environ-
nements. Les mots partageant des affinit&#233;s du second ordre n&#8217;ont pas besoin d&#8217;appara&#238;tre ensemble, mais leurs
environnements sont semblables. 2 &#187;
</p>
<p>Dans cette approche, le dictionnaire bilingue &#233;tablit un pont entre les langues du corpus comparable. L&#8217;approche
par similarit&#233; interlangue est bas&#233;e sur ce principe et &#233;vite les traductions directes des &#233;l&#233;ments des vecteurs de
contextes comme le montre la figure 1. L&#8217;impl&#233;mentation de cette approche peut &#234;tre r&#233;alis&#233;e en quatre &#233;tapes
o&#249; la premi&#232;re et la derni&#232;re sont identiques &#224; celles de l&#8217;approche standard (D&#233;jean &amp; Gaussier, 2002; Daille &amp;
Morin, 2005) :
</p>
<p>2. S&#233;lection des k plus proches voisins
Pour chaque mot &#224; traduire, les k plus proches voisins sont identifi&#233;s parmi les entr&#233;es du dictionnaire selon
</p>
<p>2. Second-order affinities show which words share the same environments. Words sharing second-order affinities need never appear toge-
ther themselves, but their environments are similar</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AMIR HAZEM, EMMANUEL MORIN ET SEBASTI&#193;N PE&#209;A SALDARRIAGA
</p>
<p>sim(i, s). Chaque plus proche voisin est ensuite traduit &#224; l&#8217;aide du dictionnaire bilingue, et le vecteur de
contexte de langue cible s correspondant &#224; la traduction est s&#233;lectionn&#233;. Si pour un plus proche voisin il
existe plusieurs traductions, s est donn&#233; par l&#8217;union des vecteurs correspondant aux diff&#233;rentes traductions.
Il est &#224; noter que les vecteurs de contexte ne sont pas traduits directement, ce qui r&#233;duit l&#8217;influence du
dictionnaire.
</p>
<p>3. Identification des vecteurs proches du mot &#224; traduire
La mesure de similarit&#233;, sim(s, t), est utilis&#233;e pour calculer le score entre chaque mot t de la langue cible
en fonction des k plus proches voisins. Le score final attribu&#233; &#224; chaque mot t est donn&#233; par :
</p>
<p>sim(i, t) =
&#8721;
</p>
<p>s&#8712;kPPV
sim(i, s)&#215; sim(s, t) (1)
</p>
<p>Une autre mani&#232;re de calculer le score de similarit&#233; a &#233;t&#233; propos&#233;e par (Daille &amp; Morin, 2005). Les auteurs
calculent alors le barycentre des vecteurs de contexte des k plus proches voisins.
</p>
<p>3 Extraction lexicale bilingue par m&#233;tarecherche
</p>
<p>3.1 Motivations
</p>
<p>L&#8217;approche propos&#233;e par (D&#233;jean &amp; Gaussier, 2002) introduit implicitement le probl&#232;me du choix de la valeur
ad&#233;quate de k dans les k plus proches voisins. D&#8217;une mani&#232;re g&#233;n&#233;rale, la valeur optimale de k d&#233;pend des
donn&#233;es mises en jeu. Cette valeur est souvent d&#233;finie de fa&#231;on empirique, bien qu&#8217;il soit possible de la d&#233;terminer
par validation crois&#233;e. L&#8217;approche par similarit&#233; interlangue (ASI) appliqu&#233;e &#224; nos donn&#233;es s&#8217;est r&#233;v&#233;l&#233;e tr&#232;s
sensible vis-&#224;-vis du param&#232;tre k. En effet, pour des valeurs de k sup&#233;rieures &#224; 20, la pr&#233;cision chute de fa&#231;on
significative. De plus, il n&#8217;est pas possible de d&#233;terminer des intervalles de stabilit&#233; relative pour k. Le choix du
param&#232;tre k devient alors crucial.
</p>
<p>En partant du principe que chaque mot contribue &#224; la caract&#233;risation du mot &#224; traduire, notre proposition vise non
seulement &#224; am&#233;liorer la pr&#233;cision, mais aussi &#224; &#234;tre plus robuste vis-&#224;-vis du nombre de plus proches voisins. En
poussant l&#8217;analogie des approches inspir&#233;es de la RI (Fung &amp; Lo, 1998) plus loin, nous proposons une nouvelle
fa&#231;on d&#8217;aborder le probl&#232;me de l&#8217;extraction lexicale bilingue &#224; partir de corpus comparables, en le consid&#233;rant
comme un probl&#232;me de fusion de r&#233;sultats analogue &#224; celui rencontr&#233; par les m&#233;tamoteurs de recherche.
</p>
<p>L&#8217;objectif de la m&#233;tarecherche est de fusionner les classements renvoy&#233;s par plusieurs syst&#232;mes de RI, en une
liste unique, afin d&#8217;obtenir un syst&#232;me combin&#233; qui soit plus performant que les syst&#232;mes individuels (Aslam &amp;
Montague, 2001). Puisque chacun des k plus proches voisins produit un classement diff&#233;rent, la m&#233;tarecherche
fourni un cadre ad&#233;quat pour exploiter l&#8217;information v&#233;hicul&#233;e par chacun des k classements. En outre, un int&#233;r&#234;t
particulier est donn&#233; aux mots candidats &#224; la traduction d&#8217;un mot donn&#233;. En effet, partant du principe que les
corpus contiennent beaucoup de bruit, il n&#8217;est pas rare de rencontrer des mots qui soient proches d&#8217;un nombre
important de mots du dictionnaire, et ainsi, viennent parasiter le mod&#232;le et fausser les r&#233;sultats. En effet, pour
traduire un mot, le syst&#232;me choisit un nombre k de plus proches voisins en langue source, puis il cherche en
langue cible les candidats les plus proches des traductions de ces k plus proches voisins sans tenir compte de la
relation de ces candidats avec le reste des mots du dictionnaire. Pour pallier cela, nous construisons un mod&#232;le qui
prend en compte cette information en accordant plus de confiance aux candidats qui sont plus proches des k plus
proches voisins que du reste des entr&#233;es du dictionnaire.
</p>
<p>3.2 Approche par m&#233;tarecherche
</p>
<p>Cette section d&#233;crit notre extension de l&#8217;approche par similarit&#233; interlangue. Les diff&#233;rents modes de fusion d&#233;finis
ici se basent sur les &#233;l&#233;ments d&#233;crits dans la table 1.
</p>
<p>La premi&#232;re &#233;tape de notre m&#233;thode consiste &#224; fixer le nombre de plus proches voisins d&#8217;un mot &#224; traduire. La
valeur de k est d&#233;termin&#233;e empiriquement. Cependant, intuitivement mais aussi &#224; travers nos exp&#233;riences, nous
pouvons dire que la s&#233;lection d&#8217;un nombre faible de plus proches voisins est insuffisante dans la plus part des cas</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#201;TARECHERCHE POUR L&#8217;EXTRACTION LEXICALE BILINGUE
</p>
<p>Symbole D&#233;finition
i Le mot &#224; traduire
t Le mot candidat &#224; la traduction de i
s L&#8217;ensemble des plus proches voisins de i
s L&#8217;ensemble des traductions des plus proches voisins de i
k Le nombre de plus proches voisins s&#233;lectionn&#233;s
n L&#8217;ensemble de tous les voisins de t
u Le nombre total de mots du dictionnaire
occs(t) L&#8217;effectif de t ie : avec combien de voisin t est-il en relation ?
sim(sk, t) Le score de similarit&#233; entre le k i&#232;me proche voisin de s et t
maxsk Le score maximum du candidat le plus proche de sk
maxs Le score maximum du candidat le plus proche de l&#8217;ensemble s
simk(s, t) Le score de similarit&#233; entre s et t par rapport au k i&#232;me plus proche voisin
sim(s, t) Le score de similarit&#233; entre s et t par rapport &#224; l&#8217;ensemble des plus proches voisins
&#952;t Le param&#232;tre de r&#233;gulation ou facteur de confiance de t
</p>
<p>TABLE 1 &#8211; &#201;l&#233;ments de notation.
</p>
<p>pour trouver la bonne traduction, et que la s&#233;lection d&#8217;un grand nombre de voisins, d&#8217;une part contredit la notion
de plus proches voisins et d&#8217;autre part, induit la prise en compte de voisins &#233;loign&#233;s qui peuvent fausser le mod&#232;le.
</p>
<p>Une fois k fix&#233;, nous consid&#233;rons chaque liste de candidats renvoy&#233;e par un proche voisin ind&#233;pendamment des
autres. Ces candidats sont les mots dont les vecteurs de contexte sont les plus similaires au vecteur de contexte
d&#8217;un voisin donn&#233;e. Dans nos exp&#233;riences, la taille des listes a &#233;t&#233; fix&#233;e &#224; 200. Partant du m&#234;me principe que le
choix du param&#232;tre k. La taille de la liste joue un r&#244;le important, en effet, une liste trop petite de candidats ne serait
pas suffisante pour aider &#224; trouver la bonne traduction, de la m&#234;me fa&#231;on, une liste trop importante de mots risque
de rajouter du bruit car il faut garder en t&#234;te que les mots appartenant &#224; une liste sont les traductions potentielles
class&#233;es par ordre de score de similarit&#233;. Notre mod&#232;le privil&#233;gie les candidats qui apparaissent dans plusieurs
listes, ainsi, plus l&#8217;effectif du mot candidat est important plus il a de chances d&#8217;&#234;tre la bonne traduction, ceci dit,
ceci reste valable si le candidat est bien class&#233;, en revanche, s&#8217;il appara&#238;t souvent mais en &#233;tant toujours mal class&#233;
par rapport aux diff&#233;rentes listes, ce mot a de fortes chances d&#8217;&#234;tre une mauvaise traduction.
</p>
<p>Dans l&#8217;approche par similarit&#233; interlangue, le calcul du score de similarit&#233; se fait sans prendre en consid&#233;ration les
plus proches voisins d&#8217;une mani&#232;re ind&#233;pendante en amont, ainsi la fusion des scores est faite de telle sorte &#224; ce
que les candidats qui ont un score &#233;lev&#233; par rapport &#224; un proche voisin soit privil&#233;gi&#233;s par rapport &#224; des candidats
qui ont un score moins &#233;lev&#233; mais qui apparaissent dans plusieurs listes. Notre approche vise &#224; prendre en compte
ce ph&#233;nom&#232;ne en normalisant les listes des plus proches voisins de la mani&#232;re suivante :
</p>
<p>simk(i, t) = (sim(i, sk)&#215; sim(sk, t))&#215; maxsk
maxs
</p>
<p>(2)
</p>
<p>Le raisonnement qui conduit &#224; ce calcul est le suivant. Les scores des diff&#233;rents classements sont sur la m&#234;me
&#233;chelle car donn&#233;s par la m&#234;me mesure de similarit&#233;. Ainsi, si max (l) &#29; max (m), cela veut dire que, selon le
syst&#232;me, le classement l est plus &#171; s&#251;r &#187; que le classement m (ind&#233;pendamment de la r&#233;ponse r&#233;elle).
</p>
<p>Nous consid&#233;rons ici que les classements, donn&#233;s par les k plus proches voisins du mot &#224; traduire, sont le r&#233;sultat
de k moteurs de RI diff&#233;rents. &#192; l&#8217;instar des m&#233;tamoteurs de recherche, nous allons tenter de nous servir des
scores des mots pour am&#233;liorer l&#8217;extraction bilingue.
</p>
<p>Une des approches majeures en m&#233;tarecherche est le mod&#232;le de fusion lin&#233;aire (LC) (Bartell et al., 1994), o&#249; le
score final d&#8217;un terme, i, est la somme pond&#233;r&#233;e de chacun des scores obtenus :
</p>
<p>sim(i, t) = &#952;t &#215;
&#8721;k
</p>
<p>j=1 simj(i, t)&#8721;n
j=1 sim(sj , t)
</p>
<p>(3)
</p>
<p>Pour r&#233;duire l&#8217;influence des candidats &#224; la traductions qui apparaissent dans diff&#233;rents contextes lexicaux et qui
peuvent par leur forte fr&#233;quence d&#8217;apparition induire en erreur les syst&#232;mes d&#8217;extraction lexicale bas&#233;s sur les</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AMIR HAZEM, EMMANUEL MORIN ET SEBASTI&#193;N PE&#209;A SALDARRIAGA
</p>
<p>contextes, on se propose de prendre en compte ce ph&#233;nom&#232;ne en consid&#233;rant en plus du score calcul&#233; &#224; partir des
k plus proches voisins, un score d&#233;finit &#224; partir de toutes les entr&#233;es du dictionnaire pour lequel le terme candidat
est li&#233;. L&#8217;&#233;quation 3 permet de calculer le score de similarit&#233; entre i et t en prenant en consid&#233;ration le score de
similarit&#233; par rapport aux k plus proche voisins choisis, normalis&#233; par la somme des scores de t par rapport &#224; tout
ses voisins pond&#233;r&#233; par le param&#232;tre de confiance &#952;. Le poids &#952; est donn&#233; par :
</p>
<p>&#952;t = occs(t)&#215; (u&#8722; (k &#8722; occs(t)))
(u&#8722; occn(t)) (4)
</p>
<p>L&#8217;&#233;quation 4 prend en compte l&#8217;effectif du candidat par rapport aux k plus proches voisins, c&#8217;est-&#224;-dire, le nombre
de voisins avec lesquels le mot t est en relation. Ceci est repr&#233;sent&#233; par occs(t). Nous privil&#233;gions ainsi les mots
avec un effectif &#233;lev&#233;. Le num&#233;rateur (u &#8722; (k &#8722; occs(t))) permet de consid&#233;rer l&#8217;effectif de t dans l&#8217;ensemble s
par rapport &#224; tous les mots du dictionnaire. On normalisera ensuite par la distribution de t par rapport &#224; tous ses
voisins &#224; l&#8217;aide de u &#8722; occn(t). Le param&#232;tre &#952; permet donc d&#8217;accorder plus de confiance &#224; un mot candidat &#224; la
traduction qui a un effectif &#233;lev&#233; par rapports aux k plus proches voisins mais qui a aussi un effectif faible par
rapport au reste de ses voisins.
</p>
<p>4 Exp&#233;riences et r&#233;sultats
</p>
<p>4.1 Ressources linguistiques
</p>
<p>Dans le cadre de cette &#233;tude, nous avons construit un corpus comparable sp&#233;cialis&#233; fran&#231;ais-anglais &#224; partir de
documents extraits du portail Elsevier 3. L&#8217;ensemble des documents collect&#233;s rel&#232;ve du domaine m&#233;dical restreint
&#224; la th&#233;matique du &#171; cancer du sein &#187;. Nous avons utilis&#233; l&#8217;interface de recherche du portail pour s&#233;lectionner les
publications scientifiques comportant dans le titre ou les mots cl&#233;s le terme cancer du sein en fran&#231;ais et breast
cancer en anglais pour la p&#233;riode de 2001 &#224; 2008. Les documents ont &#233;t&#233; nettoy&#233;s et normalis&#233;s &#224; travers les trai-
tements suivants : segmentation en occurrences de formes, &#233;tiquetage morpho-syntaxique et lemmatisation. Enfin,
les mots agrammaticaux ont &#233;t&#233; supprim&#233;s et les mots apparaissant moins de deux fois dans la partie fran&#231;aise
et dans chaque partie anglaise &#233;cart&#233;s. Nous avons ainsi construit un corpus comparable sp&#233;cialis&#233; d&#8217;environ 1
million de mots qui est compos&#233; de 130 documents pour le fran&#231;ais (7 376 mots distincts) et 103 documents pour
l&#8217;anglais (8 457 mots distincts).
</p>
<p>Le dictionnaire fran&#231;ais-anglais n&#233;cessaire aux diff&#233;rentes approches comporte, apr&#232;s normalisation, 22 300 mots
pour le fran&#231;ais avec en moyenne 1,6 traductions par entr&#233;e. Il s&#8217;agit d&#8217;un dictionnaire de langue g&#233;n&#233;rale qui ne
contient que peu de termes en rapport avec le domaine m&#233;dical.
</p>
<p>Pour &#233;valuer les diff&#233;rentes approches utilis&#233;es dans cet article, nous avons s&#233;lectionn&#233; 400 couples de mots
simples fran&#231;ais-anglais &#224; partir du meta-thesaurus UMLS 4 et du Grand dictionnaire terminologique 5. Nous
n&#8217;avons ensuite retenu que les couples pour lesquels le mot fran&#231;ais appara&#238;t au moins cinq fois dans la partie
fran&#231;aise et sa traduction au moins cinq fois dans la partie anglaise. Au terme de ce processus de s&#233;lection, nous
disposons d&#8217;une liste de r&#233;f&#233;rence compos&#233;e de 122 couples de termes simples fran&#231;ais-anglais. Cette m&#233;thode
de cr&#233;ation d&#8217;une liste de r&#233;f&#233;rence est diff&#233;rente de celle propos&#233;e par (D&#233;jean &amp; Gaussier, 2002) qui construit
sa liste &#224; partir d&#8217;un sous ensemble du dictionnaire bilingue. Nous pensons que cette approche, plus fiable d&#8217;un
point de vue statistique, ne correspond pas aux v&#233;ritables difficult&#233;s rencontr&#233;es avec des corpus sp&#233;cialis&#233;s. En
effet, en domaine sp&#233;cialis&#233; les termes qui repr&#233;sentent une difficult&#233; de traduction n&#8217;appartiennent par essence
que rarement au dictionnaire de langue g&#233;n&#233;rale. En ce sens, nous pr&#233;f&#233;rons construire notre liste de r&#233;f&#233;rence en
nous appuyant sur des nomenclatures attest&#233;es de termes du domaine non pr&#233;sent dans notre dictionnaire bilingue.
</p>
<p>3. www.elsevier.com
4. www.nlm.nih.gov/research/umls
5. www.granddictionnaire.com</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#201;TARECHERCHE POUR L&#8217;EXTRACTION LEXICALE BILINGUE
</p>
<p>4.2 Param&#232;tres exp&#233;rimentaux
</p>
<p>Trois param&#232;tres communs &#224; toutes les approches sont &#224; fixer : i) la mesure d&#8217;association, ii) la mesure de similarit&#233;
et iii) la taille de la fen&#234;tre utilis&#233;e pour construire les vecteurs de contexte. Comme mesure de similarit&#233; nous
avons choisit le jaccard pond&#233;r&#233; (Grefenstette, 1994b) :
</p>
<p>sim(i, j) =
</p>
<p>&#8721;
tmin (it, jt)&#8721;
tmax (it, jt)
</p>
<p>(5)
</p>
<p>Les entr&#233;es du vecteur de contexte ont &#233;t&#233; d&#233;termin&#233;es par la mesure d&#8217;association du taux de vraisemblance
(Dunning, 1993). La fen&#234;tre contextuelle a &#233;t&#233; fix&#233;e &#224; 7, partant de l&#8217;id&#233;e qu&#8217;elle approxime les d&#233;pendances
syntaxiques. En plus de ces param&#232;tres, notre approche ainsi que l&#8217;approche par similarit&#233; interlangue, ont besoin
de d&#233;finir le nombre de plus proche voisins.
</p>
<p>Nous ne d&#233;taillons pas plus le choix de ces param&#232;tres et renvoyons le lecteur vers (Morin, 2009) qui motive pour
les m&#234;mes ressources le choix de ces param&#232;tres.
</p>
<p>4.3 R&#233;sultats
</p>
<p>Pour &#233;valuer les performances de notre approche, nous utilisons comme r&#233;f&#233;rence l&#8217;approche par similarit&#233; in-
terlangue (ASI) propos&#233;e par (D&#233;jean &amp; Gaussier, 2002). Nous comparons l&#8217;ASI avec les deux strat&#233;gies de
l&#8217;approche par m&#233;tarecherche d&#233;finies dans la section 3 : i) le mod&#232;le qui se base sur les scores de similarit&#233;
(AMS) sans tenir compte de la fiabilit&#233; des candidats ; ii) le mod&#232;le des sources multiples (AMF) qui prend en
compte cette information. Nous allons &#233;tudier la stabilit&#233; des diff&#233;rentes strat&#233;gies de la m&#233;thode m&#233;tarecherche
en fonction de la variation des plus proches voisins.
</p>
<p>1 10 20 30 40 50 60
0
</p>
<p>10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>60
</p>
<p>70
</p>
<p>Nombre de k plus proches voisin
</p>
<p>Pr
&#233;c
</p>
<p>is
io
</p>
<p>n
au
</p>
<p>to
p
</p>
<p>20
</p>
<p>LC
MS
EA
SA
</p>
<p>FIGURE 2 &#8211; Pr&#233;cision au top 20 en fonction du nombre de ppv.
</p>
<p>La figure 2 montre la pr&#233;cision au top 20 en fonction de k. L&#8217;approche par similarit&#233; interlangue (ASI) atteint sa
meilleure performance pour un k = 7 avec une pr&#233;cision de 40, 98%, cette pr&#233;cision commence &#224; d&#233;croitre d&#8217;une
mani&#232;re significative &#224; partir de k = 20.
</p>
<p>L&#8217;approche par m&#233;tarecherche qui ne prend en consid&#233;ration que les scores de similarit&#233; (AMS) sans consid&#233;rer
la fiabilit&#233; des termes candidats &#224; la traduction, montre de meilleurs r&#233;sultats que la m&#233;thode de r&#233;f&#233;rence (ASI) &#224;
partir de k = 10 et obtient une pr&#233;cision maximale de 48, 36% pour un k = 14. On remarque aussi que la courbe
correspondant au mod&#232;le AMS reste au-dessus de la m&#233;thode ASI malgr&#233; l&#8217;augmentation du param&#232;tre k. La
courbe correspondant au mod&#232;le de l&#8217;approche par m&#233;tarecherche qui prend en compte la fiabilit&#233; des candidats</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AMIR HAZEM, EMMANUEL MORIN ET SEBASTI&#193;N PE&#209;A SALDARRIAGA
</p>
<p>(AMF) est toujours au-dessus des autres &#224; partir de k = 10. L&#8217;approche AMF am&#233;liore consid&#233;rablement la
pr&#233;cision et atteint sa meilleure performance avec 60, 65% pour un k = 21. Nous estimons que pour avoir une
bonne exploitation des informations fournies par les diff&#233;rents k plus proches voisins en termes de score de
similarit&#233;, notre syst&#232;me a besoin d&#8217;un minimum de k qui de par nos exp&#233;riences semble &#234;tre k = 10, ce qui
explique les faibles r&#233;sultats pour un k &lt; 10. La raison des faibles r&#233;sultats est simplement que notre syst&#232;me
se base sur l&#8217;effectif des candidats &#224; la traduction par rapport au param&#232;tre k, en d&#8217;autres termes, de combien de
proches voisins un candidat est-il proche ? il est &#233;vident qu&#8217;avec un k faible la notion d&#8217;effectif n&#8217;a pas assez de
poids. Nous consid&#233;rons aussi, que les candidats &#224; la traduction proches d&#8217;un nombre tr&#232;s petit de voisins comme
&#233;tant peu fiables. Ces candidats sont donc ignor&#233;s.
</p>
<p>Nous pouvons noter &#224; travers la figure 2 que les mod&#232;les AMF et AMS sont toujours meilleurs que la m&#233;thode
de r&#233;f&#233;rence (ASI) (&#224; partir de k = 10). De plus, ces mod&#232;les offrent une meilleure stabilit&#233; quant &#224; la variation
des k plus proches voisins. Quoique la pr&#233;cision d&#233;croisse en augmentant les valeurs de k, ceci se fait de mani&#232;re
moins rapide que l&#8217;approche de r&#233;f&#233;rence (ASI).
</p>
<p>Nous comparons aussi nos r&#233;sultats avec ceux obtenus par l&#8217;approche standard (AS). Celle ci est repr&#233;sent&#233;e dans
la figure 2 par une droite car elle ne d&#233;pend pas du param&#232;tre k. L&#8217;approche standard (AS) obtient une pr&#233;cision
de 56, 55% . Bien qu&#8217;elle soit au-dessus de l&#8217;approche par similarit&#233; interlangue (ASI) ainsi que du mod&#232;le AMS
de l&#8217;approche par m&#233;tarecherche, elle est en dessous de notre mod&#232;le AMF pour des valeurs de k entre 20 et 35.
Nous pouvons ainsi consid&#233;rer l&#8217;approche par m&#233;tarecherche comme sup&#233;rieure &#224; l&#8217;approche de r&#233;f&#233;rence (ASI)
mais aussi comme &#233;tant comp&#233;titive par rapport &#224; l&#8217;approche standard (AS).
</p>
<p>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
</p>
<p>5
</p>
<p>10
</p>
<p>15
</p>
<p>20
</p>
<p>25
</p>
<p>Les plus proches voisins
</p>
<p>Pr
e&#769;c
</p>
<p>is
io
</p>
<p>n
au
</p>
<p>to
p
</p>
<p>20
</p>
<p>FIGURE 3 &#8211; Pr&#233;cision au top 20 pour chacun des 20-plus proches voisins . La pr&#233;cision est calcul&#233;e en consid&#233;rant
les k plus proches voisins ind&#233;pendamment les uns des autres.
</p>
<p>La figure 3 montre la contribution de chaque plus proche voisin ind&#233;pendamment des autres. Ceci confirme l&#8217;in-
tuition que chaque proche voisin contribue &#224; la caract&#233;risation du mot &#224; traduire, et confirme notre intuition sur le
fait de les consid&#233;rer ind&#233;pendamment les uns des autres a priori et ceci en dressant pour chacun d&#8217;eux une liste
de candidats, pour ensuite les combiner et ainsi am&#233;liorer les performances.
</p>
<p>Il est &#224; noter que les plus proches voisins sont ordonn&#233;s du plus proche voisin du mot &#224; traduire au plus &#233;loign&#233;.
Bien que chaque plus proche voisin ne puisse traduire qu&#8217;un nombre assez faible de mots, en utilisant l&#8217;id&#233;e de
l&#8217;approche par m&#233;tarecherche, nous pouvons am&#233;liorer les performances en termes de pr&#233;cision. Ainsi l&#8217;id&#233;e du</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#201;TARECHERCHE POUR L&#8217;EXTRACTION LEXICALE BILINGUE
</p>
<p>paradigme de notre m&#233;thode (AMF) est de prendre en compte l&#8217;information v&#233;hicul&#233;e par tous les plus proches
voisins ainsi que le degr&#233; de fiabilit&#233; des candidats pour am&#233;liorer les performance du processus d&#8217;extraction
lexicale.
</p>
<p>Approches Top 5 Top 10 Top 15 Top 20
AS 37,70% 45,08% 52,45% 56,55%
ASI 21,31% 31,14% 36,88% 40,98%
AMF 40,98% 54,09% 56,55% 60,65%
</p>
<p>TABLE 2 &#8211; Pr&#233;cision aux tops 5, 10, 15, 20 des m&#233;thodes AS, ASI et AMF
</p>
<p>Enfin comme dernier r&#233;sultat, nous pr&#233;sentons dans le tableau 3 une comparaison des approches standard (AS),
par similarit&#233; interlangue (ASI) et par m&#233;ta-recherche (AMF), pour le top 5, 10, 15 et 20 et ceci en choisissant
la meilleure configuration des param&#232;tres de chaque approche. Nous constatons que notre approche AMF obtient
une meilleure pr&#233;cision dans chaque situation. Partant du principe que les syst&#232;mes d&#8217;extraction lexicale tentent
d&#8217;approcher le top 10 voir le top 5, nous consid&#232;reront nos r&#233;sultats comme &#233;tant encourageants notamment pour
le top 10 o&#249; AMF atteint 54, 09% ce qui n&#8217;est pas loin de l&#8217;approche standard au top 20.
</p>
<p>4.4 Discussion
</p>
<p>Les approches par similarit&#233; interlangue (ASI) et par m&#233;tarecherche se basent sur les k plus proches voisins pour
identifier les meilleurs candidats &#224; la traduction. L&#8217;approche ASI effectue une fusion en amont, privil&#233;giant ainsi
une vue globale des k plus proches voisins. Ceci peut se r&#233;v&#233;ler probl&#233;matique, car une bonne traduction pourrait
&#234;tre noy&#233;e dans la masse, et ainsi &#234;tre &#233;cart&#233;e de la liste des candidats, si des mots plus fr&#233;quents viennent &#224;
appara&#238;tre dans le contexte du mot &#224; traduire. Plus pr&#233;cis&#233;ment, si des mots obtiennent des scores de similarit&#233;
tr&#232;s &#233;lev&#233;s par rapport &#224; un seul plus proche voisin et que d&#8217;autres obtiennent des scores moins &#233;lev&#233;s mais
proches de plusieurs plus proches voisins du mot &#224; traduire, ces mots seront moins bien class&#233;s voir mal class&#233;s.
Pour pallier ce probl&#232;me, l&#8217;approche AMF consid&#232;re dans un premier temps, chaque plus proche voisin comme
&#233;tant une source d&#8217;information ind&#233;pendante des autres, privil&#233;giant ainsi sa liste de candidats en fixant une taille
arbitraire (g&#233;n&#233;ralement autour de 200 dans nos exp&#233;riences), pour ensuite effectuer une fusion en aval des plus
proches voisins apr&#232;s avoir normalis&#233; les scores de similarit&#233; comme d&#233;crit en section 3. En outre, l&#8217;approche
AMF introduit une mesure de fiabilit&#233;, en consid&#233;rant les plus proches voisins des mots candidats &#224; la traduction
comme &#233;tant proches des k plus proches voisins du mot &#224; traduire, ainsi que tous les voisins de ces candidats,
pour &#233;loigner des mots qui apparaitraient trop fr&#233;quemment et dans trop de contextes. Car ne l&#8217;oublions pas,
ces approches se basent uniquement sur une repr&#233;sentation graphique des donn&#233;es qui induit un certain volume
de bruit, lequel serait sans doute mieux trait&#233; par une analyse plus fine du contexte. Il est &#233;vident que plus les
mots sont fr&#233;quents dans le corpus plus on a une repr&#233;sentation riche de leur contexte. Cette remarque nous
am&#232;ne &#224; nous interroger sur les fr&#233;quences des k plus proches voisins du mot candidat &#224; la traduction. En effet,
si un plus proche voisin appara&#238;t fr&#233;quemment en langue source et que sa traduction en langue cible est faible
ou inversement, quel serait l&#8217;impact de ce d&#233;s&#233;quilibre sur les r&#233;sultats ? Aucune &#233;tude &#224; notre connaissance n&#8217;a
approfondi ce sujet. Quoique rien ne nous permette d&#8217;affirmer une quelconque relation entre ce d&#233;s&#233;quilibre et
une &#233;ventuelle traduction erron&#233;e, nous pouvons n&#233;anmoins supposer que cela est nuisible &#224; une repr&#233;sentation
riche du contexte du mot, car un mot peu fr&#233;quent apporte moins d&#8217;information qu&#8217;un mot tr&#232;s fr&#233;quent et ceci
toujours en se basant sur l&#8217;id&#233;e de la coloration graphique qui caract&#233;rise le contexte. Ainsi nous nous attellerons
dans nos travaux futurs &#224; &#233;tudier cette probl&#233;matique. Enfin, les plus proches voisins ont &#233;t&#233; fix&#233;s d&#8217;une mani&#232;re
empirique dans les deux approches ASI et AMF, et dans toutes les &#233;valuations. Nous avons fix&#233; un m&#234;me k pour
tous les mots de la liste d&#8217;&#233;valuation. L&#8217;&#233;tat de l&#8217;art ne sp&#233;cifie aucune mani&#232;re efficace de choisir ce param&#232;tre
k. N&#233;anmoins, nous sommes en droit de nous interroger pour savoir s&#8217;il existe un nombre k id&#233;al de plus proches
voisins qui puisse garantir une bonne traduction de tous les mots de la liste d&#8217;&#233;valuation ? On serait plut&#244;t tent&#233;
de dire qu&#8217;il existe un k pour chaque mot &#224; traduire mais que celui-ci varie selon les mots. L&#224; encore, nos travaux
futurs devront r&#233;pondre &#224; cette question cl&#233;.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>AMIR HAZEM, EMMANUEL MORIN ET SEBASTI&#193;N PE&#209;A SALDARRIAGA
</p>
<p>5 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; dans cet article une nouvelle mani&#232;re d&#8217;aborder le probl&#232;me de l&#8217;extraction lexicale bilingue
&#224; partir de corpus comparables en nous appuyant sur le principe des m&#233;tamoteurs de recherche. Nous avons ainsi
pr&#233;sent&#233; une nouvelle approche simple et robuste qui revisite la m&#233;thode par similarit&#233; interlangue pour pr&#233;senter
un mod&#232;le inspir&#233; par les m&#233;tamoteurs de recherche d&#8217;information. Ce mod&#232;le qui prend en compte la distribution
des candidats &#224; la traduction non seulement par rapport au k plus proches voisins du mot &#224; traduire mais aussi par
rapport &#224; tout leurs voisins, a permis un gain significatif en terme de pr&#233;cision. Les r&#233;sultats empiriques que nous
obtenons montrent que les performances de ce nouveau mod&#232;le sont toujours sup&#233;rieures &#224; celles obtenues avec
l&#8217;approche par similarit&#233; interlangue pour k &gt; 10, mais aussi comme &#233;tant comp&#233;titives par rapport &#224; l&#8217;approche
standard.
</p>
<p>Remerciements
</p>
<p>Ce travail qui s&#8217;inscrit dans le cadre du projet METRICC (www.metricc.com) a b&#233;n&#233;fici&#233; d&#8217;une aide de
l&#8217;Agence Nationale de la Recherche portant la r&#233;f&#233;rence ANR-08-CORD-009.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ASLAM J. A. &amp; MONTAGUE M. (2001). Models for Metasearch. In SIGIR &#8217;01, proceedings of the 24th Annual
SIGIR Conference, p. 276&#8211;284.
</p>
<p>BARTELL B. T., COTTRELL G. W. &amp; BELEW R. K. (1994). Automatic combination of multiple ranked retrieval
systems. In SIGIR &#8217;94, proceedings of the 17th Annual SIGIR Conference, p. 173&#8211;181.
</p>
<p>CHIAO Y.-C. &amp; ZWEIGENBAUM P. (2003). The Effect of a General Lexicon in Corpus-Based Identification of
French-English Medical Word Translations. In R. BAUD, M. FIESCHI, P. LE BEUX &amp; P. RUCH, Eds., The New
Navigators : from Professionals to Patients, Actes Medical Informatics Europe, volume 95 of Studies in Health
Technology and Informatics, p. 397&#8211;402, Amsterdam : IOS Press.
</p>
<p>DAILLE B. &amp; MORIN E. (2005). French-English Terminology Extraction from Comparable Corpora. In Pro-
ceedings of the 2nd International Joint Conference on Natural Language Processing (IJCLNP&#8217;05), p. 707&#8211;718,
Jeju Island, Korea.
</p>
<p>D&#201;JEAN H. &amp; GAUSSIER E. (2002). Une nouvelle approche &#224; l&#8217;extraction de lexiques bilingues &#224; partir de
corpus comparables. Lexicometrica, Alignement lexical dans les corpus multilingues, p. 1&#8211;22.
</p>
<p>D&#201;JEAN H., SADAT F. &amp; GAUSSIER E. (2002). An approach based on multilingual thesauri and model combi-
nation for bilingual lexicon extraction. In Proceedings of the 19th International Conference on Computational
Linguistics (COLING&#8217;02), p. 218&#8211;224, Tapei, Taiwan.
</p>
<p>DUNNING T. (1993). Accurate Methods for the Statistics of Surprise and Coincidence. Computational Linguis-
tics, 19(1), 61&#8211;74.
FANO R. M. (1961). Transmission of Information : A Statistical Theory of Communications. Cambridge, MA,
USA : MIT Press.
</p>
<p>FUNG P. (1998). A Statistical View on Bilingual Lexicon Extraction : From ParallelCorpora to Non-parallel
Corpora. In D. FARWELL, L. GERBER &amp; E. HOVY, Eds., Proceedings of the 3rd Conference of the Association
for Machine Translation in the Americas (AMTA&#8217;98), p. 1&#8211;16, Langhorne, PA, USA.
</p>
<p>FUNG P. &amp; LO Y. Y. (1998). An ir approach for translating new words from nonparallel, comparable texts. In
Proceedings of the 17th international conference on Computational linguistics (COLING&#8217;98), p. 414&#8211;420.
</p>
<p>FUNG P. &amp; MCKEOWN K. (1997). Finding Terminology Translations from Non-parallel Corpora. In Procee-
dings of the 5th Annual Workshop on Very Large Corpora (VLC&#8217;97), p. 192&#8211;202, Hong Kong.
</p>
<p>GREFENSTETTE G. (1994a). Corpus-Derived First, Second and Third-Order Word Affinities. In Proceedings of
the 6th Congress of the European Association for Lexicography (EURALEX&#8217;94), p. 279&#8211;290, Amsterdam, The
Netherlands.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#201;TARECHERCHE POUR L&#8217;EXTRACTION LEXICALE BILINGUE
</p>
<p>GREFENSTETTE G. (1994b). Explorations in Automatic Thesaurus Discovery. Boston, MA, USA : Kluwer
Academic Publisher.
</p>
<p>LAROCHE A. &amp; LANGLAIS P. (2010). Revisiting context-based projection methods for term-translation spotting
in comparable corpora. In Proceedings of the 23rd International Conference on Computational Linguistics,
COLING &#8217;10, p. 617&#8211;625, Stroudsburg, Pekin, Chine : Association for Computational Linguistics.
</p>
<p>MORIN E. (2009). Apport d&#8217;un corpus comparable d&#233;s&#233;quilibr&#233; &#224; l&#8217;extraction de lexiques bilingues. In Actes de
la 16&#232;me Conf&#233;rence annuelle sur le Traitement Automatique des Langues Naturelles (TALN) Senlis France., p.
101&#8211;110.
</p>
<p>OTERO P. G. (2007). Learning bilingual lexicons from comparable english and spanish corpora. In Proceedings
of Machine Translation Summit XI, p. 191&#8211;198.
</p>
<p>RAPP R. (1995). Identify Word Translations in Non-Parallel Texts. In Proceedings of the 35th Annual Meeting
of the Association for Computational Linguistics (ACL&#8217;95), p. 320&#8211;322, Boston, MA, USA.
</p>
<p>SALTON G. &amp; LESK M. E. (1968). Computer evaluation of indexing and text processing. Journal of the
Association for Computational Machinery, 15(1), 8&#8211;36.
YU K. &amp; TSUJII J. (2009). Bilingual dictionary extraction from wikipedia. In Proceedings of Machine Transla-
tion Summit XII.</p>

</div></div>
</body></html>