
Métarecherche pour l’extraction lexicale bilingue à partir de corpus
comparables

Amir Hazem1 Emmanuel Morin1 Sebastián Peña Saldarriaga2
(1) Université de Nantes, LINA - UMR CNRS 6241
2 rue de la Houssinière, BP 92208, 44322 Nantes Cedex 03
(2) Synchromedia, École de technologie supérieure
1100 rue Notre-Dame Ouest, Montréal, Québec, Canada H3C 1K3
amir.hazem@univ-nantes.fr, emmanuel.morin@univ-nantes.fr, spena@synchromedia.ca

Résumé.          Nous présentons dans cet article une nouvelle manière d’aborder le problème de l’acquisition
automatique de paires de mots en relation de traduction à partir de corpus comparables. Nous décrivons tout
d’abord les approches standard et par similarité interlangue traditionnellement dédieés à cette tâche. Nous ré-
interprétons ensuite la méthode par similarité interlangue et motivons un nouveau modèle pour reformuler cette
approche inspireé par les métamoteurs de recherche d’information. Les résultats empiriques que nous obtenons
montrent que les performances de notre modèle sont toujours supérieures à celles obtenues avec l’approche par
similarité interlangue, mais aussi comme étant compétitives par rapport à l’approche standard.
Abstract. In this article we present a novel way of looking at the problem of automatic acquisition of pairs of
translationally equivalent words from comparable corpora. We first describe the standard and extended approaches
traditionally dedicated to this task. We then re-interpret the extended method, and motivate a novel model to
reformulate this approach inspired by the metasearch engines in information retrieval. The empirical results show
that performances of our model are always better than the baseline obtained with the extended approach and also
competitive with the standard approach.
Mots-clés :         Corpus comparables, lexiques bilingues, métarecherche.

Keywords:           Comparable corpora, bilingual lexicon, metasearch.
1    Introduction

L’extraction de lexiques bilingues à partir de corpus comparables est un domaine de recherche en pleine efferves-
cence qui vise notamment à offrir une alternative crédible à l’exploitation de corpus parallèles. En effet, les corpus
parallèles sont par nature des ressources rares notamment pour les domaines spécialisés et pour des couples de
langues ne faisant pas intervenir l’anglais, là ou les corpus comparables sont par essence des ressources abon-
dantes puisque composés de documents partageant différentes caractéristiques telles que le domaine, le genre, la
période, etc. sans être en correspondance de traduction. Les lexiques bilingues extraits à partir de corpus compa-
rables sont néanmoins d’une qualité bien inférieure à ce qui peut être obtenu à partir de corpus parallèles. Cette
difficulté à extraire des lexiques bilingues peu bruités à partir de corpus comparables explique pourquoi ce champ
de recherche n’a pas encore franchi le cap de l’industrialisation à la différence des corpus parallèles et reste encore
majoritairement cantonné à une activité de recherche prometteuse. La principale difficulté des approches lieés à
l’exploitation de corpus comparables par rapport aux corpus parallèles pour l’extraction de lexiques bilingues,
est l’absence d’éléments d’ancrage entre les documents des langues source et cible composant le corpus compa-
rable. Face à cette difficulté les différentes approches lieés à l’exploitation de corpus comparables reposent sur la
simple observation qu’un mot et sa traduction ont tendance à apparaître dans les mêmes environnements lexicaux.
La mise en œuvre de cette observation repose sur l’identification d’affinités du premier ordre (i.e. identifier les
mots qui sont susceptibles d’être trouvés dans le voisinage immédiat d’un mot donné) ou d’affinités du second
ordre (i.e. identifier les mots qui partagent les mêmes environnements lexicaux sans nécessairement apparaître
ensemble) (Grefenstette, 1994a, p. 279). Les approches associeés à l’identification de ces affinités sont, d’une
A MIR H AZEM , E MMANUEL M ORIN ET S EBASTIÁN P EÑA S ALDARRIAGA

part, l’approche standard (Rapp, 1995; Fung & McKeown, 1997) qui est l’approche majoritairement exploiteé, et
d’autre part, l’approche par similarité interlangue (Déjean & Gaussier, 2002).
Dans cette article, nous reprenons à notre compte l’ideé de (Fung, 1998) qui indique que l’extraction de lexiques
bilingues à partir de corpus comparables peut être approcheé comme un problème de recherche d’information.
Dans cette représentation, la requête serait alors les mots à traduire et les documents retournés par le moteur
de recherche les candidats à la traduction de ce mot. Et de la même manière que les documents retournés sont
ordonnés suivant leur adéquation avec la requête, les traductions candidates sont classeés en fonction de leur per-
tinence par rapport au mot à traduire. Nous souhaitons donc poursuivre plus en avant cette analogie et proposer
une amélioration significative à l’approche par similarité interlangue en considérant l’extraction de lexiques bi-
lingues comme un problème de fusion de résultats analogue à celui rencontré par les métamoteurs de recherche
d’information. Nous faisons ainsi l’hypothèse que le fait de combiner différentes sources d’information permet de
renforcer globalement la méthode par similarité interlangue.
Dans la suite de cet article, nous commençons par rappeler en section 2 les deux méthodes phares en extraction de
lexiques bilingues à partir de corpus comparables, à savoir les méthodes dites standard et par similarité interlangue.
La section 3 est quant à elle dédieé à la présentation de notre approche par métarecherche qui revisite l’approche
par similarité interlangue. La section 4 se concentre sur l’évaluation des trois méthodes mises en œuvre et ouvre
une discussion sur les limites de notre approche. Enfin la section 5 vient conclure ce travail.
2      Principales approches en extraction lexicale bilingue à partir de corpus
comparables

Dans cette section, nous allons décrire les deux principales approches dédieés à l’extraction de lexiques bilingues
à partir de corpus comparables, à savoir : l’approche standard, puis l’approche par similarité interlangue.
2.1      Approche standard

Les principaux travaux en extraction de lexiques bilingues à partir de corpus comparables sont basés sur une
analyse du contexte lexical des mots et reposent sur la simple observation qu’un mot et sa traduction tendent à
apparaître dans les mêmes contextes lexicaux. La mise en œuvre de cette observation repose sur l’identification
d’affinités du premier ordre : « Les affinités du premier ordre décrivent les mots qui sont susceptibles d’être trouvés
dans le voisinage immédiat d’un mot donné. 1 » (Grefenstette, 1994a, p. 279). Elles peuvent être représenteés sous
la forme d’un vecteur de contexte, où chaque élément du vecteur représente un mot qui apparaît dans différentes
fenêtres contextuelles.
L’implémentation de l’approche standard peut être décrite par les quatre étapes suivantes (Rapp, 1995; Fung &
McKeown, 1997) :
1. Identification des contextes lexicaux
Pour chaque partie du corpus comparable, le contexte de chaque mot plein i est extrait en repérant les mots
qui apparaissent autour de lui dans une fenêtre contextuelle de n mots. Pour chaque mot i des langues
source et cible, un vecteur de contexte i est ainsi obtenu. À chaque entreé ij du vecteur est associeé un
score de cooccurrence des mots i et j. Habituellement, les mesures d’association comme l’information
mutuelle (Fano, 1961), ou le taux de vraisemblance (Dunning, 1993) sont utiliseés pour définir les entreés
des vecteurs de contextes.
2. Transfert d’un mot à traduire
Les mots d’un vecteur de contexte i, pour lequel une traduction est rechercheé, sont ensuite traduits en
s’appuyant sur un dictionnaire bilingue. Si le dictionnaire propose plusieurs traductions pour un élément,
nous ajoutons au vecteur de contexte de i l’ensemble des traductions proposeés (lesquelles sont pondéreés
par la fréquence de la traduction en langue cible). Les entreés n’ayant pas de traductions dans le dictionnaire
bilingue seront quant à elle tout simplement ignoreés.

1. First-order affinities describe what other words are likely to be found in the immediate vicinity of a given word
M ÉTARECHERCHE POUR L’ EXTRACTION LEXICALE BILINGUE

3. Identification des vecteurs proches du mot à traduire
Une mesure de similarité, sim(i, t), est utiliseé pour calculer le score entre chaque mot, t, de la langue cible
et le vecteur de contexte traduit du mot i. Parmi les mesures de similarité les plus souvent usiteés pour cette
tâche, nous retrouvons le cosinus (Salton & Lesk, 1968) ou le jaccard pondéré (Grefenstette, 1994b).
4. Obtention des traductions candidates
Les candidats à la traduction d’un mot i à traduire sont finalement ordonnés par ordre décroissant suivant
leur score de similarité.
Deux remarques s’imposent ici en ce qui concerne cette approche standard. D’une part, cette approche met en
œuvre différents paramètres (taille de la fenêtre contextuelle, choix des mesures d’association et de similarité...)
dont il est parfois peu aisé d’identifier les valeurs adéquates pour une recherche optimum (voir par exemple le
travail de (Laroche & Langlais, 2010) pour l’influence de ces paramètres sur la qualité des résultats). D’autre part,
l’approche standard qui repose originellement sur des cooccurrences graphiques peut aussi être implémenteé avec
des cooccurrences syntaxiques (Yu & Tsujii, 2009; Otero, 2007).
Dictionnaire Bilingue
Langue source   Langue cible
mot             mot

mot             mot
mot

mot                            Identifier k                 mot             mot
mot                      Identifier         ...
vecteurs similaires           mot             mot
mot
les candidats
mot             mot
.               .
.               .
.               .

1
F IGURE 1 – Illustration de la méthode par similarité interlangue.
2.2     Approche par similarité interlangue

Le principal inconvénient de l’approche standard est que ses performances dépendent grandement de la couverture
du dictionnaire bilingue par rapport au corpus comparable. En effet, en traduisant un maximum d’entreés du
vecteur de contexte du mot à traduire, on maximise les chances de retrouver sa traduction. Bien que la couverture
du dictionnaire puisse être étendue en utilisant des dictionnaires spécialisés ou des thésaurus multilingues (Chiao
& Zweigenbaum, 2003; Déjean et al., 2002), la traduction des éléments du vecteur de contexte reste le cœur de
cette approche.
Dans le but d’être moins dépendants de ce dictionnaire, (Déjean & Gaussier, 2002) ont proposé une extension de
l’approche standard connue sous le nom d’approche par similarité interlangue. Cette approche se base sur l’ideé
que les mots ayant le même sens, partagent les mêmes environnements lexicaux. Elle repose sur l’identification
d’affinités du second ordre : « Les affinités du second ordre dévoilent quels mots partagent les mêmes environ-
nements. Les mots partageant des affinités du second ordre n’ont pas besoin d’apparaître ensemble, mais leurs
environnements sont semblables. 2 »
Dans cette approche, le dictionnaire bilingue établit un pont entre les langues du corpus comparable. L’approche
par similarité interlangue est baseé sur ce principe et évite les traductions directes des éléments des vecteurs de
contextes comme le montre la figure 1. L’implémentation de cette approche peut être réaliseé en quatre étapes
où la première et la dernière sont identiques à celles de l’approche standard (Déjean & Gaussier, 2002; Daille &
Morin, 2005) :
2. Sélection des k plus proches voisins
Pour chaque mot à traduire, les k plus proches voisins sont identifiés parmi les entreés du dictionnaire selon
2. Second-order affinities show which words share the same environments. Words sharing second-order affinities need never appear toge-
ther themselves, but their environments are similar
A MIR H AZEM , E MMANUEL M ORIN ET S EBASTIÁN P EÑA S ALDARRIAGA

sim(i, s). Chaque plus proche voisin est ensuite traduit à l’aide du dictionnaire bilingue, et le vecteur de
contexte de langue cible s correspondant à la traduction est sélectionné. Si pour un plus proche voisin il
existe plusieurs traductions, s est donné par l’union des vecteurs correspondant aux différentes traductions.
Il est à noter que les vecteurs de contexte ne sont pas traduits directement, ce qui réduit l’influence du
dictionnaire.
3. Identification des vecteurs proches du mot à traduire
La mesure de similarité, sim(s, t), est utiliseé pour calculer le score entre chaque mot t de la langue cible
en fonction des k plus proches voisins. Le score final attribué à chaque mot t est donné par :

sim(i, t) =            sim(i, s) × sim(s, t)                            (1)
s∈kPPV

Une autre manière de calculer le score de similarité a été proposeé par (Daille & Morin, 2005). Les auteurs
calculent alors le barycentre des vecteurs de contexte des k plus proches voisins.
3     Extraction lexicale bilingue par métarecherche

3.1   Motivations

L’approche proposeé par (Déjean & Gaussier, 2002) introduit implicitement le problème du choix de la valeur
adéquate de k dans les k plus proches voisins. D’une manière générale, la valeur optimale de k dépend des
donneés mises en jeu. Cette valeur est souvent définie de façon empirique, bien qu’il soit possible de la déterminer
par validation croiseé. L’approche par similarité interlangue (ASI) appliqueé à nos donneés s’est révéleé très
sensible vis-à-vis du paramètre k. En effet, pour des valeurs de k supérieures à 20, la précision chute de façon
significative. De plus, il n’est pas possible de déterminer des intervalles de stabilité relative pour k. Le choix du
paramètre k devient alors crucial.
En partant du principe que chaque mot contribue à la caractérisation du mot à traduire, notre proposition vise non
seulement à améliorer la précision, mais aussi à être plus robuste vis-à-vis du nombre de plus proches voisins. En
poussant l’analogie des approches inspireés de la RI (Fung & Lo, 1998) plus loin, nous proposons une nouvelle
façon d’aborder le problème de l’extraction lexicale bilingue à partir de corpus comparables, en le considérant
comme un problème de fusion de résultats analogue à celui rencontré par les métamoteurs de recherche.
L’objectif de la métarecherche est de fusionner les classements renvoyés par plusieurs systèmes de RI, en une
liste unique, afin d’obtenir un système combiné qui soit plus performant que les systèmes individuels (Aslam &
Montague, 2001). Puisque chacun des k plus proches voisins produit un classement différent, la métarecherche
fourni un cadre adéquat pour exploiter l’information véhiculeé par chacun des k classements. En outre, un intérêt
particulier est donné aux mots candidats à la traduction d’un mot donné. En effet, partant du principe que les
corpus contiennent beaucoup de bruit, il n’est pas rare de rencontrer des mots qui soient proches d’un nombre
important de mots du dictionnaire, et ainsi, viennent parasiter le modèle et fausser les résultats. En effet, pour
traduire un mot, le système choisit un nombre k de plus proches voisins en langue source, puis il cherche en
langue cible les candidats les plus proches des traductions de ces k plus proches voisins sans tenir compte de la
relation de ces candidats avec le reste des mots du dictionnaire. Pour pallier cela, nous construisons un modèle qui
prend en compte cette information en accordant plus de confiance aux candidats qui sont plus proches des k plus
proches voisins que du reste des entreés du dictionnaire.
3.2   Approche par métarecherche

Cette section décrit notre extension de l’approche par similarité interlangue. Les différents modes de fusion définis
ici se basent sur les éléments décrits dans la table 1.
La première étape de notre méthode consiste à fixer le nombre de plus proches voisins d’un mot à traduire. La
valeur de k est détermineé empiriquement. Cependant, intuitivement mais aussi à travers nos expériences, nous
pouvons dire que la sélection d’un nombre faible de plus proches voisins est insuffisante dans la plus part des cas
M ÉTARECHERCHE POUR L’ EXTRACTION LEXICALE BILINGUE

Symbole       Définition
i             Le mot à traduire
t             Le mot candidat à la traduction de i
s             L’ensemble des plus proches voisins de i
s             L’ensemble des traductions des plus proches voisins de i
k             Le nombre de plus proches voisins sélectionnés
n             L’ensemble de tous les voisins de t
u             Le nombre total de mots du dictionnaire
occs(t)       L’effectif de t ie : avec combien de voisin t est-il en relation ?
sim(sk , t)   Le score de similarité entre le k ième proche voisin de s et t
maxsk         Le score maximum du candidat le plus proche de sk
maxs          Le score maximum du candidat le plus proche de l’ensemble s
simk (s, t)   Le score de similarité entre s et t par rapport au k ième plus proche voisin
sim(s, t)     Le score de similarité entre s et t par rapport à l’ensemble des plus proches voisins
θt            Le paramètre de régulation ou facteur de confiance de t

TABLE 1 – Éléments de notation.
pour trouver la bonne traduction, et que la sélection d’un grand nombre de voisins, d’une part contredit la notion
de plus proches voisins et d’autre part, induit la prise en compte de voisins éloignés qui peuvent fausser le modèle.
Une fois k fixé, nous considérons chaque liste de candidats renvoyeé par un proche voisin indépendamment des
autres. Ces candidats sont les mots dont les vecteurs de contexte sont les plus similaires au vecteur de contexte
d’un voisin donneé. Dans nos expériences, la taille des listes a été fixeé à 200. Partant du même principe que le
choix du paramètre k. La taille de la liste joue un rôle important, en effet, une liste trop petite de candidats ne serait
pas suffisante pour aider à trouver la bonne traduction, de la même façon, une liste trop importante de mots risque
de rajouter du bruit car il faut garder en tête que les mots appartenant à une liste sont les traductions potentielles
classeés par ordre de score de similarité. Notre modèle privilégie les candidats qui apparaissent dans plusieurs
listes, ainsi, plus l’effectif du mot candidat est important plus il a de chances d’être la bonne traduction, ceci dit,
ceci reste valable si le candidat est bien classé, en revanche, s’il apparaît souvent mais en étant toujours mal classé
par rapport aux différentes listes, ce mot a de fortes chances d’être une mauvaise traduction.
Dans l’approche par similarité interlangue, le calcul du score de similarité se fait sans prendre en considération les
plus proches voisins d’une manière indépendante en amont, ainsi la fusion des scores est faite de telle sorte à ce
que les candidats qui ont un score élevé par rapport à un proche voisin soit privilégiés par rapport à des candidats
qui ont un score moins élevé mais qui apparaissent dans plusieurs listes. Notre approche vise à prendre en compte
ce phénomène en normalisant les listes des plus proches voisins de la manière suivante :

maxsk
simk (i, t) = (sim(i, sk ) × sim(sk , t)) ×                                         (2)
maxs

Le raisonnement qui conduit à ce calcul est le suivant. Les scores des différents classements sont sur la même
échelle car donnés par la même mesure de similarité. Ainsi, si max (l)     max (m), cela veut dire que, selon le
système, le classement l est plus « sûr » que le classement m (indépendamment de la réponse reélle).
Nous considérons ici que les classements, donnés par les k plus proches voisins du mot à traduire, sont le résultat
de k moteurs de RI différents. À l’instar des métamoteurs de recherche, nous allons tenter de nous servir des
scores des mots pour améliorer l’extraction bilingue.
Une des approches majeures en métarecherche est le modèle de fusion linéaire (LC) (Bartell et al., 1994), où le
score final d’un terme, i, est la somme pondéreé de chacun des scores obtenus :

k
j=1 simj (i, t)
sim(i, t) = θt ×      n                                                     (3)
j=1 sim(sj , t)
Pour réduire l’influence des candidats à la traductions qui apparaissent dans différents contextes lexicaux et qui
peuvent par leur forte fréquence d’apparition induire en erreur les systèmes d’extraction lexicale basés sur les
A MIR H AZEM , E MMANUEL M ORIN ET S EBASTIÁN P EÑA S ALDARRIAGA

contextes, on se propose de prendre en compte ce phénomène en considérant en plus du score calculé à partir des
k plus proches voisins, un score définit à partir de toutes les entreés du dictionnaire pour lequel le terme candidat
est lié. L’équation 3 permet de calculer le score de similarité entre i et t en prenant en considération le score de
similarité par rapport aux k plus proche voisins choisis, normalisé par la somme des scores de t par rapport à tout
ses voisins pondéré par le paramètre de confiance θ. Le poids θ est donné par :
(u − (k − occs (t)))
θt = occs (t) ×                                                           (4)
(u − occn (t))
L’équation 4 prend en compte l’effectif du candidat par rapport aux k plus proches voisins, c’est-à-dire, le nombre
de voisins avec lesquels le mot t est en relation. Ceci est représenté par occs (t). Nous privilégions ainsi les mots
avec un effectif élevé. Le numérateur (u − (k − occs (t))) permet de considérer l’effectif de t dans l’ensemble s
par rapport à tous les mots du dictionnaire. On normalisera ensuite par la distribution de t par rapport à tous ses
voisins à l’aide de u − occn (t). Le paramètre θ permet donc d’accorder plus de confiance à un mot candidat à la
traduction qui a un effectif élevé par rapports aux k plus proches voisins mais qui a aussi un effectif faible par
rapport au reste de ses voisins.
4     Expériences et résultats

4.1    Ressources linguistiques

Dans le cadre de cette étude, nous avons construit un corpus comparable spécialisé français-anglais à partir de
documents extraits du portail Elsevier 3 . L’ensemble des documents collectés relève du domaine médical restreint
à la thématique du « cancer du sein ». Nous avons utilisé l’interface de recherche du portail pour sélectionner les
publications scientifiques comportant dans le titre ou les mots clés le terme cancer du sein en français et breast
cancer en anglais pour la période de 2001 à 2008. Les documents ont été nettoyés et normalisés à travers les trai-
tements suivants : segmentation en occurrences de formes, étiquetage morpho-syntaxique et lemmatisation. Enfin,
les mots agrammaticaux ont été supprimés et les mots apparaissant moins de deux fois dans la partie française
et dans chaque partie anglaise écartés. Nous avons ainsi construit un corpus comparable spécialisé d’environ 1
million de mots qui est composé de 130 documents pour le français (7 376 mots distincts) et 103 documents pour
l’anglais (8 457 mots distincts).
Le dictionnaire français-anglais nécessaire aux différentes approches comporte, après normalisation, 22 300 mots
pour le français avec en moyenne 1,6 traductions par entreé. Il s’agit d’un dictionnaire de langue générale qui ne
contient que peu de termes en rapport avec le domaine médical.
Pour évaluer les différentes approches utiliseés dans cet article, nous avons sélectionné 400 couples de mots
simples français-anglais à partir du meta-thesaurus UMLS 4 et du Grand dictionnaire terminologique 5 . Nous
n’avons ensuite retenu que les couples pour lesquels le mot français apparaît au moins cinq fois dans la partie
française et sa traduction au moins cinq fois dans la partie anglaise. Au terme de ce processus de sélection, nous
disposons d’une liste de référence composeé de 122 couples de termes simples français-anglais. Cette méthode
de création d’une liste de référence est différente de celle proposeé par (Déjean & Gaussier, 2002) qui construit
sa liste à partir d’un sous ensemble du dictionnaire bilingue. Nous pensons que cette approche, plus fiable d’un
point de vue statistique, ne correspond pas aux véritables difficultés rencontreés avec des corpus spécialisés. En
effet, en domaine spécialisé les termes qui représentent une difficulté de traduction n’appartiennent par essence
que rarement au dictionnaire de langue générale. En ce sens, nous préférons construire notre liste de référence en
nous appuyant sur des nomenclatures attesteés de termes du domaine non présent dans notre dictionnaire bilingue.
3. www.elsevier.com
4. www.nlm.nih.gov/research/umls
5. www.granddictionnaire.com
M ÉTARECHERCHE POUR L’ EXTRACTION LEXICALE BILINGUE

4.2    Paramètres expérimentaux

Trois paramètres communs à toutes les approches sont à fixer : i) la mesure d’association, ii) la mesure de similarité
et iii) la taille de la fenêtre utiliseé pour construire les vecteurs de contexte. Comme mesure de similarité nous
avons choisit le jaccard pondéré (Grefenstette, 1994b) :

min (it , jt )
sim(i, j) =        t
(5)
t max (it , jt )

Les entreés du vecteur de contexte ont été détermineés par la mesure d’association du taux de vraisemblance
(Dunning, 1993). La fenêtre contextuelle a été fixeé à 7, partant de l’ideé qu’elle approxime les dépendances
syntaxiques. En plus de ces paramètres, notre approche ainsi que l’approche par similarité interlangue, ont besoin
de définir le nombre de plus proche voisins.
Nous ne détaillons pas plus le choix de ces paramètres et renvoyons le lecteur vers (Morin, 2009) qui motive pour
les mêmes ressources le choix de ces paramètres.
4.3    Résultats

Pour évaluer les performances de notre approche, nous utilisons comme référence l’approche par similarité in-
terlangue (ASI) proposeé par (Déjean & Gaussier, 2002). Nous comparons l’ASI avec les deux stratégies de
l’approche par métarecherche définies dans la section 3 : i) le modèle qui se base sur les scores de similarité
(AMS) sans tenir compte de la fiabilité des candidats ; ii) le modèle des sources multiples (AMF) qui prend en
compte cette information. Nous allons étudier la stabilité des différentes stratégies de la méthode métarecherche
en fonction de la variation des plus proches voisins.

70
LC
MS
60                                                            EA
SA
50
Précision au top 20
40

30

20

10

0
1   10      20         30         40           50   60
Nombre de k plus proches voisin
F IGURE 2 – Précision au top 20 en fonction du nombre de ppv.

La figure 2 montre la précision au top 20 en fonction de k. L’approche par similarité interlangue (ASI) atteint sa
meilleure performance pour un k = 7 avec une précision de 40, 98%, cette précision commence à décroitre d’une
manière significative à partir de k = 20.
L’approche par métarecherche qui ne prend en considération que les scores de similarité (AMS) sans considérer
la fiabilité des termes candidats à la traduction, montre de meilleurs résultats que la méthode de référence (ASI) à
partir de k = 10 et obtient une précision maximale de 48, 36% pour un k = 14. On remarque aussi que la courbe
correspondant au modèle AMS reste au-dessus de la méthode ASI malgré l’augmentation du paramètre k. La
courbe correspondant au modèle de l’approche par métarecherche qui prend en compte la fiabilité des candidats
A MIR H AZEM , E MMANUEL M ORIN ET S EBASTIÁN P EÑA S ALDARRIAGA

(AMF) est toujours au-dessus des autres à partir de k = 10. L’approche AMF améliore considérablement la
précision et atteint sa meilleure performance avec 60, 65% pour un k = 21. Nous estimons que pour avoir une
bonne exploitation des informations fournies par les différents k plus proches voisins en termes de score de
similarité, notre système a besoin d’un minimum de k qui de par nos expériences semble être k = 10, ce qui
explique les faibles résultats pour un k < 10. La raison des faibles résultats est simplement que notre système
se base sur l’effectif des candidats à la traduction par rapport au paramètre k, en d’autres termes, de combien de
proches voisins un candidat est-il proche ? il est évident qu’avec un k faible la notion d’effectif n’a pas assez de
poids. Nous considérons aussi, que les candidats à la traduction proches d’un nombre très petit de voisins comme
étant peu fiables. Ces candidats sont donc ignorés.
Nous pouvons noter à travers la figure 2 que les modèles AMF et AMS sont toujours meilleurs que la méthode
de référence (ASI) (à partir de k = 10). De plus, ces modèles offrent une meilleure stabilité quant à la variation
des k plus proches voisins. Quoique la précision décroisse en augmentant les valeurs de k, ceci se fait de manière
moins rapide que l’approche de référence (ASI).
Nous comparons aussi nos résultats avec ceux obtenus par l’approche standard (AS). Celle ci est représenteé dans
la figure 2 par une droite car elle ne dépend pas du paramètre k. L’approche standard (AS) obtient une précision
de 56, 55% . Bien qu’elle soit au-dessus de l’approche par similarité interlangue (ASI) ainsi que du modèle AMS
de l’approche par métarecherche, elle est en dessous de notre modèle AMF pour des valeurs de k entre 20 et 35.
Nous pouvons ainsi considérer l’approche par métarecherche comme supérieure à l’approche de référence (ASI)
mais aussi comme étant compétitive par rapport à l’approche standard (AS).
25
20
Précision au top 20
15
10
5
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
Les plus proches voisins
F IGURE 3 – Précision au top 20 pour chacun des 20-plus proches voisins . La précision est calculeé en considérant
les k plus proches voisins indépendamment les uns des autres.

La figure 3 montre la contribution de chaque plus proche voisin indépendamment des autres. Ceci confirme l’in-
tuition que chaque proche voisin contribue à la caractérisation du mot à traduire, et confirme notre intuition sur le
fait de les considérer indépendamment les uns des autres a priori et ceci en dressant pour chacun d’eux une liste
de candidats, pour ensuite les combiner et ainsi améliorer les performances.
Il est à noter que les plus proches voisins sont ordonnés du plus proche voisin du mot à traduire au plus éloigné.
Bien que chaque plus proche voisin ne puisse traduire qu’un nombre assez faible de mots, en utilisant l’ideé de
l’approche par métarecherche, nous pouvons améliorer les performances en termes de précision. Ainsi l’ideé du
M ÉTARECHERCHE POUR L’ EXTRACTION LEXICALE BILINGUE

paradigme de notre méthode (AMF) est de prendre en compte l’information véhiculeé par tous les plus proches
voisins ainsi que le degré de fiabilité des candidats pour améliorer les performance du processus d’extraction
lexicale.
Approches         Top 5             Top 10           Top 15            Top 20
AS                37,70%            45,08%           52,45%            56,55%
ASI               21,31%            31,14%           36,88%            40,98%
AM F              40,98%            54,09%           56,55%            60,65%

TABLE 2 – Précision aux tops 5, 10, 15, 20 des méthodes AS, ASI et AMF
Enfin comme dernier résultat, nous présentons dans le tableau 3 une comparaison des approches standard (AS),
par similarité interlangue (ASI) et par méta-recherche (AMF), pour le top 5, 10, 15 et 20 et ceci en choisissant
la meilleure configuration des paramètres de chaque approche. Nous constatons que notre approche AMF obtient
une meilleure précision dans chaque situation. Partant du principe que les systèmes d’extraction lexicale tentent
d’approcher le top 10 voir le top 5, nous considèreront nos résultats comme étant encourageants notamment pour
le top 10 où AMF atteint 54, 09% ce qui n’est pas loin de l’approche standard au top 20.
4.4   Discussion

Les approches par similarité interlangue (ASI) et par métarecherche se basent sur les k plus proches voisins pour
identifier les meilleurs candidats à la traduction. L’approche ASI effectue une fusion en amont, privilégiant ainsi
une vue globale des k plus proches voisins. Ceci peut se révéler problématique, car une bonne traduction pourrait
être noyeé dans la masse, et ainsi être écarteé de la liste des candidats, si des mots plus fréquents viennent à
apparaître dans le contexte du mot à traduire. Plus précisément, si des mots obtiennent des scores de similarité
très élevés par rapport à un seul plus proche voisin et que d’autres obtiennent des scores moins élevés mais
proches de plusieurs plus proches voisins du mot à traduire, ces mots seront moins bien classés voir mal classés.
Pour pallier ce problème, l’approche AMF considère dans un premier temps, chaque plus proche voisin comme
étant une source d’information indépendante des autres, privilégiant ainsi sa liste de candidats en fixant une taille
arbitraire (généralement autour de 200 dans nos expériences), pour ensuite effectuer une fusion en aval des plus
proches voisins après avoir normalisé les scores de similarité comme décrit en section 3. En outre, l’approche
AMF introduit une mesure de fiabilité, en considérant les plus proches voisins des mots candidats à la traduction
comme étant proches des k plus proches voisins du mot à traduire, ainsi que tous les voisins de ces candidats,
pour éloigner des mots qui apparaitraient trop fréquemment et dans trop de contextes. Car ne l’oublions pas,
ces approches se basent uniquement sur une représentation graphique des donneés qui induit un certain volume
de bruit, lequel serait sans doute mieux traité par une analyse plus fine du contexte. Il est évident que plus les
mots sont fréquents dans le corpus plus on a une représentation riche de leur contexte. Cette remarque nous
amène à nous interroger sur les fréquences des k plus proches voisins du mot candidat à la traduction. En effet,
si un plus proche voisin apparaît fréquemment en langue source et que sa traduction en langue cible est faible
ou inversement, quel serait l’impact de ce déséquilibre sur les résultats ? Aucune étude à notre connaissance n’a
approfondi ce sujet. Quoique rien ne nous permette d’affirmer une quelconque relation entre ce déséquilibre et
une éventuelle traduction erroneé, nous pouvons néanmoins supposer que cela est nuisible à une représentation
riche du contexte du mot, car un mot peu fréquent apporte moins d’information qu’un mot très fréquent et ceci
toujours en se basant sur l’ideé de la coloration graphique qui caractérise le contexte. Ainsi nous nous attellerons
dans nos travaux futurs à étudier cette problématique. Enfin, les plus proches voisins ont été fixés d’une manière
empirique dans les deux approches ASI et AMF, et dans toutes les évaluations. Nous avons fixé un même k pour
tous les mots de la liste d’évaluation. L’état de l’art ne spécifie aucune manière efficace de choisir ce paramètre
k. Néanmoins, nous sommes en droit de nous interroger pour savoir s’il existe un nombre k idéal de plus proches
voisins qui puisse garantir une bonne traduction de tous les mots de la liste d’évaluation ? On serait plutôt tenté
de dire qu’il existe un k pour chaque mot à traduire mais que celui-ci varie selon les mots. Là encore, nos travaux
futurs devront répondre à cette question clé.
A MIR H AZEM , E MMANUEL M ORIN ET S EBASTIÁN P EÑA S ALDARRIAGA

5    Conclusion
Nous avons présenté dans cet article une nouvelle manière d’aborder le problème de l’extraction lexicale bilingue
à partir de corpus comparables en nous appuyant sur le principe des métamoteurs de recherche. Nous avons ainsi
présenté une nouvelle approche simple et robuste qui revisite la méthode par similarité interlangue pour présenter
un modèle inspiré par les métamoteurs de recherche d’information. Ce modèle qui prend en compte la distribution
des candidats à la traduction non seulement par rapport au k plus proches voisins du mot à traduire mais aussi par
rapport à tout leurs voisins, a permis un gain significatif en terme de précision. Les résultats empiriques que nous
obtenons montrent que les performances de ce nouveau modèle sont toujours supérieures à celles obtenues avec
l’approche par similarité interlangue pour k > 10, mais aussi comme étant compétitives par rapport à l’approche
standard.
Remerciements
Ce travail qui s’inscrit dans le cadre du projet METRICC (www.metricc.com) a bénéficié d’une aide de
l’Agence Nationale de la Recherche portant la référence ANR-08-CORD-009.
Références
A SLAM J. A. & M ONTAGUE M. (2001). Models for Metasearch. In SIGIR ’01, proceedings of the 24th Annual
SIGIR Conference, p. 276–284.
BARTELL B. T., C OTTRELL G. W. & B ELEW R. K. (1994). Automatic combination of multiple ranked retrieval
systems. In SIGIR ’94, proceedings of the 17th Annual SIGIR Conference, p. 173–181.
C HIAO Y.-C. & Z WEIGENBAUM P. (2003). The Effect of a General Lexicon in Corpus-Based Identification of
French-English Medical Word Translations. In R. BAUD , M. F IESCHI , P. L E B EUX & P. RUCH, Eds., The New
Navigators : from Professionals to Patients, Actes Medical Informatics Europe, volume 95 of Studies in Health
Technology and Informatics, p. 397–402, Amsterdam : IOS Press.
DAILLE B. & M ORIN E. (2005). French-English Terminology Extraction from Comparable Corpora. In Pro-
ceedings of the 2nd International Joint Conference on Natural Language Processing (IJCLNP’05), p. 707–718,
Jeju Island, Korea.
D ÉJEAN H. & G AUSSIER E. (2002). Une nouvelle approche à l’extraction de lexiques bilingues à partir de
corpus comparables. Lexicometrica, Alignement lexical dans les corpus multilingues, p. 1–22.
D ÉJEAN H., S ADAT F. & G AUSSIER E. (2002). An approach based on multilingual thesauri and model combi-
nation for bilingual lexicon extraction. In Proceedings of the 19th International Conference on Computational
Linguistics (COLING’02), p. 218–224, Tapei, Taiwan.
D UNNING T. (1993). Accurate Methods for the Statistics of Surprise and Coincidence. Computational Linguis-
tics, 19(1), 61–74.
FANO R. M. (1961). Transmission of Information : A Statistical Theory of Communications. Cambridge, MA,
USA : MIT Press.
F UNG P. (1998). A Statistical View on Bilingual Lexicon Extraction : From ParallelCorpora to Non-parallel
Corpora. In D. FARWELL , L. G ERBER & E. H OVY, Eds., Proceedings of the 3rd Conference of the Association
for Machine Translation in the Americas (AMTA’98), p. 1–16, Langhorne, PA, USA.
F UNG P. & L O Y. Y. (1998). An ir approach for translating new words from nonparallel, comparable texts. In
Proceedings of the 17th international conference on Computational linguistics (COLING’98), p. 414–420.
F UNG P. & M C K EOWN K. (1997). Finding Terminology Translations from Non-parallel Corpora. In Procee-
dings of the 5th Annual Workshop on Very Large Corpora (VLC’97), p. 192–202, Hong Kong.
G REFENSTETTE G. (1994a). Corpus-Derived First, Second and Third-Order Word Affinities. In Proceedings of
the 6th Congress of the European Association for Lexicography (EURALEX’94), p. 279–290, Amsterdam, The
Netherlands.
M ÉTARECHERCHE POUR L’ EXTRACTION LEXICALE BILINGUE

G REFENSTETTE G. (1994b). Explorations in Automatic Thesaurus Discovery. Boston, MA, USA : Kluwer
Academic Publisher.
L AROCHE A. & L ANGLAIS P. (2010). Revisiting context-based projection methods for term-translation spotting
in comparable corpora. In Proceedings of the 23rd International Conference on Computational Linguistics,
COLING ’10, p. 617–625, Stroudsburg, Pekin, Chine : Association for Computational Linguistics.
M ORIN E. (2009). Apport d’un corpus comparable déséquilibré à l’extraction de lexiques bilingues. In Actes de
la 16ème Conférence annuelle sur le Traitement Automatique des Langues Naturelles (TALN) Senlis France., p.
101–110.
OTERO P. G. (2007). Learning bilingual lexicons from comparable english and spanish corpora. In Proceedings
of Machine Translation Summit XI, p. 191–198.
R APP R. (1995). Identify Word Translations in Non-Parallel Texts. In Proceedings of the 35th Annual Meeting
of the Association for Computational Linguistics (ACL’95), p. 320–322, Boston, MA, USA.
S ALTON G. & L ESK M. E. (1968). Computer evaluation of indexing and text processing. Journal of the
Association for Computational Machinery, 15(1), 8–36.
Y U K. & T SUJII J. (2009). Bilingual dictionary extraction from wikipedia. In Proceedings of Machine Transla-
tion Summit XII.
