<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Int&#233;grer des connaissances linguistiques dans un CRF : application &#224; l&#8217;apprentissage d&#8217;un segmenteur-&#233;tiqueteur du fran&#231;ais</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211;1er juillet 2011
</p>
<p>Int&#233;grer des connaissances linguistiques dans un CRF :
application &#224; l&#8217;apprentissage d&#8217;un segmenteur-&#233;tiqueteur du fran&#231;ais
</p>
<p>Matthieu Constant1 Isabelle Tellier2 Denys Duchier2
Yoann Dupont2 Anthony Sigogne1 Sylvie Billot2
</p>
<p>(1) Universit&#233; Paris-Est, LIGM, CNRS, 5 bd Descartes, Champs-sur-Marne 77454
Marne-la-Vall&#233;e cedex 2
</p>
<p>(2) LIFO, universit&#233; d&#8217;Orl&#233;ans, 6 rue L&#233;onard de Vinci
BP 6759, 45067 Orl&#233;ans cedex 2
</p>
<p>mconstan@univ-mlv.fr, isabelle.tellier@univ-orleans.fr,
denys.duchier@univ-orleans.fr, yoann.dupont@etu.univ-orleans.fr,
</p>
<p>sigogne@univ-mlv.fr, sylvie.billot@univ-orleans.fr
</p>
<p>R&#233;sum&#233;. Dans cet article, nous synth&#233;tisons les r&#233;sultats de plusieurs s&#233;ries d&#8217;exp&#233;riences r&#233;alis&#233;es &#224; l&#8217;aide
de CRF (Conditional Random Fields ou &#8220;champs markoviens conditionnels&#8221;) lin&#233;aires pour apprendre &#224; annoter
des textes fran&#231;ais &#224; partir d&#8217;exemples, en exploitant diverses ressources linguistiques externes. Ces exp&#233;riences
ont port&#233; sur l&#8217;&#233;tiquetage morphosyntaxique int&#233;grant l&#8217;identification des unit&#233;s polylexicales. Nous montrons
que le mod&#232;le des CRF est capable d&#8217;int&#233;grer des ressources lexicales riches en unit&#233;s multi-mots de diff&#233;rentes
mani&#232;res et permet d&#8217;atteindre ainsi le meilleur taux de correction d&#8217;&#233;tiquetage actuel pour le fran&#231;ais.
</p>
<p>Abstract. In this paper, we synthesize different experiments using a linear CRF (Conditional Random
Fields) to annotate French texts from examples, by exploiting external linguistic resources. These experiments
especially dealt with part-of-speech tagging including multiword units identification. We show that CRF models
allow to integrate, in different ways, large-coverage lexical resources including multiword units and reach state-
of-the-art tagging results for French.
</p>
<p>Mots-cl&#233;s : Etiquetage morphosyntaxique, Mod&#232;le CRF, Ressources lexicales, Segmentation, Unit&#233;s polylex-
icales.
</p>
<p>Keywords: Part-of-speech tagging, CRF model, Lexical resources, Segmentation, Multiword units.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M. Constant, I. Tellier, D. Duchier, Y. Dupont, A. Sigogne, S. Billot
</p>
<p>1 Introduction
</p>
<p>Dans cet article, nous synth&#233;tisons les r&#233;sultats de plusieurs s&#233;ries d&#8217;exp&#233;riences r&#233;alis&#233;es &#224; l&#8217;aide de CRF (Con-
ditional Random Fields ou &#8220;champs markoviens conditionnels&#8221; (Lafferty et al., 2001; Tellier &amp; Tommasi, 2011))
lin&#233;aires pour apprendre &#224; annoter des textes fran&#231;ais &#224; partir d&#8217;exemples, en exploitant diverses ressources lin-
guistiques externes. La t&#226;che &#224; laquelle nous nous sommes attach&#233;s est celle de la segmentation en unit&#233;s lexicales
des phrases d&#8217;un texte, coupl&#233;e &#224; celle de leur &#233;tiquetage en cat&#233;gories morphosyntaxiques (ou &#8220;part of speech&#8221;
en anglais).
Ces derni&#232;res ann&#233;es, l&#8217;&#233;tiquetage morphosyntaxique a atteint d&#8217;excellents niveaux de performance gr&#226;ce &#224; l&#8217;u-
tilisation de mod&#232;les probabilistes discriminants comme les mod&#232;les de maximum d&#8217;entropie [MaxEnt] (Ratna-
parkhi, 1996; Toutanova et al., 2003), les s&#233;parateurs &#224; vaste marge [SVM] (Gim&#233;nez &amp; M&#225;rquez., 2004) ou, d&#233;j&#224;,
les champs markoviens conditionnels [CRF] (Tsuruoka et al., 2009). Il a par ailleurs &#233;t&#233; montr&#233; que le couplage
de ces mod&#232;les avec des lexiques externes augmente encore la qualit&#233; de l&#8217;annotation, comme l&#8217;illustre (Denis
&amp; Sagot, 2009, 2010) pour MaxEnt. N&#233;anmoins, les &#233;valuations r&#233;alis&#233;es consid&#232;rent toujours en entr&#233;e un texte
avec une segmentation lexicale parfaite, c&#8217;est-&#224;-dire que les unit&#233;s lexicales multi-mots, qui forment par d&#233;finition
des unit&#233;s linguistiques, ont &#233;t&#233; parfaitement reconnues au pr&#233;alable. Or cette t&#226;che de segmentation est difficile
car elle n&#233;cessite des ressources lexicales importantes. On notera que les syst&#232;mes tels que Macaon (Nasr et al.,
2010) et Unitex (Paumier, 2011) int&#232;grent une analyse lexicale avec segmentation multi-mots ambigu&#235; avant lev&#233;e
d&#8217;ambiguit&#233; par l&#8217;utilisation d&#8217;un mod&#232;le de Markov cach&#233; [HMM]. Dans cet article, nous proposons d&#8217;int&#233;grer
les deux t&#226;ches de segmentation et d&#8217;&#233;tiquetage dans un seul mod&#232;le CRF coupl&#233; &#224; des ressources lexicales riches.
</p>
<p>Le corpus d&#8217;apprentissage dont nous sommes partis provient du French Treebank (Abeill&#233; et al., 2003). Les
ressources linguistiques externes utilis&#233;es sont de diff&#233;rentes natures. Nous avons ainsi exploit&#233; plusieurs dictio-
nnaires : Lefff (Sagot, 2010) mais aussi DELA (Courtois, 2009; Courtois et al., 1997), ainsi que des lexiques
sp&#233;cifiques comme Prolex (Piton et al., 1999) et quelques autres incluant des noms d&#8217;organisation et des pr&#233;noms
(Martineau et al., 2009). Cet ensemble de dictionnaires est compl&#233;t&#233; par une biblioth&#232;que de grammaires locales
qui reconnaissent diff&#233;rents types d&#8217;unit&#233;s multi-mots (Constant &amp; Watrin, 2008). Nous montrons que le mod&#232;le
des CRF est capable d&#8217;int&#233;grer de telles ressources de diff&#233;rentes mani&#232;res et permet d&#8217;atteindre ainsi le meilleur
taux actuel de correction pour la segmentation et l&#8217;&#233;tiquetage du fran&#231;ais.
</p>
<p>Dans la suite de cet article, nous commen&#231;ons par pr&#233;senter le mod&#232;le des CRF et le fonctionnement des bib-
lioth&#232;ques logicielles que nous avons utilis&#233;es pour mener nos exp&#233;riences. Nous d&#233;crivons ensuite le corpus
d&#8217;apprentissage ainsi que la t&#226;che que nous traitons, en d&#233;taillant les difficult&#233;s sp&#233;cifiques que posent les unit&#233;s
multi-mots. Puis nous passons en revue les ressources &#224; notre disposition et menons une r&#233;flexion m&#233;thodologique
sur les diff&#233;rents moyens de les prendre en compte dans une cha&#238;ne de traitements qui fait appel &#224; un CRF. La
derni&#232;re partie est consacr&#233;e &#224; la pr&#233;sentation des r&#233;sultats de nos exp&#233;riences. Ces travaux ont permis la mise au
point de plusieurs segmenteurs-&#233;tiqueteurs qui sont librement disponibles.
</p>
<p>2 Les CRF
</p>
<p>2.1 Le mod&#232;le th&#233;orique
</p>
<p>Les champs markoviens conditionnels ou CRF (Tellier &amp; Tommasi, 2011) sont des mod&#232;les probabilistes discrim-
inants introduits par (Lafferty et al., 2001) pour l&#8217;annotation s&#233;quentielle. Ils ont &#233;t&#233; utilis&#233;s dans de nombreuses
t&#226;ches de Traitement des Langues, o&#249; ils donnent d&#8217;excellents r&#233;sultats (McCallum &amp; Li, 2003; Sha &amp; Pereira,
2003; Tsuruoka et al., 2009; Tellier et al., 2010).
Les CRF permettent d&#8217;associer &#224; une observation x une annotation y en se basant sur un ensemble d&#8217;exemples
&#233;tiquet&#233;s, c&#8217;est-&#224;-dire un ensemble de couples (x, y). La plupart du temps (et ce sera le cas dans la suite de cet
article), x est une s&#233;quence d&#8217;unit&#233;s (ici, une suite d&#8217;unit&#233;s lexicales) et y la s&#233;quence des &#233;tiquettes correspondante
(ici, la suite de leurs cat&#233;gories morphosyntaxiques, &#233;ventuellement enrichie pour coder la segmentation). Les CRF
sont des mod&#232;les discriminants qui appartiennent &#224; la famille des mod&#232;les graphiques non dirig&#233;s. Ils sont d&#233;finis
par X et Y, deux champs al&#233;atoires d&#233;crivant respectivement chaque unit&#233; de l&#8217;observation x et son annotation y,
et par un graphe G = (V, E) dont V = X &#8746; Y est l&#8217;ensemble des n&#339;uds (vertices) et E &#8838; V &#215; V l&#8217;ensemble des</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Inte&#769;grer des connaissances linguistiques dans un CRF
</p>
<p>arcs (edges). Deux variables sont reli&#233;es dans le graphe si elles d&#233;pendent l&#8217;une de l&#8217;autre. Le graphe sur le champ
Y des CRF lin&#233;aires, dessin&#233; en Fig 1., traduit le fait que chaque &#233;tiquette est suppos&#233;e d&#233;pendre de l&#8217;&#233;tiquette
pr&#233;c&#233;dente et de la suivante et, implicitement, de la donn&#233;e x compl&#232;te. Un dessin complet du graphe devrait ainsi
&#233;galement relier chaque variable Yi &#224; chaque variable du champ X, ce qu&#8217;on omet sur la figure pour la lisibilit&#233;.
</p>
<p>Y1 ... Yi&#8722;1 Yi Yi+1 ... Yn
</p>
<p>Figure 1 &#8211; graphe associ&#233; &#224; un CRF lin&#233;aire
</p>
<p>Dans un CRF, on a la relation suivante (Lafferty et al., 2001) :
</p>
<p>p(y|x) = 1
Z(x)
</p>
<p>&#8719;
c&#8712;C
</p>
<p>exp
(&#8721;
</p>
<p>k
&#955;k fk(yc, x, c)
</p>
<p>)
avec
</p>
<p>&#8211; C est l&#8217;ensemble des cliques (sous-graphes compl&#232;tement connect&#233;s) de G sur Y : dans le cas du graphe de la
Fig. 1, ces cliques sont constitu&#233;es soit d&#8217;un n&#339;ud isol&#233;, soit d&#8217;un couple de n&#339;uds successifs.
</p>
<p>&#8211; yc l&#8217;ensemble des valeurs prises par les variables de Y sur la clique c pour un &#233;tiquetage y donn&#233; : ici, c&#8217;est donc
soit la valeur d&#8217;une &#233;tiquette soit celles d&#8217;un couple d&#8217;&#233;tiquettes successives
</p>
<p>&#8211; Z(x) est un coefficient de normalisation, d&#233;fini de telle sorte que la somme sur y de toutes les probabilit&#233;s p(y|x)
pour une donn&#233;e x fix&#233;e soit &#233;gale &#224; 1.
</p>
<p>&#8211; Les fonctions fk sont appel&#233;es fonctions caract&#233;ristiques (features) : elles sont d&#233;finies &#224; l&#8217;int&#233;rieur de chaque
clique c et sont &#224; valeurs r&#233;elles, mais souvent choisies pour donner un r&#233;sultat binaire (0 ou 1). Elles doivent
&#234;tre founies au syst&#232;me par l&#8217;utilisateur. Par d&#233;finition, la valeur de ces fonctions peut d&#233;pendre des &#233;tiquettes
pr&#233;sentes dans une certaine clique c ainsi que de la valeur de x n&#8217;importe o&#249; dans la donn&#233;e (et pas uniquement
aux indices correspondants &#224; la clique c, ce qui donne beaucoup d&#8217;expressivit&#233; aux CRF).
</p>
<p>&#8211; Les poids &#955;k, &#224; valeurs r&#233;elles, permettent d&#8217;accorder plus ou moins d&#8217;importance &#224; chaque fonction fk dont ils
caract&#233;risent le pouvoir discriminant. Ce sont les param&#232;tres du mod&#232;le : l&#8217;enjeu de la phase d&#8217;apprentissage
est de fixer leur valeur en cherchant &#224; maximiser la log-vraisemblance sur un ensemble d&#8217;exemples d&#233;j&#224; annot&#233;s
(constituant le corpus d&#8217;apprentissage).
</p>
<p>L&#8217;int&#233;r&#234;t et l&#8217;efficacit&#233; des CRF proviennent de ce qu&#8217;ils prennent en compte des d&#233;pendances entre &#233;tiquettes re-
li&#233;es les unes aux autres dans le graphe. En cherchant le meilleur y, c&#8217;est-&#224;-dire la meilleure s&#233;quence d&#8217;&#233;tiquettes
associer &#224; une donn&#233;e compl&#232;te x, ils se comportent en g&#233;n&#233;ral mieux qu&#8217;une s&#233;rie de classifications d&#8217;unit&#233;s
isol&#233;es. Mais cette prise en compte a un prix : la phase d&#8217;apprentissage d&#8217;un CRF peut &#234;tre longue. Une fois cette
phase r&#233;alis&#233;e, annoter une nouvelle s&#233;quence x de n mots en entr&#233;e revient alors &#224; trouver le y qui maximise
p(y|x). L&#8217;espace th&#233;orique de recherche de ce meilleur &#233;tiquetage y est |Y |n, o&#249; |Y | est le nombre d&#8217;&#233;tiquettes dis-
tinctes possibles pour chaque n&#339;ud. Mais, gr&#226;ce &#224; des techniques de programmation dynamique, ce calcul peut
&#234;tre factoris&#233; &#224; l&#8217;int&#233;rieur des cliques et ramen&#233; &#224; K &#8727; n &#8727; |Y |c o&#249; c est la taille de la plus grande clique (c = 2 pour
les CRF lin&#233;aires) et K le nombre de fonctions caract&#233;ristiques. Une fois appris, l&#8217;&#233;tiqueteur est donc performant.
</p>
<p>2.2 Les biblioth&#232;ques CRF++ et Wapiti
</p>
<p>Notre objectif &#233;tant d&#8217;ins&#233;rer des connaissances linguistiques dans un apprentissage r&#233;alis&#233; &#224; l&#8217;aide de CRF
lin&#233;aires, il nous semble important de bien comprendre le fonctionnement concret des biblioth&#232;ques qui les im-
pl&#233;mentent. Plusieurs sont disponibles pour mettre en &#339;uvre les CRF lin&#233;aires, notamment crf.source.net 1 de
Sarawagi ou Mallet 2 de McCallum. Celles que nous avons utilis&#233;es sont CRF++ 3 de Taku Kado et Wapiti 4 de
Thomas Lavergne (Lavergne et al., 2010), qui utilisent des moyens similaires pour instancier les fonctions carac-
t&#233;ristiques qui entrent dans leur d&#233;finition.
</p>
<p>1. crf.sourceforge.net
2. http ://mallet.cs.umass.edu/
3. http ://crfpp.sourceforge.net/
4. http ://wapiti.limsi.fr</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M. Constant, I. Tellier, D. Duchier, Y. Dupont, A. Sigogne, S. Billot
</p>
<p>Corpus tabulaires. Les exemples d&#8217;apprentissage que requi&#232;rent ces biblioth&#232;ques sont des couples (x, y), o&#249;
x est une s&#233;quence d&#8217;unit&#233;s et y la s&#233;quence d&#8217;&#233;tiquettes correspondantes, de m&#234;mes longueurs. Pour nous, une
unit&#233; de x correspond &#224; un &#8220;mot&#8221;, mais elle peut &#234;tre enrichie par d&#8217;autres propri&#233;t&#233;s, repr&#233;sent&#233;es par p attributs,
du moment que ces derniers sont disponibles ou calculables aussi pour tout nouvel exemple x non &#233;tiquet&#233;. Les
attributs peuvent &#234;tre des bool&#233;ens (l&#8217;unit&#233; contient un chiffre, commence par une majuscule, est pr&#233;sente dans un
lexique, etc.), des valeurs num&#233;riques (nombre de lettres, etc.) ou textuelles (valeur de l&#8217;unit&#233; ou de son pr&#233;fixe
ou suffixe de telle longueur, etc.). Une donn&#233;e &#233;tiquet&#233;e (x, y) de taille n se pr&#233;sente donc comme un tableau de n
lignes et p+1 colonnes, o&#249; les p premi&#232;res colonnes contiennent toutes les informations disponibles sur la donn&#233;e
x et la derni&#232;re colonne les &#233;tiquettes y :
</p>
<p>x11 x
2
1 &#183; &#183; &#183; x
</p>
<p>p
1 y1
</p>
<p>...
</p>
<p>x1i x
2
i &#183; &#183; &#183; x
</p>
<p>p
i yi
</p>
<p>x1i+1 x
2
i+1 &#183; &#183; &#183; x
</p>
<p>p
i+1 yi+1
</p>
<p>.
</p>
<p>..
</p>
<p>Les exemples distincts sont s&#233;par&#233;s entre eux dans un m&#234;me fichier par une ligne vide. Un corpus d&#8217;apprentissage
est donc une suite de tels tableaux, tous de largeur p + 1, mais de hauteurs qui peuvent varier.
</p>
<p>Patrons tabulaires. L&#8217;utilisateur des biblioth&#232;ques ne d&#233;finit pas directement les fonctions caract&#233;ristiques du
mod&#232;le ; il doit fournir des patrons. Il existe deux types de patrons correspondant aux deux tailles de clique
possibles : les unigrammes pour les cliques de taille 1, et les bigrammes pour les cliques de taille 2.
</p>
<p>Un patron unigramme est une sorte de carte perfor&#233;e de m&#234;me largeur p + 1 que nos tableaux, de hauteur quel-
conque sur les p premi&#232;res colonnes mais ne pouvant capturer qu&#8217;une seule &#233;tiquette sur la colonne p+ 1. Chaque
position possible de cette carte sur un exemple d&#233;finit une fonction caract&#233;ristique : celle qui renvoie la valeur 1 si
la configuration de valeurs observ&#233;e dans les perforations est satisfaite, 0 sinon. Les ronds dans le tableau pr&#233;c&#233;-
dent repr&#233;sentent les valeurs captur&#233;es par une telle carte, positionn&#233;e sur la ligne i d&#8217;une donn&#233;e. Chaque fonction
caract&#233;ristique prend donc la forme d&#8217;une conjonction de crit&#232;res bool&#233;ens observ&#233;e au moins une fois parmi les
exemples et un patron en &#8220;g&#233;n&#232;re&#8221; autant qu&#8217;il y a de positions o&#249; il peut s&#8217;appliquer dans le fichier d&#8217;exemples.
Un patron permet de d&#233;finir ainsi succinctement des milliers, voire des millions de fonctions caract&#233;ristiques. Un
patron bigramme est similaire &#224; un patron unigramme, mais on l&#8217;applique successivement &#224; une position i, puis &#224;
la position suivante i + 1 et la fonction caract&#233;ristique obtenue est la conjonction de tous les crit&#232;res rencontr&#233;s.
</p>
<p>3 Corpus d&#8217;apprentissage pour la segmentation et l&#8217;&#233;tiquetage
</p>
<p>3.1 Corpus FTB
</p>
<p>Tout syst&#232;me d&#8217;annotation probabiliste supervis&#233; requiert un corpus annot&#233; de r&#233;f&#233;rence pour entra&#238;ner le mod&#232;le
et ensuite l&#8217;&#233;valuer. Pour notre t&#226;che d&#8217;&#233;tiquetage morphosyntaxique int&#233;grant la reconnaissance des unit&#233;s multi-
mots, il est donc n&#233;cessaire d&#8217;utiliser un corpus annot&#233; en cat&#233;gories grammaticales incluant l&#8217;annotation des
unit&#233;s polylexicales. Le corpus le plus complet en fran&#231;ais est le corpus arbor&#233; de Paris 7 (Abeill&#233; et al., 2003),
form&#233; d&#8217;articles du journal Le Monde allant de 1989 &#224; 1993. Il d&#233;crit la structure syntaxique des diff&#233;rentes
phrases sous la forme d&#8217;arbres. Une unit&#233; de ce corpus peut &#234;tre une ponctuation, un nombre, un mot simple ou
une unit&#233; multi-mots. Au niveau morphosyntaxique, il existait initialement un jeu d&#8217;&#233;tiquettes de 14 cat&#233;gories
principales et de 34 sous-cat&#233;gories. Pour notre t&#226;che, nous utilisons un jeu d&#8217;&#233;tiquettes optimis&#233; en 29 cat&#233;gories
pour l&#8217;analyse syntaxique (Crabb&#233; &amp; Candito, 2008) et r&#233;utilis&#233; comme standard dans une exp&#233;rience d&#8217;&#233;tiquetage
morpho-syntaxique (Denis &amp; Sagot, 2009). Les unit&#233;s multi-mots cod&#233;es sont de diff&#233;rents types : mots compos&#233;s
et entit&#233;s nomm&#233;es. Les mots compos&#233;s comprennent des noms (acquis sociaux), des verbes (faire face &#224;), des
adverbes (dans l&#8217;imm&#233;diat), des pr&#233;positions (en dehors de). Il contient quelques types d&#8217;entit&#233;s nomm&#233;es : des
noms d&#8217;organisation (Soci&#233;t&#233; suisse de micro&#233;lectronique et d&#8217;horlogerie), des noms de famille (Strauss-Kahn),
des noms de lieu (Afrique du Sud, New York).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Inte&#769;grer des connaissances linguistiques dans un CRF
</p>
<p>Dans nos s&#233;ries d&#8217;exp&#233;riences, nous avons utilis&#233; deux versions diff&#233;rentes du corpus : une version de 569 039
unit&#233;s (au LIGM), une autre de 350 931 (au LIFO). Dans ces deux versions, nous n&#8217;avons repris que le niveau des
feuilles, i.e. le niveau lexical. Nous en donnons un extrait ci-dessous :
</p>
<p>Quant_&#224;/P la/DET technique/NC ,/PONCT son/DET verdict/NC est/V implacable/ADJ ./PONCT
</p>
<p>L&#8217;unit&#233; Quant_&#224; est la fusion de deux mots simples (Quant et &#224;), formant la pr&#233;position compos&#233;e quant_&#224;.
</p>
<p>3.2 Unit&#233;s lexicales multi-mots
</p>
<p>Expressions multi-mots. Dans le consensus actuel du Traitement Automatique des Langues (TAL), les expres-
sions multi-mots forment des unit&#233;s linguistiques aux comportements lexicaux, syntaxiques et/ou s&#233;mantiques
particuliers. Elles regroupent les expressions fig&#233;es et semi-fig&#233;es, les collocations, les entit&#233;s nomm&#233;es, les verbes
&#224; particule, les constructions &#224; verbe support, les termes, etc. (Sag et al., 2002). Leur identification est donc cru-
ciale avant toute analyse s&#233;mantique. Elles apparaissent &#224; diff&#233;rents niveaux de l&#8217;analyse linguistique : certaines
forment des unit&#233;s lexicales contigues &#224; part enti&#232;re (ex. cordon bleu, San Francisco, par rapport &#224;), d&#8217;autres com-
posent des constituants syntaxiques comme les phrases fig&#233;es (N0 prendre le taureau par les cornes ; N0 prendre
N1 en compte) ou les constructions &#224; verbe support (N0 donner un avertissement &#224; N1 ; N0 faire du bruit).
</p>
<p>Ph&#233;nom&#232;nes trait&#233;s. Dans cet article, nous ne traitons que les expressions multi-mots du niveau lexical, que
nous appellerons dor&#233;navant unit&#233;s multi-mots ou polylexicales. Elles comportent les mots compos&#233;s (noms, pr&#233;-
positions, adverbes, etc.), les entit&#233;s nomm&#233;es, les termes, les collocations nominales. Il existe une grande vari&#233;t&#233;
de ph&#233;nom&#232;nes linguistiques rentrant dans cette cat&#233;gorie et donc de nombreux crit&#232;res d&#8217;identification. Les mots
compos&#233;s sont des s&#233;quences non compositionnelles de mots : ils pr&#233;sentent une opacit&#233; s&#233;mantique totale (cor-
don bleu, tout &#224; fait) ou partielle (vin blanc), des contraintes syntaxiques et lexicales, etc. Il existe un continuum
entre expressions fig&#233;es et libres, ce qui rend leur identification encore plus difficile. Les collocations sont d&#233;finies
&#224; partir de crit&#232;res statistiques. Les entit&#233;s nomm&#233;es ont souvent une certaine compositionalit&#233; s&#233;mantique mais
ont une syntaxe particuli&#232;re : ex. le 5 mars 2010 pour les dates, Jacques Chirac pour les noms de personnes.
</p>
<p>Ressources. Les unit&#233;s polylexicales peuvent &#234;tre recens&#233;es dans des dictionnaires &#233;lectroniques ou des gram-
maires locales. Les dictionnaires &#233;lectroniques sont des listes qui associent des formes lexicales &#224; des informations
linguistiques comme les cat&#233;gories grammaticales ou certains traits s&#233;mantiques (ex. humain, concret, etc.). Les
grammaires locales (Gross, 1997; Silberztein, 2000) sont des r&#233;seaux r&#233;cursifs de transitions d&#233;crits sous la forme
de graphes d&#8217;automates finis. Chaque transition est &#233;tiquet&#233;e par un &#233;l&#233;ment lexical (ex. mange), un masque lex-
ical correspondant &#224; un ensemble de formes lexicales encod&#233;es dans un dictionnaire (ex. &lt;manger&gt; symbolisant
toutes les formes fl&#233;chies dont le lemme est manger) ou un &#233;l&#233;ment non-terminal r&#233;f&#233;rant &#224; un autre automate.
Elles sont tr&#232;s utiles pour d&#233;crire de mani&#232;re compacte des unit&#233;s multi-mots acceptant des variations lexicales. Un
syst&#232;me de transduction permet d&#8217;annoter les expressions d&#233;crites, comme la cat&#233;gorie grammaticale ou l&#8217;analyse
des composants internes pour les entit&#233;s nomm&#233;es par exemple (Martineau et al., 2009).
</p>
<p>Reconnaissance. La reconnaissance automatique des unit&#233;s multi-mots est, la plupart du temps, r&#233;alis&#233;e &#224; l&#8217;aide
de ressources lexicales construites manuellement (ex. pour les expressions fig&#233;es) ou apprises automatiquement
(ex. collocations nominales). Par ailleurs, une grande partie des entit&#233;s nomm&#233;es, du fait de leur syntaxe partic-
uli&#232;re sont facilement d&#233;crites et reconnues &#224; l&#8217;aide de grammaires locales (Friburger &amp; Maurel, 2009; Martineau
et al., 2009), bien qu&#8217;il existe d&#8217;autres types d&#8217;approches telles que les syst&#232;mes statistiques (McCallum &amp; Li,
2003) ou hybrides (Poibeau, 2009). L&#8217;identification de telles expressions est une t&#226;che tr&#232;s difficile car les unit&#233;s
non d&#233;crites dans les ressources sont difficilement reconnaissables. Elle est d&#8217;autant plus difficile qu&#8217;elle d&#233;pend
du contexte d&#8217;occurrence. En effet, une expression reconnue est souvent ambigue avec l&#8217;analyse en mots simples :
par exemple, il en fait une priorit&#233; (mots simples) vs j&#8217;ai en fait beaucoup travaill&#233; (mot compos&#233;). On observe
parfois des chevauchements avec d&#8217;autres unit&#233;s polylexicales comme dans la s&#233;quence une pomme de terre cuite
o&#249; pomme de terre et terre cuite sont des mots compos&#233;s. C&#8217;est pourquoi les outils existants de segmentation en
unit&#233;s multi-mots comme dans INTEX (Silberztein, 2000) ou SxPipe (Sagot &amp; Boullier, 2008) produisent une
segmentation ambigu&#235; sous la forme d&#8217;automates finis acycliques pour &#233;viter de prendre une d&#233;cision d&#233;finitive</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M. Constant, I. Tellier, D. Duchier, Y. Dupont, A. Sigogne, S. Billot
</p>
<p>trop h&#226;tive. Cette analyse ambigu&#235; peut alors &#234;tre int&#233;gr&#233;e dans des traitements linguistiques tels que l&#8217;&#233;tiquetage
morphosyntaxique (Nasr et al., 2010; Paumier, 2011)) ou l&#8217;analyse syntaxique superficielle (Blanc et al., 2007;
Nasr et al., 2010) et profonde (Sagot &amp; Boullier, 2006).
</p>
<p>3.3 Int&#233;gration d&#8217;un segmenteur et d&#8217;un &#233;tiqueteur
</p>
<p>L&#8217;identification des unit&#233;s multi-mots est similaire &#224; une t&#226;che de segmentation comme le chunking ou &#224; la re-
connaissance des entit&#233;s nomm&#233;es, qui identifient les limites de segments (chunks ou entit&#233;s nomm&#233;es) et les
annotent. En effet, gr&#226;ce &#224; la repr&#233;sentation IOB 5 (Ramshaw &amp; Marcus, 1995), segmenter un texte revient &#224; an-
noter ses unit&#233;s minimales. Pour combiner &#233;tiquetage morphosyntaxique et reconnaissance d&#8217;unit&#233;s multi-mots,
il suffit de concat&#233;ner les deux &#233;tiquetages en associant &#224; chaque unit&#233; minimale une &#233;tiquette de la forme X+B
ou X+I, o&#249; X est sa cat&#233;gorie grammaticale et le suffixe indique si elle se trouve au d&#233;but d&#8217;une unit&#233; multi-mots
(B) ou dans une position &#8220;interne&#8221; (I). Le suffixe O est inutile car la fin d&#8217;un segment lexical correspond au d&#233;but
d&#8217;un autre (suffixe B) ou &#224; une fin de phrase. Une telle proc&#233;dure d&#8217;annotation d&#233;termine non seulement les limites
des unit&#233;s lexicales, mais aussi leur cat&#233;gorie morphosyntaxique. Pour entra&#238;ner nos CRF, nous avons donc trans-
form&#233; le corpus d&#8217;apprentissage initial en isolant les unit&#233;s composant les segments multi-mots et en les &#233;tiquetant
conform&#233;ment &#224; cette nouvelle norme. L&#8217;exemple pr&#233;c&#233;dent est alors transform&#233; en :
</p>
<p>Quant/P+B &#224;/P+I la/DET+B technique/NC+B ,/PONCT+B son/DET+B verdict/NC+B est/V+B
</p>
<p>implacable/ADJ+B ./PONCT+B
</p>
<p>Le jeu d&#8217;&#233;tiquettes initial est ainsi doubl&#233;, chaque &#233;tiquette se d&#233;doublant en une variante B et une variante I.
La reconnaissance des unit&#233;s polylexicales d&#233;pendant fortement de la richesse de ressources lexicales utilis&#233;es, il
s&#8217;agit maintenant de trouver les meilleures fa&#231;ons d&#8217;int&#233;grer ce type d&#8217;informations dans nos CRF.
</p>
<p>4 Exploitation d&#8217;une ressource externe
</p>
<p>Dans cette section, nous commen&#231;ons par pr&#233;senter les diff&#233;rentes ressources que nous avons &#224; notre disposition,
et nous cherchons tous les moyens possibles de les prendre en compte dans un apprentissage avec des CRF.
</p>
<p>4.1 Ressources
</p>
<p>M&#234;me s&#8217;il existe de plus en plus d&#8217;&#233;tudes sur l&#8217;extraction automatique d&#8217;unit&#233;s multi-mots, en particulier les
collocations ou les termes (Daille, 1995; Dias, 2003; Seretan et al., 2003), les ressources les plus riches et les
plus pr&#233;cises ont &#233;t&#233; aquises manuellement. Pour notre &#233;tude, nous avons compil&#233; diverses ressources lexicales
sous la forme de dictionnaires morphosyntaxiques et de grammaires locales fortement lexicalis&#233;es. Nous avons
utilis&#233; notamment deux dictionnaires disponibles de mots simples et compos&#233;s de la langue g&#233;n&#233;rale : DELA
(Courtois, 2009; Courtois et al., 1997) et Lefff (Sagot, 2010). Le DELA a &#233;t&#233; construit par une &#233;quipe de linguistes.
Le Lefff a &#233;t&#233; automatiquement acquis et manuellement valid&#233;. Il r&#233;sulte &#233;galement de la fusion de diff&#233;rentes
sources lexicales. En compl&#233;ment, nous disposons aussi de lexiques sp&#233;cifiques comme Prolex (Piton et al., 1999)
compos&#233; de toponymes et d&#8217;autres incluant des noms d&#8217;organisation et des pr&#233;noms (Martineau et al., 2009). Les
nombres d&#8217;entr&#233;es de ces divers dictionnaires sont donn&#233;s dans le tableau 1.
</p>
<p>Dictionnaire #mots simples #mots compos&#233;s
DELA 690,619 272,226
Lefff 553,140 26,311
Prolex 25,190 97,925
Organisations 772 587
Pr&#233;noms 22,074 2,220
</p>
<p>Table 1 &#8211; Dictionnaires morphosyntaxiques
</p>
<p>5. I : Inside (int&#233;rieur du segment) ; O : Outside (hors du segment) ; B : Beginning (d&#233;but du segment)</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Inte&#769;grer des connaissances linguistiques dans un CRF
</p>
<p>Cet ensemble de dictionnaires est compl&#233;t&#233; par une biblioth&#232;que de grammaires locales qui reconnaissent dif-
f&#233;rents types d&#8217;unit&#233;s multi-mots comme les entit&#233;s nomm&#233;es (dates, noms d&#8217;organisation, de personne et de lieu),
pr&#233;positions locatives, d&#233;terminants num&#233;riques et nominaux. En pratique, nous avons utilis&#233; une biblioth&#232;que de
211 automates d&#233;velopp&#233;e &#224; partir de la biblioth&#232;que en-ligne GraalWeb (Constant &amp; Watrin, 2008).
</p>
<p>4.2 Quelques statistiques pr&#233;liminaires
Pour les exp&#233;riences men&#233;es avec la variante du FTB la plus volumineuse, le corpus initial a &#233;t&#233; d&#233;coup&#233; en trois
parties : 80% pour la phase d&#8217;entra&#238;nement (TRAIN), 10% pour le d&#233;veloppement (DEV) et 10% pour le test.
Cela nous a permis de faire quelques observations pr&#233;alables.
</p>
<p>Ainsi, dans le corpus FTB-DEV (avec &#233;tiquetage initial non transform&#233;), nous avons observ&#233; qu&#8217;environ 97,4%
des unit&#233;s lexicales 6 sont pr&#233;sentes dans nos ressources lexicales (en particulier, 97% sont pr&#233;sentes dans les
dictionnaires). Alors que 5% des unit&#233;s sont inconnues (i.e. absentes du corpus d&#8217;apprentissage), 1,5% sont &#224; fois
inconnues et absentes des ressources lexicales, ce qui montre que 70% des unit&#233;s inconnues sont couvertes par nos
ressources. On observe &#233;galement qu&#8217;environ 6% des unit&#233;s sont multi-mots. En d&#233;composant toutes les unit&#233;s
multi-mots du texte en unit&#233;s minimales, on s&#8217;aper&#231;oit qu&#8217;&#224; peu pr&#232;s 15% d&#8217;entre elles sont incluses dans une
unit&#233; multi-mots. Parmi les unit&#233;s multi-mots cod&#233;es dans le corpus FTB-DEV, 75,5% d&#8217;entre elles sont pr&#233;sentes
dans nos ressources (87,5% en incluant le lexique du corpus d&#8217;entra&#238;nement). Ceci montre que 12,5% des unit&#233;s
multi-mots sont totalement inconnues et, par cons&#233;quent, seront sans doute tr&#232;s difficilement reconnaissables.
</p>
<p>On observe, par ailleurs, que le corpus FTB ne couvre pas la reconnaissance de toutes les unit&#233;s multi-mots.
Tout d&#8217;abord, certains d&#233;terminants ou certaines entit&#233;s nomm&#233;es ne sont pas identifi&#233;s comme les d&#233;terminants
nominaux, les dates, les noms de personne, les adresses postales. Par ailleurs, de nombreux noms compos&#233;s sont
manquants. Par exemple, apr&#232;s avoir appliqu&#233; nos ressources lexicales de mani&#232;re non contextuelle (en excluant
les grammaires locales reconnaissants des types d&#8217;entit&#233;s nomm&#233;es ou des d&#233;terminants nominaux non cod&#233;s
dans le FTB), nous avons manuellement observ&#233; sur le FTB-DEV qu&#8217;environ 30% des unit&#233;s polylexicales de nos
ressources &#8221;adapt&#233;es&#8221; ne sont pas prises en compte dans le corpus.
</p>
<p>4.3 M&#233;thodologie de prise en compte des ressources
</p>
<p>Comment prendre en compte une ou plusieurs ressources lors d&#8217;une cha&#238;ne de traitements faisant appel &#224; un
apprentissage r&#233;alis&#233; avec un CRF ? Dans le cadre de l&#8217;apprentissage de la ressource MElt f r (Denis &amp; Sagot,
2009, 2010), les auteurs ont test&#233; deux approches possibles :
&#8211; int&#233;grer les propri&#233;t&#233;s des mots du lexique dans les fonctions caract&#233;ristiques du mod&#232;le d&#8217;apprentissage ;
&#8211; filtrer les &#233;tiquetages incompatibles avec les informations pr&#233;sentes dans la ressource.
Nous avons cherch&#233; toutes les fa&#231;ons possibles d&#8217;envisager cette int&#233;gration, ce qui nous a amen&#233; &#224; en caract&#233;riser
plus finement le mode op&#233;ratoire, et &#224; en trouver de nouvelles variantes. Nous les pr&#233;sentons ci-dessous, en dis-
cutant leurs int&#233;r&#234;ts et leurs limites. Elles peuvent s&#8217;organiser en deux familles principales, suivant que la ou les
ressources disponibles sont mises &#224; contribution comme des filtres avant ou apr&#232;s l&#8217;appel au CRF ou qu&#8217;elles
sont utilis&#233;es pendant la phase d&#8217;apprentissage. L&#8217;approche &#8220;filtrage&#8221; requiert que les &#233;tiquettes qui figurent dans
la ressource soient identiques &#224; celles qui sont la cible de l&#8217;apprentissage, alors que ce n&#8217;est pas n&#233;cessairement
le cas pour l&#8217;autre approche. Au cas o&#249; les conventions d&#8217;&#233;tiquetage ne sont pas les m&#234;mes, une fonction de
correspondance doit &#234;tre pr&#233;alablement appliqu&#233;e.
</p>
<p>Les ressources comme filtrage a priori ou a posteriori Les ressources peuvent &#234;tre vues comme un moyen de
contraindre, ou encore de filtrer les &#233;tiquetages possibles. Concr&#232;tement, ce filtrage peut op&#233;rer avant ou apr&#232;s
l&#8217;appel au CRF. Le filtrage a priori consiste &#224; d&#233;finir l&#8217;espace de recherche des &#233;tiquetages possibles y d&#8217;une nou-
velle cha&#238;ne x via un pr&#233;traitement fond&#233; sur une ressource. Les analyseurs lexicaux actuels auxquels on soumet
une phrase produisent en effet g&#233;n&#233;ralement un dag (graphe orient&#233; acyclique) dont chaque chemin correspond
&#224; une s&#233;quence possible d&#8217;&#233;tiquettes. Les unit&#233;s multi-mots peuvent &#234;tre reconnues lors de cette &#233;tape, et figurer
aussi dans le dag, comme cela a &#233;t&#233; &#233;voqu&#233; section 3.2. Pour une phrase constitu&#233;e de n unit&#233;s minimales, il est
&#233;videmment plus facile et rapide de chercher le y qui maximise p(y|x) (calcul&#233; suivant la formule des CRF) parmi
</p>
<p>6. Les unit&#233;s lexicales sont les unit&#233;s autres que les nombres et les ponctuations.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M. Constant, I. Tellier, D. Duchier, Y. Dupont, A. Sigogne, S. Billot
</p>
<p>l&#8217;ensemble des &#233;tiquetages du dag plut&#244;t que sur l&#8217;espace de tous les |Y |n &#233;tiquetages possibles. Le filtrage est
ainsi a priori mais l&#8217;apprentissage du CRF est n&#233;anmoins un pr&#233;-requis de la cha&#238;ne de traitements. Le filtrage a
posteriori, lui, cherche non pas le meilleur &#233;tiquetage possible y d&#8217;une cha&#238;ne quelconque x mais les m meilleurs
possibles (c&#8217;est une option g&#233;n&#233;ralement disponibles des biblioth&#232;ques CRF) et choisit le premier d&#8217;entre eux
compatible avec la ressource. Les deux techniques donnent la m&#234;me solution ; privil&#233;gier l&#8217;une ou l&#8217;autre d&#233;pend
de la forme de la ressource. Leur int&#233;r&#234;t est de garantir que dans la solution retenue, chaque mot re&#231;oit une &#233;ti-
quette compatible avec ce que d&#233;crivent la ou les ressources consult&#233;es. Un filtrage peut d&#8217;ailleurs tr&#232;s bien se
combiner avec une approche prenant en compte les ressources pendant la phase d&#8217;apprentissage.
</p>
<p>Les ressources comme aide &#224; l&#8217;apprentissage. D&#8217;apr&#232;s la section 2.2, quand nous faisons appel &#224; une biblio-
th&#232;que qui impl&#233;mente les CRF lin&#233;aires, nous avons &#224; notre disposition trois &#8220;leviers&#8221; d&#8217;action possibles :
&#8211; le choix des &#233;tiquettes et des propri&#233;t&#233;s des unit&#233;s (les colonnes des donn&#233;es tabulaires)
&#8211; le choix des exemples (les lignes)
&#8211; le choix des fonctions caract&#233;ristiques (via les patrons), choix qui d&#233;pend fortement des pr&#233;c&#233;dents
Nous avons d&#233;j&#224; vu qu&#8217;un choix pertinent d&#8217;&#233;tiquettes permettait de &#8220;coder&#8221; en quelque sorte les deux probl&#232;mes
de la segmentation et de l&#8217;&#233;tiquetage simultan&#233;ment. D&#8217;autres exp&#233;riences ont montr&#233; l&#8217;int&#233;r&#234;t de d&#233;composer le
jeu d&#8217;&#233;tiquettes en sous-&#233;tiquettes, notamment quand celles-ci sont trop nombreuses (Tellier et al., 2010). Mais le
probl&#232;me auquel nous nous confrontons ici ne requiert pas un tel traitement, nous ne l&#8217;avons pas mis en &#339;uvre.
</p>
<p>Il est en revanche &#8220;naturel&#8221; d&#8217;ins&#233;rer les informations des ressources en tant que propri&#233;t&#233;s des unit&#233;s d&#8217;un exemple
x, donc en jouant sur les colonnes x2i , ..., xpi . Plusieurs choix sont encore possibles pour cela, suivant qu&#8217;on se
contente de concat&#233;ner les diff&#233;rentes &#233;tiquettes possibles d&#8217;une m&#234;me unit&#233; pour en faire une seule colonne de
nature textuelle, ou bien qu&#8217;on d&#233;finisse autant de colonnes &#224; valeur bool&#233;enne que d&#8217;&#233;tiquettes possibles dans
l&#8217;ensemble de la ressource. Cela aura bien s&#251;r des cons&#233;quences sur la d&#233;finition des patrons qui g&#233;n&#232;rent les
fonctions caract&#233;ristiques. Dans le cas des colonnes bool&#233;ennes, la combinatoire des conjonctions possibles de
plusieurs crit&#232;res est explosive. Dans les deux cas, on peut soit garder les &#233;tiquettes des ressources telles quelles,
soit les transformer pour qu&#8217;elles s&#8217;identifient &#224; celles vis&#233;es.
</p>
<p>Enfin, il est aussi possible de consid&#233;rer que chaque instance de couple (unit&#233; lexicale, &#233;tiquette) pr&#233;sent dans
la ressource constitue &#224; elle toute seule une &#8220;phrase&#8221; qu&#8217;on ins&#232;re parmi les exemples &#233;tiquet&#233;s, en ajoutant de
nouvelles lignes isol&#233;es dans le corpus d&#8217;apprentissage. Cela suppose bien s&#251;r que les &#233;tiquettes qui figurent dans
la ressource sont identiques &#224; celles de l&#8217;&#233;tiquetage cible. L&#8217;id&#233;e sous-jacente de cette technique, tr&#232;s simple &#224;
appliquer, est que la pr&#233;sence dans une ressource &#233;quivaut &#224; une occurrence attest&#233;e dans la langue, que l&#8217;on simule
en l&#8217;ins&#233;rant artificiellement dans le corpus d&#8217;apprentissage. Elle pr&#233;sente aussi toutefois quelques inconv&#233;nients :
&#8211; on introduit ainsi un biais sur les comptes d&#8217;occurrences puisque les diff&#233;rentes &#233;tiquettes possibles d&#8217;une unit&#233;
</p>
<p>donnent chacune lieu &#224; un exemple, comme si elles &#233;taient &#233;quiprobables. Il faut donc esp&#233;rer que le reste de
l&#8217;ensemble d&#8217;apprentissage soit suffisant pour compenser cette distorsion possible.
</p>
<p>&#8211; en introduisant des &#8220;phrases&#8221; r&#233;duites &#224; un mot, on va rendre inop&#233;rantes sur ces &#8220;phrases&#8221; particuli&#232;res toutes
les fonctions caract&#233;ristiques qui testent la valeur des unit&#233;s ou des &#233;tiquettes voisins (et donc en particulier tous
les bigrammes). Le poids de ces fonctions ne pourra &#234;tre calcul&#233; que sur le reste des exemples.
</p>
<p>5 R&#233;sultats des exp&#233;riences
</p>
<p>Les r&#233;sultats pr&#233;sent&#233;s ici sont issus d&#8217;exp&#233;riences men&#233;es en parall&#232;le au LIFO (Orl&#233;ans) et au LIGM (Paris-Est
Marne-la-Vall&#233;e). Notons au pr&#233;alable que les exp&#233;riences ont &#233;t&#233; r&#233;alis&#233;es dans des environnements diff&#233;rents,
sans coordination a priori, ce qui explique la difficult&#233; &#224; comparer pr&#233;cis&#233;ment les r&#233;sultats. Les exp&#233;riences du
LIFO ont &#233;t&#233; men&#233;es avec Wapiti 7 et &#233;valu&#233;es par validation crois&#233;e en 10 parties : 9/10 pour l&#8217;apprentissage,
1/10 pour le test. Celles du LIGM ont utilis&#233; CRF++ 8 et port&#233; sur une variante du FTB plus volumineuse rendant
plus co&#251;teuse, mais aussi moins indispensable, une validation crois&#233;e : le corpus initial a alors &#233;t&#233; d&#233;coup&#233; en trois
parties : 80% pour la phase d&#8217;entra&#238;nement (TRAIN), 10% pour le d&#233;veloppement (DEV) et 10% pour le test.
Pour l&#8217;&#233;valuation globale, nous avons pr&#233;cision = rappel = f-mesure. En effet, tous les mots ayant une unique &#233;ti-
quette, une erreur de pr&#233;cision sur une classe C1 correspond &#224; une erreur de rappel sur une classe C2 et vice versa.
</p>
<p>7. Ce programme a l&#8217;avantage d&#8217;op&#233;rer une s&#233;lection des fonctions caract&#233;ristiques en cours d&#8217;apprentissage gr&#226;ce &#224; une p&#233;nalisation L1.
8. L&#8217;algorithme de r&#233;gularisation utilis&#233; est L2 et le seuil de fr&#233;quence des traits a &#233;t&#233; fix&#233; &#224; 2.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Inte&#769;grer des connaissances linguistiques dans un CRF
</p>
<p>Pour l&#8217;&#233;tiquetage avec segmentation, nous avons deux types d&#8217;&#233;valuation : la f-mesure sur les unit&#233;s minimales
(LIFO) et sur les segments lexicaux (LIGM). Ceci explique les scores plus &#233;lev&#233;s pour LIFO sur cette t&#226;che.
</p>
<p>5.1 Evaluation de l&#8217;&#233;tiquetage avec segmentation parfaite
</p>
<p>LIGM. Nous avons tout d&#8217;abord &#233;valu&#233; l&#8217;&#233;tiquetage morphosyntaxique sur une segmentation multi-mots par-
faite, au moyen d&#8217;un mod&#232;le CRF appris en utilisant des propri&#233;t&#233;s classiques des unit&#233;s (forme lexicale, pr&#233;fixes,
suffixes, commence par une majuscule, etc.). Les exp&#233;riences du LIGM ont port&#233; sur deux m&#233;thodes d&#8217;int&#233;gra-
tion de la ressource lexicale externe d&#233;crite dans la section 4.1. La premi&#232;re m&#233;thode consiste &#224; introduire, dans
le fichier d&#8217;entra&#238;nement, une colonne suppl&#233;mentaire (AC) repr&#233;sentant la concat&#233;nation des &#233;tiquettes trouv&#233;es
dans la ressource pour l&#8217;unit&#233; courante. Nous obtenons alors un mod&#232;le LEX en utilisant tous les traits d&#233;crits dans
la table 1(a). Nous notons STD le mod&#232;le incorporant les m&#234;mes traits &#224; l&#8217;exception de ceux issus de la ressource.
La deuxi&#232;me m&#233;thode consiste &#224; proc&#233;der &#224; un filtrage a priori de toutes les &#233;tiquettes absentes de la ressource
pour chaque unit&#233;. Si l&#8217;unit&#233; est absente, toutes les &#233;tiquettes sont gard&#233;es. Les &#233;tiquettes des ressources ont &#233;t&#233;
ajust&#233;es &#224; celles du corpus pour le filtrage. Nous avons compar&#233; les r&#233;sultats avec d&#8217;autres outils d&#8217;&#233;tiquetage que
nous avons tous entrain&#233;s sur le corpus FTB-TRAIN. Nous avons &#233;valu&#233; TreeTagger (Schmid, 1994) bas&#233; sur
des arbres de d&#233;cision probabilistiques, SVMTool (Gim&#233;nez &amp; M&#225;rquez., 2004) bas&#233; sur les S&#233;parateurs &#224; Vastes
Marges utilisant des traits ind&#233;pendants de la langue, MElt (Denis &amp; Sagot, 2009) bas&#233; sur un mod&#232;le MaxEnt in-
corporant en plus des traits d&#233;pendants de la langue issus de lexiques externes. Les lexiques utilis&#233;s pour entra&#238;ner
et tester MElt int&#232;grent toutes les ressources de la section 4.1 9. Les pr&#233;cisions obtenues sur le corpus FTB-TEST
pour les diff&#233;rents syst&#232;mes sont donn&#233;es en pourcentage dans la table 1(b) avec un intervalle de confiance &#224; 95%
de +/-0,1.
</p>
<p>(a) Types de traits
Traits internes unigrammes
w0 = X &amp;t0 = T
forme en minuscule de w0 = L &amp;t0 = T
Pr&#233;fixe de w0 = P avec |P| &lt; 5 &amp;t0 = T
Suffixe de w0 = S avec |S | &lt; 5 &amp;t0 = T
w0 contient un tiret &amp;t0 = T
w0 contient un chiffre &amp;t0 = T
w0 commence par une majuscule &amp;t0 = T
w0 est tout en majuscule &amp;t0 = T
w0 commence par une majuscule et est en d&#233;but de phrase &amp;t0 = T
classe d&#8217;ambiguit&#233; de w0, AC0 = A &amp;t0 = T
Traits contextuels unigrammes
wi = X, i &#8712; {&#8722;2,&#8722;1, 1, 2} &amp;t0 = T
wiw j = XY, ( j, k) &#8712; {(&#8722;1, 0), (0, 1), (&#8722;1, 1)} &amp;t0 = T
ACi = A, i &#8712; {&#8722;2,&#8722;1, 1, 2} &amp;t0 = T
Traits bigrammes
t&#8722;1 = T &#8242; &amp;t0 = T
</p>
<p>(b) Comparaison de syst&#232;mes d&#8217;&#233;tiquetage pour le
fran&#231;ais
</p>
<p>sans filtrage avec filtrage
TreeTagger 96.4 -
SVMTool 97.2 -
MElt 97.6 -
CRF-STD 97.4 97.6
CRF-LEX 97.7 97.7
</p>
<p>Table 2 &#8211; R&#233;sultats du LIGM avec segmentation parfaite
</p>
<p>LIFO. Les exp&#233;riences du LIFO ont port&#233; sur une version du FTB moins volumineuse, en utilisant les traits un-
igrammes d&#233;crits dans la Table 3(a) sur une fen&#234;tre [&#8722;2..2] et les simples valeurs d&#8217;&#233;tiquettes pour les bigrammes.
Les patrons bigrammes produisent en effet un tr&#232;s grand nombre de fonctions caract&#233;ristiques : cette restriction
est destin&#233;e &#224; limiter les calculs. La seule ressource &#224; notre disposition &#233;tait le Lefff. La premi&#232;re m&#233;thode utilis&#233;e
pour le prendre en compte en cours d&#8217;apprentissage est de l&#8217;int&#233;grer en tant que pourvoyeur de nouveaux exem-
ples dans chaque fichier d&#8217;entra&#238;nement. Cette m&#233;thode augmente le temps d&#8217;apprentissage du simple au double
voire triple selon les parties. La seconde m&#233;thode consiste &#224; introduire des bool&#233;ens en tant qu&#8217;attributs dans les
colonnes des fichiers d&#8217;entra&#238;nement, chaque colonne repr&#233;sentant une &#233;tiquette possible dans le Lefff. Il a fallu
alors g&#233;n&#233;rer par programme tous les patrons possibles qui combinent certains attributs entre eux. Cette m&#233;thode
produit un grand nombre de fonctions caract&#233;ristiques mais Wapiti est capable de les g&#233;rer puisqu&#8217;il op&#232;re une
s&#233;lection des fonctions caract&#233;ristiques les plus discriminantes en cours d&#8217;apprentissage (Lavergne et al., 2010).
</p>
<p>9. Nous avons regroup&#233; ensemble tous les dictionnaires, ainsi que les unit&#233;s reconnues lors de l&#8217;application des grammaires locales sur le
corpus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M. Constant, I. Tellier, D. Duchier, Y. Dupont, A. Sigogne, S. Billot
</p>
<p>(a) Types de traits
unigrammes
</p>
<p>Valeur de l&#8217;unit&#233;
Commence par une majuscule
Est uniquement en majuscules
Est un chiffre
Est une ponctuation
3 derni&#232;res lettres
</p>
<p>(b) R&#233;sultats
Sans lefff 96.5
Avec lefff (exemples) 96.6
Avec lefff (attributs bool&#233;ens) 97.3
</p>
<p>Table 3 &#8211; R&#233;sultats du LIFO avec segmentation parfaite
</p>
<p>5.2 Evaluation de l&#8217;&#233;tiquetage avec identification des unit&#233;s multi-mots
</p>
<p>LIGM. Pour &#233;valuer la t&#226;che d&#8217;&#233;tiquetage int&#233;grant la reconnaissance des unit&#233;s multi-mots, nous avons en-
tra&#238;n&#233; trois mod&#232;les CRF sur le corpus FTB-TRAIN apr&#232;s avoir d&#233;compos&#233; les unit&#233;s multi-mots en s&#233;quences
d&#8217;unit&#233;s minimales &#233;tiquet&#233;es dans la repr&#233;sentation de type IOB (cf. section 3.3) : STD, LEX et MWE. Les deux
premiers ont les m&#234;mes types de traits que dans l&#8217;exp&#233;rience pr&#233;c&#233;dente. Le mod&#232;le MWE est compl&#233;t&#233; de traits
issus de l&#8217;application non-contextuelle de nos ressources multi-mots sur le texte : une unit&#233; est associ&#233;e &#224; la cat&#233;-
gorie grammaticale, la structure interne ou/et le trait s&#233;mantique de l&#8217;unit&#233; polylexicale reconnue &#224; laquelle elle
appartient, ainsi qu&#8217;&#224; sa position relative dans l&#8217;unit&#233; (I, O ou B). Par exemple, le mot de dans le contexte du mot
compos&#233; eau de vie pr&#233;sent dans nos ressources, sera associ&#233; &#224; la cat&#233;gorie grammaticale NC (nom), &#224; la structure
interne NPN (nom+pr&#233;position+nom) et &#224; la position relative I (car il est en 2&#232;me position). Ces trois syst&#232;mes
ont &#233;t&#233; compar&#233;s avec SVMTool, entra&#238;n&#233; sur le m&#234;me corpus. Pour chaque segmenteur-&#233;tiqueteur appliqu&#233; sur
le corpus TEST d&#233;compos&#233; en unit&#233;s minimales, nous avons calcul&#233; la f-mesure 10. La pr&#233;cision et le rappel sont
calcul&#233;s par rapport aux segments lexicaux trouv&#233;s et non aux unit&#233;s minimales simples. Les r&#233;sultats sont syn-
th&#233;tis&#233;s dans le tableau 3(a). La colonne SEG indique la f -mesure de la segmentation qui ne prend en compte que
les limites des segments. La colonne TAG prend aussi en compte la cat&#233;gorie grammaticale.
</p>
<p>LIFO. Pour cette t&#226;che, nous comparons les r&#233;sultats obtenus (1) sans le Lefff, (2) avec le Lefff comme source
d&#8217;exemples, (3) avec le Lefff comme source d&#8217;attributs bool&#233;ens. Nos r&#233;sultats &#233;valuent la qualit&#233; de l&#8217;&#233;tiquetage
des unit&#233;s minimales avec les cat&#233;gories int&#233;grant B et I, et non celle de l&#8217;identification des unit&#233;s multimots.
</p>
<p>(a) LIGM (f-mesure sur les
segments lexicaux)
</p>
<p>TAG SEG
SVMTool 92.1 94.7
CRF-STD 93,7 95.8
CRF-LEX 93.9 95.9
CRF-MWE 94.4 96.4
</p>
<p>(b) LIFO : m&#233;thodes d&#8217;int&#233;gration
(f-mesure sur les unit&#233;s minimales)
</p>
<p>Sans lefff 94.5%
Avec lefff (exemples) 94.7%
Avec lefff (attributs) 95.2%
</p>
<p>Table 4 &#8211; Apprentissage simultan&#233; &#233;tiquetage/segmentation
</p>
<p>5.3 Description des segmenteurs-&#233;tiqueteurs propos&#233;s
</p>
<p>Les diverses exp&#233;riences d&#233;crites ci-dessus ont men&#233; &#224; la mise au point de segmenteurs-&#233;tiqueteurs qui sont li-
brement disponibles. La cha&#238;ne de traitements de SEM 11 produite au LIFO a &#233;t&#233; &#233;crite en Python. Le programme
offre la possibilit&#233; d&#8217;exploiter ou non Lefff (sous forme d&#8217;attributs uniquement), en utilisant soit une segmenta-
tion rudimentaire &#233;crite &#224; la main (sans prise en compte de ressources externes), soit la segmentation acquise par
le CRF. Le segmenteur-&#233;tiqueteur LGTagger 12 produit au LIGM est implant&#233; en Java et comprend deux phases
distinctes : (1) une analyse lexicale bas&#233;e sur des ressources lexicales externes qui sert &#224; filtrer les analyses (sim-
ples ou multi-mots) non d&#233;crites dans les ressources et qui produit un dag 13 ; (2) un d&#233;codeur qui d&#233;termine le
</p>
<p>10. La formule de la f -mesure est la suivante : f = 2prp+r o&#249; p est la pr&#233;cision et r le rappel.
11. http ://www.univ-orleans.fr/lifo/Members/Isabelle.Tellier/SEM.html
12. http ://igm.univ-mlv.fr/&#732;mconstan/research/software
13. Pour les mots simples inconnus de nos ressources, toutes les &#233;tiquettes possibles sont gard&#233;es comme candidates. Si l&#8217;analyseur n&#8217;a
</p>
<p>aucune ressource lexicale en entr&#233;e, il produit un dag repr&#233;sentant toutes les analyses possibles dans le jeu d&#8217;&#233;tiquettes.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Inte&#769;grer des connaissances linguistiques dans un CRF
</p>
<p>chemin du dag le plus probable en fonction du mod&#232;le CRF appris. Il peut &#234;tre ex&#233;cut&#233; avec ou sans segmentation
multi-mots. Les ressources lexicales (pour le calcul des propri&#233;t&#233;s des fonctions caract&#233;ristiques et pour l&#8217;analyse
lexicale) lui sont pass&#233;es en param&#232;tres. Les programmes d&#8217;Unitex (Paumier, 2011) sont utilis&#233;s pour l&#8217;application
des ressources : consultation des dictionnaires et application des grammaires locales.
</p>
<p>6 Conclusion
</p>
<p>Dans cet article, nous avons montr&#233; que les t&#226;ches de segmentation et d&#8217;&#233;tiquetage sont intimement li&#233;es et qu&#8217;il
est naturel de les traiter simultan&#233;ment. L&#8217;&#233;cart entre la performance de l&#8217;&#233;tiquetage avec ou sans segmentation
est de 2 &#224; 4 points suivant la mesure utilis&#233;e : cela mesure le &#8220;co&#251;t&#8221; d&#8217;une bonne segmentation. Par ailleurs, nous
avons montr&#233; l&#8217;int&#233;r&#234;t certain d&#8217;int&#233;grer des ressources lexicales dans un CRF, en particulier les ressources d&#8217;unit&#233;s
polylexicales utiles pour la segmentation. Nous voyons aussi qu&#8217;&#224; ce niveau de performance, il est extr&#234;mement
difficile de gagner quelques dixi&#232;mes de points, m&#234;me en mettant en jeu des ressources riches et vari&#233;es.
Cet article a aussi &#233;t&#233; l&#8217;occasion d&#8217;une r&#233;flexion m&#233;thodologique pouss&#233;e sur les diff&#233;rents moyens d&#8217;int&#233;grer une
ressource linguistique externe dans une cha&#238;ne de traitements faisant appel &#224; un CRF. Une bonne partie de cette
r&#233;flexion est d&#8217;ailleurs transposable &#224; l&#8217;utilisation d&#8217;autres techniques d&#8217;apprentissage automatique. Les CRF, en
int&#233;grant fonctions caract&#233;ristiques locales et combinaison statistique globale, apparaissent comme un mod&#232;le
particuli&#232;rement bien adapt&#233; &#224; l&#8217;hybridation entre ressources symboliques et mod&#232;les statistiques. Gr&#226;ce &#224; cette
int&#233;gration, il a &#233;t&#233; possible de produire en peu de temps des segmenteurs-&#233;tiqueteurs tr&#232;s performants.
</p>
<p>R&#233;f&#233;rences
Abeille&#769; A., Cle&#769;ment L. &amp; Toussenel F. (2003). Building a treebank for french. In A. Abeille&#769;, Ed., Treebanks.
Dordrecht : Kluwer.
Blanc O., Constant M. &amp; Watrin P. (2007). Segmentation in super-chunks with a finite-state approach. In
Proceedings of the 6th Workshop on Finite-State Methods and Natural Language Processing (FSMNLP&#8217;07), p.
62 &#8211; 73.
ConstantM. &amp; Watrin P. (2008). Networking multiword units. In Proceedings of the 6th International Confer-
ence on Natural Language Processing (GoTAL&#8217;08), number 5221 in Lecture Notes in Artificial Intelligence, p.
120 &#8211; 125 : Springer-Verlag.
Courtois B. (2009). Un syst&#232;me de dictionnaires &#233;lectroniques pour les mots simples du fran&#231;ais. Langue
Fran&#231;aise, 87, 1941 &#8211; 1947.
Courtois B., GarriguesM., Gross G., GrossM., Jung R., Mathieu-ColasM., Monceaux A., Poncet-Montange
A., SilberzteinM. &amp; Vive&#769;s R. (1997). Dictionnaire &#233;lectronique DELAC : les mots compos&#233;s binaires. Rapport
interne 56, University Paris 7, LADL.
Crabbe&#769; B. &amp; CanditoM. H. (2008). Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais. In Actes de TALN
2008 (Traitement automatique des langues naturelles), Avignon.
Daille B. (1995). Rep&#233;rage et extraction de terminologie par une approche mixte statistique et linguistique.
traitement Automatique des Langues (TAL), 36(1-2), 101&#8211;118.
Denis P. &amp; Sagot B. (2009). Coupling an annotated corpus and a morphosyntactic lexicon for state-of-the-art pos
tagging with less human effort. In Proceedings of the 23rd Pacific Asia Conference on Language, Information
and Computation (PACLIC 2009).
Denis P. &amp; Sagot B. (2010). Exploitation d&#8217;une ressource lexicale pour la construction d&#8217;un &#233;tiqueteur mor-
phosyntaxique &#233;tat-de-l&#8217;art du francais. In actes de TALN 2010.
Dias G. (2003). Multiword unit hybrid extraction. In Proceedings of the Workshop on Multiword Expressions of
the 41st Annual Meeting of the Association of Computational Linguistics (ACL 2003), p. 41&#8211;49.
Friburger N. &amp; Maurel D. (2009). Finite-state transducer cascade to extract named entities in texts. Theoretical
Computer Science, 313, 94&#8211;104.
Gime&#769;nez J. &amp; Ma&#769;rquez. L. (2004). Svmtool : A general pos tagger generator based on support vector machines.
In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC&#8217;04).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M. Constant, I. Tellier, D. Duchier, Y. Dupont, A. Sigogne, S. Billot
</p>
<p>Gross M. (1997). The construction of local grammars. In D. J. Lipcoll, D. H. Lawrie &amp; A. H. Sameh, Eds.,
Finite-State Language Processing, p. 329&#8211;352. Cambridge, Mass. : The MIT Press.
Lafferty J., McCallum A. &amp; Pereira F. (2001). Conditional random fields : Probabilistic models for segmenting
and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning
(ICML 2001), p. 282&#8211;289.
Lavergne T., Cappe&#769; O. &amp; Yvon F. (2010). Practical very large scale CRFs. In Proceedings the 48th Annual
Meeting of the Association for Computational Linguistics (ACL), p. 504&#8211;513 : Association for Computational
Linguistics.
Martineau C., Nakamura T., Varga L. &amp; Voyatzi S. (2009). Annotation et normalisation des entit&#233;s nomm&#233;es.
Arena Romanistica, 4, 234&#8211;243.
McCallum A. &amp; LiW. (2003). Early results for named entity recognition with conditional random fields, feature
induction and web-enhanced lexicons. In Proceedings of CoNLL.
Nasr A., Be&#769;chet F. &amp; Rey J. F. (2010). Macaon : Une cha&#238;ne linguistique pour le traitement de graphes de mots.
In Traitement Automatique des Langues Naturelles - session de d&#233;monstrations, Montr&#233;al.
Paumier S. (2011). Unitex 2.1 - user manual. http ://igm.univ-mlv.fr/&#732;unitex.
Piton O., Maurel D. &amp; Belleil C. (1999). The prolex data base : Toponyms and gentiles for nlp. In Proceedings
of the Third International Workshop on Applications of Natural Language to Data Bases (NLDB&#8217;99), p. 233&#8211;237.
Poibeau T. (2009). Boosting Robustness of a Named Entity Recognizer. International Journal of Semantic
Computing, 3(1), 1&#8211;14.
Ramshaw L. A. &amp; Marcus M. P. (1995). Text chunking using transformation-based learning. In Proceedings of
the 3rd Workshop on Very Large Corpora, p. 88 &#8211; 94.
RatnaparkhiA. (1996). A maximum entropy model for part-of-speech tagging. In Proceedings of the Conference
on Empirical Methods in Natural Language Processing (EMNLP 1996), p. 133 &#8211; 142.
Sag I. A., Baldwin T., Bond F., Copestake A. A. &amp; Flickinger D. (2002). Multiword expressions : A pain in the
neck for nlp. In Proceedings of the Third International Conference on Computational Linguistics and Intelligent
Text Processing (CICLing &#8217;02), p. 1&#8211;15, London, UK : Springer-Verlag.
Sagot B. (2010). The lefff, a freely available, accurate and large-coverage lexicon for french. In Proceedings of
the 7th International Conference on Language Resources and Evaluation (LREC&#8217;10).
Sagot B. &amp; Boullier P. (2006). Deep non-probabilistic parsing of large corpora. In Proceedings of the 5th
International Conference on Language Resources and Evaluation (LREC&#8217;06).
Sagot B. &amp; Boullier P. (2008). Sxpipe 2 : architecture pour le traitement pr&#233;-syntaxique de corpus bruts.
Traitement Automatique des Langues, 49(2), 155&#8211;188.
Schmid H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings of International
Conference on New Methods in Language Processing, p. 252 &#8211; 259.
Seretan V., Nerima L. &amp; Wehrli E. (2003). Extraction of multi-word collocations using syntactic bigram com-
position. In Proceedings of the Fourth International Conference on Recent Advances in NLP (RANLP-2003), p.
424&#8211;431, Borovets, Bulgaria.
Sha F. &amp; Pereira F. (2003). Shallow parsing with conditional random fields. In Proceedings of HLT-NAACL, p.
213 &#8211; 220.
SilberzteinM. (2000). Intex : an fst toolbox. Theoretical Computer Science, 231(1), 33&#8211;46.
Tellier I., Eshkol I., Taalab S. &amp; Prost J. P. (2010). Pos-tagging for oral texts with crf and category de-
composition. Research in Computing Science, 46, 79&#8211;90. Special issue &quot;Natural Language Processing and its
Applications&quot;.
Tellier I. &amp; Tommasi M. (2011). Champs Markoviens Conditionnels pour l&#8217;extraction d&#8217;information. In Eric
Gaussier &amp; Franc&#807;ois Yvon, Eds., Mod&#232;les probabilistes pour l&#8217;acc&#232;s &#224; l&#8217;information textuelle. Herm&#232;s.
ToutanovaK., Klein D., Manning C. D. &amp; Singer Y. Y. (2003). Feature-rich part-of-speech tagging with a cyclic
dependency network. In Proceedings of HLT-NAACL 2003, p. 252 &#8211; 259.
Tsuruoka Y., Tsujii J. &amp; Ananiadou S. (2009). Fast full parsing by linear-chain conditional random fields. In
Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics
(EACL 2009), p. 790&#8211;798.</p>

</div></div>
</body></html>