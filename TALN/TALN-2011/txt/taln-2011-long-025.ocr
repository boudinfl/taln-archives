TALN 2011, Montpellier, 27 juin -1” juillet 2011

Structure des trigrammes inconnus et lissage par analogie

Julien Gosmel Yves Lepagez
(1) GREYC, université de Caen Basse-Norrnandie, France
Julien.Gosme@unicaen.fr
(2) IPS, université Waseda, J apon
Yves.Lepage@aoni.waseda.jp

Résumé. Nous montrons dans une série d’expériences sur quatre langues, sur des échantillons du corpus
Europarl, que, dans leur grande majorité, les trigrammes inconnus d’un jeu de test peuvent etre reconstruits par
analogie avec des trigrammes hapax du corpus d’entrainement. De ce résultat, nous dérivons une méthode de
lissage simple pour les modeles de langue par trigrammes et obtenons de meilleurs résultats que les lissages de
Witten—Bell, Good-Turing et Kneser-Ney dans des experiences menées en onze langues sur la partie commune
d’ Europarl, sauf pour le ﬁnnois et, dans une moindre mesure, le frangais.

Abstract. In a series of experiments in four languages on subparts of the Europarl corpus, we show that
a large number of unseen trigrams can be reconstructed by proportional analogy using only hapax trigrams. We
derive a simple smoothing scheme from this empirical result and show that it outperforms Witten—Bell, Good-
Turing and Kneser-Ney smoothing schemes on trigram models built on the common part of the Europarl corpus,
in all 11 languages except Finnish and French.

M0tS-CléS 3 analogie, trigrammes inconnus, trigrammes hapax, modele de langue trigrammes, Europarl.

Keywords: proportional analogy, unseen trigrams, hapax trigrams, trigram language models, Europarl.

1 Introduction

Les techniques de lissage de modeles de langue reposent habituellement sur des hypotheses purement statistiques
pour estimer la probabilité des évenements inconnus. 11 y a dix ans, (Rosenfeld, 2000) constatait que :

Ironically, the most successful SLM techniques use very little knowledge of what language really
is. The most popular language models (n—grams) take no advantage of the fact that what is being
modeled is language.

Nous présentons ici une technique de lissage pour les modeles de langue trigrammes qui repose sur la structure
des évenements inconnus, c’est-a-dire la maniere dont les trigrammes inconnus peuvent etre construits a partir des
trigrammes connus en utilisant une operation structurelle linguistiquement justiﬁée, l’analogie.

Le but du lissage des modeles de langue est d’attribuer des probabilités non—nulles aux évenements inconnus.
Habituellement, les probabilités attribuées dependent d’une caractérisation théorique des événements inconnus.
L’hypothese a l’origine de ce travail est que les trigrammes inconnus peuvent etre caractérisés, dans une large
mesure, par la sirnilitude de leurs structures avec des trigrammes rares. Plus précisément nous montrons ci—dessous
que, dans une large mesure, les trigrammes inconnus sont analogues aux trigrammes hapax.

En guise d’illustration, dans une de nos experiences préliminaires, le trigramme de mots opportunite’ de servir
était un trigramme de notre jeu de test absent du corpus d’entrainement. 11 se trouvait que ce trigramme pouvait
etre reconstruit par analogie a l’aide de trois trigrammes du corpus d’entrainement de la maniere suivante :

opportunite’ de servir : opportunite’ de modiﬁer :: qui pea-H=ait servir : 

La ligne précédente se lit ainsi : le trigramme inconnu opportunite’ de servir est au trigramme connu opportunite’
de modifier ce qu’un autre trigramme connu, qui pourrait servir, est a un demier trigramme connu, qui pourrait

JULIEN GOSME ET YVES LEPAGE

modifier. Les différents elements du trigramme inconnu sont obtenus par similarité avec le second et le troisieme
trigrammes (opportunité de et servir) et peuvent etre assembles par difference avec le quatrieme trigramme (mots
barres). En plus de permettre la reconstruction, les trois trigrammes ci—dessus étaient tous hapax dans le corpus
d’ entrainement.

La relation, telle celle donnée ci—dessus entre trigrammes de mots, qui enonce qu’A est a B ce que C’ est a D
est appelée analogie. Un certain nombre de travaux en traitement automatique des langues exploitent l’analogie.
Nous n’en citons que quelques—uns ici. Par exemple, sur des taches de segmentation morphologique, (Lavallée
& Langlais, 2010) ont récemment obtenu d’excellents resultats dans la découpe des mots par analogie. (Claveau
& L’Homme, 2005), entre autres auteurs, avaient auparavant étudié, en faisant usage de l’analogie, dans quelle
mesure la similarité liait la forme et le sens des mots : connector : to connect :: editor : to edit. En plus des
analogies entre mots eux—memes, (Hathout, 2009) a récemment exploité les analogies entre deﬁnitions extraites
du TLFi pour construire automatiquement des familles de mots lies par la forme et le sens. Dans le meme ordre
d’ idée, (Langlais et al., 2008) avaient propose d’utiliser l’analogie pour forger de nouvelles équivalences termino-
logiques dans le domaine medical a cheval sur deux langues. Sur le seul plan sémantique, (Tumey, 2008) a quant
a lui presenté une approche générale au probleme de l’association entre mots utilisant l’analogie entre Vecteurs
contextuels : mason : stone :: carpenter : wood, approche qu’il pretend géneralisable aux relations de synonymie
et d’antony1nie. (Lepage & Denoual, 2005) quanta eux ont congu un systeme de traduction automatique entiere—
ment fondé sur l’analogie. Dans le cadre de la traduction automatique aussi, (Denoual, 2007) et (Langlais & Patry,
2007) ont montré la possibilité de traduire certains mots inconnus par analogie.

La deﬁnition de l’analogie que nous utilisons dans ce travail est détaillée et justiﬁée dans (Lepage, 2004). Nous
l’appliquons aux trigrammes de mots. Un quadruplet de trigrammes de mots A, B, C’ et D est une analogie lorsque
les contraintes suivantes sont Vériﬁées :

d(A,B) = d(C,D)
d(A,C') = d(B,D)
|A|m ‘ |B|m = lclm ‘ |D|mvVm

Ici, d est la distance d’ edition qui compte le nombre minimum d’insertions et de suppressions de mots nécessaires
a la transformation d’un trigramme en un autre. 1 |A|m est le nombre d’occurrences du mot m dans le trigramme
A. En reprenant l’exemple precedent :

= opportunite’ de servir
opportunite’ de modifier
qui pourrait servir

= qui pourrait modifier

UQUUIL
||||

on peut Veriﬁer que d(A, B) = d(C', D) = 2 et d(A, C’) = d(B, D) = 4. La relation entre nombres d’occurrences
est Vériﬁée pour chaque mot :

motm | |A|m—|B|m=|C’|m—|D|m
opportunite’ 1 — 1 = 0 — 0
de 1 — 1 = 0 — 0
servir 1 — 0 = 1 — 0
modifier 0 — 1 = 0 — 1
qui 0 — 0 = 1 — 1
pourrait 0 — 0 = 1 — 1

Le bon sens Veut que les trigrammes inconnus apparaissant dans un jeu de test qui peuvent etre reconstruits par
analogie avec des trigrammes d’un corpus d’entrainement soient considérés plus sﬁrs que ceux qui ne peuvent pas
l’etre. Une technique de lissage basée sur de simples décomptes devrait donc donner une plus forte re-estimation
aux trigrammes pouvant etre reconstruits par analogie et une plus faible ré—estimation aux autres. Si, en plus, les
trigrammes reconstruits peuvent l’etre a l’aide de trigrammes hapax, la ré—estimation de leur effectif devrait etre
proche de l puisqu’ils sont alors proches structurellement des trigrammes hapax.

1. La distance d’édition dc Levenshtein (Levenshtein, 1966) prend en compte la substitution comme opération d’édition supplémentaire.

STRUCTURE DES TRIGRAMMES INCONNUS ET LISSAGE PAR ANALOGIE

La suite de l’article est divisée en deux parties : la section 2 est consacrée a Veriﬁer l’hypothese que les trigrammes
inconnus sont structurellement analogues aux trigrammes hapax. Des experiences successives menées sur quatre
langues européennes conﬁrment, les unes apres les autres, cette hypothese. La section 3 presente alors une tech-
nique de lissage reposant sur cette propriété, et directement inspirée des techniques élémentaires de Lidstone et
de Laplace. Des comparaisons effectuées avec quatre autres techniques de lissage classiques sur onze langues
europeennes montrent son efﬁcacité, Voire sa supériorité.

2 La structure des trigrammes inconnus d’un jeu de test

Nous menons des experiences sur les quatre langues suivantes : l’anglais, le frangais, l’allemand et le ﬁnnois. Ces
langues ont eté choisies pour leurs differentes richesses morphologiques. Sur une échelle croissante, on peut en
effet placer successivement l’anglais, le francais, l’allemand puis le ﬁnnois qui a la morphologie la plus riche.

Le corpus Europarl (Koehn, 2005) offre des textes alignés dans ces quatre langues,2 ce qui permet de mener
des experiences Véritablement comparables. Pour les experiences de cette section, de l’ensemble de toutes les
phrases correspondantes dans toutes les langues, nous avons extrait aleatoirement 100000 phrases. Parmi elles,
90000 phrases ont eté sélectionnées aléatoirement, les memes dans toutes les langues, pour servir de corpus
d’entrainement. Le jeu de test est constitue des 10 000 phrases restantes.

2.1 Proportion de trigrammes inconnus reconstruits

Pour Veriﬁer dans quelle mesure les trigrammes inconnus d’un jeu de test peuvent etre reconstr11its par analogie,
nous effectuons une premiere serie d’experiences par Validation croisée. Nous comptons simplement le nombre
total de trigrammes inconnus du jeu de test reconstructibles par analogie a l’aide de trois trigrammes du corpus
d’entrainement. Des lors que la reconstruction est possible, le processus est interrompu pour ce trigrarnme.

Les résultats obtenus, reportés dans la table 1, montrent que la proportion de trigrammes inconnus dans le jeu de
test reconstructibles par analogie avec trois autres trigrammes du corpus d’entrainement est superieure a 80 % en
anglais et en francais et supérieure a 70 % en allemand. Cette proportion, appelee /.4 ici, est donc irnportante. Elle
est calculée sur le nombre total de trigrammes inconnus djfférents (sans repetition) dont la proportion relativement
au nombre total de trigrammes du jeu de test est appelée A. Des experiences non rapportées ici montrent qu’en
augmentant la taille des donnees, les Valeurs de A baissent tandis que les Valeurs de /.1 augmentent. Les parametres
A et /.1 seront exploités dans la section 3.1.

TABLE 1 — Nombre de trigrammes inconnus différents dans le jeu de test et proportion de trigrammes inconnus
différents reconstructibles par analogie a l’aide de trois trigrammes du corpus d’entrainement.
Trigrammes inconnus
du jeu detest reconstruits
(A) (M)

anglais 114,566 (60,04 %) 83,67 %

frangais 116,922 (57,81%) 81,87 %

allemand 140,226 (68,97 %) 72,14 %

ﬁnnois 132,931 (83,33 %) 44,93 %

En ﬁnnois, la proportion de trigrammes inconnus différents reconstruits est faible avec seulement 45 %. Cette
faible Valeur est certainement explicable par la richesse morphologique de cette langue et donc l’absence relative
de mots—fonctions permettant plus de commutations de mots dans les trigrammes. Nous pouvons des a present
nous attendre a des resultats différents en ﬁnnois dans toute la suite de notre etude.

2. http: //www . statrnt . org/europarl

JULIEN GOSME ET YVES LEPAGE

2.2 Patrons d’analogie les plus fréquents

Un trigramme de mots donne peut etre obtenu par analogie a l’aide d’autres trigrammes de plusieurs fagons. Par
exemple, pour le trigramme opportunite’ de servir, on a, entre autres, les deux analogies suivantes qui utilisent des
trigrammes différents du corpus d’entrainement et respectent bien la deﬁnition de l’analogie Vue en introduction :

opportunite’ de servir : opportunite’ de modifier :: qui pourrait servir : qui pourrait modifier

opportunite’ de servir : opportunite’ pour dire :: de servir le : pour dire le

Ces deux analogies exempliﬁent deux patrons d’ analogie djfférents domes dans la table 2 et numerotes 1 et 2. Le
patron 1 correspond au remplacement du bigramme correspondant a la partie gauche du premier trigramme par un
autre bigramme et le remplacement de l’unigramme restant a droite par un autre unigramme : opportunite’ de est
remplacé par qui pourrait, et servir est remplace par modifier. Le patron 2 revient a trouver deux bigrammes dans
les memes contextes droit et gauche : de servir et pour dire existent dans les memes contextes opportunite’ ~ et ~
le.

Dans le double but d’enumerer les patrons existant reellement en corpus et d’en determiner les frequences d’ap—
parition respectives, nous enumerons simplement toutes les analogies existantes er1tre trigrammes a partir d’un
echantillon aleatoire de 10000 phrases dans chaque langue. Pour cela, nous avons contraint la methode d’enu—
meration de toutes les analogies d’un texte proposee dans (Gosme & Lepage, 2009) pour n’enumerer que les
analogies entre trigrammes de mots. Ensuite, nous regroupons les instances d’analogies obtenues par patron et les
comptons.

La table 2 donne les patrons d’analogie listes par ordre decroissant de frequences pour l’anglais. Un résultat
remarquable est que les cinq patrons d’analogie les plus frequents dans les quatre langues apparaissent dans le
meme ordre avec des proportions semblables.

TABLE 2 — Patrons d’analogie entre trigrammes de mots dans un echantillon anglais de 10 000 phrases du corpus
Europarl tries par proportions relatives sur l’ensemble des analogies entre trigrammes. Les symboles utilises dans
l’ecriture des patrons d’analogie sont distincts deux a deux. Ces patrons respectent la deﬁnition de l’analogie
donnee en introduction.

N° A : B :: C’ : D Proportion
1 abc:abd::efc :efd 12,6%
2 abc:ade::bcf:def 9,1%
3 abc:dbc::efa:efd 3,1%
4 abc:aec::bcd:ecd 2,7%
5 abc:abd::bce:bde 2,6%
6 abc:ade::fbc:fde 2,4%
7 abc:adc::bef:def 1,3%
8 abc:abd::aec:aed 0,9%

2.3 Patrons d’analogie les plus rentables

Jusqu’a present, nous avons montré, d’une part, qu’une grande majorite des trigrammes inconnus peuvent etre
reconstruits par analogie a l’aide de trigrammes issus du corpus d’entrainement (section 2.1); et nous avons
identiﬁe, d’ autre part, les patrons d’ analogie de trigrammes de mots les plus frequents dans un meme corpus
(Section 2.2). L’etape suivante est d’identiﬁer les patrons d’analogie qui permettent de reconstr11ire le plus de
trigrammes inconnus d’un jeu de test a l’aide de trigrammes du corpus d’entrainement, autrement dit, les patrons
les plus rentables. A cette ﬁn, nous conduisons une nouvelle serie d’ experiences. En raison de la lourdeur en temps
de calcul, nous limitons notre experience aux cinq patrons d’ analogie les plus frequents listes dans la table 2, et
nous procedons de la sorte : pour chaque trigramme inconnu du jeu de test, chaque patron d’analogie est essaye
successivement dans l’ordre de la table 2. Des lors qu’un patron d’analogie permet de reconstruire le trigramme
inconnu en question, nous notons son rang et passons au trigramme inconnu suivant.

STRUCTURE DES TRIGRAMMES INCONNUS ET LISSAGE PAR ANALOGIE

Les resultats sont présentes dans les tables 3((a))—(d)). Ils montrent les contributions cumulées des patrons d’ ana-
logie a la reconstruction des trigrarnmes inconnus. Le patron 1 contribue seul a la majorité de la reconstruction
des trigrammes inconnus : plus de 70 % en anglais, frangais et allemand, mais seulement 61,5 % pour le ﬁnnois.
Les patrons 1 et 2 sufﬁsent a reconstruire environ 95 % des trigrarnmes inconnus en anglais, frangais et allemand,
et presque 90 % en ﬁnnois.

TABLE 3 — Curnul des contributions des cinq patrons d’analogie les plus frequents a la reconstruction des tri-
grammes inconnus dans les quatre langues étudiees. Les pourcentages presentes sont relatifs au nombre total de

trigrarnmes inconnus.

(a) Anglais (b) Francais
N° de Trigrammes Proportion N° de Trigrarnmes Proportion
patron reconstruits cumulée patron reconstr11its cumulee
(M) (M)
1 72 426 (63,22 %) 75,55 % 1 71,466 (61,98 %) 74,66 %
2 19 952 (17,42 %) 96,37 % 2 20,475 (17,51 %) 96,05 %
3 3 411 (2,98 %) 99,93 % 3 3 655 (3,13%) 99,87 %
4 46 (0,04 %) 99,97 % 4 92 (0,08 %) 99,97 %
5 25 (0,02 %) 100,00 % 5 35 (0,03 %) 100,00 %
Total 95 860 (83,67 %) 100,00 % Total 95 723 (81,87%) 100,00 %
(c) Allemand (d) Finnois
N° de Trigrammes Proportion N° de Trigrammes Proportion
patron reconstruits cumulee patron reconstruits cumulée
(M) (M)
1 71 150 (50,74 %) 70,34 % 1 36 717 (27,62 %) 61,48 %
2 23 810 (16,98 %) 93,87 % 2 16 064 (12,08 %) 88,37 %
3 6 003 (4,28 %) 99,81 % 3 6 227 (4,68 %) 98,80 %
4 156 (0,11 %) 99,96 % 4 548 (0,41 %) 99,72 %
5 37 (0,03 %) 100,00 % 5 169 (0,13 %) 100,00 %
Total 101 156 (72,14 %) 100,00 % Total 59 725 (44,93 %) 100,00 %

Pour les quatre langues, les cinq patrons sufﬁsent a reconstruire l’intégra1ité des trigrarnmes; notre restriction se
justiﬁe donc a posteriori. Quelques exemples de reconstructions de trigrarnmes sont donnés dans les ﬁgures 1 et 2.

Q justice et : Q est, :: justice etﬁ : est, Q
de’bat en tant : de’bat de ce :: en tant qu’ : de ce qu’
couts de la : couts et les :: de la plus : et les plus

FIGURE 1 — Exemples de trigrarnmes de mots du corpus frangais d’Europarl respectant le patron 2, c’est-a—dire
abc:ade::bc}_‘:de}_‘.

debate and w : debate and E :: but as w : but as fir
Union have s_et : Union have that :: a committee & : a committee that
but they Q : but they must :: so we Q : so we must

FIGURE 2 — Exemples de trigrarnmes de mots du corpus anglais d’Europarl respectant le patron 1, c’est—a—dire
abg:abc_i::efg:efc_i.

2.4 Effectif sufﬁsant pour la reconstruction d’un trigramme inconnu

Puisque l’hypothese de la reconstruction massive des trigrammes inconnus par analogie est conﬁnnee par les
experiences precédentes, nous passons maintenant a l’étude des effectifs des trigrammes irnpliqués dans les re-
constructions. Nous cherchons a savoir quels effectifs ont les trigrarnmes qui pennettent la reconstruction des

JULIEN GOSME ET YVES LEPAGE

trigrammes inconnus. Une supposition naturelle serait que les trigrammes d’effectifs semblables aient tendance
a apparaitre dans les memes analogies. Suivant cette supposition, on peut faire l’hypothese que les trigrammes
inconnus, c’est—a—dire apparaissant zero fois dans le corpus d’entrainement, pourraient etre reconstruits a l’aide
de trigrammes apparaissant une fois dans le corpus, c’est-a-dire les trigrammes hapax. Nous conﬁrmons ici cette
hypothese.

Nous effectuons une nouvelle serie d’expériences aﬁn d’obtenir les effectifs des trigrammes en relation d’analogie
avec les trigrammes inconnus. En raison de la lourdeur des calculs, nous nous limitons a l’analyse du patron 1 :
a b c : a b d :: e f c : e f d. Pour chaque instance de ce patron, nous deﬁnissons son eﬂectzf maximum comme
l’effectif du trigramme le plus frequent parmi les quatre trigrammes de l’analogie (comme le premier trigramme
est inconnu, son effectif dans le corpus d’entrainement est évidemment zero). Pour chaque trigramme inconnu
reconstruit, nous memorisons le minimum sur les effectifs maximums de toutes les analogies permettant de le
reconstruire (effectif min—max). De cette mémorisation, et par inversion, pour chaque effectif min—max, nous
pouvons compter le nombre de trigrammes inconnus reconstr11its. Chaque effectif min-max est donc l’effectif
sufﬁsant a considerer pour trouver a coup sur des trigrammes permettant la reconstruction de tant de trigrammes
1I1COI1I11lS.

Ces décomptes sont donnes dans la table 4. Pour chaque eﬂectzf min—max, la table presente la quantite de tri-
grammes reconstruits et un pourcentage cumule. Selon ces resultats, les instances d’analogie du patron 1 impli-
quant trois trigrammes hapax (effectif min—max = 1) permettent la reconstruction de plus de 95 % des trigrammes
inconnus en anglais, 94 % en frangais ou en allemand et 91 % en ﬁnnois.

TABLE 4 — Pourcentages cumulés des trigrammes reconstr11its, classes par effectif sufﬁsant des trigrammes for-
mant analogie pour leur reconstruction (colonne eﬁ’ecttfmin-max).

(a) Anglais (b) Francais
Eﬂectif Trigrammes Pourcentage Eﬂectif Trigrammes Pourcentage
min-max reconstruits cumule min—max reconstruits cumulé

1 54 227 (96,24 %) 96,24 % 1 59 050 (94,07 %) 94,07 %

2 1288 (2,29 %) 98,53 % 2 2167 (3,45 %) 97,52 %

3 345 (0,61%) 99,14 % 3 608 (0,97 %) 98,49 %

4 127 (0,23 %) 99,36 % 4 302 (0,48 %) 98,97 %

5 99 (0,18 %) 99,54 % 5 167 (0,26 %) 99,24 %

523 1 (0,00 %) 100,00 % 576 1 (0,00 %) 100,00 %

TOTAL 56 345 (100,00 %) — TOTAL 62 771 (100,00 %) —
(c) Allemand (d) Finnois
Eﬂectif Trigrammes Pourcentage Eﬂectif Trigrammes Pourcentage
min-max reconstruits cumule min—max reconstruits cumulé

1 41272 (94,01%) 94,01 % 1 13 382 (91,02 %) 91,02 %

2 1475 (3,36 %) 97,36 % 2 760 (5,217 %) 96,18 %

3 465 (1,06 %) 98,42 % 3 238 (1,62 %) 97,80 %

4 219 (0,50 %) 98,92 % 4 101 (0,68 %) 98,49 %

5 124 (0,28 %) 99,21 % 5 56 (0,38 %) 98,87 %

412 1 (0,00 %) 100,00 % 458 1 (0,01%) 100,00 %

TOTAL 43 904 (100,00 %) — TOTAL 56 542 (100,00 %) —

L’ ensemble des résultats expérimentaux precedents conduit a la conclusion que non seulement les analogies er1tre
trigrammes structurent les trigrammes inconnus, mais qu’en plus, la reconstruction des trigrammes inconnus est
massivement possible avec des trigrammes d’effectif semblable, c’est—a—dire d’effectif 1.

Pour résumer l’etude empirique presentee ci—dessus, on peut donc dire que : dans leur grande majorite’ les tri-
grammes inconnus sont analogues aux trigrammes hapax ; leurs structures et leurs eﬂectzfs sont semblables.

STRUCTURE DES TRIGRAMMES INCONNUS ET LISSAGE PAR ANALOGIE
3 Lissage de modéles trigrammes par analogie

Dans cette deuxieme partie, nous allons exploiter les résultats de l’étude empirique précédente pour proposer une
technique de lissage de modeles de langue. Notre proposition est Volontairement simple et s’inspire de méthodes
de lissage élémentaires : les lissages de Lidstone et de Laplace.

Habituellement, lorsqu’on utilise directement des outils tels que SRILM (Stolcke, 2002), on a l’habitude d’utiliser
les techniques de lissage classiques connues pour donner des résultats acceptables. Des techniques de lissage
plus elaborées ont eté proposées aﬁn de reduire la taille des modeles de langue, nous pensons en particulier au
clustering (Brown et al., 1992). Cependant, de telles techniques requierent une phase de pré-traitement complexe,
ce qui accroit le coﬁt de calcul (Matsuzaki et al., 2003). En comparaison, la methode que nous proposons dans cet
article n’extrait pas de connaissances supplementaires des données d’ entrainement. La structure des trigrammes
inconnus est Vériﬁée au ﬁl du calcul. Les principaux avantages de cette methode sont sa simplicité et sa facilité
d’utilisation.

3.1 Ré-estimation des effectifs

Redisons une Vérité élémentaire : tout evenement inconnu apparaissant dans le jeu de test a un effectif nul dans
le corpus d’entrainement. Immediatement au—dessus de la classe des evenements d’effectif nul, Vient la classe des
évenements observes une seule fois dans le corpus d’entrainement : ce sont les hapax. Or, il est classique pour
une technique de lissage d’essayer d’esti1ner la probabilité lissée des évenements inconnus en se basant sur les
propriétés des événements classes selon leurs frequences d’apparition : c’est la base du lissage de Good-Turing
(Gale, 1994). Nous exploitons la meme idée mais dans une mise en application plus simple.

Dans le lissage de Laplace, tout évenement Voit son effectif augmenté de 1. Dans notre technique de lissage, nous
gardons cet increment de 1 pour les événements connus. L’ essence de notre technique de lissage tient dans la
distinction faite entre évenements inconnus selon qu’ils peuvent etre reconstruits par analogie ou non.

Nous donnons un fort avantage aux évenements inconnus qui peuvent etre reconstruits par analogie au detriment
de ceux qui ne peuvent pas l’etre. Les resultats des experiences presentées en section 2.4 conduisent a proposer
un effectif tres proche de 1 pour les trigrammes reconstructibles puisqu’ils sont analogues aux trigrammes hapax
Nous ﬁxons leur effectif a 1 — ct avec ct proche de 0. Ils deviennent donc de nouveaux quasi—hapax, alors que les
anciens hapax sont re-estimés avec un effectif de 1 + 1 = 2.

En désespoir de cause, nous affectons comme estimation des effectifs des trigrammes inconnus qui ne peuvent
pas etre reconstruits une Valeur tres proche de 0. Pour simpliﬁer, nous utilisons la Valeur 04. On peut dire que cette
partie du lissage est en fait un lissage de Lidstone.

Au total donc, la probabilité lissée d’un trigramme h,-.m,- (hi represente les deux mots précedant m,-) est re-
estimée selon chacun des trois cas suivants, avec N la longueur du texte, |V| la taille du Vocabulaire et 6 restant a
determiner :

— trigrammes connus ' ¥(hi.mi) + 1
N + 6 x |V| 1
. . . . — Cl!
— trigrammes 1nconnus pouvant etre reconstru1ts ar analo 1e : T
P g N + 5 x |V|
— trigrammes inconnus ne pouvant etre reconstr11its ar analo ie 3 : T
P g N + 5 x |V|

En reprenant les notations de la section 2.1 et de la table 1, nous notons A la proportion de trigrammes inconnus
différents et ,u la proportion relative de trigrammes inconnus différents reconstr11its par analogie. Les Valeurs de A
et ,u sont comprises e11tre 0 et 1. Avec ces notations :

— (1 — A) est la proportion de trigrammes connus dans le jeu detest, A étant la proportion de trigrammes inconnus
dans le jeu detest;

— ,uA est la proportion, sur l’ensemble du jeu detest, de trigrammes inconnus qui peuvent etre reconstr11its, /1 etant
la proportion de trigrammes inconnus reconstructibles ;

3. Cast en particulier le cas de tout trigramme contenant un mot inconnu. Un tel trigramme ne peut en effet étre reconstruit par analogie
dc par la déﬁnition donnée en introduction (test sur le nombre d’ occurrences des mots).

JULIEN GOSME ET YVES LEPAGE

— et (1 — /1))‘ est le reste sur l’ensemble des trigrammes du jeu de test, c’est—a—dire la proportion de trigrammes
inconnus ne pouvant etre reconstruits par analogie.

La somme des probabilites de tous les trigrammes devant faire 1, la Valeur de 6 peut etre detenninée :

6 = (1—)\)><1 + ,u)\><(1—o4) + (1—,u))\><o4
= 1—(2C\4/.L—C\4—/.t+1))\

3.2 Estimation des paramétres

Dans la pratique, les parametres A et ,u sont estimés dans une phase de pré-traitement. Le corpus d’entrainement
est divisé en deux parties, l’une comprenant les neuf dixiemes du corpus, l’autre comprenant le dixieme restant. La
proportion de trigrammes inconnus dans la plus petite partie ainsi que la part de trigrammes inconnus reconstruits
par analogie sont estimées par échantillonnage. Ces estimations deviennent les Valeurs des parametres A et ,u.

Concemant le parametre oz, des resultats d’expériences non presentés dans cet article nous ont conduits ale ﬁxer
a 10‘6 pour toutes les langues.

3.3 Temps d’exécution

Aﬁn de determiner si un trigramme inconnu peut etre reconstruit ou non par analogie, le corpus d’entrainement est
memorise sous forme de deux tableaux de sufﬁxes (sens de lecture normal et miroir). Lorsque la reconstruction
d’ un trigramme doit etre testée, pour chaque patron d’analogie, une recherche appropriee a ce patron est effectuée
dans ces tableaux de sufﬁxes. Par exemple, pour le patron 1, le trigramme candidat a b c est decompose en une
partie gauche a 17 et une partie droite c. La recherche de ces sequences dans les tableaux de sufﬁxes réduit aux
trigrammes hapax est tres rapide. I1 sufﬁt alors de prendre l’intersection en termes de positions de l’ensemble des
unigrammes d qui suivent a b (sens de lecture normal) et de l’ensemble des bigrammes e f qui precedent c (miroir).
Des qu’une position est trouvee dans l’intersection, nous en deduisons qu’il existe au moins un trigramme e f d
dans le corpus d’entrainement et nous pouvons conclure en l’existence d’une analogie a b c : a b d :: e f c : e f d.
Cela signiﬁe que le trigramme a b c peut etre reconstruit par analogie a l’aide de trigrammes du corpus d’ entrai-
nement. Une procedure similaire a ete implantee pour le patron 2.

L’i1nplantation des lissages classiques de SRILM permet de lisser environ 1000 phrases par seconde en frangais
quelle que soit la methode de lissage et quelle que soit la taille du corpus d’entrainement sur une machine equipée
d’un processeur 16 bits cadence a 2 GHz et ayant 4 Go de mémoire.

Notre méthode de lissage effectue des recherches dans des tableaux de sufﬁxes et nous nous attendons a ce que la
Vitesse de lissage depende de la taille du corpus d’entrainement. Sur le meme type de machine, nous mesurons la
Vitesse de notre methode de lissage en fonction de la taille du corpus d’entrainement pour deux Variantes : patron 1
seul et patrons 1 et 2. Nous utilisons des échantillons de la partie frangaise d’Europarl avec des tailles Variant de
900 a 320000 phrases. Dans la seconde Variante, le patron 2 est utilise en deuxieme instance dans la cas ou le
patron 1 n’a pas pennis de reconstruire le trigramme.

Les courbes de la ﬁgure 3 donnent le nombre de phrases du jeu de test traitées par seconde en fonction de la
taille du corpus d’entrainement. La Vitesse de lissage de notre methode depend nettement de la taille du corpus
d’ entrainement. Pour de petits corpus, notre implantation traite 300 phrases par seconde. Cette Vitesse chute a 100
phrases par seconde pour les corpus de plus grande taille et n’eVolue plus Vraiment a partir de 180 000 phrases.
Les deux Variantes sont similaires, ce qui signiﬁe que la Variante patrons 1 et 2 n’engendre qu’un faible surcoﬁt
de temps de traitement.

L’i1nplantation actuelle de notre méthode de lissage par analogie, en Python, est donc dix fois plus lente que les
implantations de SRILM en C++ des methodes classiques de lissage. On peut raisonnablement espérer des temps
comparables avec une implantation en C++ si l’on se ﬁe aux regles tres grossieres donnant des accelerations par
dix lors de réécritures de Python en C++. 4

4. http : //shootout . alioth . debian . org/u32q/benchmark .php?test=all&lang=gpp&lang2=python

STRUCTURE DES TRIGRAMMES INCONNUS ET LISSAGE PAR ANALOGIE

 

350 I I I I I I

_g . patron 1 - - - - - -

§ 300 _ patrons 1 et2 T _
3 .

3; 250 —
\§

-‘§ 200 -
t!

g 150 —
E

m

_g 100 -
D . . . . . . . . . . . . . . . . . . . . . . . . .

33

E 50 - -
o

Z

0 I I I I I I
0 50000 100000 150000 200000 250000 300000 350000

Taille du corpus d’ entrainement

FIGURE 3 — Vitesse de la méthode de lissage par analogie pour différentes tailles du corpus d’entrainement, pour
deux variantes de la méthode : patron 1 et patrons 1 et 2.

3.4 Evaluation des performances

Nous comparons notre méthode de lissage par analogie avec quatre méthodes de lissage classiques : Lidstone
(Chen & Goodman, 1999), Witten & Bell (1991), Good-Turing (Gale, 1994) et Kneser & Ney (1995). Cette der-
niere méthode est souvent considérée comme la meilleure en pratique. 5 Pour ces quatre méthodes, nous utilisons
les implantations de SRILM (Stolcke, 2002). Dans le cas du lissage de Lidstone, apres optimisation, nous utilisons
la valeur 10‘3 pour le parametre oz pour chaque langue.

Les criteres d’ evaluation utilisés sont la divergence de Kullback—Leibler et la perplexité en mots. La divergence de

Kullback—Leibler est déﬁnie pour chaque phrase par :
l

— entropie dujeu detest : H(p) = — :p(m,-|h,-) >< log2p(m,-|h,-) ;

72:1 I
— entropie d’un modele de langue : H (p, q) = — Z p(m,-|h,~) >< log2q(m,~|h,~) ;
— divergence de Kullback-Leibler : i=1 DKL = H (p q) — H

La perplexité en mots est déﬁnie comme la moyenne géométrique des inverses des probabilités réestimées. En
- E7-":110g21J(m.'|h,')
TB

 

notant n le nombre de mots du jeu detest : PPL = 2

Dans ces formules, p(m,-|h,-) est la probabilité conditionnelle obtenue sur le jeu de test, avec mi le mot a la
position 1' et hi son histoire, c’est—a—dire les deux mots précédant mi ; q(m,-|h,-) est la probabilité conditionnelle
lissée utilisant le corpus d’ entrainement et l est la longueur de la phrase du jeu detest.

La comparaison est effectuée sur des données extraites d’Europarl en onze langues. Pour chaque langue, les
phrases ayant une traduction en anglais sont retenues. Nous obtenons de cette maniere onze corpus alignés de
383 237 phrases représentant 10 millions de mots ou plus dans chaque langue, sauf en ﬁnnois (seulement 8 mil-
lions). Chaque corpus est ensuite divisé en deux parties : 90 % du corpus pour l’entrainement, les 10 % restants
servant de jeu de test. De cette maniere, nos experiences sont véritablement comparables e11tre langues. Les sta-
tistiques concemant le corpus d’entrainement et le jeu de test pour chaque langue sont présentées dans la table 5.

Les estimations des parametres A et /.I nécessaires a notre méthode de lissage sont détaillées dans la table 6.

5. « Kneser & Ney (1995) smoothing and its variants are generally recognized as having the best perplexity of any known method for esti-
mating N-gram language models. » (Moore & Quirk, 2009). (Chen & Goodman, 1998) ont montré qu’une premiere version modiﬁée du lissage
de Kneser-Ney « consistently had the best performance » sur l’ensemble de leurs tests et qu’une seconde version modiﬁée « [p]erfor1n[ed] just
slightly worse ».

JULIEN G0sME ET YVEs LEPAGE

TABLE 5 — Statistiques des corpus d’entrainement et des jeux de tests utilises pour la comparaison.

Corpus d’entrainement : 347 613 phrases J eux detest : 38 624 phrases
      

da 9,46 153 425 27,21 1,06 46117 27,36
de 9,51 167 942 27,36 1,06 51398 27,48
e1 10,00 149 247 28,76 1,12 52 671 28,89
en 9,94 67 819 28,60 1,11 25 854 28,76
es 10,47 100410 30,12 1,17 37128 30,27
ﬁ 7,18 299 116 20,65 0,80 84 964 20,74
fr 10,95 86 567 31,51 1,22 33 403 31,65
it 9,88 99 252 28,42 1,10 36 624 28,54
n1 10,01 125 565 28,80 1,12 39 728 29,00
pt 10,29 102 800 29,59 1,15 38 041 29,73
sv 8,99 157116 25,86 1,00 48 327 25,98

TABLE 6 — Proportion de trigrammes inconnus différents (A) et proportion de trigrarnmes inconnus différents
reconstructibles par analogie (/.1) estimees a partir d’un echantillon de 10 % du corpus d’entrainement pour chaque
langue, etVa1eurs correspondantes de 6 (04 = 10‘6). Lors du ca1cu1de 6, les Valeurs de A et /.1 sont rarnenees entre
0 et 1.

Trigrammes inconnus différents
Reconstr11its
Ox) (M) (5)
Patron 1 Patrons 1 et 2 Patron 1 Patrons 1 et 2
da 55,03 % 45,84 % 70,22 % 0,702 0,836
de 61,41 % 43,24 % 69,43 % 0,651 0,812
e1 59,57 % 42,98 % 69,29 % 0,660 0,817
en 51,97 % 55,72 % 79,72 % 0,770 0,895
es 48,96 % 50,34 % 73,45 % 0,757 0,870
ﬁ 78,24 % 26,68 % 49,25 % 0,426 0,603
fr 49,13 % 53,40 % 79,19 % 0,771 0,898
it 58,88 % 49,82 % 75,27 % 0,705 0,854
n1 54,56 % 52,00 % 75,94 % 0,738 0,869
pt 54,72 % 47,46 % 72,84 % 0,713 0,851
sv 60,18 % 47,25 % 71,28 % 0,683 0,827

TABLE 7 — Comparaison de la technique de lissage par analogie (patron 1 et patrons 1 et 2) avec quatre techniques
de lissage classiques en onze langues.
Perplexités en mots

da de el en es ﬁ fr it n1 pt sv
Patron 1 197,5 401,5 226,9 125,6 144,5 10099,8 106,0 149,0 181,0 141,6 334,6
Lidstone 171,0 247,1 179,3 107,4 107,6 1135,9 84,5 141,0 162,1 125,6 235,3

Witten-Bell 130,1 192,0 139,5 93,2 91,9 828,3 73,7 119,9 132,3 106,2 180,0
Good—Turing 128,9 189,2 138,1 92,6 91,0 784,6 73,3 119,1 131,0 105,3 177,7
Kneser—Ney 134,7 196,3 158,3 95,6 92,0 824,3 74,6 120,1 137,3 106,9 186,4

Patron 1 et2 107,8 182,4 116,4 90,9 85,8 2876,6 73,7 81,0 99,2 79,7 152,6

Divergences de Ku11back—Leib1er

Patron 1 61,2 73,1 73,5 52,2 56,7 121,9 55,8 68,8 62,9 62,3 70,3

Lidstone 54,2 66,3 63,2 44,2 47,9 95,7 45,0 56,7 54,8 53,0 60,6
Witten—Be11 47,0 60,0 56,2 40,6 43,4 89,0 41,0 52,5 49,4 48,4 54,1
Good—Turing 46,5 59,3 55,7 40,0 42,9 87,6 40,5 52,0 48,8 47,8 53,5
Kneser—Ney 46,4 58,8 55,9 40,2 43,0 87,2 40,4 51,9 48,8 47,8 53,5

Patron 1 et2 43,5 50,2 51,8 38,7 41,5 105,7 41,2 48,5 44,8 44,3 48,4

STRUCTURE DES TRIGRAMMES INCONNUS ET LISSAGE PAR ANALOGIE

Nous rappelons que A est la proportion de trigrammes inconnus différents et que ,u est la proportion relative de
trigrammes inconnus différents qui peuvent etre reconstruits par analogie. Nous considérons deux Variantes de
notre méthode : la premiere n’utilise que le patron 1, la seconde utilise les patrons 1 et 2. Aﬁn de rendre la tech-
nique de lissage independante du jeu detest, pour chaque langue les estimations des parametres ont été obtenues
automatiquement a partir d’ un échantillon aleatoire forme d’un djxieme du corpus d’ entrainement comme decrit
dans la section 3.2. Comme le montrent les chiffres de la table 6, l’uti1isation du patron 2 en plus du patron 1
augmente sensiblement la valeur du parametre ,u : plus d’un quart en valeurs absolues. A l’exception du ﬁnnois,
l’utilisation conjointe des patrons 1 et 2 permet la reconstruction de 70 % a 80 % des trigrammes inconnus. Les
valeurs pour le ﬁnnois, en gras dans la table, sont nettement differentes des valeurs pour les autres langues.

Les resultats de l’évaluation des deux variantes de la méthode proposée sont présentes dans la table 7 :
— le patron 1 seul est insufﬁsant pour atteindre meme le niveau du lissage de Lidstone. On obtient systématique-
ment les plus mauvais resultats dans les onze langues;
— a l’exception du ﬁnnois, et dans une moindre mesure du frangais, l’ajout du patron 2 est sufﬁsant pour obtenir
des resultats bien meilleurs que ceux des quatre methodes de lissage classiques.
La contre—perfor1nance sur le ﬁnnois n’est pas surprenante si l’on considere le nombre important de trigrammes
inconnus et la faible proportion de ces trigrammes qui peuvent etre reconstruits par analogie (voir table 6). Aﬁn
de remedier a ce probleme, plutot que d’accroitre la quantite de données d’entrainement, il serait sans doute plus
judicieux de segmenter les mots en morphemes. Quant aux résultats en frangais, ils sont comparables a ceux des
methodes classiques.

4 Conclusion et perspectives

Dans cet article, a l’aide d’une serie d’experiences sur quatre langues, nous avons montré qu’en majorite les
trigrammes inconnus dans un jeu detest sont structurellement analogues aux trigrammes hapax d’un corpus d’en—
trainement.

De cette propriété, nous avons derive une methode de lissage pour modeles de langue trigrammes. L’ effectif
des trigrammes connus est ré—estimé en appliquant un increment de 1 come dans le lissage de Laplace. Les
trigrammes inconnus qui peuvent etre reconstruits par analogie sont consideres comme quasi—hapax : leurs effectifs
sont re-estimés a une valeur proche de 1. Les trigrammes inconnus qui ne peuvent etre reconstruits par analogie
sont presque ignores, leurs effectifs etant ﬁxes a une valeur proche de 0 come dans le lissage de Lidstone. En
comparaison de techniques de lissage utilisant des techniques de clustering, cette methode est simple; elle ne
construit que deux classes de trigrammes inconnus : ceux qui peuvent etre reconstruits et les autres.

Des mesures sur onze langues ont montré que cette méthode de lissage donne de bons resultats en comparaison
des techniques de lissage classiques, sauf dans le cas du ﬁnnois.

L’ etude présentée ici laisse un certain nombre de points a examiner. Tout d’ abord, cette etude a eté consacrée
aux trigrammes. Or, aujourd’hui, dans de nombreux domaines du traitement automatique des langues, comme
par exemple la traduction automatique par approche statistique, on utilise des modeles de langue 5—gra1nmes.
Des experiences restent donc a effectuer avec des n—gra1nmes d’ordres supérieurs pour savoir si de bons resultats
peuvent aussi etre obtenus. L’inﬂuence du nombre de patrons d’ analogie sur l’entropie des modeles de langue
obtenus reste elle aussi a etudier. Un autre point porte sur la taille des corpus utilises. Les experiences rapportées
ici visant a une comparaison sur plusieurs langues et les tres grands corpus multilingues etant rares, la taille du
corpus utilise ici est relativement faible en regard de corpus monolingues dépassant le milliard de mots. Des
experiences sur des corpus de tailles plus importantes restent donc a effectuer. Enﬁn, dans la perspective d’une
integration a la traduction automatique par approche statistique, les pouvoirs discriminants de la technique de
lissage proposee ici restent a examiner.

5 Remerciements

Cet article décrit des resultats de recherche obtenus en partie grace une subvention de l’université Waseda pour
projets de recherche spéciﬁques (proj et numero : 2010A—906).

JULIEN GOSME ET YvEs LEPAGE

Références

BROWN P., PIETRA V., DESOUZA P., LAI J. & MERCER R. (1992). Class—based n-gram models of natural
language. Computational linguistics, 18(4), 467-479.

CHEN S. F. & GOODMAN J. (1998). An empirical study of smoothing techniques for language modeling.
Rapport inteme, Harvard university, Cambridge, Massachussetts.

CHEN S. F. & GOODMAN J. (1999). An empirical study of smoothing techniques for language modeling.
Computer Speech and language, 13(4), 359-394.

CLAVEAU V. & L’HOMME M.—C. (2005). Terminology by analogy—based machine learning. In Proceedings of
the 7th International Conference on Terminology and Knowledge Engineering, TKE 2005, Copenhagen.
DENOUAL E. (2007). Analogical translation of unknown words in a statistical machine translation framework.
In Proceedings of Machine Translation Summit XI, Copenhagen.

GALE W. (1994). Good—turing smoothing without tears. Journal of Quantitative Linguistics, 2.

GOSME J. & LEPAGE Y. (2009). A ﬁrst study of the complete enumeration of all analogies contained in a text.
In 4th language and Technology Conference (LTC 2009), p. 401-405, Poznan, Poland.

HATHOUT N. (2009). Acquisition morphologique a partir d’un dictionnaire informatisé. In T. NAZARENKO, D.
ET POIBEAU, Ed., Actes de la I 6e Confe’rence Annuelle sur le Traitement Automatique des langues Naturelles
(TALN—2009), p. 10 p. : ATALA.

KNESER R. & NEY H. (1995). Improved backing—off for m—gram language modeling. In Acoustics, Speech, and
Signal Processing, 1995. ICASSP-95., 1995 International Conference on, volume 1.

KOEHN P. (2005). Europarl : A Parallel Corpus for Statistical Machine Translation. In Proceedings of the tenth
Machine Translation Summit (MT Summit X ), p. 79-86, Phuket.

LANGLAIS P. & PATRY A. (2007). Translating unknown words by analogical learning. In Proceedings of
the 2007 Joint Conference on Empirical Methods in Natural language Processing and Computational Natural
language learning (EMNLP—CoNLL), p. 877-886.

LANGLAIS P., YVON F. & ZWEIGENBAUM P. (2008). Analogical Translation of Medical Words in Diﬂerent
languages, volume 5221/2008 of lecture Notes in Computer Science, p. 284-295. Springer Berlin / Heidelberg :
Springer Berlin / Heidelberg.

LAVALLEE J. F. & LANGLAIS P. (2010). Analyse morphologique non supervisée par analogie formelle. In
TALN 2010, p. 10 pages, Montreal, Quebec, Canada.

LEPAGE Y. (2004). Analogy and formal languages. Electronic notes in theoretical computer science, 53, 180-
191.

LEPAGE Y. & DENOUAL E. (2005). Purest ever exa1nple—based machine translation : detailed presentation and
assessment. Machine Translation, 19, 251-282.

LEVENSHTEIN V. (1966). Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics
Doklady, 10(8), 707-710.

MATSUZAKI T., MIYAO Y. & TSUJII J. (2003). An efﬁcient clustering algorithm for class—based language
models. In Proceedings of the seventh conference on Natural language learning at HLT—NAACL, volume 4, p.
119-126 : Association for Computational Linguistics.

MOORE R. & QUIRK C. (2009). Improved smoothing for N—gram language models based on ordinary counts.
In Proceedings of the ACL—IJCNLP 2009 Conference Short Papers, p. 349-352 : Association for Computational
Linguistics.

ROSENFELD R. (2000). Two decades of statistical language modelling : where do we go from here ? Proceedings
of the IEEE, 88(8), 1270-1278.

STOLCKE A. (2002). SRILM—an extensible language modeling toolkit. In Seventh International Conference on
Spoken language Processing, volume 3, p. 901-904.

TURNEY P. (2008). A uniform approach to analogies, synonyms, antonyms, and associations. In Proceedings of
the 22nd International Conference on Computational Linguistics (Coling 2008), p. 905-912, Manchester, UK :
Coling 2008 Organizing Committee.

WITTEN I. & BELL T. (1991). The zero—frequency problem : Estimating the probabilities of novel events in
adaptive text compression. Information Theory, IEEE Transactions on, 37(4), 1085-1094.

