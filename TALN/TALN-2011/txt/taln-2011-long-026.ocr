TALN 2011, Montpellier, 27juin — 1"'ju1'11et 2011

Modéles génératif et discriminant en analyse syntaxique :
expériences sur le corpus arboré de Paris 7

Joseph Le Roux Benoit Favre Seyed Abolghasem Mirroshandel Alexis Nasr
LIF - CNRS UMR 6166 - Université Aix Marseille
{joseph.le-roux, benoit.favre, alexis.nasr} @lif.univ-mrs.fr

Résumé. Nous présentons une architecture pour l’analyse syntaxique en deux étapes. Dans un premier
temps un analyseur syntagmatique constr11it, pour chaque phrase, une liste d’ analyses qui sont converties en arbres
de dépendances. Ces arbres sont ensuite réévalués par un réordonnanceur discriminant. Cette méthode permet de
prendre en compte des informations auxquelles l’analyseur n’a pas acces, en particulier des annotations fonction—
nelles. Nous validons notre approche par une evaluation sur le corpus arboré de Paris 7. La seconde étape permet
d’améliorer signiﬁcativement la qualité des analyses retoumées, quelle que soit la métrique utilisée.

Abstract. We present an architecture for parsing in two steps. First, a phrase—structure parser builds for
each sentence an n—best list of analyses which are converted to dependency trees. Then these trees are rescored by
a discriminative reranker. This method enables the incorporation of additional linguistic information, more preci-
sely functional annotations. We test our approach on the French Treebank. The evaluation shows a signiﬁcative
improvement on different parse metrics.

M0tS-CléS 3 analyse syntaxique, corpus arboré, apprentissage automatique, réordonnancement discri1ni—
nant.

Keywords: parsing, treebank, machine learning, discriminative reranking.

LE ROUX, FAVRE, MIRROSHANDEL, NASR

1 Introduction

On peut observer l’existence de deux approches en analyse syntaxique automatique. La premiere, dite generative,
se fonde sur la tradition des langages formels et des systemes de reécriture. L’ analyse syntaxique est envisagee ici
comme un processus permettant de passer d’une structure initiale (une chaine d’entree) a une structure ﬁnale (un
arbre ou une foret d’analyses). On utilise le plus couramment les grammaires algebriques qui peuvent s’analyser
en temps polynomial. Malheureusement, l’hypothese d’indépendance des réécritures qui sous—tend ce formalisme
ne permet pas une analyse tres ﬁne de certains phénomenes, en particulier les dépendances a longue distance et
les dépendances lexicales.

La seconde approche, dite discriminante, se fonde sur la << syntaxe comme théorie des modeles » (en anglais
model—theoretic syntax, (Pullum & Scholz, 2001)) eta connu un regain d’interet grace aux progres realises dans le
domaine de l’apprentissage automatique, plus précisément en classiﬁcation automatique. Dans cette approche, la
grammaire est vue comme un systeme de contraintes sur les structures syntaxiques correctes. Les mots de la phrase
d’entree sont eux—memes vus comme des contraintes sur les positions qu’ils occupent et l’analyse syntaxique
revient a résoudre ces contraintes. Le probleme majeur de cette seconde approche tient a sa complexite. Les
contraintes pouvant en théorie porter sur divers aspects des structures ﬁnales, il n’est pas possible d’utiliser des
techniques de programmation dynamique efﬁcaces et il faut, dans le pire des cas, enumerer tous les arbres pour
ensuite evaluer leur pertinence. Dans certains developpements de cette approche, utilises dans le present travail,
les contraintes sont uniquement d’ordre numérique. Une analyse y est representée par un vecteur de traits et sa
qualite se mesure par la distance entre ce demier et l’analyse de reference.

Une maniere de tirer proﬁt des deux approches consiste, comme l’a propose (Collins, 2000), a les combiner de
fagon séquentielle. Un analyseur de type genératif produit alors un ensemble de structures candidates pour un
second module, discriminant, de fagon a contraindre son espace de recherche. Cette approche par analyse puis
réordonnancement (en anglais, parsing/reranking) est utilisee dans l’analyseur de Brown (Chamiak & Johnson,
2005), adapté pour le frangais dans (Seddah et al., 2009). Il est meme intéressant de foumir au module de reordon—
nancement des analyses provenant de différents analyseurs, comme le montrent les resultats obtenus par (Johnson
& Ural, 2010).

Notre architecture, représentée sur la ﬁgure 1, reprend ces deux étapes. Lors de la premiere etape, un analyseur
syntagmatique traite chaque phrase d’ entree et produit la liste des 11 analyses les plus probables munies de leur pro-
babilité. Elles sont ensuite annotées par un étiqueteur fonctionnel avec des fonctions syntaxiques classiques sujet,
objet, objet indirect. . . Les analyses syntagmatiques enrichies d’annotations fonctionnelles sont alors converties
en structures de dépendances. A l’issue de cette conversion, on dispose donc de candidats qui sont des struc-
tures de dépendances munies du score donne par le premier analyseur. Cette etape est realisée par un analyseur
syntagmatique PCFG—LA (Petrov et al., 2006) couple a l’étiqueteur et au convertisseur BONSAI 1.

Chaque structure de dépendances munie d’un score est ensuite traduite en un vecteur de traits. Ces traits repre-
sentent des conﬁgurations structurelles qui peuvent etre absentes ou presentes dans l’arbre de dépendances et le
vecteur indique leur nombre d’occurrences pour ce candidat. Le score attribué par l’analyseur syntagmatique est
lui—meme vu comme un trait. Les différents candidats sont ﬁnalement evalués par le réordonnanceur et le systeme
retoume le meilleur candidat. Ce module est realise par notre implantation de l’algorithme MIRA (Crammer et al.,
2006)

ll nous parait important de revenir ici sur deux aspects de notre architecture. Le premier est la realisation de l’ etape
de reordonnancement sur des structures de dépendances et non pas sur des structures syntagmatiques, a l’image
de (Chamiak & Johnson, 2005). Notre analyseur produisant des structures syntagmatiques, il aurait en effet eté
plus naturel de realiser le réordonnancement sur des structures syntagmatiques et de s’epargner ainsi leur conver-
sion en structures de dependances. Deux raisons sont a l’origine de ce choix. D’une part, il nous a semble que de
nombreuses contraintes se modélisent plus naturellement sous la forme de structures de dépendances que sous la
forme de structures syntagmatiques. On pense en particulier a des contraintes sur les cadres de sous-categorisation
ou a des contraintes de selection, qui font explicitement appel a la notion de fonction syntaxique. D’autre part, un
certain nombre de travaux recents en analyse syntaxique (McDonald, 2006; Nivre et al., 2007) reposent sur les
structures de dépendances et il nous a semblé intéressant de proposer un systeme de reordonnancement pour ce
type d’analyses.

l. disponibles sur le site http : //alpage . inria . fr/statgram/frdep/fr_stat_dep_parsing. html.

MODELES GENERATIF ET DISCRIMINANT EN ANALYSE SYNTAXIQUE

La raison pour laquelle nous n’avons pas utilise directement un analyseur en dependances, qui aurait eté sans
doute un choix plus naturel, est qu’il n’existe pas a notre connaissance d’analyseur en dependances qui genere les
11 analyses les plus probables. Les analyseurs de (McDonald, 2006), ou de (Nivre et al., 2007), par exemple, ne
permettent pas de les produire, meme si le premier peut les approximer. C’est donc une raison pragmatique qui
nous a poussés a faire ce choix. Enﬁn, il etait interessant de veriﬁer si, comme pour l’anglais, les structures de
dépendances obtenues par conversions de structures syntagmatiques sont de meilleure qualite que celles renvoyees
par les analyseurs en dépendances directement.

Le reordonnanceur propose dans ce travail, qui sera decrit en detail dans la section 3, partage plusieurs de ses
caracteristiques avec l’analyseur de (McDonald, 2006), évoque ci—dessus. Les deux reposent sur l’algorithme
d’ apprentissage MIRA (Crammer et al., 2006) decrit dans la section 3. De plus, les contraintes considérées dans
notre modele sont inspirees de (McDonald, 2006). La diﬁ"érence fondamentale provient du fait que les seules
analyses prises en comptes sont celles produites par le modele génératif (il s’agit d’un réordonnanceur et non d’ un
analyseur). L’ avantage de cette solution par rapport a (McDonald, 2006) est que nous ne sommes pas restreints a
un ensemble de traits locaux. En effet la prise en compte de traits non prevus, de domaine de localité arbitraire,
dans l’algorith1ne de (McDonald, 2006) suppose des modiﬁcations de l’algorithme d’analyse alors qu’ils peuvent
etre ajoutes facilement dans notre modele de réordonnancement.

   

SENT
4/l MOD
11? NP
i]/C1 1e/D fait/N i]/C1 le/D fair/N
MOD
SENT
SUJ
/ --
i]/C1-S le/C1—0 fait/V M . WC! 16/0 faiW
3‘ . \/
Entmée H OBJ
SENT
SUI Analyse de meilleur
$ score
1'1/c1-s 1e/D fait/V i]/C1 le/D fait/V ‘M 69 ’ S°°’°
L/'
MOD
(1) Analyse syntagmatique (2) Conversion (3) Réordonnanoement
+ étiquetage fonctionnel veis dépendances

FIGURE 1 — Architecture de notre analyseur : (1) generation de 11 arbres syntagmatiques armotes en fonctions, (2)
conversion vers une representation en dépendances et extraction de vecteurs de traits, (3) calcul des scores a l’aide
d’ un modele linéaire. L’ analyse de meilleur score est considéree comme l’analyse ﬁnale.

La suite de l’article se presente de la fagon suivante : nous decrivons en 2 les details du modele utilise dans notre
analyseur génératif puis en 3 le modele de réordonnancement discriminant et les patrons de traits utilises. La
section 4 presente les resultats obtenus sur le corpus arbore developpe a l’université Paris 7 (Abeille et al., 2003)
et la section 5 présente les conclusions.

2 Modéle génératif

La premiere partie de notre systeme, l’analyse syntaxique classique, produit des structures en dépendances de
surface grace a un systeme séquentiel, a l’i1nage de (Candito et al., 2009, 2010b). Un analyseur, fondé sur les
PCFG—LA, produit des structures syntagmatiques qui sont ensuite transformées en arbres de dependances. Deux
points nous distinguent des travaux precedents : (1) la liste d’analyses candidates est produite par un nouvel
analyseur et (2) ces analyses ne sont pas considerees comme les structures ﬁnales mais seront traitées dans le
réordonnanceur.

LE ROUX, FAVRE, MIRROSHANDEL, NASR

2.1 Les grammaires algébriques £1 annotations latentes

Les grammaires algebriques probabilistes a armotations latentes (PCFG—LA), introduites par (Matsuzaki et al.,
2005), peuvent etre Vues comme une fagon de specialiser automatiquement le jeu d’etiquettes d’une grammaire
algebrique (PCFG) a partir d’un corpus de maniere a en ameliorer la precision.

Chaque symbole de la grammaire est enrichi d’ armotations se comportant comme des sous—classes de ce symbole,
et les probabilites des regles qui manipulent les symboles augmentes sont estimees par la methode EM d’appren-
tissage non—supervise, a partir des frequences relatives observees sur le corpus. (Petrov et al., 2006) proposent
d’ apprendre ces grammaires en plusieurs rondes : a chaque iteration on divise une annotation d’un symbole en
deux si l’apport des nouvelles armotations augmente la Vraisemblance du corpus d’entrainement. Cette methode
permet d’obtenir une grammaire dans laquelle le nombre d’annotations est adapte au symbole et beaucoup plus
compacte que celles obtenues par (Matsuzaki et al., 2005).

On peut reprendre l’illustration des specialisations d’etiquettes de parties du discours de (Petrov et al., 2006) pour
le frangais. Par exemple l’etiquette DET est divisee en quinze sous—etiquettes apres cinq rondes d’apprentissage.
Nous montrons dans la table 1 les trois mots les plus frequents pour chaque armotation 2. Meme si la specialisation
est difﬁcile a interpreter completement, on note que les articles deﬁnis et indeﬁnis sont separes des demonstratifs
et possessifs d’une part et des cardinaux d’ autre part. 11 est important de noter que cette distinction est apprise par
une methode qui depend largement des parametres d’initialisation et qui ne garantit pas de trouver la specialisation
optimale.

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
1 une la 1’ un les les ses 1e cette son NB deux NB NB NB
la La la son des Les ces Le Cette ce 10 trois 7 40 1

3 La L’ les Un Les de leurs un Ce leur 3 quelques trois 20 30

TABLE 1 — Division du symbole DET en armotations

Dans ce formalisme, le problemes de l’analyse exacte devient NP—djfﬁcile mais (Petrov & Klein, 2007) decrivent
comment l’approximer efﬁcacement, en tirant egalement proﬁt de la structure hierarchique des annotations creees
lors des rondes successives. Une foret d’ analyses est produite avec la PCFG d’origine et est ensuite elaguee avec
les grammaires intermediaires produites lors des rondes successives d’ apprentissage 3, c’est-a-dire qu’on ne garde
qu’un sous—ensemble a priori interessant des analyses, de maniere a restreindre au maximum 1’ espace de recherche
lors du decodage avec la grammaire ﬁnale.

Nous utilisons notre propre analyseur de PCFG—LA 4. La grammaire est apprise en cinq rondes sur le corpus d’en-
trainement : c’est le nombre de rondes optimal sur notre corpus. Pour pouvoir traiter les mots inconnus, les mots
rares sont remplaces par des chaines contenant des informations positionnelles et typographiques, en particulier
leur sufﬁxe. La liste des sufﬁxes intéressants est collectee sur ce corpus en fonction du gain d’information pour
l’etiquetage et permet de mieux traiter les mots inconnus (Attia et al., 2010).

Ce type de grammaire a deja ete utilise pour le frangais a partir du meme corpus (Crabbe & Candito, 2008). 11 a
donne des resultats du niveau de l’etat de l’art en matiere d’analyse en constituants. (Candito & Crabbe, 2009)
montrent que si l’on sait categoriser les mots en classes lexicales (agregats ou clusters), ces grammaires offrent
les meilleures analyses en syntagmes pour le frangais. Nous reprendrons cette classiﬁcation pour nos experiences
(cf. section 4). Cependant, les structures en dependances extraites des meilleures analyses en constituants ne sont
pas aussi bonnes que celles obtenues directement par un analyseur en dependances (Candito et al., 2010b).

2.2 Structures de dependances

Bien qu’une theorie syntaxique puisse se representer a partir de syntagmes et de dependances (Rambow, 2010),
certains types d’informations sont plus ou moins faciles a decrire selon la representation choisie. L’ analyseur gene-
ratif etant appris sur des structures syntagmatiques, il est Vraisemblable qu’une partie de l’information linguistique
lui echappe parce qu’elle est implicite ou difﬁcile a retrouver dans cette representation.

2. Le symbole terminal NB est une chaine générique qui remplace les nombres qui apparaissent peu de fois dans le corpus d’entrainement.
3. En réalité ces grammaires sont recalculées a la volée a partir de la grammaire ﬁnale et de la structure hierarchique des annotations.
4. Cet analyseur est disponible pour les travaux académiques. Les lecteurs intéressés peuvent contacter le premier auteur.

MODELES GENERATIF ET DISCRIMINANT EN ANALYSE SYNTAXIQUE

Cette equivalence n’est de toute fagon Vraie que si les deux representations offrent reellement les memes infor-
mations. Or, comme cela sera décrit dans la section 4, nous avons fait disparaitre les fonctions du corpus d’ap—
prentissage de l’analyseur syntagmatique pour aider lutter a contre l’effet de dispersion des données et améliorer
l’apprentissage des relations de sous—constituance. Mais pour obtenir les relations de dependances typees, il est
necessaire de disposer de l’information fonctionnelle.

Pour passer des structures en constituants aux structures en dépendances, nous utilisons le convertisseur développe
par (Candito et al., 2010a) et disponible dans la boite a outils BONSAI. La conversion se decompose en deux
étapes :
1. Les noeuds internes sont reannotes avec des etiquettes fonctionnelles, en utilisant un classiﬁeur multiclasse
par maximum d’ entropie.
2. Les arbres ainsi decores sont convertis en structures de dépendances par un ensemble de regles de propaga-
tions de tetes fonctionnelles et d’heuristiques.

Cette conversion effectuee, les analyses sont pretes a etre réordonnancees.

3 Modéle discriminant

Le modele discriminant que nous proposons repose sur 1’ algorithme Margin—infused Relaxed Algorithm (MIRA) (Cram-
mer et al., 2006). Selon ce modele, le score d’une analyse est calcule comme la combinaison linéaire des traits
extraits a partir de cette analyse, pondéres par un Vecteur de poids representant les parametres du modele. MIRA,
l’algorithme d’apprentissage des parametres du modele, est tres similaire au Perceptron (Rosenblatt, 1958), et est
donc rapide et peu gourmand en ressources, tout en offrant de meilleures performances.

Le reordonnancement discriminant des analyses se deroule selon deux étapes : apprentissage des parametres du
modele et prediction. L’ etape de prediction consiste a produire les n meilleures analyses du modele génératif,
extraire des traits pour caractériser ces analyses et attribuer un score a chaque analyse en fonction de ses traits
et du modele discriminant. L’analyse de meilleur score est alors selectionnée comme sortie ﬁnale du systeme.
L’ etape d’entrainement consiste a utiliser des exemples de phrases avec leurs analyses de reference (ensemble
d’ apprentissage) pour determiner les parametres du modele. Alors que la plupart des modeles discriminants tentent
de minimiser le taux d’erreur global sur l’ensemble des exemples d’apprentissage, MIRA se contente de traiter les
exemples un par un, ajustant son modele pour que l’analyse selectionnée pour la phrase courante soit celle qui est
la plus proche de l’analyse de reference. Une telle approche, appelée << en ligne », limite les ressources necessaires,
processeur et mémoire, rendant possible l’apprentissage de modeles qui prennent en compte un tres grand nombre
de traits.

3.1 Déﬁnitions

On se place dans un espace Vectoriel de dimension m ou chaque dimension correspond a un trait. Certaines dimen-
sions représentent la presence ou l’absence d’un trait (Valeur booléenne), son nombre d’ occurrence dans l’analyse
(entier naturel), ou une Valeur reelle quelconque (par exemple la probabilité de l’analyse, ou son logarithme, selon
le modele génératif). Une analyse p est alors représentée sous la forme d’un Vecteur de reels <;$(p). Dans le cas
d’un indicateur de presence, la 2'“ coordonnée de <;$(p) Vaut 1 si p possede le 2'“ trait et 0 sinon. Un tel Vecteur
est généralement creux (une analyse ne possede en moyenne qu’une petite partie des djfférents traits possibles).
Un modele est un Vecteur de poids w de dimension m dont la 1'“ coordonnee est le poids associe au 1'“ trait. Plus
ce poids est important, plus le trait correspondant aura ete jugé discriminant. Le score d’une analyse p n’est rien
d’autre que le produit scalaire du Vecteur ¢(p) et du Vecteur w :

score(p) = Zwi >< ¢.-(p) (1)
72:1

Soit L la liste des 12 meilleures analyses produites par l’analyseur syntaxique generatif pour une phrase. On calcule
le score de chaque analyse et l’analyse de score maximum 13 est choisie comme sortie ﬁnale du systeme :

1") = argmax sco1"e(p) (2)
peL

LE ROUX, FAVRE, MIRROSHANDEL, NASR

La phase d’apprentissage consiste a utiliser les phrases d’entrainement et leurs analyses de reference pour deter-
miner le Vecteur de poids w. Le classiﬁeur MIRA commence avec un Vecteur de poids 11ul (c’est—a—dire que toutes
les analyses ont un score de zero), et essaie de modiﬁer ce Vecteur de fagon a ce que les bonnes analyses ait un
score plus élevé que les mauvaises analyses. L’ analyse la plus proche de la reference est nommee oracle (notée 0).
ll serait souhaitable que l’oracle ait le meilleur score parmi les analyses proposee pour une phrase. Soit e1"1"o1"(p)
le nombre de mauvaises dependences (etiquette, position, direction) dans l’analyse p. L’ oracle o est l’analyse pour
laquelle errem"() est minimale.

Les phrases de l’ensemble d’entrainement sont traitées séquentiellement. Pour chacune d’entre elles, on determine
la liste des 11 meilleures analyses candidates, puis l’analyse candidate de meilleur score, notée 13. Si cette analyse
est différente de l’oracle (13 ;é o), cela signiﬁe que le Vecteur de poids w peut etre amélioré. Dans ce cas, on
recherche une modiﬁcation de 11) qui assure que o ait un score plus élevé que l’analyse qui avait le meilleur score.
Plus precisement, on souhaite que la difference entre leurs scores soit proportionnelle a la difference e11tre leur
distance a la reference. Ainsi, une tres mauvaise analyse aura un score bien plus faible qu’une analyse de qualité
moyenne. Trouver une amelioration de w peut etre formulé comme un probleme d’opti1nisation sous la contrainte
que la difference des scores de l’oracle et de l’hypothese de plus haut score soit superieure a la difference e11tre
leurs distances a la reference. Comme il existe une inﬁnite de Vecteurs w satisfaisant cette contrainte, on recherche
celui de plus petite norme. Ce probleme s’écrit sous la forme suivante :

minimiser:  tel que: score(o) — sco1"e(;r3) 2 erro1"(o) — e1"1"o1"(;6) (3)

Des méthodes classiques d’opti1nisation quadratique sous contrainte sont utilisées : tout d’abord la contrainte est
introduite dans la fonction objective grace a des multiplicateurs de Lagrange. De cette fagon, les solutions qui
Violent le plus la contrainte sont penalisées par rapport aux autres solutions. Enﬁn, la méthode de Hildreth donne
la solution analytique suivante au probleme quadratique non contraint :

w* = w + 04 [¢(0) — ¢(I3)] (4)
er1"o1"(o) — e1"1"o1"(f)) — (sco1"e(o) — score(;6)) (5)

||¢(0) — ¢(:5)||2

a=maa: 0,

Ici, w* est le nouveau Vecteur de poids, 04 est un taux de modiﬁcation et [<;$(o) — <;$(f))] est la difference entre le
Vecteur de traits de l’ oracle et celui de l’analyse de plus haut score. Concretement, cette mise a jour attire le Vecteur
de poids en direction de l’oracle et l’éloigne de 13. Cet algorithme d’apprentissage est tres proche de l’algorithme
du perceptron, et tout comme pour le perceptron, il est recommandé (1) de faire de multiples passes sur 1’ ensemble
d’apprentissage et (2) de sauvegarder le Vecteur de poids apres chaque mise a jour et d’en faire la moyenne pour
produire le Vecteur de poids ﬁnal 5. L’ algorithme 1 presente l’apprentissage MIRA.

3.2 Traits utilisés

La qualité d’un réordonnanceur depend de la capacite de l’algorith1ne d’apprentissage a attribuer un bon poids aux
traits discriminants, mais aussi, de maniere cruciale, a la qualité des traits qui lui sont foumis. Ces traits peuvent
porter sur n’i1nporte quelle conﬁguration lexico—syntaxique d’une analyse. L’ ensemble des traits potentiels est par
consequent gigantesque. Pour etre pertinent, un trait doit d’une part etre assez general pour apparaitre souvent et,
d’ autre part, permettre de discriminer les bonnes analyses des mauvaises. Il n’existe pas de methode genérale de
selection des traits pertinents, du fait de leur nombre et de leur caractere non monotone : un trait simple peut se
revéler non pertinent mais l’extension de ce trait simple en un trait plus complexe peut l’etre. L’ espace des traits
est par consequent difﬁcile a explorer systématiquement et la selection des traits pertinents est une activité qui
releve de l’art, pour reprendre un bon mot de (Charniak & Johnson, 2005).

Nous nous sommes inspires de traits utilisés dans l’analyseur (McDonald, 2006) qui a montre de bonnes perfor-
mances dans de nombreuses langues. Ils se divisent en cinq familles, chaque famille correspondant a un type de
conﬁguration. L’instanciation de ces patrons sur les sorties de l’analyseur a généré plus de 70 millions de traits.
Nous decrivons ci-dessous les cinq familles de traits que nous illustrons sur la phrase Les enfants mangent des
glaces avec appétit dans laquelle on s’intéressera en particulier a la dependance objet (mangent, glaces).

5. Dans la pratique, il n’est pas nécessaire dc sauvegarder tous les Vecteurs dc poids, mais seulement dcux Vecteurs.

MODELES GENERATIF ET DISCRIMINANT EN ANALYSE SYNTAXIQUE

Algorithme 1 Entrainement MIRA
pour z’ = 1 a t faire
pour chaque phrase de l’ensemble d’entrainement faire
Generer les 11 meilleures hypotheses de l’analyseur en constituants.
pour chaque hypothese faire
Extraire un Vecteur de traits a partir de l’hypothese.
Calculer son score comme le produit scalaire entre ce Vecteur et le Vecteur de poids (eq. 1)
ﬁn pour
Soit l’oracle, l’hypothese la plus proche de la reference pour cette phrase.
si l’hypothese de meilleur score n’est pas l’oracle alors
Calculer la difference entre le Vecteur de traits de l’oracle et le Vecteur de traits de l’hypothese.
Calculer le facteur ct qui assure que l’oracle ait un meilleur score la prochaine fois (eq. 5)
Ajouter au Vecteur de poids ce facteur fois la difference entre les deux Vecteurs (eq. 4)
ﬁn si
ﬁn pour
ﬁn pour
Retoumer un Vecteur de poids moyen consitute a partir de l’etat du Vecteur de poids apres chaque phrase
d’ entrainement.

Unigramme Les traits unigrammes sont les plus simples, ils ne mettent en jeu qu’une seule dependance. Etant
donne une dependance entre les positions 1' et j de type I, gouvemee par w,-, notee w,- —l> wj, on cree deux
traits, l’un pour le gouvemeur w,- , l’autre pour le dependant wj qui prennent la forme de sextuplets (mot,
lemme, partie du discours, statut dans la dependance (gouvemeur (G) ou dependant (D)) , direction de la
dependance (droite (D) ou gauche (G)), type de la dependance). On ajoute aussi tous les tuples avec une
partie de l’information masquee pour lutter contre la dispersion des donnees lors de l’apprentissage.

Ainsi, la presence de la dependance objet dans notre exemple donnera naissance aux deux traits :
[mangent, manger, V, G, D, objet] et [glaces, glace, N, D, D, objet]

mais aussi a tous les traits que l’on peut constr11ire a partir des deux premiers par sous—speciﬁcation :

[—, manger, V, G, D, objet] , [mangent, —, V, G, D, objet]

[mangent, —, —, —, —, objet]

Ce processus de sous—speciﬁcation des traits s’applique a toutes les familles de traits, on omettra de le
repeter ci-dessous.

Bigramme Contrairement a la famille precedente qui ne prenait en compte qu’un des deux membres d’ une de-
pendance, les traits bigrammes modelisent la cooccurrence des deux membres de la dependance, a l’image
des dependances bi—lexicales de (Collins, 1997). Etant donne la dependance w,- —l> wj, on cree un trait (mot
w,-, lemme w,-, partie du discours w,-, mot wj, lemme wj, partie du discours wj, distance 5 de 1' a j, direction
de la dependance, type de la dependance).

L’ exemple ci—dessus donnera donc naissance au trait suivant :
[mangent, manger, V, glaces, glace, N, 2, D, objet]
ou 2 est la distance separant mangent et glaces dans la chaine lineaire.

Contexte lineaire Contrairement aux deux familles precedentes qui s’interessaient a une dependance indepen-
damment de sa realisation dans la chaine, on regarde ici les elements qui separent un gouvemeur de son
dependant dans cette demiere. Etant donne la dependance w,- —l> wj On cree un trait avec les partie de dis-
cours de w,-, de wj et de chaque mot entre les positions 1' et j . On cree egalement un trait comportant les
parties de discours aux positions 1' — 1, i, i + 1, j — 1, j , j + 1. La dependance objet de notre exemple
donnera naissance aux deux traits :

[V, D, N] 6t [N, V, D, N, P]

Contexte syntaxique, nmuds fréres Cette famille de traits ainsi que la suivante mettent en jeu deux depen-
dances dans deux conﬁgurations particulieres. Etant donne deux dependances w,- —l> wj et w,- 2) wk, on
cree un trait (mot w,-, lemme w,-, partie du discours w,-, mot wj, lemme wj, partie du discours wj, mot wk,
lemme wk, partie du discours wk, distance de 2' a j , distance de 1' a k, direction de la premiere dependance,

6. Cette distance est réduite a sept classes selon qu’elle est égale 5. 1, 2, 3, 4, 5, comprise entre 5 et 10, ou supérieure 51 10.

LE ROUX, FAVRE, MIRROSHANDEL, NASR

type de la premiere dependance, direction de la seconde dependance, type de la seconde dépendance). Ce
qui donne, dans notre exemple: [mangent, manger, V, glaces, glace, avec, avec, P,
2, 3, D, objet, D, mod]

Contexte syntaxique, chaines Etant donné deux dépendances w,- —l> w j 3) wk, on cree un trait (mot w,-, lemme
w,-, partie du discours w,-, mot wj, lemme wj, partie du discours wj, mot wk, lemme wk, partie du discours wk,
distance de 1' a j , distance de 1' a k, direction de la premiere dependance, type de la premiere dependance,
direction de la seconde dependance, type de la seconde dépendance). Dans notre exemple : [mangent ,
manger, V, avec, avec, P, appétit, appétit, N, 3, 4, D, mod, D, objet]

On peut noter que les patrons de traits ne reposent que sur des connaissances présentes dans les données d’appren-
tissage. Nous n’avons pas ajouté de traits qui proviennent de connaissances linguistiques extemes.

4 Expériences

Dans cette section, nous évaluons les performances de notre analyseur. Nous presentons d’abord le module géné-
ratif seul, puis les deux modules ensemble.

Nous utilisons dans nos experiences le corpus arboré de Paris 7 (Abeillé et al., 2003) (dans la suite, FTB). Il
contient 12 350 phrases armotées syntaxiquement en constituants, et en etiquettes fonctionnelles. Ce n’est pas
directement ce corpus que nous manipulons mais deux transformations de celui-ci.

1. La premiere, FTB—UC, mise au point par (Crabbe & Candito, 2008), garde la structure en constituants mais
simpliﬁe le jeu d’etiquettes. En particulier, les fonctions disparaissent et les informations morphologiques
sont réduites. C’est sur ce corpus que nous apprendrons la grammaire syntagmatique.

2. La seconde, FTB-UC—DEP, présentée dans (Candito et al., 2009), est une conversion du FTB en dependances.
Cette conversion est realisée a l’aide de regles de propagation de tetes et d’heuristiques. C’est sur ce second
corpus que l’on apprendra l’analyseur discriminant.

Pour entrainer et évaluer notre systeme, nous divisons ces corpus en 3 : une partie pour l’entrainement (80%), une
partie pour le développement (10%) et le reste pour l’évaluation ﬁnale.

Nous employons deux types de grammaires syntagmatiques, le premier appris directement sur FTB —UC (modele
simple), le second appris sur une version modiﬁée de FTB-UC dans laquelle les mots sont remplacés par leur classe
d’equivalence (modele agrégats), comme dans (Candito & Crabbe, 2009).

4.1 Evaluation du modéle génératif seul

Les performances de notre analyseur syntagmatique sur le corpus de développement sont résumées dans le ta-
bleau 2. Le F-score7 est la moyenne harmonique du rappel (ici, les constituants de la reference retrouvés par
l’analyseur) et de la precision (ici, les constituants prédits presents dans la reference). Nous donnons les scores
oracles de notre analyseur quand il renvoie les 1, 10, 50 et 100 analyses les plus probables d’une phrase, pour
donner une idée de la marge de progression possible.

Les résultats quantitatifs de la conversion en structures de dépendances sont également presentes dans la table 2.
Le score d’attachement etiqueté (LAS) est le taux de dépendances typees correctement reconnues 8 par l’analy-
seur. Le score non—étiqueté (UAS) est ce meme taux lorsque l’on ne tient pas compte du type des dependances.
Nous avons representé sur la demiere colonne (GOLD) l’évaluation de la conversion en dependances de l’ana-
lyse syntagmatique de reference. Ces resultats nous permettent d’évaluer la qualité de l’etiquetage fonctionnel, ils
montrent que l’étiqueteur effectue a peu pres 4% d’erreurs dans l’attribution de ces etiquettes. Comme precédem—
ment, nous donnons aussi le score oracle quand notre analyseur renvoie plusieurs analyses.

7. Nous utilisons le logiciel evalb que nous avons modiﬁé pour qu’il donne également le score oracle quand l’analyseur fournit une liste
d’ arbres.
8. La ponctuation n’est pas prise en compte.

MoDELEs GENERATIE ET DISCRIMINANT EN ANALYSE SYNTAXIQUE

DEV-1 DEV-10 DEV-50 DEV-100 GOLD

F 84,41 89,35 91,71 92,56 100
LAS 86,01 89,25 90,86 91,48 96,04
UAS 89,60 92,70 94,23 94,80 100
F agrégats 85,02 89,98 92,33 93,27 100
LAS agrégats 86,99 89,93 91,61 92,25 96,04
UAS agrégats 90,72 93,48 95,05 95,68 100

TAB LE 2 — Scores de l’analyseur genératif sur la partie de developpement

Les resultats donnes ci—dessus nous permettent de tirer deux conclusions importantes. D’une part les résultats de
l’analyseur sont du niveau de l’état de l’art pour l’analyse syntagmatique du francais (84, 41% de F—score). D’autre
part, la marge de progression du réordonnanceur est importante puisque le score oracle LAS sur les 100 analyses
les plus probables est de 91, 48% alors que le score de l’analyse la plus probable est de 86, 01% soit une marge
possible de progression de 5, 47%.

4.2 Ajout du réordonnanceur
4.2.1 Apprentissage

Le modele discriminant, c’est—a—dire les instances des patrons de traits et leur poids, est appris sur le corpus
d’entrainement. L’ analyseur génératif produit 100 analyses par phrase9 pour ce corpus qui servent d’exemples
d’apprentissage au réordonnanceur. Le modele donne 71 millions de traits pour la grammaire simple et 75 millions
pour la grammaire d’agregats. Notez qu’un tel nombre de traits n’est pas penalisant car l’algorhtme discriminant
ne donne un poids non r1ul qu’aux traits utiles.

4.2.2 Evaluation

base 10 20 50 100 base 10 20 50 100
F 84,41 85,38 85,58 85,55 85,32 F 85,00 85,94 86,12 86,20 86,15
LAS 86,01 87,06 87,31 87,39 87,28 LAS 86,99 88,00 88,06 88,10 88,17
UAS 89,60 90,57 90,77 90,83 90,69 UAS 90,78 91,54 91,57 91,58 91,62
grammaire simple grammaire apprise sur agregats

TABLE 3 — scores du réordonnanceur en fonction du nombre de candidats

Pour notre evaluation, nous avons teste plusieurs conﬁgurations sur le corpus de developpement en faisant Varier le
nombre de candidats foumi au réordonnanceur lors de la phase de prediction 10. Les resultats sont presentes dans
la table 3. Pour la métrique LAS, les meilleurs resultats sont obtenus en donnant 50 candidats au réordonnanceur
dans le cas de la grammaire simple et 100 dans le cas de la grammaire d’agregats. Mais la difference avec les
autres conﬁgurations n’est pas signiﬁcative.

Puisque la meilleure conﬁguration pour les differentes grammaires n’est pas la meme selon la métrique utilisee
mais que la conﬁguration a 50 candidats est touj ours la meilleure selon l’une d’entre elles, c’est cette conﬁguration
qui est utilisee sur le corpus de test pour l’éValuation ﬁnale avec la grammaire simple et la grammaire d’agregats.
Les resultats, dans la table 4, sont du meme ordre de grandeur 11. Pour la grammaire simple, le réordonnanceur
de notre systeme permet de passer d’un F—score de 85,09% a 86,02%, pour le LAS de 86,68% a 87,91% et pour
le UAS de 90,22% a 91,31%. Sur les 3 métriques le réordonnanceur montre une amelioration signiﬁcative 12. Il
est intéressant de noter que nos traits portent uniquement sur les structures en dependances (mis a part le score

9. Pour certaines phrases, les phrases courtes en particulier, notre systeme renvoie moins de 100 analyses.
10. Les poids des traits sont toujours appris avec 100 candidats par phrase.
11. F < 40 est le F—score en constituants pour les phrases de moins de 40 mots.
12. Les differences de scores entre le systeme de base et les nouveaux systemes incorporant le module discriminant sont statistiquement
signiﬁcatives avec une valeur p < 0.01. Les differences entre les nouveaux systemes ne le sont pas.

LE ROUX, FAVRE, MIRROSHANDEL, NASR

attribué par l’analyseur PCFG—LA) et que le F—score qui mesure la qualité des arbres syntagmatiques est tout de
meme amelioree.

base réord. base reord.
F 85,09 86,02 F 86,35 86,89
F < 40 87,10 87,82 F < 40 88,45 88,74
LAS 86,68 87,91 LAS 87,37 88,45
UAS 90,22 91,31 UAS 91,08 91,91

grammaire simple grammaire apprise sur agrégats

TABLE 4 — Scores du systeme sur le corpus detest

4.2.3 Comparaisons

F < 40 LAS UAS

Ce travail 87,82 87,91 91,31
Ce travail + agrégats 88,74 88,45 91,91
MATE + MELT — 88,17 90,15
BKY 88,2 86,8 91,0
MST — 88,2 90,9

TAB LE 5 — Comparaisons des différents résultats d’ analyse syntaxique

Nous donnons un tableau récapitulatif de différents résultats d’analyseurs sur le FTB dans la table 5. Nous compa-
rons notre systeme (nous avons choisi les conﬁgurations qui donnaient les meilleurs scores LAS sur le corpus de
développement) avec l’analyseur en dépendances MATE (Bohnet, 2010), entraine et evalué avec MELT (Denis &
Sagot, 2010) pour l’etiquetage en parties du discours. Nous citons aussi les travaux de comparaisons de (Candito
et al., 2010b), avec un premier systeme (B KY dans la table) proche du notre avec un analyseur syntagmatique
qui fournit une sortie convertie en arbre de dependances. Le second systeme (MST dans la table) est l’analyseur

MSTParser de (McDonald et al., 2005). Ces deux systemes utilisent aussi les agrégats et non directement les mots
du texte.

4.2.4 Analyse

Une analyse du vecteur de poids produit par le modele discriminant montre que seuls 27% des 75 millions de
traits observes dans les donnees d’entrainement correspondent a des poids non nuls (modele avec agrégats). Les
autres traits ont donc eté jugés non discriminants. Nous avons analyse les 1000 traits de plus grand poids positif,
représentant les caracteristiques jugees les plus pertinentes pour discrirniner les bonnes analyses et les 1000 traits
de poids negatifs de plus grande valeur absolue, symptomatiques des mauvaises analyses.

Avant Ie réordonnement Aprés Ie réordonnement
arbres
’7”“°9""“"‘7”e5 SENT SENT
PP PP PP PP
"P V" (\AP "P NP V" /\AI> /\NP /\NP
/\ /\ I //7% /\ /\ I I I
NPP NPP V VPP P AD] PONCF DEF AD] PONCF P AD] PONCF NPP NPP V VPP P AD] PONCF P NC PONCF P AD] PONCT
Francois Mariel: fut qualiﬁé de laxiste , d' irresponsable , d' irréaliste . Francois Mariel: fut qualiﬁé de laxiste , d' irresponsable , d' irréaliste .

arbres en

dépendance Wm

 

ram mod
DOIICK
sul aux. 5 ] ‘l‘| suJ mix. 5 sub mango“
rmnu] F} ['1 v 51. HI fmod} E2] fiﬂunj] f on; j ram]
Francois Mariet fut qualiﬁé de laxisle , d' inesponsahle , d' irréaliste . Francois Mariet fut qualiﬁé de laxiste , d‘ irresponsable , d' irréaliste .
NPP NPP V VFF F AD] PONCF DET AD] FONCF F AD] PONCF NPP NFF V VFF F AD] PONCF F NC FONCF F AD] PONCF

FIGURE 2 — Exemple de réordonnancement bénéﬁque (163° phrase de developpement) : la meilleure analyse selon
le modele genératif est a gauche, la meilleure selon le modele discriminant, la 35° hypothese du modele genératif,
est a droite. Les erreurs, indiquees par des pointillés, sont propagées lors de la conversion en dependances.

MODELES GENERATIF ET DISCRIMINANT EN ANALYSE SYNTAXIQUE

Cette analyse fait apparaitre que les traits issus du repli13 sont utiles pour caractériser de mauvaises analyses
(63% des 1000 poids les plus négatifs). De plus, les traits negatifs font souvent reference a un indicateur d’échec
de la lemmatisation. Comme cette lemmatisation est produite a partir d’un lexique et de la paire forme / partie
du discours, et sous l’hypothese que notre lexique est sufﬁsamment riche, une erreur signiﬁe que l’étiquetage en
partie du discours est mauvais.

Le trait positif le plus discriminant est, sans surprise, le score donne par l’analyseur. Les autres traits positifs
importants pennettent d’avantager des étiquetages de parties du discours en fonction du contexte lineaire. On
remarque aussi l’existence de traits qui incitent les conj oints a avoir la meme catégorie dans les coordinations.

On voit donc que le réordonnancement peut remettre en question l’etiquetage de l’analyseur mais aussi qu’il peut
inﬂuencer le traitement de phenomenes plus complexes comme la coordination. La ﬁgure 2 donne un exemple de
phrase dont la meilleure analyse a eté corrigée par le modele discriminant.

Les patrons les plus representes en positif sont unigramme, bigramme, contexte linéaire, chaines, et leurs
versions relachees, et en negatif unigramme, bigramme, chaines, nmuds fréres. Une analyse des resultats par
type de dependance montre que le reordonnanceur fait moins d’erreurs unifonnement sur l’ensemble des types.
La ﬁgure 2 donne un exemple de phrase dont l’analyse a ete corrigee par le modele discriminant.

5 Conclusion

Nous avons montre que l’ajout d’un module discriminant permet d’améliorer la qualité des analyses, comme nous
avons pu le veriﬁer expérimentalement sur le corpus FTB a l’aide de trois métriques (F—score Parseval, LAS,
UAS). Cependant, le gain est moins important que celui observe pour l’anglais (Charniak & Johnson, 2005). Sans
proceder a une analyse d’erreurs exhaustive, on peut toutefois evoquer plusieurs points pouvant etre améliorés.

En premier lieu, l’approche sequentielle est vulnerable aux erreurs en cascade. Bien que l’analyseur generatif
foumisse plusieurs candidats, ce n’est pas le cas de l’étiqueteur fonctionnel. Les erreurs d’etiquetage ne sont donc
pas récuperables. On peut envisager deux solutions ici : (1) pennettre a l’ étiqueteur de renvoyer une sortie ambigue
et laisser le réordonnanceur decider du meilleur étiquetage, et (2) utiliser des techniques plus sophistiquées dans
la phase discriminante comme la prediction structurée. On pourra ainsi se passer de l’etiqueteur.

Ensuite, cette approche a deux niveaux ne permet pas d’atteindre l’oracle, ce qui a déja été observe sur l’anglais.
11 est difﬁcile de trouver un jeu de traits sufﬁsamment general et qui soit utile pour une phrase particuliere. Il
y a encore des investigations a mener pour trouver un jeu de traits optimal, par exemple sur l’utilisation plus
systématique de traits sur les structures de dépendances (par exemple en passant par des noyaux d’arbres), ou
celle de connaissances extemes, linguistiques ou collectées sur corpus (preferences lexicales, cadres de sous-
categorisation, verbes copulatifs, symétrie de la coordination. . . ).

Enﬁn, notre systeme doit encore etre amelioré pour une utilisation en situation réelle (par exemple, l’analyse de
gros volumes de données provenant de la toile). L’ extraction des traits pour le reordonnanceur, et vraisemblable—
ment pour l’étiqueteur fonctionnel, est clairement le goulot d’étranglement. A titre d’exemple, pour analyser les
1235 phrases du corpus de test, les temps d’analyse en constituants, d’étiquetage fonctionnel et de conversion en
structures de dependances, d’ extraction de traits et ﬁnalement de réordonnancement, sont respectivement : 9 min
55 s, 25min43 s, 51 min 12set4min03 s.

Ce travail ouvre la voie a l’utilisation de donnees non étiquetées en plus d’un corpus arbore pour apprendre une
meilleure grammaire generative (self training comme (McClosky et al., 2008)) ou le reordonnanceur évite au
systeme d’apprendre sur les erreurs commises par l’analyseur génératif.

Remerciements

Ces travaux sont en partie ﬁnances par le projet ANR Sequoia ANR—08—EMER—0l3. Nous tenons a remercier
Marie Candito qui nous a aides a maitriser BONSAL Djamé Seddah qui nous a suggére de tester notre architecture
sur les grammaires d’agrégats, ainsi que les relecteurs anonymes.

13. C’est-5-dire qu’une partie de l’information est masquée (cf. section 3.2).

LE ROUX, FAVRE, MIRROSHANDEL, NASR

Références

AB EILLE A., CLEMENT L. & FRANCOIS T. (2003). Treebanks, chapter Building a treebank for French. Kluwer,
Dordrecht.

ATTIA M., FOSTER J ., HOGAN D., LE Roux J ., TOUNSI L. & VAN GENABITH J . (2010). Handling Unknown
Words in Statistical Latent—Variable Parsing Models for Arabic, English and French. In Proceedings of SPMRL.
BOHNET B. (2010). Top Accuracy and Fast Dependency Parsing is not a Contradiction. In Proceedings of
COLING.

CANDITO M., CRABBE B. & DENIS P. (2010a). Statistical French Dependency Parsing : Treebank Conversion
and First Results. In Proceedings of LREC20l 0.

CANDITO M.—H. & CRABBE B. (2009). Improving Generative Statistical Parsing with Semi—Supervised Word
Clustering. In Proceedings of IWPT 2009.

CANDITO M.—H., CRABBE B., DENIS P. & GUERIN F. (2009). Analyse syntaxique du francais : des consti-
tuants aux dépendances. In Actes de TALN.

CANDITO  NIVRE J ., DENIS P. & HENESTROZA ANGUIANO E. (2010b). Benchmarking of Statistical
Dependency Parsers for French. In Proceedings of COLING’20l 0.

CHARNIAK E. & JOHNSON M. (2005). Coarse—to—Fine n—Best Parsing and MaxEnt Discriminative Reranking.
In Proceedings of ACL.

COLLINS M. (1997). Three Generative, Lexicalised Models for Statistical Parsing. In Proceedings of the 35th
Annual Meeting of the ACL.

COLLINS M. (2000). Discriminative Reranking for Natural Language Parsing. In Proceedings of ICML.
CRABBE B. & CANDITO M. (2008). Experiences d’analyse syntaxique du francais. In Actes de TALN.
CRAMMER K., DEKEL 0., KESHET J ., SHALEVSHWARTZ S. & SINGER Y. (2006). Online Passive-Aggressive
Algorithm. Journal of Machine Learning Research.

DENIS P. & SAGOT B. (2010). Exploitation d’une ressource lexicale pour la construction d’un étiqueteur mor-
phosyntaxique état—de—l’art du francais. In Actes de TALN.

JOHNSON M. & URAL A. E. (2010). Reranking the Berkeley and Brown Parsers. In Human Language Tech-
nologies : The 2010 Annual Conference of the North American Chapter of the Association for Computational
Linguistics, p. 665-668, Los Angeles, California : Association for Computational Linguistics.

MATSUZAKI T., MIYAO Y. & ICHI TSUJII J . (2005). Probabilistic CFG with Latent Annotations. In Proceedings
of ACL.

MCCLOSKY D., CHARNIAK E. & JOHNSON M. (2008). When is Self—Training Effective for Parsing ? In D.
SCOTT & H. USZKOREIT, Eds., COLING, p. 561-568.

MCDONALD R. (2006). Discriminative Training and Spanning Tree Algorithms for Dependency Parsing. PhD
thesis, University of Pennsylvania.

MCDONALD R., CRAMMER K. & PEREIRA F. (2005). Online Large—Margin Training of Dependency Parsers.
In Association for Computational Linguistics (ACL).

NIVRE J ., HALL J ., NILSSON J ., CHANEV A., ERYIGIT G., KUBLER S., MARINOV S. & MARSI E. (2007).
Maltparser : A language—independent system for data—driven dependency parsing. Natural language Enginee-
ring, 13(2), 95-135.

PETROV S., BARRETT L., THIBAUX R. & KLEIN D. (2006). Learning Accurate, Compact, and Interpretable
Tree Annotation. In ACL.

PETROV S. & KLEIN D. (2007). Improved Inference for Unlexicalized Parsing. In HLT—NAACL, p. 404-411.
PULLUM G. K. & SCHOLZ B. C. (2001). On the distinction between model—theoretic and generative-
enumerative syntactic frameworks. In Logical Aspects of Computational Linguistics.

RAMBOW O. (2010). The Simple Truth about Dependency and Phrase Structure Representations : An Opinion
Piece. In NAACL HLT.

ROSENBLATT F. (1958). The Perceptron : A Probabilistic Model for Information Storage and Organization in
the Brain. Psychological Review.

SEDDAH D., CANDITO M. & CRABBE B. (2009). Adaptation de parsers statistiques lexicalisés pour le francais :
Une evaluation complete sur corpus arborés. In TALN.

