<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Apport de la syntaxe pour l&#8217;extraction de relations en domaine m&#233;dical</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211;1er juillet 2011
</p>
<p>Apport de la syntaxe pour l&#8217;extraction de relations en domaine m&#233;dical
</p>
<p>Anne-Lyse Minard1, 2 Anne-Laure Ligozat1, 3 Brigitte Grau1, 3
(1) LIMSI-CNRS, BP 133, 91403 Orsay cedex
</p>
<p>(2) Universit&#233; Paris-Sud, 91400 Orsay
(3) ENSIIE, 1 square de la r&#233;sistance, 91000 &#201;vry
</p>
<p>prenom.nom@limsi.fr
</p>
<p>R&#233;sum&#233;. Dans cet article, nous nous int&#233;ressons &#224; l&#8217;identification de relations entre entit&#233;s en domaine de sp&#233;cialit&#233;, et &#233;tudions
l&#8217;apport d&#8217;informations syntaxiques. Nous nous pla&#231;ons dans le domaine m&#233;dical, et analysons des relations entre concepts dans
des comptes-rendus m&#233;dicaux, t&#226;che &#233;valu&#233;e dans la campagne i2b2 en 2010. Les relations &#233;tant exprim&#233;es par des formulations
tr&#232;s vari&#233;es en langue, nous avons proc&#233;d&#233; &#224; l&#8217;analyse des phrases en extrayant des traits qui concourent &#224; la reconnaissance de la
pr&#233;sence d&#8217;une relation et nous avons consid&#233;r&#233; l&#8217;identification des relations comme une t&#226;che de classification multi-classes, chaque
cat&#233;gorie de relation &#233;tant consid&#233;r&#233;e comme une classe. Notre syst&#232;me de r&#233;f&#233;rence est celui qui a particip&#233; &#224; la campagne i2b2,
dont la F-mesure est d&#8217;environ 0,70. Nous avons &#233;valu&#233; l&#8217;apport de la syntaxe pour cette t&#226;che, tout d&#8217;abord en ajoutant des attributs
syntaxiques &#224; notre classifieur, puis en utilisant un apprentissage fond&#233; sur la structure syntaxique des phrases (apprentissage &#224; base
de tree kernels) ; cette derni&#232;re m&#233;thode am&#233;liore les r&#233;sultats de la classification de 3%.
</p>
<p>Abstract. In this paper, we study relation identification between concepts in medical reports, a task that was evaluated in the
i2b2 campaign in 2010, and evaluate the usefulness of syntactic information. As relations are expressed in natural language with a
great variety of forms, we proceeded to sentence analysis by extracting features that enable to identify a relation and we modeled
this task as a multiclass classification task based on SVM, each category of relation representing a class. This method obtained an
F-measure of 0.70 at i2b2 evaluation. We then evaluated the introduction of syntactic information in the classification process, by
adding syntactic features, and by using tree kernels. This last method improves the classification up to 3%.
</p>
<p>Mots-cl&#233;s : extraction de relation, domaine m&#233;dical, apprentissage multi-classes, tree kernel.
</p>
<p>Keywords: relation identification, medical domain, multiclass learning, tree kernel.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ANNE-LYSE MINARD, ANNE-LAURE LIGOZAT, BRIGITTE GRAU
</p>
<p>1 Introduction
</p>
<p>L&#8217;extraction d&#8217;information permet d&#8217;obtenir des repr&#233;sentations structur&#233;es du contenu d&#8217;un corpus. Le domaine m&#233;dical repr&#233;sente
en cela un domaine d&#8217;application int&#233;ressant : en effet, les documents m&#233;dicaux tels que les comptes-rendus cliniques contiennent
de nombreuses informations sur le suivi m&#233;dical des patients, et la structuration automatique de ces informations pourrait am&#233;liorer
la prise en charge de ceux-ci.
</p>
<p>L&#8217;extraction de ces informations am&#232;ne &#224; se poser diff&#233;rents probl&#232;mes, li&#233;s aux types d&#8217;information cherch&#233;s : la reconnaissance
des termes du domaine dans les textes, des concepts qui leur sont li&#233;s, ainsi que l&#8217;identification des types de relations qui les lient
dans les documents.
</p>
<p>Nous nous sommes int&#233;ress&#233;es &#224; l&#8217;identification de relations dans des comptes-rendus m&#233;dicaux, t&#226;che qui a fait l&#8217;objet d&#8217;une
campagne d&#8217;&#233;valuation i2b2 en 2010 1. Un premier travail a &#233;t&#233; r&#233;alis&#233; mod&#233;lisant l&#8217;identification des relations comme une t&#226;che
de classification multi-classes (Minard et al., 2011b). Cette approche a &#233;t&#233; choisie car elle permet de caract&#233;riser les relations par
des ensembles de traits lexicaux et de surface, et a conduit &#224; l&#8217;obtention de bons r&#233;sultats &#224; i2b2. N&#233;anmoins, les phrases &#233;tant
parfois complexes, leur repr&#233;sentation par des traits de surface uniquement ne permet pas de capturer des relations entre termes
distants. C&#8217;est pourquoi nous nous sommes pos&#233; la question de l&#8217;utilit&#233; des traits syntaxiques pour la reconnaissance de relations en
domaine de sp&#233;cialit&#233; : des attributs portant de l&#8217;information sur la structure syntaxique des phrases am&#233;liorent-ils l&#8217;extraction ? Et
des approches par apprentissage sur des arbres syntaxiques sont-elles meilleures que des approches &#171;sac de mots&#187; ?
</p>
<p>Apr&#232;s avoir pr&#233;sent&#233; les travaux existant dans ce domaine, nous pr&#233;senterons le contexte de notre &#233;tude, puis nous expliquerons nos
m&#233;thodes et &#233;valuerons notre approche.
</p>
<p>2 L&#8217;extraction de relations
</p>
<p>L&#8217;extraction de relations a donn&#233; lieu &#224; de nombreux travaux, notamment dans le domaine biom&#233;dical. Les approches actuelles se
fondent sur une classification automatique plus ou moins supervis&#233;e.
</p>
<p>(Roberts et al., 2008) proposent une approche classique fond&#233;e sur des SVM (machine &#224; vecteurs de support) pour extraire des
relations dans un corpus de sp&#233;cialit&#233; : le corpus du projet CLEF (the Clinical E-Science Framework project). Ils extraient des
relations entre des entit&#233;s (ex : condition, m&#233;dicament, r&#233;sultat) et des modifieurs (ex : marqueur de n&#233;gation) dans des dossiers de
patients atteints d&#8217;un cancer. Les relations sont de sept types. Deux types d&#8217;entit&#233;s (ou une entit&#233; et un modifieur) ne peuvent &#234;tre
reli&#233;es que par une relation (sauf entre une investigation et une condition o&#249; la relation peut &#234;tre de deux types). La t&#226;che est donc
mod&#233;lis&#233;e comme une classification binaire, c&#8217;est-&#224;-dire que les SVM sont entra&#238;n&#233;s pour une d&#233;cision entre une classe et toutes les
autres. Les attributs qu&#8217;ils utilisent correspondent &#224; des attributs de notre syst&#232;me de base :
&#8211; des attributs lexicaux : les mots (et les radicaux des mots) dans une fen&#234;tre de 6 mots avant et apr&#232;s les entit&#233;s en relation, les mots
</p>
<p>formant les entit&#233;s, les mots situ&#233;s entre les entit&#233;s ;
&#8211; des attributs morpho-syntaxiques : les cat&#233;gories morpho-syntaxiques et ces m&#234;mes cat&#233;gories g&#233;n&#233;ralis&#233;es (par exemple toutes
</p>
<p>les cat&#233;gories verbales sont regroup&#233;es en VB) ;
&#8211; des attributs s&#233;mantiques : le type des entit&#233;s en relation et des autres entit&#233;s de la phrase.
D&#8217;autres travaux utilisent des attributs syntaxiques plus riches ((Zhou et al., 2005), (Uzuner et al., 2010)). En particulier, (Uzuner
et al., 2010) utilisent les d&#233;pendances syntaxiques entre les concepts sous forme d&#8217;attributs dans une approche vectorielle bas&#233;e sur
des SVM. Ils souhaitent typer des relations entre des probl&#232;mes, des tests et des traitements dans des comptes-rendus m&#233;dicaux. Ils
classent les relations en six cat&#233;gories, comme par exemple les relations existantes entre une maladie qu&#8217;a le patient et un traitement,
ou les relations entre une &#233;ventuelle maladie et un traitement. Ils utilisent des attributs classiques (l&#8217;ordre des concepts, la distance,
des trigrammes lexicaux, les mots qui forment les concepts, les verbes, des bigrammes syntaxiques, etc.) ainsi que des attributs
portant des informations sur les d&#233;pendances syntaxiques reliant les entit&#233;s. Pour plusieurs relations ils obtiennent des F-mesures
entre 0,60 et 0,85, mais pour les relations pour lesquelles il y a peu d&#8217;exemples dans le corpus d&#8217;apprentissage les F-mesures sont
nulles. Ils &#233;valuent leurs classes d&#8217;attributs, et montrent que les attributs qui apparaissent comme les plus utiles sont les trigrammes
lexicaux et les mots qui forment les concepts. Les informations syntaxiques n&#8217;am&#233;liorent pas la classification notamment car les
d&#233;pendances syntaxiques compl&#232;tes ne sont trouv&#233;es que pour une faible proportion des phrases analys&#233;es.
</p>
<p>Des travaux en domaine ouvert ont cependant montr&#233; que l&#8217;information structurelle utilis&#233;e sous forme d&#8217;arbres gr&#226;ce &#224; des tree
kernels am&#233;liore la classification ((Culotta &amp; Sorensen, 2004), (Zelenko et al., 2003), (Zhang et al., 2006)). En particulier, (Zhang
et al., 2006) ont &#233;tudi&#233; l&#8217;apport de la structure syntaxique des phrases pour l&#8217;extraction de relation en domaine g&#233;n&#233;ral, en s&#8217;appuyant
</p>
<p>1. https ://www.i2b2.org/NLP/Relations/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>APPORT DE LA SYNTAXE POUR L&#8217;EXTRACTION DE RELATIONS EN DOMAINE M&#201;DICAL
</p>
<p>sur le corpus ACE 2003. Ils testent diff&#233;rentes s&#233;lections dans les arbres syntaxiques (arbre complet englobant les deux entit&#233;s en
relation, plus petit arbre commun, en conservant que les chunks, etc.), et ils montrent que les meilleurs r&#233;sultats sont obtenus en
utilisant le plus petit sous-arbre commun aux deux entit&#233;s. (Culotta &amp; Sorensen, 2004) utilisent des arbres de d&#233;pendance sur le
m&#234;me corpus, et montrent que les tree kernels sont meilleurs que l&#8217;information structurelle mise sous forme vectorielle. Ils testent
deux types de tree kernels : contiguous kernel qui n&#8217;apparie pas les s&#233;quences qui sont interrompues par des n&#339;uds non appari&#233;s, et
sparse tree qui autorise les n&#339;uds non appari&#233;s &#224; l&#8217;int&#233;rieur de s&#233;quences appari&#233;es. Les meilleurs r&#233;sultats sont obtenus avec des
contiguous kernel associ&#233;s &#224; des kernels &#171;sac de mots&#187;.
</p>
<p>3 Objectif et m&#233;thodes
</p>
<p>Nous nous sommes int&#233;ress&#233;es &#224; l&#8217;extraction de relations en domaine de sp&#233;cialit&#233;. Notre objectif &#233;tait d&#8217;&#233;tudier comment int&#233;grer des
informations syntaxiques dans un syst&#232;me de classification automatique, et quel &#233;tait l&#8217;apport de ce type d&#8217;informations. Nous avons
consid&#233;r&#233; deux sous-t&#226;ches : la d&#233;tection de la pr&#233;sence d&#8217;une relation entre deux entit&#233;s, en l&#8217;occurrence des concepts m&#233;dicaux, et
la cat&#233;gorisation de cette relation &#233;ventuelle selon des cat&#233;gories pr&#233;d&#233;finies. Ces sous-t&#226;ches ont &#233;t&#233; abord&#233;es comme des probl&#232;mes
de classification supervis&#233;e bi-classes ou multi-classes.
</p>
<p>Nous avons tout d&#8217;abord ajout&#233; des attributs portant des informations sur la structure syntaxique des phrases aux vecteurs lin&#233;aires.
Mais l&#8217;information syntaxique structurelle &#233;tant difficile &#224; d&#233;crire par un vecteur d&#8217;attributs lin&#233;aires, nous avons ensuite utilis&#233; les
tree kernels qui permettent d&#8217;explorer les attributs contenus dans la structure des arbres en calculant la similarit&#233; des arbres deux &#224;
deux.
</p>
<p>3.1 Classification
</p>
<p>Nous avons utilis&#233; des classifieurs &#224; base de SVM car ils sont tr&#232;s pr&#233;sents dans l&#8217;&#233;tat de l&#8217;art des syst&#232;mes d&#8217;extraction de relations.
De plus ils donnent de bons r&#233;sultats pour les t&#226;ches pour lesquelles il y a beaucoup d&#8217;attributs mais qui sont tr&#232;s &#233;pars, comme c&#8217;est
souvent le cas en TAL. Pour tenir compte de l&#8217;information syntaxique, nous avons choisi d&#8217;utiliser une fonction kernel qui mesure
la similarit&#233; entre deux arbres, en comptant le nombre de fragments en commun. L&#8217;arbre est d&#233;coup&#233; en fragments de diff&#233;rentes
tailles. Deux options sont possibles, soit ST (subtrees) qui calcule tous les sous-arbres possibles avec tous leurs descendants (voir
figure 1), soit SST (subset tree) qui autorise &#233;galement les fragments d&#8217;arbres dont les feuilles ne sont pas des &#233;l&#233;ments terminaux,
mais des chunks ou des &#233;tiquettes morpho-syntaxiques (voir figure 2). Pour la classification binaire, c&#8217;est-&#224;-dire la d&#233;tection de
relation, nous avons utilis&#233; le logiciel SVM-Light-TK version 1.5 de (Moschitti, 2006). Nous avons param&#233;tr&#233; le classifieur de la
fa&#231;on suivante : combinaison d&#8217;arbres et de vecteurs comme type de fonction kernel, et somme des contributions des arbres et des
vecteurs comme op&#233;rateur de combinaison. Nous avons choisi d&#8217;utiliser l&#8217;option SST qui est plus g&#233;n&#233;rale et donne de meilleurs
r&#233;sultats selon (Moschitti, 2006).
</p>
<p>FIGURE 1 &#8211; Exemple de subtrees (ST) de (Moschitti, 2006)
</p>
<p>Pour la classification multi-classes, c&#8217;est-&#224;-dire la d&#233;tection de relation et le typage des relations, nous avons utilis&#233; le programme
LIBSVM (Chang &amp; Lin, 2001) avec une approche &#171; un-contre-un &#187;. Nous avons utilis&#233; un noyau lin&#233;aire, ce choix est conseill&#233;
par (Hsu et al., 2003) quand le nombre d&#8217;attributs est important par rapport au nombre d&#8217;instances. Nous avons fix&#233; la valeur du
param&#232;tre C (penalty parameter) &#224; 16 et celle du param&#232;tre gamma (kernel parameter) &#224; 0,03125. Ces valeurs ont &#233;t&#233; choisies par
l&#8217;outil grid fourni avec LIBSVM.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ANNE-LYSE MINARD, ANNE-LAURE LIGOZAT, BRIGITTE GRAU
</p>
<p>FIGURE 2 &#8211; Exemple de subset trees (SST) de (Moschitti, 2006)
</p>
<p>3.2 Attributs de r&#233;f&#233;rence
</p>
<p>Les attributs choisis pour la classification automatique prennent en compte des informations de surface, sur les distances entre mots
par exemple, des informations lexicales, comme les mots formant les concepts, des informations morpho-syntaxiques, comme les
cat&#233;gories morpho-syntaxiques des mots, et des informations s&#233;mantiques gr&#226;ce &#224; un typage de concepts.
</p>
<p>Tous les attributs pr&#233;sent&#233;s ici constitueront les attributs de notre syst&#232;me de r&#233;f&#233;rence, auxquels seront ajout&#233;es des informations
syntaxiques. La s&#233;lection des attributs est pr&#233;sent&#233;e de mani&#232;re plus d&#233;taill&#233;e dans (Minard et al., 2011b).
</p>
<p>3.2.1 Attributs de surface
</p>
<p>Les attributs de surface sont relatifs &#224; la position des concepts dans la phrase ; ce sont les suivants :
&#8211; l&#8217;ordre des concepts : celui-ci influence en effet la fa&#231;on dont la relation est exprim&#233;e ;
&#8211; la distance entre les deux concepts en termes de nombre de mots 2 : deux concepts ont d&#8217;autant moins de chance d&#8217;&#234;tre en relation
</p>
<p>qu&#8217;il y a de nombreux mots entre les deux ;
&#8211; la pr&#233;sence d&#8217;autres concepts entre les deux concepts &#233;tudi&#233;s : la pr&#233;sence d&#8217;un troisi&#232;me concept modifie les probabilit&#233;s que les
</p>
<p>deux concepts soient bien en relation.
</p>
<p>3.2.2 Attributs lexicaux
</p>
<p>Plusieurs attributs lexicaux sont pris en compte :
&#8211; les mots, et leurs radicaux (stems) 3, qui composent les concepts, et le mot t&#234;te de chaque concept 4. Nous avons consid&#233;r&#233; les
</p>
<p>radicaux de mani&#232;re &#224; regrouper les variantes flexionnelles et d&#233;rivationnelles ;
&#8211; les radicaux des trois mots &#224; gauche et &#224; droite des concepts. La taille de la fen&#234;tre a &#233;t&#233; choisie apr&#232;s plusieurs tests : avec une
</p>
<p>fen&#234;tre plus grande ou plus petite la pr&#233;cision augmente tr&#232;s l&#233;g&#232;rement mais le rappel diminue ;
&#8211; les radicaux des mots entre les concepts, ce qui permet de tenir compte de tous les mots entre les concepts ; c&#8217;est ici qu&#8217;est situ&#233;e
</p>
<p>l&#8217;information la plus utile &#224; la classification ;
&#8211; les radicaux des verbes dans une fen&#234;tre de trois mots avant et apr&#232;s chaque concept, et entre eux, le verbe marquant souvent la
</p>
<p>relation ;
&#8211; les pr&#233;positions entre les concepts.
</p>
<p>3.2.3 Attributs morpho-syntaxiques
</p>
<p>Le TreeTagger est appliqu&#233; sur les phrases &#224; analyser, et son &#233;tiquetage est utilis&#233; pour les attributs suivants :
</p>
<p>&#8211; la cat&#233;gorie morpho-syntaxique des mots dans une fen&#234;tre de trois mots &#224; gauche et &#224; droite des concepts ;
&#8211; la pr&#233;sence d&#8217;une pr&#233;position entre les concepts, peu importe la pr&#233;position ;
&#8211; la pr&#233;sence d&#8217;une conjonction de coordination ou d&#8217;une virgule entre les concepts ;
</p>
<p>2. Le d&#233;coupage en mots est effectu&#233; par le TreeTagger (Schmid, 1994).
3. Pour obtenir les radicaux des mots nous utilisons le module PERL lingua : :stem.
4. La t&#234;te d&#8217;un concept correspond au mot pr&#233;c&#233;dant une pr&#233;position ou le dernier mot du concept, comme d&#233;fini dans (Zhou et al., 2005).</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>APPORT DE LA SYNTAXE POUR L&#8217;EXTRACTION DE RELATIONS EN DOMAINE M&#201;DICAL
</p>
<p>&#8211; si les concepts ne sont s&#233;par&#233;s que par un mot, un attribut marque la pr&#233;sence d&#8217;un signe de ponctuation. Cet attribut permet de
consid&#233;rer les &#233;num&#233;rations diff&#233;remment.
</p>
<p>3.2.4 Attributs s&#233;mantiques
</p>
<p>Enfin, des attributs s&#233;mantiques permettent de g&#233;n&#233;raliser l&#8217;information port&#233;e par certains mots des phrases et concernent les
concepts du domaine d&#8217;une part et les classes de verbes d&#8217;autre part :
&#8211; le type s&#233;mantique (issu de l&#8217;UMLS 5) des mots dans une fen&#234;tre de trois mots &#224; gauche et &#224; droite de chaque concept ;
&#8211; les types des concepts : c&#8217;est l&#8217;attribut le plus important car les relations possibles d&#233;pendent des types des deux concepts consi-
</p>
<p>d&#233;r&#233;s ;
&#8211; les classes de VerbNet 6 (une extension des classes de Levin) des verbes dans un fen&#234;tre de trois mots &#224; gauche et &#224; droite des
</p>
<p>concepts, et entre les concepts.
</p>
<p>3.3 Informations syntaxiques
</p>
<p>Les informations syntaxiques utilis&#233;es proviennent des arbres de constituants ; ces arbres syntaxiques ont &#233;t&#233; produits par l&#8217;analyseur
de Charniak/McClosky (McClosky, 2010). Nous avons choisi d&#8217;utiliser cet analyseur car il est entra&#238;n&#233; sur des textes biom&#233;dicaux et
obtient de bons r&#233;sultats dans ce domaine (f-score de 87,6% 7). Les phrases ont &#233;t&#233; analys&#233;es apr&#232;s remplacement des abr&#233;viations,
normalisation des dates, &#226;ges, noms propre et nombres, et annotation des concepts. La figure 3 est un exemple d&#8217;arbre fourni par
l&#8217;analyseur &#224; partir de la phrase suivante :
</p>
<p>2 Low back strain requiring hospitalization for pain in 2002.
</p>
<p>avec hospitalization &#233;tiquet&#233; comme un concept de type traitement et pain &#233;tiquet&#233; comme un concept de type probl&#232;me (la balise
&lt;NUM&gt; remplace un nombre et la balise &lt;DATE&gt; une date ou une ann&#233;e).
</p>
<p>&#192; partir de cet arbre nous avons produit le sous-arbre minimal reliant les deux entit&#233;s possiblement en relation. Ce sous-arbre
correspondant au chemin le plus court pour aller d&#8217;un concept &#224; l&#8217;autre, nous l&#8217;appellerons &#171;sous-arbre minimal complet&#187;. Nous
avons &#233;galement produit un sous-arbre plus restreint, qui est &#233;quivalent au sous-arbre minimal complet, sauf que nous n&#8217;avons pas
gard&#233; le contexte gauche de la premi&#232;re entit&#233; ni le contexte droit de la deuxi&#232;me entit&#233;.
</p>
<p>La figure 4 repr&#233;sente le sous-arbre minimal complet produit &#224; partir de l&#8217;arbre pr&#233;sent&#233; dans la figure 3 et la figure 5 le sous-arbre
minimal. Ces trois arbres sont utilis&#233;s comme attributs pour la classification des relations.
</p>
<p>FIGURE 3 &#8211; Exemple de l&#8217;arbre complet
</p>
<p>&#192; partir du sous-arbre minimal nous avons calcul&#233; deux attributs : la taille du chemin reliant les deux entit&#233;s (nous comptons le
chemin entre les n&#339;uds ayant pour valeur les types des concepts), et le constituant du n&#339;ud racine du sous-arbre. Pour le couple
hospitalization et pain, la taille du plus petit chemin reliant les entit&#233;s est sept et le constituant du n&#339;ud racine du sous-arbre minimal
est NP (voir figure 5).
</p>
<p>5. http ://www.nlm.nih.gov/research/umls/
6. http ://verbs.colorado.edu/ mpalmer/projects/verbnet.html
7. http ://www.cs.brown.edu/ dmcc/biomedical.html</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ANNE-LYSE MINARD, ANNE-LAURE LIGOZAT, BRIGITTE GRAU
</p>
<p>FIGURE 4 &#8211; Exemple du sous-arbre minimal complet entre
les deux entit&#233;s
</p>
<p>FIGURE 5 &#8211; Exemple du sous-arbre minimal entre les deux
entit&#233;s
</p>
<p>4 Exp&#233;rimentations
</p>
<p>Les r&#233;sultats pr&#233;sent&#233;s ici s&#8217;inscrivent dans le cadre de la campagne d&#8217;&#233;valuation i2b2 en 2010. Trois t&#226;ches &#233;taient propos&#233;es lors
de cette campagne : la premi&#232;re consistait en l&#8217;annotation des probl&#232;mes m&#233;dicaux, des traitements et des tests, la seconde en la
d&#233;termination du statut d&#8217;assertion et la troisi&#232;me en l&#8217;identification de relations. Nous avons travaill&#233; sur la troisi&#232;me t&#226;che.
</p>
<p>Les corpus, fournis par les organisateurs de la t&#226;che i2b2, sont compos&#233;s de comptes-rendus hospitaliers en anglais provenant de
plusieurs centres m&#233;dicaux aux &#201;tats-Unis. Ces documents avaient &#233;t&#233; anonymis&#233;s et annot&#233;s manuellement. Un premier corpus a &#233;t&#233;
fourni avant l&#8217;&#233;valuation, compos&#233; de 350 documents. Puis, les organisateurs d&#8217;i2b2 ont fourni le corpus d&#8217;&#233;valuation, qui comporte
477 documents.
</p>
<p>Nous pr&#233;sentons dans une premi&#232;re partie les relations que nous devons identifier, dans une deuxi&#232;me partie le corpus et nous
terminons par les r&#233;sultats des tests.
</p>
<p>4.1 Relations consid&#233;r&#233;es
</p>
<p>La t&#226;che consistait &#224; annoter dans les comptes-rendus les relations existant entre deux concepts. Les concepts consid&#233;r&#233;s &#233;taient les
suivants :
&#8211; les probl&#232;mes m&#233;dicaux : les observations des patients ou cliniciens concernant ce qui n&#8217;allait pas ou semblait &#234;tre caus&#233; par une
</p>
<p>maladie. Cette cat&#233;gorie comprend notamment les maladies, syndromes, signes, et sympt&#244;mes, les observations sur l&#8217;&#233;tat mental
du patient, les r&#233;sultats anormaux de tests etc. ;
</p>
<p>&#8211; les traitements : les proc&#233;dures, interventions, substances et m&#233;dicaments donn&#233;s &#224; un patient pour tenter de r&#233;soudre un probl&#232;me
m&#233;dical ;
</p>
<p>&#8211; les tests : les proc&#233;dures et examens effectu&#233;s sur un patient ou un fluide corporel pour v&#233;rifier ou infirmer la pr&#233;sence d&#8217;un
probl&#232;me, ou pour avoir plus d&#8217;informations sur un probl&#232;me.
</p>
<p>Ces concepts peuvent &#234;tre reli&#233;s par des relations, par exemple un examen a pu &#234;tre prescrit pour analyser un probl&#232;me m&#233;dical,
il peut &#233;galement r&#233;v&#233;ler un probl&#232;me. Nous avons cherch&#233; &#224; extraire ces relations dans les documents du corpus. Afin d&#8217;&#233;tudier
sp&#233;cifiquement l&#8217;extraction des relations, les documents sur lesquels nous avons travaill&#233; comportaient d&#233;j&#224; l&#8217;annotation de r&#233;f&#233;rence
des concepts 8, et il s&#8217;agissait donc de d&#233;terminer si, &#233;tant donn&#233; deux concepts, ils &#233;taient en relation, et si oui, quel &#233;tait le type de
la relation.
</p>
<p>Trois ensembles de relations ont &#233;t&#233; d&#233;finis :
</p>
<p>&#8211; relations entre probl&#232;me et traitement :
&#8211; le traitement am&#233;liore le probl&#232;me (TrIP)
</p>
<p>Exemple : &#171;&lt;pb&gt;hypertension&lt;/pb&gt; was controlled on &lt;treat&gt;hydrochlorothiazide&lt;/treat&gt;&#187;
&#8211; le traitement aggrave le probl&#232;me (TrWP), ce qui inclut les cas o&#249; le traitement est administr&#233; pour le probl&#232;me mais ne
</p>
<p>l&#8217;am&#233;liore pas
Exemple : &#171;&lt;pb&gt;the tumor&lt;/pb&gt; was growing despite the available &lt;treat&gt;chemotherapeutic regimen&lt;/treat&gt;&#187;
</p>
<p>8. Dans les exemples pr&#233;sent&#233;s dans l&#8217;article nous annotons les probl&#232;mes m&#233;dicaux avec la balise &lt;pb&gt;, les tests avec la balise &lt;test&gt; et les traitements avec la
balise &lt;treat&gt;</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>APPORT DE LA SYNTAXE POUR L&#8217;EXTRACTION DE RELATIONS EN DOMAINE M&#201;DICAL
</p>
<p>&#8211; le traitement cause le probl&#232;me (TrCP)
Exemple : &#171;&lt;treat&gt;Bactrim&lt;/treat&gt; could be a cause of &lt;pb&gt;these abnormalities&lt;/pb&gt;.&#187;
</p>
<p>&#8211; le traitement est administr&#233; en raison du probl&#232;me (TrAP)
Exemple : &#171;&lt;treat&gt;antibiotic therapy&lt;/treat&gt; for presumed &lt;pb&gt;right forearm phlebitis&lt;/pb&gt;&#187;
</p>
<p>&#8211; le traitement n&#8217;est pas administr&#233; en raison du probl&#232;me (TrNAP)
Exemple : &#171;&lt;treat&gt;Relafen&lt;/treat&gt; which is contra-indicated because of &lt;pb&gt;ulcers&lt;/pb&gt;.&#187;
</p>
<p>&#8211; relations entre probl&#232;me et test :
&#8211; le test r&#233;v&#232;le le probl&#232;me (TeRP), et plus g&#233;n&#233;ralement les tests men&#233;s accompagn&#233;s de leurs r&#233;sultats
</p>
<p>Exemple : &#171;&lt;test&gt;an echocardiogram&lt;/test&gt; revealed &lt;pb&gt;a pericardial effusion&lt;/pb&gt;&#187;
&#8211; le test est conduit en raison du probl&#232;me (TeCP)
</p>
<p>Exemple : &#171;&lt;test&gt;an VQ scan&lt;/test&gt; was performed to investigate &lt;pb&gt;pulmonary embolus&lt;/pb&gt;&#187;
&#8211; relations entre probl&#232;me et probl&#232;me
</p>
<p>&#8211; un probl&#232;me en indique un autre (PIP), incluant les cas o&#249; des probl&#232;mes r&#233;v&#232;lent diff&#233;rents aspects d&#8217;un m&#234;me probl&#232;me
m&#233;dical
Exemple : &#171;a history of &lt;pb&gt;noninsulin dependent diabetes mellitus&lt;/pb&gt;, now presenting with &lt;pb&gt;acute blurry vision on the
left side&lt;/pb&gt;.&#187;
</p>
<p>Le tableau 1 indique le nombre de relations par cat&#233;gorie dans le corpus d&#8217;entra&#238;nement et d&#8217;&#233;valuation, ainsi que l&#8217;accord inter-
annotateur 9. Nous observons que l&#8217;accord inter-annotateur est faible pour certaines cat&#233;gories comme TrIP et TrWP.
</p>
<p>Relation entra&#238;nement &#233;valuation accord inter-annotateur
TrIP 107 198 0,62
</p>
<p>TrWP 56 143 0,58
TrCP 296 444 0,82
TrAP 1423 2487 0,95
</p>
<p>TrNAP 106 191 0,76
PIP 1239 1986 0,79
</p>
<p>TeRP 1734 3033 0,96
TeCP 303 588 0,74
Toutes 5264 9070
</p>
<p>TABLE 1 &#8211; Nombre de relations par cat&#233;gorie dans chaque corpus
</p>
<p>4.2 Corpus
</p>
<p>Sur le corpus d&#8217;entra&#238;nement (350 documents) la taille moyenne des phrases contenant au moins deux concepts est de 16,78
mots/phrase (les signes de ponctuation ne sont pas compt&#233;s comme des mots). La phrase la plus courte contient deux mots, la
phrase la plus longue 212 et la m&#233;diane est situ&#233;e &#224; 15 mots/phrase. (Coden et al., 2005) compare la taille moyenne des phrases de
trois corpus, le premier est un extrait du Penn TreeBank (compos&#233; d&#8217;articles de journaux), le second le corpus GENIA (compos&#233; de
r&#233;sum&#233; de MedLine) et le troisi&#232;me est le corpus MED compos&#233; de rapports clinique. Les tailles moyenne des phrases de ces trois
corpus ainsi que du corpus pour la campagne i2b2 2010 que nous utilisons sont r&#233;pertori&#233;es dans le tableau 2. Ces donn&#233;es montrent
que le corpus sur lequel nous travaillons est compos&#233; de phrases courtes, compar&#233; au corpus GENIA. En effet les documents type
rapport clinique sont compos&#233;s de beaucoup de fragments de phrase (e.g. 1) et d&#8217;&#233;num&#233;rations (e.g. 2) ce qui fait leur particularit&#233;.
</p>
<p>taille moyenne des phrases
Penn Treebank 24,16
</p>
<p>MED 13,79
GENIA 27,18
</p>
<p>i2b22010 corpus 16,78
</p>
<p>TABLE 2 &#8211; Taille moyenne des phrases de diff&#233;rents corpus
</p>
<p>(1) &lt;pb&gt;C5-6 disc herniation&lt;/pb&gt; with &lt;pb&gt;cord compression&lt;/pb&gt; and &lt;pb&gt;myelopathy&lt;/pb&gt; .
</p>
<p>9. L&#8217;accord inter-annotateur nous a &#233;t&#233; fourni par les organisateurs, il a &#233;t&#233; calcul&#233; &#224; partir de Knowtator.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ANNE-LYSE MINARD, ANNE-LAURE LIGOZAT, BRIGITTE GRAU
</p>
<p>(2) Revealed &lt;pb&gt;icteric sclerae&lt;/pb&gt; , &lt;pb&gt;the oropharynx with extensive thrush&lt;/pb&gt; , and &lt;pb&gt;an ulcer under his tongue&lt;/pb&gt;
.
</p>
<p>4.3 Pr&#233;traitement du corpus
</p>
<p>Les fichiers du corpus ont &#233;t&#233; pr&#233;trait&#233;s et normalis&#233;s. Tout d&#8217;abord, les abr&#233;viations connues ont &#233;t&#233; remplac&#233;es par leur forme
compl&#232;te, gr&#226;ce &#224; une liste. La liste a &#233;t&#233; constitu&#233;e pour la campagne d&#8217;&#233;valuation i2b2 2009 10 &#224; partir de la liste d&#8217;abr&#233;viations
biom&#233;dicales form&#233;e par Berman 11 &#224; laquelle ont &#233;t&#233; ajout&#233;s les exemples du corpus du challenge i2b2 2009. Ainsi, h.o. a &#233;t&#233;
converti en history of et p.r.n. en as needed. Puis, les donn&#233;es d&#8217;anonymisation (diff&#233;rentes pour chaque corpus) ont &#233;t&#233; remplac&#233;es
par des balises NAME, DATE et AGE. NUM remplace toutes les valeurs num&#233;riques pr&#233;sentes dans les fichiers (principalement des
dosages). Enfin, les textes ont &#233;t&#233; &#233;tiquet&#233;s par le TreeTagger et analys&#233;s par le parser de Charniak/McClosky.
</p>
<p>4.4 Tests et r&#233;sultats
</p>
<p>4.4.1 Syst&#232;me : sans information syntaxique
</p>
<p>Nous avons d&#8217;abord &#233;valu&#233; l&#8217;approche vectorielle avec les attributs de base d&#233;crits dans la section 3.2. Les r&#233;sultats sont donn&#233;s dans
le tableau 3. Les r&#233;sultats de la ligne Toutes relations sont la pr&#233;cision moyenne, le rappel moyen et la F-mesure moyenne pour la
classification de toutes les relations. Nous avons utilis&#233; ce syst&#232;me pour la campagne d&#8217;&#233;valuation i2b2. Nous obtenons une F-mesure
de 0,703, ce qui nous permet de nous placer troisi&#232;me sur seize participants (Minard et al., 2011a).
</p>
<p>Relation Pr&#233;cision Rappel F-mesure
TrIP 0,852 0,146 0,250
TrWP 0,000 0,000 0,000
TrCP 0,735 0,362 0,485
TrAP 0,743 0,689 0,715
TrNAP 0,461 0,062 0,110
PIP 0,781 0,530 0,632
TeRP 0,876 0,832 0,853
TeCP 0,870 0,251 0,390
Toutes relations 0,807 0,622 0,703
M&#233;diane 0,664
1er syst&#232;me 0,720 0,753 0,736
2e syst&#232;me 0,773 0,693 0,731
</p>
<p>TABLE 3 &#8211; Pr&#233;cision, rappel et F-mesure obtenus sur le corpus d&#8217;&#233;valuation avec le syst&#232;me de base
</p>
<p>4.4.2 Syst&#232;me : avec des informations syntaxiques sous forme vectorielle
</p>
<p>Nous avons voulu voir si l&#8217;ajout d&#8217;informations syntaxiques am&#233;liorerait la classification des relations. Pour cela nous avons calcul&#233;
des informations &#224; partir de l&#8217;arbre de constituants produit par l&#8217;analyseur Charniak/McClosky, que nous avons ajout&#233;es aux attributs
de base. Il s&#8217;agit de la taille du chemin entre le premier concept et le deuxi&#232;me concept, et du nom du constituant du n&#339;ud racine du
sous-arbre minimal. Ce syst&#232;me obtient une F-mesure de 0,700. Les r&#233;sultats d&#233;taill&#233;s sont pr&#233;sent&#233;s dans le tableau 4.
</p>
<p>4.4.3 Syt&#232;me &#224; base de tree kernels
</p>
<p>L&#8217;ajout d&#8217;attributs n&#8217;am&#233;liorant pas la classification, nous avons test&#233; l&#8217;ajout d&#8217;informations structurelles plus importantes que les
deux attributs pr&#233;c&#233;dents. Pour cela nous avons utilis&#233; le classifieur SVM-Light-TK bas&#233; sur des tree kernels. Comme certaines
</p>
<p>10. https ://www.i2b2.org/NLP/Medication/
11. http ://www.julesberman.info/abbtwo.htm</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>APPORT DE LA SYNTAXE POUR L&#8217;EXTRACTION DE RELATIONS EN DOMAINE M&#201;DICAL
</p>
<p>Relation Pr&#233;cision Rappel F-mesure
TrIP 0,875 0,141 0,243
TrWP 0,000 0,000 0,000
TrCP 0,733 0,360 0,483
TrAP 0,741 0,684 0,712
TrNAP 0,444 0,062 0,110
PIP 0,776 0,525 0,626
TeRP 0,877 0,833 0,854
TeCP 0,869 0,248 0,386
Toutes relations 0,806 0,619 0,700
</p>
<p>TABLE 4 &#8211; Pr&#233;cision, rappel et F-mesure obtenus sur le corpus d&#8217;&#233;valuation avec le syst&#232;me utilisant des informations syntaxiques
sous forme vectorielle
</p>
<p>relations ne sont pas suffisamment repr&#233;sent&#233;es dans le corpus, nous n&#8217;avons pas fait de classification multi-classes avec SVM-Light-
TK. En effet pour 5 des 8 relations (TrIP, TrWP, TrNAP, TrCP et TeCP), le classifieur ne d&#233;tectait pas de relation. Les &#233;valuations
que nous avons faites portent donc sur de la classification entre relation et non-relation, c&#8217;est-&#224;-dire de la d&#233;tection de relation.
</p>
<p>Nous avons ajout&#233; les arbres de constituants complets ainsi que les sous-arbres minimaux complets entre les deux entit&#233;s possible-
ment en relation et les sous-arbres minimaux (c.f. 3.3), pour &#233;valuer si d&#8217;autres informations contenues dans les arbres pouvaient
&#234;tre utilis&#233;es pour la d&#233;tection des relations.
</p>
<p>Les arbres complets contiennent des informations suppl&#233;mentaires par rapport aux sous-arbres minimaux. Dans les informations
supprim&#233;es, il y a du bruit qui peut g&#234;ner la classification, mais il y a &#233;galement des d&#233;clencheurs des relations. Il semble donc per-
tinent d&#8217;utiliser les deux types d&#8217;arbres pour avoir le maximum d&#8217;informations. Les sous-arbres minimaux contiennent en moyenne
la moiti&#233; du nombre de mots de l&#8217;arbre complet. Plus pr&#233;cis&#233;ment les arbres complets ont un nombre moyen de mots par phrase de
21 12 (sans compter la ponctuation, et en comptant les concepts comme un seul mot), et un nombre moyen de n&#339;uds de 48. Alors
que les sous-arbres minimaux ont un nombre moyen de mots de 8 et un nombre moyen de n&#339;uds de 22.
</p>
<p>Nous avons &#233;valu&#233; plusieurs combinaisons &#224; partir des arbres de constituants complets (AC), des sous-arbres minimaux complets
(AMC), des sous-arbres minimaux (AM) et des attributs du syst&#232;me de base (ATT). Les r&#233;sultats sont pr&#233;sent&#233;s dans le tableau 5 et
dans la figure 6.
</p>
<p>Combinaison Pr&#233;cision Rappel F-mesure
AC 0,749 0,611 0,673
</p>
<p>AMC 0,623 0,726 0,651
AM 0,819 0,625 0,709
ATT 0,835 0,709 0,767
</p>
<p>AC + AM 0,790 0,708 0,747
AC + ATT 0,826 0,731 0,776
</p>
<p>AMC + ATT 0,832 0,729 0,773
AM + ATT 0,828 0,724 0,772
</p>
<p>AC + AM + ATT 0,776 0,804 0,790
AMC + AM + ATT 0,819 0,727 0,770
AC + AMC + ATT 0,818 0,726 0,769
</p>
<p>AC + AMC + AM + ATT 0,816 0,730 0,771
</p>
<p>TABLE 5 &#8211; &#201;valuation des combinaisons des diff&#233;rents apprentissages &#224; base de tree kernels pour la d&#233;tection de relations
</p>
<p>Ces r&#233;sultats nous montrent que l&#8217;information contenue dans les arbres seule n&#8217;est pas suffisante pour la classification des relations
quel que soit l&#8217;arbre utilis&#233;. De plus la combinaison des arbres minimaux et des arbres complets apportent des meilleurs r&#233;sultats
que les arbres complets seuls, mais la F-mesure n&#8217;atteint pas celle obtenue avec les attributs de base seuls. Les attributs apportent
donc des informations suppl&#233;mentaires par rapport aux arbres. Dans cette &#233;tude nous n&#8217;avons pas &#233;valu&#233; l&#8217;apport de chaque attribut
vectoriel mais il serait int&#233;ressant de savoir quelles donn&#233;es ne sont pas fournies par les arbres mais sont donn&#233;es par les attributs.
</p>
<p>12. Le nombre de mots par phrase est diff&#233;rent de celui donn&#233; dans la section 4.2 car nous avons un arbre par couple de concepts, c&#8217;est-&#224;-dire que si une phrase
contient trois concepts, nous avons trois arbres dans le corpus.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ANNE-LYSE MINARD, ANNE-LAURE LIGOZAT, BRIGITTE GRAU
</p>
<p>Feuille1
</p>
<p>Page 1
</p>
<p>Combinaison Pr&#233;cision Rappel F-mesure
AC 0,749 0,611 0,673
AMC 0,623 0,726 0,651
AM 0,819 0,625 0,709
ATT 0,835 0,709 0,767
AC+AM 0,79 0,708 0,747
AC+ATT 0,826 0,731 0,776
AMC+ATT 0,832 0,729 0,773
AM+ATT 0,828 0,724 0,772
AC+AM+ATT 0,776 0,804 0,79
AMC+AM+ATT 0,819 0,727 0,77
AC+AMC+ATT 0,818 0,726 0,769
AC+AMC+AM+ATT 0,816 0,73 0,771
</p>
<p>A
C
</p>
<p>A
M
</p>
<p>C
</p>
<p>A
M
</p>
<p>A
T
</p>
<p>T
</p>
<p>A
C
</p>
<p>+A
M
</p>
<p>A
C
</p>
<p>+A
T
</p>
<p>T
</p>
<p>A
M
</p>
<p>C
+A
</p>
<p>T
T
</p>
<p>A
M
</p>
<p>+A
T
</p>
<p>T
</p>
<p>A
C
</p>
<p>+A
M
</p>
<p>+A
T
</p>
<p>T
</p>
<p>A
M
</p>
<p>C
+A
</p>
<p>M
+A
</p>
<p>T
T
</p>
<p>A
C
</p>
<p>+A
M
</p>
<p>C
+A
</p>
<p>T
T
</p>
<p>A
C
</p>
<p>+A
M
</p>
<p>C
+A
</p>
<p>M
+A
</p>
<p>T
T
</p>
<p>0,5
</p>
<p>0,55
</p>
<p>0,6
</p>
<p>0,65
</p>
<p>0,7
</p>
<p>0,75
</p>
<p>0,8
</p>
<p>0,85
</p>
<p>0,9
</p>
<p>Pr&#233;cision
Rappel
F-mesure
</p>
<p>FIGURE 6 &#8211; Comparaison des diff&#233;rents apprentissages
</p>
<p>Nous observons &#233;galement que la meilleure combinaison est celle associant les arbres complets, les sous-arbres minimaux et les
attributs (AC + AM + ATT). Les sous-arbres minimaux complets n&#8217;apportent pas d&#8217;informations suppl&#233;mentaires. En effet ils
apportent moins d&#8217;information que les arbres complets (la F-mesure pour AC + AM + ATT est de 0,790 et pour AMC + AM +
ATT de 0,770), et plus d&#8217;informations bruit&#233;es que les arbres minimaux r&#233;duits (la F-mesure pour AC + AMC + ATT est de 0,771,
contre 0,790 avec les arbres minimaux).
</p>
<p>Nous avons effectu&#233; une premi&#232;re &#233;tude des relations d&#233;tect&#233;es avec les attributs seuls et avec les attributs plus les arbres complets
(AC + ATT). Nous avons observ&#233; que les arbres &#233;taient utilis&#233;s pour d&#233;tecter les relations entre des concepts &#233;loign&#233;s dans la
phrase. Les relations correctement d&#233;tect&#233;es avec (AC + ATT) mais qui ne le sont pas avec (ATT) concernent deux concepts dont
l&#8217;&#233;loignement moyen est de 10,8 mots (ou ponctuations), alors que celles qui sont correctement class&#233;es par les deux syst&#232;mes
concernent des concepts qui sont s&#233;par&#233;s en moyenne par 5,4 mots (ou ponctuations). Dans la figure 7 nous montrons une phrase
contenant une relation de type PIP (un probl&#232;me indique un autre probl&#232;me) entre increased tracer activity et active bleeding ; les
concepts sont s&#233;par&#233;s par 17 mots ou ponctuations. Cette relation a &#233;t&#233; correctement d&#233;tect&#233;e lorsque les arbres &#233;taient utilis&#233;s, mais
elle n&#8217;est pas rep&#233;r&#233;e avec l&#8217;utilisation des attributs seuls.
</p>
<p>FIGURE 7 &#8211; Exemple de l&#8217;arbre complet d&#8217;une phrase contenant deux concepts reli&#233;s par une relation de type PIP</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>APPORT DE LA SYNTAXE POUR L&#8217;EXTRACTION DE RELATIONS EN DOMAINE M&#201;DICAL
</p>
<p>5 Conclusion
</p>
<p>Dans cet article nous nous sommes int&#233;ress&#233;es &#224; l&#8217;extraction de relations en domaine de sp&#233;cialit&#233;. Nous avons d&#233;velopp&#233; un syst&#232;me
de d&#233;tection et typage de relations fond&#233; sur une classification automatique, qui obtient une F-mesure d&#8217;environ 0,7. L&#8217;apport d&#8217;in-
formations syntaxiques &#224; ce syst&#232;me a ensuite &#233;t&#233; &#233;valu&#233;. Les informations syntaxiques tr&#232;s simples ajout&#233;es sous forme vectorielle
n&#8217;ont pas am&#233;lior&#233; la classification ; en revanche, l&#8217;utilisation des structures syntaxiques avec les tree kernels am&#233;liore la d&#233;tection
des relations, les meilleurs r&#233;sultats &#233;tant obtenus avec une combinaison de l&#8217;arbre complet, le sous-arbre minimal et les attributs de
base (augmentation de 3% de la F-mesure).
</p>
<p>Il serait int&#233;ressant de poursuivre cette &#233;tude en faisant une classification multi-classes, pour &#233;valuer l&#8217;apport des informations
syntaxiques pour le typage des relations, ce qui n&#233;cessiterait d&#8217;augmenter le corpus d&#8217;entra&#238;nement, ou d&#8217;&#233;tendre l&#8217;&#233;tude &#224; d&#8217;autres
corpus de sp&#233;cialit&#233;.
</p>
<p>Remerciements
</p>
<p>Ce travail a &#233;t&#233; partiellement financ&#233; par OSEO dans le cadre du programme Qu&#230;ro.
</p>
<p>R&#233;f&#233;rences
</p>
<p>CHANG C.-C. &amp; LIN C.-J. (2001). LIBSVM : a library for support vector machines. Software available at
http ://www.csie.ntu.edu.tw/&#8764;cjlin/libsvm.
CODEN A. R., PAKHOMOV S. V., ANDO R. K., DUFFY P. H. &amp; CHUTE C. G. (2005). Domain-specific language models and
lexicons for tagging. Journal of Biomedical Informatics, 38, 422&#8211;430.
CULOTTA A. &amp; SORENSEN J. (2004). Dependency tree kernels for relation extraction. In in Proceedings of the 42nd Annual
Meeting on Association for Computational Linguistics.
</p>
<p>HSU C.-W., CHANG C.-C. &amp; LIN C.-J. (2003). A Practical Guide to Support Vector Classification. Rapport interne, Department
of Computer Science, National Taiwan University.
</p>
<p>MCCLOSKY D. (2010). Any domain parsing : Automatic domain adaptation for natural language parsing. PHD Thesis, Department
of Computer Science, Brown University.
</p>
<p>MINARD A.-L., LIGOZAT A.-L., BEN ABACHA A., BERNHARD D., CARTONI B., DEL&#201;GER L., GRAU B., ROSSET S., ZWEI-
GENBAUM P. &amp; GROUIN C. (2011a). Hybrid methods for improving information access in clinical documents : Concept, assertion,
and relation identification. Journal of the American Medical Informatics Association. &#192; para&#238;tre.
</p>
<p>MINARD A.-L., LIGOZAT A.-L. &amp; GRAU B. (2011b). Extraction de relations dans des comptes rendus hospitaliers. In Actes des
22&#232;mes Journ&#233;es francophones d&#8217;Ing&#233;nierie des Connaissances (IC&#8217;2011).
</p>
<p>MOSCHITTI A. (2006). Making tree kernels practical for natural language learning. In In Proceedings of the Eleventh International
Conference on European Association for Computational Linguistics (EACL), Trento, Italy, 2006.
</p>
<p>ROBERTS A., GAIZAUSKAS R. &amp; HEPPLE M. (2008). Extracting clinical relationships from patient narratives. In Proceedings of
the Workshop on Current Trends in Biomedical Natural Language Processing, BioNLP &#8217;08, p. 10&#8211;18.
</p>
<p>SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings of the International Conference on
New Methods in Language Processing, p. 44&#8211;49.
</p>
<p>UZUNER O., MAILOA J., RYAN R. &amp; SIBANDA T. (2010). Semantic relations for problem-oriented medical records. Artificial
Intelligence in Medicine, 50, 63&#8211;73.
ZELENKO D., AONE C. &amp; RICHARDELLA A. (2003). Kernel methods for relation extraction. Journal of Machine Learning
Research, 3, 1083&#8211;1106.
ZHANG M., ZHANG J. &amp; SU J. (2006). Exploring syntactic features for relation extraction using a convolution tree kernel. In
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, p. 288&#8211;295.
</p>
<p>ZHOU G., SU J., ZHANG J. &amp; ZHANG M. (2005). Exploring various knowledge in relation extraction. In Proceedings of the 43rd
Annual Meeting of the ACL, p. 427&#8211;434.</p>

</div></div>
</body></html>