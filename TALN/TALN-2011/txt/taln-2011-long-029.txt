TALN 2011, Montpellier, 27juin — 1°’ju1'11et 2011

Classiﬁcation en polarité de sentiments avec une représentation textuelle
a base de sous-graphes d’arbres de dépendances

Alexander Pak, Patrick Paroubek
alexpak@limsi.fr, pap@limsi.fr
Université de Paris-Sud, Laboratoire LIlVISI-CNRS, Batiment 508,
F-91405 Orsay Cedex, France

Résumé. Les approches classiques a base de n-grammes en analyse supervisée de sentiments ne peuvent
pas correctement identiﬁer les expressions complexes de sentiments a cause de la perte d’information induite par
1’ approche << sac de mots » utilisée pour représenter les textes. Dans notre approche, nous avons recours a des sous-
graphes extraits des graphes de dépendances syntaxiques comme traits pour la classiﬁcation de sentiments. Nous
représentons un texte par un vecteur compose de ces sous-graphes syntaxiques et nous employons un classiﬁeurs
SVM état—de—l’art pour identiﬁer la polarité d’un texte. Nos evaluations expérimentales sur des critiques de jeux
video montrent que notre approche a base de sous-graphes est meilleure que les approches standard a modeles
<< sac de mots » et n-grammes. Dans cet article nous avons travaillé sur le frangais, mais notre approche peut
facilement etre adaptée a d’autres langues.

Abstract. A standard approach for supervised sentiment analysis with n—grarns features cannot correctly
identify complex sentiment expressions due to the loss of information incurred when representing texts with bag-
of-words models. In our research, we propose to use subgraphs from sentence dependency parse trees as features
for sentiment classiﬁcation. We represent a text by a feature vector made from extracted subgraphs and use a state
of the art SVM classiﬁer to identify the polarity of a text. Our experimental evaluations on video game reviews
show that using our dependency subgraph features outperforms standard bag—of—words and n—gram models. In this
paper, we worked with French, however our approach can be easily adapted to other languages.

M0tS-CléS 3 analyse de sentiments, analyse syntaxique, arbre de dépendances, SVM.

Keywords: sentiment analysis, parsing, dependency tree, SVM.

ALEXANDER PAK, PATRICK PAROUBEK

1 Introduction

L’ approche << sac de mots » est un des premiers modeles de representation textuelle, qui est de nos jour encore
souvent utilise pour l’analyse de sentiments. Le texte y est représenté comme un ensemble de n—gra1nmes sans
prise en consideration de leur ordre d’apparition dans le texte, ni des relations qui les relient au sein du texte. Des
approches classiques en apprentissage automatique (Naive Bayes or SVM) utilisent ensuite cette representation
pour construire des systemes de classiﬁcation en sentiments des textes. L’ exactitudel de ce genre d’approche
peut etre tres élevée, tout particulierement lorsque l’on utilise des techniques avancées de selection de traits, en
conjonction avec des lexiques additionnels extraits de textes identiﬁes au préalable comme porteur d’opinion.
Cependant, nous sommes convaincus que des modeles capables d’identiﬁer des expressions plus complexes de
sentiments, allant au dela de la simple reconnaissance de construction comme << bon ﬁlm » ou << jeu deplorable »,
doivent permettre d’obtenir de meilleurs systemes de classiﬁcation. Un des problemes de l’approche sac de mots
reside dans la perte d’information lors de la construction de la representation des textes, vus comme des collections
de termes dissociés. Or les relations qu’entretiennent les mots au sein du texte sont souvent tres importantes dans
la determination precise du degré ou de la polarité d’un sentiment. Si nous considérons la phrase : << Ce ﬁlm est
mauvais », elle exprime de maniere évidente un sentiment négatif et un systeme de classiﬁcation standard a base
d’unigrammes n’aura pas de mal a la classer comme negative, pourvu qu’il ait ete sufﬁsamment entrainé sur des
données appropriées. Dans le cas d’un enoncé un peu plus complexe comme : << Ce ﬁlm n’est pas mauvais »,
un modele unigramme simple sera probablement mis en echec, mais un modele utilisant des bigrammes sera
lui capable de detecter l’occurrence de << pas mauvais » comme un terme a connotation positive. Considérons
maintenant un exemple encore plus complexe comme : << Ce ﬁlm est étonnamment pas si mal » et la les systemes
a base d’unigrammes et de bigrammes vont probablement se tromper. Dans cet exemple, il faudrait qu’ils soient
associés a un traitement plus sophistiqué de la negation.

En plus d’etre incapables de prendre en compte toutes les expressions de negation, les modeles n-grammes sont
incapables de représenter les dépendances longue distance. Un modele de bigrammes pourra identiﬁer << J ’ai
apprécié » comme un motif a connotation positive dans l’enonce « J ’ai apprécié le ﬁlm », mais pas dans << J ’ai
beaucoup apprécié le ﬁlm ». Nous pensons qu’il faut recourir a d’autres modeles que le modele sac de mots si
nous voulons progresser dans l’identiﬁcation automatique des sentiments en utilisant une classiﬁcation plus ﬁne,
qui rende par exemple compte de l’intensité d’un sentiment en plus de sa polarité, car les modeles sac de mots ne
nous foumissent pas assez d’information.

Pour aller au dela des modeles sac de mots, nous proposons d’utiliser les arbres de dépendances issus de l’analyse
syntaxique des phrases pour générer des sous—graphes, qui serviront a représenter un texte. Un arbre de depen-
dances est une representation graphique associée a une phrase, dans laquelle les noeuds correspondent aux mots
de la phrase et les arcs representent des relations syntaxiques e11tre les noeuds comme : objet, sujet, modiﬁeur etc.
La Figure 1 représente un arbre de dépendance syntaxique pour la phrase << Je n’aime pas beaucoup le poisson ».
Une telle representation des phrases est parfaitement adaptée a l’analyse de sentiment voire meme a la fouille
d’opinion car :

— A partir de l’arbre de dépendances, nous pouvons facilement identiﬁer le sous-graphe contenant la negation

<< ne  ) ai1ne ».
— Nous pouvons identiﬁer les marqueurs d’intensité : << beaucoup  > aime »

- . . . SUBJ . . . . .
— De meme pour la source d’une expression d’opm1on : << J e —) aime » et la c1ble d’une expression op1n1on :
. OBJ .
<< aime ?) po1sson »

Comme pour les modeles a base de n—gra1nmes, notre approche utilise un parametre de taille pour calibrer les
sous—graphes extraits des arbres de dépendance pour représenter un texte. Nous posons que la taille d’un sous-
graphe est égale au nombre de ses arcs. Ainsi, un sous graphe de taille l contiendra un arc et deux noeuds, un sous
graphe de taille 2 contiendra 2 arcs et 3 noeuds, etc. La Figure 2 contient la representation de l’énoncé << J ’aime
bien le poisson » au moyen de sous—graphes de taille 2.

Dans la section suivante, nous expliquons en details comment obtenir la representation a base de sous—graphes
d’un texte a partir des arbres de dépendances syntaxiques qui lui sont associés. Ensuite, nous montrons comment
utiliser cette representation pour indexer des critiques de jeux video et pour entrainer un classiﬁeur en polarité de
sentiments a base de SVM. Nous presentons notre protocole d’ evaluation et les résultats obtenus par notre modele

1. accuracy

SENTIMENT POLARITY CLASSIFICATION USING DEPENDENCY TREE SUBGRAPHS TEXT REPRESENTATION

WHITELAW C., GARG N. & ARGAMON S. (2005). Using appraisal groups for sentiment analysis. In Pro-

ceedings of the 14th ACM international conference on Information and knowledge management, CIKM ’05, p.
625-631, New York, NY, USA : ACM.

ZHUANG L., J ING F. & ZHU X.—Y. (2006). Movie review mining and summarization. In Proceedings of the
15th ACM international conference on Information and knowledge management, CIKM ’06, p. 43-50, New

York, NY, USA : ACM.

Annexe A. Liste des dépendences produites par XIP

ADJMOD
ADJMOD_POSIT1
ADJMOD_PROPQUE

ADVMOD
AUXIL_PASSIVE

CONNECT
CONNECT_REL
CONNECT_SUBJ

COORD
COORDITEMS
COORDITEMS_SC

COREF_POSITl_REL
COREF_REL

DATE*
DATE_PERIODE*

DEEPOBJ

DEEPSUBJ
DEEPSUBJ_PASSIVE
DEEPSUBJ_PROPQUE

DETERM
DETERM_DEF
DETERM_DEM
DETERM_INT
DETERM_NUM
DETERM_POSS
DETERM_QUANT
DETERM_QUANT_DEF
DETERM_QUANT_DEM

LIEU*

LIEU_BATIMENT*
LIEU_CONTINENT*
LIEU_IMPERSO*
LIEU_PAYS*
LIEU_PAYS_REGION*
LIEU_QUARTIER*
LIEU_REGION*
LIEU_REGION_VILLE*
LIEU_VILLE*

NEGAT*
NEGAT_SUBJ
NMOD
NMOD_NUM

OBJ

ORG*

NMOD_POSIT1
NMOD_POSIT2
NMOD_POSIT3
NMOD_PROPQUE
NMOD_REL

OBJ_COORD
OBJ_COORD_SPRED
OBJ_PROPQUE
OBJ_PROPQUE_COORD
OBJ_PROPQUE_SPRED
OBJ_REL

OBJ_SPRED
OBJ_SUBJ

ORG_BATIMENT_LIEU*
ORG_ENTREPRISE*

PERSONNE*

PREPMOD

PREPOBJ_REL

SEQNP**

SUBJ
SUBJ_COORD
SUBJ_IMPERSO
SUBJ_IMPERSO_COORD
SUBJ_IMPERSO_PASSIVE
SUBJ_PASSIVE
SUBJ_PASSIVE_COORD
SUBJ_PASSIVE_PROPQUE
SUBJ_PASSIVE_REL
SUBJ_PROPQUE
SUBJ_REFLEXIVE
SUBJ_REL
SUBJ_REL_COORD
SUBJ_SUBJ

SUBJCLIT
SUBJCLIT_PASSIVE

URL *
VMOD

VMOD_COORD
VMOD_COORD_SPRED
VMOD_IMPERSO
VMOD_POSIT1
VMOD_POSIT1_SUBJ
VMOD_POSIT1_SUBORD
VMOD_POSIT2
VMOD_PROPQUE
VMOD_REL
VMOD_SPRED
VMOD_SUBJ
VMOD_SUBORD

Les relations sont marquees d’un astérisque (*), une sequence de relation SEQNP est marquee par (**).

SENTIMENT POLARITY CLASSIFICATION USING DEPENDENCY TREE SUBGRAPHS TEXT REPRESENTATION

be aucoup

V > 0D_POSITl

  

   

FIGURE 1 — Un arbre de dépendance syntaxique pour la phrase << J e n’aime pas beaucoup le poisson ». Les noeuds
représentent des mots , les arcs des relations entre les mots. Le mot «pas» ne ﬁgure pas explicitement dans le
diagramme, car il est encode par la relation de negation.

 

FIGURE 2 — Une representation de la phrase << J ’aime bien le poisson » avec des sous-graphes de taille 2. La
relation << determinant » contenant le noeud << le » a été écartée.

dans la Section 3, une presentation des recherches antérieures dans le domaine dans la Section 4 et la conclusion
sur nos travaux en section 5.

2 Notre approche

2.1 Représentation :71 base de sous-graphes de dépendances

Nous utilisons la sortie en dépendances typées de l’analyseur syntaxique Xerox Incremental Parser (XIP) (A'1't—
Mokhtar et al., 2002) pour construire l’arbre de dépendances de la phrase. La Table 1 contient un exemple de
dépendances produites par XIP.

SUBJ(VERB :aime, PRON :Je)

OBJ(VERB :aime, NOUN :poisson)
VMOD_POSITl(VERB :aime, ADV :beaucoup)
DETERM_DEF(NOUN :poisson, DET :le)
NEGAT(VERB :aime)

TABLE 1 — Les dépendances produites par XIP pour la phrase : << J e n’aime pas beaucoup le poisson »

Chaque ligne de la sortie de XIP contient une unique dépendance qui correspond a une description des relations
grammaticales entre les mots de la phrase (de Marnee & Manning, 2008). Chaque dépendance peut etre Vue

ALEXANDER PAK, PATRICK PAROUBEK

comme un triplet <Type, Source, Cible>, ou Type determine la relation grarnmaticale (ex. sujet, objet, etc.) entre
la Source et la Cible. La source et la cible sont representes comme des mots associes a leur etiquette grammati-
cale. XIP produit aussi des relations unaires, que nous catégorisons en deux types distincts, avec pour chacun un
traitement speciﬁque :

1. Négations (ex. NEGAT (VERB : aime) ) Nous transformons une relation unaire en relation ternaire par
l’ajout de la particule ’ne’ comme cible. Ainsi, nous obtenons : NEGAT (VERB : aime , NEG : ne)

2. Entités XIP reconnait et etiquette les entités telles que les noms de personnes, dates, temps, noms de lieux
etc. Ces informations n’etant pas utiles pour la detection des sentiments, elles sont ignorees.

Nous ecartons aussi la relation SEQNP, qui indique les enumerations dans les phrases ; ceci aﬁn de reduire la taille
de l’index, la suppression de cette relation n’ayant pas d’impact notoire sur nos resultats.

De l’ensemble de relations produit par XIP pour chaque énoncé, nous Voulons obtenir un arbre dans lequel chaque
noeud possede un sens completement determine. Dans notre exemple, un noeuds comme << ne » n’a pas de sens
intrinseque et le noeud << aime » possede un sens partiel (il lui manque la prise en compte de la negation dans
son interpretation). Par consequent, nous avons besoin de fusionner certains noeud et de retirer certaines relations.
Nous avons decide de reduire le nombre de relations avec lesquelles travailler, car XIP produit plus de 90 types de
relations (une liste complete est présentée en 5.).

2.1.1 Réduction du jeu de relations

Nous avons simpliﬁe le jeu de relations de dépendances en ne considérant que les classes generiques en appliquant
les regles d’assimilation de la Table 2.

NMOD_* —> NMOD les modiﬁeurs de nom (ante et post poses)
VMOD_* —> VMOD les djfférents modiﬁeurs de Verbe

SUBJ_* —> SUBJ les différents sujets

OBJ_* —> OBJ les djfférents complements d’objet directs
DEEPSUBJ* —> SUBJ le sujet profond est assimilé au sujet de surface

TABLE 2 — Regles de simpliﬁcation des relations de dépendances.

En outre, lors de la construction de l’arbre de dépendance, nous excluons certains arcs qui ne sont pas indispens-

ables a notre analyse :

, . . . DETERM_DEF . . .
— Les determinants, a1ns1 << le T) ﬁlm » deV1ent << ﬁlm », mais nous conservons les quantrﬁcateurs

(DETERM_NUM, DETERM_QUANT, DETERM_QUANT_DEF, DETERM_QUANT_DEM).

. . . DETERM_POSS . . .
— Les pronoms possess1fs, a1ns1 << mon T) l1Vre » deV1ent << l1Vre ».

— Les relations modiﬁeur de nom NMOD, lorsque la source et la cible sont tous deux des noms,

. . . NMOD_POSIT1 . . . .
a1ns1 << lime) cu1s1ne » deV1ent << hvre ».

Au ﬁnal, le jeu de relation de dependances que nous considérons pour notre analyse est donné en Table 3.

ADJMOD modiﬁeur d’adjectif
ADVMOD modiﬁeur d’ adverbe
DETERM_NUM determinant numerique
DETERM_QUANT quantiﬁcateur

NMOD modiﬁeur de nom

OBJ complement d’ obj et direct
SUBJ sujet (de surface ou profond)
VMOD modiﬁeur de Verbe

TABLE 3 — Jeu de relations de dépendances ﬁnal.

SENTIMENT POLARITY CLASSIFICATION USING DEPENDENCY TREE SUBGRAPHS TEXT REPRESENTATION

2.1.2 Combinaison de nmuds

Nous utilisons les regles suivantes pour combiner les noeuds :
— noeuds lies par la relation de negation (NEGAT), ainsi l’arc << ne LCW1> aime » devient un noeuds simple << ne

aime »
. . . . . . . AUXIL . , . . . ,
— Verbes auxihaires et pr1nc1paux (AUXIL), a1I1S1 l’arc << a E) aime » devient un noeuds simple << a aime »

— Verbes passifs, réﬂéchis et composes (AUXIL, AUXIL_PASSIVE, REFLEX, OBJ_SPRED,
COORDITEMS_SC)

Un exemple d’arbre issu de l’application des regles précédentes est donné dans la ﬁgure Figure 3.

poisson beaucoup

MOD

     
 

FIGURE 3 — Arbre de dépendance obtenu pour la phrase << J e n’aime pas beaucoup le poisson », apres combinaison
des noeuds et reduction des arcs.

Finalement, la phrase est représentée par un le jeu de tous les sous—graphes possibles pour une taille S’, ou S’ est
egal au nombre d’arc des sous—graphes. Dans nos experiences, nous avons utilise S’ = 1, 2, 3.

2.1.3 Naeud universel

La majorite des expressions de sentiment ont la meme structure grammaticale. Par exemple, dans les expressions
suivantes : << J ’aime le poisson » et << J ’aime le ﬁlm » seul l’obj et differe tandis que le reste de la construction reste
le meme. Nous aimerions entrainer notre systeme a reconnaitre ces expressions. Pour cela, nous avons aj outé un
noeud universel, representant la classe de tous les mots, dans les sous-graphes (Arora et al., 2010).

Pour chaque sous—graphe obtenu a l’ etape precedente, nous generons une permutation des sous—graphes contenants
plusieurs nombres (de 0 a S’ — 1) de noeuds universels. Pour ce faire, nous remplagons tout a tour chaque noeud
d’un sous-graphe par un noeud universel, sauf pour les Verbes, les adjectifs et les adverbes car ils peuvent exprimer
des sentiments. Par ailleurs, nous interdisons d’aVoir deux noeuds universels adjacents. Un exemple de l’emploi

. SUBJ . 03.1 . , . .
des noeuds un1Versels avec la phrase << Je —> aime —> poisson » est decrit dans la Figure 4.

©@

SUBJ OBJ UBJ OBJ UBJ BJ

FIGURE 4 — Sous—graphes avec noeud universel (X) obtenus pour << J ’aime le poisson »

ALEXANDER PAK, PATRICK PAROUBEK

2.2 Construction des vecteurs de traits

Nous représentons un texte donné T comme un vecteur de traits T = {w1, U22, - - - ,wK}, 011 w,- est le poid d’un
sous—graphe i dans le texte T et K est le nombre de sous—graphes dans T. Nous utilisons le schema de pondération
delta TFIDF lissé, car il a permis d’obtenir la meilleure performance dans des recherches antérieures (Paltoglou
& Thelwall, 2010).

“)7: = tfi ‘ Aidfi (1)

. N1 'df2+0.5
A d ,- =l m 2
“C °gN2-df1+0.5 ()

01) N1 et N2 représentent le nombre total de documents de classe 1 et 2, dfl et dfg sont des classes de frequences
du graphe 2' (c.a.d. le nombre de documents de classes 1 et 2 dans lesquelles le graphe apparait). Dans notre cas,
les classes 1 et 2 sont des documents positifs et negatifs.

3 Expériences et résultats

3.1 Les données

Nous utilisons des critiques de jeux video issues du projet DOXA 2, dont le but est la construction d’une plateforme
industrielle de fouille d’opinion.

Le corpus est constitué de critiques de jeux video provenant de 8 sites dédiés 3. Le corpus et ses annotations sont
décrites dans (Paroubek et al., 2010). Les annotations synthétisent les sentiments exprimés par les auteurs des
critiques au niveau du document et du paragraphe (déﬁnis arbitrairement comme un empan de texte d’environ 100
mots). Un exemple d’annotation est foumi dans la table 4.

| Attribut  Valeur |
catégorie sémantique une liste de 1 a 5 catégories d’ opinion DOXA, ex. « nec0mmandati0n_suggesti0n »
polarité —, :|:, +, neutre
intensité faible-moyen, fort
theme la cible de l’expression d’ opinion sélectionnée dans une taxonomie du domaine considéré
(une liste de 1 a 5 concepts)
lien lorsque plusieurs catégories sémantiques et plusieurs themes sont présents,
le lien peut étre fait entre certaines opinions s’ils sont plus particuliérement associés.
justiﬁcation référence au paragraphe/segment de texte qui représente au mieux l’opinion armotée

TABLE 4 — Annotation d’opinon DOXA au niveau document et paragraphe.

Dans les annotations DOXA, la polarité d’un sentiment est exprimée au moyen d’une échelle de six Valeurs :
neutre, trés—ne’gatiﬁ faible-moyen-négatif mixte, faible—moyen-positif fort—positzf. Nous avons sélectionné tous
les documents ayant une polarité positive (forst—positif etfaible—moyen—positif), ainsi que tous les documents avec
une polarite negative (fort—ne’gatif et faible—moyen—ne’gatif) que nous avons répartis dans deux classes distinctes.
Nous n’avons pas utilise les documents annotés comme neutre (pas d’expression de sentiment) ni ceux annote
mixte (qui contiennent a la fois des expressions positives et negatives, resultant en une interpretation mitigée).
Notre corpus contient donc 387 documents considerés a teneur positive et 250 a teneur negative. Nous avons
ensuite divisé le sous corpus des documents positifs en deux parties : un corpus d’entrainement et un corpus de
tests, en sélectionnant pour ce demier, tous les documents qui ont eté annotés par deux annotateurs. Le sous—corpus
négatif a subit le meme découpage. La Table 5 resume les caracteristiques de notre corpus.

2. https ://www.projet-doxa.fr/index.php
3. www.ccrans.fr, www.gamehope.com, www.gamepro.fr, www.jeuxactu.com, www.jeuxvideo.com, www.jeuxvideo.fr, www.play3-
live.com

SENTIMENT POLARITY CLASSIFICATION USING DEPENDENCY TREE SUBGRAPHS TEXT REPRESENTATION

| Classe  Entrainement | Tests |
Positif 334 53
Negatif 197 35
Total 531 88

TABLE 5 — Nombre de documents par classe

3.2 Evaluation

Nous avons entrainé un classiﬁeur SVM a base de n—grammes (Pang et al., 2002) avec un schéma de pondération
delta TFIDF (Paltoglou & Thelwall, 2010), que nous utilisons pour obtenir une mesure de performance de base.
Les négations ont été traitées en attachant la particule de négation successivement au mot qui la précéde et au
mot qui la suit lors de la génération des n-grammes (Pak & Paroubek, 2010). Nous avons généré trois types de
classieurs, respectivement a base de n—grammes, de bigrammes et de trigrammes.

De manieres similaire, pour notre modéle a base de sous—graphes de dépendances, nous avons utilisé trois types
de modéles, utilisant respectivement des sous—graphes de taille 1, 2 et 3.

Aussi bien pour le modele a n-gramme que pour notre modéle a sous—graphes de dépendances, nous avons utilisé
une implémentation libre de classiﬁeur SVM issue de la librairie LIBLINEAR (Fan et al., 2008), avec des Valeurs
de paramétre par défaut et un noyau linéaire. Le classiﬁeur a d’abord été entrainé sur un jeu de 531 documents puis
évalué sur un ensemble de 88 documents. L’ exactitude moyenne et la précision moyenne (Manning & Schiitze,
1999) ont été choisies comme mesures d’éValuation.

+1m
H d = WT 3
emaczue vp+vn+fp+fn ()
. . UP

preczszon = (4)

vp+fp

ou vp est le nombre de documents classés correctement comme positifs (vrais positifs), vn est le nombre de
document classés correctement comme étant négatifs (vrais négatifs), f p est le nombre de document incorrecte—
ment identiﬁés comme positifs (faux positifs) et f n est le nombre de document incorrectement identiﬁés comme
négatifs (faux négatifs).

3.3 Résultats

Les résultats de l’éValuation sont donnés dans la Table 6. Les mentions unigramme, bigramme et trigramme
correspondent respectivement aux trois modéles de base n— gramme, tandis que les mentions subgraph— 1, subgraph—
2 et subgraph—3 correspondent a nos modéles a sous-graphes de dépendances, respectivement de taille 1, 2 et 3.

| Modele  Exactitude moy. (%) | Précision moy. (%) | Précpos (%) | Précneg (%) |
unigramme 73.86 69.57 90.57 48.57
bigramme 72.73 69.11 86.79 51.43
trigramme 64.77 60.08 83.02 37.14
subgraph—1 78.41 74.80 92.45 57.14
subgraph-2 64.77 61.05 79 .25 42. 86
subgraph—3 60.23 59.22 64.15 54.29

TABLE 6 — Comparaison des mesures d’exactitude et de précision pour des modéles unigramme, bigramme et
trigramme par rapport a nos modéles a sous—graphes de dépendances de tailles 1, 2 et 3.

Come le montre la table de mesures, la meilleure Valeur d’ exactitude est obtenue avec un modéle a sous—graphes
de dépendances de taille 1 (78.41%). Quant a elle, la meilleur Valeur d’exactitude pour les modéles a n—grarnmes
est obtenue avec un modéle unigramme (73.86%). Les performances des modéles n—gramme se dégradent au fur
et a mesure que l’ordre du modele augmente. Le méme phénomene se produit avec les modéles a base de sous-
graphes de dépendances : l’exactitude dirninue avec l’accroissement de la taille des sous—graphes. D’aprés nous,

ALEXANDER PAK, PATRICK PAROUBEK

ce phenomene provient de la taille des donnees, qui n’est pas sufﬁsante pour que les modeles d’ordres superieurs
soient confrontes a sufﬁsamment d’exemples d’apprentissage.

Puisque dans nos donnees, nous avons plus de documents d’opinion positive, la precision moyenne de classiﬁca-
tion est meilleure pour ces demiers. La combinaison des modeles unigramme, bigramme and trigramme en Vue
d’obtenir de meilleurs résultats de classiﬁcation n’a pas répondu a nos attentes de maniere signiﬁcative. De la
meme maniere, la combinaison des modeles a base de sous—graphes de dépendances de djfférentes tailles n’a pas
produit d’amelioration signiﬁcative non plus.

Dans les Figure 5 et 6 nous présentons les 10 sous—graphes les plus frequents de taille 1 et les 5 sous—graphes les
plus frequents de taille 2 (selectionnes avec le score Aidf) respectivement pour les classes de documents positifs
et négatifs.

K ETERM_NUM

   
    

indispensable

FIGURE 5 — Sous-graphes extraits des critiques de jeux Video positives

4 Travaux apparentés

Une premiere experience par (Pang et al., 2002), utilisant la representation << sac de mots » avec des traits binaires
et des classﬁeurs SVM, est devenue une base pour de nombreux travaux dans le domaine de la classiﬁcation
des sentiments. Les auteurs ont amélioré leur systeme dans (Pang & Lee, 2004) en utilisant un détecteur de
subjectivité base sur la notion de coupe minimale dans un graphe. L’utilisation d’un detecteur de subjectivité a
permi de diminuer le bruit et se concentrer uniquement sur les phrases exprimant des sentiments. Cette methode
a amelioré la precision de 82.7% a 86.4%. Par la suite, de nombreux travaux ont utilise des techniques avancees
et des lexiques additionels pour augmenter l’espace de trait ou bien pour afﬁner la selection des traits pertinents,
améliorant ainsi la precision de la classiﬁcation. (Whitelaw et al., 2005) utilise des groupes d’ appreciation, comme
« very good » (tres bon) ou << not terribly funny » (pas Vraiment drole) dans le cadre de la theorie de l’appréciation
(Appraisal theory) en combinaison avec le modele << sac de mots » et a obtenu une precision de 90.2% sur le jeu
de donnees de critiques de ﬁlms. (Aue & Gamon, 2005) a utilise les SVM avec une selection de traits par registre
de probabilite eta obtenu une precision de 90.2% sur le meme jeu de donnees.

L’arbre de dépendances des phrases a eté largement utilise dans le domaine de l’analyse de sentiments. Une
recherche récente par (Arora et al., 2010) a note les problemes de la representation habituelle des textes par une
approche << sac de mots ». Les auteurs suggéraient d’utiliser leur algorithme pour extraire les traits de sous—graphe

SENTIMENT POLARITY CLASSIFICATION USING DEPENDENCY TREE SUBGRAPHS TEXT REPRESENTATION

  

   
   

FIGURE 6 — Sous-graphes extraits des critiques de jeux Video negatives

par la programmation genetique. Cependant, les traits obtenues n’étaient pas utilisées pour remplacer le mod-
ele n—gramme classique, mais plutot comme un jeu de traits complementaire. Un travail recent par (Nakagawa
et al., 2010) utilise un arbre de dépendances pour obtenir des traits qui sont utilisées pour entrainer un classiﬁeur
CRF pour la detection de la polarite des sentiments. Dans (Zhuang et al., 2006), les auteurs utilisent des arbres
de dependances pour extraire les paires trait—opinion, ou le premier membre de la paire est un terme trait (ex.
« movie »/ﬁlm) et le second est un porteur d’opinion (ex. « masterpiece »/chef d’oeuVre). Les arbres de depen-
dances sont utilises aﬁn d’établir les relations entre les mots traits et les mots-cles d’opinion. Dans (Chaumartin,
2007), l’arbre de dependance est utilise pour normaliser des titres Vers des formes grammaticalement correctes,
avant analyse des sentiments. Dans (Meena & Prabhakar, 2007), les auteurs utilisent l’arbre de dépendances et
WordNet pour effectuer une analyse en sentiments.

5 Conclusion

Avec l’explosion du nombre de blogs et le developpement des reseaux sociaux, la fouille d’opinion et l’analyse
de sentiments sont devenus des domaines d’intéret pour la recherche. Un travail pionnier sur la classiﬁcation
supervisée en sentiments a base de n—grammes ayant produit des resultats prometteurs, de nombreux chercheurs
ont développé ce type de modele. Cependant, l’approche << sac de mots » pour représenter un texte ne permet
pas de prendre en compte des expressions complexes de sentiments et ne se prete que difﬁcilement a l’utilisation
de modeles sophistiques de sentiments, qui nécessitent d’identiﬁer entre autres, l’intensité d’une opinion ou la
source/cible d’une expression d’opinion. Clairement, un nouveau type de modele est necessaire aﬁn d’obtenir de
meilleures performances en classiﬁcation automatique de sentiments et en fouille d’opinion. Dans nos travaux,
nous avons developpe une nouvelle representation a base de sous—graphes extraits des arbres de dependances
syntaxiques. Nous representons un texte comme une collection de sous—graphes, ou les noeuds sont des mots
(ou des classes de mots) et les arcs des dépendances syntaxiques entre ceux—ci. Une telle representation évite la
perte d’information associée a l’emploi de modeles << sac de mots » pour représenter un texte, ces demiers étant
bases uniquement sur des collections de n-grammes de mots. Nous avons teste notre modele sur un ensemble
de critiques de jeux Video, développe dans le cadre du projet DOXA sur la fouille d’opinion. Ainsi nous avons
pu montrer qu’un classiﬁeur SVM utilisant des traits construits a partir des sous—graphes extraits des arbres de
dépendances, donne de meilleurs resultats que les systemes traditionnels a base d’unigrammes. L’ exactitude la
plus elevee que nous ayons mesuree sur des textes en frangais est de 75%. Nous pensons que cette mesure peut

ALEXANDER PAK, PATRICK PAROUBEK

encore etre améliorée par l’utilisation de techniques avancées de selection de traits ou l’utilisation de lexiques
dédiés a l’analyse de sentiments et d’opinion.

Remerciements

Ces travaux ont recu le soutien ﬁnancier du proj et DOXA du pole de compétitivité CAP—DIGITAL.

Références

AIT-MOKHTAR S., CHANOD J .—P. & ROUX C. (2002). Robustness beyond shallowness : incremental deep
parsing. Nat. Lang. Eng., 8, 121-144.

ARORA S., MAYFIELD E., PENSTEIN-ROSE C. & NYBERG E. (2010). Sentiment classiﬁcation using auto-
matically extracted subgraph features. In Proceedings of the NAACL HLT 2010 Workshop on Computational
Approaches to Analysis and Generation of Emotion in Text, CAAGET ’10, p. 131-139, Morristown, NJ, USA :
Association for Computational Linguistics.

AUE A. & GAMON M. (2005). Customizing Sentiment Classiﬁers to New Domains : a Case Study. In Proc.
International Conference on Recent Advances in NLP.

CHAUMARTIN F.—R. (2007). Upar7 : a knowledge—based system for headline sentiment tagging. In Proceedings
of the 4th International Workshop on Semantic Evaluations, SemEval ’07, p. 422-425, Morristown, NJ, USA :
Association for Computational Linguistics.

DE MARNEE M.—C. & MANNING C. D. (2008). Stanford typed dependencies manual.
http ://nlp.stanford.edu/software/dependencies_manual.pdf

FAN R.—E., CHANG K.—W., HSIEH C.—J., WANG X.—R. & LIN C.—J. (2008). Liblinear : A library for large
linear classiﬁcation. J. Mach. learn. Res., 9, 1871-1874.

MANNING C. D. & SCHUTZE H. (1999). Foundations of statistical natural language processing. Cambridge,
MA, USA : MIT Press.

MEENA A. & PRABHAKAR T. V. (2007). Sentence level sentiment analysis in the presence of conjuncts using
linguistic analysis. In Proceedings of the 29th European conference on IR research, ECIR’07, p. 573-580, Berlin,
Heidelberg : Springer—Verlag.

NAKAGAWA T., INUI K. & KUROHASHI S. (2010). Dependency tree—based sentiment classiﬁcation using
crfs with hidden variables. In Human language Technologies : The 2010 Annual Conference of the North
American Chapter of the Association for Computational Linguistics, HLT ’10, p. 786-794, Morristown, NJ,
USA : Association for Computational Linguistics.

PAK A. & PAROUBEK P. (2010). Twitter as a corpus for sentiment analysis and opinion mining. In Proceedings
of the Seventh conference on International language Resources and Evaluation (LRECIO), Valletta, Malta :
European Language Resources Association (ELRA).

PALTOGLOU G. & THELWALL M. (2010). A study of information retrieval weighting schemes for sentiment
analysis. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’ 10,
p. 1386-1395, Morristown, NJ, USA : Association for Computational Linguistics.

PANG B. & LEE L. (2004). A sentimental education : Sentiment analysis using subjectivity summarization
based on minimum cuts. In Proceedings of the ACL, p. 271-278.

PANG B ., LEE L. & VAITHYANATHAN S. (2002). Thumbs up ? : sentiment classiﬁcation using machine learning
techniques. In Proceedings of the ACL—02 conference on Empirical methods in natural language processing -
Volume I 0, EMNLP ’02, p. 79-86, Morristown, NJ, USA : Association for Computational Linguistics.

PAROUBEK P., PAK A. & MOSTEFA D. (2010). Annotations for opinion mining evaluation in the industrial
context of the doxa project. In N. C. C. CHAIR), K. CHOUKRI, B. MAEGAARD, J . MARIANI, J . ODIJK, S.
PIPERIDIS, M. ROSNER & D. TAPIAS, Eds., Proceedings of the Seventh conference on International language
Resources and Evaluation (LREC’I 0), Valletta, Malta : European Language Resources Association (ELRA).

