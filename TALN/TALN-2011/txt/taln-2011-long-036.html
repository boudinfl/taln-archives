<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>G&#233;n&#233;ralisation de l&#8217;alignement sous-phrastique par &#233;chantillonnage</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211;1er juillet 2011
</p>
<p>G&#233;n&#233;ralisation de l&#8217;alignement sous-phrastique par &#233;chantillonnage
</p>
<p>Adrien Lardilleux1 Fran&#231;ois Yvon1,2 Yves Lepage3
(1) LIMSI-CNRS, BP 133, 91403 Orsay Cedex
</p>
<p>(2) Universit&#233; Paris-Sud
(3) IPS, universit&#233; Waseda, Japon
</p>
<p>Adrien.Lardilleux@limsi.fr, Francois.Yvon@limsi.fr, Yves.Lepage@aoni.waseda.jp
</p>
<p>R&#233;sum&#233;. L&#8217;alignement sous-phrastique consiste &#224; extraire des traductions d&#8217;unit&#233;s textuelles de grain inf&#233;-
rieur &#224; la phrase &#224; partir de textes multilingues parall&#232;les align&#233;s au niveau de la phrase. Un tel alignement est
n&#233;cessaire, par exemple, pour entra&#238;ner des syst&#232;mes de traduction statistique. L&#8217;approche standard pour r&#233;aliser
cette t&#226;che implique l&#8217;estimation successive de plusieurs mod&#232;les probabilistes de complexit&#233; croissante et l&#8217;uti-
lisation d&#8217;heuristiques qui permettent d&#8217;aligner des mots isol&#233;s, puis, par extension, des groupes de mots. Dans
cet article, nous consid&#233;rons une approche alternative, initialement propos&#233;e dans (Lardilleux &amp; Lepage, 2008),
qui repose sur un principe beaucoup plus simple, &#224; savoir la comparaison des profils d&#8217;occurrences dans des sous-
corpus obtenus par &#233;chantillonnage. Apr&#232;s avoir analys&#233; les forces et faiblesses de cette approche, nous montrons
comment am&#233;liorer la d&#233;tection d&#8217;unit&#233;s de traduction longues, et &#233;valuons ces am&#233;liorations sur des t&#226;ches de
traduction automatique.
</p>
<p>Abstract. Sub-sentential alignment is the process by which multi-word translation units are extracted from
sentence-aligned multilingual parallel texts. Such alignment is necessary, for instance, to train statistical machine
translation systems. Standard approaches typically rely on the estimation of several probabilistic models of increa-
sing complexity and on the use of various heuristics that make it possible to align, first isolated words, then, by
extension, groups of words. In this paper, we explore an alternative approach, originally proposed in (Lardilleux
&amp; Lepage, 2008), that relies on a much simpler principle, which is the comparison of occurrence profiles in sub-
corpora obtained by sampling. After analyzing the strengths and weaknesses of this approach, we show how to
improve the detection of long translation units, and evaluate these improvements on machine translation tasks.
</p>
<p>Mots-cl&#233;s : alignement sous-phrastique, traduction automatique par fragments.
Keywords: sub-sentential alignment, phrase-based machine translation.
</p>
<p>1 Introduction
</p>
<p>L&#8217;alignement sous-phrastique consiste &#224; extraire des traductions d&#8217;unit&#233;s textuelles de grain inf&#233;rieur &#224; la phrase
&#224; partir de corpus multilingues parall&#232;les, c&#8217;est-&#224;-dire dont les phrases ont pr&#233;alablement &#233;t&#233; mises en corres-
pondance. Cette t&#226;che constitue la premi&#232;re &#233;tape de la plupart des syst&#232;mes de traduction automatique fond&#233;s
sur les donn&#233;es (traduction statistique et traduction par l&#8217;exemple). Les syst&#232;mes qui concentrent aujourd&#8217;hui les
efforts de recherche sont majoritairement des syst&#232;mes statistiques par fragments (phrases en anglais), qui uti-
lisent comme principale ressource une table de traductions, d&#233;riv&#233;e d&#8217;alignements sous-phrastiques. Un telle table
consiste en une liste pr&#233;-calcul&#233;e de couples de traductions associant &#224; chaque couple de fragments (source, cible)
un certain nombre de scores refl&#233;tant la probabilit&#233; que source se traduise par cible.
</p>
<p>On peut globalement inscrire les m&#233;thodes d&#8217;alignement sous-phrastique dans l&#8217;un des deux courants suivants :
l&#8217;approche estimative, introduite par Brown et al. (1988), et l&#8217;approche associative, introduite par Gale &amp; Church
(1991). La premi&#232;re est la plus utilis&#233;e &#224; ce jour, principalement parce qu&#8217;elle est parfaitement int&#233;gr&#233;e &#224; la traduc-
tion automatique statistique, dont elle constitue un pilier depuis l&#8217;apparition des mod&#232;les IBM (Brown et al., 1993).
Cette approche consiste &#224; d&#233;finir un mod&#232;le probabiliste du corpus parall&#232;le dont les param&#232;tres sont estim&#233;s se-
lon un processus de maximisation globale sur l&#8217;ensemble des couples de phrases disponibles. Pratiquement, le but
est de d&#233;terminer les meilleurs appariements possibles entre les mots sources et cibles dans chacun des couples
de phrases parall&#232;les. Dans la seconde approche, on &#233;tablit une liste de traductions candidates soumises &#224; un test
d&#8217;ind&#233;pendance statistique, tels que l&#8217;information mutuelle (Fung &amp; Church, 1994) ou le rapport de vraisemblance</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ADRIEN LARDILLEUX, FRAN&#199;OIS YVON, YVES LEPAGE
</p>
<p>(Dunning, 1993) &#8212; voir (Melamed, 2000; Moore, 2005) pour des travaux r&#233;cents dans cette lign&#233;e. Il s&#8217;agit ici
d&#8217;un processus de maximisation locale : chaque segment est trait&#233; ind&#233;pendamment des autres. Cette approche est
plus souvent utilis&#233;e pour extraire directement des couples de traductions, tandis que la premi&#232;re cherche avant
tout &#224; &#233;tablir des liens de traduction entre les mots sources et cibles de chacun des couples de phrases du corpus
d&#8217;entr&#233;e. Ces liens permettent, dans un deuxi&#232;me temps, d&#8217;extraire des couples de traductions.
</p>
<p>Nous avons r&#233;cemment propos&#233; une m&#233;thode d&#8217;alignement sous-phrastique (Lardilleux &amp; Lepage, 2008, 2009;
Lardilleux, 2010), apparent&#233;e aux m&#233;thodes associatives, s&#8217;attaquant &#224; un certain nombre de probl&#232;mes souvent
n&#233;glig&#233;s dans le domaine : traitement simultan&#233; de multiples langues, parall&#233;lisme massif, passage &#224; l&#8217;&#233;chelle
au c&#339;ur de la m&#233;thode, et simplicit&#233; de mise en &#339;uvre. En moyenne, cette m&#233;thode s&#8217;est r&#233;v&#233;l&#233;e meilleure que
l&#8217;&#233;tat de l&#8217;art sur des t&#226;ches de constitution de lexiques bilingues, mais en retrait sur des t&#226;ches de traduction
automatique par fragments (Lardilleux et al., 2009). Nous n&#8217;avions &#233;mis jusqu&#8217;alors que des hypoth&#232;ses pour
expliquer ces r&#233;sultats a priori contradictoires. Dans cet article, nous proposons une analyse fine du comportement
de notre m&#233;thode afin de d&#233;terminer l&#8217;origine de ces diff&#233;rences, ainsi qu&#8217;une g&#233;n&#233;ralisation destin&#233;e &#224; am&#233;liorer
ses performances en traduction automatique par fragments.
</p>
<p>Cet article est organis&#233; de la fa&#231;on suivante : la section 2 pr&#233;sente une vue d&#8217;ensemble de la m&#233;thode d&#8217;alignement
d&#8217;origine ; la section 3 pr&#233;sente des exp&#233;riences mettant en &#233;vidence l&#8217;origine de ses faiblesses ; nous d&#233;crivons
dans la section 4 une g&#233;n&#233;ralisation, et &#233;valuons ses performances ; et la section 5 conclut ces travaux.
</p>
<p>2 Vue d&#8217;ensemble de la m&#233;thode d&#8217;alignement d&#8217;origine
</p>
<p>2.1 Principes de base
</p>
<p>Notre m&#233;thode d&#8217;alignement peut &#234;tre vue comme une &#233;mulation des m&#233;thodes associatives, &#224; la diff&#233;rence (ma-
jeure) pr&#232;s qu&#8217;elle ne se restreint pas &#224; aligner des couples de mots1 (source, cible). Elle permet, en effet, de consi-
d&#233;rer des s&#233;quences de mots de taille variable, &#233;ventuellement discontinues, qui partagent strictement la m&#234;me
distribution (r&#233;partition) dans les phrases du corpus parall&#232;le d&#8217;entr&#233;e, ind&#233;pendamment de leur langue. Ces s&#233;-
quences constituent en fait un sous-ensemble des candidats de traduction qui obtiendraient un score maximal par
des tests d&#8217;association statistiques. Le nombre de s&#233;quences de mots ayant exactement la m&#234;me distribution &#233;tant
r&#233;duit, nous ne recherchons pas ces s&#233;quences dans le corpus d&#8217;entr&#233;e m&#234;me, mais dans des sous-corpus de celui-
ci, l&#8217;id&#233;e &#233;tant que plus un sous-corpus est petit, plus les mots qu&#8217;il contient ont de chances de partager la m&#234;me
distribution, et que par cons&#233;quent plus le nombre de mots align&#233;s dans ce sous-corpus est &#233;lev&#233;e.
</p>
<p>Le c&#339;ur de la m&#233;thode consiste donc &#224; extraire des alignements &#224; partir de multiples sous-corpus ind&#233;pendants
construits par &#233;chantillonnage. En pratique, nous privil&#233;gions les sous-corpus de petite taille car ils sont plus
rapides &#224; traiter et semblent donner de meilleurs r&#233;sultats (Lardilleux, 2010). Pour chaque s&#233;quence de mots de
m&#234;me distribution dans un sous-corpus, deux alignements sont extraits : la s&#233;quence elle-m&#234;me, d&#8217;une part, et son
compl&#233;mentaire, d&#8217;autre part. Le nombre de sous-corpus &#224; traiter n&#8217;&#233;tant pas d&#233;fini &#224; l&#8217;avance, le processus est
anytime, c&#8217;est-&#224;-dire qu&#8217;il peut &#234;tre interrompu &#224; tout moment par l&#8217;utilisateur, ou selon des crit&#232;res tels que le
temps &#233;coul&#233; ou le taux de couverture du corpus de d&#233;part. Plus le nombre de sous-corpus trait&#233;s est &#233;lev&#233;, plus la
couverture du corpus de d&#233;part est grande et plus les mesures d&#8217;association sont pr&#233;cises. Les alignements extraits
sont collect&#233;s &#224; partir de l&#8217;ensemble des sous-corpus trait&#233;s, et sont &#233;valu&#233;s par divers scores (probabilit&#233; de
traduction et poids lexicaux (Koehn et al., 2003)) &#224; proportion du nombre de fois qu&#8217;ils ont &#233;t&#233; extraits. Le r&#233;sultat
est une table de traductions directement utilisable, par exemple, pour des t&#226;ches de traduction automatique.
</p>
<p>2.2 Algorithme complet
</p>
<p>L&#8217;algorithme d&#8217;extraction complet est sch&#233;matis&#233; dans le tableau 1.
</p>
<p>La figure 1 illustre les principales &#233;tapes de l&#8217;algorithme sur un exemple d&#8217;alignement d&#8217;un texte trilingue. Dans
la suite de cet article consacr&#233; aux applications de l&#8217;alignement en traduction automatique, nous nous limiterons &#224;
une application bilingue de la m&#233;thode, bien que son caract&#232;re multilingue en constitue un atout majeur.
</p>
<p>1Nous employons le terme &#171; mot &#187; pour d&#233;signer toute forme graphique identifi&#233;e par un programme de tokenisation.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G&#201;N&#201;RALISATION DE L&#8217;ALIGNEMENT SOUS-PHRASTIQUE PAR &#201;CHANTILLONNAGE
</p>
<p>Entr&#233;e : un corpus multilingue, ici arabe-fran&#231;ais-anglais.
</p>
<p>1 . &#189;&#202; &#9;&#146; &#9;&#772; &#9;&#225;&#211; , &#16;&#232;&#241;&#234;&#16;&#772; &#8596; Un caf&#233; , s&#8217;il vous pla&#238;t .&#8596; One coffee , please .
2 . &#16;&#232; &#9;PA&#16;J&#220;&#216; &#16;&#232;&#241;&#234;&#16;&#772; &#232; &#9;Y&#235; &#8596; Ce caf&#233; est excellent . &#8596; This coffee is excellent .
3 . &#201;J&#10;&#16;&#174;&#17;K &#248;&#10; A
</p>
<p>&#17;&#131; &#8596; Un th&#233; fort . &#8596; One strong tea .
4 . &#16;&#233;&#202;J&#10; &#16;&#174;&#17;K &#16;&#232;&#241;&#234;&#16;&#772; &#8596; Un caf&#233; fort . &#8596; One strong coffee .
</p>
<p>&#8659;
</p>
<p>Transformation en corpus alingue (= monolingue) en concat&#233;nant les traductions
d&#8217;une m&#234;me phrase et distinguant les mots en fonction de leur langue d&#8217;origine.
</p>
<p>S&#233;lection d&#8217;un sous-corpus al&#233;atoire (ici, les trois premi&#232;res lignes du corpus d&#8217;origine).
</p>
<p>1 1 . 1 &#189;&#202; &#9;&#146; &#9;&#772; 1 &#9;&#225;&#211; 1, 1 &#16;&#232;&#241;&#234;&#16;&#772; Un2 caf&#233;2 ,2 s&#8217;il2 vous2 pla&#238;t2 .2 One3 coffee3 ,3 please3 .3
2 1 . 1 &#16;&#232; &#9;PA&#16;J&#220;&#216; 1 &#16;&#232;&#241;&#234;&#16;&#772; 1 &#232; &#9;Y&#235; Ce2 caf&#233;2 est2 excellent2 .2 This3 coffee3 is3 excellent3 .3
3 1 . 1 &#201;J&#10;&#16;&#174;&#17;K 1 &#248;&#10; A
</p>
<p>&#17;&#131; Un2 th&#233;2 fort2 .2 One3 strong3 tea3 .3
</p>
<p>&#8659;
</p>
<p>Indexation des mots (calcul des vecteurs de pr&#233;sence). Les mots ayant m&#234;me distribution sont regroup&#233;s.
</p>
<p>1 . .2 .3 1 &#16;&#232;&#241;&#234;&#16;&#772; caf&#233;2 coffee3 One3 Un2 1, 1 &#189;&#202; &#9;&#146; &#9;&#772; 1 &#9;&#225;&#211; ,3 ,2 pla&#238;t2 please3 s&#8217;il2 vous2 1 &#232; &#9;Y&#235; 1 &#16;&#232; &#9;PA&#16;J&#220;&#216; Ce2 This3 est2 excellent2 . . .
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 . . .
2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 . . .
3 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . . .
</p>
<p>&#8659;
</p>
<p>Chaque groupe de mots permet d&#8217;extraire deux alignements par phrase o&#249; il appara&#238;t.
</p>
<p>Les mots :
apparaissent dans
</p>
<p>les phrases : d&#8217;o&#249; sont extraits :
</p>
<p>1
&#16;&#232;&#241;&#234;&#16;&#772; caf&#233;2 coffee3
</p>
<p>1
1
</p>
<p>&#16;&#232;&#241;&#234;&#16;&#772; caf&#233;2 coffee3
1 . 1 &#189;&#202; &#9;&#146; &#9;&#772; 1 &#9;&#225;&#211; 1, Un2 _ ,2 s&#8217;il2 vous2 pla&#238;t2 .2 One3 _ ,3 please3 .3
</p>
<p>2
1
</p>
<p>&#16;&#232;&#241;&#234;&#16;&#772; caf&#233;2 coffee3
1 . 1 &#16;&#232; &#9;PA&#16;J&#220;&#216; _ 1 &#232; &#9;Y&#235; Ce2 _ est2 excellent2 .2 This3 _ is3 excellent3 .3
</p>
<p>...
</p>
<p>&#8659;
</p>
<p>D&#233;compte des alignements et r&#233;tablissement des limites entre langues.
</p>
<p>Arabe Fran&#231;ais Anglais D&#233;compte
&#16;&#232;&#241;&#234;&#16;&#772; &#8596; caf&#233; &#8596; coffee 2
</p>
<p>. &#189;&#202; &#9;&#146; &#9;&#772; &#9;&#225;&#211; , &#8596; Un _ , s&#8217;il vous pla&#238;t . &#8596; One _ , please . 1
. &#16;&#232; &#9;PA&#16;J&#220;&#216; _ &#232; &#9;Y&#235; &#8596; Ce _ est excellent . &#8596; This _ is excellent . 1
</p>
<p>...
</p>
<p>FIG. 1 &#8211; Vue d&#8217;ensemble de la m&#233;thode d&#8217;alignement. C&#8217;est la phase d&#8217;indexation et de constitution des groupes
de mots (troisi&#232;me &#233;tape sur la figure) que nous g&#233;n&#233;raliserons dans la suite de l&#8217;article.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ADRIEN LARDILLEUX, FRAN&#199;OIS YVON, YVES LEPAGE
</p>
<p>Transformer le corpus parall&#232;le d&#8217;entr&#233;e, multilingue, en corpus alingue (= monolingue)
Initialiser un tableau associatif CompteurAlignements
Faire
</p>
<p>S&#233;lectionner un sous-corpus par &#233;chantillonnage
Indexer les mots par leur vecteur de pr&#233;sence dans les phrases du sous-corpus
Les mots de m&#234;me distribution sont rassembl&#233;s dans un m&#234;me groupe
Pour chaque groupe de mots :
</p>
<p>Pour chaque phrase o&#249; le groupe appara&#238;t :
R&#233;tablir l&#8217;ordre des mots du groupe
CompteurAlignements[groupe] ++
CompteurAlignements[phrase - groupe] ++
</p>
<p>Jusqu&#8217;&#224; interruption par l&#8217;utilisateur ou temps imparti &#233;coul&#233; ou plus aucun alignement obtenu ou tout autre crit&#232;re
Calculer les scores des alignements
</p>
<p>TAB. 1 &#8211; Les &#233;tapes de la m&#233;thode d&#8217;alignement.
</p>
<p>2.3 R&#233;sultats
</p>
<p>Dans cette section, nous r&#233;sumons les principaux r&#233;sultats et conclusions de (Lardilleux, 2010). Nous avons &#233;valu&#233;
cette m&#233;thode d&#8217;alignement sur deux t&#226;ches : en traduction automatique statistique par fragments et en constitu-
tion de lexiques bilingues. L&#8217;impl&#233;mentation de notre m&#233;thode, Anymalign2, est compar&#233;e &#224; MGIZA++3 (Gao &amp;
Vogel, 2008), l&#8217;implantation la plus r&#233;cente des mod&#232;les IBM. Anymalign &#233;tant anytime, nous commen&#231;ons en
pratique par ex&#233;cuter MGIZA++ avec ses param&#232;tres par d&#233;faut (5 it&#233;rations de chacun des mod&#232;les IBM1, HMM,
IBM3 et IBM4), mesurons son temps d&#8217;ex&#233;cution, et ex&#233;cutons Anymalign pendant la m&#234;me dur&#233;e. Les corpus
parall&#232;les utilis&#233;s dans les exp&#233;riences sont principalement Europarl (Koehn, 2005) et des extraits du BTEC (Take-
zawa et al., 2002), distribu&#233;s lors des campagnes d&#8217;&#233;valuation de traduction automatique IWSLT (Fordyce, 2007).
Les extraits du BTEC sont constitu&#233;s de 20 000 &#224; 40 000 couples de phrases courtes align&#233;es (10 mots anglais en
moyenne) et ceux d&#8217;Europarl de 100 000 couples de phrases longues (30 mots anglais).
</p>
<p>Dans la t&#226;che de traduction automatique statistique par fragments, nous comparons les scores obtenus par Moses
(Koehn et al., 2007) avec sa table de traductions par d&#233;faut, construite &#224; partir des alignements de MGIZA++, et
celle produite par Anymalign. En moyenne, Anymalign est en retrait de deux points BLEU (Papineni et al., 2002)
sur l&#8217;ensemble des exp&#233;riences que nous avons men&#233;es. Dans le meilleur des cas, nous avons obtenu un gain
d&#8217;un point par rapport &#224; MGIZA++ (BTEC, japonais-anglais) ; dans le pire, une perte de huit points (Europarl,
finnois-anglais). Dans l&#8217;ensemble, les &#233;carts sont plus prononc&#233;s sur Europarl que sur le BTEC.
</p>
<p>Dans la t&#226;che de constitution de lexiques bilingues, nous comparons les tables de traductions produites par les deux
aligneurs avec un lexique bilingue de r&#233;f&#233;rence4. Dans un premier temps, ce lexique est filtr&#233; de fa&#231;on qu&#8217;il ne
contienne que des couples de traductions qui peuvent effectivement &#234;tre extraits par les aligneurs &#224; partir du corpus
parall&#232;le d&#8217;entr&#233;e. En pratique, un couple de traductions du lexique de r&#233;f&#233;rence est conserv&#233; s&#8217;il s&#8217;agit d&#8217;une sous-
s&#233;quence d&#8217;un couple de phrases du corpus parall&#232;le. Nous d&#233;finissons alors le score d&#8217;une table de traductions
relativement &#224; ce lexique de r&#233;f&#233;rence filtr&#233; comme la somme des probabilit&#233;s de traduction source&#8594; cible des
alignements de la table de traductions pr&#233;sents dans la r&#233;f&#233;rence, divis&#233;e par le nombre d&#8217;entr&#233;es distinctes dans la
r&#233;f&#233;rence. Le r&#233;sultat s&#8217;interpr&#232;te comme un score de rappel, entre 0 et 1. En moyenne, Anymalign est meilleur de
7 % relativement &#224; MGIZA++ sur l&#8217;ensemble des exp&#233;riences que nous avons men&#233;es. Dans le meilleur des cas,
nous avons obtenu un gain relatif de 70 % (Europarl, finnois-fran&#231;ais) ; dans le pire une perte de 18 % (Europarl,
su&#233;dois-finnois). Le genre de textes constituant le corpus ne semble pas avoir d&#8217;influence majeure sur ces scores.
</p>
<p>En r&#233;sum&#233;, notre m&#233;thode est en retrait sur les t&#226;ches de traduction automatique par fragments, mais produit de
meilleurs alignements de mots, comme l&#8217;attestent les r&#233;sultats de comparaison avec lexiques de r&#233;f&#233;rence, dont les
entr&#233;es sont majoritairement des mots simples (le nombre moyen de mots par entr&#233;e est 1,2). Nous avons montr&#233;
(Lardilleux et al., 2009) que cela est en fait principalement d&#251; &#224; la faible capacit&#233; de cette m&#233;thode &#224; produire des
alignements de n-grammes de mots avec n &gt; 2, comme l&#8217;illustre la figure 2. Le but de la section suivante est de
mettre en &#233;vidence l&#8217;origine de ces diff&#233;rences.
</p>
<p>2http://users.info.unicaen.fr/~alardill/anymalign
3http://geek.kyloo.net/software/doku.php/mgiza:overview
4Nos lexiques proviennent principalement du site XDXF : http://xdxf.sourceforge.net</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G&#201;N&#201;RALISATION DE L&#8217;ALIGNEMENT SOUS-PHRASTIQUE PAR &#201;CHANTILLONNAGE
</p>
<p>0 %
</p>
<p>20 %
</p>
<p>40 %
</p>
<p>60 %
</p>
<p>80 %
</p>
<p>100 %
</p>
<p>1 2 3 4 5 6 7
</p>
<p>C
o
</p>
<p>u
v
</p>
<p>er
tu
</p>
<p>re
 d
</p>
<p>es
 n
</p>
<p>&#8722;
g
</p>
<p>ra
m
</p>
<p>m
es
</p>
<p>n
</p>
<p>MGIZA++
Anymalign
</p>
<p>FIG. 2 &#8211; Couverture de la partie source d&#8217;un &#233;chantillon d&#8217;Europarl fran&#231;ais-anglais par les tables de traductions
de MGIZA++ et d&#8217;Anymalign. Anymalign aligne plus d&#8217;unigrammes, mais peu de n-grammes plus longs.
</p>
<p>3 Une analyse du comportement de la m&#233;thode
</p>
<p>Dans cette section, nous pr&#233;sentons des exp&#233;riences montrant que deux causes principales sont &#224; l&#8217;origine des
r&#233;sultats apparemment contradictoires pr&#233;sent&#233;s ci-dessus : les diff&#233;rences de fr&#233;quences des mots qui composent
les s&#233;quences &#224; aligner (cause propre &#224; la m&#233;thode), et les fr&#233;quences de mots utiles &#224; ces t&#226;ches (cause propre &#224;
la t&#226;che). Les exp&#233;riences pr&#233;sent&#233;es ici sont r&#233;alis&#233;es sur un extrait d&#8217;environ 320 000 phrases d&#8217;Europarl, avec
les couples de langues portugais-espagnol (cas extr&#234;mes de langues proches dans nos exp&#233;riences) et finnois-
anglais (cas extr&#234;me de langues &#233;loign&#233;es : le finnois est une langue ouralienne agglutinante, l&#8217;anglais une langue
germanique d&#8217;influence romane isolante, ce qui s&#8217;exprime par une grande diff&#233;rence de taille des vocabulaires).
Le tableau 2 pr&#233;sente le nombre de mots de chaque partie de nos corpus.
</p>
<p>Langue Nombre de mots (tokens) Taille du vocabulaire
</p>
<p>portugais 9 249 177 87 341
espagnol 9 330 199 85 366
</p>
<p>finnois 6 472 649 274 958
anglais 8 955 995 53 704
</p>
<p>TAB. 2 &#8211; Caract&#233;ristiques des corpus utilis&#233;s pour nos analyses.
</p>
<p>3.1 Diff&#233;rences de fr&#233;quences
</p>
<p>Nous avons pr&#233;c&#233;demment montr&#233; (Lardilleux et al., 2009) qu&#8217;en pratique, la contrainte d&#8217;identit&#233; des distribu-
tions qui est au c&#339;ur de la m&#233;thode emp&#234;che d&#8217;extraire des s&#233;quences compos&#233;es de mots de fr&#233;quences diff&#233;-
rentes. Par exemple, un bigramme constitu&#233; d&#8217;un mot hapax suivi du point de fin de phrase (assimil&#233; &#224; un mot
typographique) ne peut &#234;tre produit, car en supposant que le point apparaisse dans toutes les phrases du corpus
d&#8217;entr&#233;e, la seule configuration dans laquelle ces deux mots partageraient la m&#234;me distribution serait un sous-
corpus constitu&#233; d&#8217;une seule phrase. Dans une telle configuration, presque tous les mots seraient hapax, et la
s&#233;quence extraite consisterait donc en l&#8217;unique phrase de ce sous-corpus. Le bigramme attendu serait donc &#171; mas-
qu&#233; &#187; et ne pourrait pas &#234;tre extrait isol&#233;ment.
</p>
<p>Nous faisons un pas suppl&#233;mentaire en &#233;tudiant la taille des sous-corpus d&#8217;o&#249; les mots sont extraits en fonction de
la fr&#233;quence de ces mots. &#201;tant donn&#233; un mot source ms &#224; aligner isol&#233;ment, trois cas peuvent se produire :
</p>
<p>1. dans un sous-corpus &#171; trop petit &#187;, d&#8217;autres mots sources ont la m&#234;me distribution que ms. Il n&#8217;est donc pas
possible d&#8217;aligner ms isol&#233;ment.
</p>
<p>2. dans un sous-corpus de taille &#171; id&#233;ale &#187;, aucun autre mot source n&#8217;a la m&#234;me distribution que ms, et au moins
un mot cible a cette distribution. ms peut donc &#234;tre align&#233; isol&#233;ment.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ADRIEN LARDILLEUX, FRAN&#199;OIS YVON, YVES LEPAGE
</p>
<p>3. dans un sous-corpus &#171; trop grand &#187;, aucun autre mot source n&#8217;a la m&#234;me distribution que ms, mais aucun
mot cible non plus. ms ne peut donc pas &#234;tre align&#233; du tout.
</p>
<p>Il existe ainsi une plage de tailles de sous-corpus qui permet d&#8217;extraire un mot isol&#233;ment. Cette plage d&#233;pend bien
entendu du mot &#224; extraire et plus particuli&#232;rement de sa fr&#233;quence. Ces plages sont d&#233;termin&#233;es empiriquement
en mesurant, pour chaque mot source d&#8217;un corpus parall&#232;le, la taille moyenne des sous-corpus &#224; partir de laquelle
il peut &#234;tre align&#233; isol&#233;ment, ainsi que celle &#224; partir de laquelle il ne peut plus &#234;tre align&#233; du tout. Pour cela, nous
commen&#231;ons par tirer al&#233;atoirement un sous-corpus d&#8217;une seule phrase contenant ce mot, testons si le mot peut y
&#234;tre align&#233;, puis recommen&#231;ons ce test en augmentant le sous-corpus d&#8217;une nouvelle phrase tir&#233;e al&#233;atoirement.
Le processus s&#8217;arr&#234;te lorsque plus aucun mot cible n&#8217;a la m&#234;me distribution que le mot source test&#233;.
</p>
<p>Chaque exp&#233;rience produit deux nombres : la taille &#224; partir de laquelle le mot peut &#234;tre align&#233; isol&#233;ment (passage
du cas 1 au cas 2 ci-dessus), et celle &#224; partir de laquelle le mot ne peut plus &#234;tre align&#233; du tout (du cas 2 au cas 3).
Ce test est r&#233;p&#233;t&#233; 1 000 fois pour chaque mot source, et nous effectuons la moyenne des mesures recueillies sur
l&#8217;ensemble des 1 000 tirages. Les r&#233;sultats sont pr&#233;sent&#233;s &#224; la figure 3, par classes de mots de fr&#233;quences proches.
</p>
<p>T
ai
</p>
<p>ll
e 
</p>
<p>m
o
</p>
<p>y
en
</p>
<p>n
e 
</p>
<p>d
es
</p>
<p> s
o
</p>
<p>u
s&#8722;
</p>
<p>co
rp
</p>
<p>u
s
</p>
<p>Nombre d&#8217;occurrences du mot
</p>
<p>pt &#8594; es
</p>
<p>1
</p>
<p>10
</p>
<p>100
</p>
<p>1 000
</p>
<p>10 000
</p>
<p>100 000
</p>
<p>1 10 100 1 000 100 000
</p>
<p>Non alignable
</p>
<p>Alignable, mais pas isol&#233;ment
</p>
<p>Alignable isol&#233;ment
</p>
<p>T
ai
</p>
<p>ll
e 
</p>
<p>m
o
</p>
<p>y
en
</p>
<p>n
e 
</p>
<p>d
es
</p>
<p> s
o
</p>
<p>u
s&#8722;
</p>
<p>co
rp
</p>
<p>u
s
</p>
<p>Nombre d&#8217;occurrences du mot
</p>
<p>fi &#8594; en
</p>
<p>1
</p>
<p>10
</p>
<p>100
</p>
<p>1 000
</p>
<p>10 000
</p>
<p>100 000
</p>
<p>1 10 100 1 000 100 000
</p>
<p>Non alignable
</p>
<p>Alignable, mais pas isol&#233;ment
</p>
<p>FIG. 3 &#8211; Tailles moyennes des sous-corpus &#224; partir desquelles un mot source peut &#234;tre extrait en fonction de la
fr&#233;quence de ce mot. Dans la zone inf&#233;rieure, le mot ne peut pas &#234;tre align&#233; isol&#233;ment (cas 1). Dans la zone
du milieu, le mot peut &#234;tre align&#233; isol&#233;ment (cas 2). Dans la zone sup&#233;rieure, le mot ne peut pas &#234;tre align&#233; du
tout (cas 3). Le petit sursaut de la limite sup&#233;rieure &#224; l&#8217;extr&#233;mit&#233; droite des deux graphiques est d&#251; au point de
fin de phrase, qui s&#8217;aligne plus facilement que les autres mots fr&#233;quents : il peut &#234;tre align&#233; isol&#233;ment dans des
sous-corpus de 5 &#224; 80 phrases environ.
</p>
<p>Ces graphiques nous permettent de faire deux remarques. D&#8217;abord, la plage des tailles &#171; id&#233;ales &#187; des sous-corpus,
autrement dit la largeur de la zone du milieu, varie grandement d&#8217;un couple de langues &#224; l&#8217;autre. Notons que
l&#8217;&#233;chelle logarithmique fait para&#238;tre cette plage plus &#233;troite qu&#8217;elle ne l&#8217;est en r&#233;alit&#233; : le rapport moyen entre sa
limite sup&#233;rieure et sa limite inf&#233;rieure est de 2,2 pour le couple espagnol-portugais et 1,2 pour le couple finnois-
anglais. Cette diff&#233;rence de rapport s&#8217;explique ais&#233;ment par les diff&#233;rences de morphologie des langues dans
chacun de ces couples. Nous pouvons donc nous attendre &#224; ce que l&#8217;alignement d&#8217;un mot donn&#233; par Anymalign
n&#233;cessite le traitement de davantage de sous-corpus avec le couple finnois-anglais qu&#8217;avec le couple portugais-
espagnol, puisqu&#8217;il est alors plus difficile de tirer al&#233;atoirement un sous-corpus de la &#171; bonne &#187; taille.
</p>
<p>La seconde remarque nous int&#233;resse tout particuli&#232;rement dans le cadre de cet article : plus un mot est fr&#233;quent,
plus les sous-corpus &#224; partir desquels il est extrait sont petits, et r&#233;ciproquement. Les mots rares (partie gauche
des graphiques) sont donc align&#233;s &#224; partir de grands sous-corpus, tandis que les mots fr&#233;quents (partie droite des
graphiques) sont align&#233;s &#224; partir de petits sous-corpus, constitu&#233;s par exemple de 5 &#224; 9 phrases pour la virgule. Ces
r&#233;sultats valident nos premi&#232;res hypoth&#232;ses : s&#8217;il est difficile de tirer un sous-corpus dans lequel deux mots source
de fr&#233;quences diff&#233;rentes partagent la m&#234;me distribution, c&#8217;est avant tout parce que ces mots ne peuvent pas &#234;tre
align&#233;s &#224; partir du m&#234;me sous-corpus. Pour aligner des mots de fr&#233;quences diff&#233;rentes, il est n&#233;cessaire de les
extraire &#224; partir de sous-corpus de tailles diff&#233;rentes. Nous proposerons une alternative dans la section suivante.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G&#201;N&#201;RALISATION DE L&#8217;ALIGNEMENT SOUS-PHRASTIQUE PAR &#201;CHANTILLONNAGE
</p>
<p>3.2 Fr&#233;quences utiles
</p>
<p>La seconde explication des diff&#233;rences de r&#233;sultats d&#8217;Anymalign sur les deux t&#226;ches sur lesquelles il a &#233;t&#233; &#233;valu&#233;
provient en fait de la t&#226;che elle-m&#234;me, ou pour &#234;tre plus pr&#233;cis du couple (aligneur, t&#226;che).
</p>
<p>Notre m&#233;thode et les mod&#232;les IBM reposent sur des intuitions oppos&#233;es : la premi&#232;re tire parti de la raret&#233; des
mots pour les aligner (on r&#233;duit artificiellement et temporairement la fr&#233;quence de tous les mots en se pla&#231;ant dans
un sous-corpus), tandis que les seconds sont estim&#233;s &#224; partir des observations mesur&#233;es sur l&#8217;ensemble du corpus.
En cons&#233;quence, Anymalign aligne mieux les mots rares, tandis que MGIZA++ aligne mieux les mots fr&#233;quents,
comme l&#8217;illustre la figure 4.
</p>
<p>0 %
</p>
<p>20 %
</p>
<p>40 %
</p>
<p>60 %
</p>
<p>80 %
</p>
<p>100 %
</p>
<p>1 10 100 1 000 100 000
</p>
<p>S
co
</p>
<p>re
</p>
<p>Nombre d&#8217;occurrences des mots
</p>
<p>pt-es
</p>
<p>Anymalign (60 %)
MGIZA++ (53 %)
</p>
<p>0 %
</p>
<p>20 %
</p>
<p>40 %
</p>
<p>60 %
</p>
<p>80 %
</p>
<p>100 %
</p>
<p>1 10 100 1 000 100 000
</p>
<p>S
co
</p>
<p>re
</p>
<p>Nombre d&#8217;occurrences des mots
</p>
<p>fi-en
</p>
<p>Anymalign (36 %)
MGIZA++ (26 %)
</p>
<p>FIG. 4 &#8211; Scores obtenus par les tables de traductions produites par Anymalign et MGIZA++ sur la t&#226;che de
constitution de lexiques bilingues. Les scores entre parenth&#232;ses sont les scores globaux, calcul&#233;s comme d&#233;crits au
3e paragraphe de la section 2.3. Les courbes pr&#233;sentent le d&#233;tail de ces scores, en fonction du nombre d&#8217;occurrences
du mot source de chacun des alignements : un score a &#233;t&#233; calcul&#233; localement pour chaque effectif de mot. Les
courbes ont &#233;t&#233; liss&#233;es pour am&#233;liorer leur lisibilit&#233;.
</p>
<p>Ce qui nous int&#233;resse ici n&#8217;est pas tant l&#8217;allure g&#233;n&#233;rale des courbes que leur position relative : la courbe corres-
pondant &#224; Anymalign est au-dessus de celle de MGIZA++ pour les mots d&#8217;effectif 1 &#224; 5 000 environ, et en-dessous
pour les effectifs sup&#233;rieurs. Cela montre qu&#8217;Anymalign aligne mieux non seulement les mots rares, mais &#233;ga-
lement les mots de fr&#233;quence interm&#233;diaire. Cette observation a &#233;t&#233; corrobor&#233;e sur d&#8217;autres couples de langues
(de-en, es-en, fr-en).
</p>
<p>Or, les mots rares &#233;tant beaucoup plus nombreux dans tout texte &#8212; cf. loi d&#8217;Estoup-Zipf (Zipf, 1965; Mandel-
brot, 1954; Montemurro, 2004) &#8212;, a fortiori dans notre corpus parall&#232;le ainsi que dans les tables de traductions
produites, et notre protocole d&#8217;&#233;valuation par comparaison avec lexiques de r&#233;f&#233;rence traitant les mots ind&#233;pen-
demment de leur fr&#233;quence, il est attendu que notre m&#233;thode obtienne de meilleurs scores en constitution de
lexiques bilingues, puisque les mots qu&#8217;elle aligne le mieux sont au total les plus nombreux. &#192; l&#8217;oppos&#233;, les mots
fr&#233;quents sont beaucoup moins nombreux, mais autrement plus importants en traduction automatique car ils y sont
beaucoup plus sollicit&#233;s : un mot fr&#233;quent a plus de chances d&#8217;appara&#238;tre dans un jeu de test qu&#8217;un mot rare. Cela
peut expliquer, au moins pour partie, les scores plus faibles d&#8217;Anymalign en traduction automatique. Id&#233;alement,
nous aimerions pouvoir utiliser les alignements de tel ou tel aligneur en fonction de la fr&#233;quence des mots, par
exemple en combinant les tables de traductions produites par les aligneurs. Des exp&#233;riences pr&#233;liminaires utilisant
les probabilit&#233;s de traduction d&#8217;Anymalign comme fonction de trait suppl&#233;mentaire dans la table de traduction
par d&#233;faut de Moses ont donn&#233; des r&#233;sultats prometteurs. Cela sort cependant du cadre de cet article, et nous nous
consacrons par la suite &#224; l&#8217;alignement de mots de fr&#233;quences diff&#233;rentes. Nous garderons n&#233;anmoins &#224; l&#8217;esprit
que, pour bien faire en traduction automatique, notre m&#233;thode devra &#233;galement aligner plus efficacement les mots
fr&#233;quents, ce que nous gardons pour des recherches futures.
</p>
<p>4 G&#233;n&#233;ralisation de la m&#233;thode &#224; toutes les cha&#238;nes de mots
</p>
<p>Dans cette section, nous pr&#233;sentons une g&#233;n&#233;ralisation de la m&#233;thode destin&#233;e &#224; am&#233;liorer ses performances en
traduction automatique statistique par fragments. En conformit&#233; avec la m&#233;thode d&#8217;origine, nous travaillerons</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ADRIEN LARDILLEUX, FRAN&#199;OIS YVON, YVES LEPAGE
</p>
<p>toujours sur les formes surfaciques des mots et sans ressource autre que le corpus d&#8217;entr&#233;e (traitement endog&#232;ne).
Notre but est d&#8217;extraire davantage d&#8217;alignements de n-grammes (cha&#238;nes de mots) avec n &gt; 2 (cf. figure 2), tout
en contournant le probl&#232;me de l&#8217;extraction des mots de fr&#233;quences diff&#233;rentes (section 3.1).
</p>
<p>4.1 Phase d&#8217;indexation
</p>
<p>Nous introduisons le traitement &#224; un grain variable en indexant des n-grammes plut&#244;t que des mots. Nous ne
chercherons pas &#224; effectuer une segmentation particuli&#232;re des phrases, par exemple en chunks, dont Vergne (2009)
a montr&#233; qu&#8217;ils pouvaient &#234;tre d&#233;termin&#233;s de fa&#231;on endog&#232;ne, mais traiterons plus simplement tous les n-grammes
de mots se chevauchant. Consid&#233;rons le (sous-)corpus d&#8217;entr&#233;e alingue5 suivant, constitu&#233; de trois phrases :
</p>
<p>1 a b c
2 a b d e
3 a c
</p>
<p>L&#8217;indexation sur l&#8217;ensemble des n-grammes de ce corpus, avant recensement des groupes de m&#234;me distribution
servant de base &#224; l&#8217;extraction des alignements, produit le r&#233;sultat suivant :
</p>
<p>n = 1 n = 2 n = 3 n = 4
a b c d e ab ac bc bd de abc abd bde abde
</p>
<p>1 1 1 1 0 0 1 0 1 0 0 1 0 0 0
2 1 1 0 1 1 1 0 0 1 1 0 1 1 1
3 1 0 1 0 0 0 1 0 0 0 0 0 0 0
</p>
<p>Dans l&#8217;&#233;tape suivante, le recensement des groupes de m&#234;me distribution, nous introduisons un changement ma-
jeur : si des n-grammes de m&#234;me distribution se chevauchent, le groupe de mots r&#233;sultant est constitu&#233; de l&#8217;union
de ces n-grammes. Par exemple, les bigrammes de m&#234;me distribution bd et de formeront le groupe de mots bde.
Autrement dit, les groupes ne sont plus constitu&#233;s de mots de m&#234;me distribution, mais de mots issus de n-grammes
de m&#234;me distribution. Un m&#234;me mot peut d&#233;sormais appara&#238;tre dans plusieurs groupes, ce qui n&#8217;&#233;tait pas le cas
dans la m&#233;thode d&#8217;origine.
</p>
<p>Ce changement soul&#232;ve un probl&#232;me qui ne pouvait pas se produire avec la m&#233;thode d&#8217;origine : des n-grammes
peuvent masquer des (n&#8722;1)-grammes, et ce r&#233;cursivement. L&#8217;unigramme b est par exemple masqu&#233; par le bi-
gramme de m&#234;me distribution ab, car l&#8217;union de b et ab donne ab, et b ne peut plus &#234;tre align&#233; isol&#233;ment. Il est
donc n&#233;cessaire de traiter l&#8217;introduction de chaque longueur de n-gramme de fa&#231;on sp&#233;cifique.
</p>
<p>4.2 Strat&#233;gie de constitution des groupes de mots
</p>
<p>Nous avons test&#233; trois strat&#233;gies :
1. traiter s&#233;par&#233;ment les n-grammes en fonction de leur longueur. Ainsi, les groupes de mots ne sont construits
</p>
<p>qu&#8217;&#224; partir de n-grammes de m&#234;me longueur en source et en cible. Cela est bien entendu d&#8217;efficacit&#233; limit&#233;e
sur des couples de langues tels que finnois-anglais : il serait pr&#233;f&#233;rable d&#8217;autoriser l&#8217;extraction d&#8217;un seul
mot d&#8217;une langue agglutinante avec plusieurs mots d&#8217;une langue isolante.
</p>
<p>2. permettre le m&#233;lange de toutes les longueurs de n-grammes, mais en ajoutant progressivement chaque lon-
gueur. L&#8217;ensemble initial ne contient que des unigrammes (m&#233;thode d&#8217;origine). Dans un deuxi&#232;me temps,
nous ajoutons les bigrammes et recr&#233;ons tous les groupes de mots : certains sont identiques (les d&#233;comptes
des alignements correspondants sont renforc&#233;s), d&#8217;autres sont nouveaux, d&#8217;autres enfin sont masqu&#233;s mais
cela n&#8217;a pas d&#8217;importance car ils ont d&#233;j&#224; &#233;t&#233; extraits &#224; partir des unigrammes. On ajoute ensuite les tri-
grammes, etc. Les alignements sont extraits &#224; chaque fois que des n-grammes sont ajout&#233;s.
</p>
<p>3. forcer l&#8217;alignement de n-grammes de longueurs diff&#233;rentes, &#224; contrepied de la premi&#232;re strat&#233;gie, en traitant
s&#233;quentiellement tous les couples de longueurs (source, cible) possibles (produit cart&#233;sien). Cela permet
l&#8217;alignement de n-grammes de longueurs tr&#232;s diff&#233;rentes en source et en cible, voire trop : puisque nous
n&#8217;avons recours &#224; aucune connaissance ext&#233;rieure, Anymalign ne sait pas a priori quelle langue est trait&#233;e,
et rien ne l&#8217;emp&#234;che par exemple de vouloir aligner des unigrammes en anglais avec de longs n-grammes en
finnois, quand bien m&#234;me il est peu probable que le moindre alignement puisse &#234;tre produit &#224; partir d&#8217;une
telle configuration. En outre, la complexit&#233; de cette approche est bien plus importante que celle des deux
pr&#233;c&#233;dentes, et ne passe pas &#224; l&#8217;&#233;chelle lorsque nous traitons plus de deux langues simultan&#233;ment.
</p>
<p>5Comme d&#233;crit &#224; la section 2, notre principal algorithme ne fait pas de diff&#233;rence entre corpus multilingues et corpus monolingues.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G&#201;N&#201;RALISATION DE L&#8217;ALIGNEMENT SOUS-PHRASTIQUE PAR &#201;CHANTILLONNAGE
</p>
<p>Pour comparer ces trois strat&#233;gies, nous pr&#233;parons un ensemble de 100 000 sous-corpus al&#233;atoires issus d&#8217;Europarl
(fran&#231;ais-anglais) et en extrayons les alignements selon chacune de ces strat&#233;gies. Nous r&#233;alisons l&#8217;exp&#233;rience
pour des longueurs maximales de n-grammes allant de 1 &#224; 5. Les tables de traductions (3&#215; 5 = 15 tables au total),
obtenues &#224; partir de ce m&#234;me ensemble de sous-corpus, sont &#233;valu&#233;es sur les m&#234;mes t&#226;ches que pr&#233;c&#233;demment :
en traduction automatique statistique par fragments (les crit&#232;res d&#8217;&#233;valuation sont BLEU et TER (Snover et al.,
2006)) et en constitution de lexiques bilingues. Les r&#233;sultats sont pr&#233;sent&#233;s dans le tableau 3.
</p>
<p>Strat&#233;gie n max. Score en lexique (%) BLEU (%) TER (%) Nombre d&#8217;entr&#233;es Long. moy. des entr&#233;es
</p>
<p>1 36,19 21,12 63,57 83 967 1,92
2 36,71 22,62 61,93 277 858 2,79
</p>
<p>1. 3 36,66 23,08 62,06 366 971 3,13
4 36,60 23,23 61,43 393 453 3,24
5 36,58 22,92 62,14 399 810 3,27
</p>
<p>1 36,19 21,12 63,57 83 967 1,92
2 37,08 23,63 60,68 290 631 2,78
</p>
<p>2. 3 37,35 24,72 59,86 398 880 3,12
4 37,45 24,47 60,69 436 760 3,25
5 37,56 24,25 59,94 448 212 3,31
</p>
<p>1 36,19 21,12 63,57 83 967 1,92
2 31,71 23,85 60,41 312 273 2,86
</p>
<p>3. 3 30,90 24,50 60,68 453 429 3,24
4 30,48 24,47 59,96 507 359 3,39
5 30,25 24,26 60,03 524 091 3,45
</p>
<p>TAB. 3 &#8211; Qualit&#233; et caract&#233;ristiques des tables de traductions produites selon chacune des trois strat&#233;gies de consti-
tution de groupes de mots, pour diff&#233;rente longueurs maximales de n-grammes index&#233;s. Les lignes o&#249; n max. = 1
sont identiques pour les trois strat&#233;gies et correspondent &#224; la m&#233;thode d&#8217;origine.
</p>
<p>Comme il &#233;tait attendu, plus la longueur maximale des n-grammes index&#233;s est grande, plus le nombre d&#8217;entr&#233;es
dans la table de traductions et la longueur de ces entr&#233;es sont &#233;galement &#233;lev&#233;s, car les alignements produits avec
un n max. donn&#233; contiennent ceux produits avec un n max. inf&#233;rieur (inclusion des tables). Les scores en consti-
tution de lexiques augmentent de fa&#231;on n&#233;gligeable lorsque n max. augmente avec les deux premi&#232;res approches,
mais se d&#233;gradent de fa&#231;on significative avec la troisi&#232;me. Le gain en traduction automatique est significatif avec
les trois approches. La seconde semble n&#233;anmoins fournir des r&#233;sultats tr&#232;s l&#233;g&#232;rement meilleurs selon les trois
crit&#232;res d&#8217;&#233;valuation. Son temps d&#8217;ex&#233;cution est l&#233;g&#232;rement sup&#233;rieur &#224; celui de la premi&#232;re (au pire deux fois plus
lent avec les 5-grammes), mais bien en-de&#231;&#224; de celui de la troisi&#232;me (de l&#8217;ordre de l&#8217;heure &#224; celui de la journ&#233;e
avec les 5-grammes).
</p>
<p>La strat&#233;gie que nous utiliserons par la suite sera donc la deuxi&#232;me. Elle constitue sur le fond un bon compromis
entre les deux autres. La figure 5 pr&#233;sente le d&#233;tail de la colonne &#171; Nombre d&#8217;entr&#233;es &#187; du tableau 3 pour cette
deuxi&#232;me strat&#233;gie, et est &#224; confronter avec la figure 2.
</p>
<p>Dans l&#8217;ensemble, l&#8217;ajout d&#8217;une longueur de n-grammes index&#233;s, autrement dit le passage d&#8217;une courbe &#224; celle im-
m&#233;diatement au-dessus, augmente consid&#233;rablement la quantit&#233; de l&#8217;ensemble des n-grammes produits (y compris,
de fa&#231;on marginale, les n-grammes de taille inf&#233;rieure, mais cela n&#8217;est d&#251; qu&#8217;&#224; l&#8217;extraction des compl&#233;mentaires
des groupes de mots). Le cas le plus significatif est celui de l&#8217;indexation des bigrammes (n max. = 2), qui fait
exploser la quantit&#233; de bigrammes en sortie, et dans une moindre mesure de toutes les tailles de n-grammes sup&#233;-
rieures. Le ph&#233;nom&#232;ne se produit &#233;galement en indexant des n-grammes encore plus longs, mais cela est de moins
en moins significatif &#224; mesure que n max. augmente. Le graphique semble montrer qu&#8217;il n&#8217;est pas utile d&#8217;indexer
des n-grammes de plus de 3 ou 4 mots, car cela se r&#233;v&#232;le peu productif. Les n-grammes qui nous int&#233;ressent
le plus sont de toute fa&#231;on ceux de longueur 1 &#224; 3, parce que ce sont g&#233;n&#233;ralement les plus utiles en traduction
automatique par fragments.
</p>
<p>4.3 Exp&#233;riences et nouveaux r&#233;sultats
</p>
<p>Nous comparons &#224; pr&#233;sent notre m&#233;thode g&#233;n&#233;ralis&#233;e (indexation des n-grammes + constitution des groupes de
mots selon la deuxi&#232;me strat&#233;gie test&#233;e) &#224; MGIZA++ sur des t&#226;ches de traduction automatique statistique par</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ADRIEN LARDILLEUX, FRAN&#199;OIS YVON, YVES LEPAGE
</p>
<p>0
</p>
<p>20 000
</p>
<p>40 000
</p>
<p>60 000
</p>
<p>80 000
</p>
<p>100 000
</p>
<p>120 000
</p>
<p>140 000
</p>
<p>1 2 3 4 5 6 7
</p>
<p>N
o
</p>
<p>m
b
</p>
<p>re
 d
</p>
<p>&#8217;e
n
</p>
<p>tr
&#233;e
</p>
<p>s 
so
</p>
<p>u
rc
</p>
<p>e
</p>
<p>Longueur des entr&#233;es source (en mots)
</p>
<p>n max. = 5
n max. = 4
n max. = 3
n max. = 2
n max. = 1
</p>
<p>FIG. 5 &#8211; Distribution des n-grammes dans les cinq tables de traductions obtenues par la deuxi&#232;me strat&#233;gie de
constitution de groupes de mots. Chaque courbe correspond &#224; une ligne du tableau 3, et la somme des ordonn&#233;es
de ses points report&#233;s est &#233;gale &#224; la valeur indiqu&#233;e dans la colonne &#171; Nombre d&#8217;entr&#233;es &#187; du tableau. La courbe
la plus basse (n max. = 1) correspond &#224; la m&#233;thode d&#8217;origine (cf. figure 2).
</p>
<p>T&#226;che Entra&#238;nement D&#233;veloppement Test R&#233;f&#233;rences par phrase de test
</p>
<p>BTEC : ar-en 19 972 1 512 489 7
BTEC : zh-en 19 972 1 512 989 7
Europarl : fi-en, fr-en, pt-es 318 804 500 1 000 1
</p>
<p>TAB. 4 &#8211; Caract&#233;ristiques des corpus utilis&#233;s pour notre &#233;valuation.
</p>
<p>Aligneur n max. BLEU (%) TER (%) Nombre d&#8217;entr&#233;es
</p>
<p>MGIZA++ 33,68 46,17 217 512
Anymalign 1 26,33 51,17 170 521
</p>
<p>ar-en - 2 30,88 49,70 269 454
- 3 31,81 51,48 273 197
- 4 33,75 48,80 258 141
</p>
<p>MGIZA++ 15,46 70,49 141 773
Anymalign 1 14,77 68,97 158 904
</p>
<p>zh-en - 2 16,35 71,70 263 315
- 3 16,54 70,62 250 292
- 4 16,84 69,45 269 353
</p>
<p>TAB. 5 &#8211; R&#233;sultats des t&#226;ches de traduction sur le BTEC.
</p>
<p>M&#234;me temps de traitement que MGIZA++ Temps th&#233;orique = 20 &#215;MGIZA++
Aligneur n max. BLEU (%) TER (%) Nombre d&#8217;entr&#233;es BLEU (%) TER (%) Nombre d&#8217;entr&#233;es
</p>
<p>MGIZA++ 21,68 65,50 5 241 325
Anymalign 1 13,73 77,57 1 871 639 13,54 74,34 5 178 683
</p>
<p>fi-en - 2 14,39 76,59 890 644 16,21 71,18 5 948 094
- 3 14,64 77,15 696 420 17,44 72,63 4 001 816
- 4 12,79 78,46 279 437 16,80 71,34 2 266 448
</p>
<p>MGIZA++ 29,39 54,37 10 783 083
Anymalign 1 22,74 61,85 1 755 334 23,58 61,09 7 882 822
</p>
<p>fr-en - 2 24,68 60,22 1 805 297 24,55 58,42 8 317 221
- 3 24,40 59,77 1 074 258 25,29 57,66 6 943 421
- 4 23,01 61,86 492 530 24,78 58,11 5 121 617
</p>
<p>MGIZA++ 38,22 47,47 17 828 592
Anymalign 1 34,63 50,25 1 532 520 34,84 50,35 6 730 554
</p>
<p>pt-es - 2 36,03 49,63 987 884 36,72 49,10 7 295 581
- 3 35,72 49,95 744 947 35,98 49,02 6 126 896
- 4 35,18 50,34 342 168 37,01 48,71 3 926 578
</p>
<p>TAB. 6 &#8211; R&#233;sultats des t&#226;ches de traduction sur Europarl.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>G&#201;N&#201;RALISATION DE L&#8217;ALIGNEMENT SOUS-PHRASTIQUE PAR &#201;CHANTILLONNAGE
</p>
<p>fragments. Le tableau 4 pr&#233;sente les caract&#233;ristiques des donn&#233;es utilis&#233;es pour chacune de ces exp&#233;riences, et les
tableaux 5 et 6 pr&#233;sentent les r&#233;sultats.
</p>
<p>Les lignes o&#249; n max. = 1 correspondent &#224; la version d&#8217;origine d&#8217;Anymalign. Comme d&#233;crit pr&#233;c&#233;demment (sec-
tion 2.3), Anymalign &#233;tant anytime, la condition d&#8217;arr&#234;t que nous lui imposons d&#233;pend du temps d&#8217;ex&#233;cution de
MGIZA++. Ce temps est constant quelle que soit la valeur de n max. Le temps de traitement augmentant avec
ce param&#232;tre, plus ce param&#232;tre est &#233;lev&#233; et plus le nombre de sous-corpus trait&#233;s est faible, contrairement aux
exp&#233;riences pr&#233;sent&#233;es dans la section 4.2 o&#249; l&#8217;ensemble des sous-corpus &#224; traiter &#233;tait fix&#233; &#224; l&#8217;avance, impliquant
un temps de traitement d&#233;pendant de n max. Th&#233;oriquement, les tables produites pour un n max. donn&#233; sont plus
grandes que pour un n max. inf&#233;rieur, &#224; condition que l&#8217;aligneur soit ex&#233;cut&#233; suffisamment longtemps. Cela ex-
plique pourquoi les tables de traductions des tableaux 5 et 6 peuvent contenir moins d&#8217;entr&#233;es pour de plus grandes
valeurs de n max. En pratique, ces tables contiennent tout de m&#234;me davantage de longs n-grammes, ce qui permet
une am&#233;lioration tr&#232;s significative des scores, malgr&#233; une table de traductions plus petite.
</p>
<p>Sur les t&#226;ches impliquant le BTEC, les lignes o&#249; n max. = 1 montrent que la version d&#8217;origine d&#8217;Anymalign
obtient des scores BLEU comparables &#224; MGIZA++ en chinois-anglais, et est loin derri&#232;re en arabe-anglais. La
g&#233;n&#233;ralisation aux n-grammes lui permet de devancer MGIZA++ de plus d&#8217;un point BLEU en chinois-anglais, et
de l&#8217;&#233;galiser en arabe-anglais, soit un gain spectaculaire de 7 points BLEU.
</p>
<p>Sur les t&#226;ches impliquant Europarl, les scores de la version d&#8217;origine d&#8217;Anymalign sont en retrait de fa&#231;on signifi-
cative par rapport &#224; MGIZA++, ce qui est conforme aux exp&#233;riences que nous avions men&#233;es pr&#233;c&#233;demment. Cela
dit, la diff&#233;rence n&#8217;&#233;tait pas aussi prononc&#233;e dans nos anciennes exp&#233;riences : nous observions une diff&#233;rence de 2
&#224; 3 points BLEU en moyenne, alors qu&#8217;elle est ici de 6 points. Nous pensons que ce changement est d&#251; &#224; la taille de
notre corpus qui est d&#233;sormais beaucoup plus &#233;lev&#233; : 320 000 couples de phrases contre 100 000 pr&#233;c&#233;demment.
La taille des tables de traductions d&#8217;Anymalign, tr&#232;s petites par rapport &#224; celles de MGIZA++, semble indiquer
que le temps d&#8217;ex&#233;cution de notre m&#233;thode n&#8217;est pas suffisant. Pour cette raison, le tableau 6 contient dans sa par-
tie droite une deuxi&#232;me s&#233;rie de r&#233;sultats, qui correspondent &#224; l&#8217;ex&#233;cution d&#8217;Anymalign pendant une dur&#233;e totale
&#233;gale &#224; 20 fois le temps d&#8217;ex&#233;cution de MGIZA++. En pratique, Anymalign &#233;tant massivement parall&#233;lisable, nous
avons d&#233;coup&#233; les traitements en 140 processus et les avons ex&#233;cut&#233;s sur un cluster, pour finalement profiter d&#8217;un
temps de traitement 7 fois plus rapide qu&#8217;avec les r&#233;sultats pr&#233;sent&#233;s dans la partie gauche du tableau. Les tailles
des tables de traductions dans la partie droite du tableau sont plus proches de celles de MGIZA++, ce qui confirme
que le temps d&#8217;ex&#233;cution n&#8217;&#233;tait pas suffisant6, mais le gain en BLEU de la version d&#8217;origine d&#8217;Anymalign n&#8217;est
pas significatif pour autant. Il l&#8217;est par contre lorsque nous augmentons n max. : nous gagnons jusqu&#8217;&#224; 3 points
BLEU en finnois-anglais (n max. = 3) simplement en ex&#233;cutant Anymalign plus longtemps. Dans tous les cas de
la partie droite du tableau, l&#8217;indexation des n-grammes permet un gain en BLEU allant d&#8217;1,7 point en fran&#231;ais-
anglais &#224; pr&#232;s de 4 points en finnois-anglais. En moyenne, les meilleurs scores d&#8217;Anymalign sont d&#233;sormais en
retrait de 3,5 points BLEU par rapport &#224; MGIZA++, divisant pratiquement par deux son retard initial.
</p>
<p>5 Conclusion
</p>
<p>Cet article a pr&#233;sent&#233; une g&#233;n&#233;ralisation de notre m&#233;thode d&#8217;alignement sous-phrastique afin d&#8217;am&#233;liorer ses
r&#233;sultats en traduction automatique. La m&#233;thode d&#8217;origine obtient de meilleurs r&#233;sultats que l&#8217;&#233;tat de l&#8217;art sur des
t&#226;ches de constitution de lexiques bilingues, mais des r&#233;sultats inf&#233;rieurs en traduction automatique statistique par
fragments. Nous avons montr&#233; que ces diff&#233;rences ont principalement deux causes : les diff&#233;rences de fr&#233;quences
des mots qui composent les s&#233;quences &#224; aligner (cause propre &#224; la m&#233;thode), et les fr&#233;quences de mots utiles &#224;
ces t&#226;ches (cause propre &#224; la t&#226;che). Pour pallier le premier probl&#232;me, nous avons propos&#233; une g&#233;n&#233;ralisation de
la phase d&#8217;indexation de notre m&#233;thode, en ne consid&#233;rant non plus le mot comme unit&#233;, mais le n-gramme. Le
r&#233;sultat de cette g&#233;n&#233;ralisation est un fort accroissement du nombre de n-grammes en sortie, qui m&#232;ne &#224; des gains
tr&#232;s significatifs en traduction automatique par fragments (jusqu&#8217;&#224; +7 points BLEU sur le couple arabe-anglais).
Notre m&#233;thode fait d&#233;sormais jeu &#233;gal avec l&#8217;&#233;tat de l&#8217;art sur des t&#226;ches &#171; simples &#187; de traduction automatique
(BTEC), et nous avons pratiquement divis&#233; son retard par deux sur des t&#226;ches plus difficiles (Europarl). Pour aller
plus loin, nous envisageons d&#8217;&#233;tudier le cas de l&#8217;alignement des mots fr&#233;quents, dont nous avons montr&#233; qu&#8217;ils
&#233;taient moins bien align&#233;s que les mots rares par notre m&#233;thode, ainsi que la question de sa condition d&#8217;arr&#234;t.
</p>
<p>6Cela soul&#232;ve une autre question, qui est celle de la condition d&#8217;arr&#234;t d&#8217;Anymalign. Les pr&#233;sentes exp&#233;riences montrent que nos crit&#232;res
actuels sont insuffisants, ne serait-ce que pour effectuer une juste comparaison avec d&#8217;autres outils.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ADRIEN LARDILLEUX, FRAN&#199;OIS YVON, YVES LEPAGE
</p>
<p>Remerciements
Les travaux pr&#233;sent&#233;s dans cet article ont &#233;t&#233; partiellement financ&#233;s par le projet Cap Digital SAMAR.
</p>
<p>R&#233;f&#233;rences
BROWN P., COCKE J., DELLA PIETRA S., DELLA PIETRA V., JELINEK F., MERCER R. &amp; ROOSSIN P. (1988).
A Statistical Approach to Language Translation. In Proceedings of Coling&#8217;88, p. 71&#8211;76, Budapest.
BROWN P., DELLA PIETRA S., DELLA PIETRA V. &amp; MERCER R. (1993). The Mathematics of Statistical
Machine Translation : Parameter Estimation. Computational Linguistics, 19(2), 263&#8211;311.
DUNNING T. (1993). Accurate methods for the statistics of surprise and coincidence. Computational Linguistics,
19(1), 61&#8211;74.
FORDYCE C. S. (2007). Overview of the IWSLT 2007 Evaluation Campaign. In Proceedings of IWSLT 2007,
p. 1&#8211;12, Trente.
FUNG P. &amp; CHURCH K. (1994). K-vec : A New Approach for Aligning Parallel Texts. In Proceedings of
Coling&#8217;94, volume 2, p. 1096&#8211;1102, Kyo&#772;to.
GALE W. &amp; CHURCH K. (1991). Identifying Word Correspondences in Parallel Texts. In Proceedings of the
fourth DARPA workshop on Speech and Natural Language, p. 152&#8211;157, Pacific Grove.
GAO Q. &amp; VOGEL S. (2008). Parallel Implementations of Word Alignment Tool. In Software Engineering,
Testing, and Quality Assurance for Natural Language Processing, p. 49&#8211;57, Columbus (Ohio, USA).
KOEHN P. (2005). Europarl : A Parallel Corpus for Statistical Machine Translation. In Proceedings of MT
Summit X, p. 79&#8211;86, Phuket.
KOEHN P., HOANG H., BIRCH A., CALLISON-BURCH C., FEDERICO M., BERTOLDI N., COWAN B., SHEN
W., MORAN C., ZENS R., DYER C., BOJAR O., CONSTANTIN A. &amp; HERBST E. (2007). Moses : Open Source
Toolkit for Statistical Machine Translation. In Proceedings of ACL 2007, p. 177&#8211;180, Prague.
KOEHN P., OCH F. &amp; MARCU D. (2003). Statistical Phrase-Based Translation. In Proceedings of HLT-NAACL
2003, p. 48&#8211;54, Edmonton.
LARDILLEUX A. (2010). Contribution des basses fr&#233;quences &#224; l&#8217;alignement sous-phrastique multilingue : une
approche diff&#233;rentielle. PhD thesis, universit&#233; de Caen Basse-Normandie. 204 pages.
LARDILLEUX A., CHEVELU J., LEPAGE Y., PUTOIS G. &amp; GOSME J. (2009). Lexicons or phrase tables ? An
investigation in sampling-based multilingual alignment. In Proceedings of EBMT3, p. 45&#8211;52, Dublin.
LARDILLEUX A. &amp; LEPAGE Y. (2008). A truly multilingual, high coverage, accurate, yet simple, sub-sentential
alignment method. In Proceedings of AMTA 2008, p. 125&#8211;132, Waikiki.
LARDILLEUX A. &amp; LEPAGE Y. (2009). Sampling-based multilingual alignment. In Proceedings of RANLP
2009, p. 214&#8211;218, Borovets.
MANDELBROT B. (1954). Structure formelle des textes et communication. Word, 10, 1&#8211;27.
MELAMED D. (2000). Models of Translational Equivalence among Words. Computational Linguistics, 26(2),
221&#8211;249.
MONTEMURRO M. (2004). A generalization of the Zipf-Mandelbrot Law in Linguistics. Nonextensive Entropy :
interdisciplinary applications. 12 pages.
MOORE R. (2005). Association-Based Bilingual Word Alignment. In Proceedings of the ACL Workshop on
Building and Using Parallel Texts, p. 1&#8211;8, Ann Arbor.
PAPINENI K., ROUKOS S., WARD T. &amp; ZHU W.-J. (2002). BLEU : a Method for Automatic Evaluation of
Machine Translation. In Proceedings of ACL 2002, p. 311&#8211;318, Philadelphie.
SNOVER M., DORR B., SCHWARTZ R., MICCIULLA L. &amp; MAKHOUL J. (2006). A Study of Translation Edit
Rate with Targeted Human Annotation. In Proceedings of AMTA 2006, p. 223&#8211;231, Cambridge.
TAKEZAWA T., SUMITA E., SUGAYA F., YAMAMOTO H. &amp; YAMAMOTO S. (2002). Toward a Broad-coverage
Bilingual Corpus for Speech Translation of Travel Conversation in the Real World. In Proceedings of LREC
2002, p. 147&#8211;152, Las Palmas de Gran Canaria.
VERGNE J. (2009). Defining the chunk as the period of the functions length and frequency of words on the
syntagmatic axis. In Proceedings of LTC&#8217;09, p. 85&#8211;89, Poznan&#769;.
ZIPF G. (1965). The Psycho-Biology of Language : An Introduction to Dynamic Philology. Classic Series.
Cambridge, USA : The MIT Press. Fist edition 1935.</p>

</div></div>
</body></html>