<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Estimation d&#8217;un mod&#232;le de traduction &#224; partir d&#8217;alignements mot-&#224;-mot non-d&#233;terministes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211;1er juillet 2011
</p>
<p>Estimation d&#8217;un mod&#232;le de traduction &#224; partir d&#8217;alignements mot-&#224;-mot
non-d&#233;terministes
</p>
<p>Nadi Tomeh Alexandre Allauzen Fran&#231;ois Yvon
Universit&#233; Paris Sud et LIMSI/CNRS
</p>
<p>BP 133 91 403 Orsay
{nadi,allauzen,yvon}@limsi.fr
</p>
<p>R&#233;sum&#233;. Dans les syst&#232;mes de traduction statistique &#224; base de segments, le mod&#232;le de traduction est estim&#233; &#224; partir d&#8217;aligne-
ments mot-&#224;-mot gr&#226;ce &#224; des heuristiques d&#8217;extraction et de valuation. Bien que ces alignements mot-&#224;-mot soient construits par des
mod&#232;les probabilistes, les processus d&#8217;extraction et de valuation utilisent ces mod&#232;les en faisant l&#8217;hypoth&#232;se que ces alignements
sont d&#233;terministes. Dans cet article, nous proposons de lever cette hypoth&#232;se en consid&#233;rant l&#8217;ensemble de la matrice d&#8217;alignement,
d&#8217;une paire de phrases, chaque association &#233;tant valu&#233;e par sa probabilit&#233;. En comparaison avec les travaux ant&#233;rieurs, nous montrons
qu&#8217;en utilisant un mod&#232;le exponentiel pour estimer de mani&#232;re discriminante ces probabilit&#233;s, il est possible d&#8217;obtenir des am&#233;liora-
tions significatives des performances de traduction. Ces am&#233;liorations sont mesur&#233;es &#224; l&#8217;aide de la m&#233;trique BLEU sur la t&#226;che de
traduction de l&#8217;arabe vers l&#8217;anglais de l&#8217;&#233;valuation NIST MT&#8217;09, en consid&#233;rant deux types de conditions selon la taille du corpus de
donn&#233;es parall&#232;les utilis&#233;es.
</p>
<p>Abstract. In extant phrase-based statistical translation systems, the translation model relies on word-to-word alignments,
which serve as constraints for further heuristic extraction and scoring processes. These word alignments are infered in a probabilistic
framework ; yet, only one single best word alignment is used as if alignments were deterministically produced. In this paper, we
propose to take the full probabilistic alignment matrix into account, where each alignment link is scored by its probability score. By
comparison with previous attempts, we show that using an exponential model to compute these probabilities is an effective way to
achieve significant improvements in translation accuracy on the NIST MT&#8217;09 Arabic to English translation task, where the accuracy
is measured in terms of BLEU scores.
</p>
<p>Mots-cl&#233;s : traduction statistique, mod&#232;les de traduction &#224; base de segments, mod&#232;les d&#8217;alignement mot-&#224;-mot.
</p>
<p>Keywords: statistical machine translation, phrase based translation models, word alignment models.
</p>
<p>1 Introduction
</p>
<p>Dans les syst&#232;mes de traduction statistique &#224; base de segments (phrase-based systems), le mod&#232;le de traduction sert de pont entre
les langues source et cible. Sur la base d&#8217;hypoth&#232;ses de segmentation de la phrase source &#224; traduire, il permet de proposer, pour
chacun des segments, des traductions candidates en langue cible. Ces hypoth&#232;ses de traduction sont s&#233;lectionn&#233;es dans un inventaire
qui enregistre des appariements valu&#233;s entre segments de longueur variable. Ces associations et les scores qui les accompagnent
constituent la table de traductions (phrase-table).
</p>
<p>Ce mod&#232;le est estim&#233; en deux temps &#224; partir d&#8217;un corpus parall&#232;le : (i) extraction d&#8217;un ensemble de couples de segments candidats,
(ii) valuation des couples retenus dans la phase (i). Faute de disposer de m&#233;thodes d&#8217;estimation th&#233;oriquement bien fond&#233;es, cha-
cune de ces deux &#233;tapes repose sur un ensemble d&#8217;heuristiques. Il s&#8217;av&#232;re en effet impossible d&#8217;estimer directement les valuations
calcul&#233;es en (ii), ni m&#234;me de recencer tous les appariements possibles en (i). En effet, estimer de fa&#231;on non-supervis&#233;e un mod&#232;le
probabiliste des alignements de segments demanderait de pouvoir calculer des sommes sur tous les alignements de segments pos-
sibles, &#224; d&#233;faut, de savoir calculer un alignement optimal utilisant des segments de taille variable. Ces deux proc&#233;dures posent des
probl&#232;mes combinatoires NP-difficiles (DeNero &amp; Klein, 2008) et ne peuvent &#234;tre effectu&#233;es de mani&#232;re exacte. De mani&#232;re plus
subtile, construire des mod&#232;les d&#8217;alignements de segments demande de mettre en comp&#233;tition des segmentations conjointes de taille
variable des phrases source et cible, au risque de toujours pr&#233;f&#233;rer les alignements impliquant des segments longs. Enfin, ne consi-
d&#233;rer qu&#8217;une seule segmentation lors de l&#8217;apprentissage semble avoir un effet n&#233;gatif sur la capacit&#233; de g&#233;n&#233;ralisation du mod&#232;le
(DeNero et al., 2006).
</p>
<p>La solution pratique qui s&#8217;est progressivement impos&#233;e contourne le probl&#232;me en consid&#233;rant en premier lieu une segmentation</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADI TOMEH, ALEXANDRE ALLAUZEN ET FRAN&#199;OIS YVON
</p>
<p>maximale et en effectuant un alignement pr&#233;alable au niveau des mots ; des proc&#233;dures efficaces fond&#233;es sur l&#8217;algorithme EM
(Expectation-Maximisation) pour effectuer cet alignement de mani&#232;re efficace existent depuis le d&#233;but des ann&#233;es 90 (Brown et al.,
1993; Och &amp; Ney, 2003). Ces alignements de mots sont ensuite r&#233;-analys&#233;s pour en d&#233;duire des alignements de segments, la m&#233;thode
la plus r&#233;pandue consistant &#224; extraire les alignements de segments compatibles avec les contraintes pos&#233;es par les alignements de
mots.
</p>
<p>Dans un troisi&#232;me temps, les statistiques d&#8217;occurrence de ces alignements de segments sont collect&#233;es et utilis&#233;es pour attribuer des
scores de confiance &#224; ces groupes bilingues. Ces trois &#233;tapes successives de la construction du mod&#232;le de traduction sont usuelle-
ment abord&#233;es et optimis&#233;es s&#233;par&#233;ment les unes des autres. Le risque est naturellement que les erreurs s&#8217;accumulent le long de
cette s&#233;quence de traitements. Ainsi, des erreurs pr&#233;coces dans les calculs des alignements mot-&#224;-mot viennent bruiter le processus
d&#8217;extraction des couples de segments appari&#233;s et biaiser les calculs de scores aff&#233;rents.
</p>
<p>Pour pallier ce probl&#232;me, les auteurs de (Liu et al., 2009) proposent d&#8217;extraire davantage d&#8217;informations de la phase d&#8217;alignement
des mots, sous la forme d&#8217;une matrice d&#8217;alignements pond&#233;r&#233;s, qui repr&#233;sente de mani&#232;re compacte un ensemble d&#8217;alignements de
mots potentiels. Cette matrice est utilis&#233;e dans les &#233;tapes ult&#233;rieures de l&#8217;apprentissage. Dans une matrice pond&#233;r&#233;e, chaque lien
d&#8217;alignement potentiel est nanti d&#8217;une probabilit&#233; qui mesure la confiance dans l&#8217;alignement de ces deux mots. Dans (Liu et al.,
2009), ces probabilit&#233;s sont estim&#233;es &#224; partir du calcul des n-meilleurs alignements de mots tels que produits par les mod&#232;les d&#8217;ali-
gnement standards. &#192; l&#8217;aide de cette technique, ces auteurs parviennent &#224; am&#233;liorer de fa&#231;on modeste leurs syst&#232;mes de traduction
automatique. Une des limites de cette approche est toutefois l&#8217;utilisation d&#8217;une liste de n-meilleurs, qui ne repr&#233;sente que tr&#232;s im-
parfaitement la diversit&#233; et la variabilit&#233; des alignements de mots potentiels, et conduit &#224; des mauvais estimateurs des probabilit&#233;s a
posteriori des liens d&#8217;alignement.
</p>
<p>Dans ce travail, nous soutenons qu&#8217;une meilleure estimation des probabilit&#233;s des liens d&#8217;alignement est susceptible de donner lieu &#224;
de meilleurs mod&#232;les. Nous &#233;tudions donc une m&#233;thode alternative pour r&#233;aliser cette estimation, fond&#233;e sur des mod&#232;les discrimi-
nants pour l&#8217;alignement de mots (Ayan &amp; Dorr, 2006; Tomeh et al., 2010, 2011) et analysons les performances qu&#8217;elles permettent
d&#8217;obtenir. La principale contribution de ce travail est donc de nature empirique : en comparant diff&#233;rentes mani&#232;res de calculer et
d&#8217;exploiter ces matrices d&#8217;alignement pond&#233;r&#233;es, nous montrons qu&#8217;il peut &#234;tre b&#233;n&#233;fique, en particulier quand les donn&#233;es d&#8217;appren-
tissage du mod&#232;le de traduction sont r&#233;duites, de prendre en compte l&#8217;information contenue dans ces matrices, au-del&#224; du meilleur
alignement mot-&#224;-mot.
</p>
<p>Cet article est organis&#233; comme suit. Apr&#232;s avoir bri&#232;vement pos&#233; le cadre de la construction du mod&#232;le de traduction dans l&#8217;approche
standard, nous pr&#233;sentons &#224; la section 2 les principes de construction et d&#8217;exploitation de matrices d&#8217;alignements pond&#233;r&#233;es. Nous
introduisons, &#224; la section 3 une approche alternative permettant d&#8217;estimer directement la matrice d&#8217;alignement pond&#233;r&#233;e. Les r&#233;sultats
exp&#233;rimentaux sont ensuite d&#233;crits &#224; la section 4. Enfin, nous explicitons le positionnement de notre approche par rapport aux travaux
existants, avant de conclure et d&#8217;&#233;voquer diverses pistes vers lesquelles nous comptons nous orienter dans le futur.
</p>
<p>2 Matrices pond&#233;r&#233;es pour la construction de mod&#232;les de traduction
</p>
<p>Pour un syst&#232;me de traduction &#224; base de segments (Zens et al., 2002), le mod&#232;le de traduction est la source de connaissance principale
qui &#233;tablit une correspondance entre les deux langues (source et cible). Son r&#244;le est de guider la construction, pour chaque phrase
source, d&#8217;un ensemble d&#8217;hypoth&#232;ses de traduction en langue cible. L&#8217;unit&#233; de traduction est le segment, qui correspond &#224; un groupe
de mots contigus. L&#8217;association entre un segment source et une traduction possible en cible forme un bi-segment. Notons qu&#8217;il est
possible qu&#8217;un segment admette plusieurs traductions alternatives, donnant lieu &#224; plusieurs bi-segments partageant le m&#234;me segment
source. Afin de faire un bon usage de ces bi-segments, il est n&#233;cessaire de leur associer des mesures, par exemple statistiques, qui
quantifient la confiance en l&#8217;association ainsi r&#233;alis&#233;e.
</p>
<p>Dans la suite de cet article, nous utilisons les notations suivantes : un couple de phrases est d&#233;sign&#233; par (e, f), o&#249; la phrase source
f = f1, ..., fi, ..., fI est une s&#233;quence de I mots et la phrase cible e = e1, ..., ej , ..., eJ est une s&#233;quence de J mots. De plus, une
sous-s&#233;quence de mots extraite d&#8217;une phrase sera not&#233;e f i2i1 = fi1 . . . fi2 et donc f = f
</p>
<p>I
1 .
</p>
<p>2.1 Cadre g&#233;n&#233;ral
</p>
<p>Les m&#233;thodes d&#233;crites dans la litt&#233;rature pour construire le mod&#232;le de traduction peuvent se r&#233;sumer par l&#8217;algorithme pr&#233;sent&#233; dans
la partie gauche de la figure 1. Le point de d&#233;part est un couple de phrases accompagn&#233; d&#8217;un alignement mot-&#224;-mot repr&#233;sent&#233; par
une matrice d&#8217;alignement. Chaque cellule de cette matrice bool&#233;enne A = {ai,j : 1 &#8804; i &#8804; I, 1 &#8804; j &#8804; J} repr&#233;sente un lien</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ESTIMATION D&#8217;UN MOD&#200;LE DE TRADUCTION
</p>
<p>1: POUR toutes les paires de phrases (fJ1 , e
I
1) FAIRE
</p>
<p>2: POUR tous les segments f j2j1 FAIRE
3: Construire l&#8217;ensemble des bi-segmentsEA = {f j2j1 , ei2i1}
</p>
<p>satisfaisant le jeu de contraintes CA
4: Trier EA selon la fonction fR
5: Appliquer le crit&#232;re de s&#233;lection CS d&#233;finissant l&#8217;en-
</p>
<p>semble EAS des bi-segments &#224; extraire
6: Assigner une fonction de compte fC &#224; chaque bi-
</p>
<p>segments (f j2j1 , e
i2
i1) de EAS
</p>
<p>7: end POUR
8: end POUR
9: POUR chaque bi-segments extraite {(e, f)} FAIRE
</p>
<p>10: Calcul des scores :
</p>
<p>&#966;(e|f) = fC(e, f)&#8721;
fi
fC(e, fi)
</p>
<p>,
</p>
<p>lex(e|f,A) =
length(e)&#8719;
</p>
<p>i=1
</p>
<p>1
</p>
<p>|{j : (i, j) &#8712; A}|
&#8721;
</p>
<p>&#8704;(i,j)&#8712;a
w(ei|fj),
</p>
<p>o&#249; A d&#233;signe la matrice d&#8217;alignement, et w une probabi-
lit&#233; de traduction lexicale (IBM1 ou fr&#233;quence relative).
</p>
<p>11: end POUR
</p>
<p>Corpus parall&#232;le : 
e : je n' aime pas la glace au chocolat .
f  : I  do  not   like chocolate ice cream .    
</p>
<p>f : je n' aime pas la glace au chocolat .
</p>
<p>e : I do not like chocolate ice cream . f : je n' aime pas la glace au chocolat .
</p>
<p>e : I do not like chocolate ice cream .
</p>
<p>4 2e soumission &#224; TAL
</p>
<p>que les m&#233;thodes d&#8217;&#233;valuation (sous-section 2.4) et la mani&#232;re dont nous &#233;valuerons
les diff&#233;rents mod&#232;les.
</p>
<p>2.1. D&#233;finition
</p>
<p>Un alignement mot-&#224;-mot entre une phrase et sa traduction associe &#224; chaque mot
de cette phrase un mot de la traduction. Un alignement regroupe donc un ensemble de
liens d&#233;crivant une relation de traduction entre mots. Il est possible qu&#8217;un mot n&#8217;ait
pas de traduction directe, il est alors align&#233; sur un symbole sp&#233;cial not&#233; null.
</p>
<p>Dans la suite de cet article, nous utilisons les notations suivantes : un couple de
phrases est d&#233;sign&#233; par e, f , o&#249; la phrase e = e1, ..., ei, ..., eI est une s&#233;quence de I
mots et f = f1, ..., fj , ..., fJ est une s&#233;quence de J mots. Un alignem nt mot-&#224;- ot
d&#8217;un couple de phrases est repr&#233;sent&#233; par une matrice d&#8217;alignement. L&#8217;&#233;l&#233;ment (i, j)
de la matrice est 1 si le i&#232;me mot de e est align&#233; avec le j&#232;me mot de f et 0 sinon. La
Figure 1 donne un exemple de matrice d&#8217;alignement et des liens qui lui sont associ&#233;s.
</p>
<p>I
do
not
like
chocolate
ice
cream
.
</p>
<p>Je n&#8217; ai
m
</p>
<p>e
pa
</p>
<p>s
la gl
</p>
<p>ac
e
</p>
<p>au ch
oc
</p>
<p>ol
at
</p>
<p>.
</p>
<p>Figure 1. Exemple de matrice d&#8217;alignement entre une phrase anglaise et
une phrase fran&#231;aise. Les termes non nuls de la matrices sont repr&#233;sen-
t&#233;s par des carr&#233;s pleins. L&#8217;ensemble des liens associ&#233;s &#224; cette matrice est
{(1, 1), (2, 2), (2, 3), (3, 4), (4, 2), (4, 3), (6, 6), (6, 7), (7, 5), (8, 5), (9, 8)}
</p>
<p>Nous pouvons d&#8217;ores et d&#233;j&#224; remarquer qu&#8217;une matrice d&#8217;alignement comporte
majoritairement des termes nuls : en premi&#232;re approximation, chaque mot de la phrase
e est align&#233; avec un mot de la phrase f ; la matrice d&#8217;alignement comporte donc envi-
ron min(I, J) &#233;l&#233;ments non nuls o&#249; I et J sont les tailles des deux phrases &#224; aligner.
</p>
<p>glace au chocolat ||| chocolate ice cream |||0.82 0.21 0.81 0.49 2.72
</p>
<p>Mod&#232;le d'alignements mot-&#224;-mot
</p>
<p>Heuristique de sym&#233;trisation
</p>
<p>Extraction et &#233;valuation
des segments bilingues
</p>
<p>FIGURE 1 &#8211; Algorithme g&#233;n&#233;rique pour la construction du mod&#232;le de traduction et un exemple de son application fr&#233;quement utilis&#233;
</p>
<p>d&#8217;alignement potentiel ; la variable binaire ai,j vaut 1 si le lien entre le i&#232;me mot de f et le j&#232;me mot de e est actif, et 0 sinon.
</p>
<p>Un jeu de contraintes CA permet de d&#233;finir, parmi tous les bi-segments potentiellement contenus dans une paire de phrases, ceux qui
sont &#171; acceptables &#187; ou coh&#233;rents avec la matrice d&#8217;alignement. Les contraintes apport&#233;es par les alignements de mots permettent
l&#8217;&#233;num&#233;ration conjointe de toutes les segmentations de la paire de phrases avec tous les alignements de segments autoris&#233;s. Une fois
cet ensemble de bi-segments identifi&#233;, il est possible de le trier (fR) et de lui appliquer un crit&#232;re de s&#233;l&#233;ction CS afin d&#8217;&#233;liminer les
bi-segments qui semblent a priori les moins plausibles. La derni&#232;re &#233;tape concerne la valuation des bi-segments ainsi extraits. Les
fonctions de valuation les plus commun&#233;ment utilis&#233;es sont :
&#8211; la fr&#233;quence d&#8217;observation du segment e connaissant le segment f not&#233;e &#966;(e|f) ainsi que le terme sym&#233;trique &#966;(f |e) ;
&#8211; les poids lexicaux ou lexical weights dans les deux directions (lex(e|f,A) et lex(f |e,A)), qui utilisent, le plus souvent, les
</p>
<p>probabilit&#233;s de traduction lexicale du mod&#232;le IBM1.
Ces fonctions sont d&#233;finies dans l&#8217;algorithme d&#233;taill&#233; sur la figure 1 (ligne 10).
</p>
<p>L&#8217;instanciation standard de cet algorithme correspond aux travaux de (Zens et al., 2002; Koehn et al., 2003) (voir partie droite de la
figure 1), qui se d&#233;duit du cadre g&#233;n&#233;ral en utilisant les d&#233;finitions suivantes :
&#8211; CA repr&#233;sente des contraintes de coh&#233;rence qui s&#8217;appliquent &#224; un alignement mots-&#224;-mots sym&#233;tris&#233; d&#8217;une paire de phrases. Ces
</p>
<p>alignements se d&#233;duisent des deux meilleures hypoth&#232;ses donn&#233;es par le mod&#232;le IBM4 (une pour chaque direction de traduction),
sym&#233;tris&#233;es par l&#8217;heuristique grow-diag-final-and (Koehn et al., 2003).
</p>
<p>&#8211; La fonction de compte et celle de tri sont les m&#234;mes : fR = fC = 1
&#8211; la contrainte CS est d&#233;finie par un seuil portant sur la longueur relative des segments source et cible et permet de filtrer les
</p>
<p>bi-segments trop longs.
Les hypoth&#232;ses simplificatrices utilis&#233;es dans l&#8217;approche standard permettent d&#8217;obtenir une proc&#233;dure efficace et robuste ; elles
soul&#232;vent n&#233;anmoins quelques critiques. Tout d&#8217;abord, le choix du mod&#232;le IBM4 pose probl&#232;me puisque sa complexit&#233; interdit
d&#8217;utiliser des proc&#233;dures exactes lors de l&#8217;inf&#233;rence et du calcul des probabilit&#233;s a posteriori de chacun des liens d&#8217;alignement.
Ainsi, les contraintes de coh&#233;rence des bi-segments portent sur des alignements qui ne sont pas forc&#233;ment les meilleurs et pour
lesquels les approximations des probabilit&#233;s a posteriori ne refl&#232;tent qu&#8217;imparfaitement la confiance du mod&#232;le. Ce dernier point
implique naturellement le choix des fonctions de compte et de tri fC = fR = 1, puisqu&#8217;en l&#8217;absence de mesure de confiance,
une d&#233;cision binaire s&#8217;impose. Enfin, ces simplifications entra&#238;nent que l&#8217;exploration de la matrice d&#8217;alignement est restreinte &#224; la
sous-partie s&#233;lectionn&#233;e par les alignements IBM4 et ne prend pas en consid&#233;ration la plus grande partie de la matrice d&#8217;alignement.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADI TOMEH, ALEXANDRE ALLAUZEN ET FRAN&#199;OIS YVON
</p>
<p>0,9 0,5 0,8 
</p>
<p>0,8 0,6 0,7 0,2 
</p>
<p>0,4 0,8 0,7 0,1 0,3 0,1 
</p>
<p>0,4 0,8 0,2 0,3 0,1 
</p>
<p>0,1 0,6 0,3 0,8 0,2 
</p>
<p>0,1 0,4 0,8 0,7 0,2 0,1 
</p>
<p>0,9 0,1 0,3 
</p>
<p>0,4 0,5 0,6 0,5 
</p>
<p>0,9 0,4 0,8 0,8 
</p>
<p>0,8 1,0 
</p>
<p>i1 
</p>
<p>i2 
</p>
<p>j1 j2 
</p>
<p>, 
</p>
<p>, 
</p>
<p>FIGURE 2 &#8211; Illustration du calcul des comptes fractionnaire pour un bi-segment donn&#233;. Dans cet exemple, le calcul des comptes
fractionnaires se fait de la mani&#232;re suivante : fC(f
</p>
<p>j2
j1
, ei2i1) = &#945;(j1, j2, i1, i2)&#215; &#946;(j1, j2, i1, i2).
</p>
<p>2.2 La matrice d&#8217;alignement pond&#233;r&#233;e
</p>
<p>Dans (Liu et al., 2009), les auteurs proposent d&#8217;augmenter le nombre des alignements mot-&#224;-mot qui sont impliqu&#233;s dans l&#8217;estimation
des mod&#232;les de traduction et introduisent, &#224; cet effet, la notion de matrice d&#8217;alignement pond&#233;r&#233;e : Ap = {p(ai,j |e, f) : 1 &#8804; i &#8804;
I, 1 &#8804; j &#8804; J}. Dans cette matrice, chaque lien d&#8217;alignement est pond&#233;r&#233; par sa probabilit&#233; a posteriori p(ai,j |e, f). Ces probabilit&#233;s
sont calcul&#233;es &#224; partir des n-meilleurs alignements sym&#233;tris&#233;s propos&#233;s par le mod&#232;le IBM4. Partant de cette matrice, l&#8217;algorithme
repr&#233;sente &#224; la figure 1 est modifi&#233; de la mani&#232;re suivante :
&#8211; Les contraintes de coh&#233;rence CA stipulent qu&#8217;un bi-segment est acceptable si au moins un lien d&#8217;alignement ai,j &#224; l&#8217;int&#233;rieur du
</p>
<p>bi-segment est tel que p(ai,j |e, f) est sup&#233;rieur &#224; un certain seuil.
&#8211; Les fonctions de compte fC = fR prennent en compte le caract&#232;re non-d&#233;terministe des liens d&#8217;alignement de la mani&#232;re suivante.
</p>
<p>Pour un bi-segment fC(f
j2
j1
, ei2i1) :
</p>
<p>fC(f
j2
j1
, ei2i1) = &#945;(j1, j2, i1, i2)&#215; &#946;(j1, j2, i1, i2) avec (1)
</p>
<p>&#945;(j1, j2, i1, i2) = 1&#8722;
&#8719;
</p>
<p>(j,i)&#8712;in(j1,j2,i1,i2)
p&#772;(ai,j |e, f), (2)
</p>
<p>&#946;(j1, j2, i1, i2) =
&#8719;
</p>
<p>(j,i)&#8712;out(j1,j2,i1,i2)
p&#772;(ai,j |e, f) (3)
</p>
<p>o&#249; p&#772;(ai,j |e, f) = (1&#8722; p(ai,j |e, f)), le coefficient &#945; correspond &#224; la confiance accord&#233;e au lien &#224; l&#8217;int&#233;rieur (in) du bi-segment et
&#946; quantifie la masse totale de probabilit&#233; des liens situ&#233;s &#224; l&#8217;ext&#233;rieur (out) de ce bi-segment. L&#8217;estimation de cette fonction est
illustr&#233;e &#224; la figure 2.
</p>
<p>Avec ces nouvelles d&#233;finitions, l&#8217;&#233;valuation des bi-segments doit &#234;tre modifi&#233;e pour &#233;galement prendre en compte les probabilit&#233;s
des alignements. La fonction &#966; ne n&#233;cessite pas de modification, puisqu&#8217;elle utilise la fonction fC , qui a &#233;t&#233; red&#233;finie. En revanche,
les poids lexicaux sont maintenant d&#233;finis comme suit :
</p>
<p>lex(e|f,Ap) =
|e|&#8719;
i=1
</p>
<p>((
1
</p>
<p>{j|p(ai,j |e, f) &gt; 0}
&#8721;
</p>
<p>&#8704;j:p(ai,j |e,f)&gt;0
w(ei|fj)p(ai,j |e, f)
</p>
<p>)
+ w(ei|f0)
</p>
<p>|f |&#8719;
j=1
</p>
<p>p&#772;(ai,j |e, f)
)
. (4)
</p>
<p>L&#8217;une des hypoth&#232;ses explor&#233;e dans notre travail est que les gains modestes obtenus par (Liu et al., 2009) sont dus &#224; la m&#233;thode
utilis&#233;e pour estimer cette matrice pond&#233;r&#233;e, qui s&#8217;appuie sur un petit ensemble d&#8217;alignements calcul&#233;s par le mod&#232;le IBM4. En</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ESTIMATION D&#8217;UN MOD&#200;LE DE TRADUCTION
</p>
<p>effet l&#8217;&#233;chantillonnage des alignements en ne consid&#233;rant que les n-meilleures hypoth&#232;ses des mod&#232;les IBM4 (n = 10 en pratique)
revient &#224; consid&#233;rer qu&#8217;un sous-ensemble qui ne contient que peu de variation et beaucoup de redondance. Ainsi, l&#8217;exploration de la
matrice d&#8217;alignement est par construction tr&#232;s limit&#233;e et l&#8217;estimation approximative. Par ailleurs, le calcul de la matrice d&#8217;alignement
s&#8217;appuie sur une proc&#233;dure ad hoc de recombinaisons des probabilit&#233;s a posteriori des alignements initialement calcul&#233;s s&#233;par&#233;ment
pour chaque direction de traduction.
</p>
<p>L&#8217;alternative que nous proposons d&#8217;explorer consiste &#224; estimer cette matrice en utilisant une mod&#233;lisation directe de la probabilit&#233;
d&#8217;un lien d&#8217;alignement en utilisant des mod&#232;les conditionnels exponentiels qui seront d&#233;crits &#224; la section 3.
</p>
<p>3 Mod&#233;lisation de la matrice d&#8217;alignement
</p>
<p>Un alignement mot &#224; mot entre une phrase source, et sa traduction (la phrase cible) regroupe un ensemble de liens d&#233;crivant une
relation de traduction entre mots. Ainsi, pr&#233;dire la matrice d&#8217;alignement peut &#234;tre envisag&#233; comme un probl&#232;me de classification
supervis&#233;&#233; pour des donn&#233;es structur&#233;es. Lorsque des donn&#233;es &#233;tiquett&#233;es sont disponibles, la solution propos&#233;e dans (Ayan &amp; Dorr,
2006; Tomeh et al., 2010, 2011) consiste &#224; estimer de mani&#232;re ind&#233;pendante la probabilit&#233; de chaque lien dans la matrice &#224; l&#8217;aide
d&#8217;un mod&#232;le de r&#233;gression logistique d&#233;fini par :
</p>
<p>p (y|x) = 1
Z(x)
</p>
<p>exp
</p>
<p>(
K&#8721;
k=1
</p>
<p>&#955;kfk (y,x)
</p>
<p>)
, (5)
</p>
<p>o&#249; y d&#233;signe la variable al&#233;atoire binaire qui indique si un lien est actif, x l&#8217;observation, Z(x) le facteur de normalisation, (fk)Kk=1
d&#233;finit un ensemble de fonctions caract&#233;ristiques, et (&#955;k)Kk=1 les poids associ&#233;s. Dans l&#8217;&#233;quation (5), l&#8217;observation x d&#233;signe la paire
de phrases augment&#233;e de son &#233;tiquetage morphosyntaxique et des liens d&#8217;alignement produits par les mod&#232;les g&#233;n&#233;ratifs.
</p>
<p>Cette formulation du probl&#232;me permet de mod&#233;liser directement chaque cellule de la matrice d&#8217;alignement. Mais elle peut &#234;tre
&#233;galement per&#231;ue comme une mani&#232;re de fusionner diff&#233;rents alignements d&#8217;une paire de phrases. Cette approche permet donc
&#233;galement de remplacer l&#8217;&#233;tape heuristique de sym&#233;trisation, nomm&#233;e grow-diag-final-and (Koehn et al., 2003) dans l&#8217;approche
standard, par un mod&#232;le d&#8217;apprentissage statistique pouvant prendre en compte un nombre arbitraire d&#8217;alignements en entr&#233;e.
</p>
<p>Estimer ce mod&#232;le &#224; partir d&#8217;exemples demande n&#233;anmoins de prendre en consid&#233;ration le caract&#232;re tr&#232;s creux de la matrice d&#8217;ali-
gnement, cons&#233;quence du fait qu&#8217;une forte majorit&#233; de liens sont inactifs. La t&#226;che de classification consid&#233;r&#233;e est donc tr&#232;s d&#233;s-
&#233;quilibr&#233;e. Afin d&#8217;&#233;viter d&#8217;apprendre un classifieur trop biais&#233; en faveur de la pr&#233;diction de liens inactifs, l&#8217;ensemble des liens &#224;
&#233;tiqueter peut &#234;tre au pr&#233;alable r&#233;duit &#224; un sous-ensemble de la matrice. Pour d&#233;finir ce sous-ensemble, les mod&#232;les g&#233;n&#233;ratifs clas-
siques sont utilis&#233;s (mod&#232;les de Markov cach&#233;s et/ou IBM4 dans les deux directions) : tout lien qui n&#8217;apparait pas dans un des
alignements g&#233;n&#233;ratifs est consid&#233;r&#233; comme inactif ; les autres liens sont &#233;valu&#233;s par le mod&#232;le de classification. Dans ce cadre,
les alignements g&#233;n&#233;ratifs sont utilis&#233;s pour r&#233;duire l&#8217;espace de recherche et permettent de limiter l&#8217;effet potentiellement n&#233;faste de
donn&#233;es d&#233;s&#233;quilibr&#233;es (Ayan &amp; Dorr, 2006; Elming &amp; Habash, 2007).
</p>
<p>Ce mod&#232;le est utilis&#233; pour estimer la matrice pond&#233;r&#233;e d&#8217;alignementAp d&#233;crite &#224; la section 2.2. Le classifieur supervis&#233; estime donc
la probabilit&#233; p(ai,j |e, f) pour chaque cellule de la matrice.
</p>
<p>Apprentissage L&#8217;estimation des param&#232;tres du mod&#232;le (les &#955;k dans l&#8217;&#233;quation (5)) est faite de mani&#232;re &#224; maximiser la vraisem-
blance conditionnelle r&#233;gularis&#233;e &#224; partir d&#8217;un corpus d&#8217;entra&#238;nement. La r&#233;gularisation utilis&#233;e est connue sous le nom d&#8217; elastic-
net (Zou &amp; Hastie, 2005) et combine un terme de r&#233;gularisation `1, qui aide &#224; s&#233;lectionner les fonctions caract&#233;ristiques les plus
utiles et ainsi r&#233;duire la taille du mod&#232;le, et un terme de r&#233;gularisation `2, qui garantit que le Hessien de la fonction objectif n&#8217;est
jamais trop proche de z&#233;ro, et permet ainsi d&#8217;&#233;viter les probl&#232;mes d&#8217;instabilit&#233; num&#233;rique. Ce choix de r&#233;gularisation nous permet
d&#8217;envisager de nombreuses fonctions caract&#233;ristiques, sachant que certaines d&#8217;entre elles seront &#233;limin&#233;es lors de l&#8217;entra&#238;nement car
jug&#233;es inutiles.
</p>
<p>Les caract&#233;ristiques Les fonctions caract&#233;ristiques utilis&#233;es pour le classifieur sont d&#233;crites en d&#233;tail dans (Tomeh et al., 2010)
et reprennent en partie celles propos&#233;es par (Ayan &amp; Dorr, 2006). Elles prennent en compte les multiples sources d&#8217;informations :
la paire de phrases augment&#233;e de son &#233;tiquetage morphosyntaxique et les liens d&#8217;alignement produits par les diff&#233;rents mod&#232;les
g&#233;n&#233;ratifs consid&#233;r&#233;s. Ainsi, pour un lien d&#8217;alignement donn&#233;, ces fonctions binaires indiquent par exemple : l&#8217;association entre les
mots source/cible et de m&#234;me pour les &#233;tiquettes morphosyntaxiques associ&#233;es ; quel mod&#232;le g&#233;n&#233;ratif propose ce lien comme actif</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADI TOMEH, ALEXANDRE ALLAUZEN ET FRAN&#199;OIS YVON
</p>
<p>ainsi que le nombre total de mod&#232;les g&#233;n&#233;ratifs proposant ce lien comme actif ; combien de liens sont propos&#233;s par les mod&#232;les
g&#233;n&#233;ratifs dans le voisinage ; la fertilit&#233; du mot source (et resp. du mot cible) consid&#233;rant l&#8217;ensemble des alignements d&#8217;entr&#233;e ;
l&#8217;&#233;cart du lien &#224; la diagonale afin de favoriser ou non les alignements monotones ; la distance du lien avec le mot align&#233; le plus
proche (en source et en cible) afin de caract&#233;riser si ce lien est isol&#233; des autres.
</p>
<p>&#192; ces caract&#233;ristiques s&#8217;ajoutent celles que nous allons d&#233;crire. Une premi&#232;re famille de fonctions caract&#233;ristiques d&#233;crit les mots
source et cible relatifs &#224; un lien d&#8217;alignement (i.e une case de la matrice) :
&#8211; Probabilit&#233; de traduction lexicale pour le couple de mots utilis&#233; : p(fi|ej) et p(ei|fj) estim&#233;es par le mod&#232;le IBM1.
&#8211; La fr&#233;quence des mots source et cible ainsi que leur ratio.
&#8211; Un test sur tous les pr&#233;fixes et suffixes de longueur 3.
&#8211; La similarit&#233; entre les mots source et cible calcul&#233;e par la distance d&#8217;&#233;dition. Cette caract&#233;ristique tente de capturer la propension
</p>
<p>qu&#8217;ont les noms propres &#224; &#234;tre traduits de mani&#232;re similaire, comme par exemple : SdAm Hsyn et Saddam Hussein.
&#8211; Un test portant sur l&#8217;&#233;galit&#233; entre les mots source et cible.
&#8211; Un test indiquant si l&#8217;un des mots est une ponctuation associ&#233; avec un mot qui n&#8217;est pas une ponctuation.
Nous avons &#233;galement d&#233;finit un ensemble de fonctions caract&#233;ristiques permettant de d&#233;crire la structure de la matrice et les liens qui
la composent. En plus des fonctions d&#233;crites dans (Tomeh et al., 2010), nous ajoutons la fonction qui indique si un lien d&#8217;alignement
implique un mot dupliqu&#233; dans l&#8217;une des phrases. Cette caract&#233;ristique permet de pallier une faible mod&#233;lisation de la distorsion.
Par exemple le mot arabe fy peut appara&#238;tre plusieurs fois dans une m&#234;me phrase et &#234;tre ainsi toujours align&#233; avec le m&#234;me mot in
en cible. Cette fonction retourne la distance du lien consid&#233;r&#233; &#224; la diagonale.
</p>
<p>4 Exp&#233;riences
</p>
<p>Pour &#233;valuer les diff&#233;rentes approches, nous utilisons la t&#226;che de traduction de l&#8217;arabe vers l&#8217;anglais de l&#8217;&#233;valuation NIST MT&#8217;09.
Nous comparons quatre m&#233;thodes d&#8217;estimation de la matrice pond&#233;r&#233;e : l&#8217;approche standard qui utilise les mod&#232;les d&#8217;alignement
IBM4 et les heuristiques d&#8217;extraction et de valuation usuelles ; la m&#233;thode d&#233;crite dans le premier article sur les matrices pond&#233;-
r&#233;es (Liu et al., 2009) ; le syst&#232;me PostCAT (Gra&#231;a et al., 2010) (d&#233;crit bri&#232;vement &#224; la section 4.1) ; et l&#8217;estimation directe de la
matrice via un mod&#232;le de r&#233;gression logistique. Le syst&#232;me de traduction utilis&#233; est MOSES(Koehn et al., 2007), un outil sous licence
libre.
</p>
<p>4.1 Corpus et outils
</p>
<p>Pour entra&#238;ner le mod&#232;le logistique, nous avons utilis&#233; Wapiti (Lavergne et al., 2010) 1, avec comme corpus d&#8217;apprentissage et de
d&#233;veloppement les donn&#233;es align&#233;es manuellement du corpus IBMAC (Ittycheriah et al., 2006), contenant respectivement 10 000 et
663 paires de phrases. Nous avons construit 2 sous-ensembles, de taille diff&#233;rente, de donn&#233;es parall&#232;les pour entra&#238;ner le syst&#232;me
de traduction, afin d&#8217;&#233;valuer l&#8217;impact du volume de donn&#233;es disponibles sur les r&#233;sultats obtenus. Ces deux corpus ont &#233;t&#233; constitu&#233;s
&#224; partir des donn&#233;es autoris&#233;es dans la t&#226;che contrainte de l&#8217;&#233;valuation NIST MT&#8217;09. Elles sont toutes disponibles via le Linguistic
Data Consortium 2.
</p>
<p>Nous avons ainsi d&#233;fini 2 t&#226;ches, l&#8217;une avec un corpus parall&#232;le de 30 000 phrases (30k) et l&#8217;autre avec 130 000 phrases (130k). Les
syst&#232;mes de traduction sont construits avec MOSES 3 en utilisant la configuration par d&#233;faut. Les param&#232;tres de ces syst&#232;mes sont
optimis&#233;s de mani&#232;re usuelle avec l&#8217;outil MERT (Minimum Error Rate Training) avec comme donn&#233;es de d&#233;veloppement le corpus
NIST MT&#8217;06 contenant 1 800 phrases arabes et 4 traductions anglaises. Les traductions produites sont &#233;valu&#233;es avec la m&#233;trique
BLEU (Papineni et al., 2002) sur les donn&#233;es d&#8217;&#233;valuation NIST MT&#8217;08, qui contiennent 1 400 phrases et 53k mots.
</p>
<p>Pour le syst&#232;me PostCAT 4 et l&#8217;extraction des unit&#233;s de traduction 5, nous avons utilis&#233; les outils libres disponibles sur la toile. Enfin
les mod&#232;les de langue cible ont &#233;t&#233; appris avec la bo&#238;te &#224; outils SRILM 6 en utilisant toutes les donn&#233;es monolingues autoris&#233;es dans
le cadre de l&#8217;&#233;valuation NIST MT&#8217;09 (pour plus de d&#233;tails, on se reportera &#224; (Allauzen et al., 2009)).
</p>
<p>La partie anglaise des donn&#233;es est pr&#233;-trait&#233;e de mani&#232;re classique (les m&#233;thodes utilis&#233;es sont d&#233;crites dans (Allauzen et al., 2009)).
</p>
<p>1. http ://wapiti.limsi.fr/
2. La description compl&#232;te est disponible &#224; l&#8217;adresse http ://www.itl.nist.gov/iad/mig/tests/mt/2009/
3. http ://www.statmt.org/moses/
4. http://www.seas.upenn.edu/~strctlrn/CAT/CAT.html
5. http://www.nlp.org.cn/~liuyang/wam/wam.html.
6. http://www-speech.sri.com/projects/srilm/.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ESTIMATION D&#8217;UN MOD&#200;LE DE TRADUCTION
</p>
<p>Pour la partie arabe, toutes les phrases sont analys&#233;es et segment&#233;es avec l&#8217;outil MADA+TOKAN 7. Nous avons utilis&#233; le sch&#233;ma
de segmentation D2 afin de tenir compte de la morphologie riche de l&#8217;arabe et ainsi segmenter les mots arabes en des unit&#233;s qui
correspondent approximativement aux mots anglais.
</p>
<p>4.2 Construction des mod&#232;les de traduction
</p>
<p>Dans la section 2, nous avons d&#233;crit un algorithme g&#233;n&#233;rique pour la construction d&#8217;un mod&#232;le de traduction. Cet algorithme fonc-
tionne en trois &#233;tapes s&#233;par&#233;es : construction des matrices d&#8217;alignement pond&#233;r&#233;es, extraction puis &#233;valuation des bi-segments. Nous
allons maintenant &#233;valuer l&#8217;impact de ces trois &#233;tapes sur les r&#233;sultats en traduction automatique.
</p>
<p>Pour la premi&#232;re &#233;tape, nous exp&#233;rimentons deux mani&#232;res de construire les matrices pond&#233;r&#233;es :
(i) la m&#233;thode standard qui ne consid&#232;re que les meilleurs alignements
(ii) la matrice pond&#233;r&#233;e par les probabilit&#233;s qui est utilis&#233;e dans le processus d&#8217;extraction et de valuation.
</p>
<p>Notons qu&#8217;il est possible de passer de la configuration (ii) &#224; (i) par un simple seuillage sur les probabilit&#233;s. Dans toutes nos exp&#233;-
riences, nous utilisons un seuil de 0, 5. Ainsi, pour chaque mod&#232;le d&#8217;alignement, deux types de syst&#232;mes sont construits : standard
(configuration (i)) et WAM pour la matrice pond&#233;r&#233;e (configuration (ii) ). Le corpus de r&#233;f&#233;rence IBMAC contient &#233;galement un jeu
de test qui est utilis&#233; pour calculer le taux d&#8217;erreur d&#8217;alignement (ou AER, pour Alignment Error Rate).
</p>
<p>Les deux autres &#233;tapes (extraction et valuation des bi-segments) d&#233;pendent du mode de construction de la matrice d&#8217;alignement.
Dans le cas standard, les bi-segments sont extraits et &#233;valu&#233;s selon les heuristiques d&#233;crites &#224; la section 2.1. Lorsque l&#8217;on utilise
des matrices pond&#233;r&#233;es, nous utilisons les m&#233;thodes d&#8217;extraction et de valuation d&#233;crites &#224; la section 2.2, qui prennent en compte la
probabilit&#233; des liens d&#8217;alignement. Pour cette derni&#232;re approche, seuls les bi-segments dont la probabilit&#233; est sup&#233;rieure &#224; un seuil
sont conserv&#233;s. Ceci permet, comme le pr&#233;conisent les auteurs de (Liu et al., 2009), de restreindre le nombre de bi-segments qui
sont extraits. De plus, comme cela est fait dans l&#8217;approche standard, les bi-segments comprenant un segment de longueur sup&#233;rieur
&#224; 7 sont &#233;galement rejet&#233;s. Comme il est d&#8217;usage, les performances en traduction automatique sont &#233;valu&#233;es par la m&#233;trique BLEU
(Papineni et al., 2002).
</p>
<p>4.3 Mod&#232;les d&#8217;alignement mot-&#224;-mot
</p>
<p>En plus des deux m&#233;thodes de construction du mod&#232;le de traduction, nous avons &#233;galement consid&#233;r&#233; plusieurs mod&#232;les d&#8217;alignement
mot-&#224;-mot, que nous allons d&#233;crire bri&#232;vement.
</p>
<p>MGIZA++ 8 propose une impl&#233;mentation efficace et parall&#232;le (Gao &amp; Vogel, 2008) des mod&#232;les g&#233;n&#233;ratifs les plus utilis&#233;s : les
mod&#232;les IBM1 &#224; IBM4 (Brown et al., 1993) et HMM (Vogel et al., 1996). Ces mod&#232;les sont utilis&#233;s par la suite pour construire des
mod&#232;les de traduction selon la configuration standard et pour entra&#238;ner notre syst&#232;me d&#8217;alignement discriminant (voir section 3).
</p>
<p>N-best WAM construit la matrice pond&#233;r&#233;e en effectuant une moyenne des occurences des liens d&#8217;alignement &#224; partir des n-
meilleures s&#233;quences d&#8217;alignement produites par le mod&#232;le IBM4. Cette m&#233;thode correspond &#224; l&#8217;article original sur les matrices
pond&#233;r&#233;es (Liu et al., 2009). Comme ces auteurs, nous avons utilis&#233; la valeur n = 10.
</p>
<p>PostCAT (Posterior Constrained Alignment Toolkit) propose une impl&#233;mentation des mod&#232;les HMM permettant d&#8217;injecter des
contraintes lors de l&#8217;apprentissage via l&#8217;algorithme EM. Ces contraintes portent sur les probabilit&#233;s a posteriori des variables la-
tentes (Gra&#231;a et al., 2010) et permettent de corr&#233;ler les deux directions d&#8217;alignement. Deux types de contraintes simples (symm&#233;trie
et bijectivit&#233;) permettent au mod&#232;le HMM d&#8217;atteindre des performances comparables au mod&#232;le IBM4. Le fait d&#8217;utiliser des mod&#232;les
HMM permet de pouvoir calculer de mani&#232;re exacte et efficace les probabilit&#233;s a posteriori et ainsi construire la matrice pond&#233;r&#233;e
en consid&#233;rant l&#8217;ensemble des liens d&#8217;alignement. Dans cet article, nous avons utilis&#233; la boite &#224; outils Geppetto 9 (Ling et al., 2010),
une impl&#233;mentation de PostCAT et des matrices d&#8217;alignement pond&#233;r&#233;es.
</p>
<p>7. http ://www1.ccls.columbia.edu/ cadim/MADA.html
8. http ://geek.kyloo.net/
9. http ://code.google.com/p/geppetto/</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADI TOMEH, ALEXANDRE ALLAUZEN ET FRAN&#199;OIS YVON
</p>
<p>MaxEntWA est le syst&#232;me d&#233;crit &#224; la section 3. Il s&#8217;agit d&#8217;un classifieur MaxEnt qui pr&#233;dit pour chaque lien de la matrice sa
probabilit&#233; a posteriori.
</p>
<p>Exception faite du mod&#232;le not&#233; MGIZA++, il est possible pour tous les mod&#232;les d&#8217;extraire et de valuer les bi-segments selon les
deux m&#233;thodes. Pour appliquer la m&#233;thode (i), nous avons appliqu&#233; pour toutes les exp&#233;riences un seuil de 0, 1 comme les auteurs
de (Liu et al., 2009).
</p>
<p>4.4 R&#233;sultats
</p>
<p>Les r&#233;sultats exp&#233;rimentaux pour les diff&#233;rentes configurations et les diff&#233;rents mod&#232;les d&#8217;alignement sont rassembl&#233;s dans le ta-
bleau 1. Examinons pour commencer, la partie 30k du tableau qui correspond aux exp&#233;riences o&#249; MOSES a &#233;t&#233; entra&#238;n&#233; sur un corpus
de 30 000 phrases parall&#232;les. La partie MGIZA++ pr&#233;sente les r&#233;sultats obtenus en utilisant l&#8217;approche standard : utilisation des
meilleures hypoth&#232;ses d&#8217;alignement IBM4 symmetris&#233;s pour extraire et valuer les bi-segments via les heuristiques usuelles (Koehn
et al., 2003). Ainsi sur la t&#226;che 30k, le syst&#232;me standard obtient un score BLEU de 35,9. La partie 10-best WAM correspond au
matrice pond&#233;r&#233;e o&#249; les probabibilit&#233;s a posteriori sont estim&#233;es &#224; partir des 10 meilleurs alignements de IBM4. Cette approche
permet d&#8217;obtenir un faible gain de 0,3 points BLEU par rapport &#224; l&#8217;approche standard, soit (36,2). Ce r&#233;sultat est coh&#233;rent avec ceux
publi&#233;s dans (Liu et al., 2009).
</p>
<p>La partie PostCAT introduit par rapport aux travaux de (Liu et al., 2009) l&#8217;utilisation des mod&#232;les HMM pour les alignements de
mot et donc la possibilit&#233; d&#8217;estimer les probabilit&#233;s a posteriori de mani&#232;re exacte pour l&#8217;ensemble de la matrice. Cet apport permet
d&#8217;augmenter le BLEU de mani&#232;re significative : de 35,9 &#224; 36,9 ou 37,0 selon la variante du mod&#232;le HMM utilis&#233;e. Enfin la partie
MaxEntWA pr&#233;sente les r&#233;sultats obtenus en utilisant un mod&#232;le exponentiel pour pr&#233;dire la matrice d&#8217;alignement. Les r&#233;sultats
montrent un gain en BLEU suppl&#233;mentaire et cons&#233;quent : 1,5 points par rapport &#224; l&#8217;approche standard et 0,5 points par rapport &#224;
l&#8217;approche PostCAT. Notons &#233;galement, que m&#234;me si les m&#233;thodes standard d&#8217;extraction et de valuation sont utilis&#233;es, les matrices
d&#8217;alignements engendr&#233;es par PostCAT et MaxEntWA permettent d&#8217;obtenir de meilleurs r&#233;sultats et que MaxEntWA est &#224; nouveau la
m&#233;thode donnant le meilleur r&#233;sultat.
</p>
<p>Sur la t&#226;che 130k (MOSES est entrain&#233; sur 130 000 phrases parall&#232;les), nous observons les m&#234;mes tendances, avec cependant des
gains en BLEU moindres. Notons que le gain modeste obtenu avec la m&#233;thode 10-best pour estimer la matrice pond&#233;r&#233;e est similaire
&#224; celui obtenu sur la t&#226;che 30k. Pour les autres m&#233;thodes de calcul de la matrice pond&#233;r&#233;e, les gains restent significatifs, bien
que moins importants. De nouveau, nous pouvons observer que le calcul de la matrice d&#8217;alignement avec le mod&#232;le de r&#233;gression
logisitique (MaxEntWA) permet d&#8217;obtenir de meilleurs r&#233;sultats en termes de score BLEU.
</p>
<p>La colonne PT du tableau 1 indique la taille du mod&#232;le de traduction en nombre de bi-segments extraits. Nous observons, tout
naturellement, que quand on consid&#232;re l&#8217;int&#233;gralit&#233; de la matrice pond&#233;r&#233;e (PostCAT et MaxEntWA), la taille du mod&#232;le de traduction
augmente consid&#233;rablement, puisqu&#8217;elle se trouve multipli&#233;e par plus de 4, alors m&#234;me que le seuil de filtrage est rest&#233; constant &#224; 0,1.
Le risque &#233;tait, en multipliant les entr&#233;es du mod&#232;le de traduction, d&#8217;ajouter un bruit pouvant affecter le comportement global du
syst&#232;me. Toutefois, il appara&#238;t que la valuation des bi-segments par les probabilit&#233;s (voir la section 2.2) est un moyen effectif pour
filtrer les bi-segments les moins utiles lors de l&#8217;&#233;tape de traduction.
</p>
<p>Ainsi, l&#8217;am&#233;lioration de la valuation des bi-segments a un impact significatif sur les r&#233;sultats en BLEU. Si cette am&#233;lioration peut &#234;tre
imput&#233;e en partie &#224; l&#8217;utilisation des matrice pond&#233;r&#233;e, la colonne AER (Alignment Error Rate) montre que cette am&#233;lioration peut
provenir &#233;galement d&#8217;alignements mot-&#224;-mot de meilleure qualit&#233;. Partant d&#8217;un l&#8217;AER obtenu avec les mod&#232;les IBM4 sym&#233;tris&#233;s
d&#8217;une valeur de 25,0%, on note tout d&#8217;abord que l&#8217;usage des 10-meilleurs alignements ne permet pas d&#8217;am&#233;liorer la qualit&#233; intrin-
s&#232;que des alignements. En revanche, l&#8217;utilisation d&#8217;un mod&#232;le plus appropri&#233; tel que PostCAT entra&#238;ne une am&#233;lioration sensible
des alignements, avec un AER de 22,5%. Cette tendance est encore plus affirm&#233;e avec la m&#233;thode MaxEntWA, qui introduit dans le
processus des alignements de qualit&#233; nettement accrue, puisque la r&#233;duction absolue de l&#8217;AER est de plus de 10 points.
</p>
<p>Globalement, les r&#233;sultats exp&#233;rimentaux montrent que l&#8217;utilisation de la matrice pond&#233;r&#233;e pour extraire et valuer les bi-segments
permet d&#8217;am&#233;liorer les performances des syst&#232;mes de traduction, quand cette m&#233;thode est associ&#233;e &#224; un mode de calcul pertinent
pour les valuations de la matrice pond&#233;r&#233;e. Ce dernier point recouvre d&#8217;une part la mani&#232;re dont sont calcul&#233;es les probabilit&#233;s
d&#8217;alignement, et d&#8217;autre part la fraction de cette matrice qui est effectivement explor&#233;e. La diff&#233;rence de r&#233;sultats entre les deux
t&#226;ches (30k et 130k) sugg&#232;re que l&#8217;utilisation d&#8217;un mod&#232;le de r&#233;gression logistique pour estimer la matrice pond&#233;r&#233;e conduit &#224;
des gains bien plus importants sur la petite t&#226;che (30k). Une explication de cette diff&#233;rence est que cette approche permet, lorsque
l&#8217;on dispose de peu de donn&#233;es parall&#232;les, d&#8217;extraire plus de bi-segments : lorsque les donn&#233;es manquent pour estimer le mod&#232;le
de traduction, il est en effet important de pouvoir malgr&#233; tout engendrer un grand nombre de bi-segments potentiels. De surcro&#238;t,
on note que la valuation par des probabilit&#233;s permet effectivement de limiter, au moment du d&#233;codage, les effets de l&#8217;introduction
d&#8217;entr&#233;es bruit&#233;es dans la table de traduction.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ESTIMATION D&#8217;UN MOD&#200;LE DE TRADUCTION
</p>
<p>T&#226;che de traduction : 30K 130K
</p>
<p>Construction du MT : Standard(i) WAM(ii) Standard(i) WAM(ii)
</p>
<p>Alignement AER BLEU PT BLEU PT AER BLEU PT BLEU PT
</p>
<p>MGIZA++ HMM 28,4 35,0 3,6 - - 26,8 39,2 9,7 - -IBM4 25,0 35,9 2,4 - - 23,3 40,2 6,5 - -
</p>
<p>10-best IBM4 24,9 35,8 2,4 36,2 3,0 23,3 40,0 6,6 40,4 8,5
</p>
<p>PostCAT Bijective 22,5 36,6 3,3 36,9 10,2 20,5 40,1 9,1 40,6 29,5Symmetric 22,5 36,7 2,9 37,0 10,7 20,8 40,2 8,5 40,4 30,2
</p>
<p>MaxEntWA
HMM 17,6 36,9 6,7 37,5 11,7 16,4 40,5 17,7 40,8 30,0
IBM4 15,6 37,2 5,5 37,5 9,6 14,3 41,0 14,5 41,1 25,0
</p>
<p>HMM+IBM 1,3,4 14,7 37,1 5,2 37,9 8,6 13,9 40,8 13,4 41,1 22,2
</p>
<p>TABLE 1 &#8211; Comparaison de 4 mod&#232;les d&#8217;alignement (MGIZA++, 10-best, PostCAT and MaxEntWA) et de leurs interactions avec
la m&#233;thode d&#8217;extraction et de valuation de la table de traduction en termes de taux d&#8217;erreur d&#8217;alignement (AER), de score BLEU
et de la taille de la table de traduction exprim&#233;e en millions de bi-segments (PT). Les deux m&#233;thodes de construction du mod&#232;le
de traduction (MT) sont l&#8217;approche standard (standard) et celle utilisant les matrices pond&#233;r&#233;es (WAM). Deux tailles de donn&#233;es
parall&#232;les d&#8217;apprentissage sont consid&#233;r&#233;es (30K et 130K).
</p>
<p>5 Discussion
</p>
<p>De nombreux travaux r&#233;cents se sont int&#233;ress&#233;s aux m&#233;thodes d&#8217;extraction d&#8217;unit&#233;s de traduction &#224; partir de corpus parall&#232;les. Que
ce soit dans le cadre des syst&#232;mes hi&#233;rarchiques ou &#224; base de segments, le processus d&#8217;extraction (Koehn et al., 2003; Chiang, 2007)
repose sur les matrices d&#8217;alignement mot-&#224;-mot construites &#224; partir des mod&#232;les d&#8217;alignement IBM4 (Brown et al., 1993) sym&#233;tris&#233;s.
Comme nous l&#8217;avons &#233;voqu&#233; &#224; la section 2.1, ce choix de la premi&#232;re &#233;tape se justifie par un souci d&#8217;efficacit&#233; puisqu&#8217;il restreint
consid&#233;rablement l&#8217;espace des unit&#233;s qui sont explor&#233;es, puis s&#233;lectionn&#233;es. N&#233;anmoins, ce choix favorise la propagation d&#8217;erreurs
dues &#224; des d&#233;cisions (d&#8217;accepter ou de rejeter des liens d&#8217;alignement) qui sont prises trop t&#244;t dans le processus, sans qu&#8217;il soit de
surcroit possible d&#8217;affecter de r&#233;els scores de confiance &#224; ces d&#233;cisions.
</p>
<p>Lorsqu&#8217;il s&#8217;agit d&#8217;&#233;tendre l&#8217;espace des unit&#233;s qui sont explor&#233;es, la premi&#232;re difficult&#233; est la complexit&#233; qui r&#233;sulte de l&#8217;&#233;num&#233;ration
puis de la valuation de toutes les unit&#233;s de traduction possible. Ainsi, une partie des travaux r&#233;cents s&#8217;int&#233;resse &#224; l&#8217;&#233;laboration d&#8217;une
repr&#233;sentation efficace. Dans (Mi &amp; Huang, 2008), le processus d&#8217;extraction des r&#232;gles pour un syst&#232;me hi&#233;rarchique est &#233;tendu en
consid&#233;rant l&#8217;ensemble compos&#233; des n-meilleurs arbres d&#8217;analyse syntaxique au lieu de tenir compte uniquement du meilleur. Afin
de repr&#233;senter puis de manipuler efficacement ces n-meilleurs arbres, les auteurs utilisent une repr&#233;sentation efficace (packed forest)
(Billot &amp; Lang, 1989) ayant &#233;galement d&#233;montr&#233; son utilit&#233; (Galley et al., 2006; Wang et al., 2007) en traduction automatique.
</p>
<p>De mani&#232;re similaire, les n-meilleurs alignements peuvent &#234;tre utilis&#233;s afin d&#8217;enrichir la matrice d&#8217;alignement, que ce soit pour
extraire les bi-segments (Xue et al., 2006), ou les r&#232;gles d&#8217;un syst&#232;me hi&#233;rarchique (Venugopal et al., 2008). Dans ce dernier article
comme dans (Mi &amp; Huang, 2008), les auteurs d&#233;finissent une distribution de probabilit&#233; sur les alignements &#224; partir des n-meilleurs
alignements et des n-meilleurs arbres d&#8217;analyse syntaxique. Cette approche par &#233;chantillonage permet aux auteurs d&#8217;introduire des
comptes fractionnaires pour les r&#232;gles extraites et ainsi de pouvoir estimer le mod&#232;le de traduction.
</p>
<p>Ce recours &#224; l&#8217;&#233;chantillonnage pour l&#8217;inf&#233;rence des probabilit&#233;s a posteriori des d&#8217;alignement se justifie par la complexit&#233; d&#8217;inf&#233;rence
du mod&#232;le IBM4. Il existe en revanche, pour les mod&#232;les plus simples, tels que ceux qui s&#8217;inspirent des mod&#232;les de Markov cach&#233;s
(souvent d&#233;sign&#233;s de mani&#232;re g&#233;n&#233;rique sous le nom de &#171; mod&#232;le HMM &#187;) (Vogel et al., 1996) ou pour le mod&#232;le IBM1 (Brown
et al., 1993), des algorithmes d&#8217;inf&#233;rence exacts et efficaces (Venugopal et al., 2003; Deng &amp; Byrne, 2005). Une des limitations
du mod&#232;le HMM est son absence de mod&#233;lisation de la fertilit&#233;. Pour pallier cette limitation, les auteurs de (Deng &amp; Byrne, 2005)
d&#233;finissent un HMM permettant d&#8217;aligner des mots avec des segments qui rivalise en termes de performances avec le mod&#232;leIBM4,
tout en pr&#233;servant la possibilit&#233; d&#8217;un calcul exact des probabilit&#233;s a posteriori des alignements de mots et qui s&#8217;&#233;tend au calcul de
distributions a posteriori des segments ou des r&#232;gles. Les exp&#233;riences montrent que cette approche am&#233;liore significativement le pro-
cessus d&#8217;extraction d&#8217;unit&#233;s de traductions pour les syst&#232;mes &#224; base de segments (Deng &amp; Byrne, 2005) et hi&#233;rarchiques (de Gispert
et al., 2010).
</p>
<p>L&#8217;introduction des matrices pond&#233;r&#233;es (Liu et al., 2009) que nous d&#233;crivons &#224; la section 2 peut &#234;tre consid&#233;r&#233;e comme l&#8217;adaptation</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADI TOMEH, ALEXANDRE ALLAUZEN ET FRAN&#199;OIS YVON
</p>
<p>des packed forests des syst&#232;mes hi&#233;rarchiques au syst&#232;mes &#224; base de segments : une exploration plus exhaustive de la matrice
d&#8217;alignement, l&#8217;usage des probabilit&#233;s des alignements de mots pour d&#233;river des scores de confiance sur les bi-segments extraits.
Pour ce dernier point, les auteurs s&#8217;inspirent d&#8217;ailleurs des travaux de (Mi &amp; Huang, 2008).
</p>
<p>Comme mentionn&#233; &#224; la section 2, un des probl&#232;me des matrices pond&#233;r&#233;es est l&#8217;estimation des probabilit&#233;s a posteriori des aligne-
ments. Dans (Liu et al., 2009), cette estimation est faite en &#233;chantillonnant les n-meilleurs alignements des mod&#232;les IBM4, alors que
dans (Deng &amp; Byrne, 2005; de Gispert et al., 2010; Ling et al., 2010) le mod&#232;le HMM ou une de ses variante est utilis&#233; pour les
estimer de mani&#232;re exacte. Cependant, dans ce dernier type d&#8217;approche, il est encore n&#233;cessaire de fusionner les alignements corres-
pondant aux deux directions (un mod&#232;le d&#8217;alignement de source vers cible et r&#233;ciproquement). Les solutions envisag&#233;es semblent
peu satisfaisantes : soit la fusion est heuristique et consiste simplement &#224; prendre la moyenne arithm&#233;tique des distributions a poste-
riori (Gra&#231;a et al., 2010; Ling et al., 2010) ; soit de mani&#232;re beaucoup plus co&#251;teuse, deux syst&#232;mes de traduction ind&#233;pendants sont
utilis&#233;s utilisant chaque mod&#232;le HMM, la fusion se fait alors sur les treillis engendr&#233;s par chaque syst&#232;me (de Gispert et al., 2010).
</p>
<p>Dans cet article, nous introduisons donc une extension du travail de (Liu et al., 2009) en proposant une nouvelle m&#233;thode de
construction de la matrice d&#8217;alignement. Pour cela, nous proposons d&#8217;utiliser un classifieur au maximum d&#8217;entropie d&#233;crit dans (Ayan
&amp; Dorr, 2006; Tomeh et al., 2010, 2011). Cette approche permet en effet de calculer directement la matrice pond&#233;r&#233;e sans avoir
recours ni &#224; une fusion heuristique des distributions a posteriori, ni &#224; une co&#251;teuse &#233;tape de fusion de syst&#232;me. Faute de donn&#233;es
&#233;tiquett&#233;es permettant de mettre en &#339;uvre cette d&#233;marche, l&#8217;approche de (Gra&#231;a et al., 2010) semble fournir des performances
proches de nos meilleurs r&#233;sultats.
</p>
<p>6 Conclusion
</p>
<p>Dans cet article, nous avons abord&#233; le probl&#232;me de l&#8217;estimation des mod&#232;les de traduction &#224; partir d&#8217;alignements mot-&#224;-mot non-
d&#233;terministes. En effet, dans l&#8217;approche consid&#233;r&#233;e comme standard, les mod&#232;les de traduction sont estim&#233;s &#224; partir d&#8217;alignements
mot-&#224;-mot gr&#226;ce &#224; des heuristiques d&#8217;extraction et de valuation. Bien que ces alignements mot-&#224;-mot soient construits par des mo-
d&#232;les probabilistes, les processus d&#8217;extraction et de valuation utilisent ces mod&#232;les comme produisant des alignements d&#233;terministes.
&#192; la suite (Liu et al., 2009), la solution que nous avons envisag&#233;e l&#232;ve cette limitation en consid&#233;rant une matrice d&#8217;alignement
pond&#233;r&#233;e, dans laquelle chaque lien d&#8217;alignement est valu&#233; par sa probabilit&#233;. Les premiers travaux dans cette direction &#233;taient, selon
nos hypoth&#232;ses, limit&#233;s par la m&#233;thode d&#8217;estimation de la matrice pond&#233;r&#233;e, et nous avons propos&#233; une m&#233;thode permettant d&#8217;estimer
directement cette matrice &#224; l&#8217;aide d&#8217;une m&#233;thode de classification supervis&#233;e.
</p>
<p>Afin de valider cette approche, nous avons effectu&#233; des exp&#233;riences sur la t&#226;che de traduction automatique de l&#8217;Arabe vers l&#8217;Anglais
de l&#8217;&#233;valuation NIST MT&#8217;09. Dans ce cadre exp&#233;rimental, nous avons compar&#233; 4 m&#233;thodes de construction du mod&#232;le de traduc-
tion, contrastant ainsi l&#8217;approche standard avec l&#8217;usage des matrices pond&#233;r&#233;es, et &#233;valuant diff&#233;rents estimateurs de cette matrice.
Les r&#233;sultats ont montr&#233; que l&#8217;usage des matrices pond&#233;r&#233;es impliquait une extraction plus importante de bi-segments et que leur
valuation adapt&#233;e permettait au syst&#232;me de traduction d&#8217;obtenir de meilleurs r&#233;sultats mesur&#233;s en terme de BLEU. En particulier,
des gains significatifs (entre 2 et 0,9 point BLEU, selon la t&#226;che consid&#233;r&#233;e) ont &#233;t&#233; obtenus par notre m&#233;thode, qui semble la mieux
&#224; m&#234;me de produire des alignements de bonne qualit&#233; (au sens de l&#8217;AER). Ces r&#233;sultats nous ont permis de conclure que le choix
de l&#8217;estimateur des matrices pond&#233;r&#233;s a un impact net sur les performances en traduction et que notre m&#233;thode est nettement plus
pertinente que celles propos&#233;es dans les travaux ant&#233;rieurs.
</p>
<p>Contrairement aux heuristiques standard, notre m&#233;thode permet de contr&#244;ler et d&#8217;adapter le nombre de bi-segments extraits &#224; la taille
des donn&#233;es parall&#232;les d&#8217;entra&#238;nement. Nous souhaitons donc &#224; l&#8217;avenir explorer cet aspect. L&#8217;approche envisag&#233;e consiste &#224; extraire
le plus de bi-segments possibles et &#224; travailler sur leur filtrage. L&#8217;int&#233;r&#234;t de cette approche est que nous pensons ainsi limiter l&#8217;impact
des erreurs commises par les mod&#232;les d&#8217;alignement. De plus, l&#8217;&#233;tape de filtrage peut se faire en prenant en compte l&#8217;utilit&#233; des bi-
segments lors de l&#8217;&#233;tape de traduction et ainsi ne pas se limiter &#224; des tests statistiques qui ne prennent pas en compte la finalit&#233; des
mod&#232;les de traduction. Des articles r&#233;cents comme (Wuebker et al., 2010) montrent l&#8217;importance d&#8217;une valuation des bi-segments
qui am&#233;liorerait les simples calculs de fr&#233;quences, et qui serait plus directement en rapport avec la finalit&#233; des mod&#232;les de traduction.
</p>
<p>Remerciements
</p>
<p>Ces travaux ont &#233;t&#233; en partie financ&#233; par l&#8217;agence OSEO dans le cadre du programme Quaero. Les auteurs tiennent &#224; remercier
Thomas Lavergne pour son aide pr&#233;cieuse concernant la mise en &#339;uvre de Wapiti.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>ESTIMATION D&#8217;UN MOD&#200;LE DE TRADUCTION
</p>
<p>R&#233;f&#233;rences
</p>
<p>ALLAUZEN A., CREGO J., MAX A. &amp; YVON F. (2009). LIMSI&#8217;s statistical translation systems for WMT&#8217;09. In Proc. of the 4th
Workshop on Statistical Machine Translation, p. 100&#8211;104, Athens, Greece : Association for Computational Linguistics.
AYAN N. F. &amp; DORR B. J. (2006). A maximum entropy approach to combining word alignments. In Proceedings of the main
conference on Human Language Technology Conference of the North American Chapter of the Association of Computational
Linguistics, p. 96&#8211;103 : Association for Computational Linguistics.
BILLOT S. &amp; LANG B. (1989). The structure of shared forests in ambiguous parsing. In Proceedings of the 27th annual meeting
on Association for Computational Linguistics, ACL &#8217;89, p. 143&#8211;151.
BROWN P. F., PIETRA V. J. D., PIETRA S. A. D. &amp; MERCER R. L. (1993). The mathematics of statistical machine translation :
parameter estimation. Comput. Linguist., 19, 263&#8211;311.
CHIANG D. (2007). Hierarchical phrase-based translation. Comput. Linguist., 33(2), 201&#8211;228.
DE GISPERT A., PINO J. &amp; BYRNE W. (2010). Hierarchical phrase-based translation grammars extracted from alignment posterior
probabilities. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &#8217;10, p. 545&#8211;
554, Morristown, NJ, USA : Association for Computational Linguistics.
DENERO J., GILLICK D., ZHANG J. &amp; KLEIN D. (2006). Why generative phrase models underperform surface heuristics.
In Proceedings on the Workshop on Statistical Machine Translation, p. 31&#8211;38, New York City : Association for Computational
Linguistics.
DENERO J. &amp; KLEIN D. (2008). The complexity of phrase alignment problems. In Proceedings of ACL-08 : HLT, Short Papers,
p. 25&#8211;28, Columbus, Ohio : Association for Computational Linguistics.
DENG Y. &amp; BYRNE W. (2005). Hmm word and phrase alignment for statistical machine translation. In Proceedings of the
conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT &#8217;05, p. 169&#8211;176,
Morristown, NJ, USA : Association for Computational Linguistics.
ELMING J. &amp; HABASH N. (2007). Combination of statistical word alignments based on multiple preprocessing schemes. In Human
Language Technologies 2007 : The Conference of the North American Chapter of the Association for Computational Linguistics ;
Companion Volume, Short Papers, NAACL-Short &#8217;07, p. 25&#8211;28, Stroudsburg, PA, USA : Association for Computational Linguistics.
GALLEY M., GRAEHL J., KNIGHT K., MARCU D., DENEEFE S., WANG W. &amp; THAYER I. (2006). Scalable inference and
training of context-rich syntactic translation models. In Proceedings of the 21st International Conference on Computational Lin-
guistics and 44th Annual Meeting of the Association for Computational Linguistics, p. 961&#8211;968, Sydney, Australia : Association
for Computational Linguistics.
GAO Q. &amp; VOGEL S. (2008). Parallel implementations of word alignment tool. In Software Engineering, Testing, and Quality
Assurance for Natural Language Processing, SETQA-NLP &#8217;08, p. 49&#8211;57, Stroudsburg, PA, USA : Association for Computational
Linguistics.
GRA&#199;A J. A. V., GANCHEV K. &amp; TASKAR B. (2010). Learning tractable word alignment models with complex constraints.
Comput. Linguist., 36, 481&#8211;504.
ITTYCHERIAH A., AL-ONAIZAN Y. &amp; ROUKOS S. (2006). The IBM Arabic-English Word Alignment Corpus. Rapport interne
RC24024, IBM.
KOEHN P., HOANG H., BIRCH A., CALLISON-BURCH C., FEDERICO M., BERTOLDI N., COWAN B., SHEN W., MORAN C.,
ZENS R., DYER C., BOJAR O., CONSTANTIN A. &amp; HERBST E. (2007). Moses : Open source toolkit for statistical machine
translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume
Proceedings of the Demo and Poster Sessions, p. 177&#8211;180, Prague, Czech Republic : Association for Computational Linguistics.
KOEHN P., OCH F. J. &amp; MARCU D. (2003). Statistical phrase-based translation. In NAACL &#8217;03 : Proceedings of the 2003
Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, p.
48&#8211;54 : Association for Computational Linguistics.
LAVERGNE T., CAPP&#201; O. &amp; YVON F. (2010). Practical very large scale CRFs. In Proceedings the 48th Annual Meeting of the
Association for Computational Linguistics (ACL), p. 504&#8211;513 : Association for Computational Linguistics.
LING W., LU&#205;S T., GRA&#199;A J., COHEUR L. &amp; TRANCOSO I. (2010). Towards a General and Extensible Phrase-Extraction
Algorithm. In M. FEDERICO, I. LANE, M. PAUL &amp; F. YVON, Eds., Proceedings of the seventh International Workshop on Spoken
Language Translation (IWSLT), p. 313&#8211;320.
LIU Y., XIA T., XIAO X. &amp; LIU Q. (2009). Weighted alignment matrices for statistical machine translation. In Proceedings of
the 2009 Conference on Empirical Methods in Natural Language Processing : Volume 2 - Volume 2, EMNLP &#8217;09, p. 1017&#8211;1026,
Morristown, NJ, USA : Association for Computational Linguistics.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>NADI TOMEH, ALEXANDRE ALLAUZEN ET FRAN&#199;OIS YVON
</p>
<p>MI H. &amp; HUANG L. (2008). Forest-based translation rule extraction. In Proceedings of the 2008 Conference on Empirical Methods
in Natural Language Processing, p. 206&#8211;214, Honolulu, Hawaii : Association for Computational Linguistics.
</p>
<p>OCH F. J. &amp; NEY H. (2003). A systematic comparison of various statistical alignment models. Comput. Linguist., 29, 19&#8211;51.
PAPINENI K., ROUKOS S., WARD T. &amp; ZHU W.-J. (2002). Bleu : a method for automatic evaluation of machine translation. In
Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL &#8217;02, p. 311&#8211;318, Stroudsburg, PA,
USA : Association for Computational Linguistics.
</p>
<p>TOMEH N., ALLAUZEN A., WISNIEWSKI G. &amp; YVON F. (2010). Refining word alignment with discriminative training. In
Proceedings of the ninth Conference of the Association for Machine Translation in the America (AMTA), Denver, CO.
</p>
<p>TOMEH N., LAVERGNE T., ALLAUZEN A. &amp; YVON F. (2011). Designing an improved discriminative word aligner. In Proceedings
of the 12th International Conference on Intelligent Text Processing and Computational Linguistics (CICLING), Tokyo, Japan.
</p>
<p>VENUGOPAL A., VOGEL S. &amp; WAIBEL A. (2003). Effective phrase translation extraction from alignment models. In Proceedings
of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL &#8217;03, p. 319&#8211;326, Stroudsburg, PA, USA :
Association for Computational Linguistics.
</p>
<p>VENUGOPAL A., ZOLLMANN A., SMITH N. A. &amp; VOGEL S. (2008). Wider pipelines : N-best alignments and parses in MT
training. In Proceedings of the Association for Machine Translation in the Americas (AMTA).
</p>
<p>VOGEL S., NEY H. &amp; TILLMANN C. (1996). Hmm-based word alignment in statistical translation. In Proceedings of the 16th
conference on Computational linguistics, p. 836&#8211;841 : Association for Computational Linguistics.
</p>
<p>WANG W., KNIGHT K. &amp; MARCU D. (2007). Binarizing syntax trees to improve syntax-based machine translation accuracy.
In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL), p. 746&#8211;754, Prague, Czech Republic : Association for Computational Linguistics.
</p>
<p>WUEBKER J., MAUSER A. &amp; NEY H. (2010). Training phrase translation models with leaving-one-out. In Proceedings of the 48th
Annual Meeting of the Association for Computational Linguistics, p. 475&#8211;484, Uppsala, Sweden : Association for Computational
Linguistics.
</p>
<p>XUE Y.-Z., LI S., ZHAO T., YANG M. &amp; LI J. (2006). Bilingual phrase extraction from n-best alignments. In ICICIC (3), p.
410&#8211;414.
</p>
<p>ZENS R., OCH F. J. &amp; NEY H. (2002). Phrase-based statistical machine translation. In KI &#8217;02 : Proceedings of the 25th Annual
German Conference on AI, p. 18&#8211;32, London, UK : Springer-Verlag.
</p>
<p>ZOU H. &amp; HASTIE T. (2005). Regularization and variable selection via the elastic net. Journal of the Royal Statistical Society,
Series B, 67, 301&#8211;320.</p>

</div></div>
</body></html>