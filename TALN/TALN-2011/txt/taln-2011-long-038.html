<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Combinaison d&#8217;informations pour l&#8217;alignement monolingue</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Combinaison d&#8217;informations pour l&#8217;alignement monolingue
</p>
<p>Houda Bouamor Aur&#233;lien Max Anne Vilnat
LIMSI-CNRS, Univ. Paris-Sud
</p>
<p>Orsay, F-91403, France
{pr&#233;nom.nom}@limsi.fr
</p>
<p>R&#233;sum&#233;. Dans cet article, nous d&#233;crivons une nouvelle m&#233;thode d&#8217;alignement automatique de paraphrases
d&#8217;&#233;nonc&#233;s. Nous utilisons des m&#233;thodes d&#233;velopp&#233;es pr&#233;c&#233;demment afin de produire diff&#233;rentes approches hy-
brides (hybridations). Ces diff&#233;rentes m&#233;thodes permettent d&#8217;acqu&#233;rir des &#233;quivalences textuelles &#224; partir d&#8217;un
corpus monolingue parall&#232;le. L&#8217;hybridation combine des informations obtenues par diverses techniques : aligne-
ments statistiques, approche symbolique, fusion d&#8217;arbres syntaxiques et alignement bas&#233; sur des distances d&#8217;&#233;di-
tion. Nous avons &#233;valu&#233; l&#8217;ensemble de ces r&#233;sultats et nous constatons une am&#233;lioration sur l&#8217;acquisition de para-
phrases sous-phrastiques.
</p>
<p>Abstract. In this paper, we detail a new method to automatic alignment of paraphrase of statements. We also
use previously developed methods to produce different hybrid approaches. These methods allow the acquisition
of textual equivalence from a parallel monolingual corpus. Hybridization combines information obtained by using
advanced statistical alignments, symbolic approach, syntax tree based alignment and edit distances technique. We
evaluated all these results and we see an improvement on the acquisition of sub-sentential paraphrases.
</p>
<p>Mots-cl&#233;s : Paraphrase sous-phrastique, corpus parall&#232;le monolingue, hybridation.
</p>
<p>Keywords: Phrasal paraphrase, monolingual parallel corpora, hybridization.
</p>
<p>1 Introduction
</p>
<p>Le traitement de corpus monolingues et multilingues constitue un champ d&#8217;investigation tr&#232;s anim&#233; dans le do-
maine du traitement automatique des langues. Ils sont souvent constitu&#233;s d&#8217;unit&#233;s de texte ayant des liens s&#233;man-
tiques forts, une information qui peut &#234;tre exploit&#233;e pour acqu&#233;rir des &#233;quivalences entre des mots ou des groupes
de mots et construire des ressources linguistiques importantes pour diverses applications. Ces resssources peu-
vent &#234;tre utilis&#233;es par la suite pour extraire des r&#233;ponses &#224; des questions (Duclaye et al., 2003), par exemple, ou
autoriser des formulations diff&#233;rentes en &#233;valuation de la traduction automatique (Russo-Lassner .G &amp; .P, 2005;
Kauchak &amp; Barzilay, 2006), ainsi qu&#8217;en g&#233;n&#233;ration, pour aider des auteurs &#224; trouver des formulations plus adapt&#233;es
(Max, 2008).
</p>
<p>De nombreuses techniques ont &#233;t&#233; propos&#233;es pour l&#8217;acquisition de segments en relation de paraphrase. Ces tech-
niques ont en commun d&#8217;&#234;tre directement li&#233;es aux types de ressources sur lesquelles elles s&#8217;appliquent. Les plus
nombreuses exploitent des corpus monolingues comparables disponibles en grandes quantit&#233;s, et se fondent sur
l&#8217;hypoth&#232;se que des unit&#233;s linguistiques apparaissant de nombreuses fois dans des contextes similaires peuvent
avoir la m&#234;me signification. Restreindre les corpus utilis&#233;s &#224; des textes comparables, s&#233;lectionn&#233;s sur la base
d&#8217;un genre ou de th&#232;mes communs, permet d&#8217;augmenter la probabilit&#233; que les correspondances obtenues seront
effectivement valides gr&#226;ce aux contextes plus restreints.
</p>
<p>Peu de travaux ont, en comparaison, port&#233; sur l&#8217;exploitation de corpus monolingues parall&#232;les, constitu&#233;s de
phrases align&#233;es en relation de paraphrase. Cela peut certainement s&#8217;expliquer par la faible disponibilit&#233; de telles
ressources engendr&#233;e par le co&#251;t de leur construction. Mais elles pr&#233;sentent des caract&#233;ristiques qui en font les
candidates les plus naturelles pour l&#8217;&#233;tude de la paraphrase sous-phrastique : les phrases parall&#232;les &#233;tant issues
de la volont&#233; d&#8217;exprimer la m&#234;me id&#233;e, les &#233;quivalences apprises apparaissent comme beaucoup plus fiables que
celles extraites indirectement via des textes comparables ou des &#233;quivalences de traduction. En outre, le contexte
de ces &#233;quivalences peut &#234;tre extrait de fa&#231;on directe, ce qui est particuli&#232;rement important pour caract&#233;riser les</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>HOUDA BOUAMOR, AUR&#201;LIEN MAX ET ANNE VILNAT
</p>
<p>conditions de leur validit&#233;.
</p>
<p>Ce travail porte sur l&#8217;acquisition de paraphrases sous-phrastiques depuis des corpus monolingues parall&#232;les, et
vise en particulier &#224; extraire des paraphrases de qualit&#233;. Dans cet article, nous pr&#233;sentons DIST une nouvelle
m&#233;thode symbolique optimis&#233;e pour l&#8217;alignement de bi-segments exploitant un corpus monolingue parall&#232;le. Puis
nous d&#233;crivons une approche hybride d&#8217;extraction de paraphrases sous-phrastiques par la combinaison d&#8217;infor-
mations issues de diff&#233;rentes techniques. Cet article est organis&#233; comme suit : dans la section 2, nous passons en
revue les travaux portant sur l&#8217;acquisition automatique de paraphrases puis nous d&#233;taillons, dans la section 3, le
cadre exp&#233;rimental de notre travail, l&#8217;approche suivie pour combiner des informations issues de diff&#233;rentes tech-
niques et extraire des bi-segments &#224; partir de corpus monolingues parall&#232;les ainsi que les r&#233;sultats obtenus. Nous
terminerons par une description de nos prochains travaux (section 4).
</p>
<p>2 Travaux pr&#233;c&#233;dents en acquisition de paraphrases
</p>
<p>L&#8217;acquisition de paraphrases peut &#234;tre r&#233;alis&#233;es &#224; l&#8217;aide de diverses m&#233;thodologies. Langkilde &amp; Knight (1998)
se sont bas&#233;s sur les connaissances s&#233;mantiques de WordNet (Miller, 1995) pour exploiter les relations de syn-
onymie entre termes et les utiliser ensuite lors de la g&#233;n&#233;ration de paraphrases. Cependant, ces ressources ne sont
pas n&#233;cessairement disponibles dans toutes les langues et ne comportent que des &#233;quivalences textuelles au niveau
des mots. C&#8217;est la raison pour laquelle de nombreux autres travaux se sont bas&#233;s sur des corpus monolingues et
multilingues parall&#232;les ou comparables.
</p>
<p>La majorit&#233; des travaux men&#233;s sur des corpus monolingues parall&#232;les se basent essentiellement sur l&#8217;hypoth&#232;se
de distributionnalit&#233; (Harris, 1954), selon laquelle les mots apparaissant dans le m&#234;me contexte tendent &#224; avoir
des sens similaires. Cette hypoth&#232;se a &#233;t&#233; appliqu&#233;e, par exemple, &#224; des chemins dans des arbres de d&#233;pendance
pour la d&#233;couverte de r&#232;gles d&#8217;inf&#233;rence &#224; partir de textes (Lin &amp; Pantel, 2001). Barzilay &amp; McKeown (2001)
utilisent des informations contextuelles bas&#233;es sur des similarit&#233;s lexicales pour extraire des paraphrases &#224; partir
d&#8217;un ensemble de corpus align&#233;s. De mani&#232;re similaire, Pang et al. (2003) exploitent la structure syntaxique d&#8217;un
ensemble de phrases issues de corpus parall&#232;les monolingues pour construire de nouvelles paraphrases d&#8217;&#233;nonc&#233;s
par fusion syntaxique et reg&#233;n&#233;ration. Ibrahim et al. (2003) pr&#233;sentent eux une m&#233;thode non supervis&#233;e d&#8217;acqui-
sition de paraphrases qui consiste &#224; extraire des paraphrases structurelles, ou des fragments d&#8217;arbres syntaxiques
s&#233;mantiquement &#233;quivalents, &#224; partir de corpus monolingues parall&#232;les.
</p>
<p>Puisque les corpus monolingues parall&#232;les sont des ressources rares et difficiles &#224; obtenir, d&#8217;autres techniques
ont &#233;t&#233; impl&#233;ment&#233;es en se basant sur des corpus monolingues comparables, corpus compos&#233;s de textes dans la
m&#234;me langue partageant une partie du vocabulaire employ&#233;, ce qui implique g&#233;n&#233;ralement que les textes parlent
d&#8217;un m&#234;me sujet, durant la m&#234;me p&#233;riode, afin d&#8217;obtenir des paraphrases. Notamment, certains travaux exploitent
des corpus monolingues comparables, comme ceux de Del&#233;ger &amp; Zweigenbaum (2009) dans le domaine m&#233;dical
visant la construction d&#8217;un corpus de paraphrases de segments opposant les langues de sp&#233;cialit&#233; et de vulgar-
isation. Barzilay &amp; Lee (2003) introduisent une technique d&#8217;alignement multi-s&#233;quence factorisant des phrases
ayant la m&#234;me structure syntaxique, extraites &#224; partir d&#8217;un corpus comparable, sous forme de treillis contenant des
&#233;quivalences locales. Quirk et al. (2004) proposent une approche consistant &#224; apprendre un syst&#232;me de traduction
statistique sur un corpus monolingue de phrases align&#233;es automatiquement &#224; partir d&#8217;un corpus comparable qui
op&#232;re par reformulations locales.
</p>
<p>Outre les corpus monolingues, des corpus multilingues parall&#232;les ont &#233;t&#233; exploit&#233;s pour l&#8217;extraction des para-
phrases en se basant sur l&#8217;hypoth&#232;se que des segments partageant des traductions dans une autre langue peuvent
&#234;tre des paraphrases dans certains contextes. Bannard &amp; Callison-Burch (2005) ont d&#233;crit une approche par pivot
exploitant plusieurs corpus parall&#232;les. De la m&#234;me mani&#232;re, Max (2009) utilise des traductions de segments en
pivot pour produire des reformulations et s&#233;lectionner parmi celles-ci celles qui sont pr&#233;f&#233;r&#233;es par diff&#233;rents types
de mod&#232;les. La majorit&#233; de ces approches s&#8217;attaque au probl&#232;me d&#8217;acquisition de paraphrases d&#8217;&#233;nonc&#233;s complets.
Or, il est &#233;galement int&#233;ressant de pouvoir extraire des reformulations pour des unit&#233;s de texte plus petites &#224; partir
de plusieurs corpus quel que soit leur degr&#233; de parall&#233;lisme.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMBINAISON D&#8217;INFORMATIONS POUR L&#8217;ALIGNEMENT MONOLINGUE
</p>
<p>3 Combiner des informations pour l&#8217;alignement
</p>
<p>Diff&#233;rentes approches peuvent &#234;tre utilis&#233;es pour faire l&#8217;acquisition de paraphrases sous-phrastiques depuis des
corpus monolingues parall&#232;les (Bouamor et al., 2010). Outre l&#8217;am&#233;lioration individuelle de ces techniques, il est
possible de parvenir &#224; une am&#233;lioration des performances obtenues en exploitant utilement les r&#233;sultats de cha-
cune. Dans cette section, nous commen&#231;ons par d&#233;crire le cadre exp&#233;rimental dans lequel s&#8217;ancre notre &#233;tude sur
l&#8217;alignement monolingue dans des paires de paraphrases, puis nous pr&#233;sentons bri&#232;vement quatre techniques que
nous utilisons pour cette t&#226;che. Nous d&#233;crivons ensuite un cadre de combinaison des r&#233;sultats qu&#8217;elles produisent
et d&#233;taillons les r&#233;sultats de nos exp&#233;riences.
</p>
<p>3.1 Cadre exp&#233;rimental
</p>
<p>Les paraphrases d&#8217;&#233;nonc&#233;s sont relativement rares &#224; l&#8217;&#233;tat naturel, car peu d&#8217;activit&#233;s humaines en gardent la trace
lorsqu&#8217;elles existent. En outre, certains types de r&#233;&#233;critures, comme le r&#233;sum&#233;, alt&#232;rent de fa&#231;on significative le
contenu des textes. Des solutions pour l&#8217;acquisition de paraphrases ont cependant &#233;t&#233; propos&#233;es, par exemple &#224;
partir de corpus comparables (Dolan &amp; Brockett, 2005) ou de traces d&#8217;&#233;ditions (Dutrey et al., 2010), mais l&#8217;iden-
tification de ce qui constitue des paraphrases acceptables reste une difficult&#233; majeure. Une solution plus directe
consiste &#224; faire produire de telles paraphrases par des humains dans le cadre naturel d&#8217;une traduction o&#249; une m&#234;me
phrase est traduite plusieurs fois ind&#233;pendamment. Le corpus MultiTrad (Bouamor, 2010) a &#233;t&#233; construit selon ce
principe en obtenant des traductions vers le fran&#231;ais d&#8217;extraits du corpus des d&#233;bats parlementaire europ&#233;en.
</p>
<p>Pour l&#8217;&#233;tude pr&#233;sent&#233;e ici, nous avons s&#233;lectionn&#233; un corpus de d&#233;veloppement issu de MultiTrad constitu&#233; de 50
&#233;nonc&#233;s traduits 4 fois de l&#8217;anglais vers le fran&#231;ais. Pour chaque groupe de quatre paraphrases, la paraphrase la
plus similaire en moyenne aux autres paraphrases a &#233;t&#233; identifi&#233;e et associ&#233;e aux trois autres. Cette similarit&#233; est
calcul&#233;e par une valeur moyenne d&#8217;&#233;dition mesur&#233;e par TER (Translation Error Rate) (Snover et al., 2009). Les
150 paires de paraphrases obtenues ont alors &#233;t&#233; annot&#233;e au niveau des mots par 3 annotateurs &#224; l&#8217;aide de YAWAT
(Germann, 2008), un outil qui permet d&#8217;utiliser, au choix, une vue parall&#232;le entre &#233;nonc&#233;s pr&#233;sent&#233;s sous forme
de paragraphes ou de matrices d&#8217;alignement. Chaque paire a &#233;t&#233; annot&#233;e par un seul annotateur : Callison-Burch
(2008) mentionne un accord inter-annotateur acceptable sur une telle t&#226;che 1, mais l&#8217;ensemble des annotations
a par la suite &#233;t&#233; v&#233;rifi&#233; par le m&#234;me annotateur. &#192; partir des matrices d&#8217;alignement produites, l&#8217;ensemble des
bi-segments de r&#233;f&#233;rence est extrait en respectant la contrainte suivante : tous les mots du segment contenu dans
la premi&#232;re paraphrase sont align&#233;s avec au moins un mot du segment de la seconde paraphrase et ne sont align&#233;s
qu&#8217;avec des mots de ce segment, et r&#233;ciproquement.
</p>
<p>Pour &#233;valuer la performance de nos techniques d&#8217;alignement monolingue, nous utilisons l&#8217;approche PARAMET-
RIC (Callison-Burch et al., 2008), dans laquelle un ensemble de bi-segments (correspondant &#224; des paires de para-
phrases sous-phrastiques) de r&#233;f&#233;rence est compar&#233; aux bi-segments produits par la m&#233;thode &#233;valu&#233;e. La mesure
PARAMETRIC se d&#233;compose en des valeurs usuelles de pr&#233;cision et de rappel, d&#233;finies respectivement comme la
proportion des candidats propos&#233;s appartenant &#224; la r&#233;f&#233;rence et la proportion des &#233;l&#233;ments de la r&#233;f&#233;rence pro-
pos&#233;s, ainsi qu&#8217;en une F-Mesure combinant les deux &#224; &#233;galit&#233;. Notre &#233;valuation portera sur un extrait du corpus
de traductions multiples issus de la campagne CESTA 2 contenant 375 paires de paraphrases (comportant entre
15 et 25 mots) et obtenues par traduction de l&#8217;anglais vers le fran&#231;ais. L&#8217;alignement de r&#233;f&#233;rence a &#233;t&#233; r&#233;alis&#233;
en suivant la m&#234;me proc&#233;dure que pour le corpus de d&#233;veloppement avec 2 annotateurs. Notre &#233;tude a r&#233;v&#233;l&#233; un
taux d&#8217;accord inter-annotateur global de 88,96% qu n&#8217;est plus, cependant, que de 67,35% lorsque les paraphrases
&quot;identit&#233;&quot; ne sont pas prises en compte.
</p>
<p>3.2 Techniques individuelles
</p>
<p>Nous avons impl&#233;ment&#233; dans ce travail quatre techniques, d&#233;velopp&#233;es pour des besoins diff&#233;rents. Nous les avons
choisies parce qu&#8217;elles op&#232;rent &#224; diff&#233;rents niveaux ce qui devrait permettre de tirer parti de leur compl&#233;mentarit&#233;
potentielle. La premi&#232;re est fond&#233;e sur l&#8217;apprentissage statistique d&#8217;alignements entre mots (MOT), et requiert
</p>
<p>1. Il faut cependant noter que les travaux de Callison-Burch (2008) portait sur des textes journalistiques en anglais et qu&#8217;un guide d&#8217;anno-
tation avait &#233;t&#233; fourni aux annotateurs.
</p>
<p>2. Corpus de la Campagne d&#8217;Evaluation de Syst&#232;mes de Traduction Automatique : http://www.elda.org/article125.html</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>HOUDA BOUAMOR, AUR&#201;LIEN MAX ET ANNE VILNAT
</p>
<p>donc des quantit&#233;s de donn&#233;es d&#8217;apprentissage en nombre relativement important. La seconde exploite des r&#232;gles
de description de variantes de termes et des connaissances a priori sur la variation lexicale (TERME). La troisi&#232;me
utilise la structure syntaxique des &#233;nonc&#233;s pour mettre en correspondance des segments (SYNT), et requiert par
cons&#233;quent un analyseur syntaxique. La quatri&#232;me, calcule une transformation au niveau des mots pour trans-
former une s&#233;quence de mots en une autre en mettant en jeu des op&#233;rations de transformation dont le co&#251;t est
appris automatiquement (DIST). Une &#233;tude comparative des trois premi&#232;res techniques a &#233;t&#233; faite dans (Bouamor
et al., 2010). Elle a, en particulier, mis en &#233;vidence des diff&#233;rences de performance notables sur deux types de
corpus parall&#232;les monolingues obtenus par traductions multiples &#224; partir d&#8217;une m&#234;me langue d&#8217;une part, et de
plusieurs langues d&#8217;autre part. Dans cet article, une nouvelle technique est introduite et utilis&#233;e de fa&#231;on originale,
et une combinaison efficace sous forme d&#8217;adaptation de cette derni&#232;re technique est propos&#233;e.
</p>
<p>3.2.1 Approche fond&#233;e sur l&#8217;apprentissage d&#8217;alignements entre mots (MOT)
</p>
<p>La technique MOT consiste &#224; apprendre des alignements entre mots en utilisant des mod&#232;les d&#8217;alignement statis-
tique appliqu&#233;s sur deux phrases parall&#232;les, initialement con&#231;us pour la t&#226;che d&#8217;alignement bilingue entre mots
en traduction automatique statistique. Une telle technique requiert typiquement des quantit&#233;s de donn&#233;es impor-
tantes pour apprendre des alignements fiables 3. Dans nos exp&#233;riences, nous mettrons &#224; disposition de MOT toutes
les paires de paraphrases possibles (pour des groupes constitu&#233;s de 4 paraphrases) afin d&#8217;am&#233;liorer ses capac-
it&#233;s d&#8217;alignement, ce qui constitue pour elle un avantage car les autres techniques ne consid&#232;rent les paires de
paraphrases qu&#8217;isol&#233;ment (en d&#8217;autres termes, pour les autres techniques l&#8217;information acquise sur une paire de
paraphrases n&#8217;est pas directement exploit&#233;e pour les alignements ult&#233;rieurs). Par ailleurs, ce type de technique
fonctionne d&#8217;autant mieux que les phrases des corpus d&#8217;apprentissage utilis&#233;es sont parall&#232;les, signifiant ici qu&#8217;un
alignement mot &#224; mot est facile &#224; r&#233;aliser. Dans le cas bilingue, ce n&#8217;est &#233;videmment pas le cas de langues tr&#232;s
diff&#233;rentes, et dans le cas monolingue, nos exp&#233;riences pr&#233;c&#233;dentes ont montr&#233; que MOT obtenait des r&#233;sultats
sensiblement meilleurs lorsque les paraphrases utilis&#233;es sont obtenues par traduction depuis une m&#234;me langue.
</p>
<p>Nous avons utilis&#233; le programme GIZA++ (Och &amp; Ney, 2003) pour r&#233;aliser l&#8217;alignement entre mots et les heuris-
tiques du syst&#232;me de traduction statistique MOSES (Koehn et al., 2007) pour extraire des bi-segments &#224; partir
des matrices d&#8217;alignement obtenues. Un exemple d&#8217;une matrice d&#8217;alignement produite par MOT est donn&#233; dans
la figure 1. &#192; partir de cette matrice, 12 bi-segments diff&#233;rents sont extraits en appliquant les crit&#232;res d&#233;crits
ci-dessus.
</p>
<p>3.2.2 Approche fond&#233;e sur l&#8217;expression symbolique de la variation (TERME)
</p>
<p>Pour chaque paire d&#8217;&#233;nonc&#233;s en relation de paraphrase, il est possible d&#8217;exprimer des r&#232;gles r&#233;gissant les variations
syntagmatiques et paradigmatiques acceptables au niveau des segments. Les nombreux travaux qui ont port&#233; sur
les notions de termes et de variantes de termes offrent ainsi une solution assez directe &#224; ce probl&#232;me de mise en
correspondance. L&#8217;approche symbolique TERME que nous utilisons exploite l&#8217;op&#233;ration d&#8217;indexation contr&#244;l&#233;e
du syst&#232;me FASTR (Jacquemin, 1999) pour trouver les alignements sous-phrastiques possibles entre deux para-
phrases d&#8217;une paire donn&#233;e. Cette op&#233;ration d&#233;finit les variations acceptables pour un terme par un syst&#232;me de
m&#233;tar&#232;gles d&#233;crivant ses r&#233;&#233;critures morphosyntaxiques possibles. Les m&#233;tar&#232;gles peuvent &#233;galement mettre en
jeu des relations lexicales d&#233;finissant des variations morphologiques (mots d&#8217;une m&#234;me famille morphologique)
et s&#233;mantiques (synonymie). Ces ressources constituent donc des connaissances a priori utilis&#233;es par TERME qui
ne sont pas accessibles aux autres techniques.
</p>
<p>L&#8217;outil FASTR utilis&#233; a &#233;t&#233; con&#231;u pour rechercher efficacement des termes et leurs variantes dans de grands corpus
de textes. Pour nos besoins, consid&#233;rant une paire de paraphrases d&#8217;&#233;nonc&#233;s, nous recherchons dans la premi&#232;re
phrase (notre &#171; corpus &#187;) des variantes pour chacun des segments possibles de l&#8217;autre phrase (&#224; concurrence d&#8217;une
certaine taille), puis nous inversons la recherche et retenons l&#8217;intersection des r&#233;sultats. L&#8217;usage que nous faisons
du moteur de d&#233;tection de variantes de termes semble favorable &#224; l&#8217;obtention d&#8217;une bonne pr&#233;cision. &#192; l&#8217;inverse,
les m&#233;tar&#232;gles d&#233;finies pour le rep&#233;rage de variantes de termes ne sont pas n&#233;cessairement les mieux adapt&#233;es
pour assurer une bonne couverture des ph&#233;nom&#232;nes paraphrastiques entre segments de nature quelconque (Dutrey
et al., 2010).
</p>
<p>3. La technique d&#233;velopp&#233;e par Lardilleux (2010) constitue une exception notable adapt&#233;e aux &#233;v&#233;nements de basse fr&#233;quence, et sera
naturellement consid&#233;r&#233;e dans la suite de nos travaux.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMBINAISON D&#8217;INFORMATIONS POUR L&#8217;ALIGNEMENT MONOLINGUE
L
</p>
<p>a
C
</p>
<p>om
m
</p>
<p>is
si
</p>
<p>on
a-
</p>
<p>t-
el
</p>
<p>le
l&#8217; in
</p>
<p>te
nt
</p>
<p>io
n
</p>
<p>de t&#233;
m
</p>
<p>oi
gn
</p>
<p>er
so
</p>
<p>n
in
</p>
<p>t&#233;
r&#234;
</p>
<p>t
po
</p>
<p>ur
l&#8217; ap
</p>
<p>pl
ic
</p>
<p>at
io
</p>
<p>n
, pa
</p>
<p>r
le
</p>
<p>s
&#233;t
</p>
<p>at
s
</p>
<p>m
em
</p>
<p>br
es
</p>
<p>, du r&#232;
gl
</p>
<p>em
en
</p>
<p>t
pr
</p>
<p>&#233;c
it&#233;
</p>
<p>?
</p>
<p>La
Commission
envisage-t-elle
de
contr&#244;ler
la
mise
en
oeuvre
de
cette
r&#233;glementation
par
les
Etats
membres
?
</p>
<p>L
a
</p>
<p>C
om
</p>
<p>m
is
</p>
<p>si
on
</p>
<p>a-
t-
</p>
<p>el
le
</p>
<p>l&#8217; in
te
</p>
<p>nt
io
</p>
<p>n
de t&#233;
</p>
<p>m
oi
</p>
<p>gn
er
</p>
<p>so
n
</p>
<p>in
t&#233;
</p>
<p>r&#234;
t
</p>
<p>po
ur
</p>
<p>l&#8217; ap
pl
</p>
<p>ic
at
</p>
<p>io
n
</p>
<p>, pa
r
</p>
<p>le
s
</p>
<p>&#233;t
at
</p>
<p>s
m
</p>
<p>em
br
</p>
<p>es
, du r&#233;
</p>
<p>gl
em
</p>
<p>en
t
</p>
<p>pr
&#233;c
</p>
<p>it&#233;
?
</p>
<p>FIGURE 1 &#8211; Matrice d&#8217;alignement d&#8217;une paire de phrases dans MOT (&#224; gauche), et sa matrice correspondante dans
la base de r&#233;f&#233;rence.
</p>
<p>3.2.3 Approche fond&#233;e sur l&#8217;alignement de structures syntaxiques (SYNT)
</p>
<p>Lorsque deux &#233;nonc&#233;s en relation de paraphrase partagent une m&#234;me structure syntaxique, il est possible de
r&#233;aliser un alignement fin guid&#233; par la syntaxe permettant de faire appara&#238;tre des correspondances sous-phrastiques
fines. L&#8217;algorithme de Pang et al. (2003) d&#233;crit une fusion syntaxique consistant essentiellement &#224; fusionner des
arbres de constituants de deux &#233;nonc&#233;s l&#224; o&#249; les listes de cat&#233;gories filles sont compatibles et qu&#8217;aucune &#233;vidence
de non parall&#233;lisme syntaxique (via un m&#233;canisme de blocage lexical) n&#8217;est d&#233;tect&#233;e. La for&#234;t d&#8217;arbres syntaxiques
ainsi obtenue permet de construire un treillis de mots repr&#233;sentant des formulations alternatives qu&#8217;il est possible
d&#8217;extraire par simple parcours du treillis.
</p>
<p>Pour la m&#233;thode SYNT nous avons r&#233;impl&#233;ment&#233; l&#8217;algorithme originel et avons am&#233;lior&#233; sa robustesse et sa cor-
rection en ajoutant un mode de fusion flexible dans lequel les parties de la phrase non concern&#233;es par un blocage
lexical sont tout de m&#234;me fusionn&#233;es. Par ailleurs, &#233;tant donn&#233; que l&#8217;algorithme est tr&#232;s d&#233;pendant de la qualit&#233; des
analyses syntaxiques produites, nous avons &#233;galement ajout&#233; un mode exploitant les k meilleures analyses pro-
duites par un analyseur probabiliste. La combinaison retenue entre une analyse du premier &#233;nonc&#233; et une analyse
du second parmi les k2 combinaisons possibles est celle minimisant le nombre de n&#339;uds dans le treillis obtenu
avant r&#233;duction. Un exemple de treillis obtenu par application de SYNT est donn&#233; dans la figure 2.
</p>
<p>0 4...
19
</p>
<p>5sous 6la 12 13ou7barre 8des
92
</p>
<p>10
deux
</p>
<p>%
</p>
<p>11pour
cent
</p>
<p>14dans
aux 16autour
</p>
<p>15cette
alentours
</p>
<p>proximit&#233;
</p>
<p>17de 18cette
valeur
</p>
<p>FIGURE 2 &#8211; Exemple d&#8217;un treillis obtenu par application de SYNT
</p>
<p>Tout comme TERME, cette technique semble a priori plus adapt&#233;e &#224; l&#8217;extraction pr&#233;cise de bi-segments mono-
lingues, mais contrairement &#224; TERME il est attendu qu&#8217;elle ne parvienne pas &#224; extraire de correspondance lorsque
les structures syntaxiques de haut niveau des paraphrases d&#8217;&#233;nonc&#233;s ne sont pas compatibles.
</p>
<p>3.2.4 Approche fond&#233;e sur la distance d&#8217;&#233;ditions sur des s&#233;quences de mots (DIST)
</p>
<p>Une relation entre deux paraphrases peut &#233;galement s&#8217;exprimer sous forme de la s&#233;quence d&#8217;&#233;ditions la plus
directe permettant de transformer l&#8217;une en l&#8217;autre. Une telle s&#233;quence d&#8217;&#233;ditions sur les mots est, par exemple,</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>HOUDA BOUAMOR, AUR&#201;LIEN MAX ET ANNE VILNAT
</p>
<p>impl&#233;ment&#233;e dans la technique TERp (Translation Edit Rate plus) (Snover et al., 2009), originellement d&#233;velopp&#233;e
pour le calcul d&#8217;une distance d&#8217;&#233;dition servant de mesure en traduction automatique pour &#233;valuer une hypoth&#232;se
de traduction relativement &#224; une traduction de r&#233;f&#233;rence. Ce calcul met en jeu des op&#233;rations de transformation de
cha&#238;ne incluant l&#8217;insertion, la suppression et la substitution de mots, ainsi que le d&#233;placement et la substitution de
segments. Chaque type d&#8217;op&#233;ration est associ&#233; &#224; une pond&#233;ration optimis&#233;e sur un corpus de d&#233;veloppement pour
une mesure particuli&#232;re, et l&#8217;algorithme effectue une recherche de la s&#233;quence d&#8217;op&#233;ration la moins co&#251;teuse. Les
substitutions de mots ou segments sont optionnelles, mais peuvent exploiter des listes fournies &#224; l&#8217;algorithme 4, et
les substitutions de segments ont une probabilit&#233; associ&#233;e.
</p>
<p>Pour son calcul, TERp produit donc un alignement au niveau des mots entre deux &#233;nonc&#233;s. Pour nos besoins,
nous avons impl&#233;ment&#233; une m&#233;thode DIST qui extrait l&#8217;ensemble des bi-segments (&#224; concurrence d&#8217;une taille
maximale) d&#233;rivables des alignements produits par TERp. Nous avons exploit&#233; la possibilit&#233; d&#8217;optimiser TERp
pour nos besoins, en optimisant ses param&#232;tres par la m&#233;thode du hill climbing 5. Par la suite, nous d&#233;noterons
DISTA l&#8217;optimisation originelle r&#233;alis&#233;e par Snover et al. (2009) pour l&#8217;&#233;valuation de la traduction automatique (le
&#171; A &#187; est pour &#171; adequacy &#187;). Les variantes DISTP , DISTR et DISTF1 correspondent &#224; des optimisations r&#233;alis&#233;es
sur un corpus de d&#233;veloppement maximisant respectivement la pr&#233;cision, le rappel et la F-mesure de PARAMET-
RIC exploitant des annotations de r&#233;f&#233;rence. L&#8217;ensemble de ces configurations n&#8217;utilisent pas de substitutions de
segments, mais nous ferons appel &#224; cette possibilit&#233; dans un cadre d&#8217;hybridation d&#233;crit plus loin. Un exemple de
r&#233;sultat d&#8217;alignement fourni par TERp est donn&#233; dans la figure 3.
</p>
<p>FIGURE 3 &#8211; Exemple d&#8217;un alignement r&#233;sultat de DIST
</p>
<p>3.2.5 R&#233;sultats exp&#233;rimentaux et analyse
</p>
<p>Nous avons &#233;valu&#233; chacune des m&#233;thodes pr&#233;sent&#233;es ci-dessus sur le corpus de test d&#233;crit dans la section 3.1.
Les techniques MOT, TERME et SYNT ont &#233;t&#233; utilis&#233;es telles que d&#233;crites. Pour DIST, nous avons exploit&#233; la
possibilit&#233; d&#8217;optimiser la mesure selon nos propres objectifs. La variante DISTA, &#233;valu&#233;e pour r&#233;f&#233;rence, corre-
spond &#224; la version de TERp optimis&#233;e pour les besoins de l&#8217;&#233;valuation de la traduction automatique. Les autres
variantes DISTP , DISTR et DISTF1 correspondent &#224; TERp optimis&#233;e pour maximiser respectivement la pr&#233;cision,
le rappel et la f-mesure de PARAMETRIC. La premi&#232;re partie de la table 1 donne les r&#233;sultats obtenus sur les
trois sous-mesures de PARAMETRIC. On constate tout d&#8217;abord que les r&#233;sultats pour les 3 premi&#232;res techniques
sont coh&#233;rents avec ceux obtenus dans (Bouamor et al., 2010). La seule diff&#233;rence notable est l&#8217;am&#233;lioration
de la pr&#233;cision des deux techniques symboliques TERME et SYNT. La technique statistique d&#8217;alignement entre
mots MOT obtient un rappel beaucoup plus important que les deux autres techniques qui se distinguent par une
pr&#233;cision relativement forte (60,87 pour TERME et 66,96 pour SYNT). La pr&#233;cision de MOT reste toutefois dans
une zone raisonnable &#224; 47,02. Comme expliqu&#233; pr&#233;cedemment, MOT tire avantage des 3 paires de paraphrases
sur lesquelles il peut r&#233;aliser son apprentissage, alors que les deux autres techniques, telles qu&#8217;impl&#233;ment&#233;es, ne
peuvent am&#233;liorer l&#8217;alignement &#224; l&#8217;int&#233;rieur d&#8217;une phrase en exploitant des informations d&#233;riv&#233;es d&#8217;autres phrases.
</p>
<p>L&#8217;ajout original pour notre t&#226;che de DIST, technique fond&#233;e sur une distance d&#8217;&#233;dition sur des s&#233;quences de mots,
r&#233;v&#232;le de nouveaux r&#233;sultats int&#233;ressants. Tout d&#8217;abord, on constate qu&#8217;au niveau de la f-mesure, il n&#8217;existe qu&#8217;une
faible diff&#233;rence entre DISTA et la variante optimis&#233;e sur la f-mesure, DISTF1 . Ceci signifie que nos objectifs sont
tr&#232;s similaires &#224; ceux de l&#8217;&#233;valuation en traduction automatique tels que d&#233;crits par (Snover et al., 2009). On
constate cependant que des optimisations sp&#233;cifiques en faveur de la pr&#233;cision ou du rappel m&#232;nent ici &#224; des gains
tr&#232;s importants de +8,69 en pr&#233;cision et de +7,42 en rappel. Ces r&#233;sultats montrent que la technique DIST peine
&#224; am&#233;liorer simultan&#233;ment la pr&#233;cision et le rappel, m&#234;me si celle-ci obtient globalement des performances tr&#232;s
proches de la meilleure technique envisag&#233;e jusque-l&#224;, MOT, avec une pr&#233;cision l&#233;g&#232;rement meilleure et un rappel
</p>
<p>4. La version standard de TERp fournit des techniques de racinisation ainsi que des ressources de synonymie ainsi que de paraphrases
locales pour l&#8217;anglais. TERp utilise jusqu&#8217;&#224; 11 param&#232;tres.
</p>
<p>5. La premi&#232;re it&#233;ration d&#8217;optimisation se fait avec des poids uniformes, puis nous r&#233;alisons 10 it&#233;rations avec des valeurs initiales tir&#233;es
al&#233;atoirement afin de diminuer le risque d&#8217;utiliser un minimum local.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMBINAISON D&#8217;INFORMATIONS POUR L&#8217;ALIGNEMENT MONOLINGUE
</p>
<p>l&#233;g&#232;rement inf&#233;rieur. Il est possible que les mod&#232;les mis en jeu pour le calcul de la distance d&#8217;&#233;dition ne soient
pas suffisamment expressifs pour nos besoins, et qu&#8217;en particulier, la non prise en compte de crit&#232;res linguistiques
pour op&#233;rer des transformations de s&#233;quences de mots soit &#224; mettre en cause.
</p>
<p>Pr&#233;cision Rappel/13532 F1
Mot 47,02 61,42 53,26
Terme 60,87 4,19 7,85
Synt 66,96 13,11 21,92
DistA 49,85 54,14 51,91
DistP 58,54 2,68 5,13
DistR 39,48 61,56 48,11
DistF1 49,03 56,21 52,37
</p>
<p>union(Mot,Terme,Synt,DistF1 ) 38,99 73,55 50,97
intersection(Mot,DistF1 ) 70,38 32,31 44,29
</p>
<p>TABLE 1 &#8211; R&#233;sultats obtenus pour chaque technique
</p>
<p>La derni&#232;re partie de la table 1 donne les r&#233;sultats obtenus en op&#233;rant une combinaison &#233;l&#233;mentaire des r&#233;sultats
visant &#224; maximiser d&#8217;une part la pr&#233;cision, et d&#8217;autre part le rappel. L&#8217;union sur le r&#233;sultat de l&#8217;ensemble des
techniques obtient un maximum de valeur de rappel de 73,55 (+12,13 relativement &#224; MOT), avec une pr&#233;cision
l&#233;g&#232;rement affect&#233;e (-2,29 relativement &#224; MOT). Par ailleurs, r&#233;aliser l&#8217;intersection entre les diff&#233;rentes techniques
peut raisonnablement mener &#224; une pr&#233;cision am&#233;lior&#233;e. Cependant, le peu de r&#233;sultats produits par TERME et
SYNT nous ont fait pr&#233;f&#233;rer une mesure sur l&#8217;intersection de MOT et DISTF1 : nous obtenons alors une valeur
maximale de pr&#233;cision de 70,38 (+23,36 relativement &#224; MOT et +21,35 relativement &#224; DISTF1 ). Ces r&#233;sultats
montrent bien la compl&#233;mentarit&#233; qui existe entre ces diff&#233;rentes techniques, et servent donc ici de motivation
pour la recherche d&#8217;un mode de combinaison plus efficace des informations issues de chaque technique.
</p>
<p>3.3 Approche hybride d&#8217;extraction de paraphrases locales
</p>
<p>3.3.1 Observations et motivations
</p>
<p>Les exp&#233;riences pr&#233;sent&#233;es dans la section 3.2.5 ont r&#233;v&#233;l&#233; que les diff&#233;rentes techniques ont des performances
vari&#233;es, ce qui permet aussi de faire l&#8217;hypoth&#232;se qu&#8217;il est possible d&#8217;op&#233;rer une combinaison efficace de leurs
r&#233;sultats. Nous faisons ici une synth&#232;se des points forts et des limitations de chacune de ces techniques orient&#233;e
par la recherche d&#8217;un mode de combinaison plus efficace :
</p>
<p>&#8211; MOT : tr&#232;s sensible &#224; la fr&#233;quence de ses observations de mots et de cooccurrences entre mots, cette technique
peut &#234;tre inform&#233;e par des connaissances d&#8217;association a priori, qui peuvent par exemple &#234;tre transmises sous
forme de donn&#233;es d&#8217;apprentissage additionnelles. En outre, il est possible, avec des donn&#233;es d&#8217;entra&#238;nement
annot&#233;es, d&#8217;am&#233;liorer les performances des alignements statistiques par apprentissage discriminant (Tomeh
et al., 2010).
</p>
<p>&#8211; TERME : cette technique est sp&#233;cialis&#233;e dans l&#8217;extraction d&#8217;un type de bi-segments contraints par des r&#232;gles de
r&#233;&#233;criture et de variation lexicale. Les m&#233;tar&#232;gles, qui ont &#233;t&#233; d&#233;velopp&#233;es manuellement, sont assez pr&#233;cises
et ne peuvent couvrir tous les ph&#233;nom&#232;nes de paraphrase. Leur apprentissage automatique peut am&#233;liorer la
couverture, mais au d&#233;triment de la pr&#233;cision. L&#8217;enrichissement automatique des familles morphologiques et
s&#233;mantiques devrait &#233;galement permettre d&#8217;augmenter le rappel.
</p>
<p>&#8211; SYNT : cette technique est tr&#232;s sensible au degr&#233; de parall&#233;lisme des &#233;nonc&#233;s qui d&#233;cide de la fusion de consti-
tuants syntaxiques. Nous avons d&#233;j&#224; pris en compte la qualit&#233; des analyses syntaxiques en autorisant la fusion &#224;
op&#233;rer sur les k-meilleures analyses syntaxiques. Le blocage lexical emp&#234;che une fusion lorsqu&#8217;un mot pr&#233;sent
dans le constituant d&#8217;une phrase est attest&#233; dans un constituant non align&#233; de l&#8217;autre phrase. Il pourrait &#234;tre
am&#233;lior&#233; par la connaissance a priori de paraphrases locales, ce qui, n&#233;anmoins, ne pourrait b&#233;n&#233;ficier qu&#8217;&#224; la
pr&#233;cision.
</p>
<p>&#8211; DIST : cette technique transforme une s&#233;quence de mots en une autre en un co&#251;t minimal, en utilisant des
pond&#233;rations optimis&#233;es pour les diff&#233;rentes op&#233;rations utilis&#233;es. L&#8217;algorithme manipule des segments qui n&#8217;ont
pas n&#233;cessairement de motivation linguistique, ce qui peut mener &#224; des transformations aberrantes. En outre, des</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>HOUDA BOUAMOR, AUR&#201;LIEN MAX ET ANNE VILNAT
</p>
<p>op&#233;rations d&#8217;insertion et de suppression peuvent &#234;tre utilis&#233;es &#224; tort lorsque des correspondance au niveau des
mots ou des segments ne sont pas connues. Ainsi, si de telles correspondances peuvent &#234;tre fournies &#224; TERp,
il est possible d&#8217;esp&#233;rer diminuer le nombre d&#8217;op&#233;rations de transformation aberrantes et ainsi d&#8217;augmenter la
performance.
</p>
<p>3.3.2 Pr&#233;sentation de l&#8217;hybridation des m&#233;thodes
</p>
<p>Dans la section pr&#233;c&#233;dente nous avons montr&#233; qu&#8217;il existait plusieurs voies pour am&#233;liorer la performance de
l&#8217;alignement monolingue auquel nous nous int&#233;ressons &#224; partir des techniques d&#233;crites. Sans consid&#233;rer davantage,
&#224; ce stade, l&#8217;am&#233;lioration individuelle de chacune des techniques, nous pouvons d&#233;crire les deux grandes familles
d&#8217;approches possibles pour l&#8217;hybridation de la mani&#232;re suivante : 1) les r&#233;sultats produits ind&#233;pendamment par
chaque technique sont combin&#233;s a posteriori, et 2) une technique est adapt&#233;e par la connaissance des r&#233;sultats
produits par les autres techniques.
</p>
<p>Nous avons d&#233;j&#224; montr&#233; le r&#233;sultat de l&#8217;&#233;valuation d&#8217;une approche &#233;l&#233;mentaire par combinaison a posteriori dans
la section 3.2.5, illustr&#233;e sur la partie gauche de la figure 4, qui r&#233;v&#232;le que la pr&#233;cision et le rappel peuvent ainsi
&#234;tre facilement am&#233;lior&#233;s. Nous consid&#233;rons d&#233;sormais la seconde approche. D&#8217;apr&#232;s nos observations, DIST est
un candidat assez naturel pour l&#8217;adaptation. En effet, la connaissance d&#8217;alignements au niveau des mots ou des
segments peut diminuer le nombre d&#8217;op&#233;rations effectu&#233;es &#224; tort. Il s&#8217;agit pr&#233;cis&#233;ment de la motivation majeure
pour l&#8217;&#233;volution de TER &#224; TERp (Snover et al., 2009), li&#233;e &#224; la possibilit&#233; d&#8217;utiliser une base de paraphrases
locales connues a priori et ainsi d&#8217;&#234;tre plus robustes quant aux hypoth&#232;ses de traduction accept&#233;es par le syst&#232;me
lorsqu&#8217;elle ne correspondent pas exactement &#224; une traduction de r&#233;f&#233;rence.
</p>
<p>Au contraire de ce qui est fait dans TERp, nous n&#8217;utiliserons pas une base de connaissances externe, m&#234;me si
nous ne rejetons pas cette hypoth&#232;se pour de futures exp&#233;riences, mais nous adaptons dynamiquement la base
de paraphrases utilis&#233;es en fonction des hypoth&#232;ses extraites par les autres techniques, &#224; savoir des hypoth&#232;ses
nombreuses et relativement pr&#233;cises pour MOT, et peu nombreuses mais pr&#233;cises pour TERME et SYNT. De plus,
comme nous l&#8217;avons d&#233;j&#224; montr&#233;, ces techniques peuvent &#234;tre compl&#233;mentaires quant aux types de paraphrases
locales qu&#8217;elles permettent d&#8217;identifier, ce qui rejoint nos intuitions initiales li&#233;es &#224; la nature de chacune d&#8217;elles.
</p>
<p>Cette approche est illustr&#233;e sur la partie droite de la figure 4. Les bi-segments obtenus par MOT, TERME et SYNT
sont combin&#233;s pour construire une table de paraphrases utilis&#233;e ensuite par DIST, que nous pouvons optimiser en
fonction d&#8217;un besoin particulier (pr&#233;cision, rappel ou f-mesure). On remarque ici une analogie assez directe avec
d&#8217;autres sc&#233;narios de combinaisons d&#8217;informations en TAL : en traduction automatique, l&#8217;approche de la partie
gauche de la figure 4 correspond &#224; la d&#233;finition classique de la combinaison de syst&#232;mes (Matusov et al., 2009),
alors que l&#8217;approche de la partie droite correspond &#224; l&#8217;adaptation d&#8217;un syst&#232;me par des sources externes telles que
d&#8217;autres syst&#232;mes de traduction (Crego et al., 2010).
</p>
<p>Mot
</p>
<p>Terme
</p>
<p>Synt
</p>
<p>Dist
</p>
<p>combinaison
</p>
<p>(union)
</p>
<p>Bitexte
</p>
<p>monolingue
</p>
<p>Mot
</p>
<p>Terme
</p>
<p>Synt
</p>
<p>Dist
</p>
<p>combinaison
</p>
<p>Bitexte
</p>
<p>monolingue
</p>
<p>FIGURE 4 &#8211; Principales approches de combinaisons d&#8217;informations pour l&#8217;alignement multilingue. &#192; gauche,
plusieurs techniques produisent des r&#233;sultats combin&#233;s pour produire une nouvelle sortie. &#192; droite, un sous-
ensemble des techniques fournissent leurs r&#233;sultats &#224; une derni&#232;re technique adapt&#233;e &#224; l&#8217;exploitation de ces con-
naissances.
</p>
<p>Un probl&#232;me important &#224; consid&#233;rer concerne la mani&#232;re dont la table de paraphrases utilis&#233;e par TERp est con-
struite &#224; partir des hypoth&#232;ses produites par les diff&#233;rentes techniques. &#192; ce stade de nos travaux, nous ne disposons
pas de mesures de confiance donn&#233;es par chaque technique pour chacune de ses hypoth&#232;ses, et nous sommes donc
contraints de les consid&#233;rer initialement comme &#233;quiprobables. De plus, pour assurer une comparaison plus di-
recte avec la combinaison correspondant &#224; la partie gauche de la figure 4, nous r&#233;alisons une combinaison simple</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMBINAISON D&#8217;INFORMATIONS POUR L&#8217;ALIGNEMENT MONOLINGUE
</p>
<p>&#224; base d&#8217;union : chaque hypoth&#232;se apparaissant au moins une fois parmi les hypoth&#232;ses des diff&#233;rents syst&#232;mes
est retenue et est associ&#233;e &#224; un poids constant uniforme. 6
</p>
<p>Un autre aspect important concerne l&#224; encore la pond&#233;ration associ&#233;e &#224; chacune des paires de paraphrases a priori
fournies &#224; TERp. Consid&#233;rons le cas o&#249; deux paraphrases sont fournies &#224; TERp et o&#249; l&#8217;une est un sous-segment
de l&#8217;autre : par exemple, (ce degr&#233;vement &#8596; cet all&#232;gement) inclut (d&#233;gr&#232;vement &#8596; all&#232;gement). Si ces deux
paraphrases sont fournies avec le m&#234;me score &#224; TERp, celui-ci pr&#233;f&#232;rera, dans de nombreux cas, utiliser la plus
couvrante des deux, car cela minimisera souvent la quantit&#233; d&#8217;op&#233;rations de transformation restant &#224; faire, et donc
le co&#251;t global de transformation (voir partie gauche de la figure 5). Cela peut ne pas &#234;tre un d&#233;faut en soi, car
l&#8217;identification des plus longues sous-unit&#233;s paraphrastiques peut &#234;tre utile. Cependant, PARAMETRIC base ces
mesures sur l&#8217;ensemble des bi-segments pouvant &#234;tre extraits &#224; partir d&#8217;alignement sur les mots. Ainsi, si dans
l&#8217;exemple pr&#233;c&#233;dent l&#8217;alignement de r&#233;f&#233;rence inclut deux points d&#8217;alignement pour (ce&#8596; cet) et (d&#233;gr&#232;vement
&#8596; all&#232;gement), l&#8217;ensemble des bi-segments de r&#233;f&#233;rence sera constitu&#233; des deux bi-segments pr&#233;c&#233;dents et de leur
combinaison ou &#171; extension &#187; (ce degr&#233;vement &#8596; cet all&#232;gement). Si ce dernier est utilis&#233; par TERp, il n&#8217;existe
pas de moyen imm&#233;diat pour retrouver l&#8217;alignement sous-phrastique, et donc le rappel de la technique adapt&#233;e
sera p&#233;nalis&#233;.
</p>
<p>Plusieurs solutions sont envisageables pour pallier ce probl&#232;me. La pond&#233;ration des paraphrases pourraient pren-
dre en compte le nombre de mots/tokens couverts en favorisant les courts segments. Ne disposant n&#233;anmoins
pas de solutions g&#233;n&#233;riques applicables &#224; toutes les techniques ni de moyen d&#8217;int&#233;grer des scores de confiance
motiv&#233;s, nous pr&#233;f&#233;rons nous en remettre &#224; une solution initiale plus simple, qui consiste &#224; ne conserver que les
sous-segments minimaux parmi l&#8217;union de ceux propos&#233;s par chacune des techniques. Ainsi, ne seront gard&#233;s
pour construire la table de paraphrases utilis&#233;e par TERp que les bi-segments n&#8217;&#233;tant inclus dans aucun autre
bi-segment, que nous appellons bi-segments minimaux.
</p>
<p>FIGURE 5 &#8211; Exemple de deux alignements r&#233;sultats de DISTF1 , avec &#224; gauche l&#8217;ensemble des bi-segments non
filtr&#233;s, et &#224; droite un ensemble de bi-segments minimaux
</p>
<p>3.3.3 R&#233;sultats exp&#233;rimentaux et analyse
</p>
<p>Les r&#233;sultats que nous obtenons en optimisant TERp sur les trois mesures de PARAMETRIC et en utilisant dif-
f&#233;rentes sources de bi-segments sont pr&#233;sent&#233;s dans la table 2. Le r&#233;sultat principal de ces exp&#233;riences est la
nouvelle f-mesure de 55,27 obtenue en optimisant sur cette mesure et en exploitant les bi-segments provenant
des trois autres techniques. C&#8217;est la valeur la plus &#233;lev&#233;e sur l&#8217;ensemble de nos exp&#233;riences, et elle correspond
notamment &#224; un gain de +4,3 par rapport &#224; la combinaison par union des r&#233;sultats de toutes les techniques, ou
encore &#224; un gain de +2,01 par rapport &#224; MOT, la meilleure technique individuelle pour la f-mesure, et &#224; un gain de
+2,9 par rapport &#224; DISTF1 , la technique utilis&#233;e sans adaptation et optimis&#233;e selon le m&#234;me crit&#232;re. Ces r&#233;sultats
viennent confirmer notre hypoth&#232;se que TERp a pu ici tirer utilement profit des connaissances a priori qui lui ont
&#233;t&#233; fournies.
</p>
<p>Nous constatons de plus que des valeurs de pr&#233;cision et de rappel encourageantes peuvent &#234;tre atteintes : une
pr&#233;cision de 69,66 est obtenue en exploitant les pr&#233;dictions de TERME et en optimisant sur la pr&#233;cision (+2,7 par
rapport &#224; la meilleure technique individuelle SYNT), et un rappel de 62,38 est obtenu en exploitant les pr&#233;dictions
de MOT en optimisant sur le rappel (+0.82 par rapport &#224; la meilleure technique individuelle DISTR).
</p>
<p>Les cas de combinaisons o&#249; une seule technique est utilis&#233;e pour alimenter la base de paraphrases de TERp peuvent
&#233;galement &#234;tre &#233;tudi&#233;s en comparant les valeurs des tables 1 et 2. Hormis les valeurs de rappel obtenues pour
</p>
<p>6. Il serait bien s&#251;r possible de pond&#233;rer a priori chaque hypoth&#232;se par le nombre de techniques l&#8217;ayant propos&#233;e, et/ou par la performance
mesur&#233;e des techniques en question, d&#233;riv&#233;e par exemple de leur performance individuelle dans les diff&#233;rentes valeurs de PARAMETRIC. En
outre, la contribution de chacune des techniques pourrait faire l&#8217;objet d&#8217;un param&#232;tre optimis&#233; simultan&#233;ment aux param&#232;tres de TERp. Toutes
ces possibilit&#233;s seront consid&#233;r&#233;es dans notre travail futur.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>HOUDA BOUAMOR, AUR&#201;LIEN MAX ET ANNE VILNAT
</p>
<p>Source de bi-segments
Crit&#232;re d&#8217;optimisation
</p>
<p>DISTP DISTR DISTF1
P R/13532 F1 P R/13532 F1 P R/13532 F1
</p>
<p>MOT 67,83 13,21 22,11 41,49 62,38 49,83 55,11 54,51 54,81
TERME 69,66 6,82 12,42 40,51 55,6 46,87 53,16 49,84 51,45
SYNT 68,08 8,11 14,48 29,99 56,84 39,26 51,25 50,14 50,69
</p>
<p>comb(MOT, SYNT, TERME) 66,02 13,15 21,93 38,46 61,09 47,2 55,01 55,54 55,27
</p>
<p>TABLE 2 &#8211; R&#233;sultats obtenus pour diff&#233;rentes optimisations et diff&#233;rentes sources de bi-segments. La fonction
comb correspond &#224; l&#8217;union avec pond&#233;ration uniforme des bi-segments ne retenant que les bi-segments minimaux.
</p>
<p>DISTR avec les paraphrases de TERME et SYNT, toutes les autres combinaisons de DIST avec les donn&#233;es d&#8217;une
autre technique et optimis&#233;es selon un crit&#232;re particulier am&#233;liorent la meilleure des deux valeurs pr&#233;c&#233;dentes.
Par exemple, DISTP adapt&#233; avec les paraphrases de TERME obtient une pr&#233;cision de 69,66, qui est meilleure que
celle de DISTP (58,54) et celle de TERME (60,87). Il est &#224; noter qu&#8217;en combinaison de syst&#232;mes, comme c&#8217;est par
exemple le cas en traduction automatique, des gains sont plus g&#233;n&#233;ralement obtenus lorsque un certain nombre
de syst&#232;mes sont combin&#233;s. La compl&#233;mentarit&#233; de nos sources d&#8217;information et l&#8217;impact assez imm&#233;diat d&#8217;une
am&#233;lioration des informations a priori utilis&#233;es par TERp semblent donc ici avoir un r&#244;le tr&#232;s b&#233;n&#233;fique pour notre
t&#226;che.
</p>
<p>Il est finalement instructif de consid&#233;rer la performance des diff&#233;rentes configurations test&#233;es en fonction d&#8217;une
certaine difficult&#233; a priori. Celle-ci pourrait se mesurer par le degr&#233; d&#8217;accord inter-annotateurs pour chaque phrase,
mais nous avons choisi d&#8217;utiliser un r&#233;sultat en lien avec TERp : (1 &#8722; TER(paraphrase1, paraphrase2)), qui
est donc d&#8217;autant plus grand que les phrases sont proches. Le r&#233;sultat pour nos quatre techniques individuelles
est pr&#233;sent&#233; dans la figure 6. Pour la pr&#233;cision, on constate tout d&#8217;abord que MOT est tr&#232;s sensible &#224; la difficult&#233;
telle que nous la d&#233;finissons, et que les alignements que cette technique produit sont d&#8217;autant moins bons que les
phrases sont diff&#233;rentes. De fa&#231;on un peu plus surprenante, SYNT et DISTP ne semblent pas trop affect&#233;s par cette
difficult&#233;. Cependant, ceci est peut-&#234;tre d&#251; au fait que les valeurs des barres, pour chaque intervalle discr&#233;tis&#233;, sont
une moyenne qui ne rend pas compte du nombre d&#8217;&#233;l&#233;ments. Il est possible que SYNT extraie peu de bi-segments
sur des paires de phrases difficiles, mais que lorsqu&#8217;elle parvient &#224; trouver des structures syntaxiques compatibles,
celles-ci permettent un alignement pr&#233;cis. Enfin, TERME est lui insensible &#224; cette difficult&#233;, ce qui &#233;tait attendu
puisqu&#8217;elle fonctionne sur de courts patrons morphosyntaxiques pouvant impliquer des mots diff&#233;rents. Nous
d&#233;duisons donc de ces remarques que ces diff&#233;rentes techniques peuvent &#234;tre utilis&#233;es &#224; bon escient pour diff&#233;rents
niveaux de parall&#233;lisme des corpus d&#8217;acquisition. Le rappel fait appara&#238;tre une tendance beaucoup plus marqu&#233;e :
MOT, DISTR et SYNT extraient d&#8217;autant moins de bi-segments de la r&#233;f&#233;rence que les phrases sont difficiles. &#192;
nouveau, TERME y semble insensible. On retiendra de cette analyse qu&#8217;il est pr&#233;f&#233;rable d&#8217;avoir des paraphrases
d&#8217;&#233;nonc&#233;s les plus &#171; parall&#232;les &#187; possibles pour obtenir une bonne performance en acquisition, mais que les
techniques symboliques sont utiles pour extraire des paraphrases sous-phrastiques pr&#233;cises dans des paraphrases
d&#8217;&#233;nonc&#233;s de formes tr&#232;s diff&#233;rentes.
</p>
<p>4 Conclusion et travaux futurs
</p>
<p>Dans cet article nous avons poursuivi deux objectifs. D&#8217;une part, nous avons pr&#233;sent&#233; quatre m&#233;thodes d&#8217;acqui-
sition de paraphrases sous-phrastiques &#224; partir de corpus monolingues parall&#232;les. Trois d&#8217;entre elles avaient d&#233;j&#224;
&#233;t&#233; &#233;valu&#233;es, la derni&#232;re est nouvelle. Ces m&#233;thodes reposent sur des caract&#233;ristiques linguistiques diff&#233;rentes :
MOT sur l&#8217;apprentissage statistique, TERME sur un approche symbolique de la variation de termes, SYNT sur des
proximit&#233;s syntaxiques et enfin DIST sur des distances d&#8217;&#233;dition. En &#233;valuant ces m&#233;thodes, nous avons constat&#233;
qu&#8217;effectivement leurs r&#233;sultats semblent compl&#233;mentaires, ce qui nous a men&#233; &#224; notre second objectif, &#224; savoir
l&#8217;hybridation de ces m&#233;thodes. Plut&#244;t que de combiner les r&#233;sultats a posteriori, nous avons choisi d&#8217;utiliser les
r&#233;sultats de certaines m&#233;thodes comme donn&#233;es d&#8217;entr&#233;e d&#8217;une autre. Les r&#233;sultats de cette approche ont confirm&#233;
notre hypoth&#232;se en montrant que la compl&#233;mentarit&#233; de ces techniques donne un gain significatif.
</p>
<p>De nombreuses pistes s&#8217;ouvrent &#224; nous &#224; la suite de ce travail. Nous souhaitons explorer toutes celles &#233;voqu&#233;es au
cours de cet article. &#192; court terme, nous comptons attribuer des scores de confiance &#224; chacune des techniques afin</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>COMBINAISON D&#8217;INFORMATIONS POUR L&#8217;ALIGNEMENT MONOLINGUE
</p>
<p>FIGURE 6 &#8211; Performance selon les diff&#233;rents crit&#232;res de PARAMETRIC de diff&#233;rentes techniques. La valeur de
chaque barre dans les intervalles discr&#233;tis&#233;s est une moyenne des &#233;l&#233;ments de cet intervalle, et ne rend pas compte
du nombre de ces &#233;l&#233;ments. Pour la pr&#233;cision, une valeur de 0 peut indiquer soit l&#8217;absence de proposition pour les
phrases de cet intervalle, soit de propositions toutes incorrectes.
</p>
<p>de mieux tirer parti de leur compl&#233;mentarit&#233;. Nous allons &#233;galement utiliser des connaissances compl&#233;mentaires.
Il est important de noter que cette m&#233;thode peut s&#8217;adapter &#224; la t&#226;che requ&#233;rant des paraphrases. Ainsi, on peut
souhaiter en obtenir de nombreuses, au d&#233;triment de leur qualit&#233; pour de la recherche d&#8217;information, alors que la
correction sera privil&#233;gi&#233;e pour le r&#233;sum&#233; automatique.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BANNARD C. &amp; CALLISON-BURCH C. (2005). Paraphrasing with bilingual parallel corpora. In Actes de ACL,
Ann Arbor, USA.
</p>
<p>BARZILAY R. &amp; LEE L. (2003). Learning to paraphrase : an unsupervised approach using multiple-sequence
alignment. In Actes de NAACL-HLT, Edmonton, Canada.
</p>
<p>BARZILAY R. &amp; MCKEOWN K. (2001). Extracting paraphrases from a parallel corpus. In Actes de ACL,
Toulouse, France.
</p>
<p>BOUAMOR H. (2010). Construction d&#8217;un corpus de paraphrases d&#8217;&#233;nonc&#233;s par traduction multilingue multi-
source. In R&#233;cital-TALN, Montr&#233;al, Canada.
</p>
<p>BOUAMOR H., MAX A. &amp; VILNAT A. (2010). Acquisition de paraphrases sous-phrastiques depuis des para-
phrases d&#8217;&#233;nonc&#233;s. In Actes de TALN 2010, Montr&#233;al, Canada.
</p>
<p>CALLISON-BURCH C. (2008). Syntactic constraints on paraphrases extracted from parallel corpora. In Actes de
EMNLP, Hawai, USA.
</p>
<p>CALLISON-BURCH C., COHN T. &amp; LAPATA M. (2008). Parametric : An automatic evaluation metric for para-
phrasing. In Actes de COLING, Manchester, UK.</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>HOUDA BOUAMOR, AUR&#201;LIEN MAX ET ANNE VILNAT
</p>
<p>CREGO J. M., MAX A. &amp; YVON F. (2010). Local lexical adaptation in machine translation through triangu-
lation : SMT helping SMT. In Proceedings of the 23rd International Conference on Computational Linguistics
(Coling 2010), Beijing, China.
DEL&#201;GER L. &amp; ZWEIGENBAUM P. (2009). Extracting lay paraphrases of specialized expressions from mono-
lingual comparable medical corpora. In Proceedings of the 2nd Workshop on Building and Using Comparable
Corpora.
DOLAN W. B. &amp; BROCKETT C. (2005). Automatically constructing a corpus of sentential paraphrases. In
Proceedings of the Third International Workshop on Paraphrasing (IWP2005), Jeju Island, South Korea.
DUCLAYE F., COLLIN O. &amp; YVON F. (2003). Apprentissage automatique de paraphrases pour l&#8217;am&#233;lioration
d&#8217;un syst&#232;me de questions-r&#233;ponses. In Actes de TALN, Batz-sur-mer, France.
DUTREY C., BOUAMOR H., BERNHARD D. &amp; MAX A. (2010). Local modifications and paraphrases in
wikipedia&#8217;s revision history. In Workshop on Corpus-Based Approaches to Paraphrasing and Nominaliza-
tion,CBA 2010, Barcelone, Espagne.
GERMANN U. (2008). Yawat :Yet Another Word Alignment Tool. In Proceedings of the ACL-08 : HLT Demo
Session, Columbus, Ohio.
HARRIS Z. (1954). Distributional structure. Word.
IBRAHIM A., KATZ B. &amp; LIN J. (2003). Extracting structural paraphrases from aligned monolingual corpora. In
Proceedings of the second international workshop on Paraphrasing : Association for Computational Linguistics.
JACQUEMIN C. (1999). Syntagmatic and paradigmatic representations of term variation. In Actes de ACL,
College Park, &#201;tats-Unis.
KAUCHAK D. &amp; BARZILAY R. (2006). Paraphrasing for automatic evaluation. In Actes de NAACL-HLT, New
York, &#201;tats-Unis.
KOEHN P., HOANG H., BIRCH A., CALLISON-BURCH C., FEDERICO M., BERTOLDI N., COWAN B., SHEN
W., MORAN C., ZENS R., DYER C., BOJAR O., CONSTANTIN A. &amp; HERBST E. (2007). Moses : Open source
toolkit for statistical machine translation. In Proceedings of ACL, demo session, Prague, Czech Republic.
LANGKILDE I. &amp; KNIGHT K. (1998). Generations that Exploits Corpus-based Statistical Knowledge. In Pro-
ceedings of the 36th International Conference on Computational Linguistics.
LARDILLEUX A. (2010). Contribution des basses fr&#233;quences &#224; l&#8217;alignement sous-phrastique multilingue : une
approche diff&#233;rentielle. PhD thesis, Universit&#233; de Caen, France.
LIN D. &amp; PANTEL P. (2001). Discovery of inference rules for question answering. Natural Language Engineer-
ing, 7(4).
MATUSOV E., LEUSCH G. &amp; NEY H. (2009). Learning To Combine Machine Translation Systems. MIT Press.
MAX A. (2008). G&#233;n&#233;ration de reformulations locales par pivot pour l&#8217;aide &#224; la r&#233;vision. In Actes de TALN,
Avignon, France.
MAX A. (2009). Sub-sentencial paraphrasing by contextual pivot translation. In Proceedings of the ACL 2009
Workshop on Applied Textual Inference, Singapore.
MILLER G. A. (1995). Wordnet : a lexical database for english. Commun. ACM, 38(11).
OCH F. J. &amp; NEY H. (2003). A systematic comparison of various statistical alignment models. Computational
Linguistics.
PANG B., KNIGHT K. &amp; MARCU D. (2003). Syntax-based alignement of multiple translations : Extracting
paraphrases and generating new sentences. In Actes de NAACL-HLT, Edmonton, Canada.
QUIRK C., BROCKETT C. &amp; DOLAN W. B. (2004). Monolingual machine translation for paraphrase generation.
In Proceedings of EMNLP, volume 149, Barcelona, Spain.
RUSSO-LASSNER .G L. J. &amp; .P R. (2005). A Paraphrase-Based Approach to Machine Translation Evaluation.
Rapport interne TR-2005-57, UMIACS.
SNOVER M., MADNANI N., DORR B. &amp; SCHWARTZ R. (2009). Fluency, adequacy, or HTER ? Exploring
different human judgments with a tunable MT metric. In Proceedings of the Fourth Workshop on Statistical
Machine Translation, Athens, Greece.
TOMEH N., ALLAUZEN A., WISNIEWSKI G. &amp; YVON F. (2010). Refining word alignment with discriminative
training. In Proceedings of The Ninth Conference of the Association for Machine Translation in the Americas
(AMTA 2010).</p>

</div></div>
</body></html>