<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Extraction de pr&#233;f&#233;rences &#224; partir de dialogues de n&#233;gociation</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 343&#8211;350,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Extraction de pr&#233;f&#233;rences &#224; partir de dialogues de n&#233;gociation
</p>
<p>Ana&#239;s Cadilhac Farah Benamara Vladimir Popescu Nicholas Asher
Mohamadou Seck
</p>
<p>IRIT, 118, Route de Narbonne, 31062 Toulouse Cedex 9
{&#13;adilha&#13;, benamara, popes&#13;u, asher, se&#13;k}&#8;irit.fr
</p>
<p>R&#201;SUM&#201;
Cet article pr&#233;sente une approche linguistique pour l&#8217;extraction d&#8217;expressions de pr&#233;f&#233;rence &#224;
partir de dialogues de n&#233;gociation. Nous proposons un nouveau sch&#233;ma d&#8217;annotation pour enco-
der les pr&#233;f&#233;rences et les d&#233;pendances exprim&#233;es linguistiquement dans deux genres de corpus
diff&#233;rents. Ensuite, nous proposons une m&#233;thode d&#8217;apprentissage qui extrait les expressions de
pr&#233;f&#233;rence en utilisant une combinaison de traits locaux et discursifs. Finalement, nous &#233;valuons
la fiabilit&#233; de notre approche sur chaque genre de corpus.
</p>
<p>ABSTRACT
Towards Preference Extraction From Negotiation Dialogues
</p>
<p>This paper presents an NLP based approach for preference expression extraction from negotia-
tion dialogues. We propose a new annotation schema for preferences and dependencies among
them and illustrate on two different corpus genres. We then suggest a learning approach that
efficiently extracts preference expressions using a combination of local and discursive features
and assess the reliability of our approach on each corpus genre.
</p>
<p>MOTS-CL&#201;S : Pr&#233;f&#233;rence, dialogue, apprentissage automatique.
</p>
<p>KEYWORDS: Preference, dialogue, machine learning.
</p>
<p>1 Introduction
Mod&#233;liser les pr&#233;f&#233;rences est incontournable dans de nombreux probl&#232;mes de la vie courante,
que ce soit pour la prise de d&#233;cision individuelle ou collective (Arora et Allenby, 1999), les
interactions strat&#233;giques entre agents (Brainov, 2000) ou la th&#233;orie des jeux (Hausman, 2000).
Un aper&#231;u des travaux sur les pr&#233;f&#233;rences en Intelligence Artificielle est donn&#233; par Kaci (2011).
</p>
<p>Une pr&#233;f&#233;rence est g&#233;n&#233;ralement d&#233;finie comme un ordre donn&#233; par un agent sur diff&#233;rentes
options. Les options d&#233;pendent du domaine : elles peuvent &#234;tre des vols d&#8217;avions, des voitures,
des horaires et lieux de rendez-vous, etc. L&#8217;ordonnancement des pr&#233;f&#233;rences peut &#234;tre total
(strict ou non), rendant chaque paire d&#8217;options comparable, ou partiel, quand certaines options
ne peuvent pas &#234;tre compar&#233;es par un agent donn&#233;. Parmi ces options, certaines sont acceptables
pour l&#8217;agent, c&#8217;est-&#224;-dire qu&#8217;il est pr&#234;t &#224; agir pour les r&#233;aliser, et d&#8217;autres ne le sont pas. Parmi
les options acceptables, l&#8217;agent en pr&#233;f&#232;re g&#233;n&#233;ralement certaines par rapport aux autres.
</p>
<p>Il est important de diff&#233;rencier les notions de pr&#233;f&#233;rence et d&#8217;opinion. Alors que les opinions
sont un point de vue, un sentiment ou un jugement qu&#8217;un agent peut avoir sur un objet ou une
personne, les pr&#233;f&#233;rences, comme nous les avons d&#233;finies, impliquent un ordre de la part de
</p>
<p>343</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>l&#8217;agent et sont ainsi relationnelles et comparatives. Les opinions concernent donc un jugement
absolu sur des objets ou des personnes (positif, n&#233;gatif ou neutre), tandis que les pr&#233;f&#233;rences
concernent un jugement relatif sur des options, les pr&#233;f&#233;rant, ou non, aux autres. Par exemple,
Ce film n&#8217;est pas mauvais exprime une opinion directe positive sur un film mais nous ne savons
pas si ce film est le &#171; plus &#187; pr&#233;f&#233;r&#233;. J&#8217;aimerais aller au cin&#233;ma. Allons voir Madagascar 2 ex-
prime deux pr&#233;f&#233;rences, l&#8217;une d&#233;pendant de l&#8217;autre. La premi&#232;re est que l&#8217;auteur pr&#233;f&#232;re aller
au cin&#233;ma par rapport aux autres actions alternatives ; la seconde est qu&#8217;&#233;tant donn&#233;e cette
pr&#233;f&#233;rence, il pr&#233;f&#232;re aller voir Madagascar 2 plut&#244;t que les autres films possibles.
</p>
<p>Traiter les pr&#233;f&#233;rences n&#8217;est pas ais&#233;. Tout d&#8217;abord, il est n&#233;cessaire de conna&#238;tre au moins par-
tiellement l&#8217;ensemble des options sur lesquelles portent les pr&#233;f&#233;rences. Ensuite, il faut pouvoir
d&#233;finir un ordre a priori sur les options acceptables mais ce n&#8217;est pas toujours trivial. De plus,
donner un ordre entre deux options (appareils photos) peut &#234;tre difficile &#224; cause de la n&#233;ces-
sit&#233; de tenir compte des compromis et des interd&#233;pendances entre les diff&#233;rents crit&#232;res (dur&#233;e
de vie de la batterie, poids, etc.). Ensuite, les utilisateurs manquent souvent d&#8217;informations
compl&#232;tes sur leurs pr&#233;f&#233;rences initiales qui tendent &#224; changer au cours du temps. En effet, les
utilisateurs peuvent apprendre du domaine, des pr&#233;f&#233;rences des autres et m&#234;me de leurs propres
pr&#233;f&#233;rences au cours du processus de prise de d&#233;cision. Plusieurs m&#233;thodes ont &#233;t&#233; propos&#233;es
en Intelligence Artificielle pour &#233;liciter les pr&#233;f&#233;rences (Chen et Pu, 2004). Cependant, &#224; notre
connaissance, aucun travail ne montre comment les pr&#233;f&#233;rences pourraient &#234;tre d&#233;termin&#233;es &#224;
partir de dialogues en utilisant une approche linguistique.
</p>
<p>L&#8217;approche que nous proposons a pour but d&#8217;&#233;tudier le r&#244;le du discours pour extraire et raisonner
sur les pr&#233;f&#233;rences. Notre approche comporte trois &#233;tapes :
</p>
<p>1. Extraire les options. L&#8217;objectif est de rep&#233;rer, au sein de chaque segment de discours, les
expressions linguistiques sur lesquelles portent les pr&#233;f&#233;rences d&#8217;un agent.
</p>
<p>2. Identifier les &#233;ventuelles d&#233;pendances entre les options extraites &#224; l&#8217;&#233;tape 1 en utilisant un en-
semble d&#8217;op&#233;rateurs sp&#233;cifiques. Ces d&#233;pendances nous permettent d&#8217;inf&#233;rer les pr&#233;f&#233;rences
de l&#8217;agent et d&#8217;identifier, &#233;tant donn&#233;es deux options, leur ordonnancement.
</p>
<p>3. Proposer une description formelle des pr&#233;f&#233;rences de chaque agent. Nous &#233;tudions comment
les relations de discours permettent de suivre l&#8217;&#233;volution des pr&#233;f&#233;rences au cours du dia-
logue. Cette description se fait en utilisant une repr&#233;sentation compacte des pr&#233;f&#233;rences,
les CP-nets (Conditional Preference Networks) (Boutilier et al., 2004).
</p>
<p>Une description d&#233;taill&#233;e de ces &#233;tapes est donn&#233;e dans (Cadilhac et al., 2011). Le travail pr&#233;-
sent&#233; ici est un premier pas vers l&#8217;automatisation de ce processus en se focalisant sur la premi&#232;re
&#233;tape. Nous analysons comment les pr&#233;f&#233;rences sont exprim&#233;es linguistiquement, c&#8217;est-&#224;-dire
comment les options et les d&#233;pendances sont lexicalis&#233;es. Nous montrons comment les options
peuvent &#234;tre extraites automatiquement gr&#226;ce &#224; un algorithme d&#8217;apprentissage supervis&#233; utili-
sant des traits locaux et discursifs et nous &#233;valuons la fiabilit&#233; de notre approche.
</p>
<p>2 Donn&#233;es
Nos donn&#233;es viennent de deux corpus. Le premier corpus, Verbmobil, est compos&#233; de 35
dialogues choisis au hasard dans le corpus Verbmobil d&#233;j&#224; existant (Wahlster, 2000), dans
lequel deux agents discutent pour fixer la date et le lieu d&#8217;un rendez-vous. Il a &#233;t&#233; utilis&#233;
pour cr&#233;er la liste des traits d&#8217;apprentissage. Le second corpus, R&#233;servations, a &#233;t&#233; utilis&#233;
pour &#233;valuer &#224; quel point notre m&#233;thode est d&#233;pendante du domaine. Il a &#233;t&#233; construit &#224; par-
tir de plusieurs ressources d&#8217;apprentissage de l&#8217;anglais disponibles sur Internet (par exemple,
www.bbc.co.uk/worldservice/learningenglish). Il contient 21 dialogues choisis au hasard, dans
</p>
<p>344</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>lesquels un agent, le client, appelle un service pour r&#233;server une chambre, un vol d&#8217;avion, un
taxi, etc. En voici un exemple typique :
pi1 A : Northwind Airways, good morning. May I help you ?
pi2 B : Yes, do you have any flights to Sydney next Tuesday afternoon ?
pi3 A : Yes, there&#8217;s a flight at 16:45 and one at 18:00.
pi4 A : Economy, business class or first class ticket ?
pi5 B : Economy, please.
Afin d&#8217;analyser comment les options et les d&#233;pendances sont exprim&#233;es linguistiquement dans
les dialogues de n&#233;gociation, nous avons r&#233;alis&#233; une annotation &#224; deux niveaux : d&#8217;abord, au ni-
veau du discours, s&#233;parant le texte en segments (les pii ci-dessus) li&#233;s entre eux par des relations
rh&#233;toriques ; puis, au niveau des pr&#233;f&#233;rences exprim&#233;es dans chaque segment.
</p>
<p>2.1 Annotation du discours
Les dialogues sont structur&#233;s par des tours de parole qui permettent &#224; chaque agent de partici-
per au dialogue. Un agent peut, par exemple, r&#233;pondre aux questions d&#8217;autres agents, poser ses
propres questions, etc. Dans chacun de ces tours, les agents s&#8217;engagent sur leurs croyances et
pr&#233;f&#233;rences. En g&#233;n&#233;ral, les mod&#232;les formels de dialogue n&#8217;explicitent pas le lien entre les &#233;non-
c&#233;s et les pr&#233;f&#233;rences (voir, par exemple, (Ginzburg, 2012)). Il est alors n&#233;cessaire d&#8217;avoir, d&#8217;une
part, une m&#233;thode qui permet une extraction partielle des pr&#233;f&#233;rences et de leurs d&#233;pendances
et, d&#8217;autre part, une m&#233;thode qui permet d&#8217;exploiter cette description partielle afin d&#8217;identifier
l&#8217;ensemble des options pr&#233;f&#233;r&#233;es.
</p>
<p>Notre approche exploite la structure du discours selon la Th&#233;orie des Repr&#233;sentations Segmen-
t&#233;es du Discours, SDRT (Asher et Lascarides, 2003) o&#249; des unit&#233;s discursives (UD) sont li&#233;es
entre elles par des relations rh&#233;toriques telles que Paire Question-R&#233;ponse (QAP), Plan-Correction
(P-Corr), etc. Bien que le probl&#232;me d&#8217;extraction de la structure du discours reste redoutable, on
peut approximer ces relations relativement bien en utilisant des caract&#233;ristiques qui peuvent
facilement &#234;tre obtenues automatiquement (par exemple, Baldridge et Lascarides (2005b) r&#233;a-
lisent un F-score d&#8217;environ 69,2%). Notre &#233;tude montre ici l&#8217;importance des caract&#233;ristiques
du discours pour l&#8217;extraction de pr&#233;f&#233;rences, en supposant que celles-ci sont donn&#233;es par un
oracle. Pour Verbmobil, nous avons utilis&#233; l&#8217;annotation de Baldridge et Lascarides (2005a).
Pour R&#233;servations, l&#8217;annotation a &#233;t&#233; faite par consensus en utilisant le m&#234;me ensemble de
relations rh&#233;toriques qui a &#233;t&#233; utilis&#233; pour annoter Verbmobil.
</p>
<p>2.2 Annotation des pr&#233;f&#233;rences
Notre objectif est d&#8217;analyser comment les pr&#233;f&#233;rences sont linguistiquement exprim&#233;es dans des
segments de dialogues. Deux &#233;tapes sont n&#233;cessaires : (i) identifier l&#8217;ensemble O des options
(des termes) sur lesquelles portent les pr&#233;f&#233;rences d&#8217;un agent, (ii) identifier les &#233;ventuelles d&#233;-
pendances entre les &#233;l&#233;ments de O en utilisant un ensemble d&#8217;op&#233;rateurs sp&#233;cifiques, c&#8217;est-&#224;-dire
identifier les pr&#233;f&#233;rences de l&#8217;agent parmi les options &#233;nonc&#233;es. Par exemple, dans Rencontrons
nous lundi ou mardi, nous avons O = {lundi, mardi} o&#249; les options sont linguistiquement re-
li&#233;es par la conjonction ou qui signifie que l&#8217;agent est pr&#234;t &#224; r&#233;aliser une de ces options, les
pr&#233;f&#233;rant de mani&#232;re &#233;gale.
</p>
<p>Dans une UD, les pr&#233;f&#233;rences peuvent &#234;tre exprim&#233;es de diff&#233;rentes mani&#232;res. Elles peuvent &#234;tre
atomiques, par exemple, &#171; Je veux X &#187; ou &#171; Je pr&#233;f&#232;re X &#187; o&#249; &#171; X &#187; est une option acceptable.
Cette option peut &#234;tre un groupe nominal (lundi), un groupe pr&#233;positionnel (&#224; mon bureau)
ou un groupe verbal (se rencontrer). Les pr&#233;f&#233;rences peuvent aussi &#234;tre exprim&#233;es dans des
constructions comparatives et/ou superlatives (un vol moins cher). Elles sont aussi exprim&#233;es
</p>
<p>345</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>d&#8217;une mani&#232;re indirecte en utilisant des questions. Bien que toutes les questions n&#8217;impliquent pas
que l&#8217;auteur s&#8217;engage sur une pr&#233;f&#233;rence, dans beaucoup de cas elles le font. C&#8217;est-&#224;-dire si un
agent demande Pouvons-nous nous rencontrer la semaine prochaine ?, il implique une pr&#233;f&#233;rence
pour se rencontrer. Des expressions de sentiment ou de politesse peuvent aussi &#234;tre utilis&#233;es
pour introduire indirectement des pr&#233;f&#233;rences. Dans R&#233;servations, le segment Economique,
s&#8217;il vous pla&#238;t indique que l&#8217;agent pr&#233;f&#232;re &#234;tre dans la classe &#233;conomique.
</p>
<p>Les expressions de pr&#233;f&#233;rences peuvent aussi &#234;tre complexes, exprimant des n&#233;gations, conjonc-
tions, disjonctions, ou d&#233;pendances. Nous associons &#224; chacune de ces expressions des op&#233;rateurs
sp&#233;cifiques (non-bool&#233;ens), que nous d&#233;signons respectivement par not, &amp;, or et 7&#8594;. Les r&#233;alisa-
tions linguistiques de ces op&#233;rateurs nous seront utiles dans la phase d&#8217;extractions des options
(voir section 3). Les n&#233;gations indiquent ce que l&#8217;agent ne pr&#233;f&#232;re pas, c&#8217;est-&#224;-dire que l&#8217;option
exprim&#233;e est non-pr&#233;f&#233;r&#233;e. La n&#233;gation peut &#234;tre explicite, comme dans Je ne veux pas qu&#8217;on
se rencontre vendredi, ou inf&#233;r&#233;e &#224; partir du contexte, comme dans Je suis occup&#233; mardi. Un
exemple de conjonction entre pr&#233;f&#233;rences est Pourrais-je avoir un petit d&#233;jeuner et un repas v&#233;-
g&#233;tarien ? o&#249; l&#8217;agent exprime deux pr&#233;f&#233;rences qu&#8217;il souhaite satisfaire et il aimerait en avoir
au moins une des deux s&#8217;il ne peut pas les avoir toutes. La s&#233;mantique des disjonctions est une
modalit&#233; de choix libre. Par exemple, Je suis libre lundi ou mardi signifie que lundi ou mardi
est un jour possible pour se rencontrer et que l&#8217;agent est indiff&#233;rent entre les deux. Finalement,
certaines UD expriment des engagements sur des pr&#233;f&#233;rences d&#233;pendantes. Par exemple, dans
la phrase Pourquoi pas lundi, dans l&#8217;apr&#232;s-midi ?, il y a deux pr&#233;f&#233;rences : une pour le jour lundi
et, &#233;tant donn&#233; la pr&#233;f&#233;rence pour lundi, une pour la p&#233;riode de l&#8217;apr&#232;s-midi (au moins pour
une des interpr&#233;tations syntaxiques du segment).
</p>
<p>Pour chaque UD, nous avons demand&#233; &#224; deux annotateurs d&#8217;identifier comment les options sont
exprim&#233;es et ensuite d&#8217;indiquer comment les pr&#233;f&#233;rences sur ces options sont li&#233;es entre elles
en utilisant les op&#233;rateurs sp&#233;cifiques not, &amp;, or et 7&#8594;. Nous donnons ci-dessous un exemple de
comment certains segments sont annot&#233;s. &lt; o &gt;_i indique que o est l&#8217;option num&#233;ro i dans le
segment, et le symbole // est utilis&#233; pour s&#233;parer les deux niveaux d&#8217;annotation. Une description
d&#233;taill&#233;e de ce sch&#233;ma d&#8217;annotation est donn&#233;e dans (Cadilhac et al., 2012).
pi1 : Je suis libre &lt;&#224; quatre&gt;_1 ou &lt;cinq heures&gt;_2 &lt;ces jours-l&#224;&gt;_3. // 3 7&#8594; (1 or 2)
pi2 : &lt;Mardi 16&gt;_1, j&#8217;ai s&#233;minaire &lt;de 9h &#224; midi&gt;_2. // 1 7&#8594; not 2
En utilisant le coefficient Kappa de Cohen, nous avons calcul&#233; deux taux d&#8217;accord inter-
annotateurs sur l&#8217;identification des options. L&#8217;un est bas&#233; sur un accord exact o&#249; deux anno-
tations (c&#8217;est-&#224;-dire, les unit&#233;s de texte correspondant &#224; une option) doivent correspondre exac-
tement pour &#234;tre consid&#233;r&#233;es comme correctes. L&#8217;autre est bas&#233; sur un accord souple o&#249; deux
annotations correspondent s&#8217;il y a un chevauchement entre leurs unit&#233;s de texte (comme pour 2
heures et environ 2 heures). Nous avons obtenu un accord exact de 0,66 et un accord souple de
0,85. L&#8217;accord souple &#233;tant bon pour Verbmobil, nous avons d&#233;cid&#233; d&#8217;annoter R&#233;servations
par consensus.
</p>
<p>Le gold standard pour les deux corpus a &#233;t&#233; construit apr&#232;s discussion des cas de d&#233;saccord.
Nous avons observ&#233; quatre cas. (1) Le premier concerne la redondance des pr&#233;f&#233;rences et nous
avons d&#233;cid&#233; de ne pas garder les pr&#233;f&#233;rences redondantes dans le gold standard. En effet, les
agents r&#233;p&#232;tent souvent des pr&#233;f&#233;rences qui ont d&#233;j&#224; &#233;t&#233; &#233;tablies, comme dans l&#8217;exemple suivant,
pi1 A : jeudi, vendredi et samedi je ne suis pas l&#224;. pi2 A : Ces 3 jours ne sont pas possibles pour moi,
o&#249; nous avons Resultat(pi1, pi2). (2) Le second cas de d&#233;saccord vient des pr&#233;f&#233;rences qui sont
exprim&#233;es par des anaphores. Nous avons d&#233;cid&#233; de les annoter dans le gold standard car elles
sont souvent utilis&#233;es dans les corpus pour introduire ou pr&#233;ciser des pr&#233;f&#233;rences. Comme dans
</p>
<p>346</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>l&#8217;exemple suivant, pi1 A : A 2 heures, le 17 ? pi2 B : C&#8217;est parfait, o&#249; nous avons Q-Elab(pi1, pi2). (3)
Le troisi&#232;me cas de d&#233;saccord concerne l&#8217;explication de pr&#233;f&#233;rence. Dans le gold standard, nous
avons choisi de ne pas annoter les expressions qui sont utilis&#233;es pour expliquer des pr&#233;f&#233;rences
d&#233;j&#224; &#233;tablies. Comme dans l&#8217;exemple suivant, pi1 A : pas lundi, pi2 A : j&#8217;ai un cours de 9 &#224; 12
heures, o&#249; nous avons Explication(pi1, pi2). (4) Finalement, le dernier cas de d&#233;saccord provient
des pr&#233;f&#233;rences qui ne sont pas directement li&#233;es &#224; l&#8217;action de fixer une date pour le rendez-vous
mais plut&#244;t &#224; d&#8217;autres actions comme d&#233;jeuner ensemble. M&#234;me si ces pr&#233;f&#233;rences ont souvent
&#233;t&#233; omises par les annotateurs, nous avons d&#233;cid&#233; de les garder.
</p>
<p>3 Extraction des objets de pr&#233;f&#233;rences
Le probl&#232;me de l&#8217;extraction est de d&#233;cider si un terme est une option ou non. L&#8217;objectif est donc
de classer les termes en deux cat&#233;gories : Option et Non-option indiquant respectivement que
le terme exprime une option faisant l&#8217;objet des pr&#233;f&#233;rences, ou non. Nous rappelons que les
options peuvent &#234;tre des groupes nominaux, groupes pr&#233;positionnels ou groupes verbaux. Nous
devons donc choisir quels groupes de mots doivent &#234;tre class&#233;s. Dans les donn&#233;es, les agents
n&#233;gocient pour se mettre d&#8217;accord sur une action : se rencontrer un jour donn&#233;, r&#233;server un
certain vol, etc. Nous sommes g&#233;n&#233;ralement inform&#233;s de ces actions dans les groupes verbaux.
Cependant, les termes correspondants aux options de pr&#233;f&#233;rences sont plut&#244;t contenus dans les
groupes nominaux (GN). Par exemple, pour fixer un rendez-vous, la n&#233;gociation porte sur les
jours et les heures. Pour r&#233;server un h&#244;tel, la n&#233;gociation porte sur des options plus sp&#233;cifiques
comme une chambre double. Il semble donc appropri&#233; d&#8217;extraire les GN. Pour les classer dans
une des deux classes, nous utilisons deux genres de traits (tous binaires) : les traits locaux et les
traits discursifs. Le classifieur est bas&#233; sur les Machines &#224; Vecteurs de Support.
</p>
<p>La port&#233;e des traits locaux est soit l&#8217;unit&#233; qui doit &#234;tre class&#233;e, c&#8217;est-&#224;-dire le GN, soit le segment
qui contient le GN. Certains de ces traits reposent sur une ontologie qui mod&#233;lise un calendrier
(date, temps, etc.) inspir&#233;e de deux ontologies de haut niveau, SUMO et COSMO. Nous avons
cinq traits au niveau du GN qui testent si le GN contient : le label d&#8217;un concept appartenant &#224;
l&#8217;ontologie, un comparatif, un superlatif, une disjonction ou une conjonction. Nous avons dix
traits au niveau du segment : (1) le voisin gauche du GN correspond &#224; un label d&#8217;un concept
de l&#8217;ontologie. Puisque la liste des termes associ&#233;s &#224; chaque concept de notre ontologie est
courte, ce trait aide &#224; retrouver des lexicalisations suppl&#233;mentaires ; (2) le segment contient
une disjonction ou une conjonction ; (3) le GN est dans la port&#233;e d&#8217;une n&#233;gation, d&#8217;un modal ou
d&#8217;un verbe d&#8217;action du domaine (se rencontrer, r&#233;server). La port&#233;e des n&#233;gations et des modaux
est r&#233;solue de mani&#232;re simplifi&#233;e en utilisant l&#8217;arbre syntaxique de l&#8217;UD ; (4) le segment contient
un mot d&#8217;opinion (bon, mauvais, OK, etc.), un mot de politesse ou un mot qui introduit des
pr&#233;f&#233;rences (pr&#233;f&#233;rer, favori, choix, trop, etc.) ; (5) le segment contient une r&#233;f&#233;rence &#224; l&#8217;autre
agent. Ce trait est un indice pour la classe Non-option. Dans des segments comme Tu as dit que tu
n&#8217;es pas libre mardi matin ou mercredi apr&#232;s-midi ?, l&#8217;agent n&#8217;apporte pas de nouvelle information
sur les pr&#233;f&#233;rences mais r&#233;p&#232;te seulement ce qui a d&#233;j&#224; &#233;t&#233; &#233;tabli par l&#8217;autre agent.
</p>
<p>Nous avons neuf traits au niveau du discours : (1) les relations rh&#233;toriques qui lient l&#8217;UD cou-
rante &#224; l&#8217;UD pr&#233;c&#233;dente et &#224; l&#8217;UD suivante impliquent des pr&#233;f&#233;rences. Nous avons remarqu&#233;
que certaines relations de discours peuvent aider &#224; rep&#233;rer des segments qui contiennent, ou
non, des pr&#233;f&#233;rences. Nous dissocions les relations de discours en trois cat&#233;gories : (a) celles
qui impliquent &#171; g&#233;n&#233;ralement &#187; une Non-option comme Explication, Commentaire, R&#233;sum&#233;, (b)
celles qui impliquent &#171; peut-&#234;tre &#187; une Option comme Elaboration, Continuation, Correction et
</p>
<p>347</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CV CR CV + CR
P R F P R F P R F
</p>
<p>Tous les GN 40.9 100.0 58.1 28.0 100.0 43.8 28.3 100.0 44.1
Baselines Ontologie seule 95.6 61.3 74.7 55.6 16.7 25.7 49.2 13.5 21.2
</p>
<p>Classifieur simplifi&#233; 65.2 71.1 68.0 68.4 43.3 53.1 43.9 55.7 49.1
</p>
<p>Traits Tous les traits (GN) 95.7 62.0 75.2 100.0 3.3 6.5 50.7 16.0 24.4
Locaux + Tous les traits (Segment) 94.1 78.9 85.8 68.4 43.3 53.1 60.2 26.2 36.5
</p>
<p>+ Relation Pr&#233;c&#233;dente 94.9 78.9 86.2 67.6 41.7 51.6 60.2 26.2 36.5
Traits + Relation Suivante 94.0 77.5 84.9 66.7 40.0 50.0 59.4 25.3 35.5
Discursifs + Questions 95.6 75.4 84.3 79.0 50.0 61.2 59.4 25.3 35.5
</p>
<p>+ &#8805; 2 occurrences du GN 90.8 83.1 86.8 75.6 56.7 64.8 62.9 32.9 43.2
TABLE 1 &#8211; R&#233;sultats (pourcentages) pour les trois &#233;valuations.
</p>
<p>(c) celles qui impliquent &#171; g&#233;n&#233;ralement &#187; une Option. Dans Verbmobil, 86 % des relations
de discours sont de la cat&#233;gorie (a) alors que 14 % des relations annot&#233;es appartiennent &#224; la
cat&#233;gorie (b). Nous observons la m&#234;me tendance pour R&#233;servations. Il n&#8217;y a pas d&#8217;instances
de la cat&#233;gorie (c) dans les relations de discours utilis&#233;es lors de l&#8217;annotation des deux corpus.
Ainsi, nous avons six traits : trois pour tester si la relation entre l&#8217;UD courante et l&#8217;UD pr&#233;c&#233;dente
appartient, ou non, &#224; une des trois cat&#233;gories, et trois autre pour la relation entre l&#8217;UD courante
et l&#8217;UD suivante ; (2) l&#8217;UD courante ou l&#8217;UD pr&#233;c&#233;dente est une question. Dans nos corpus, les
formes interrogatives ne sont pas toujours suivies par une marque de question. Pour d&#233;tecter les
questions, nous utilisons donc les relations de discours sp&#233;cifiques, comme QAP, Q-Elab ; (3) le
GN appara&#238;t au moins deux fois dans le dialogue.
</p>
<p>4 Evaluation et R&#233;sultats
Plusieurs &#233;valuations sont r&#233;alis&#233;es pour &#233;valuer la validit&#233; de notre m&#233;thode d&#8217;extraction. La
premi&#232;re est effectu&#233;e sur les 35 dialogues de Verbmobil (CV ) pour un total de 1272 UD. Nous
le s&#233;parons au hasard en un corpus d&#8217;entra&#238;nement constitu&#233; de 25 dialogues, soit 2374 GN, et
un corpus de test de 10 dialogues, soit 700 GN. Dans la seconde (CR), le classifieur est entra&#238;n&#233;
sur 15 dialogues de R&#233;servations, soit 837 GN et test&#233; sur 6 dialogues pris au hasard, soit
312 GN. Les 21 dialogues de ce deuxi&#232;me corpus comportent au total 348 UD. Pour la troi-
si&#232;me, le classifieur est &#233;valu&#233; en utilisant Verbmobil pour l&#8217;entra&#238;nement (les 35 dialogues)
et R&#233;servations pour le test (les 21 dialogues) (CV + CR). Cette derni&#232;re &#233;valuation, plut&#244;t
inhabituelle, est suppos&#233;e aider &#224; d&#233;terminer si notre m&#233;thode permet l&#8217;entrainement sur un cor-
pus plus grand et disponible et le test sur un corpus plus petit et parfois d&#8217;un domaine diff&#233;rent.
Pour toutes ces &#233;valuations, nous utilisons le logiciel SVM-light (http ://svmlight.joachims.org).
</p>
<p>Nous comparons les r&#233;sultats du classifieur avec ceux de trois baselines : la premi&#232;re classe
tous les GN dans la cat&#233;gorie Option, la seconde classe dans la cat&#233;gorie Option tous les GN
qui contiennent un concept appartenant &#224; l&#8217;ontologie, et la troisi&#232;me baseline est une version
simplifi&#233;e de notre classifieur qui utilise seulement un sous-ensemble de nos traits (nous enle-
vons les traits bas&#233;s sur l&#8217;ontologie ainsi que tous les traits bas&#233;s sur les relations de discours).
La table 1 pr&#233;sente les r&#233;sultats, sous forme de pr&#233;cision (P), rappel (R) et F-mesure (F). Elle
montre d&#8217;abord les r&#233;sultats des baselines. Nous d&#233;veloppons ensuite notre mod&#232;le en consid&#233;-
rant les traits locaux au niveau du GN, puis nous ajoutons les traits locaux au niveau du segment
et ajoutons progressivement les traits au niveau du discours (l&#8217;ajout des traits est symbolis&#233; par
le signe +). La derni&#232;re ligne pr&#233;sente le r&#233;sultat final, obtenu en utilisant tous les traits.
</p>
<p>348</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Les r&#233;sultats dans la table 1 montrent que, parmi les trois baselines, la seconde donne les
meilleurs r&#233;sultats pour Verbmobil. Ceci &#233;tait attendu puisque l&#8217;ontologie a &#233;t&#233; construite
pour ces donn&#233;es. Cependant, cette baseline ne permet pas de retrouver toutes les options car
certains GN qui contiennent des concepts de l&#8217;ontologie ne sont pas des options (ce sont des
r&#233;p&#233;titions, des commentaires, etc.) et bien s&#251;r toutes les options exprim&#233;es par les agents ne
sont pas couvertes par les concepts de l&#8217;ontologie. Pour R&#233;servations, l&#8217;ontologie d&#233;grade le
rappel par rapport &#224; la premi&#232;re baseline, puisqu&#8217;il y a un faible recouvrement entre les concepts
dans l&#8217;ontologie et ceux dans le corpus. Il en va de m&#234;me pour la troisi&#232;me &#233;valuation (CV + CR).
Cependant, ce n&#8217;est pas un probl&#232;me critique puisque des ontologies adapt&#233;es sont &#233;galement
disponibles pour le domaine touristique. Dans tous les cas, la troisi&#232;me baseline donne des r&#233;-
sultats assez stables, toujours meilleurs que ceux de la premi&#232;re baseline et, dans les deuxi&#232;me
et troisi&#232;me &#233;valuations (pour lesquelles nous n&#8217;avons pas utilis&#233; d&#8217;ontologie adapt&#233;e), ces r&#233;sul-
tats sont &#233;galement meilleurs que ceux de la deuxi&#232;me baseline. Le classifieur donne un meilleur
rappel pour la troisi&#232;me &#233;valuation que pour la deuxi&#232;me. Cela peut montrer un probl&#232;me de
raret&#233; des donn&#233;es lors de l&#8217;entrainement uniquement sur R&#233;servations (configuration (CR)).
</p>
<p>Les &#233;valuations montrent que notre m&#233;thode a une tendance similaire sur Verbmobil et
R&#233;servations. Nous voyons que les traits locaux au niveau du GN sont pertinents pour obtenir
une bonne pr&#233;cision. Les traits au niveau du segment et les traits discursifs am&#233;liorent le rappel
et la F-mesure dans les trois configurations. L&#8217;am&#233;lioration est mieux marqu&#233;e dans les deuxi&#232;me
et troisi&#232;me &#233;valuations. Peut-&#234;tre parce que l&#8217;ontologie, moins bien adapt&#233;e pour ces &#233;valua-
tions, a moins d&#8217;impact sur les performances. Finalement, pour Verbmobil, nous obtenons une
F-mesure de 86,8 %, i.e. presque 20 % au-dessus de la troisi&#232;me baseline (classifieur simplifi&#233;)
et plus de 10 % au-dessus de la deuxi&#232;me baseline (bas&#233;e sur l&#8217;ontologie). Pour R&#233;servations,
nous obtenons une F-mesure de 64,8 %, i.e. plus de 10 % au dessus du classifieur simplifi&#233;. Pour
la troisi&#232;me &#233;valuation, les r&#233;sultats ne montrent pas d&#8217;am&#233;lioration par rapport aux baselines.
C&#8217;est probablement d&#251; &#224; l&#8217;influence de l&#8217;ontologie qui adapte mieux les vecteurs de support au
corpus d&#8217;entrainement (Verbmobil), les rendant moins pertinents pour le corpus de test. En
d&#233;sactivant les deux traits bas&#233;s sur l&#8217;ontologie, nous obtenons 50,2 % de pr&#233;cision, 62,9 % de
rappel et 55,8 % de F-mesure, soit une am&#233;lioration par rapport aux baselines.
</p>
<p>Pour les traits discursifs, nous remarquons que, pour Verbmobil, les relations rh&#233;toriques entre
l&#8217;UD courante et l&#8217;UD pr&#233;c&#233;dente apportent plus d&#8217;am&#233;lioration que les autres informations
discursives. Cela peut s&#8217;expliquer par la nature du corpus, o&#249; le contexte (exprim&#233; dans les tours
de dialogues pr&#233;c&#233;dents) est important. Pour R&#233;servations, le trait qui teste si l&#8217;UD courante
ou l&#8217;UD pr&#233;c&#233;dente sont des questions apporte la meilleure am&#233;lioration des performances car
ce corpus contient principalement des paires question-r&#233;ponse. Pour la troisi&#232;me &#233;valuation,
les traits discursifs n&#8217;apportent pas d&#8217;am&#233;lioration importante par rapport aux baselines. C&#8217;est
peut-&#234;tre caus&#233; par l&#8217;incapacit&#233; des informations discursives &#224; compenser les diff&#233;rences entre
les donn&#233;es d&#8217;entrainement et de test : en effet, en principe, il y a plus d&#8217;instances des traits
locaux (au niveau du GN et du segment) associ&#233;es &#224; des cas positifs, que d&#8217;instances des traits
discursifs associ&#233;es &#224; des cas positifs. Et quand le classifieur est entrain&#233; sur des traits extraits
d&#8217;un domaine de corpus et test&#233; sur un autre domaine, le poids des traits discursifs peut ne pas
suffire &#224; compenser les autres traits, locaux.
</p>
<p>Dans ces trois configurations, le trait testant la pr&#233;sence d&#8217;un GN au moins deux fois dans le
dialogue apporte une am&#233;lioration cons&#233;quente par rapport aux autres. C&#8217;&#233;tait plut&#244;t attendu
puisqu&#8217;en principe la fr&#233;quence d&#8217;un GN apporte de l&#8217;information sur le sujet principal, et cela a
du sens, puisque les agents ont tendance &#224; exprimer des pr&#233;f&#233;rences sur le sujet de la discussion.
</p>
<p>349</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>5 Conclusion et futurs travaux
Nous avons pr&#233;sent&#233; une m&#233;thode linguistique pour l&#8217;extraction des expressions de pr&#233;f&#233;rence
dans des dialogues de n&#233;gociation. Nous avons d&#8217;abord propos&#233; un sch&#233;ma d&#8217;annotation pour
&#233;tudier comment les pr&#233;f&#233;rences sont exprim&#233;es dans des dialogues dans deux domaines diff&#233;-
rents. Nous avons ensuite propos&#233; une m&#233;thode d&#8217;apprentissage qui extrait les expressions de
pr&#233;f&#233;rence des dialogues en utilisant une combinaison de traits locaux et discursifs. Les r&#233;sul-
tats montrent que la structure discursive coupl&#233;e avec une ontologie est utile pour extraire les
expressions de pr&#233;f&#233;rence de mani&#232;re efficace. Dans nos futurs travaux, nous voulons &#233;valuer
la m&#233;thode sur des corpus plus grands et vari&#233;s, pour v&#233;rifier sa pertinence et sa robustesse sur
diff&#233;rents domaines de conversation et registres de discours. Pour le moment, la m&#233;thode de
classification traite uniquement des GN. Ceci est justifi&#233; pour les corpus sur lesquels nous avons
travaill&#233; mais nous devons &#233;tudier s&#8217;il est toujours pertinent d&#8217;utiliser uniquement des GN pour
d&#8217;autres corpus et, si n&#233;cessaire, &#233;tendre la m&#233;thode &#224; d&#8217;autres types de syntagmes. Ce travail
d&#8217;extraction des expressions de pr&#233;f&#233;rence est, nous le rappelons, la premi&#232;re &#233;tape d&#8217;un proces-
sus plus complexe d&#8217;&#233;licitation des pr&#233;f&#233;rences (Cadilhac et al., 2011) qui sera compl&#232;tement
automatis&#233; afin de l&#8217;appliquer &#224; des cas pratiques de n&#233;gociation et marchandage.
</p>
<p>Les auteurs remercient le projet STAC ERC Grant n&#778; 269427.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ARORA, N. et ALLENBY, G. M. (1999). Measuring the influence of individual preference struc-
tures in group decision making. Journal of Marketing Research, 36:476&#8211;487.
ASHER, N. et LASCARIDES, A. (2003). Logics of Conversation. Cambridge University Press.
BALDRIDGE, J. et LASCARIDES, A. (2005a). Annotating discourse structures for robust semantic
interpretation. In Proceedings of the 6th IWCS.
BALDRIDGE, J. et LASCARIDES, A. (2005b). Probabilistic head-driven parsing for discourse struc-
ture. In Proceedings of CoNLL.
BOUTILIER, C., BRAFMAN, C., DOMSHLAK, C., HOOS, H. H. et POOLE, D. (2004). Cp-nets : A tool
for representing and reasoning with conditional ceteris paribus preference statements. Journal
of Artificial Intelligence Research, 21:135&#8211;191.
BRAINOV, S. (2000). The role and the impact of preferences on multiagent interaction. In
Proceedings of ATAL, pages 349&#8211;363. Springer-Verlag.
CADILHAC, A., ASHER, N., BENAMARA, F. et LASCARIDES, A. (2011). Commitments to preferences
in dialogue. In Proceedings of SIGDIAL, pages 204&#8211;215. ACL.
CADILHAC, A., BENAMARA, F. et ASHER, N. (2012). Annotating preferences in negotiation dia-
logues. &#192; para&#238;tre.
CHEN, L. et PU, P. (2004). Survey of preference elicitation methods. Rapport technique.
GINZBURG, J. (2012). The Interactive Stance : Meaning for Conversation. Oxford University
Press.
HAUSMAN, D. M. (2000). Revealed preference, belief, and game theory. Economics and Philoso-
phy, 16(01):99&#8211;115.
KACI, S. (2011). Working with Preferences : Less Is More. Cognitive Technologies. Springer.
WAHLSTER, W., &#233;diteur (2000). Verbmobil : Foundations of Speech-to-Speech Translation. Sprin-
ger.
</p>
<p>350</p>

</div></div>
</body></html>