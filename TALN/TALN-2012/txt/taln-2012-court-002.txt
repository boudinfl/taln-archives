Extraction de préférences a partir de dialogues de négociation

Ana'1's Cadilhac Farah Benamara Vladimir Popescu Nicholas Asher
Mohamadou Seck

IRIT, 118, Route de Narbonne, 31062 Toulouse Cedex 9
{cadi1hac, benamara, popescu, asher, seck}irit .fr

RESUME
Cet article présente une approche linguistique pour l’extraction d’expressions de préférence a
partir de dialogues de négociation. Nous proposons un nouveau schéma d’annotation pour enco-
der les préférences et les dépendances exprimées linguistiquement dans deux genres de corpus
différents. Ensuite, nous proposons une méthode d’apprentissage qui extrait les expressions de
préférence en utilisant une combinaison de traits locaux et discursifs. Finalement, nous évaluons
la ﬁabilité de notre approche sur chaque genre de corpus.

ABSTRACT
Towards Preference Extraction From Negotiation Dialogues

This paper presents an NLP based approach for preference expression extraction from negotia-
tion dialogues. We propose a new annotation schema for preferences and dependencies among
them and illustrate on two different corpus genres. We then suggest a learning approach that
efﬁciently extracts preference expressions using a combination of local and discursive features
and assess the reliability of our approach on each corpus genre.

MOTS-CLES : Préférence, dialogue, apprentissage automatique.

KEYWORDS: Preference, dialogue, machine learning.

1 Introduction

Modéliser les préférences est incontournable dans de nombreux problémes de la vie courante,
que ce soit pour la prise de décision individuelle ou collective (Arora et Allenby, 1999), les
interactions stratégiques entre agents (Brainov, 2000) ou la théorie des jeux (Hausman, 2000).
Un apergu des travaux sur les préférences en Intelligence Artiﬁcielle est donné par Kaci (2011).

Une préférence est généralement déﬁnie comme un ordre donné par un agent sur différentes
options. Les options dépendent du domaine : elles peuvent étre des vols d’avions, des voitures,
des horaires et lieux de rendez-vous, etc. Ifordonnancement des préférences peut étre total
(strict ou non), rendant chaque paire d’options comparable, ou partiel, quand certaines options
ne peuvent pas étre comparées par un agent donné. Parmi ces options, certaines sont acceptables
pour l’agent, c’est-‘a-dire qu’il est prét a agir pour les réaliser, et d’autres ne le sont pas. Parmi
les options acceptables, l’agent en préfére généralement certaines par rapport aux autres.

Il est important de différencier les notions de préférence et d’opinion. Alors que les opinions
sont un point de Vue, un sentiment ou un jugement qu’un agent peut avoir sur un objet ou une
personne, les préférences, comme nous les avons déﬁnies, impliquent un ordre de la part de

Actes de la conférence onjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 343-350,
Grenoble, 4 au 8 juin 2012. ©2012 ATAI.A 8: AFCP

343

l’agent et sont ainsi relationnelles et comparatives. Les opinions concernent donc un jugement
absolu sur des objets ou des personnes (positif, négatif ou neutre), tandis que les préférences
concernent un jugement relatif sur des options, les préférant, ou non, aux autres. Par exemple,
Ce film n’est pas mauvais exprime une opinion directe positive sur un ﬁlm mais nous ne savons
pas si ce ﬁlm est le « plus » préféré. J’aimerais aller au cinéma. Allons voir Madagascar 2 ex-
prime deux préférences, l’une dépendant de l’autre. Ia premiere est que l’auteur préfere aller
au cinéma par rapport aux autres actions alternatives; la seconde est qu’étant donnée cette
préférence, il préfere aller voir Madagascar 2 plutot que les autres ﬁlms possibles.

Traiter les préférences n’est pas aisé. Tout d’abord, il est nécessaire de connaitre au moins par-
tiellement l’ensemble des options sur lesquelles portent les préférences. Ensuite, il faut pouvoir
déﬁnir un ordre a priori sur les options acceptables mais ce n’est pas toujours trivial. De plus,
donner un ordre entre deux options (appareils photos) peut étre difﬁcile a cause de la néces-
sité de tenir compte des compromis et des interdépendances entre les différents criteres (durée
de vie de la batterie, poids, etc.). Ensuite, les utilisateurs manquent souvent d’informations
completes sur leurs préférences initiales qui tendent a changer au cours du temps. En effet, les
utilisateurs peuvent apprendre du domaine, des préférences des autres et méme de leurs propres
préférences au cours du processus de prise de décision. Plusieurs méthodes ont été proposées
en Intelligence Artiﬁcielle pour éliciter les préférences (Chen et Pu, 2004). Cependant, a notre
connaissance, aucun travail ne montre comment les préférences pourraient étre déterminées a
par11'r de dialogues en utilisant une approche linguistique.

I.’approche que nous proposons a pour but d’étudier le role du discours pour extraire et raisonner
sur les préférences. Notre approche comporte trois étapes :

1. Extraire les options. I.’objectif est de repérer, au sein de chaque segment de discours, les
expressions linguistiques sur lesquelles portent les préférences d’un agent.

2. Identifier les éventuelles dépendances entre les options extraites a l’e’tape 1 en utilisant un en-
semble d’ope’rateurs .me’cifiques. Ces dépendances nous permettent d’inférer les préférences
de l’agent et d’identiﬁer, étant données deux options, leur ordonnancement.

3. Proposer une description formelle des pre’fe’renoes de chaque agent. Nous étudions comment
les relations de discours permettent de suivre l’évolut1'on des préférences au cours du dia-
logue. Cette description se fait en utilisant une représentation compacte des préférences,
les CP-nets (Conditional Preference Networks) (Boutilier et aL, 2004).

Une description détaillée de ces étapes est donnée dans (Cadilhac et al., 2011). Ie travail pré-
senté ici est un premier pas vers l’automatisat1'on de ce processus en se focalisant sur la premiere
étape. Nous analysons comment les préférences sont exprimées linguistiquement, c’est-a-dire
comment les options et les dépendances sont lexicalisées. Nous montrons comment les options
peuvent étre extraites automatiquement grace a un algorithme d’apprentissage supervisé utili-
sant des traits locaux et discursifs et nous évaluons la ﬁabilité de notre approche.

2 Données

Nos données viennent de deux corpus. Ie premier corpus, Verbmobil, est composé de 35
dialogues choisis au hasard dans le corpus Verbmobil déja existant (Wahlster, 2000), dans
lequel deux agents discutent pour ﬁxer la date et le lieu d’un rendez-vous. II a été utilisé
pour créer la liste des traits d’apprentissage. Le second corpus, Réservations, a été utilisé
pour évaluer a quel point notre méthode est dépendante du domaine. II a été const1uit a par-
tir de plusieurs ressources d’apprentissage de l’anglais disponibles sur Internet (par exemple,
www.bbc.co.uk/worldservice/learningenglish). Il contient 21 dialogues choisis au hasard, dans

344

lesquels un agent, le client, appelle un service pour réserver une chambre, un vol d’avion, un
taxi, etc. En voici un exemple typique :

7:1 A : Northwind Airways, good morning. May I help you ?

7:2 B : Yes, do you have any ﬂights to Sydney next Tuesday afternoon ?

7:3 A : Yes, there's a ﬂight at 16:45 and one at 18:00.

in, A : Economy, business class or ﬁrst class ticket ?

7:5 B : Economy, please.

Aﬁn d’analyser comment les options et les dépendances sont exprimées linguistiquement dans
les dialogues de négociation, nous avons réalisé une annotation a deux niveaux : d’abord, au ni-
veau du discours, séparant le texte en segments (les 71,- ci-dessus) liés entre eux par des relations
rhétoriques; puis, au niveau des préférences exprimées dans chaque segment.

2.1 Annotation du discours

les dialogues sont structurés par des tours de parole qui permettent a chaque agent de partici-
per au dialogue. Un agent peut, par exemple, répondre aux questions d’autres agents, poser ses
propres questions, etc. Dans chacun de ces tours, les agents s’engagent sur leurs croyances et
préférences. En général, les modéles formels de dialogue n’explicitent pas le lien entre les énon-
cés et les préférences (voir, par exemple, (Ginzburg, 2012)). Il est alors nécessaire d’avoir, d’une
part, une méthode qui permet une extraction partielle des préférences et de leurs dépendances
et, d’autre part, une méthode qui permet d’exploiter cette description partielle aﬁn d’identiﬁer
l’ensemble des options préférées.

Notre approche exploite la structure du discours selon la Théorie des Représentations Segmen-
tées du Discours, SDRT (Asher et Lascarides, 2003) oil des unités discursives (UD) sont liées
entre elles par des relations rhétoriques telles que Paire Question-Réponse (QAP), Plan-Correction
(P-Corr), etc. Bien que le probléme d’extraction de la structure du discours reste redoutable, on
peut approximer ces relations relativement bien en utilisant des caractéristiques qui peuvent
facilement étre obtenues automatiquement (par exemple, Baldridge et Lascarides (2005b) réa-
lisent un F-score d’environ 69,2%). Notre étude montre ici l’importance des caractéristiques
du discours pour l’extraction de préférences, en supposant que celles-ci sont données par un
oracle. Pour Verbmobil, nous avons utilisé l’annotation de Baldridge et Lascarides (2005a).
Pour Réservat ions, l’annotation a été faite par consensus en utilisant le méme ensemble de
relations rhétoriques qui a été utilisé pour annoter Verbmobil.

2.2 Annotation des préférences

Notre objectif est d’analyser comment les préférences sont linguistiquement exprimées dans des
segments de dialogues. Deux étapes sont nécessaires : (i) identiﬁer l’ensemble O des options
(des termes) sur lesquelles portent les préférences d’un agent, (ii) identiﬁer les éventuelles dé-
pendances entre les éléments de 0 en utilisant un ensemble d’opérateurs spéciﬁques, c’est-‘a-dire
identiﬁer les préférences de l’agent parmi les options énoncées. Par exemple, dans Rencontrons
nous lundi ou mardi, nous avons O = {lundi, mardi} o1‘1les options sont linguistiquement re-
liées par la conjonction ou qui signiﬁe que l’agent est prét a réaliser une de ces options, les
préférant de maniére égale.

Dans une UD, les préférences peuvent étre exprimées de différentes maniéres. Elles peuvent étre
atomiques, par exemple, « Je veux X » ou « Je préfére X » o1‘1 « X » est une option acceptable.
Cette option peut étre un groupe nominal (lundi), un groupe prépositionnel (61 mon bureau)
ou un groupe verbal (se rencontrer). Les préférences peuvent aussi étre exprimées dans des
constructions comparatives et/ou superlatives (un vol moins cher). Elles sont aussi exprimées

345

d’une maniére indirecte en utilisant des questions. Bien que toutes les questions n’impliquent pas
que l’auteur s’engage sur une préférence, dans beaucoup de cas elles le font. C’est-a-dire si un
agent demande Pouvons-nous nous rencontrer la semaine prochaine ?, il implique une préférence
pour se rencontrer. Des expressions de sentiment ou de politesse peuvent aussi étre utilisées
pour introduire indirectement des préférences. Dans Réservat ions, le segment Economique,
s’il vous plaft indique que l’agent préfére étre dans la classe économique.

Ies expressions de préférences peuvent aussi étre complexes, exprimant des négations, conjonc-
tions, disjonctions, ou dépendances. Nous associons a chacune de ces expressions des opérateurs
spéciﬁques (non-booléens), que nous désignons respectivement par not, 8:, or et -—>. Ies réalisa-
tions linguistiques de ces opérateurs nous seront utiles dans la phase d’extractions des options
(voir section 3). Ies négations indiquent ce que l’agent ne préfére pas, c’est-‘a-dire que l’option
exprimée est non-préférée. Ia négation peut étre explicite, comme dans Je ne veux pas qu’on
se rencontre vendredi, ou inférée a partir du contexte, comme dans Je suis occupe’ mardi. Un
exemple de conjonction entre préférences est Pourrais-je avoir un petit déjeuner et un repas ve’-
gétarien ? o1‘1 l’agent exprime deux préférences qu’i1 souhaite satisfaire et il aimerait en avoir
au moins une des deux s’il ne peut pas les avoir toutes. Ia sémantique des disjonctions est une
modalité de choix libre. Par exemple, Je suis libre lundi ou mardi signiﬁe que lundi ou mardi
est un jour possible pour se rencontrer et que l’agent est indifférent entre les deux. Finalement,
certaines UD expriment des engagements sur des préférences dépendantes. Par exemple, dans
la phrase Pourquoi pas lundi, dans l’aprés-midi ?, il y a deux préférences : une pour le jour lundi
et, étant donné la préférence pour lundi, une pour la période de l’aprés-midi (au moins pour
une des interprétations syntaxiques du segment).

Pour chaque UD, nous avons demandé a deux annotateurs d’identiﬁer comment les options sont
exprimées et ensuite d’indiquer comment les préférences sur ces options sont liées entre elles
en utilisant les opérateurs spéciﬁques not, 8:, or et -—>. Nous donnons ci-dessous un exemple de
comment certains segments sont annotés. < o >_i indique que o est l’option numéro i dans le
segment, et le symbole // est utilisé pour séparer les deux niveaux d’annotation. Une description
détaillée de ce schéma d’annotation est donnée dans (Cadilhac et al., 2012).

rrl : Je suis libre <21 quat1'e>_1 ou <cinq heures>_2 <ces jours—1a>_3. // 3 -—> (1 or 2)

7:2 : <Mardi 16>_1,j’ai séminaire <de 9h 21 midi>_2. // 1 -—> not 2

En utilisant le coefﬁcient Kappa de Cohen, nous avons calculé deux taux d’accord inter-
annotateurs sur l’identiﬁcation des options. I.’un est basé sur un accord exact o1‘1 deux anno-
tations (c’est-a-dire, les unités de texte correspondant a une option) doivent correspondre exac-
tement pour étre considérées comme correctes. L’autre est basé sur un accord souple o1‘1 deux
annotations correspondent s’il y a un chevauchement entre leurs unités de texte (comme pour 2
heures et environ 2 heures). Nous avons obtenu un accord exact de 0,66 et un accord souple de
0,85. I.’accord souple étant bon pour Verbmobil, nous avons décidé d’annoter Réservat ions
par consensus.

Ie gold standard pour les deux corpus a été construit aprés discussion des cas de désaccord.
Nous avons observé quatre cas. (1) Le premier concerne 1a redondanoe des préférences et nous
avons décidé de ne pas garder les préférences redondantes dans le gold standard. En effet, les
agents répétent souvent des préférences qui ont déja été établies, comme dans l’exemple suivant,
711 A : jeudi, vendredi et samedi je ne suis pas la. 712 A : Ces 3 jours ne sont pas possibles pour moi,
o1‘1 nous avons Resultat(7r1, 712). (2) 1e second cas de désaccord vient des préférences qui sont
exprimées par des anaphores. Nous avons décidé de les annoter dans le gold standard car elles
sont souvent utilisées dans les corpus pour introduire ou préciser des préférences. Comme dans

346

l’exemple suivant, 711 A :A 2 heures, le 1 7 ? 712 B : C’estparfait, o1‘1 nous avons Q-Elab(7r1, 7:2). (3)
Le troisiéme cas de désaccord concerne Pexplication de pre’fe’renoe. Dans le gold standard, nous
avons choisi de ne pas annoter les expressions qui sont utilisées pour expliquer des préférences
déja établies. Comme dans l’exemple suivant, 711 A : pas lundi, 712 A : j’ai un cours de 9 a 12
heures, o1‘1 nous avons Explication(7r1, 7:2). (4) Finalement, le dernier cas de désaccord provient
des préférences qui ne sont pas directement liées a l’action de ﬁxer une date pour le rendez-vous
mais plutot a d’autres actions comme déjeuner ensemble. Méme si ces préférences ont souvent
été omises par les annotateurs, nous avons décidé de les garder.

3 Extraction des objets de préférences

Ie probléme de l’extraction est de décider si un terme est une option ou non. L’objectif est donc
de classer les termes en deux catégories : Option et Non-option indiquant respectivement que
le terme exprime une option faisant l’objet des préférences, ou non. Nous rappelons que les
options peuvent étre des groupes nominaux, groupes prépositionnels ou groupes verbaux. Nous
devons donc choisir quels groupes de mots doivent étre classés. Dans les données, les agents
négocient pour se mettre d’accord sur une action : se rencontrer un jour donné, réserver un
certain vol, etc. Nous sommes généralement informés de ces actions dans les groupes verbaux.
Cependant, les termes correspondants aux options de préférences sont plutot contenus dans les
groupes nominaux (GN). Par exemple, pour ﬁxer un rendez-vous, la négociation porte sur les
jours et les heures. Pour réserver un hotel, la négociation porte sur des options plus spéciﬁques
comme une chambre double. Il semble donc approprié d’extraire les GN. Pour les classer dans
une des deux classes, nous utilisons deux genres de traits (tous binaires) : les traits locaux et les
traits discursifs. Ie classiﬁeur est basé sur les Machines a Vecteurs de Support.

Ia portée des traits locaux est soit l’unité qui doit étre classée, c’est-‘a-dire le GN, soit le segment
qui contient le GN. Certains de ces traits reposent sur une ontologie qui modélise un calendrier
(date, temps, etc.) inspirée de deux ontologies de haut niveau, SUMO et COSMO. Nous avons
cinq traits au niveau du GN qui testent si le GN contient : le label d’un concept appartenant a
l’ontologie, un comparatif, un superlatif, une disjonction ou une conjonction. Nous avons dix
traits au niveau du segment : (1) le voisin gauche du GN correspond a un label d’un concept
de l’ontologie. Puisque la liste des termes associés a chaque concept de notre ontologie est
courte, ce trait aide a retrouver des lexicalisations supplémentaires; (2) le segment contient
une disjonction ou une conjonction; (3) le GN est dans la portée d’une négation, d’un modal ou
d’un verbe d’action du domaine (se rencontrer, réserver). Ia portée des négations et des modaux
est résolue de maniére simpliﬁée en utilisant l’arbre syntaxique de l’UD ; (4) le segment contient
un mot d’opinion (bon, mauvais, OK, etc.), un mot de politesse ou un mot qui introduit des
préférences (pre’fe’rer, favori, choix, trop, etc.) ; (5) le segment contient une référence a l’autre
agent. Ce trait est un indice pour la classe Non-option. Dans des segments comme 'IiL as dit que tu
n’es pas libre mardi matin ou mercredi aprés-midi ?, l’agent n’apporte pas de nouvelle information

I-\ I

sur les préférences mais répéte seulement ce qui a deja eté établi par l’autre agent.

Nous avons neuf traits au niveau du discours : (1) les relations rhétoriques qui lient l’UD cou-
rante a l’UD précédente et a l’UD suivante impliquent des préférences. Nous avons remarqué
que certaines relations de discours peuvent aider a repérer des segments qui contiennent, ou
non, des préférences. Nous dissocions les relations de discours en trois catégories : (a) celles
qui impliquent « généralement » une Non-option comme Explication, Commentaire, Re’sume', (b)
celles qui impliquent « peut-étre » une Option comme Elaboration, Continuation, Correction et

347

100.0 58.1 28.0 100.0 28.3 1

Baselines

75.2 100.0 3.3

7 41.7

 

OCCUTIEIICES

TABLE 1 — Résultats (pourcentages) pour les trois évaluations.

(c) celles qui impliquent « généralement » une Option. Dans Verbmobil, 86 % des relations
de discours sont de la catégorie (a) alors que 14 % des relations annotées appartiennent a la
catégorie (b). Nous observons la méme tendance pour Réservations. Il n’y a pas d’instances
de la catégorie (c) dans les relations de discours utilisées lors de l’annotation des deux corpus.
Ainsi, nous avons six traits : trois pour tester si la relation entre l’UD courante et l’UD précédente
appartient, ou non, a une des trois catégories, et trois autre pour la relation entre l’UD courante
et l’UD suivante; (2) l’UD courante ou l’UD précédente est une question. Dans nos corpus, les
formes interrogatives ne sont pas toujours suivies par une marque de question. Pour détecter les
questions, nous utilisons donc les relations de discours spéciﬁques, comme QAP, Q-Elab; (3) le
GN apparait au moins deux fois dans le dialogue.

4 Evaluation et Résultats

Plusieurs évaluations sont réalisées pour évaluer la validité de notre méthode d’extraction. Ia
premiere est effectuée sur les 35 dialogues de Verbmobil (CV) pour un total de 1272 UD. Nous
le séparons au hasard en un corpus d’entrainement constitué de 25 dialogues, soit 2374 GN, et
un corpus de test de 10 dialogues, soit 700 GN. Dans la seconde (CR), le classiﬁeur est entrainé
sur 15 dialogues de Réservations, soit 837 GN et testé sur 6 dialogues pris au hasard, soit
312 GN. les 21 dialogues de ce deuxiéme corpus comportent au total 348 UD. Pour la troi-
siéme, le classiﬁeur est évalué en utilisant Verbmobil pour l’entrainement (les 35 dialogues)
et Réservations pour le test (les 21 dialogues) (CV + CR). Cette derniére évaluation, plutét
inhabituelle, est supposée aider a déterminer si notre méthode permet l’entrainement sur un cor-
pus plus grand et disponible et le test sur un corpus plus petit et parfois d’un domaine différent.
Pour toutes ces évaluations, nous utilisons le logiciel SVM-light (http ://svmlight.joachims.org).

Nous comparons les résultats du classiﬁeur avec ceux de trois baselines : la premiere classe
tous les GN dans la catégorie Option, la seconde classe dans la catégorie Option tous les GN
qui contiennent un concept appartenant a l’ontologie, et la troisiéme baseline est une version
simpliﬁée de notre classiﬁeur qui utilise seulement un sous-ensemble de nos traits (nous enle-
vons les traits basés sur l’ontologie ainsi que tous les traits basés sur les relations de discours).
Ia table 1 présente les résultats, sous forme de précision (P), rappel (R) et F-mesure (F). Elle
montre d’abord les résultats des baselines. Nous développons ensuite notre modéle en considé-
rant les traits locaux au niveau du GN, puis nous ajoutons les traits locaux au niveau du segment
et ajoutons progressivement les traits au niveau du discours (l’ajout des traits est symbolisé par
le signe +). Ia derniére ligne présente le résultat ﬁnal, obtenu en utilisant tous les traits.

348

Les résultats dans la table 1 montrent que, parmi les trois baselines, la seconde donne les
meilleurs résultats pour Verbmobil. Ceci était attendu puisque l’ontologie a été construite
pour ces données. Cependant, cette baseline ne permet pas de retrouver toutes les options car
certains GN qui contiennent des concepts de l’ontologie ne sont pas des options (ce sont des
répétitions, des commentaires, etc.) et bien s1"1r toutes les options exprimées par les agents ne
sont pas couvertes par les concepts de l’ontologie. Pour Réservat ions, l’ontologie dégrade le
rappel par rapport a la premiere baseline, puisqu’il y a un faible recouvrement entre les concepts
dans l’ontologie et ceux dans le corpus. Il en va de méme pour la troisiéme évaluation (CV + CR).
Cependant, ce n’est pas un probléme critique puisque des ontologies adaptées sont également
disponibles pour le domaine touristique. Dans tous les cas, la troisiéme baseline donne des ré-
sultats assez stables, toujours meilleurs que ceux de la premiere baseline et, dans les deuxiéme
et troisiéme évaluations (pour lesquelles nous n’avons pas utilisé d’ontologie adaptée), ces résul-
tats sont également meilleurs que ceux de la deuxiéme baseline. Le classiﬁeur donne un meilleur
rappel pour la troisiéme évaluation que pour la deuxiéme. Cela peut montrer un probléme de
rareté des données lors de l’entrainement uniquement sur Réservations (conﬁguration (CR)).

les évaluations montrent que notre méthode a une tendance similaire sur Verbmobil et
Réservat ions. Nous voyons que les traits locaux au niveau du GN sont pertinents pour obtenir
une bonne précision. les traits au niveau du segment et les traits discursifs améliorent le rappel
et la F-mesure dans les trois conﬁgurations. L’amélioration est mieux marquée dans les deuxiéme
et troisiéme évaluations. Peut-étre parce que l’ontologie, moins bien adaptée pour ces évalua-
tions, a moins d’impact sur les performances. Finalement, pour Verbmobil, nous obtenons une
F-mesure de 86,8 %, i.e. presque 20 % au-dessus de la troisiéme baseline (classiﬁeur simpliﬁé)
et plus de 10 % au-dessus de la deuxiéme baseline (basée sur l’ontologie). Pour Réservations,
nous obtenons une F-mesure de 64,8 %, i.e. plus de 10 % au dessus du classiﬁeur simpliﬁé. Pour
la troisiéme évaluation, les résultats ne montrent pas d’amélioration par rapport aux baselines.
C’est probablement d1"1 a l’inﬂuence de l’ontologie qui adapte mieux les vecteurs de support au
corpus d’entrainement (Verbmobil), les rendant moins pertinents pour le corpus de test. En
désactivant les deux traits basés sur l’ontologie, nous obtenons 50,2 % de précision, 62,9 % de
rappel et 55,8 % de F-mesure, soit une amélioration par rapport aux baselines.

Pour les traits discursifs, nous remarquons que, pour Verbmobil, les relations rhétoriques entre
l’UD courante et l’UD précédente apportent plus d’amélioration que les autres informations
discursives. Cela peut s’expliquer par la nature du corpus, o1‘1le contexte (exprimé dans les tours
de dialogues précédents) est important. Pour Réservat ions, le trait qui teste si l’UD courante
ou l’UD précédente sont des questions apporte la meilleure amélioration des performances car
ce corpus contient principalement des paires question-réponse. Pour la troisiéme évaluation,
les traits discursifs n’apportent pas d’amélioration importante par rapport aux baselines. C’est
peut-étre causé par l’incapacité des informations discursives a compenser les différences entre
les données d’entrainement et de test : en effet, en principe, il y a plus d’instances des traits
locaux (au niveau du GN et du segment) associées a des cas positifs, que d’instances des traits
discursifs associées a des cas positifs. Et quand le classiﬁeur est entrainé sur des traits extraits
d’un domaine de corpus et testé sur un autre domaine, le poids des traits discursifs peut ne pas
sufﬁre a compenser les autres traits, locaux.

Dans ces trois conﬁgurations, le trait testant la présence d’un GN au moins deux fois dans le
dialogue apporte une amélioration conséquente par rapport aux autres. C’était plut6t attendu
puisqu’en principe la fréquence d’un GN apporte de l’information sur le sujet principal, et cela a
du sens, puisque les agents ont tendance a exprimer des préférences sur le sujet de la discussion.

349

5 Conclusion et futurs travaux

Nous avons présenté une méthode linguistique pour l’extraction des expressions de préférence
dans des dialogues de négociation. Nous avons d’abord proposé un schéma d’annotation pour
étudier comment les préférences sont exprimées dans des dialogues dans deux domaines diffé-
rents. Nous avons ensuite proposé une méthode d’apprentissage qui extrait les expressions de
préférence des dialogues en utilisant une combinaison de traits locaux et discursifs. les résul-
tats montrent que la structure discursive couplée avec une ontologie est utile pour extraire les
expressions de préférence de maniére efﬁcace. Dans nos futurs travaux, nous voulons évaluer
la méthode sur des corpus plus grands et variés, pour vériﬁer sa pertinence et sa robustesse sur
différents domaines de conversation et registres de discours. Pour le moment, la méthode de
classiﬁcation traite uniquement des GN. Ceci est justiﬁé pour les corpus sur lesquels nous avons
travaillé mais nous devons étudier s’il est toujours pertinent d’uti1iser uniquement des GN pour
d’autres corpus et, si nécessaire, étendre la méthode a d’autres types de syntagmes. Ce travail
d’extraction des expressions de préférence est, nous le rappelons, la premiere étape d’un proces-
sus plus complexe d’élicitation des préférences (Cadilhac et al., 2011) qui sera complétement
automatisé aﬁn de l’appliquer a des cas pratiques de négociation et marchandage.

les auteurs remercient le projet STAC ERC Grant n°269427.

Références

ARORA, N. et ALLENBY, G. M. (1999). Measuring the inﬂuence of individual preference struc-
tures in group decision making. Journal of Marketing Research, 36:476-487.
ASHER, N. et LASCARIDES, A. (2003). Logic; of Conversation. Cambridge University Press.

BALDRIDGE, J. et LASCARIDES, A. (2005a). Annotating discourse structures for robust semantic
interpretation. In Proceedings of the 6th IWCS.

BALDRIDGE, J. et LASCARIDES, A. (2005b). Probabilistic head-driven parsing for discourse struc-
ture. In Proceedings of CoNI.L.

BOUTILIER, C., BRAFMAN, C., DOMSHLAK, C., Hoos, H. H. et PooLE, D. (2004). Cp-nets : A tool
for representing and reasoning with conditional ceteris paribus preference statements. Journal
ofArtificial Intelligence Research, 21:135-191.

BRAINOV, S. (2000). The role and the impact of preferences on multiagent interaction. In
Proceedings ofATAL, pages 349-363. Springer-Verlag.

CADILHAC, A., ASHER, N., BENAMARA, F. et LASCARIDES, A. (2011). Commitments to preferences
in dialogue. In Proceedings of SIGDIAL, pages 204-215. ACL.

CADILHAC, A., BENAMARA, F. et ASHER, N. (2012). Annotating preferences in negotiation dia-
logues. A paraitre.

CHEN, L. et PU, P. (2004). Survey of preference elicitation methods. Rapport technique.

GINZBURG, J. (2012). The Interactive Stance : Meaning for Conversation. Oxford University
Press.

HAUSMAN, D. M. (2000). Revealed preference, belief, and game theory. Economics and Philoso-
phy, 16(01):99-115.
KAc1, S. (2011). Working with Preferences : Less Is More. Cognitive Technologies. Springer.

WAHLSTER, W., éditeur (2000). Verbmobil : Foundations of Speech-to-Speech Translation. Sprin-
ger.

350

