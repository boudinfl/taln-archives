Actes de la conférence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 343–350,
Grenoble, 4 au 8 juin 2012. c©2012 ATALA & AFCP
Extraction de préférences à partir de dialogues de négociation
Anaïs Cadilhac Farah Benamara Vladimir Popescu Nicholas Asher
Mohamadou Seck
IRIT, 118, Route de Narbonne, 31062 Toulouse Cedex 9
{adilha, benamara, popesu, asher, sek}irit.fr
RÉSUMÉ
Cet article présente une approche linguistique pour l’extraction d’expressions de préférence à
partir de dialogues de négociation. Nous proposons un nouveau schéma d’annotation pour enco-
der les préférences et les dépendances exprimées linguistiquement dans deux genres de corpus
différents. Ensuite, nous proposons une méthode d’apprentissage qui extrait les expressions de
préférence en utilisant une combinaison de traits locaux et discursifs. Finalement, nous évaluons
la fiabilité de notre approche sur chaque genre de corpus.
ABSTRACT
Towards Preference Extraction From Negotiation Dialogues
This paper presents an NLP based approach for preference expression extraction from negotia-
tion dialogues. We propose a new annotation schema for preferences and dependencies among
them and illustrate on two different corpus genres. We then suggest a learning approach that
efficiently extracts preference expressions using a combination of local and discursive features
and assess the reliability of our approach on each corpus genre.
MOTS-CLÉS : Préférence, dialogue, apprentissage automatique.
KEYWORDS: Preference, dialogue, machine learning.
1 Introduction
Modéliser les préférences est incontournable dans de nombreux problèmes de la vie courante,
que ce soit pour la prise de décision individuelle ou collective (Arora et Allenby, 1999), les
interactions stratégiques entre agents (Brainov, 2000) ou la théorie des jeux (Hausman, 2000).
Un aperçu des travaux sur les préférences en Intelligence Artificielle est donné par Kaci (2011).
Une préférence est généralement définie comme un ordre donné par un agent sur différentes
options. Les options dépendent du domaine : elles peuvent être des vols d’avions, des voitures,
des horaires et lieux de rendez-vous, etc. L’ordonnancement des préférences peut être total
(strict ou non), rendant chaque paire d’options comparable, ou partiel, quand certaines options
ne peuvent pas être comparées par un agent donné. Parmi ces options, certaines sont acceptables
pour l’agent, c’est-à-dire qu’il est prêt à agir pour les réaliser, et d’autres ne le sont pas. Parmi
les options acceptables, l’agent en préfère généralement certaines par rapport aux autres.
Il est important de différencier les notions de préférence et d’opinion. Alors que les opinions
sont un point de vue, un sentiment ou un jugement qu’un agent peut avoir sur un objet ou une
personne, les préférences, comme nous les avons définies, impliquent un ordre de la part de
343
l’agent et sont ainsi relationnelles et comparatives. Les opinions concernent donc un jugement
absolu sur des objets ou des personnes (positif, négatif ou neutre), tandis que les préférences
concernent un jugement relatif sur des options, les préférant, ou non, aux autres. Par exemple,
Ce film n’est pas mauvais exprime une opinion directe positive sur un film mais nous ne savons
pas si ce film est le « plus » préféré. J’aimerais aller au cinéma. Allons voir Madagascar 2 ex-
prime deux préférences, l’une dépendant de l’autre. La première est que l’auteur préfère aller
au cinéma par rapport aux autres actions alternatives ; la seconde est qu’étant donnée cette
préférence, il préfère aller voir Madagascar 2 plutôt que les autres films possibles.
Traiter les préférences n’est pas aisé. Tout d’abord, il est nécessaire de connaître au moins par-
tiellement l’ensemble des options sur lesquelles portent les préférences. Ensuite, il faut pouvoir
définir un ordre a priori sur les options acceptables mais ce n’est pas toujours trivial. De plus,
donner un ordre entre deux options (appareils photos) peut être difficile à cause de la néces-
sité de tenir compte des compromis et des interdépendances entre les différents critères (durée
de vie de la batterie, poids, etc.). Ensuite, les utilisateurs manquent souvent d’informations
complètes sur leurs préférences initiales qui tendent à changer au cours du temps. En effet, les
utilisateurs peuvent apprendre du domaine, des préférences des autres et même de leurs propres
préférences au cours du processus de prise de décision. Plusieurs méthodes ont été proposées
en Intelligence Artificielle pour éliciter les préférences (Chen et Pu, 2004). Cependant, à notre
connaissance, aucun travail ne montre comment les préférences pourraient être déterminées à
partir de dialogues en utilisant une approche linguistique.
L’approche que nous proposons a pour but d’étudier le rôle du discours pour extraire et raisonner
sur les préférences. Notre approche comporte trois étapes :
1. Extraire les options. L’objectif est de repérer, au sein de chaque segment de discours, les
expressions linguistiques sur lesquelles portent les préférences d’un agent.
2. Identifier les éventuelles dépendances entre les options extraites à l’étape 1 en utilisant un en-
semble d’opérateurs spécifiques. Ces dépendances nous permettent d’inférer les préférences
de l’agent et d’identifier, étant données deux options, leur ordonnancement.
3. Proposer une description formelle des préférences de chaque agent. Nous étudions comment
les relations de discours permettent de suivre l’évolution des préférences au cours du dia-
logue. Cette description se fait en utilisant une représentation compacte des préférences,
les CP-nets (Conditional Preference Networks) (Boutilier et al., 2004).
Une description détaillée de ces étapes est donnée dans (Cadilhac et al., 2011). Le travail pré-
senté ici est un premier pas vers l’automatisation de ce processus en se focalisant sur la première
étape. Nous analysons comment les préférences sont exprimées linguistiquement, c’est-à-dire
comment les options et les dépendances sont lexicalisées. Nous montrons comment les options
peuvent être extraites automatiquement grâce à un algorithme d’apprentissage supervisé utili-
sant des traits locaux et discursifs et nous évaluons la fiabilité de notre approche.
2 Données
Nos données viennent de deux corpus. Le premier corpus, Verbmobil, est composé de 35
dialogues choisis au hasard dans le corpus Verbmobil déjà existant (Wahlster, 2000), dans
lequel deux agents discutent pour fixer la date et le lieu d’un rendez-vous. Il a été utilisé
pour créer la liste des traits d’apprentissage. Le second corpus, Réservations, a été utilisé
pour évaluer à quel point notre méthode est dépendante du domaine. Il a été construit à par-
tir de plusieurs ressources d’apprentissage de l’anglais disponibles sur Internet (par exemple,
www.bbc.co.uk/worldservice/learningenglish). Il contient 21 dialogues choisis au hasard, dans
344
lesquels un agent, le client, appelle un service pour réserver une chambre, un vol d’avion, un
taxi, etc. En voici un exemple typique :
pi1 A : Northwind Airways, good morning. May I help you ?
pi2 B : Yes, do you have any flights to Sydney next Tuesday afternoon ?
pi3 A : Yes, there’s a flight at 16:45 and one at 18:00.
pi4 A : Economy, business class or first class ticket ?
pi5 B : Economy, please.
Afin d’analyser comment les options et les dépendances sont exprimées linguistiquement dans
les dialogues de négociation, nous avons réalisé une annotation à deux niveaux : d’abord, au ni-
veau du discours, séparant le texte en segments (les pii ci-dessus) liés entre eux par des relations
rhétoriques ; puis, au niveau des préférences exprimées dans chaque segment.
2.1 Annotation du discours
Les dialogues sont structurés par des tours de parole qui permettent à chaque agent de partici-
per au dialogue. Un agent peut, par exemple, répondre aux questions d’autres agents, poser ses
propres questions, etc. Dans chacun de ces tours, les agents s’engagent sur leurs croyances et
préférences. En général, les modèles formels de dialogue n’explicitent pas le lien entre les énon-
cés et les préférences (voir, par exemple, (Ginzburg, 2012)). Il est alors nécessaire d’avoir, d’une
part, une méthode qui permet une extraction partielle des préférences et de leurs dépendances
et, d’autre part, une méthode qui permet d’exploiter cette description partielle afin d’identifier
l’ensemble des options préférées.
Notre approche exploite la structure du discours selon la Théorie des Représentations Segmen-
tées du Discours, SDRT (Asher et Lascarides, 2003) où des unités discursives (UD) sont liées
entre elles par des relations rhétoriques telles que Paire Question-Réponse (QAP), Plan-Correction
(P-Corr), etc. Bien que le problème d’extraction de la structure du discours reste redoutable, on
peut approximer ces relations relativement bien en utilisant des caractéristiques qui peuvent
facilement être obtenues automatiquement (par exemple, Baldridge et Lascarides (2005b) réa-
lisent un F-score d’environ 69,2%). Notre étude montre ici l’importance des caractéristiques
du discours pour l’extraction de préférences, en supposant que celles-ci sont données par un
oracle. Pour Verbmobil, nous avons utilisé l’annotation de Baldridge et Lascarides (2005a).
Pour Réservations, l’annotation a été faite par consensus en utilisant le même ensemble de
relations rhétoriques qui a été utilisé pour annoter Verbmobil.
2.2 Annotation des préférences
Notre objectif est d’analyser comment les préférences sont linguistiquement exprimées dans des
segments de dialogues. Deux étapes sont nécessaires : (i) identifier l’ensemble O des options
(des termes) sur lesquelles portent les préférences d’un agent, (ii) identifier les éventuelles dé-
pendances entre les éléments de O en utilisant un ensemble d’opérateurs spécifiques, c’est-à-dire
identifier les préférences de l’agent parmi les options énoncées. Par exemple, dans Rencontrons
nous lundi ou mardi, nous avons O = {lundi, mardi} où les options sont linguistiquement re-
liées par la conjonction ou qui signifie que l’agent est prêt à réaliser une de ces options, les
préférant de manière égale.
Dans une UD, les préférences peuvent être exprimées de différentes manières. Elles peuvent être
atomiques, par exemple, « Je veux X » ou « Je préfère X » où « X » est une option acceptable.
Cette option peut être un groupe nominal (lundi), un groupe prépositionnel (à mon bureau)
ou un groupe verbal (se rencontrer). Les préférences peuvent aussi être exprimées dans des
constructions comparatives et/ou superlatives (un vol moins cher). Elles sont aussi exprimées
345
d’une manière indirecte en utilisant des questions. Bien que toutes les questions n’impliquent pas
que l’auteur s’engage sur une préférence, dans beaucoup de cas elles le font. C’est-à-dire si un
agent demande Pouvons-nous nous rencontrer la semaine prochaine ?, il implique une préférence
pour se rencontrer. Des expressions de sentiment ou de politesse peuvent aussi être utilisées
pour introduire indirectement des préférences. Dans Réservations, le segment Economique,
s’il vous plaît indique que l’agent préfère être dans la classe économique.
Les expressions de préférences peuvent aussi être complexes, exprimant des négations, conjonc-
tions, disjonctions, ou dépendances. Nous associons à chacune de ces expressions des opérateurs
spécifiques (non-booléens), que nous désignons respectivement par not, &, or et 7?. Les réalisa-
tions linguistiques de ces opérateurs nous seront utiles dans la phase d’extractions des options
(voir section 3). Les négations indiquent ce que l’agent ne préfère pas, c’est-à-dire que l’option
exprimée est non-préférée. La négation peut être explicite, comme dans Je ne veux pas qu’on
se rencontre vendredi, ou inférée à partir du contexte, comme dans Je suis occupé mardi. Un
exemple de conjonction entre préférences est Pourrais-je avoir un petit déjeuner et un repas vé-
gétarien ? où l’agent exprime deux préférences qu’il souhaite satisfaire et il aimerait en avoir
au moins une des deux s’il ne peut pas les avoir toutes. La sémantique des disjonctions est une
modalité de choix libre. Par exemple, Je suis libre lundi ou mardi signifie que lundi ou mardi
est un jour possible pour se rencontrer et que l’agent est indifférent entre les deux. Finalement,
certaines UD expriment des engagements sur des préférences dépendantes. Par exemple, dans
la phrase Pourquoi pas lundi, dans l’après-midi ?, il y a deux préférences : une pour le jour lundi
et, étant donné la préférence pour lundi, une pour la période de l’après-midi (au moins pour
une des interprétations syntaxiques du segment).
Pour chaque UD, nous avons demandé à deux annotateurs d’identifier comment les options sont
exprimées et ensuite d’indiquer comment les préférences sur ces options sont liées entre elles
en utilisant les opérateurs spécifiques not, &, or et 7?. Nous donnons ci-dessous un exemple de
comment certains segments sont annotés. < o >_i indique que o est l’option numéro i dans le
segment, et le symbole // est utilisé pour séparer les deux niveaux d’annotation. Une description
détaillée de ce schéma d’annotation est donnée dans (Cadilhac et al., 2012).
pi1 : Je suis libre <à quatre>_1 ou <cinq heures>_2 <ces jours-là>_3. // 3 7? (1 or 2)
pi2 : <Mardi 16>_1, j’ai séminaire <de 9h à midi>_2. // 1 7? not 2
En utilisant le coefficient Kappa de Cohen, nous avons calculé deux taux d’accord inter-
annotateurs sur l’identification des options. L’un est basé sur un accord exact où deux anno-
tations (c’est-à-dire, les unités de texte correspondant à une option) doivent correspondre exac-
tement pour être considérées comme correctes. L’autre est basé sur un accord souple où deux
annotations correspondent s’il y a un chevauchement entre leurs unités de texte (comme pour 2
heures et environ 2 heures). Nous avons obtenu un accord exact de 0,66 et un accord souple de
0,85. L’accord souple étant bon pour Verbmobil, nous avons décidé d’annoter Réservations
par consensus.
Le gold standard pour les deux corpus a été construit après discussion des cas de désaccord.
Nous avons observé quatre cas. (1) Le premier concerne la redondance des préférences et nous
avons décidé de ne pas garder les préférences redondantes dans le gold standard. En effet, les
agents répètent souvent des préférences qui ont déjà été établies, comme dans l’exemple suivant,
pi1 A : jeudi, vendredi et samedi je ne suis pas là. pi2 A : Ces 3 jours ne sont pas possibles pour moi,
où nous avons Resultat(pi1, pi2). (2) Le second cas de désaccord vient des préférences qui sont
exprimées par des anaphores. Nous avons décidé de les annoter dans le gold standard car elles
sont souvent utilisées dans les corpus pour introduire ou préciser des préférences. Comme dans
346
l’exemple suivant, pi1 A : A 2 heures, le 17 ? pi2 B : C’est parfait, où nous avons Q-Elab(pi1, pi2). (3)
Le troisième cas de désaccord concerne l’explication de préférence. Dans le gold standard, nous
avons choisi de ne pas annoter les expressions qui sont utilisées pour expliquer des préférences
déjà établies. Comme dans l’exemple suivant, pi1 A : pas lundi, pi2 A : j’ai un cours de 9 à 12
heures, où nous avons Explication(pi1, pi2). (4) Finalement, le dernier cas de désaccord provient
des préférences qui ne sont pas directement liées à l’action de fixer une date pour le rendez-vous
mais plutôt à d’autres actions comme déjeuner ensemble. Même si ces préférences ont souvent
été omises par les annotateurs, nous avons décidé de les garder.
3 Extraction des objets de préférences
Le problème de l’extraction est de décider si un terme est une option ou non. L’objectif est donc
de classer les termes en deux catégories : Option et Non-option indiquant respectivement que
le terme exprime une option faisant l’objet des préférences, ou non. Nous rappelons que les
options peuvent être des groupes nominaux, groupes prépositionnels ou groupes verbaux. Nous
devons donc choisir quels groupes de mots doivent être classés. Dans les données, les agents
négocient pour se mettre d’accord sur une action : se rencontrer un jour donné, réserver un
certain vol, etc. Nous sommes généralement informés de ces actions dans les groupes verbaux.
Cependant, les termes correspondants aux options de préférences sont plutôt contenus dans les
groupes nominaux (GN). Par exemple, pour fixer un rendez-vous, la négociation porte sur les
jours et les heures. Pour réserver un hôtel, la négociation porte sur des options plus spécifiques
comme une chambre double. Il semble donc approprié d’extraire les GN. Pour les classer dans
une des deux classes, nous utilisons deux genres de traits (tous binaires) : les traits locaux et les
traits discursifs. Le classifieur est basé sur les Machines à Vecteurs de Support.
La portée des traits locaux est soit l’unité qui doit être classée, c’est-à-dire le GN, soit le segment
qui contient le GN. Certains de ces traits reposent sur une ontologie qui modélise un calendrier
(date, temps, etc.) inspirée de deux ontologies de haut niveau, SUMO et COSMO. Nous avons
cinq traits au niveau du GN qui testent si le GN contient : le label d’un concept appartenant à
l’ontologie, un comparatif, un superlatif, une disjonction ou une conjonction. Nous avons dix
traits au niveau du segment : (1) le voisin gauche du GN correspond à un label d’un concept
de l’ontologie. Puisque la liste des termes associés à chaque concept de notre ontologie est
courte, ce trait aide à retrouver des lexicalisations supplémentaires ; (2) le segment contient
une disjonction ou une conjonction ; (3) le GN est dans la portée d’une négation, d’un modal ou
d’un verbe d’action du domaine (se rencontrer, réserver). La portée des négations et des modaux
est résolue de manière simplifiée en utilisant l’arbre syntaxique de l’UD ; (4) le segment contient
un mot d’opinion (bon, mauvais, OK, etc.), un mot de politesse ou un mot qui introduit des
préférences (préférer, favori, choix, trop, etc.) ; (5) le segment contient une référence à l’autre
agent. Ce trait est un indice pour la classe Non-option. Dans des segments comme Tu as dit que tu
n’es pas libre mardi matin ou mercredi après-midi ?, l’agent n’apporte pas de nouvelle information
sur les préférences mais répète seulement ce qui a déjà été établi par l’autre agent.
Nous avons neuf traits au niveau du discours : (1) les relations rhétoriques qui lient l’UD cou-
rante à l’UD précédente et à l’UD suivante impliquent des préférences. Nous avons remarqué
que certaines relations de discours peuvent aider à repérer des segments qui contiennent, ou
non, des préférences. Nous dissocions les relations de discours en trois catégories : (a) celles
qui impliquent « généralement » une Non-option comme Explication, Commentaire, Résumé, (b)
celles qui impliquent « peut-être » une Option comme Elaboration, Continuation, Correction et
347
CV CR CV + CR
P R F P R F P R F
Tous les GN 40.9 100.0 58.1 28.0 100.0 43.8 28.3 100.0 44.1
Baselines Ontologie seule 95.6 61.3 74.7 55.6 16.7 25.7 49.2 13.5 21.2
Classifieur simplifié 65.2 71.1 68.0 68.4 43.3 53.1 43.9 55.7 49.1
Traits Tous les traits (GN) 95.7 62.0 75.2 100.0 3.3 6.5 50.7 16.0 24.4
Locaux + Tous les traits (Segment) 94.1 78.9 85.8 68.4 43.3 53.1 60.2 26.2 36.5
+ Relation Précédente 94.9 78.9 86.2 67.6 41.7 51.6 60.2 26.2 36.5
Traits + Relation Suivante 94.0 77.5 84.9 66.7 40.0 50.0 59.4 25.3 35.5
Discursifs + Questions 95.6 75.4 84.3 79.0 50.0 61.2 59.4 25.3 35.5
+ ≥ 2 occurrences du GN 90.8 83.1 86.8 75.6 56.7 64.8 62.9 32.9 43.2
TABLE 1 – Résultats (pourcentages) pour les trois évaluations.
(c) celles qui impliquent « généralement » une Option. Dans Verbmobil, 86 % des relations
de discours sont de la catégorie (a) alors que 14 % des relations annotées appartiennent à la
catégorie (b). Nous observons la même tendance pour Réservations. Il n’y a pas d’instances
de la catégorie (c) dans les relations de discours utilisées lors de l’annotation des deux corpus.
Ainsi, nous avons six traits : trois pour tester si la relation entre l’UD courante et l’UD précédente
appartient, ou non, à une des trois catégories, et trois autre pour la relation entre l’UD courante
et l’UD suivante ; (2) l’UD courante ou l’UD précédente est une question. Dans nos corpus, les
formes interrogatives ne sont pas toujours suivies par une marque de question. Pour détecter les
questions, nous utilisons donc les relations de discours spécifiques, comme QAP, Q-Elab ; (3) le
GN apparaît au moins deux fois dans le dialogue.
4 Evaluation et Résultats
Plusieurs évaluations sont réalisées pour évaluer la validité de notre méthode d’extraction. La
première est effectuée sur les 35 dialogues de Verbmobil (CV ) pour un total de 1272 UD. Nous
le séparons au hasard en un corpus d’entraînement constitué de 25 dialogues, soit 2374 GN, et
un corpus de test de 10 dialogues, soit 700 GN. Dans la seconde (CR), le classifieur est entraîné
sur 15 dialogues de Réservations, soit 837 GN et testé sur 6 dialogues pris au hasard, soit
312 GN. Les 21 dialogues de ce deuxième corpus comportent au total 348 UD. Pour la troi-
sième, le classifieur est évalué en utilisant Verbmobil pour l’entraînement (les 35 dialogues)
et Réservations pour le test (les 21 dialogues) (CV + CR). Cette dernière évaluation, plutôt
inhabituelle, est supposée aider à déterminer si notre méthode permet l’entrainement sur un cor-
pus plus grand et disponible et le test sur un corpus plus petit et parfois d’un domaine différent.
Pour toutes ces évaluations, nous utilisons le logiciel SVM-light (http ://svmlight.joachims.org).
Nous comparons les résultats du classifieur avec ceux de trois baselines : la première classe
tous les GN dans la catégorie Option, la seconde classe dans la catégorie Option tous les GN
qui contiennent un concept appartenant à l’ontologie, et la troisième baseline est une version
simplifiée de notre classifieur qui utilise seulement un sous-ensemble de nos traits (nous enle-
vons les traits basés sur l’ontologie ainsi que tous les traits basés sur les relations de discours).
La table 1 présente les résultats, sous forme de précision (P), rappel (R) et F-mesure (F). Elle
montre d’abord les résultats des baselines. Nous développons ensuite notre modèle en considé-
rant les traits locaux au niveau du GN, puis nous ajoutons les traits locaux au niveau du segment
et ajoutons progressivement les traits au niveau du discours (l’ajout des traits est symbolisé par
le signe +). La dernière ligne présente le résultat final, obtenu en utilisant tous les traits.
348
Les résultats dans la table 1 montrent que, parmi les trois baselines, la seconde donne les
meilleurs résultats pour Verbmobil. Ceci était attendu puisque l’ontologie a été construite
pour ces données. Cependant, cette baseline ne permet pas de retrouver toutes les options car
certains GN qui contiennent des concepts de l’ontologie ne sont pas des options (ce sont des
répétitions, des commentaires, etc.) et bien sûr toutes les options exprimées par les agents ne
sont pas couvertes par les concepts de l’ontologie. Pour Réservations, l’ontologie dégrade le
rappel par rapport à la première baseline, puisqu’il y a un faible recouvrement entre les concepts
dans l’ontologie et ceux dans le corpus. Il en va de même pour la troisième évaluation (CV + CR).
Cependant, ce n’est pas un problème critique puisque des ontologies adaptées sont également
disponibles pour le domaine touristique. Dans tous les cas, la troisième baseline donne des ré-
sultats assez stables, toujours meilleurs que ceux de la première baseline et, dans les deuxième
et troisième évaluations (pour lesquelles nous n’avons pas utilisé d’ontologie adaptée), ces résul-
tats sont également meilleurs que ceux de la deuxième baseline. Le classifieur donne un meilleur
rappel pour la troisième évaluation que pour la deuxième. Cela peut montrer un problème de
rareté des données lors de l’entrainement uniquement sur Réservations (configuration (CR)).
Les évaluations montrent que notre méthode a une tendance similaire sur Verbmobil et
Réservations. Nous voyons que les traits locaux au niveau du GN sont pertinents pour obtenir
une bonne précision. Les traits au niveau du segment et les traits discursifs améliorent le rappel
et la F-mesure dans les trois configurations. L’amélioration est mieux marquée dans les deuxième
et troisième évaluations. Peut-être parce que l’ontologie, moins bien adaptée pour ces évalua-
tions, a moins d’impact sur les performances. Finalement, pour Verbmobil, nous obtenons une
F-mesure de 86,8 %, i.e. presque 20 % au-dessus de la troisième baseline (classifieur simplifié)
et plus de 10 % au-dessus de la deuxième baseline (basée sur l’ontologie). Pour Réservations,
nous obtenons une F-mesure de 64,8 %, i.e. plus de 10 % au dessus du classifieur simplifié. Pour
la troisième évaluation, les résultats ne montrent pas d’amélioration par rapport aux baselines.
C’est probablement dû à l’influence de l’ontologie qui adapte mieux les vecteurs de support au
corpus d’entrainement (Verbmobil), les rendant moins pertinents pour le corpus de test. En
désactivant les deux traits basés sur l’ontologie, nous obtenons 50,2 % de précision, 62,9 % de
rappel et 55,8 % de F-mesure, soit une amélioration par rapport aux baselines.
Pour les traits discursifs, nous remarquons que, pour Verbmobil, les relations rhétoriques entre
l’UD courante et l’UD précédente apportent plus d’amélioration que les autres informations
discursives. Cela peut s’expliquer par la nature du corpus, où le contexte (exprimé dans les tours
de dialogues précédents) est important. Pour Réservations, le trait qui teste si l’UD courante
ou l’UD précédente sont des questions apporte la meilleure amélioration des performances car
ce corpus contient principalement des paires question-réponse. Pour la troisième évaluation,
les traits discursifs n’apportent pas d’amélioration importante par rapport aux baselines. C’est
peut-être causé par l’incapacité des informations discursives à compenser les différences entre
les données d’entrainement et de test : en effet, en principe, il y a plus d’instances des traits
locaux (au niveau du GN et du segment) associées à des cas positifs, que d’instances des traits
discursifs associées à des cas positifs. Et quand le classifieur est entrainé sur des traits extraits
d’un domaine de corpus et testé sur un autre domaine, le poids des traits discursifs peut ne pas
suffire à compenser les autres traits, locaux.
Dans ces trois configurations, le trait testant la présence d’un GN au moins deux fois dans le
dialogue apporte une amélioration conséquente par rapport aux autres. C’était plutôt attendu
puisqu’en principe la fréquence d’un GN apporte de l’information sur le sujet principal, et cela a
du sens, puisque les agents ont tendance à exprimer des préférences sur le sujet de la discussion.
349
5 Conclusion et futurs travaux
Nous avons présenté une méthode linguistique pour l’extraction des expressions de préférence
dans des dialogues de négociation. Nous avons d’abord proposé un schéma d’annotation pour
étudier comment les préférences sont exprimées dans des dialogues dans deux domaines diffé-
rents. Nous avons ensuite proposé une méthode d’apprentissage qui extrait les expressions de
préférence des dialogues en utilisant une combinaison de traits locaux et discursifs. Les résul-
tats montrent que la structure discursive couplée avec une ontologie est utile pour extraire les
expressions de préférence de manière efficace. Dans nos futurs travaux, nous voulons évaluer
la méthode sur des corpus plus grands et variés, pour vérifier sa pertinence et sa robustesse sur
différents domaines de conversation et registres de discours. Pour le moment, la méthode de
classification traite uniquement des GN. Ceci est justifié pour les corpus sur lesquels nous avons
travaillé mais nous devons étudier s’il est toujours pertinent d’utiliser uniquement des GN pour
d’autres corpus et, si nécessaire, étendre la méthode à d’autres types de syntagmes. Ce travail
d’extraction des expressions de préférence est, nous le rappelons, la première étape d’un proces-
sus plus complexe d’élicitation des préférences (Cadilhac et al., 2011) qui sera complètement
automatisé afin de l’appliquer à des cas pratiques de négociation et marchandage.
Les auteurs remercient le projet STAC ERC Grant n˚ 269427.
Références
ARORA, N. et ALLENBY, G. M. (1999). Measuring the influence of individual preference struc-
tures in group decision making. Journal of Marketing Research, 36:476–487.
ASHER, N. et LASCARIDES, A. (2003). Logics of Conversation. Cambridge University Press.
BALDRIDGE, J. et LASCARIDES, A. (2005a). Annotating discourse structures for robust semantic
interpretation. In Proceedings of the 6th IWCS.
BALDRIDGE, J. et LASCARIDES, A. (2005b). Probabilistic head-driven parsing for discourse struc-
ture. In Proceedings of CoNLL.
BOUTILIER, C., BRAFMAN, C., DOMSHLAK, C., HOOS, H. H. et POOLE, D. (2004). Cp-nets : A tool
for representing and reasoning with conditional ceteris paribus preference statements. Journal
of Artificial Intelligence Research, 21:135–191.
BRAINOV, S. (2000). The role and the impact of preferences on multiagent interaction. In
Proceedings of ATAL, pages 349–363. Springer-Verlag.
CADILHAC, A., ASHER, N., BENAMARA, F. et LASCARIDES, A. (2011). Commitments to preferences
in dialogue. In Proceedings of SIGDIAL, pages 204–215. ACL.
CADILHAC, A., BENAMARA, F. et ASHER, N. (2012). Annotating preferences in negotiation dia-
logues. À paraître.
CHEN, L. et PU, P. (2004). Survey of preference elicitation methods. Rapport technique.
GINZBURG, J. (2012). The Interactive Stance : Meaning for Conversation. Oxford University
Press.
HAUSMAN, D. M. (2000). Revealed preference, belief, and game theory. Economics and Philoso-
phy, 16(01):99–115.
KACI, S. (2011). Working with Preferences : Less Is More. Cognitive Technologies. Springer.
WAHLSTER, W., éditeur (2000). Verbmobil : Foundations of Speech-to-Speech Translation. Sprin-
ger.
350
