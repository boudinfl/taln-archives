<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Sur l'application de m&#233;thodes textom&#233;triques &#224; la construction de crit&#232;res de classification en analyse des sentiments</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 367&#8211;374,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Sur l'application de m&#233;thodes textom&#233;triques &#224; la construction de crit&#232;res de classi!cation en analyse des sentiments
Egle Eensoo  Mathieu Valette
</p>
<p>INALCO, ERTIM, 2 rue de Lille, 75343 Paris Cedex 07
{prenom.nom}@inalco.fr
</p>
<p>R&#201;SUM&#201;____________________________________________________________________________________________________________
Depuis  une dizaine d'ann&#233;es,  le  TAL s'int&#233;resse  &#224; la  subjectivit&#233;,  notamment dans la 
perspective d'applications telles que la fouille d'opinion et l'analyse des sentiments. Or, la 
linguistique de corpus outill&#233;e par des m&#233;thodes textom&#233;triques a souvent abord&#233; la 
question de la subjectivit&#233; dans les textes. Notre objectif est de montrer d'une part, ce 
que pourrait apporter &#224; l'analyse des sentiments l'analyse textom&#233;trique et d'autre part, 
comment mutualiser les avantages d'une association entre celle-ci et une m&#233;thode de 
classi!cation automatique bas&#233;e sur l'apprentissage supervis&#233;. En nous appuyant sur un 
corpus de t&#233;moignages issus de forums de discussion, nous montrerons que la prise en 
compte de crit&#232;res s&#233;lectionn&#233;s suivant une analyse textom&#233;trique permet d'obtenir des 
r&#233;sultats de classi!cation satisfaisants par rapport &#224; une vision purement lexicale.
ABSTRACT__________________________________________________________________________________________________________
About the application of textometric methods for developing classi!cation criteria 
in Sentiment analysis 
Over  the  last  ten  years,  NLP  has  contributed  to  applied  research  on  subjectivity, 
especially  in  applications such as  Opinion mining  and Sentiment  analysis.  However, 
corpus linguistics and textometry have often addressed the issue of subjectivity in text. 
Our  purpose  is  to  show,  !rst,  what  textometric  analysis  could  bring  to  sentiment 
analysis,  and  second,  the  bene!ts  of  pooling  linguistic/textometric  analysis  and 
automatic classi!cation methods based on supervised learning. By processing a corpus of 
posts from fora, we will show that the building of criteria from a textometric analysis 
could improve classi!cation results, compared to a purely lexical approach.
MOTS-CL&#201;S : linguistique  de  corpus,  textom&#233;trie,  analyse  de  sentiments,  classi!cation 
automatique supervis&#233;e. 
KEYWORDS : corpus linguistics, textometry, sentiment analysis, supervised learning.
</p>
<p>1 Introduction
L&#8217;extraction d&#8217;information subjective (Pang et Lee, 2008) est depuis une dizaine d&#8217;ann&#233;es 
un vaste domaine d&#8217;applications en croissance r&#233;guli&#232;re. Malgr&#233; quelques travaux (par 
exemple Vernier, 2009 ; B&#233;chet et al., 2008) le savoir-faire linguistique y est peu sollicit&#233;. 
La subjectivit&#233; a pourtant fait l&#8217;objet de nombreux travaux linguistiques, dans di#&#233;rents 
courants th&#233;oriques &#8211; linguistique de l&#8217;&#233;nonciation, analyse de discours, s&#233;mantique des 
textes. La textom&#233;trie, aux con!ns de la linguistique g&#233;n&#233;rale et du TAL, propose par 
ailleurs  une  archive  int&#233;ressante  de  travaux  sur  corpus  susceptibles  d&#8217;int&#233;resser  les 
</p>
<p>367</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>applications d'analyse des sentiments (AS).  On songe, dans le discours politique, aux 
travaux de (Salem, 1993), dans les sondages d'opinion, &#224; (Lebart et Salem, 1988) ou dans 
la litt&#233;rature, &#224; (Brunet, 2009).
On souhaiterait ici susciter une rencontre entre d&#8217;une part le TAL ing&#233;nierique et ses 
applications  et,  d&#8217;autre  part,  la  textom&#233;trie,  &#224;  partir  des  constats  suivants :  (1) 
l'&#233;valuation des m&#233;thodes en TAL repose sur un ensemble restreint de mesures (telles que 
pr&#233;cision, rappel, f-mesure) qui ont pour but de v&#233;ri!er la qualit&#233; des m&#233;thodes plus que 
de  valider  des  hypoth&#232;ses  et  des  m&#233;thodologies  linguistiques.  Leurs  r&#233;sultats  ne 
n&#233;cessitent pas d'interpr&#233;tation pour &#234;tre valides ; (2) la textom&#233;trie rel&#232;ve, au contraire, 
d&#8217;une  tradition  descriptive.  Elle  se  focalise  sur  l&#8217;interpr&#233;tation  des  r&#233;sultats  de 
traitements  statistiques,  davantage  que  sur  l&#8217;am&#233;lioration  desdits  traitements.  &#192;  la 
di#&#233;rence du TAL, l&#8217;&#233;valuation n'est pas un enjeu en textom&#233;trie1. 
Notre projet repose sur l&#8217;hypoth&#232;se que la textom&#233;trie, discipline descriptive, est &#224; m&#234;me 
d&#8217;apporter des solutions m&#233;thodologiques pour les applications g&#233;n&#233;ralement d&#233;volues 
au  TAL.  Nous  tenterons  d&#8217;&#233;valuer  l'apport  potentiel  de  la  conjonction  d'une  analyse 
textom&#233;trique et de m&#233;thodes d'apprentissage pour une application d'AS.
</p>
<p>2 &#201;tat de l'art
La  cat&#233;gorisation  des  textes,  qu&#8217;elle  soit  bipolaire  (positif/n&#233;gatif)  ou  multiclasse 
(mauvais/bon/excellent),  est  l'application  principale  en  extraction  d&#8217;information 
subjective. Elle peut &#234;tre r&#233;alis&#233;e au moyen d'algorithmes ad hoc (Turney, 2002 ; Snyder 
et Barzilay, 2007) ou des m&#233;thodes d'apprentissage comme Naive Bayes, Support Vector 
Machines,  etc.  (Pang  et  al.,  2002 ;  Mihalcea  et  Liu,  2006),  en  utilisant  des attributs 
di#&#233;rents pour caract&#233;riser les documents. M&#234;me si perdurent d'autres m&#233;thodes &#8211; ayant 
principalement recours &#224; l'utilisation de ressources lexicales, construites  (Kim et Hovy, 
2004)  ou  automatiquement  acquises  (Turney,  2002 ;  Rilo#  et  al.,  2003),  avec  la 
banalisation  des  corpus  annot&#233;s,  les  m&#233;thodes  de  cat&#233;gorisation  bas&#233;es  sur 
l'apprentissage  supervis&#233;  sont  de  plus  en  plus  utilis&#233;es.  Elles  utilisent  diverses 
caract&#233;ristiques textuelles : (i) tous les mots du texte (sac de mots, unigrammes ou n-
grammes)  (Pang  et  al.,  2002 ;  Dave  et  al.  2003) ;  (ii)  la  pr&#233;sence  ou l'absence  d'un 
ensemble  de  mots  d&#233;termin&#233;s ;  (iii)  l'emplacement  de  certains  mots  (Kim  et  Hovy, 
2006) ;  (iv)  certaines  parties  du  discours  seules :  adjectifs  (Kamps  et  Marx,  2002), 
collocations  adverbe-adjectif  (Turney,  2002) ;  substantifs ;  en!n  (v)  les  d&#233;pendances 
syntaxiques (Nakagawa et al., 2010 ; Wi et al., 2009 ; Wiegand et Klakow, 2010). Nous 
nous  inscrivons  donc  pleinement  dans  cette  d&#233;marche  en  proposant  des  crit&#232;res  de 
classi!cation issus d'analyses textom&#233;triques pour servir de base aux divers algorithmes 
d'apprentissage supervis&#233;.
</p>
<p>1 Autrement dit, les &#233;tudes textom&#233;triques ne sont valid&#233;es que par l&#8217;assentiment d&#8217;une communaut&#233; qui, dans 
le meilleur des cas, est distante (par exemple, critique litt&#233;raire, sociologie), mais, dans le pire des cas, n&#8217;est 
peut-&#234;tre qu&#8217;un avatar du jugement d&#8217;acceptabilit&#233; pourtant honni de ladite communaut&#233;.
</p>
<p>368</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3 Pr&#233;sentation du corpus
3.1 Contexte applicatif de l&#8217;&#233;tude
Le corpus est constitu&#233; de 300 textes courts r&#233;unis par SAMESTORY (http://www.same-
story.com),  un  service  d&#8217;agr&#233;gation  d&#8217;ego-documents.  Il  s'agit,  en  l&#8217;occurrence,  de 
t&#233;moignages et r&#233;cits d'histoires v&#233;cues post&#233;s par les internautes sur di#&#233;rents forums 
de discussion (aufeminin.com, doctissimo.fr, etc.). Les cat&#233;gorisations sont multicrit&#232;res : 
th&#233;matiques, tonalit&#233;, conseil  vs demande, sexe de l'&#233;metteur, situation familiale, etc. 
Nous traitons, dans des textes portant sur la sant&#233;, la tonalit&#233; &#171; gai/triste &#187;. De prime 
abord, elle s'apparente &#224; une analyse thymique, mais il s'agit de cat&#233;gories complexes o&#249; 
les ph&#233;nom&#232;nes discursifs (ex : structure du r&#233;cit) interviennent dans la classi!cation 
autant que l'expression linguistique des sentiments. Ainsi, notre t&#226;che est de mod&#233;liser 
l'art de t&#233;moigner d'une histoire v&#233;cue. 
</p>
<p>3.2 Annotation tonale du corpus
L'annotation tonale du corpus a &#233;t&#233; e#ectu&#233;e par SAMESTORY. Nous en avons analys&#233; 
un &#233;chantillon pour en d&#233;duire la strat&#233;gie d'annotation de fa&#231;on &#224; caract&#233;riser plus 
!nement l'opposition binaire gai/triste. Un t&#233;moignage &#171; triste &#187; est (i) une histoire qui 
!nit mal, (ii) un t&#233;moignage exprimant des doutes, des interrogations, ou sollicitant de 
l'aide. Un t&#233;moignage &#171; gai &#187; est (i) une histoire triste qui !nit bien, (ii) un t&#233;moignage 
modulant la gravit&#233; de la situation et soulignant les points positifs (iii) un conseil. 
</p>
<p>4 Description de l&#8217;exp&#233;rience
4.1 &#201;tape  1 :  Choix  des  caract&#233;ristiques  textuelles  au  moyen  des 
</p>
<p>m&#233;thodes textom&#233;triques
Nous  tentons  de  mettre  en  &#233;vidence  les  ph&#233;nom&#232;nes  textuels  qui  di#&#233;rencient  les 
t&#233;moignages  de  nos  deux cat&#233;gories.  Nous  avons  une double  ambition :  trouver  des 
crit&#232;res  de  classi!cation  linguistiquement  explicables  et  su&quot;samment  robustes  pour 
servir de crit&#232;res aux m&#233;thodes d'apprentissage supervis&#233;.  Nous faisons l'hypoth&#232;se que 
les crit&#232;res de classi!cation interpr&#233;tables sont plus performants que les crit&#232;res trouv&#233;s 
par des m&#233;thodes d'apprentissage, souvent non signi!ants d'un point de vue textuel et 
incidents  au  corpus  d'apprentissage  (ex :  pr&#233;sence  de  fautes  d'orthographe  non 
pertinentes  par  rapport  aux  cat&#233;gories  de  classi!cation).  Ainsi,  lors  de  l'&#233;tape  de 
s&#233;lection de crit&#232;res, l'analyste &#233;carte les crit&#232;res li&#233;s &#224; l'&#233;chantillon du corpus et choisit 
les crit&#232;res textuels coh&#233;rents avec les composantes textuelles (th&#233;matique, dialogique, 
etc. cf. &#167; 5) actualis&#233;es dans le corpus. Pour l'exp&#233;rience, nous avons utilis&#233; trois types de 
crit&#232;res :  (i)  crit&#232;res  unitaires :  un  choix  de  formes,  lemmes  ou  cat&#233;gories 
morphosyntaxiques ; (ii) crit&#232;res composites adjacents (n-grammes) ; (iii) cooccurrences 
multiniveaux (combinant les &#233;l&#233;ments de di#&#233;rents niveaux de description linguistique : 
formes, lemmes ou cat&#233;gories morphosyntaxiques).  Tous les crit&#232;res sont s&#233;lectionn&#233;s 
selon 4 principes : leur caract&#232;re sp&#233;ci!que &#224; un sous-corpus, leur r&#233;partition uniforme 
dans le sous-corpus, leur fr&#233;quence et leur pertinence linguistique. 
L'analyse du corpus et  l'extraction des crit&#232;res  ont  &#233;t&#233; e#ectu&#233;es avec deux logiciels 
</p>
<p>369</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>textom&#233;triques  &#8211;  Lexico3  (Salem  et  al. 2003)  et  TXM  (Heiden  et  al. 2010)  &#8211;  qui 
impl&#233;mentent les algorithmes de sp&#233;ci!cit&#233;s (Lafon, 1980) et de cooccurrences (Lafon, 
1981). Nous avons choisi les deux premiers types de crit&#232;res selon le proc&#233;d&#233; suivant :
</p>
<p>1. calcul  des  sp&#233;ci!cit&#233;s  des  items  isol&#233;s  (formes,  lemmes  et  cat&#233;gories 
morphosyntaxiques)  et  de  leur  n-grammes (fonction &#171; Segments  R&#233;p&#233;t&#233;s &#187;  de 
Lexico 3) pour chaque sous-corpus (gai/triste) ;
</p>
<p>2. analyse  des  contextes  d'apparition  des  items  sp&#233;ci!ques  (au  moyen  de 
concordances  textuelles)  a!n  de  s'assurer  de  leur  pertinence  textuelle  et  de 
l'unicit&#233; de leur fonction (les crit&#232;res ayant une seule fonction et signi!cation ont 
&#233;t&#233; privil&#233;gi&#233;s) ;
</p>
<p>3. v&#233;ri!cation  de  la  r&#233;partition  uniforme  des  items  dans  le  sous-corpus 
(fonctionnalit&#233; &#171; Carte de Sections &#187; du Lexico 3) ;
</p>
<p>La s&#233;lection des cooccurrences s'est fait comme suit :
1. calcul  des  cooccurrences  (fonction  &#171; Cooccurrences &#187;  de  TXM)  des  items 
</p>
<p>sp&#233;ci!ques fr&#233;quents et uniform&#233;ment repartis sur la totalit&#233; du corpus ;
2. analyse des contextes d'apparition de ces cooccurrences ;
3. s&#233;lection des cooccurrences sp&#233;ci!ques &#224; un sous-corpus ;
</p>
<p>Dans les deux cas, les crit&#232;res de classi!cation pour chaque texte sont des fr&#233;quences ou 
des valeurs bool&#233;ennes (pr&#233;sence/absence) des items s&#233;lectionn&#233;s.
</p>
<p>4.2 &#201;tape 2 : Classi!cation
La deuxi&#232;me &#233;tape consiste  &#224; utiliser  des algorithmes d'apprentissage supervis&#233; pour 
classer les textes.  En utilisant Weka2,  nous en avons exp&#233;riment&#233; trois,  chacun d'une 
famille di#&#233;rente : les arbres de d&#233;cision (J48 ;  Quinlan, 1993), Naive Bayes (John et 
Langley, 1995) et les Machines &#224; Vecteurs de Support (SMO ; Platt, 1998). L'objectif est 
d'observer les  di#&#233;rences et similitudes au niveau des performances en changeant la 
nature et la quantit&#233; des crit&#232;res.
Le corpus contient 300 textes &#233;quitablement r&#233;partis entres les  deux cat&#233;gories (147 
&#171; gaies &#187; et 153 &#171; tristes &#187;). L'&#233;valuation a &#233;t&#233; e#ectu&#233;e avec la m&#233;thode de validation 
crois&#233;e sur cinq parties.
</p>
<p>&#8226; Exp&#233;rimentation  1.1 :  premi&#232;re  exp&#233;rimentation  avec  des  mots  simples  sans 
aucune  modi!cation  (avec  pour  valeur  leur  fr&#233;quence  dans  un  texte) ;  on 
consid&#232;re ces r&#233;sultats comme la base de comparaison  (baseline)  pour d'autres 
exp&#233;rimentations.  La  base  de  comparaison  est  donc  l'exp&#233;rimentation  qui 
n&#233;cessite  l'e#ort  computationnel  minimal sur  les  textes  en  consid&#233;rant  ces 
derniers  comme  un  mat&#233;riau  brut,  directement  accessible  (au  moyen  d'une 
segmentation  en  mots).  Toutes  les  autres  exp&#233;rimentations  e#ectuent  des 
traitements  suppl&#233;mentaires  sur  les  textes  visant &#224;  am&#233;liorer  les  r&#233;sultats. 
L'&#233;valuation a &#233;t&#233; e#ectu&#233;e avec la validation crois&#233;e sur 5 parties du corpus.
</p>
<p>2 http://www.cs.waikato.ac.nz/ml/weka/
</p>
<p>370</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#8226; Exp&#233;rimentation 1.2 : A la place des mots, nous avons utilis&#233;s leurs lemmes (casse 
normalis&#233;e).
</p>
<p>&#8226; Exp&#233;rimentation 1.3 : Utilisation des n-grammes de mots (longueur maximale 3).
Dans la s&#233;rie des exp&#233;rimentations 2, nous avons utilis&#233; les crit&#232;res &#233;labor&#233;s selon la 
m&#233;thodologie d&#233;crite dans la partie pr&#233;c&#233;dente. 
</p>
<p>&#8226; Exp&#233;rimentation 2.1 :  Utilisation  de crit&#232;res unitaires et  de crit&#232;res composites 
adjacents pour un total de 30 crit&#232;res.
</p>
<p>&#8226; Exp&#233;rimentation  2.2 :  Ajout  de  crit&#232;res  cooccurrentiels  et  augmentation  du 
nombre (total : 46 crit&#232;res). 
</p>
<p>&#8226; Exp&#233;rimentation 2.3 : Augmentation du nombre de crit&#232;res (total : 61 crit&#232;res). 
</p>
<p>5 R&#233;sultat et discussion
Type d'attributs Algorithme de 
</p>
<p>classi!cation
% des textes 
bien cat&#233;goris&#233;s
</p>
<p>1.1. Mots simples (1200 crit&#232;res) J48 53
Naive Bayes 63
SMO 70
</p>
<p>1.2. Lemmes (370 crit&#232;res) J48 55
Naive Bayes 63
SMO 64
</p>
<p>1.3 N-grammes de mots (1357 crit&#232;res) J48 56
Naive Bayes 64
SMO 74
</p>
<p>2.1. Crit&#232;res textom&#233;triques (30 crit&#232;res) J48 67
Naive Bayes 64
SMO 65
</p>
<p>2.2. Crit&#232;res textom&#233;triques (43 crit&#232;res) J48 62
Naive Bayes 72
SMO 72
</p>
<p>2.3. Crit&#232;res textom&#233;triques (61 crit&#232;res) J48 70
Naive Bayes 74
SMO 77
</p>
<p>TABLE 1 &#8211; R&#233;sultat des exp&#233;rimentations
Comme  dans  des  exp&#233;riences  similaires  (Pang  et  al.,  2002),  on  constate  que  la 
</p>
<p>371</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>classi!cation  sur  les  mots  simples  et  les  n-grammes  permet  d'obtenir  des  r&#233;sultats 
convenables  compte  tenu de  la  di&quot;cult&#233;  de  la  t&#226;che.  N&#233;anmoins,  cela  constitue  un 
plafond  que  l'on  ne  peut  d&#233;passer.  La  g&#233;n&#233;ralisation  des  crit&#232;res  apport&#233;e  par  la 
lemmatisation ne permet pas d'am&#233;liorer les r&#233;sultats. Ce ph&#233;nom&#232;ne a fait l'objet de 
nombreux d&#233;bats dans la communaut&#233; textom&#233;trique (par exemple Mellet, 2003).
A la di#&#233;rence de la premi&#232;re s&#233;rie d'exp&#233;rimentations, nos crit&#232;res textom&#233;triques sont 
peu nombreux mais ils constituent une base facilement extensible. L'ajout des crit&#232;res 
augmente  syst&#233;matiquement  les  performances  de  Naive  Bayes  et  SMO.  Ainsi,  nous 
observons  une  progression  sensible  sur  l'ensemble  des  algorithmes.  Notre  meilleur 
r&#233;sultat (avec SMO) d&#233;passe de 7 points celui obtenu avec des mots simples et de 3 
points celui des n-grammes. Par ailleurs, l'am&#233;lioration des r&#233;sultats pour J48 et Naive 
Bayes est syst&#233;matique.
L'interpr&#233;tation des  r&#233;sultats chi#r&#233;s et des crit&#232;res obtenus  participe selon nous de la 
validation de l'exp&#233;rimentation et en constitue une valeur ajout&#233;e. Ainsi,  nous avons 
organis&#233; nos crit&#232;res selon une typologie inspir&#233;e de travaux s&#233;miotiques. Les crit&#232;res 
thymiques  (Court&#232;s,  1991),  qui  rel&#232;vent  d'une  lecture  axiologique  des  textes,  sont 
essentiellement dysphoriques et concernent donc les textes tristes :  &#171; avoir peur &#187;,  &#171; je  
sou&quot;re &#187;, &#171; douleur &#187;,  &#171; stress &#187;. Le seul crit&#232;re thymique retenu pour la classi!cation des 
textes gai est  &#171; heureux &#187;  (euphorique). Au-del&#224; des crit&#232;res thymiques courants, nous 
nous sommes int&#233;ress&#233;s &#224; ceux relatifs &#224; des composantes textuelles (Rastier, 2001) parce 
que, ne relevant pas de typologies axiologiques classiques (positif/n&#233;gatif) (Charaudeau, 
1992),  ils  sont  rarement  pris  en  compte  en AS.  La  composante  dialectique  concerne 
l'organisation lin&#233;aire et temporelle du r&#233;cit. Ces crit&#232;res, dans les textes &#171; gais &#187;, sont 
di#&#233;rents marqueurs de structuration argumentative (&#171; par contre &#187;, &#171; car &#187;) et temporelle 
(&#171; apr&#232;s &#187;,  &#171; puis &#187;)  absents  des  textes  &#171; tristes &#187;.  Dans  ceux-ci,  la  structuration  est 
cumulative (&#171; en plus &#187;, &#171; de nouveau &#187;) ou indice d'incertitude (&#171; ne pas arriver &#224; &#187;, &#171; avoir  
l'impression de &#187;). La composante  dialogique est relative au positionnement des acteurs. 
Elle  met  en  &#339;uvre  un  fort  contraste  entre  les  textes  &#171; gais &#187;,  o&#249;  le  destinateur-
&#233;nonciateur s'adresse explicitement &#224; un &#171; tu &#187; destinataire actualis&#233; par des pronoms de 
2&#232;me personne  (pronoms personnel,  possessifs,  etc.),  relate  une exp&#233;rience  &#233;di!ante 
(&#171; mon exp&#233;rience &#187;,  &#171; pour  ma part &#187;)  et  prodigue des  conseils  (pr&#233;sence  d'hyperliens 
&#171; www &#187;) et des encouragements (&#171; bon courage &#187;) sans pour autant mettre en avant un je. 
Les  t&#233;moignages  &#171; tristes &#187;  mettent  en  texte  un  &#171; je &#187; massif.  En!n,  la  composante 
th&#233;matique n'a pas &#233;t&#233; n&#233;glig&#233;e mais nous nous sommes e#orc&#233;s de ne s&#233;lectionner que 
des crit&#232;res d'un grand niveau de g&#233;n&#233;ralit&#233; relatifs au domaine de la sant&#233;. Ainsi, aux 
noms de sympt&#244;mes, maladies, traitements ou m&#233;dicaments, nous avons pr&#233;f&#233;r&#233;, pour les 
textes &#171; tristes &#187; :  &#171; urgences &#187;,  &#171; h&#244;pital &#187;,  &#171; rendez-vous &#187;,  &#171; analyses &#187;,  &#171; m&#233;decins &#187;, ou la 
locution  &#171; &#234;tre  atteint  de &#187;.  Pour  les  textes  &#171; gais &#187; :  &#171; r&#233;mission &#187;,  &#171; produit  naturel &#187;, 
&#171; hom&#233;opathie &#187; permettent d'obtenir des r&#233;sultats convaincants.
</p>
<p>6 Conclusion
Il  est  admis  que  les  m&#233;thodes  e&quot;caces  en  classi!cation  th&#233;matique  (par  exemple, 
l'apprentissage  supervis&#233;  sur  mots  simples)  sont  peu  performantes  pour  les  t&#226;ches 
d'analyse de la subjectivit&#233;. La di&quot;cult&#233; r&#233;side dans le fait que la subjectivit&#233; ne rel&#232;ve 
pas seulement du lexique, mais d'autres niveaux de description : organisation temporelle 
</p>
<p>372</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>du  r&#233;cit,  structure  argumentative,  etc.  Nous  avons  propos&#233;  ici  quelques  &#233;l&#233;ments 
d'analyse pour la prise en compte de ces niveaux de description et leur impl&#233;mentation 
pour la classi!cation. Le co&#251;t en temps de notre m&#233;thode d'&#233;laboration de crit&#232;res n'a 
pas &#233;t&#233; quanti!&#233; mais nous estimons qu'il  est  comparable &#224; d'autres  m&#233;thodes semi-
automatiques. Le domaine manquant de m&#233;thodes &#233;prouv&#233;es, notre exp&#233;rience nous a 
permis de mieux comprendre la t&#226;che et sa complexit&#233; et d'esquisser une proposition 
m&#233;thodologique tenant compte d'une caract&#233;risation textuelle de la subjectivit&#233;.
</p>
<p>7 R&#233;f&#233;rences
BRUNET,  &#201;.  (2009).  &#201;crits  choisis, Volume  1,  Comptes  d&#8217;auteurs.  &#201;tudes  statistiques.  De  
Rabelais &#224; Gracq. Textes &#233;dit&#233;s par D. Maya#re, Champion, Paris
B&#201;CHET,  F.,  EL-B&#200;ZE,  M.  et  TORRES-MORENO,  J.-M. (2008).  En !nir  avec la  confusion des 
genres pour mieux s&#233;parer les th&#232;mes Actes de l'atelier de cl&#244;ture de la 4&#232;me &#233;dition du D&#233;!  
Fouille de Texte.
CHARAUDEAU P. (1992). Grammaire du sens et de l&#8217;expression. Hachette Education.
COURT&#200;S,  J.  (1991).  Analyse  s&#233;miotique  du  discours.  De  l'&#233;nonc&#233;  &#224;  l'&#233;nonciation,  Paris, 
Hachette.
DAVE,  K.,  LAWRENCE,  S.,  et PENNOCK,  D.M. (2003).  Mining  the  peanut  gallery:  opinion 
extraction  and  semantic  classi!cation  of  product  reviews.  In  Proceedings  of  the  12th 
international WWW conference, May 20-24, 2003, Budapest, Hungary, pages 519-528.
HEIDEN, S., MAGU&#201;, J-P. et PINCEMIN, B. (2010). TXM : Une plateforme logicielle open-source 
pour la textom&#233;trie &#8211; conception et d&#233;veloppement. In I. C. Sergio Bolasco (Ed.),JADT 
2010, Vol. 2, pages 1021-1032. [logiciel disponible sur http://textometrie.ens-lyon.fr/]
JOHN,  G.  H.  et  LANGLEY,  P.  (1995).  Estimating  Continuous  Distributions  in  Bayesian 
Classi!ers.  Eleventh Conference on Uncertainty in Arti!cial Intelligence, San Mateo, pages 
338-345.
KAMPS, J. et MARX, M. (2002). Words with Attitude. 1st International WordNet Conference, 
pages 332-341.
KIM, S-M. et  HOVY, E. (2004). Determining the sentiment of opinions.Proceedings of the  
20th international conference on Computational  Linguistics (COLING '04).  Association for  
Computational Linguistics, Stroudsburg, PA, USA.
KIM, S.-M. et HOVY, E. (2006). Extracting opinions, opinion holders, and topics expressed 
in  online  news  media  text.  SST  '06:  Proceedings  of  the  Workshop  on  Sentiment  and  
Subjectivity in Text, Association for Computational Linguistics, pages 1-8.
LEBART L. et SALEM A., (1988). Analyse statistique des donn&#233;es textuelles. Questions ouvertes et  
lexicom&#233;trie, Paris, Dunod.
LAFON, P. (1980). Sur la variabilit&#233; de la fr&#233;quence des formes dans un corpus, Mots,  1, 
pages 127-165.
LAFON, P. (1981). Analyse lexicom&#233;trique et recherche des cooccurrences, Mots, 3, pages 
95-148.
</p>
<p>373</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>MELLET,  S.  (2003).  Lemmatisation  et  encodage  grammatical :  un  luxe  inutile ? 
Lexicometrica : Autour de la lemmatisation, Dominique Labb&#233;, &#233;d.
MIHALCEA,  R.  et  LIU,  H.  A (2006).  Corpus-Based Approach to  Finding Happiness  AAAI 
Symposium on Computational Approaches to Analysing Weblogs (AAAI-CAAW).
NAKAGAWA,  T.,  INUI,  K.  et  KUROHASHI,  S.  (2010).  Dependency  Tree-based  Sentiment 
Classi!cation  using  CRFs  with  Hidden  Variables.  Proceedings  of  Human  Language  
Technologies. 
PANG, B.,  LEE, L. et  VAITHYANATHAN, S. (2002). Thumbs up? Sentiment classification using 
machine  learning  techniques.  Proceedings  of  the  Conference  on  Empirical  Methods  in  
Natural Language Processing (EMNLP), pages 79-86.
PANG, B. et LEE, L. (2008). Opinion Mining and Sentiment Analysis, Now Publishers Inc. 
PLATT,  J.  (1998).  Machines using Sequential  Minimal  Optimization.  B.  Schoelkopf,  C. 
Burges and A. Smola, editors, Advances in Kernel Methods - Support Vector Learning.
RASTIER, F. (2001). Arts et sciences du texte, Paris, PUF.
RILOFF,  E.,  WIEBE,  J.  et  WILSON (2003).  T.  Learning  subjective  nouns  using  extraction 
pattern  bootstrapping.  Proceedings  of  the  Conference  on  Natural  Language  Learning  
(CoNLL), pages 25-32.
QUINLAN, R. (1993).  C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers, 
San Mateo, CA.
SALEM, R. (1993). M&#233;thodes de la statistique textuelle, Th&#232;se pour le doctorat d'&#201;tat &#232;s 
lettres et sciences humaines, Universit&#233; de la Sorbonne Nouvelle &#8211; Paris 3, 998 pages.
SALEM A., LAMALLE C., MARTINEZ W., FLEURY S., FRACCHIOLLA B., et al. (2003). Lexico3 &#8211; Outils de 
statistique textuelle. Manuel d&#8217;utilisation. http://www.tal.univ-paris3.fr/lexico/]
SNYDER, B. et BARZILAY, R. (2007). Multiple aspect ranking using the Good Grief algorithm. 
Proceedings of the Joint Human Language Technology/North American Chapter of the ACL  
Conference (HLT-NAACL), pages 300-307.
TURNEY,  P.  (2002).  Thumbs  up  or  thumbs  down?  Semantic  orientation  applied  to 
unsupervised classification of reviews.  Proceedings of the Association for Computational  
Linguistics (ACL), pages 417-424.
VERNIER, M.,  MONCEAUX, l. et  DAILLE, B. (2009). DEFT'09 : d&#233;tection de la subjectivit&#233; et 
cat&#233;gorisation de  textes  subjectifs  par  une  approche  mixte  symbolique  et  statistique 
Actes de l'atelier de cl&#244;ture de la 5&#232;me &#233;dition du D&#233;! Fouille de Textes.
WI, Y.,  ZHANG, Q., Huang, X., et Wu, L. (2009). Phrase Dependency Parsing for Opinion 
Mining. Proceedings of EMNLP-2009, Singapore.
WIEBE,  J.M.,  WILSON,  T.,  BRUCE,  R.,  BELL,  M.  et  MARTIN,  M.  (2004).  Learning subjective 
language. Computational Linguistics, 30(3), pages 277-308.
WIEGAND, M. et  KLAKOW, D. (2010). Convolution Kernels for Opinion Holder Extraction. 
Proceedings of Human Language Technologies: The 2010 Annual Conference of the North  
American Chapter of the ACL, L.A., CA.
</p>
<p>374</p>

</div></div>
</body></html>