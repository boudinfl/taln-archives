Sur l'application de méthodes textométriques à la
construction de critères de classi!cation en analyse des
sentiments
Egle Eensoo Mathieu Valette
INALCO, ERTIM, 2 rue de Lille, 75343 Paris Cedex 07
{prenom.nom}@inalco.fr
RÉSUMÉ____________________________________________________________________________________________________________
Depuis une dizaine d'années, le TAL s'intéresse à la subjectivité, notamment dans la
perspective d'applications telles que la fouille d'opinion et l'analyse des sentiments. Or, la
linguistique de corpus outillée par des méthodes textométriques a souvent abordé la
question de la subjectivité dans les textes. Notre objectif est de montrer d'une part, ce
que pourrait apporter à l'analyse des sentiments l'analyse textométrique et d'autre part,
comment mutualiser les avantages d'une association entre celle-ci et une méthode de
classi!cation automatique basée sur l'apprentissage supervisé. En nous appuyant sur un
corpus de témoignages issus de forums de discussion, nous montrerons que la prise en
compte de critères sélectionnés suivant une analyse textométrique permet d'obtenir des
résultats de classi!cation satisfaisants par rapport à une vision purement lexicale.
ABSTRACT__________________________________________________________________________________________________________
About the application of textometric methods for developing classi!cation criteria
in Sentiment analysis
Over the last ten years, NLP has contributed to applied research on subjectivity,
especially in applications such as Opinion mining and Sentiment analysis. However,
corpus linguistics and textometry have often addressed the issue of subjectivity in text.
Our purpose is to show, !rst, what textometric analysis could bring to sentiment
analysis, and second, the bene!ts of pooling linguistic/textometric analysis and
automatic classi!cation methods based on supervised learning. By processing a corpus of
posts from fora, we will show that the building of criteria from a textometric analysis
could improve classi!cation results, compared to a purely lexical approach.
MOTS-CLÉS : linguistique de corpus, textométrie, analyse de sentiments, classi!cation
automatique supervisée.
KEYWORDS : corpus linguistics, textometry, sentiment analysis, supervised learning.

1     Introduction
L’extraction d’information subjective (Pang et Lee, 2008) est depuis une dizaine d’années
un vaste domaine d’applications en croissance régulière. Malgré quelques travaux (par
exemple Vernier, 2009 ; Béchet et al., 2008) le savoir-faire linguistique y est peu sollicité.
La subjectivité a pourtant fait l’objet de nombreux travaux linguistiques, dans di#érents
courants théoriques – linguistique de l’énonciation, analyse de discours, sémantique des
textes. La textométrie, aux con!ns de la linguistique générale et du TAL, propose par
ailleurs une archive intéressante de travaux sur corpus susceptibles d’intéresser les
367
applications d'analyse des sentiments (AS). On songe, dans le discours politique, aux
travaux de (Salem, 1993), dans les sondages d'opinion, à (Lebart et Salem, 1988) ou dans
la littérature, à (Brunet, 2009).
On souhaiterait ici susciter une rencontre entre d’une part le TAL ingénierique et ses
applications et, d’autre part, la textométrie, à partir des constats suivants : (1)
l'évaluation des méthodes en TAL repose sur un ensemble restreint de mesures (telles que
précision, rappel, f-mesure) qui ont pour but de véri!er la qualité des méthodes plus que
de valider des hypothèses et des méthodologies linguistiques. Leurs résultats ne
nécessitent pas d'interprétation pour être valides ; (2) la textométrie relève, au contraire,
d’une tradition descriptive. Elle se focalise sur l’interprétation des résultats de
traitements statistiques, davantage que sur l’amélioration desdits traitements. À la
1
di#érence du TAL, l’évaluation n'est pas un enjeu en textométrie .
Notre projet repose sur l’hypothèse que la textométrie, discipline descriptive, est à même
d’apporter des solutions méthodologiques pour les applications généralement dévolues
au TAL. Nous tenterons d’évaluer l'apport potentiel de la conjonction d'une analyse
textométrique et de méthodes d'apprentissage pour une application d'AS.

2       État de l'art

La catégorisation des textes, qu’elle soit bipolaire (positif/négatif) ou multiclasse
(mauvais/bon/excellent), est l'application principale en extraction d’information
subjective. Elle peut être réalisée au moyen d'algorithmes ad hoc (Turney, 2002 ; Snyder
et Barzilay, 2007) ou des méthodes d'apprentissage comme Naive Bayes, Support Vector
Machines, etc. (Pang et al., 2002 ; Mihalcea et Liu, 2006), en utilisant des attributs
di#érents pour caractériser les documents. Même si perdurent d'autres méthodes – ayant
principalement recours à l'utilisation de ressources lexicales, construites (Kim et Hovy,
2004) ou automatiquement acquises (Turney, 2002 ; Rilo# et al., 2003), avec la
banalisation des corpus annotés, les méthodes de catégorisation basées sur
l'apprentissage supervisé sont de plus en plus utilisées. Elles utilisent diverses
caractéristiques textuelles : (i) tous les mots du texte (sac de mots, unigrammes ou n-
grammes) (Pang et al., 2002 ; Dave et al. 2003) ; (ii) la présence ou l'absence d'un
ensemble de mots déterminés ; (iii) l'emplacement de certains mots (Kim et Hovy,
2006) ; (iv) certaines parties du discours seules : adjectifs (Kamps et Marx, 2002),
collocations adverbe-adjectif (Turney, 2002) ; substantifs ; en!n (v) les dépendances
syntaxiques (Nakagawa et al., 2010 ; Wi et al., 2009 ; Wiegand et Klakow, 2010). Nous
nous inscrivons donc pleinement dans cette démarche en proposant des critères de
classi!cation issus d'analyses textométriques pour servir de base aux divers algorithmes
d'apprentissage supervisé.
1
Autrement dit, les études textométriques ne sont validées que par l’assentiment d’une communauté qui, dans
le meilleur des cas, est distante (par exemple, critique littéraire, sociologie), mais, dans le pire des cas, n’est
peut-être qu’un avatar du jugement d’acceptabilité pourtant honni de ladite communauté.
368
3     Présentation du corpus
3.1    Contexte applicatif de l’étude
Le corpus est constitué de 300 textes courts réunis par SAMESTORY (http://www.same-
story.com), un service d’agrégation d’ego-documents. Il s'agit, en l’occurrence, de
témoignages et récits d'histoires vécues postés par les internautes sur di#érents forums
de discussion (aufeminin.com, doctissimo.fr, etc.). Les catégorisations sont multicritères :
thématiques, tonalité, conseil vs demande, sexe de l'émetteur, situation familiale, etc.
Nous traitons, dans des textes portant sur la santé, la tonalité « gai/triste ». De prime
abord, elle s'apparente à une analyse thymique, mais il s'agit de catégories complexes où
les phénomènes discursifs (ex : structure du récit) interviennent dans la classi!cation
autant que l'expression linguistique des sentiments. Ainsi, notre tâche est de modéliser
l'art de témoigner d'une histoire vécue.

3.2    Annotation tonale du corpus

L'annotation tonale du corpus a été e#ectuée par SAMESTORY. Nous en avons analysé
un échantillon pour en déduire la stratégie d'annotation de façon à caractériser plus
!nement l'opposition binaire gai/triste. Un témoignage « triste » est (i) une histoire qui
!nit mal, (ii) un témoignage exprimant des doutes, des interrogations, ou sollicitant de
l'aide. Un témoignage « gai » est (i) une histoire triste qui !nit bien, (ii) un témoignage
modulant la gravité de la situation et soulignant les points positifs (iii) un conseil.

4     Description de l’expérience
4.1    Étape 1 : Choix des caractéristiques textuelles au moyen des
méthodes textométriques

Nous tentons de mettre en évidence les phénomènes textuels qui di#érencient les
témoignages de nos deux catégories. Nous avons une double ambition : trouver des
critères de classi!cation linguistiquement explicables et su"samment robustes pour
servir de critères aux méthodes d'apprentissage supervisé. Nous faisons l'hypothèse que
les critères de classi!cation interprétables sont plus performants que les critères trouvés
par des méthodes d'apprentissage, souvent non signi!ants d'un point de vue textuel et
incidents au corpus d'apprentissage (ex : présence de fautes d'orthographe non
pertinentes par rapport aux catégories de classi!cation). Ainsi, lors de l'étape de
sélection de critères, l'analyste écarte les critères liés à l'échantillon du corpus et choisit
les critères textuels cohérents avec les composantes textuelles (thématique, dialogique,
etc. cf. § 5) actualisées dans le corpus. Pour l'expérience, nous avons utilisé trois types de
critères : (i) critères unitaires : un choix de formes, lemmes ou catégories
morphosyntaxiques ; (ii) critères composites adjacents (n-grammes) ; (iii) cooccurrences
multiniveaux (combinant les éléments de di#érents niveaux de description linguistique :
formes, lemmes ou catégories morphosyntaxiques). Tous les critères sont sélectionnés
selon 4 principes : leur caractère spéci!que à un sous-corpus, leur répartition uniforme
dans le sous-corpus, leur fréquence et leur pertinence linguistique.
L'analyse du corpus et l'extraction des critères ont été e#ectuées avec deux logiciels
369
textométriques – Lexico3 (Salem et al. 2003) et TXM (Heiden et al. 2010) – qui
implémentent les algorithmes de spéci!cités (Lafon, 1980) et de cooccurrences (Lafon,
1981). Nous avons choisi les deux premiers types de critères selon le procédé suivant :
1. calcul des spéci!cités des items isolés (formes, lemmes et catégories
morphosyntaxiques) et de leur n-grammes (fonction « Segments Répétés » de
Lexico 3) pour chaque sous-corpus (gai/triste) ;
2. analyse des contextes d'apparition des items spéci!ques (au moyen de
concordances textuelles) a!n de s'assurer de leur pertinence textuelle et de
l'unicité de leur fonction (les critères ayant une seule fonction et signi!cation ont
été privilégiés) ;
3. véri!cation de la répartition uniforme des items dans le sous-corpus
(fonctionnalité « Carte de Sections » du Lexico 3) ;
La sélection des cooccurrences s'est fait comme suit :
1. calcul des cooccurrences (fonction « Cooccurrences » de TXM) des items
spéci!ques fréquents et uniformément repartis sur la totalité du corpus ;
2. analyse des contextes d'apparition de ces cooccurrences ;
3. sélection des cooccurrences spéci!ques à un sous-corpus ;
Dans les deux cas, les critères de classi!cation pour chaque texte sont des fréquences ou
des valeurs booléennes (présence/absence) des items sélectionnés.

4.2        Étape 2 : Classi!cation
La deuxième étape consiste à utiliser des algorithmes d'apprentissage supervisé pour
2
classer les textes. En utilisant Weka , nous en avons expérimenté trois, chacun d'une
famille di#érente : les arbres de décision (J48 ; Quinlan, 1993), Naive Bayes (John et
Langley, 1995) et les Machines à Vecteurs de Support (SMO ; Platt, 1998). L'objectif est
d'observer les di#érences et similitudes au niveau des performances en changeant la
nature et la quantité des critères.
Le corpus contient 300 textes équitablement répartis entres les deux catégories (147
« gaies » et 153 « tristes »). L'évaluation a été e#ectuée avec la méthode de validation
croisée sur cinq parties.
•    Expérimentation 1.1 : première expérimentation avec des mots simples sans
aucune modi!cation (avec pour valeur leur fréquence dans un texte) ; on
considère ces résultats comme la base de comparaison (baseline) pour d'autres
expérimentations. La base de comparaison est donc l'expérimentation qui
nécessite l'e#ort computationnel minimal sur les textes en considérant ces
derniers comme un matériau brut, directement accessible (au moyen d'une
segmentation en mots). Toutes les autres expérimentations e#ectuent des
traitements supplémentaires sur les textes visant à améliorer les résultats.
L'évaluation a été e#ectuée avec la validation croisée sur 5 parties du corpus.

2
http://www.cs.waikato.ac.nz/ml/weka/
370
•     Expérimentation 1.2 : A la place des mots, nous avons utilisés leurs lemmes (casse
normalisée).
•     Expérimentation 1.3 : Utilisation des n-grammes de mots (longueur maximale 3).
Dans la série des expérimentations 2, nous avons utilisé les critères élaborés selon la
méthodologie décrite dans la partie précédente.
•     Expérimentation 2.1 : Utilisation de critères unitaires et de critères composites
adjacents pour un total de 30 critères.
•     Expérimentation 2.2 : Ajout de critères cooccurrentiels et augmentation du
nombre (total : 46 critères).
•     Expérimentation 2.3 : Augmentation du nombre de critères (total : 61 critères).

5       Résultat et discussion

Type d'attributs                                   Algorithme de         % des textes
classi!cation         bien catégorisés
1.1. Mots simples (1200 critères)                  J48                   53
Naive Bayes           63
SMO                   70
1.2. Lemmes (370 critères)                         J48                   55
Naive Bayes           63
SMO                   64

1.3 N-grammes de mots (1357 critères)              J48                   56
Naive Bayes           64
SMO                   74
2.1. Critères textométriques (30 critères)         J48                   67
Naive Bayes           64
SMO                   65
2.2. Critères textométriques (43 critères)         J48                   62
Naive Bayes           72
SMO                   72
2.3. Critères textométriques (61 critères)         J48                   70
Naive Bayes           74
SMO                   77

TABLE 1 – Résultat des expérimentations
Comme dans des expériences similaires (Pang et al., 2002), on constate que la
371
classi!cation sur les mots simples et les n-grammes permet d'obtenir des résultats
convenables compte tenu de la di"culté de la tâche. Néanmoins, cela constitue un
plafond que l'on ne peut dépasser. La généralisation des critères apportée par la
lemmatisation ne permet pas d'améliorer les résultats. Ce phénomène a fait l'objet de
nombreux débats dans la communauté textométrique (par exemple Mellet, 2003).
A la di#érence de la première série d'expérimentations, nos critères textométriques sont
peu nombreux mais ils constituent une base facilement extensible. L'ajout des critères
augmente systématiquement les performances de Naive Bayes et SMO. Ainsi, nous
observons une progression sensible sur l'ensemble des algorithmes. Notre meilleur
résultat (avec SMO) dépasse de 7 points celui obtenu avec des mots simples et de 3
points celui des n-grammes. Par ailleurs, l'amélioration des résultats pour J48 et Naive
Bayes est systématique.
L'interprétation des résultats chi#rés et des critères obtenus participe selon nous de la
validation de l'expérimentation et en constitue une valeur ajoutée. Ainsi, nous avons
organisé nos critères selon une typologie inspirée de travaux sémiotiques. Les critères
thymiques (Courtès, 1991), qui relèvent d'une lecture axiologique des textes, sont
essentiellement dysphoriques et concernent donc les textes tristes : « avoir peur », « je
sou"re », « douleur », « stress ». Le seul critère thymique retenu pour la classi!cation des
textes gai est « heureux » (euphorique). Au-delà des critères thymiques courants, nous
nous sommes intéressés à ceux relatifs à des composantes textuelles (Rastier, 2001) parce
que, ne relevant pas de typologies axiologiques classiques (positif/négatif) (Charaudeau,
1992), ils sont rarement pris en compte en AS. La composante dialectique concerne
l'organisation linéaire et temporelle du récit. Ces critères, dans les textes « gais », sont
di#érents marqueurs de structuration argumentative (« par contre », « car ») et temporelle
(« après », « puis ») absents des textes « tristes ». Dans ceux-ci, la structuration est
cumulative (« en plus », « de nouveau ») ou indice d'incertitude (« ne pas arriver à », « avoir
l'impression de »). La composante dialogique est relative au positionnement des acteurs.
Elle met en œuvre un fort contraste entre les textes « gais », où le destinateur-
énonciateur s'adresse explicitement à un « tu » destinataire actualisé par des pronoms de
2ème personne (pronoms personnel, possessifs, etc.), relate une expérience édi!ante
(« mon expérience », « pour ma part ») et prodigue des conseils (présence d'hyperliens
« www ») et des encouragements (« bon courage ») sans pour autant mettre en avant un je.
Les témoignages « tristes » mettent en texte un « je » massif. En!n, la composante
thématique n'a pas été négligée mais nous nous sommes e#orcés de ne sélectionner que
des critères d'un grand niveau de généralité relatifs au domaine de la santé. Ainsi, aux
noms de symptômes, maladies, traitements ou médicaments, nous avons préféré, pour les
textes « tristes » : « urgences », « hôpital », « rendez-vous », « analyses », « médecins », ou la
locution « être atteint de ». Pour les textes « gais » : « rémission », « produit naturel »,
« homéopathie » permettent d'obtenir des résultats convaincants.

6    Conclusion
Il est admis que les méthodes e"caces en classi!cation thématique (par exemple,
l'apprentissage supervisé sur mots simples) sont peu performantes pour les tâches
d'analyse de la subjectivité. La di"culté réside dans le fait que la subjectivité ne relève
pas seulement du lexique, mais d'autres niveaux de description : organisation temporelle
372
du récit, structure argumentative, etc. Nous avons proposé ici quelques éléments
d'analyse pour la prise en compte de ces niveaux de description et leur implémentation
pour la classi!cation. Le coût en temps de notre méthode d'élaboration de critères n'a
pas été quanti!é mais nous estimons qu'il est comparable à d'autres méthodes semi-
automatiques. Le domaine manquant de méthodes éprouvées, notre expérience nous a
permis de mieux comprendre la tâche et sa complexité et d'esquisser une proposition
méthodologique tenant compte d'une caractérisation textuelle de la subjectivité.

7    Références
BRUNET, É. (2009). Écrits choisis, Volume 1, Comptes d’auteurs. Études statistiques. De
Rabelais à Gracq. Textes édités par D. Maya#re, Champion, Paris
BÉCHET, F., EL-BÈZE, M. et TORRES-MORENO, J.-M. (2008). En !nir avec la confusion des
genres pour mieux séparer les thèmes Actes de l'atelier de clôture de la 4ème édition du Dé!
Fouille de Texte.
CHARAUDEAU P. (1992). Grammaire du sens et de l’expression. Hachette Education.
COURTÈS, J. (1991). Analyse sémiotique du discours. De l'énoncé à l'énonciation, Paris,
Hachette.
DAVE, K., LAWRENCE, S., et PENNOCK, D.M. (2003). Mining the peanut gallery: opinion
extraction and semantic classi!cation of product reviews. In Proceedings of the 12th
international WWW conference, May 20-24, 2003, Budapest, Hungary, pages 519-528.
HEIDEN, S., MAGUÉ, J-P. et PINCEMIN, B. (2010). TXM : Une plateforme logicielle open-source
pour la textométrie – conception et développement. In I. C. Sergio Bolasco (Ed.),JADT
2010, Vol. 2, pages 1021-1032. [logiciel disponible sur http://textometrie.ens-lyon.fr/]
JOHN, G. H. et LANGLEY, P. (1995). Estimating Continuous Distributions in Bayesian
Classi!ers. Eleventh Conference on Uncertainty in Arti!cial Intelligence, San Mateo, pages
338-345.
KAMPS, J. et MARX, M. (2002). Words with Attitude. 1st International WordNet Conference,
pages 332-341.
KIM, S-M. et HOVY, E. (2004). Determining the sentiment of opinions.Proceedings of the
20th international conference on Computational Linguistics (COLING '04). Association for
Computational Linguistics, Stroudsburg, PA, USA.
KIM, S.-M. et HOVY, E. (2006). Extracting opinions, opinion holders, and topics expressed
in online news media text. SST '06: Proceedings of the Workshop on Sentiment and
Subjectivity in Text, Association for Computational Linguistics, pages 1-8.
LEBART L. et SALEM A., (1988). Analyse statistique des données textuelles. Questions ouvertes et
lexicométrie, Paris, Dunod.
LAFON, P. (1980). Sur la variabilité de la fréquence des formes dans un corpus, Mots, 1,
pages 127-165.
LAFON, P. (1981). Analyse lexicométrique et recherche des cooccurrences, Mots, 3, pages
95-148.
373
MELLET, S. (2003). Lemmatisation et encodage grammatical : un luxe inutile ?
Lexicometrica : Autour de la lemmatisation, Dominique Labbé, éd.
MIHALCEA, R. et LIU, H. A (2006). Corpus-Based Approach to Finding Happiness AAAI
Symposium on Computational Approaches to Analysing Weblogs (AAAI-CAAW).
NAKAGAWA, T., INUI, K. et KUROHASHI, S. (2010). Dependency Tree-based Sentiment
Classi!cation using CRFs with Hidden Variables. Proceedings of Human Language
Technologies.
PANG, B., LEE, L. et VAITHYANATHAN, S. (2002). Thumbs up? Sentiment classification using
machine learning techniques. Proceedings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP), pages 79-86.
PANG, B. et LEE, L. (2008). Opinion Mining and Sentiment Analysis, Now Publishers Inc.
PLATT, J. (1998). Machines using Sequential Minimal Optimization. B. Schoelkopf, C.
Burges and A. Smola, editors, Advances in Kernel Methods - Support Vector Learning.
RASTIER, F. (2001). Arts et sciences du texte, Paris, PUF.
RILOFF, E., WIEBE, J. et WILSON (2003). T. Learning subjective nouns using extraction
pattern bootstrapping. Proceedings of the Conference on Natural Language Learning
(CoNLL), pages 25-32.
QUINLAN, R. (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers,
San Mateo, CA.
SALEM, R. (1993). Méthodes de la statistique textuelle, Thèse pour le doctorat d'État ès
lettres et sciences humaines, Université de la Sorbonne Nouvelle – Paris 3, 998 pages.
SALEM A., LAMALLE C., MARTINEZ W., FLEURY S., FRACCHIOLLA B., et al. (2003). Lexico3 – Outils de
statistique textuelle. Manuel d’utilisation. http://www.tal.univ-paris3.fr/lexico/]
SNYDER, B. et BARZILAY, R. (2007). Multiple aspect ranking using the Good Grief algorithm.
Proceedings of the Joint Human Language Technology/North American Chapter of the ACL
Conference (HLT-NAACL), pages 300-307.
TURNEY, P. (2002). Thumbs up or thumbs down? Semantic orientation applied to
unsupervised classification of reviews. Proceedings of the Association for Computational
Linguistics (ACL), pages 417-424.
VERNIER, M., MONCEAUX, l. et DAILLE, B. (2009). DEFT'09 : détection de la subjectivité et
catégorisation de textes subjectifs par une approche mixte symbolique et statistique
Actes de l'atelier de clôture de la 5ème édition du Dé! Fouille de Textes.
WI, Y., ZHANG, Q., Huang, X., et Wu, L. (2009). Phrase Dependency Parsing for Opinion
Mining. Proceedings of EMNLP-2009, Singapore.
WIEBE, J.M., WILSON, T., BRUCE, R., BELL, M. et MARTIN, M. (2004). Learning subjective
language. Computational Linguistics, 30(3), pages 277-308.
WIEGAND, M. et KLAKOW, D. (2010). Convolution Kernels for Opinion Holder Extraction.
Proceedings of Human Language Technologies: The 2010 Annual Conference of the North
American Chapter of the ACL, L.A., CA.
374
