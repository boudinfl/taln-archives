Sur Papplication gle Inéthodes textgmétriques 5 la
COI1St1‘11Ct10I1 de crlteres de_c1ass1ﬁcat1on en analyse des
sentlments

Egle Eensoo Mathieu Valette
INALCO, ERTIM, 2 rue de Lille, 75343 Paris Cedex 07
{prenom. nom} @inalco . fr

Résumfz

Depuis une dizaine d'années, le TAL s'intéresse 5 la subjectivité, notamment dans la
perspective d'applications telles que la fouille d'opinion et l'analyse des sentiments. Or, la
linguistique de corpus outillée par des méthodes textométtiques a souvent abordé la
question de la subjectivité dans les textes. Notre objectif est de montrer d'une part, ce
que pourrait apporter 5 l'analyse des sentiments l'analyse textométrique et d'autre part,
comment mut11aliser les avantages d'une association entre celle-ci et une méthode de
classiﬁcation automatique basée sur l'apprentissage supervisé. En nous appuyant sur un
corpus de témoignages issus de forums de discussion, nous montrerons que la prise en
compte de critéres sélectionnés suivant une analyse textométrique permet d'obtenir des
résultats de classiﬁcation satisfaisants par rapport 5 une vision purement lexicale.

ABSTRACT

About the application of textometric methods for developing classiﬁcation criteria
in Sentirnent analysis

Over the last ten years, NLP has contributed to applied research on subjectivity,
especially in applications such as Opinion mining and Sentiment analysis. However,
corpus linguistics and textometry have often addressed the issue of subjectivity in text
Our purpose is to show, ﬁrst, what textometric analysis could bring to sentiment
analysis, and second, the beneﬁts of pooling linguistic/textometric analysis and
automatic classiﬁcation methods based on supervised learning. By processing a corpus of
posts from fora, we will show that the building of criteria from a textometric analysis
could improve classiﬁcation results, compared to a purely lexical approach.

Mors-cL1‘zs: linguistique de corpus, textométtie, analyse de sentiments, classiﬁcation
automatique supervisée.

KEYWORDS : corpus linguistics, textometry, sentiment analysis, supervised learning.

1 Introduction

L’extraction d’information subjective (Pang et Lee, 2008) est depuis une dizaine d’années
un vaste domaine d’applications en croissance réguliére. Malgré quelques travaux (par
exemple Vernier, 2009 ; Béchet et aL, 2008) le savoir-faire linguistique y est peu sollicité.
La subjectivité a pourtant fait l’objet de nombreux travaux linguistiques, dans différents
courants théoriques — linguistique de l’énonciation, analyse de discours, sémantique des
textes. Ia textométrie, aux conﬁns de la linguistique générale et du TAL, propose par
ailleurs une archive intéressante de travaux sur corpus susceptibles d’intéresser les

Actes de la conférence onjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 367-374,
Grenoble, 4 an 8 juin 2012. ©2012 ATAI.A 8: AFCP

367

applications d'analyse des sentiments (AS). On songe, dans le discours politique, aux
travaux de (Salem, 1993), dans les sondages d'opinion, 5 (Lebart et Salem, 1988) ou dans
la littérature, 5 (Brunet, 2009).

On souhaiterait ici susciter u.ne rencontre ent:re d’une part le TAL ingénierique et ses
applications et, d’autre part, la textométiie, a partir des constats suivants : (1)
l'évaluation des méthodes en TAL repose sur un ensemble restreint de mesu.res (telles que
précision, rappel, f-mesure) qui ont pour but de vériﬁer la qualité des méthodes plus que
de valider des hypotheses et des méthodologies linguistiques. Leurs résultats ne
nécessitent pas d'interprétation pour étre valides ; (2) la textométiie releve, au contraire,
d’une tradition descriptive. Elle se focalise su.r l’interprétation des résultats de
traitements statistiques, davantage que su.r l’amélioration desdits traitements. A la
différence du TAL, l’évaluation n'est pas u.n enjeu en textométtiel.

Notre projet repose su.r l’hypothese que la textométtie, discipline descriptive, est 5 meme
d’apporter des solutions méthodologiques pour les applications généralement dévolues
au TAL. Nous tenterons d’évaluer l'apport potentiel de la conjonction d'u.ne analyse
textométiique et de méthodes d'apprentissage pour une application d'AS.

2 Etat de l'art

La catégorisation des textes, qu’elle soit bipolaire (positif/négatif) ou multiclasse
(mauvais/bon/excellent), est l'application principale en extraction d’information
subjective. Elle peut étre réalisée au moyen d'algorithmes ad hoc (Turney, 2002 ; Snyder
et Barzilay, 2007) ou des mét.hodes d'apprentissage comme Naive Bayes, Support Vector
Machines, etc. (Pang et aL, 2002; Mihalcea et Liu, 2006), en utilisant des attributs
différents pour caractériser les documents. Méme si perdurent d'aut:res méthodes — ayant
principalement recours 5 l'utilisation de ressources lexicales, construites (Kim et Hovy,
2004) ou automatiquement acquises (Turney, 2002; Riloff et aL, 2003), avec la
banalisation des corpus annotés, les mét.hodes de catégorisation basées sur
l'apprentissage supervisé sont de plus en plus utilisées. Elles utilisent diverses
caractéristiques text11elles: (i) tous les mots du texte (sac de mots, unigrammes ou n-
grammes) (Pang et aL, 2002; Dave et aL 2003); (ii) la présence ou l'absence d'un
ensemble de mots déterminés ; (iii) l'emplacement de certains mots (Kim et Hovy,
2006); (iv) certaines parties du discours seules: adjectifs (Kamps et Marx, 2002),
collocations adverbe-adjectif (Turney, 2002); substantifs ; enﬁn (v) les dépendances
syntaxiques (Nakagawa et aL, 2010 ; Wi et aL, 2009 ; Wiegand et Klakow, 2010). Nous
nous inscrivons donc pleinement dans cette démarche en proposant des criteres de
classiﬁcation issus d'analyses textométtiques pour servir de base aux divers algorithmes
d'apprentissage supervisé.

1 Autrement dit, les études textométriques ne sont validées que par Passentiment d’une communauté qui, dans
le meilleur des cas, est distante (par exemple, critique l.ittéra.ire, sociologie), mais, dans le pire des cas, n’est

peut-étre qu’un avatar dujuganznt d’acceptabilité pourtant honni de ladite communauté.

368

3 Présentation du corpus

3.1 Contexte applicatif de l’étude

Le corpus est constitué de 300 textes courts réunis par SAMESTORY (http://www.same-
story.com), un service d’agrégation d’ego-documents. Il s'agit, en l’occu.rrence, de
témoignages et récits d'h.istoires vécues postés par les intemautes sur différents forums
de discussion (aufemin.in.com, doctissimo.fr, etc.). Les catégorisations sont multicriteres :
thématiques, tonalité, conseil vs demande, sexe de l'émetteur, situation familiale, etc.
Nous traitons, dans des textes portant sur la santé, la tonalité << gai/triste ». De prime
abord, elle s'apparente 5 une analyse thymique, mais il s'agit de catégories complexes oil
les phénoménes discursifs (ex: structure du récit) interviennent dans la classiﬁcation
autant que l'expression linguistique des sentiments. Ainsi, notre tache est de modéliser
l'art de témoigner d'une histoire vécue.

3.2 Annotation tonale du corpus

L'annotation tonale du corpus a été effect11ée par SAMESTORY. Nous en avons analysé
un échantillon pour en déduire la stratégie d'annotation de facon 5 caractériser plus
ﬁnement l'opposition binaire gai/triste. Un témoignage << triste » est (i) une histoire qui
ﬁnit mal, (ii) un témoignage exprimant des doutes, des interrogations, ou sollicitant de
l'aide. Un témoignage << gai » est (i) une histoire triste qui ﬁnit bien, (ii) un témoignage
modulant la gravité de la situation et soulignant les points positifs (iii) un conseil.

4 Description de l’expé1-ience

4.1 Etape 1: Choix des caractéristiques textuelles au moyen des
méthodes textométriques

Nous tentons de mettre en évidence les phénomenes text11els qui différencient les
témoignages de nos deux catégories. Nous avons une double ambition: trouver des
critéres de classiﬁcation linguistiquement explicables et sufﬁsamment robustes pour
servir de criteres aux méthodes d'apprentissage supervisé. Nous faisons l'hypothese que
les criteres de classiﬁcation interprétables sont plus performants que les critéres trouvés
par des méthodes d'apprentissage, souvent non signiﬁants d'un point de vue text11el et
incidents au corpus d'apprentissage (ex: présence de fautes d'orthographe non
pertinentes par rapport aux catégories de classiﬁcation). Ainsi, lors de l'étape de
sélection de criteres, l'analyste écarte les criteres liés 5 l'échantillon du corpus et choisit
les critéres text11els cohérents avec les composantes text11elles (thématique, dialogique,
etc. cf. § 5) actualisées dans le corpus. Pour l'expérience, nous avons utilisé trois types de
critéres: (i) critéres unitaires: un choix de formes, lemmes ou catégories
morphosyntaxiques ; (ii) criteres composites adjacents (n-grammes) ; (iii) cooccurrences
multiniveaux (combinant les éléments de différents niveaux de description linguistique :
formes, lemmes ou catégories morphosyntaxiques). Tous les critéres sont sélectionnés
selon 4 principes : leur caractére spéciﬁque 5 un sous-corpus, leur répartition uniforme
dans le sous-corpus, leur fréquence et leur pertinence linguistique.

L'analyse du corpus et l'extraction des critéres ont été effectuées avec deux logiciels

369

textométriques — Lexico3 (Salem et aL 2003) et TXM (Heiden et aL 2010) — qui
implémentent les algoritl1mes de spéciﬁcités (Lafon, 1980) et de cooccurrences (Lafon,
1981). Nous avons choisi les deux premiers types de critéres selon le procédé suivant :

1. calcul des spéciﬁcités des items isolés (formes, lemmes et catégories
morphosyntaxiques) et de leur n-gram.mes (fonction << Segments Répétés » de
Lexico 3) pour chaque sous-corpus (gai/t1iste) ;

2. analyse des contextes d'apparition des items spéciﬁques (au moyen de
concordances text11elles) aﬁn de s'assurer de leur pertinence text11elle et de
l'u.nicité de leur fonction (les criteres ayant u.ne seule fonction et signiﬁcation ont
été privilégiés) ;

3. vériﬁcation de la répartition u.niforme des items dans le sous-corpus
(fonctionnalité << Carte de Sections >> du Lexico 3) ;

La sélection des cooccurrences s'est fait comme suit :

1. calcul des cooccurrences (fonction << Cooccurrences >> de TXM) des items
spéciﬁques fréquents et uniformément repartis sur la totalité du corpus ;

2. analyse des contextes d'apparition de ces cooccurrences ;
3. sélection des cooccurrences spéciﬁques 5 un sous-corpus ;

Dans les deux cas, les criteres de classiﬁcation pour chaque texte sont des fréquences ou
des valeurs booléennes (présence/absence) des items sélectionnés.

4.2 Etape 2 : Classiﬁcation

La deuxiéme étape consiste 5 utiliser des algoritl1mes d'apprentissage supervisé pour
classer les textes. En utilisant Wekaz, nous en avons expérimenté trois, chacun d'une
famille différente: les arbres de décision (J48 ; Quinlan, 1993), Naive Bayes (John et
Langley, 1995) et les Machines 5 Vecteurs de Support (SMO ; Platt, 1998). L'objectif est
d'observer les différences et similit11des au niveau des performances en changeant la
nature et la quantité des critéres.

Le corpus contient 300 textes équitablement répartis entres les deux catégories (147
<< gaies » et 153 << tristes >>). L'évaluation a été effectuée avec la méthode de validation
croisée su.r cinq parties.

- Expérimentation 1.1: premiere expérimentation avec des mots simples sans
aucune modiﬁcation (avec pour valeur leur fréquence dans un texte); on
considere ces résultats comme la base de comparaison (baseline) pour d'autres
expérimentations. La base de comparaison est donc l'expérimentation qui
nécessite l'effort computationnel minimal sur les textes en considérant ces
derniers comme u.n matériau brut, directement accessible (au moyen d'une
segmentation en mots). Toutes les autres expérimentations effect11ent des
traitements supplémentaires sur les textes visant 5 améliorer les résultats.
L'évaluation a été effectuée avec la validation croisée sur 5 parties du corpus.

2ht : www.cs.waikato.ac.nz ml we

370

- Expérimentation 1.2 : A la place des mots, nous avons utilisés leu.rs lemmes (casse
normalisée).

- Expérimentation 1.3 : Utilisation des n-grammes de mots (longueur maximale 3).

Dans la série des expérimentations 2, nous avons utilisé les critéres élaborés selon la
méthodologie décrite dans la partie précédente.

- Expérimentation 2.1 : Utilisation de criteres unitaires et de criteres composites
adjacents pour un total de 30 criteres.

- Expérimentation 2.2: Ajout de criteres cooccurrentiels et augmentation du
nombre (total : 46 criteres).

- Expérimentation 2.3 : Augmentation du nombre de critéres (total : 61 criteres).

5 Résultat et discussion

Type d'att1-ibuts Algorithme de % des textes
classiﬁcation bien catégorisés
1.1. Mots simples (1200 criteres) J48 53
Naive Bayes 63
SMO 70
1.2. Lemmes (370 criteres) J48 55
Naive Bayes 63
SMO 64
1.3 N-grammes de mots (1357 criteres) J48 56
Naive Bayes 64
SMO 74
2.1. Critéres textométtiques (30 critéres) J48 67
Naive Bayes 64
SMO 65
2.2. Critéres textométtiques (43 critéres) J48 62
Naive Bayes 72
SMO 72
2.3. Critéres textométtiques (61 critéres) J48 70
Naive Bayes 74
SMO 77

TABLE 1 — Résultat des expérimentations

Comme dans des expériences similaires (Pang et aL, 2002), on constate que la

371

classiﬁcation sur les mots simples et les n-grammes permet d'obtenir des résultats
convenables compte tenu de la difﬁculté de la tache. Néanmoins, cela constitue u.n
plafond que l'on ne peut dépasser. La généralisation des critéres apportée par la
lemmatisation ne permet pas d'améliorer les résultats. Ce phénomene a fait l'objet de
nombreux débats dans la communauté textométrique (par exemple Mellet, 2003).

A la différence de la premiere série d'expérimentations, nos critéres textométriques sont
peu nombreux mais ils constit11ent une base facilement extensible. L'ajout des criteres
augmente systématiquement les performances de Naive Bayes et SMO. Ainsi, nous
observons une progression sensible sur l'ensemble des algorithmes. Notre meilleur
résultat (avec SMO) dépasse de 7 points celui obtenu avec des mots simples et de 3
points celui des n-grammes. Par ailleurs, l'améliorat:ion des résultats pour J48 et Naive
Bayes est systématique.

L'interprétation des résultats chiffrés et des critéres obtenus participe selon nous de la
validation de l'expérimentat:ion et en constit11e une valeur ajoutée. Ainsi, nous avons
organisé nos criteres selon une typologie inspirée de travaux sémiotiques. Les critéres
thymiques (Courtes, 1991), qui relevent d'une lecture axiologique des textes, sont
essentiellement dysphoriques et concernent donc les textes tristes: «avoir peur », «je
souﬁ're », « douleur », « stress ». Le seul critere thymique retenu pour la classiﬁcation des
textes gai est « heureux» (euphorique). Au-dela des criteres thymiques courants, nous
nous sommes intéressés 5 ceux relatifs a des corrposantes textuelles (Rastier, 2001) parce
que, ne relevant pas de typologies axiologiques classiques (positif/négatif) (Charaudeau,
1992), ils sont rarement pris en compte en AS. La composante dialectique concerne
l'organisat:ion linéaire et temporelle du récit. Ces criteres, dans les textes << gais », sont
différents marqueurs de structuration argumentative («par corme », « car ») et temporelle
(« aprés », « puis ») absents des textes << tristes ». Dans ceux-ci, la structuration est
cumulative (« en plus », « de nouveau ») ou indice d'incert:itude (« ne pas arriver c‘: », « avoir
Pirrqrression de »). La composante dialogique est relative au position.nement des acteurs.
Elle met en oeuvre u.n fort contraste entre les textes << gais », ou le dest:inateur-
énonciateur s'adresse explicitement 5 un « tu » destinataire act11a]isé par des pronoms de
2eme personne (pronoms personnel, possessifs, etc.), relate une expérience édiﬁante
(« man expérience », «pour ma part») et prodigue des conseils (présence d'hyperliens
« www ») et des encouragements (« bon courage ») sans pour autant mettre en avant u.n je.
Les témoignages << tristes >> mettent en texte u.n «je » massif. Enﬁn, la composante
thématique n'a pas été négligée mais nous nous sommes efforcés de ne sélectionner que
des criteres d'un grand niveau de généralité relatifs au domaine de la santé. Ainsi, aux
noms de sympt6mes, maladies, traitements ou médicaments, nous avons préféré, pour les
textes << tristes >> : « wgences », « hﬁpital », « rendez—vous », « analyses », « médecins », ou la
locution «étre atteint de ». Pour les textes << gais>>: «rémission », «produit naturel»,
« homéopathie » permettent d'obtenir des résultats convaincants.

6 Conclusion
Il est ad.mis que les mét.l1odes efﬁcaces en classiﬁcation t.hématique (par exemple,
l'apprent:issage supervisé sur mots simples) sont peu performantes pour les taches

d'analyse de la subjectivité. La difﬁculté réside dans le fait que la subjectivité ne releve
pas seulement du lexique, mais d'autres niveaux de description : organisation temporelle

372

du récit, structure argumentative, etc. Nous avons proposé ici quelques éléments
d'analyse pour la prise en compte de ces niveaux de description et leur implémentation
pour la classiﬁcation. Le coﬁt en temps de notre méthode d'élaboration de criteres n'a
pas été quantiﬁé mais nous estimons qu'il est comparable 5 d'autres méthodes semi-
automatiques. Le domaine manquant de méthodes éprouvées, notre expérience nous a
permis de mieux comprendre la tache et sa complexité et d'esquisser une proposition
méthodologique tenant compte d'une caractérisation text11elle de la subjectivité.

7 Références

BRUNET, E. (2009). Ecrits choisis, Volume 1, Cornptes d’auteurs. Etudes statistiques. De
Rabelais a Gracq. Textes édités par D. Mayaffre, Champion, Paris

BEcHEr, F., EL-B1‘=1E, M. et TORRES-MORENO, J.-M. (2008). En ﬁnir avec la confusion des
genres pour mieux séparer les themes Actes de l'atelier de cléture de la 4éme édition du Déﬁ
Fouille de Texte.

CHARAUDEAU P. (1992). Grammaire du sens et de l’expression. Hachette Education.

CoURrEs, J. (1991). Analyse sémiotique du discours. De l'énoncé a l'énonciation, Paris,
Hachette.

DAvE, K., LAWRENCE, S., et PENNoc1<, D.M. (2003). Mining the peanut gallery: opinion
extraction and semantic classiﬁcation of product reviews. In Proceedings of the 12”‘
international WWWconference, May 20-24, 2003, Budapest, Hungary, pages 519-528.

HEIDEN, S., MAGUE, J-P. et PmcEMm, B. (2010). TXM : Une plateforme logicielle open-source
pour la textométtie — conception et développement In I. C. Sergio Bolasco (Ed.),JADT
2010, Vol. 2, pages 1021-1032. [logiciel disponible sur http://textomet1ie.ens-lyon.ft'/]

JOHN, G. H. et LANGLEY, P. (1995). Estimating Continuous Distributions in Bayesian
Classiﬁers. Eleventh Conference on Uncertainty in Artiﬁcial Intelligence, San Mateo, pages
338-345.

KAMPS, J. et MARX, M. (2002). Words with Attitude. 1st International WordNet Cory‘erence,
pages 332-341.

KIM, S-M. et Hovv, E. (2004). Determining the sentiment of opinions.Proceedings of the
20th international cory‘erence on Computational Linguistics (COLING '04). Association for
Computational Linguistics, Slroudsburg, PA, USA.

KIM, S.-M. et Hovv, E. (2006). Extracting opinions, opinion holders, and topics expressed
in online news media text SST '06: Proceedings of the Workshop on Sentiment and
Subjectivity in Text, Association for Computational Linguistics, pages 1-8.

LEBART L. et SALEM A., (1988). Analyse statistique des données textuelles. Questions ouvertes et
lexicoméhie, Paris, Dunod.

LAFON, P. (1980). Sur la variabilité de la fréquence des formes dans un corpus, Mots, 1,
pages 127-165.

LAFON, P. (1981). Analyse lexicométrique et recherche des cooccurrences, Mots, 3, pages
95-148.

373

MELLET, S. (2003). Lemmatisation et encodage grammatical: un luxe inutile?
Lexicomehica : Autour de la lernmatisation, Dominique Iabbé, éd.

MIHALCEA, R. et LIU, H. A (2006). Corpus-Based Approach to Finding Happiness AAAI
Symposium on Computational Approaches to Analysing Weblogs (AAAI-CAAVV).

NAKAGAWA, T., INUI, K. et KUROHASHI, S. (2010). Dependency Tree-based Sentiment
Classiﬁcation using CRFs with Hidden Variables. Proceedings of Human Language
Technologies.

PANG, B., LEE, L. et VAITHYANATHAN, S. (2002). Thumbs up? Sentiment classiﬁcation using
machine learning techniques. Proceedings of the Cory‘erence on Errpirical Methods in
Natural Language Processing (EMNLP), pages 79-86.

PANG, B. et LEE, L. (2008). Opinion Mining and Sentiment Analysis, Now Publishers Inc.

PLATT, J. (1998). Machines using Sequential Minimal Optimization. B. Schoelkopf, C.
Burges and A. Smola, editors, Advances in Kernel Methods — Support Vector Learning.

RAsnER, F. (2001). Arts et sciences du texte, Paris, PUF.

RILOFF, E., WIEEE, J. et WILsoN (2003). T. Learning subjective nouns using extraction
pattern bootstrapping. Proceedings of the Conference on Natural Language Learning
(CoNLL), pages 25-32.

QUINLAN, R. (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers,
San Mateo, CA.

SALEM, R. (1993). Métl1odes de la statistique text11elle, These pour le doctorat d'}i'.tat es
lettres et sciences humaines, Université de la Sorbonne Nouvelle — Paris 3, 998 pages.

SALEM A., LAMALLE C., MARnNEz W., FLEURY S., FRAcc1-1IoLLA B., et aL (2003). LeXico3 — Outils de
statistique text11elle. Manuel d’utilisat:ion. http://www.tal.univ-paris3.fr/lexico/]

SNYDER, B. et BARZILAY, R. (2007). Multiple aspect ranking using the Good Grief algorithm.
Proceedings of the Joint Human Language Technology/North American Chapter of the ACL
Conference (HLT—NAACL), pages 300-307.

TURNEY, P. (2002). Thumbs up or thumbs down? Semantic orientation applied to
unsupervised classiﬁcation of reviews. Proceedings of the Association for Computational
Linguistics (ACL), pages 417-424.

VERNIER, M., MoNcEAux, 1. et DAILLE, B. (2009). DEFT'09 : détection de la subjectivité et
catégorisation de textes subjectifs par une approche mixte symbolique et statistique
Actes de l'atelier de cléture de la 5éme édition du Déﬁ Fouille de Textes.

W1, Y., ZHANG, Q., Huang, X., et Wu, L. (2009). Phrase Dependency Parsing for Opinion
Mining. Proceedings of EMNLP—2009, Singapore.

WIEEE, J.M., WILsoN, T., BRUCE, R., BELL, M. et MARTIN, M. (2004). Learning subjective
language. Computational Linguistics, 30(3), pages 277-308.

WIEGAND, M. et KLAKOW, D. (2010). Convolution Kernels for Opinion Holder Extraction.
Proceedings of Human Language Technologies: The 2010 Annual Conference of the North
American Chapter of the ACL, L.A., CA.

374

