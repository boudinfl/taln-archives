<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Etude de diff&#233;rentes strat&#233;gies d'adaptation &#224; un nouveau domaine en fouille d'opinion</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 391&#8211;398,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>&#201;tude de diff&#233;rentes strat&#233;gies d&#8217;adaptation &#224; un nouveau
domaine en fouille d&#8217;opinion
</p>
<p>Anne Garcia-Fernandez Olivier Ferret
CEA, LIST, Laboratoire Vision et Ing&#233;nierie des Contenus
</p>
<p>Gif-sur-Yvette, F-91191 France.
</p>
<p>pr&#233;nom.nom@cea.fr
</p>
<p>R&#201;SUM&#201;
Le travail pr&#233;sent&#233; dans cet article se situe dans le contexte de la fouille d&#8217;opinion et se focalise sur
la d&#233;termination de la polarit&#233; d&#8217;un texte en adoptant une approche par apprentissage. Dans ce
cadre, son objet est d&#8217;&#233;tudier diff&#233;rentes strat&#233;gies d&#8217;adaptation &#224; un nouveau domaine dans le cas
de figure fr&#233;quent o&#249; des donn&#233;es d&#8217;entra&#238;nement n&#8217;existent que pour un ou plusieurs domaines
diff&#233;rents du domaine cible. Cette &#233;tude montre en particulier que l&#8217;utilisation d&#8217;une forme
d&#8217;auto-apprentissage par laquelle un classifieur annote un corpus du domaine cible et modifie son
corpus d&#8217;entra&#238;nement en y incorporant les textes class&#233;s avec la plus grande confiance se r&#233;v&#232;le
comme la strat&#233;gie la plus performante et la plus stable pour les diff&#233;rents domaines test&#233;s. Cette
strat&#233;gie s&#8217;av&#232;re m&#234;me sup&#233;rieure dans un nombre significatif de cas &#224; la m&#233;thode propos&#233;e par
(Blitzer et al., 2007) sur les m&#234;mes jeux de test tout en &#233;tant plus simple.
</p>
<p>ABSTRACT
Study of various strategies for adapting an opinion classifier to a new domain
</p>
<p>The work presented in this article takes place in the field of opinion mining and aims more
particularly at finding the polarity of a text by relying on machine learning methods. In this
context, it focuses on studying various strategies for adapting a statistical classifier to a new
domain when training data only exist for one or several other domains. This study shows more
precisely that a self-training procedure consisting in enlarging the initial training corpus with
texts from the target domain that were reliably classified by the classifier is the most successful
and stable strategy for the tested domains. Moreover, this strategy gets better results in most
cases than (Blitzer et al., 2007)&#8217;s method on the same evaluation corpus while it is more simple.
</p>
<p>MOTS-CL&#201;S : fouille d&#8217;opinion, adaptation &#224; un nouveau domaine, auto-apprentissage.
</p>
<p>KEYWORDS: opinion mining, domain adaptation, self-training.
</p>
<p>1 Introduction
</p>
<p>Le travail pr&#233;sent&#233; dans cet article part de deux constats bien connus en Traitement Automatique
des Langues, et notamment en fouille d&#8217;opinion, lorsqu&#8217;une approche par apprentissage supervis&#233;
est mise en place. D&#8217;une part, la constitution de ressources annot&#233;es est un processus tr&#232;s
co&#251;teux. D&#8217;autre part, un syst&#232;me ayant de bonnes performances dans un domaine donn&#233;
n&#8217;est pas n&#233;cessairement adapt&#233; &#224; un autre domaine. De nombreux travaux ont &#233;t&#233; men&#233;s en
</p>
<p>391</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>fouille d&#8217;opinion, en particulier sur la probl&#233;matique de l&#8217;adaptation &#224; un nouveau domaine. Les
approches ainsi d&#233;velopp&#233;es vont de l&#8217;identification des correspondances terminologiques entre
domaines &#224; l&#8217;utilisation de ressources externes telles que des lexiques d&#8217;opinion, lexiques au sein
desquels chaque terme se voit typiquement associer une polarit&#233; positive, n&#233;gative voire m&#234;me
neutre. Mais que se passe-t-il si l&#8217;on ne dispose pas de telles ressources ? Comment proc&#233;der en
n&#8217;ayant acc&#232;s qu&#8217;&#224; quelques donn&#233;es annot&#233;es ne relevant pas du domaine cibl&#233; ?
</p>
<p>Nous nous attachons dans cet article &#224; &#233;tudier des strat&#233;gies d&#8217;apprentissage automatique pour
la classification de textes n&#8217;utilisant pas de ressources externes. Diff&#233;rentes configurations de
donn&#233;es annot&#233;es pour la t&#226;che de classification de textes en polarit&#233; positive ou n&#233;gative sont
test&#233;es afin de d&#233;terminer celles permettant d&#8217;obtenir les meilleures performances lorsqu&#8217;il s&#8217;agit
de classer des textes relevant d&#8217;un nouveau domaine. En particulier, nous exposons une approche
d&#8217;apprentissage dit it&#233;ratif par laquelle un corpus annot&#233; manuellement est enrichi au cours de
boucles successives par des donn&#233;es annot&#233;es automatiquement.
</p>
<p>2 Fouille d&#8217;opinion et classification de textes multi-domaine
</p>
<p>La fouille d&#8217;opinion regroupe un grand nombre de travaux centr&#233;s sur l&#8217;exploration de textes
afin d&#8217;en d&#233;terminer le caract&#232;re objectif ou subjectif ou encore d&#8217;extraire les avis qui y sont
exprim&#233;s par leurs auteurs. Une des caract&#233;ristiques de ce type d&#8217;analyses est leur caract&#232;re
transversal : leur nature ne d&#233;pend pas le plus souvent du domaine des textes consid&#233;r&#233;s. Ainsi,
dans le travail consid&#233;r&#233; ici, qui se focalise sur une t&#226;che de classification de textes subjectifs, en
l&#8217;occurrence des critiques issues du site AMAZON, les deux classes consid&#233;r&#233;es, polarit&#233; positive ou
n&#233;gative, sont g&#233;n&#233;rales et non d&#233;pendantes des diff&#233;rents domaines qu&#8217;abordent ces critiques.
En revanche, les moyens pour effectuer cette classification peuvent &#234;tre plus ou moins li&#233;s &#224;
un domaine, ce qui rend la probl&#233;matique de l&#8217;adaptation &#224; un nouveau domaine de ce type
d&#8217;analyses particuli&#232;rement importante. Dans ce qui suit, nous illustrerons d&#8217;abord le caract&#232;re
contextuel de la d&#233;termination de la polarit&#233; d&#8217;un &#233;nonc&#233; avant de passer en revue les principales
approches pour l&#8217;adaptation d&#8217;une telle classification &#224; un nouveau domaine.
</p>
<p>2.1 Classer des textes selon leur polarit&#233;
</p>
<p>Une des principales approches pour d&#233;terminer la polarit&#233; d&#8217;un texte consiste &#224; se focaliser
sur des termes porteurs d&#8217;opinion. De tels termes peuvent &#234;tre trouv&#233;s dans des ressources de
r&#233;f&#233;rence, telles que SENTIWORDNET (Esuli et Sebastiani, 2006). N&#233;anmoins, la disponibilit&#233; de
ces ressources n&#8217;est pas suffisante pour d&#233;terminer la polarit&#233; d&#8217;un texte. En effet, la polarit&#233;
d&#8217;un terme peut d&#233;pendre de son contexte. Cette d&#233;pendance existe d&#8217;abord &#224; un niveau local.
Ainsi, la pr&#233;sence d&#8217;une n&#233;gation dans une phrase peut inverser la polarit&#233; de celle-ci alors
m&#234;me qu&#8217;elle contient un ou plusieurs termes n&#233;gatifs (&quot;Cela dit le r&#233;alisateur sait y faire et c&#8217;est
bien pour &#231;a que le film n&#8217;est pas mauvais du tout, ni ennuyeux, ni lent.&quot;). Cette dimension est
prise en compte par de nombreux travaux. Taboada et al. (2011) utilisent ainsi un lexique de
termes porteurs d&#8217;opinion mais pond&#232;rent l&#8217;importance de ces termes en fonction du caract&#232;re
subjectif ou objectif des paragraphes dans lesquels ils apparaissent. Ils int&#232;grent par ailleurs les
n&#233;gations, les modifieurs (notamment les modifieurs d&#8217;intensit&#233;) et la modalit&#233; (en particulier
les suppositions). Choi et Cardie (2009) proposent au travers de l&#8217;algorithme Vote &amp; Flip de
</p>
<p>392</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>prendre en compte la pr&#233;sence d&#8217;une ou plusieurs n&#233;gations dans le contexte d&#8217;un terme porteur
d&#8217;opinion modifiant ainsi sa polarit&#233;. L&#8217;objet auquel un terme porteur d&#8217;opinion se rapporte peut
&#233;galement influer sur la valeur de ce terme. Ainsi mortel est porteur d&#8217;opinion n&#233;gative dans un
ennui mortel mais d&#8217;opinion positive dans cette f&#234;te &#233;tait vraiment mortelle. Enfin, la polys&#233;mie des
termes peut aussi jouer un r&#244;le puisque certains termes n&#8217;ont pas la m&#234;me valeur d&#8217;opinion selon
leur sens. C&#8217;est le cas par exemple de navet qui, dans la phrase &quot;C&#8217;est un navet.&quot;, n&#8217;est pas porteur
d&#8217;opinion si l&#8217;on fait r&#233;f&#233;rence au l&#233;gume mais renvoie &#224; une opinion n&#233;gative s&#8217;il qualifie un
film. La polarit&#233; d&#8217;un terme dans un texte est alors influenc&#233;e plus globalement par le domaine
auquel ce texte se rattache. Dans cette perspective, Harb et al. (2008) proposent d&#8217;acqu&#233;rir un
lexique d&#8217;opinion li&#233; &#224; une th&#233;matique en s&#233;lectionnant dans des corpus li&#233;s &#224; cette th&#233;matique
des termes cooccurrents avec des termes dont la polarit&#233; est d&#233;j&#224; connue et en utilisant une
mesure de similarit&#233; entre les termes candidats et les termes connus.
</p>
<p>2.2 D&#8217;un domaine &#224; l&#8217;autre
</p>
<p>Dans le prolongement des travaux de la section pr&#233;c&#233;dente fond&#233;s sur des lexiques d&#8217;opinion, une
premi&#232;re voie pour aborder le probl&#232;me de la d&#233;pendance par rapport au domaine en mati&#232;re
de fouille d&#8217;opinion consiste &#224; d&#233;finir des capacit&#233;s d&#8217;adaptation automatique de ces lexiques &#224;
un domaine donn&#233;. Dans cette optique, Jijkoun et al. (2010) proposent d&#8217;adapter un lexique
d&#8217;opinion g&#233;n&#233;ral &#224; un domaine sp&#233;cifique en caract&#233;risant les termes de ce lexique par des
profils de contextes syntaxiques obtenus &#224; partir d&#8217;un corpus g&#233;n&#233;ral. Ces profils sont ensuite
utilis&#233;s pour identifier les termes porteurs d&#8217;opinion pertinents pour ce domaine &#224; partir de
corpus repr&#233;sentatifs de celui-ci. Gindl et al. (2010) adaptent pour leur part un lexique d&#8217;opinion
en fonction du domaine consid&#233;r&#233; en supprimant les termes de ce lexique dont la polarit&#233; varie
selon le contexte.
Outre l&#8217;utilisation de lexiques d&#8217;opinion, la d&#233;termination de la polarit&#233; d&#8217;un texte peut b&#233;n&#233;ficier
de l&#8217;utilisation de corpus annot&#233;s. La d&#233;pendance de ceux-ci par rapport &#224; un domaine donn&#233;
rend n&#233;anmoins leur usage d&#233;licat et conduit &#224; d&#233;finir diff&#233;rentes approches pour compenser
cette d&#233;pendance. Denecke (2009) associent ainsi le lexique g&#233;n&#233;ral SENTIWORDNET et un corpus
d&#8217;entra&#238;nement relevant de diff&#233;rents domaines autres que le domaine cible pour classer des
textes comme subjectifs ou objectifs. Pour la m&#234;me t&#226;che, Aue et Gamon (2005) s&#8217;affranchissent
de lexiques d&#8217;opinion et comparent diff&#233;rentes approches utilisant des corpus d&#8217;apprentissage
d&#8217;un domaine autre que le domaine cible. La disponibilit&#233; de corpus annot&#233;s relevant de diff&#233;-
rents domaines est ainsi un &#233;l&#233;ment clef dans la t&#226;che de classification de textes d&#8217;un nouveau
domaine. Blitzer et al. (2007) construisent un tel corpus, le Multi-domain Sentiment Dataset
(MDSD), en s&#8217;appuyant pour minimiser les co&#251;ts d&#8217;annotation sur les critiques r&#233;dig&#233;es sur le site
AMAZON portant sur des objets vari&#233;s appartenant &#224; 25 grands domaines. Par ailleurs, Blitzer et al.
(2007) proposent &#233;galement de chercher des correspondances entre domaines par la technique
du Structural Correspondence Learning (SCL) en s&#8217;appuyant sur des traits et des pr&#233;dicteurs
pivots. Li et Zong (2008) r&#233;utilisent ce corpus et proposent deux approches. L&#8217;approche par
fusion de traits (ou feature fusion) se fonde sur le regroupement des corpus d&#8217;apprentissage
de diff&#233;rents domaines en un seul. L&#8217;approche par fusion de classifieurs (ou classifier fusion)
consiste &#224; construire autant de classifieurs que de domaines sources disponibles et &#224; entra&#238;ner un
classifieur (un m&#233;ta-classifieur) sur les sorties de ces mod&#232;les.
Quelle que soit la m&#233;thode, les performances obtenues pour des textes relevant d&#8217;un nouveau
domaine cible sont moins bonnes que celles obtenues en disposant de donn&#233;es annot&#233;es dans le
</p>
<p>393</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>domaine cible. Pour r&#233;duire le co&#251;t de cette annotation, des approches dites d&#8217;Active learning ont
&#233;t&#233; propos&#233;es. L&#8217;id&#233;e est de d&#233;tecter les exemples class&#233;s avec un faible score de confiance par le
mod&#232;le, d&#8217;annoter ces exemples manuellement et d&#8217;int&#233;grer ces nouvelles donn&#233;es aux donn&#233;es
d&#8217;apprentissage. Si ces m&#233;thodes permettent de limiter la quantit&#233; d&#8217;annotation manuelle &#224; effec-
tuer, elles restent tout de m&#234;me co&#251;teuses. De ce fait, des m&#233;thodes dites d&#8217;auto-apprentissage
(self-training) proposent, &#224; l&#8217;image de (Drury et al., 2011), de s&#8217;appuyer sur des donn&#233;es non
annot&#233;es manuellement mais class&#233;es avec un fort score de confiance par un classifieur pour
enrichir le corpus d&#8217;apprentissage de ce dernier et &#233;largir ainsi sa couverture. C&#8217;est l&#8217;approche
que nous privil&#233;gierons ici en la transposant au cas de textes appartenant &#224; d&#8217;autres domaines.
</p>
<p>3 Strat&#233;gies d&#8217;adaptation
</p>
<p>L&#8217;&#233;tude que nous pr&#233;sentons dans cet article aborde la classification de textes en termes de
polarit&#233; positive ou n&#233;gative selon une approche supervis&#233;e fond&#233;e sur un corpus d&#8217;entra&#238;nement
annot&#233; manuellement, sans s&#8217;appuyer sur un lexique d&#8217;opinion constitu&#233; a priori. Dans ce cadre,
qui reprend celui de (Blitzer et al., 2007) et de (Li et Zong, 2008), son objectif est de d&#233;terminer,
partant de corpus d&#8217;entra&#238;nement dans un ou plusieurs domaines sources et d&#8217;un corpus non
annot&#233; dans un domaine cible (corpus dit de d&#233;veloppement), la strat&#233;gie la plus adapt&#233;e de
constitution d&#8217;un nouveau corpus d&#8217;entra&#238;nement &#224; partir de ces corpus disponibles afin d&#8217;obtenir
les meilleures performances possibles sur le domaine cible. Les diff&#233;rentes strat&#233;gies consid&#233;r&#233;es
se diff&#233;rencient selon deux facteurs principaux : l&#8217;utilisation de corpus appartenant &#224; un seul ou &#224;
plusieurs domaines sources ; l&#8217;utilisation ou non d&#8217;un corpus du domaine cible non annot&#233;. Nous
avons plus pr&#233;cis&#233;ment test&#233; les strat&#233;gies suivantes, chacune reposant sur le m&#234;me volume de
textes annot&#233;s manuellement pour constituer leur corpus d&#8217;entra&#238;nement :
</p>
<p>Un corpus source [BASELINE] Cette strat&#233;gie baseline utilise un corpus annot&#233; d&#8217;un unique
domaine source autre que le domaine cible.
Apprentissage it&#233;ratif &#224; partir d&#8217;un corpus source [ITE-FIXE, ITE-SEUIL] Dans cette approche,
nous entra&#238;nons un mod&#232;le sur un seul corpus source, comme pr&#233;c&#233;demment, classifions les textes
du corpus du domaine cible, s&#233;lectionnons les exemples ayant le meilleur score de confiance et
int&#233;grons ces exemples au corpus d&#8217;entra&#238;nement. Cette boucle est r&#233;it&#233;r&#233;e jusqu&#8217;&#224; &#233;puisement
du corpus du domaine cible. La s&#233;lection des meilleurs exemples peut se faire en fonction d&#8217;un
seuil sur le score de confiance (approche dite ITE-SEUIL) ou bien en fonction d&#8217;un nombre fixe
d&#8217;exemples int&#233;gr&#233;s &#224; chaque it&#233;ration (ITE-FIXE).
Plusieurs corpus sources [MULTI-DOMAINE] Dans cette configuration, les corpus de plusieurs
domaines sources sont associ&#233;s pour construire le corpus d&#8217;entra&#238;nement. Nous prenons ici tous
les domaines sources, ce qui repr&#233;sente une autre forme de baseline.
M&#233;thode par vote [MULTI-VOTE] Dans cette strat&#233;gie, elle aussi classique, nous entra&#238;nons un
mod&#232;le par corpus source et proc&#233;dons &#224; une classification finale par vote : un exemple donn&#233;
est ainsi class&#233; en fonction de la d&#233;cision majoritaire observ&#233;e parmi les classifieurs associ&#233;s &#224;
chaque domaine source.
Apprentissage it&#233;ratif &#224; partir de plusieurs corpus sources [ITE-MULTI-VOTE] Cette strat&#233;gie
est une hybridation de la m&#233;thode par vote et de l&#8217;apprentissage it&#233;ratif. &#192; partir d&#8217;un corpus
source, nous entra&#238;nons plusieurs mod&#232;les (un par domaine source) ; puis nous s&#233;lectionnons les
meilleurs exemples qui sont ensuite int&#233;gr&#233;s dans chacun des corpus sources de d&#233;part. Nous
s&#233;lectionnons alors les exemples class&#233;s unanimement par tous les mod&#232;les.
</p>
<p>394</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4 Mise en &#339;uvre et r&#233;sultats
</p>
<p>Nos exp&#233;riences ont &#233;t&#233; men&#233;es sur le corpus MDSD &#233;voqu&#233; pr&#233;c&#233;demment, corpus compos&#233; de
critiques portant sur des produits vari&#233;s et tri&#233;es par domaine (livre, cuisine et articles m&#233;nagers,
v&#234;tements . . .). Une critique est compos&#233;e d&#8217;un texte, d&#8217;un titre et d&#8217;une note. Les textes sont
courts, quelques phrases seulement, et r&#233;dig&#233;s en anglais. Les notes varient de 1 &#224; 5, 1 indiquant
l&#8217;avis le plus n&#233;gatif sur le produit et 5 l&#8217;avis le plus positif. L&#8217;exemple pr&#233;sent&#233; &#224; la figure 1 est
une critique issue du sous-corpus &quot;Book&quot;. Nous avons utilis&#233; la m&#234;me configuration de donn&#233;es
</p>
<p>&lt;review&gt;
( . . . )
&lt;r a t i n g&gt;5.0&lt;/ r a t i n g&gt;
&lt;rev iew_tex t&gt;
</p>
<p>I read Les Mis&#233; r a b l e s a f t e r I saw the opera , and i t has i n s p i r e d
in me more than any book I &#8217;ve ever read . I don&#8217; t b e l i e v e one
could ever f ind a b e t t e r novel anywhere . For everyone ( . . . )
</p>
<p>&lt;/ rev iew_tex t&gt;
&lt;/ review&gt;
</p>
<p>FIG. 1 &#8211; Exemple de critique issue du MDSD relevant du domaine BOO
</p>
<p>que celle de (Blitzer et al., 2007) afin de pouvoir comparer nos r&#233;sultats aux leurs &#224; la diff&#233;rence
pr&#232;s que les corpus de test ont &#233;t&#233; scind&#233;s en corpus de d&#233;veloppement et corpus de test. Le
tableau 1 pr&#233;sente une description g&#233;n&#233;rale du corpus utilis&#233;, organis&#233; en quatre domaines. Les
donn&#233;es d&#8217;apprentissage sont &#233;quilibr&#233;es entre critiques positives et n&#233;gatives1 et sont pr&#233;sentes
en m&#234;me quantit&#233; dans les quatre domaines.
</p>
<p>Corpus d&#8217;entra&#238;nement Corpus de d&#233;veloppement Corpus de test
Domaine #critiques #formes/critiques # critiques # critiques
Cuisine &amp; articles m&#233;nagers (KIT) 2 000 96 2 000 3 945
Livres (BOO) 2 000 174 2 000 2 465
DVD (DVD) 2 000 189 2 000 3 945
Mat&#233;riel &#233;lectronique (ELE) 2 000 113 2 000 3 945
</p>
<p>TAB. 1 &#8211; Description g&#233;n&#233;rale du corpus
</p>
<p>&#192; l&#8217;instar de (Torres-Moreno et al., 2007), nous avons utilis&#233; un mod&#232;le de classification &#224; base
de boosting pour effectuer nos tests, mod&#232;le mise en &#339;uvre gr&#226;ce &#224; l&#8217;outil BoosTexter (Shapire
et Singer, 2000). Le mod&#232;le produit est compos&#233; d&#8217;un ensemble de r&#232;gles binaires (ou weak
learners) portant chacune sur la pr&#233;sence d&#8217;un n-gramme et se voyant associer une probabilit&#233;
par rapport &#224; chaque classe consid&#233;r&#233;e. Lors de la phase de classification, un score est calcul&#233;
pour chaque classe en fonction des r&#232;gles d&#233;clench&#233;es par le texte trait&#233; et la classe de plus
haut score est attribu&#233;e au texte. La configuration utilis&#233;e a &#233;t&#233; s&#233;lectionn&#233;e empiriquement en
optimisant les param&#232;tres pour notre approche baseline. Le nombre de tours a ainsi &#233;t&#233; fix&#233; &#224;
50. Les r&#232;gles utilisent des n-grammes de taille 1 et les textes ne sont pas lemmatis&#233;s.
</p>
<p>Les r&#233;sultats de classification sont donn&#233;s en termes d&#8217;exactitude (accuracy) afin de pouvoir
comparer nos r&#233;sultats avec ceux de (Blitzer et al., 2007). Le tableau 2 pr&#233;sente les r&#233;sultats pour
</p>
<p>1Comme Blitzer, nous consid&#233;rons une critique comme positive si sa note est &gt; 3 et n&#233;gative si elle est &lt; 3.
</p>
<p>395</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>l&#8217;ensemble des approches. Si l&#8217;on se concentre en premier lieu sur les strat&#233;gies ne mettant en jeu
qu&#8217;un seul domaine source, on peut observer que l&#8217;approche baseline donne des exactitudes
sup&#233;rieures &#224; 70% quels que soient les domaines d&#8217;entra&#238;nement (TRN) et les domaines de test
(TEST). L&#8217;approche ite-fixe est simple mais ne prend pas en compte le score de confiance
donn&#233; par BoosTexter. Elle ne dispose donc pas de crit&#232;re naturel d&#8217;arr&#234;t de prise en compte
de nouveaux exemples, ce qui la conduit &#224; &#171; consommer &#187; tout le corpus de d&#233;veloppement.
Elle obtient en pratique des performances tr&#232;s inf&#233;rieures &#224; celles de baseline et se r&#233;v&#232;le
&#234;tre la moins bonne de nos strat&#233;gies. La prise en compte du score de confiance de BoosTexter
(approche ite-seuil) donne en revanche la meilleure exactitude (not&#233;e par &#8727;) pour la plupart
des couples (domaine source, domaine cible). Il est &#224; noter que les cas o&#249; cette approche ne
donne pas de meilleurs r&#233;sultats que baseline font tous intervenir les donn&#233;es du domaine
ELE (mat&#233;riel &#233;lectronique).
</p>
<p>TRN TEST baseline ite-fixe ite-seuil multi-domaine multi-vote ite-multi-vote
DVD BOO 79,7 48,8 84,4&#8727;
</p>
<p>68,1 69,6 75,6&#8224;ELE BOO 75,4 41,6 79,3&#8727;
KIT BOO 70,9 38,1 81,8&#8727;
BOO DVD 77,2 69,5 82,0&#8727;
</p>
<p>72,2 70,3 81,4&#8224;ELE DVD 76,2 54,3 73,4
KIT DVD 76,9 54,0 78,2&#8727;
BOO ELE 77,5&#8727; 64,5 65,5
</p>
<p>69,1 64,7 77,5&#8224;DVD ELE 74,1&#8727; 69,7 62,2
KIT ELE 86,8&#8727; 60,4 75,7
BOO KIT 78,9 68,4 82,7&#8727;
</p>
<p>75,4 71,0 81,4&#8224;DVD KIT 81,4 61,1 82,3&#8727;
ELE KIT 85,9 65,6 78,7
</p>
<p>TAB. 2 &#8211; R&#233;sultats en termes d&#8217;exactitude pour l&#8217;ensemble des approches
</p>
<p>Les r&#233;sultats des strat&#233;gies utilisant des donn&#233;es annot&#233;es relevant de plusieurs domaines sont
pr&#233;sent&#233;s dans les 3 derni&#232;res colonnes du tableau 2. L&#8217;approche multi-domaine constitue dans
ce cas notre baseline. La comparaison de ses r&#233;sultats avec ceux de l&#8217;approche baseline (un
unique domaine source) est clairement en d&#233;faveur de l&#8217;approche multi-domaine dans tous les
cas de figure. Ce constat tend &#224; montrer qu&#8217;utiliser un corpus d&#8217;entra&#238;nement compos&#233; de donn&#233;es
sources h&#233;t&#233;rog&#232;nes du point de vue th&#233;matique (approche multi-domaine) est une moins
bonne option pour classer des textes dans un domaine cible qu&#8217;utiliser un corpus d&#8217;entra&#238;nement
source th&#233;matiquement homog&#232;ne. Il est n&#233;anmoins possible qu&#8217;une telle observation soit &#224;
nuancer en fonction de la taille des corpus et du nombre de domaines. L&#8217;approche par vote
(multi-vote) ne permet pas quant &#224; elle d&#8217;obtenir une performance de classification plus
&#233;lev&#233;e que la baseline. Cette approche, tout comme l&#8217;approche ite-fixe, ne prend pas en
compte le score de confiance accord&#233; par le mod&#232;le lors de la classification et le fait que la
majorit&#233; des mod&#232;les cat&#233;gorisent un exemple dans une classe donn&#233;e n&#8217;est apparemment
pas un indice suffisant pour compenser cette insuffisance. Cependant, l&#224; encore, le nombre
de domaines consid&#233;r&#233;s peut avoir une influence. L&#8217;approche ite-multi-vote est celle des
trois approches utilisant plusieurs corpus annot&#233;s donnant les meilleurs r&#233;sultats (not&#233;s par
&#8224;) et ce, quel que soit le domaine cible. La m&#233;thode d&#8217;apprentissage it&#233;rative se r&#233;v&#232;le donc
particuli&#232;rement int&#233;ressante dans ce cas de figure comme elle l&#8217;est dans le cas d&#8217;un domaine
source unique. L&#8217;exactitude moyenne de ite-multi-vote, &#233;gale &#224; 79,0, est m&#234;me l&#233;g&#232;rement
sup&#233;rieure &#224; l&#8217;exactitude moyenne de ite-seuil, &#233;gale &#224; 77,2, en particulier du fait d&#8217;un
</p>
<p>396</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>meilleur comportement pour le domaine cible ELE.
</p>
<p>FIG. 2 &#8211; Exactitude obtenue par les approches utilisant un seul domaine d&#8217;apprentissage2
</p>
<p>La figure 2 propose une comparaison de nos r&#233;sultats avec ceux de (Blitzer et al., 2007). Les
barres horizontales pleines indiquent l&#8217;exactitude obtenue par une approche intra-domaine (les
corpus source et cible rel&#232;vent du m&#234;me domaine). Les barres horizontales pointill&#233;es indiquent
l&#8217;exactitude obtenue par notre approche baseline. Pour chaque couple de domaines sources et
cibles sont indiqu&#233;s nos r&#233;sultats ainsi que ceux de Blitzer. On peut observer que notre meilleure
approche (ite-seuil) obtient de meilleurs r&#233;sultats que ceux de Blitzer en dehors du domaine
ELE (qu&#8217;il soit source ou cible). L&#8217;approche propos&#233;e dans (Blitzer et al., 2007) permet de mettre
en correspondance des termes suppos&#233;s &#233;quivalents d&#8217;un domaine &#224; un autre, termes prenant la
forme de n-grammes tels que must read (BOO) ou excellent product (KIT). Il semble n&#233;anmoins
que ces correspondances concernent essentiellement des termes constitu&#233;s de mots pleins. Nous
expliquons la performance de notre approche par le fait que nos mod&#232;les ne favorisent pas un
type d&#8217;unit&#233;s plut&#244;t qu&#8217;un autre, ce qui leur permet d&#8217;utiliser aussi bien des mots outils, qui
se retrouvent dans tous les domaines, que des mots pleins, plus sp&#233;cifiques &#224; un domaine. Or
les mots outils jouent un r&#244;le dans l&#8217;expression des opinions puisqu&#8217;ils permettent notamment
d&#8217;exprimer la n&#233;gation et l&#8217;intensit&#233; (Taboada et al., 2011).
</p>
<p>5 Conclusion et perspectives
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; une &#233;tude sur diff&#233;rentes strat&#233;gies possibles pour construire
un classifieur statistique pour un domaine cible en ne disposant de donn&#233;es annot&#233;es pour son
entra&#238;nement que pour un ou plusieurs autres domaines. Nous avons en particulier montr&#233;
l&#8217;efficacit&#233; pour cette t&#226;che d&#8217;une strat&#233;gie d&#8217;apprentissage it&#233;ratif assimilable &#224; une forme d&#8217;auto-
apprentissage et consistant &#224; incorporer progressivement dans le corpus d&#8217;entra&#238;nement du
classifieur les textes d&#8217;un corpus du domaine cible que ce classifieur annote avec la plus grande
confiance. Cette strat&#233;gie se r&#233;v&#232;le m&#234;me dans un nombre significatif de cas plus efficace que la
m&#233;thode pr&#233;sent&#233;e dans (Blitzer et al., 2007) tout en &#233;tant plus simple. Une des prolongations
les plus imm&#233;diates de ce travail est sa g&#233;n&#233;ralisation &#224; d&#8217;autres types de classifieurs que le
</p>
<p>2L&#8217;approche intra-domaine correspond &#224; la m&#234;me configuration que notre approche BASELINE &#224; la diff&#233;rence que les
corpus d&#8217;entra&#238;nement et de test rel&#232;vent du m&#234;me domaine.
</p>
<p>397</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>boosting utilis&#233; ici. Au-del&#224;, nous envisageons la transposition &#224; notre contexte inter-domaine de
la d&#233;marche d&#8217;auto-apprentissage pr&#233;sent&#233;e dans (Wiebe et Riloff, 2005), d&#233;marche fond&#233;e sur
l&#8217;utilisation d&#8217;un classifieur suppl&#233;mentaire, de nature diff&#233;rente du classifieur initial, pour la
constitution non supervis&#233;e du corpus d&#8217;entra&#238;nement.
</p>
<p>Remerciements
</p>
<p>Ce travail a &#233;t&#233; financ&#233; par la Fondation Jean-Luc Lagard&#232;re. Nous tenons &#233;galement &#224; remercier
Morgane Marchand et Romaric Besan&#231;on pour leur contribution aux pr&#233;mices de ce travail.
</p>
<p>R&#233;f&#233;rences
</p>
<p>AUE, A. et GAMON, M. (2005). Customizing sentiment classifiers to new domains : a case study.
In RANLP 2005.
</p>
<p>BLITZER, J., DREDZE, M. et PEREIRA, F. (2007). Biographies, Bollywood, Boom-boxes and Blenders :
Domain Adaptation for Sentiment Classification. In ACL 2007, Prague, Czech Republic.
</p>
<p>CHOI, Y. et CARDIE, C. (2009). Adapting a Polarity Lexicon using Integer Linear Programming
for Domain-Specific Sentiment Classification. In EMNLP 2009, pages 590&#8211;598, Singapore.
</p>
<p>DENECKE, K. (2009). Are SentiWordNet scores suited for multi-domain sentiment classification ?
In 4th International Conference on Digital Information Management (ICDIM 2009), pages 1&#8211;6.
</p>
<p>DRURY, B., TORGO, L. et ALMEIDA, J. J. (2011). Guided self training for sentiment classification.
In Workshop on Robust Unsupervised and Semisupervised Methods in Natural Language Processing.
</p>
<p>ESULI, A. et SEBASTIANI, F. (2006). SentiWordNet : A Publicly Available Lexical Resource for
Opinion Mining. In 5th Conference on Language Resources and Evaluation (LREC 2006).
</p>
<p>GINDL, S., WEICHSELBRAUN, A. et SCHARL, A. (2010). Cross-Domain Contextualization of Senti-
ment Lexicons. In 19th European Conference on Artificial Intelligence, pages 771&#8211;776.
</p>
<p>HARB, A., DRAY, G., PLANTI&#201;, M., PONCELET, P., ROCHE, M. et TROUSSET, F. (2008). D&#233;tection
d&#8217;opinion : Apprenons les bons adjectifs ! In INFORSID&#8217;08 - Atelier FODOP&#8217;08, pages 59&#8211;66.
</p>
<p>JIJKOUN, V., de RIJKE, M. et WEERKAMP, W. (2010). Generating focused topic-specific sentiment
lexicons. In 48th Annual Meeting of the Association for Computational Linguistics, pages 585&#8211;594.
</p>
<p>LI, S. et ZONG, C. (2008). Multi-domain sentiment classification. In 46th Annual Meeting of the
Association for Computational Linguistics on Human Language Technologies, pages 257&#8211;260.
</p>
<p>SHAPIRE, R. E. et SINGER, Y. (2000). BoosTexter : A boosting-based system for text categorization.
Machine Learning, 39(1):135&#8211;168.
</p>
<p>TABOADA, M., BROOKE, J., TOFILOSKI, M., VOLL, K. et STEDE, M. (2011). Lexicon-based methods
for sentiment analysis. Computational Linguistics, 37(2):267&#8211;307.
</p>
<p>TORRES-MORENO, J.-M., EL-B&#200;ZE, M., B&#201;CHET, F. et CAMELIN, N. (2007). Comment faire pour que
l&#8217;opinion forg&#233;e &#224; la sortie des urnes soit la bonne ? Application au d&#233;fi DEFT 2007. In Atelier
DEFT&#8217;07 - Plate-forme AFIA 2007, Grenoble, France.
</p>
<p>WIEBE, J. et RILOFF, E. (2005). Creating subjective and objective sentence classifiers from
unannotated texts. In CICLing-2005.
</p>
<p>398</p>

</div></div>
</body></html>