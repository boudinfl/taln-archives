<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Le Lexicoscope : un outil pour l'&#233;tude de profils combinatoires et l'extraction de constructions lexico-syntaxiques</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 399&#8211;406,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Le Lexicoscope : un outil pour l'&#233;tude de profls 
combinatoires et l'extraction de constructions 
</p>
<p>lexico-syntaxiques
</p>
<p>Olivier Kraif 1, Sascha Diwersy 2
(1) LIDILEM, Universit&#233; Stendhal Grenoble 3, BP 25, 38040 Grenoble Cedex
</p>
<p>(2) Universit&#233; de Cologne
olivier.kraif@u-grenoble3.fr, sascha.diwersy@uni-koeln.de
</p>
<p>R&#201;SUM&#201;_________________________________________________________________________
Dans  le  cadre  du  projet  franco-allemand  Emolex,  d&#233;di&#233;  &#224;  l'&#233;tude  contrastive  de  la 
combinatoire du lexique des &#233;motions en 5 langues, nous avons d&#233;velopp&#233; des outils et 
des  m&#233;thodes  permettant  l'extraction,  la  visualisation  et  la  comparaison  de  profls 
combinatoires  pour  des  expressions  simples  et  complexes.  Nous  pr&#233;sentons  ici 
l'architecture d'ensemble de la plate-forme, con&#231;ue pour efectuer des extractions sur des 
corpus de grandes dimensions (de l'ordre de la centaine de millions de mots) avec des 
temps  de  r&#233;ponse  r&#233;duits  (le  corpus  &#233;tant  interrogeable  en  ligne1).  Nous  d&#233;crivons 
comment nous avons introduit  la notion de pivots  complexes,  afn de permettre aux 
utilisateurs de rafner progressivement leurs requ&#234;tes pour caract&#233;riser des constructions 
lexico-syntaxiques  &#233;labor&#233;es.  Enfn,  nous donnons les  premiers  r&#233;sultats  d'un module 
d'extraction automatique d'expressions polylexicales r&#233;currentes.
ABSTRACT_______________________________________________________________________
The Lexicoscope  :  an integrated tool  for combinatoric  profles  observation and 
lexico-syntactic constructs extraction.
The German-French research project Emolex whose aim is the contrastive study of the 
combinatorial behaviour of emotion lexemes in 5 languages has led to the development 
of  methods  and  tools  to  extract,  display  and  compare  the  combinatorial  profles  of 
simple and complex expressions. In this paper, we present the overall architecture of the 
query  platform  which  has  been  conceived  to  ensure  efcient  processing  of  huge 
annotated text corpora (consisting of several hundred millions of word tokens) accessible 
through a web-based interface. We put forward the concept of &#8220;complex query nodes&#8221; 
introduced  to  enable  users  to  carry  out  progressively  elaborated  extractions  of 
lexical-syntactic patterns. We fnally give primary results of an automated method for 
the retrieval of recurrent multi-word expressions, which takes advantage of the complex 
query nodes implementation.
MOTS-CL&#201;S : collocations,  cooccurrences,  profl  combinatoire,  expressions  polylexicales, 
lexique des &#233;motions.
KEYWORDS : collocations, combinatorial profles, multi-word expressions.
1 L'acc&#232;s au corpus sera rendu public, moyennant authentifcation, d'ici quelques mois.
</p>
<p>399</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
Cette  communication  pr&#233;sente  des  travaux  r&#233;alis&#233;s  dans  le  cadre  du  projet  Emolex,  
projet franco-allemand cofnanc&#233; par l'ANR et la DFG. Dans le cadre de cette recherche, 
nous avons rassembl&#233; des corpus massifs comportant plusieurs centaines de millions de 
mots pour 5 langues dif&#233;rentes (l'allemand, le fran&#231;ais, l'anglais, l'espagnol et le russe). 
L'objectif du projet est d'analyser, dans une perspective formul&#233;e par Sinclair (2004) ou 
encore Hoey (2005) et d'un point de vue contrastif, les valeurs s&#233;mantiques et les r&#244;les 
discursifs  &#224;  partir  de  la  combinatoire  du  lexique  des  &#233;motions,  afn  d'&#233;laborer  une 
cartographie permettant de mieux structurer ce champ lexical, avec des applications en 
lexicographie mais aussi en didactique des langues et traductologie. Cette &#233;tude porte 
plus pr&#233;cis&#233;ment sur le d&#233;veloppement d'une approche automatis&#233;e permettant de guider 
l'observation linguistique par l'extraction de cooccurrences autour d'un pivot.
</p>
<p>2 Un mod&#232;le de cooccurrence fexible
Pour  caract&#233;riser  le  profl  combinatoire  d'une  entr&#233;e,  nous  reprenons  le  concept  de 
lexicogramme, introduit par Maurice Tournier et repris dans le logiciel WebLex (Heiden, 
Tournier 1998) : il s'agit d'&#233;tablir, pour un pivot donn&#233;, la liste de ses cooccurrents les 
plus  fr&#233;quents,  &#224;  gauche  et  &#224;  droite,  en  faisant  l'extraction  des  fr&#233;quences  de 
cooccurrence et en calculant des mesures d'association statistiques (telles que rapport de 
vraisemblance  ou  t-score).  Pour  construire  ces  lexicogrammes,  nous  proposons  un 
mod&#232;le de cooccurrence fexible permettant &#224; l'utilisateur de d&#233;fnir lui-m&#234;me les unit&#233;s  
de cooccurrences  :   formes,  lemmes, cat&#233;gories  morphosyntaxiques,  traits  additionnels 
(p.ex.  s&#233;mantiques),  relations  syntaxiques  (dans  le  cas  des  colligations)  ou  des 
combinaisons de ces informations. La possibilit&#233; de faire intervenir des combinaisons de 
ses traits nous semble importante pour permettre &#224; l'utilisateur d'ajuster la focale de ses  
observations  en  allant  du  g&#233;n&#233;ral  au  particulier  (ou  vice-versa),  de  pr&#233;ciser  des 
contraintes pour d&#233;sambigu&#239;ser certains contextes, et de combiner les aspects lexicaux et 
syntaxiques  dans  ses  observations.  Par  ailleurs  nous  proposons  &#233;galement  une 
caract&#233;risation  fexible  de  l'espace  de  cooccurrence,  qui  conditionne  les  points  de 
rencontre entre pivot et collocatifs, ainsi que la mani&#232;re de les d&#233;nombrer. On peut par 
exemple d&#233;fnir la cooccurrence &#224; l'int&#233;rieur d'un empan de largeur fxe, &#233;ventuellement 
dif&#233;rente &#224; droite et &#224; gauche du pivot. Mais on peut aussi rechercher la  cooccurrence  
syntaxique, &#224; l'instar de Kilgarif et Tugwell (2001) ou Charest et al. (2010), mise en jeu 
lorsqu'une relation fonctionnelle (du type sujet, compl&#233;ment d'objet, modifeur, etc.) a 
&#233;t&#233; identif&#233;e entre deux unit&#233;s. Evert (2007), signale l'int&#233;r&#234;t de ce type de cooccurrence 
en terme de bruit et de silence : &quot;(...)  unlike surface cooccurrence, it does not set an 
arbitrary  distance  limit,  but  at  the  same  time  introduces  less  &#8220;noise&#8221;  than  textual 
cooccurrence&quot;.  Pour  la  cooccurrence  syntaxique,  nous  exploitons  les  relations  de 
d&#233;pendances obtenues gr&#226;ce &#224; dif&#233;rents analyseurs : XIP pour l'anglais (A&#239;t-Mokhtar et 
al. 2001), Connexor pour l'allemand, le fran&#231;ais et l'espagnol (Tapanainen &amp; J&#228;rvinen 
1997), DeSR pour le russe (Attardi et al. 2007), bas&#233; sur un mod&#232;le stochastique cr&#233;&#233; &#224; 
partir  du  corpus arbor&#233; SyntagRus (Nivre  et  al., 2008).  Un post-traitement a  permis 
d'harmoniser  et  de  standardiser  l'annotation  des  relations  de  d&#233;pendance  entre  les 
</p>
<p>400</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>langues (l'annotation de Connexor ayant servi de r&#233;f&#233;rence). Nous avons par la suite 
compl&#233;t&#233;  ces  relations  pour  obtenir  des  d&#233;pendances  plus  pertinentes  sur  le  plan 
s&#233;mantique (p. ex. sujet profond dans les constructions passives, etc.).
Avec le mod&#232;le de cooccurrence ainsi d&#233;fni, on peut viser des aspects tr&#232;s g&#233;n&#233;riques de 
la combinatoire (par exemple : quels sont les principaux collocatifs de la forme surprise 
toutes relations confondues) ou beaucoup plus sp&#233;cifques et circonscrits (par exemple : 
quels sont les principaux collocatifs verbaux &#224; l'imparfait du nom lemmatis&#233; surprise en 
tant qu'objet direct). Le tableau 1 montre un tel lexicogramme :
</p>
<p>l1 l2 f f1 f2 loglike
surprise_N cr&#233;er_V 614 2098 21658 4548,43
surprise_N r&#233;server_V 230 2098 2869 2143,50
surprise_N avoir_V 484 2098 423602 627,50
surprise_N constituer_V 94 2098 13778 406,80
surprise_N &#233;viter_V 43 2098 16296 109,30
surprise_N manifester_V 22 2098 2424 106,62
surprise_N causer_V 19 2098 2210 90,06
surprise_N m&#233;nager_V 15 2098 1495 75,58
surprise_N exprimer_V 23 2098 6186 72,54
surprise_N provoquer_V 23 2098 10551 50,61
surprise_N feindre_V 9 2098 676 50,31
TABLEAU 1 : extrait du lexicogramme pour le nom lemmatis&#233; surprise pris en tant qu'objet 
</p>
<p>direct (f=fr&#233;quence de cooccurrence, f1=fr&#233;quence de l1, f2=fr&#233;quence de l2)
</p>
<p>3 Visualisations comparatives
A partir de ces lexicogrammes, nous ofrons dif&#233;rentes modalit&#233;s d'exploration : 
&#8211; pour l'analyse linguistique, le &quot;retour au texte&quot; est indispensable : un simple clic sur 
</p>
<p>un collocatif permet de retrouver, sous forme de concordance, tous les contextes de 
cooccurrence avec le pivot.
</p>
<p>&#8211; pour comparer de mani&#232;re synth&#233;tique divers profls combinatoires, nous proposons 
d'identifer les lexicogrammes &#224; des points dans un espace vectoriel, en ne retenant 
que la mesure jug&#233;e la plus pertinente (fr&#233;quence, loglike, t-score, etc.). Il est d&#232;s 
lors  possible  d'utiliser  des  m&#233;thodes  d'analyse  de  donn&#233;es  pour  visualiser  les 
similarit&#233;s  entre  pivots  :  analyse  factorielle  des  correspondances  (AFC), 
&#233;chelonnement multidimensionnel (MDS) ou classifcation hi&#233;rarchique ascendante 
(hClust). La fgure 1 montre ces sorties pour des unit&#233;s du domaine s&#233;mantique de la 
'col&#232;re' (obtenues gr&#226;ce aux modules du projet 'GNU R').  La classifcation, r&#233;alis&#233;e 
pour la relation &quot;objet&quot;, indique une hi&#233;rarchisation assez bien corr&#233;l&#233;e &#224; l'intensit&#233; 
du  sentiment.  Quant  &#224;  la  'factor  map',  r&#233;alis&#233;e  pour  des  relations  quelconques 
</p>
<p>401</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>concernant  des  collocatifs  adjectivaux,  elle  permet  de  distinguer  trois  groupes  : 
r&#233;volte, indignation - souvent li&#233; &#224; la sph&#232;re publique et politique ; fureur, rage, col&#232;re - 
li&#233; &#224; l'expression ponctuelle et plus ou moins intense de l'afect ; enfn &#233;nervement, 
irritation,  exasp&#233;ration - qui concernent plut&#244;t des &#233;tats &#233;motionnels pr&#233;curseurs de 
cette  manifestation.  Ces  cas  montrent  de  fa&#231;on assez  &#233;clairante  le  lien  entre  les 
valeurs s&#233;mantiques et la combinatoire lexico-syntaxique.
</p>
<p>FIGURE 1 : Classifcation hi&#233;rarchique et AFC (domaine s&#233;mantique de la 'col&#232;re')
</p>
<p>4 Architecture logicielle
Comment r&#233;pondre rapidement &#224; une requ&#234;te d'utilisateur lorsqu'on interroge des corpus 
contenant des centaines de millions d'occurrences ? La r&#233;ponse est simple,  a priori  : 
gr&#226;ce &#224; une indexation pr&#233;alable des unit&#233;s et des cooccurrences. Mais la difcult&#233; de 
notre syst&#232;me tient au fait que ni les unit&#233;s, ni l'espace de cooccurrence ne sont d&#233;fnis &#224; 
l'avance  :  on  peut  interroger  des  lemmes,  des  formes,  des  combinaisons 
lemmes-cat&#233;gories,  et  toute  combinaison  de  forme,  lemme,  cat&#233;gorie  et  traits  (ces 
derniers pouvant &#234;tre caract&#233;ris&#233;s par des expressions r&#233;guli&#232;res). En outre, l'espace de 
cooccurrence est &#233;tabli dynamiquement, au moment de la requ&#234;te, par des expressions 
r&#233;guli&#232;res d&#233;fnissant l'ensemble des relations &#224; prendre en compte.
Pour r&#233;pondre &#224; la double exigence de fexibilit&#233; et d'efcacit&#233;, nous avons &#233;labor&#233; une 
indexation  multi-niveaux, sous la forme de hachages  de hachages  s&#233;rialis&#233;s  :  chaque 
forme pointe vers l'ensemble des lemmes correspondants ; chaque lemme pointe vers 
l'ensemble de ses cat&#233;gories possibles (dans le corpus) ; chaque lemme-cat&#233;gorie pointe 
vers l'ensemble des traits associ&#233;s (dans le corpus) ; chaque lemme-cat&#233;gorie-traits pointe 
vers l'ensemble des  relations associ&#233;es ;  chaque lemme-cat&#233;gorie-traits-relation pointe 
vers  un  ensemble  de  paires  (collocatif,fr&#233;quence).  Les  expressions  r&#233;guli&#232;res  li&#233;es  au 
contraintes portant sur les cat&#233;gories, traits et relations sont appliqu&#233;es lors du parcours  
de l'index. Les ensembles de cat&#233;gories, traits et relations &#233;tant r&#233;duits (et ferm&#233;s) et le 
temps de recherche dans le hachage &#233;tant en O(1), la succession de ces recherches n'est 
</p>
<p>402</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>pas tr&#232;s couteuse.
En ce qui concerne l'impl&#233;mentation, nous avons opt&#233; pour le langage Perl, pour son 
traitement tr&#232;s efcace des expressions r&#233;guli&#232;res. Pour les index, nous avons test&#233; deux 
syst&#232;mes  de  bases  de  donn&#233;es  r&#233;put&#233;s  pour  leur  efcacit&#233;  :  BerkeleyDB  5.1.252 et 
KyotoCabinet 1.2.483. Les r&#233;sultats du tableau 3 montrent que le syst&#232;me qui est apparu 
le plus efcace pour nos requ&#234;tes &#233;tait celui de KyotoCabinet::BTree.
</p>
<p>Corpus presse (fr) 2007-
2008 (87 807 463 tokens)
</p>
<p>Taille 
des 
</p>
<p>index
</p>
<p>test 2
1 pivot
</p>
<p>test 2
5 pivots
</p>
<p>test 3
24 pivots
</p>
<p>BerkeleyDB:Hash 1800 Mo 125 s. / 1,3 s. 275 s. / 206 s. 892 s. / 766 s.
KyotoCabinet::Hash 1200 Mo 50 s. / 1 s. 376 s. / 180 s. 749 s. / 702 s.
KyotoCabinet::Btree 955 Mo 76 s. / 1.5 s. 247 s./ 231 s. 416 s. / 315 s.
</p>
<p>TABLEAU 2 : comparaison des tailles et des temps de r&#233;ponse pour dif&#233;rents types de DBM 
(le 2&#232;me temps est obtenu lorsqu'une requ&#234;te est imm&#233;diatement r&#233;it&#233;r&#233;e).
</p>
<p>Ces temps sont donn&#233;s &#224; titre de comparaison : ils ont &#233;t&#233; obtenus sur un PC ancien et 
assez lent. Sur notre mat&#233;riel actuel (Intel Core2 Quad CPU Q9550  2.83GHz, avec 4Go 
de RAM) nous obtenons des temps environ 4 fois sup&#233;rieurs. La dif&#233;rence importante 
entre le 1er et le 2&#232;me temps indique que ce sont les acc&#232;s disques qui p&#233;nalisent les  
traitements, car lorsque la DBM est en cache, la r&#233;ponse est presque instantan&#233;e. En 
utilisant un disque SSD ultra-rapide, nous pr&#233;voyons d'am&#233;liorer les temps de r&#233;ponse de 
mani&#232;re drastique.
</p>
<p>5 Prise en compte des pivots multimots
L'aspect exclusivement binaire des relations de d&#233;pendance directe peut aboutir &#224; un 
r&#233;tr&#233;cissement  du  contexte  des  observations  et  faire  manquer  des  ph&#233;nom&#232;nes 
int&#233;ressants  sur  le  plan  phras&#233;ologique.  Ces  limitations  emp&#234;chent  notamment 
l&#8217;extraction automatique de s&#233;quences polylexicales &#224; valeur d&#8217;unit&#233; minimale de sens 
(les  &#171;  meaning  units  &#187;  selon  Sinclair  2004),  qui  peuvent  pr&#233;senter  une  variabilit&#233; 
consid&#233;rable sur le plan de l&#8217;expression.
Cependant, en ce qui concerne les &#171; collocations lexicales &#187;, Tutin (2008) afrme que la 
plupart d'entre elles ont une structure binaire, m&#234;me pour celles qui s'&#233;tendent &#224; plus de 
deux  &#233;l&#233;ments,  car  elles  correspondent  s&#233;mantiquement  &#224;  une  structure 
pr&#233;dicat-argument : &quot;Collocations can be considered as predicate-argument structures, and as  
such,  are  prototypically  binary  associations,  where  the  predicate  is  the  collocate  and  the  
argument is the base. Most ternary (and over) collocations are merged collocations (collocational  
clusters) or recursive collocations.&quot;
</p>
<p>Et en efet, de nombreux travaux d&#233;di&#233;s &#224; l'extraction de collocations &#233;tendues &#224; plus de 
deux  mots  se  basent  en  fait  sur  des  mod&#232;les  binaires,  appliqu&#233;s  &#224;  deux  &#233;l&#233;ments 
compos&#233;s : collocation d'arbres syntaxiques (Charest et al., 2010), construction it&#233;rative 
2http://www.oracle.com/technetwork/database/berkeleydb/overview/index.html
3http://fallabs.com/kyotocabinet/
</p>
<p>403</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>de cooccurrence multimots &#224; partir de cooccurrences binaires (Seretan et al., 2003), ou 
encore  calcul  de  mesure  d'association  multimots  en  combinant  des  mesures  &#224;  deux 
termes.
De la  m&#234;me mani&#232;re,  il  est  possible  d'&#233;tendre  notre  architecture  pour  le  calcul  des 
lexicogrammes d'un pivot donn&#233;, en la g&#233;n&#233;ralisant &#224; des confgurations plus complexes : 
la solution consiste  &#224;  d&#233;fnir  le  pivot  non plus  seulement &#224;  partir  d'une forme prise 
isol&#233;ment, mais comme une forme associ&#233;e &#224; un certain contexte lexico-syntaxique. Une fois 
d&#233;termin&#233;  ce  contexte,  il  est  possible  de  calculer  le  tableau  de  contingence  comme 
pr&#233;c&#233;demment, le pivot et son contexte formant en quelque sorte une nouvelle unit&#233; 
pour laquelle il est possible de calculer &#224; la fois les fr&#233;quences de cooccurrence (en se 
basant sur les relations du pivot) et la fr&#233;quence marginale dans le corpus.
Pour l'&#233;criture des contextes, nous utilisons le formalisme de m&#233;ta-expressions r&#233;guli&#232;res 
propos&#233; par Kraif (2008).  Par exemple, pour rechercher le pattern V+ DET(poss.) + 
admiration_N + POUR, nous d&#233;fnissons le contexte suivant : 
</p>
<p>pivot : #1= admiration#N
contexte : &lt;l=son&gt; &lt;#1&gt; &amp;&amp; &lt;#2&gt; &amp;&amp; &lt;pour,#3&gt;::(.*,#1,#2)(.*,#2,#3)
</p>
<p>Le calcul est seulement un peu plus long &#224; mettre en &#339;uvre, car les pivots multimots  
n'&#233;tant pas connus a priori, il n'est pas possible de les indexer tels quels. Seuls les tokens  
(formes ou lemmes) composant le contexte, ainsi que les relations de d&#233;pendances entre 
deux tokens d&#233;fnis, sont index&#233;s, ce qui permet de r&#233;duire signifcativement l'ensemble 
des phrases &#224; analyser. Pour des expressions comportant plusieurs relations, comme c'est 
l'intersection des phrases index&#233;es pour chaque relation qui est retenue, la recherche est  
plus rapide : en d'autres termes, plus un pivot complexe est long, plus sa recherche est 
rapide. Dans le tableau 3 ci-dessous, on constate que pour le contexte donn&#233; en exemple, 
la mesure du log-likelihood fait clairement ressortir les verbes  cacher et  dissimuler, qui 
correspondent tous deux &#224; la m&#234;me construction st&#233;r&#233;otyp&#233;e : X ne pas cacher/dissimuler 
son admiration pour Y.
</p>
<p>l1 l2 f f1 f2 N loglike
admiration_N cacher_V 4 14 527 544994 38,83
admiration_N dissimuler_V 2 14 107 544994 22,70
admiration_N proclamer_V 2 14 176 544994 20,70
admiration_N exprimer_V 2 14 642 544994 15,53
admiration_N redire_V 1 14 76 544994 10,57
admiration_N manifester_V 1 14 193 544994 8,70
admiration_N confier_V 1 14 1319 544994 4,91
</p>
<p>TABLEAU 3 - extrait de lexicogramme pour le pivot multimot son admiration pour pris en 
tant qu'objet direct
</p>
<p>Ainsi con&#231;ue, l'extraction des lexicogrammes pour les pivots multimots se veut surtout 
&#234;tre un outil d'observation permettant aux utilisateurs, par complexifcation progressive, 
de  mieux  pr&#233;ciser  le  contexte  des  ph&#233;nom&#232;nes  qui  les  int&#233;ressent  (comme  ici  en 
pr&#233;cisant la d&#233;termination ou la structure pr&#233;positionnelle).
Cette  approche  qui  va  du  simple  vers  le  complexe  peut  n&#233;anmoins,  d'une  certaine 
</p>
<p>404</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>mani&#232;re, s'automatiser. Partant d'un pivot simple, on peut retenir ses collocatifs les plus 
saillants pour former de nouveaux pivots multimots. Et l'on peut r&#233;it&#233;rer l'op&#233;ration de 
mani&#232;re r&#233;cursive sur les nouveaux pivots, jusqu'&#224; une taille limite fx&#233;e arbitrairement. 
Nous  avons  impl&#233;ment&#233;  ce  processus  jusqu'&#224;  une taille  maximale  de  5  mots,  en  ne 
retenant, &#224; chaque it&#233;ration, que les candidats &#224; l'extension qui cooccurrent au moins 3 
fois et pour lesquelles la valeur de loglike sont sup&#233;rieure &#224; 10. Ne sont retenus que les 
pivots multimots maximaux (de 5 mots) ou qui ne peuvent &#234;tre &#233;tendus par un pivot 
multimot plus long.
Dans l'exemple ci-dessous, pour mieux cibler l'extraction autour du nom admiration, nous 
avons impos&#233; que le premier collocatif soit issu de la relation d'objet direct (on trouve 
donc, pour commencer, un verbe). Voici les r&#233;sultats obtenus, sans fltrage, pour les 3 
verbes les plus saillants.
</p>
<p>1 : pr&#233;cision_N qui_PRON forcer_V la_DET admiration_N 
2 : pr&#233;cision_N forcer_V la_DET admiration_N 
3 : vouer_V une_DET admiration_N sans_PREP borne_N 
4 : vouer_V une_DET profond_A  admiration_N
5 : vouer_V une_DET grand_A admiration_N 
6 : il_PRON vouer_V une_DET grand_A admiration_N 
7 : qui_PRON vouer_V une_DET admiration_N 
8 : qui_PRON pas_ADV cacher_V son_PRON admiration_N 
9 : ne_ADV pas_ADV cacher_V son_PRON admiration_N 
10 : avoir_V cacher_V son_PRON  admiration_N
11 : il_PRON pas_ADV cacher_V son_PRON admiration_N 
12 : qui_PRON ne_ADV cacher_V pas_ADV admiration_N
</p>
<p>Comme souvent dans les extractions d'expressions  multimots,  on trouve un ensemble 
d'expressions de natures diverses (collocations simples, collocations r&#233;cursives, locutions, 
etc.), avec notamment des fragments incomplets d'expressions plus larges (cf. exemple. 
2) ou des expressions qui agr&#232;gent des &#233;l&#233;ments de contexte non pertinent (cf. exemple 
10, avec avoir). On obtient cependant, et ceci de fa&#231;on assez pr&#233;cise, des constructions 
r&#233;currentes et st&#233;r&#233;otyp&#233;es caract&#233;ristiques de la combinatoire du nom admiration pris en 
tant qu'objet.
</p>
<p>6 Conclusion
Nous avons pr&#233;sent&#233; un nouvel outil d'exploration de la combinatoire lexico-syntaxique, 
que nous avons baptis&#233; le lexicoscope. Cet outil s'appuie sur un mod&#232;le de cooccurrence 
fexible permettant  &#224;  l'utilisateur de d&#233;fnir  lui  m&#234;me les  unit&#233;s  qui  l'int&#233;ressent  (en 
combinant forme, lemme, cat&#233;gorie et traits) ainsi que l'espace de cooccurrence vis&#233; (en 
pr&#233;cisant  les  relations  de  d&#233;pendance  concern&#233;es).  Le  lexicoscope  permet  en  outre 
d'efectuer  des  comparaisons  des  profls  combinatoires,  synth&#233;tis&#233;s  sous  la  forme  de 
lexicogrammes, et propose en sortie des visualisations du type AFC, MDS ou hClust.
Enfn, pour permettre &#224; l'utilisateur de ne pas se limiter aux seules d&#233;pendances directes 
autour d'un pivot, nous avons ajout&#233; la possibilit&#233; de d&#233;fnir des pivots multimots avec 
leurs contextes syntaxiques. Ce nouvel outil est actuellement &#224; l'essai, dans le cadre des 
</p>
<p>405</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>observations  contrastives  efectu&#233;es  pour le  projet  Emolex.  L'interface sera accessible 
pour  le  grand  public  d'ici  quelque  mois  (mais  les  corpus,  qui  sont  soumis  &#224;  des 
restrictions de droits d'auteur, ne pourront &#234;tre difus&#233;s dans leur int&#233;gralit&#233;). D'ici l&#224;,  
nous  pourrons  efectuer  une  analyse  plus  pr&#233;cise  des  possibilit&#233;s  ofertes  par  le 
lexicoscope pour la comparaison des  profls combinatoires de dif&#233;rents  pivots,  et  en 
d&#233;gager une m&#233;thodologie d'observation adapt&#233;e. 
</p>
<p>7 R&#233;f&#233;rences
A&#207;T-MOKHTAR,  S.,  CHANOD,  J.-P.,  ROUX C. (2002)  &#8220;Robustness  beyond  Shallowness: 
Incremental Deep Parsing&#8221;, Natural Language Engineering, 8 :121-144.
ATTARDI,  G.,  DELL'ORLETTA,  F.,  SIMI,  M.,  CHANEV,  A.,  CIARAMITA,  M. (2007)  &#8220;Multilingual 
Dependency Parsing and Domain Adaptation using DeSR&#8221;, In Proc. of the CoNLL Shared  
Task Session of EMNLP-CoNLL 2007, Prague.
CHAREST,S.  BRUNELLE E.,  FONTAINE J. (2010)  Au-del&#224; de la paire de mots  :  extraction de 
cooccurrences syntaxiques multilex&#233;miques, Actes de TALN 2010, Montr&#233;al, juillet 2010
EVERT, STEFAN (2007). Corpora and collocations. in A. L&#252;deling and M. Kyt&#246; (eds.), Corpus  
Linguistics. An International Handbook, article 58. Mouton de Gruyter, Berlin.
Heiden S., Tournier M. (1998) Lexicom&#233;trie textuelle, sens et strat&#233;gie discursive, actes I  
Simposio Internacional de An&#225;lisis del Discurso, Madrid.
HOEY,  M.  (2005) :  Lexical  Priming:  A  New  Theory  of  Words  and  Language,  London, 
Routledge.
KILGARIFF A.,TUGWELL D. (2001)  WORD SKETCH:  Extraction  and  Display  of  Signifcant 
Collocations  for  Lexicography,  Proc  ACL  workshop  on  COLLOCATION  Computational  
Extraction Analysis and Exploitation, Toulouse July 2001.
KRAIF,  O.  (2008)  Comment  allier  la  puissance  du  TAL  et  la  simplicit&#233;  d'utilisation  ? 
l'exemple du concordancier bilingue ConcQuest, JADT 2008, PUL, 625-634, vol. 2.
NIVRE, J., BOGUSLAVSKY, I. M., IOMDIN, L. L. (2008) &#8220;Parsing the SYNTAGRUS Treebank of 
Russian&#8221;,  Proceedings  of  the  22nd  International  Conference  on  Computational  Linguistics 
(Coling 2008), Manchester, August 2008, p. 641&#8211;648.
SERETAN V.,  NERIMA L.,  WEHRLI E.  (2003).  Extraction  of  Multi-Word  Collocations  Using 
Syntactic  Bigram  Composition.  Proceedings  of  the  Fourth  International  Conference  on  
Recent Advances in NLP, (RANLP-2003), 424&#8211;431.
SINCLAIR,  JOHN MCH.  (2004)  Trust  the  text  :  language,  corpus  and  discourse,  London, 
Routledge.
TAPANAINEN, P., J&#196;RVINEN, T. (1997) &#8220;A non-projective dependency parser&#8221;, In Proceedings of  
the 5th Conference on Applied Natural Language Processing, Washington, DC, p. 64-74.
TUTIN A. (2008), For an extended defnition of lexical collocations, Proceedings of Euralex, 
Barcelone 15-19 juillet 2008, Universit&#233; Pompeu Fabra.
</p>
<p>406</p>

</div></div>
</body></html>