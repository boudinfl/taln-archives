Le Lexicoscope : un outil pour 1'étude de proﬁls
combinatoires et 1'extraction de constructions

lexico-syntaxiques

Olivier Kraif 1, Sascha Diwersy 2
(1) I.IDILEM, Université Stendhal Grenoble 3, BP 25, 38040 Grenoble Cedex
(2) Univetsité de Cologne
olivier.kraif@u—grenoble3.fr, sascha.diwersy@uni—koeln.de

Rﬁsumﬁ

Dans le cadre du projet franco-allemand Emolex, dédié 5 l'ét11de contrastive de la
combinatoire du lexique des émotions en 5 langues, nous avons développé des outils et
des métl1odes permettant l'ext:raction, la visualisation et la comparaison de proﬁls
combinatoires pour des expressions simples et complexes. Nous présentons ici
l'architecture d'ensemble de la plate-forme, concue pour effectuer des extractions sur des
corpus de grandes dimensions (de l'ordre de la centaine de millions de mots) avec des
temps de réponse réduits (le corpus étant interrogeable en lignel). Nous décrivons
comment nous avons int:roduit la notion de pivots complexes, aﬁn de permettre aux
utilisateurs de rafﬁner progressivement leurs requétes pour caractériser des constructions
lexico-syntaxiques élaborées. Enﬁn, nous donnons les premiers résultats d'un module
d'extraction automatique d'expressions polylexicales récurrentes.

ABSTRACT

The Lexicoscope : an integrated tool for combinatoric proﬁles observation and
lexico-syntactic constructs extraction.

The German-French research project Emolex whose aim is the cont:rastive study of the
combinatorial behaviour of emotion lexemes in 5 languages has led to the development
of methods and tools to extract, display and compare the combinatorial proﬁles of
simple and complex expressions. In this paper, we present the overall architecture of the
query platform which has been conceived to ensure efﬁcient processing of huge
annotated text corpora (consisting of several hundred millions of word tokens) accessible
through a web-based interface. We put forward the concept of “complex query nodes”
introduced to enable users to carry out progressively elaborated extractions of
lexical-syntactic patterns. We ﬁnally give primary results of an automated method for
the retrieval of recurrent multi-word expressions, which takes advantage of the complex
query nodes implementation.

Mors-cL1‘zs: collocations, cooccurrences, proﬁl combinatoire, expressions polylexicales,
lexique des émotions.

KEYWORDS : collocations, combinatorial proﬁles, multi-word expressions.

1 L‘accés au corpus seta rendu public, moyennant authentiﬁcation, d'ici quelques mois.

Actes de la conférence onjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 399-406,
Grenoble, 4 an 8 juin 2012. ©2012 ATAI.A 8: AFCP

399

1 Introduction

Cette communication présente des travaux réalisés dans le cadre du projet Emolex,
projet franco-allemand coﬁnancé par l'ANR et la DFG. Dans le cadre de cette recherche,
nous avons rassemblé des corpus massifs comportant plusieurs centaines de millions de
mots pour 5 langues différentes (l'allemand, le frangais, l'anglais, l'espagnol et le russe).
L'object:if du projet est d'analyser, dans une perspective formu.lée par Sinclair (2004) ou
encore Hoey (2005) et d'un point de vue contrastif, les valeurs sémantiques et les r6les
discursifs a partir de la combinatoire du lexique des émotions, aﬁn d'élaborer une
cartographie permettant de mieux structurer ce champ lexical, avec des applications en
lexicographie mais aussi en didactique des langues et traductolog'ie. Cette ét11de porte
plus précisément sur le développement d'une approche automatisée permettant de guider
l'observat:ion linguistique par l'extraction de cooccurrences autour d'un pivot

2 Un modéle de cooccurrence ﬂexible

Pour caractériser le proﬁl combinatoire d'une entrée, nous reprenons le concept de
lexicogramme, introduit par Maurice Tournier et repris dans le logiciel WebLex (Heiden,
Tournier 1998) : il s'ag'it d'établir, pour un pivot donné, la liste de ses cooccurrents les
plus fréquents, 5 gauche et 5 droite, en faisant l'extraction des fréquences de
cooccurrence et en calculant des mesures d'association statistiques (telles que rapport de
vraisemblance ou t-score). Pour construire ces lexicogrammes, nous proposons un
modéle de cooccurrence ﬂexible permettant 5 l'utilisateur de déﬁnir lui-méme les unités
de cooccwrences : formes, lemmes, catégories morphosyntaxiques, traits additionnels
(p.ex. sémantiques), relations syntaxiques (dans le cas des colligations) ou des
combinaisons de ces informations. La possibilité de faire intervenir des combinaisons de
ses traits nous semble importante pour permettre 5 l'utilisateur d'ajuster la focale de ses
observations en allant du général au particulier (ou vice-versa), de préciser des
contraintes pour désambigui'ser certains contextes, et de combiner les aspects lexicaux et
syntaxiques dans ses observations. Par ailleurs nous proposons également une
caractérisation ﬂexible de l'espace de cooccurrence, qui conditionne les points de
rencontre entre pivot et collocatifs, ainsi que la maniere de les dénombrer. On peut par
exemple déﬁnir la cooccurrence 5 l'intérieur d'un empan de largeur ﬁxe, évent11ellement
différente 5 droite et 5 gauche du pivot Mais on peut aussi rechercher la cooccurrence
gntaxique, 5 l'instar de Kilgariff et Tugwell (2001) ou Charest et al. (2010), mise en jeu
lorsqu'une relation fonctionnelle (du type sujet, complément d'objet, modiﬁeur, etc.) a
été identiﬁée entre deux unités. Evert (2007), signale l'intérét de ce type de cooccurrence
en terme de bruit et de silence: "(...) unlike surface cooccurrence, it does not set an
arbitrary distance limit, but at the same time introduces less “noise” than textual
cooccurrence". Pour la cooccurrence syntaxique, nous exploitons les relations de
dépendances obtenues grace 5 différents analyseurs : XIP pour l'anglais (Ai't-Mokhtar et
al. 2001), Connexor pour l'allemand, le frangais et l'espagnol (Tapanainen & Jarvinen
1997), DeSR pour le russe (Attardi et al. 2007), basé sur un modele stochastique créé a
partir du corpus arboré SyntagRus (Nivre et aL, 2008). Un post-traitement a permis
d'harmoniser et de standardiser l'annotat:ion des relations de dépendance entre les

400

langues (l'annotation de Connexor ayant servi de référence). Nous avons par la suite
complété ces relations pour obtenir des dépendances plus pertinentes sur le plan
sémantique (p. ex. sujet profond dans les constructions passives, etc.).

Avec le modéle de cooccurrence ainsi déﬁni, on peut viser des aspects tres génériques de
la combinatoire (par exemple : quels sont les principaux collocatifs de la forme swprise
toutes relations confondues) ou beaucoup plus spéciﬁques et circonscrits (par exemple :
quels sont les principaux collocatifs verbaux 5 l'imparfait du nom lemmatisé swprise en
tant qu'objet direct). Le tableau 1 montre u.n tel lexicogramme :

11 12 f f1 f2 loglike
su.rprise_N créer_V 614 2098 21658 4548,43
su.rprise_N réserver_V 230 2098 2869 2143,50
surprise_N avoir_V 484 2098 423 602 627,50
surprise_N const:it11er_V 94 2098 13778 406,80
surprise_N éviter_V 43 2098 16296 109,30
su.rprise_N manifester_V 22 2098 2424 106,62
su.rprise_N causer_V 19 2098 2210 90,06
su.rprise_N ménager_V 15 2098 1495 75,58
surprise_N exprimer_V 23 2098 6186 72,54
su.rprise_N provoquer_V 23 2098 10551 50,61
su.rprise_N feindre_V 9 2098 676 50,31

TABLEAU 1 : extrait du lexicogramme pour le nom lemmatisé swprise pris en tant qu'objet
direct (f = fréquence de cooccurrence, f1 = fréquence de 11, f2 = fréquence de 12)

3 Visualisations comparatives

A partir de ces lexicogrammes, nous offrons différentes modalités d'exploration :

— pour l'analyse linguistique, le "retou.r au texte" est indispensable : u.n simple clic sur
un collocatif permet de retrouver, sous forme de concordance, tous les contextes de
cooccurrence avec le pivot.

— pour comparer de maniére synthétique divers proﬁls combinatoires, nous proposons
d'identiﬁer les lexicogrammes a des points dans un espace vectoriel, en ne retenant
que la mesure jugée la plus pertinente (fréquence, loglike, t-score, etc.). Il est des
lors possible d'utiliser des méthodes d'analyse de données pour visualiser les
similarités entre pivots : analyse factorielle des correspondances (AFC),
échelon.nement multidimensionnel (MDS) ou classiﬁcation hiérarchique ascendante
(l1Clust). La ﬁgure 1 montre ces sorties pour des u.nités du domaine sémantique de la
'colére' (obtenues grace aux modules du projet ‘GNU R’). La classiﬁcation, réalisée
pour la relation "objet", indique u.ne hiérarchisation assez bien corrélée 5 l'intensité
du sentiment. Quant 5 la ‘factor map‘, réalisée pour des relations quelconques

401

concernant des collocatifs adjectivaux, elle permet de distinguer trois groupes :
révolte, indignation - souvent lié 51a sphere publique et politique ; fureur, rage, colére -
lié 5 l'expression ponct11elle et plus ou moins intense de l'affect ; enﬁn énervement,
irritation, exaspération - qui concement plut6t des états émotionnels précu.rseurs de
cette manifestation. Ces cas montrent de facon assez éclairante le lien entre les
valeu.rs sémantiques et la combinatoire lexico-syntaxique.

Cluster Dendrogram CAl“°l°" "mp

eﬂervemem N

CEJTFIHW A
4

, s  A Imtah-on N
crowssant A

C 9
tur=.=4N _

S _ Z A qvawwdlisarl §Wme“_A.
m 2‘ 2 2 ‘ ' . 7 ‘
=3 gs 5 5  9° _,Q| exasperation N
E .\ 9 ~ ‘ 9 2 3 0 "" * ' "
E: 0 g 2 3’ Z S lﬂnuﬁatxon N
I 2 E‘ ‘Q’ aesespeiéﬂg _ —
(O 8 <5 E tegirme A
, Q, 5 A
C 2
§ ‘ T phpu\dI'a A

2‘ 2‘ .

E 5

E E revolts N

’* 1 d 1 A

E -37 (V 95 U liﬂ W‘

9 E

m

x x
4 0 I 2 3 4
Dim 1 :30 47%;‘

FIGURE 1 : Classiﬁcation hiérarchique et AFC (domaine sémantique de la 'colere')
4 Architecture logicielle

Comment répondre rapidement 5 u.ne requéte d'utilisateu.r lorsqu'on interroge des corpus
contenant des centaines de millions d'occu1rences ? La réponse est simple, a priori :
grace 5 u.ne indexation préalable des u.nités et des cooccuirences. Mais la difﬁculté de
notre systeme tient au fait que ni les u.nités, ni l'espace de cooccuirence ne sont déﬁnis 5
l'avance : on peut interroger des lemmes, des formes, des combinaisons
lemmes-catégories, et toute combinaison de forme, lemme, catégorie et traits (ces
derniers pouvant étre caractérisés par des expressions régulieres). En outre, l'espace de
cooccuirence est établi dynamiquement, au moment de la requéte, par des expressions
réguliéres déﬁnissant l'ensemble des relations 5 prend.re en compte.

Pour répondre 5 la double exigence de ﬂexibilité et d'efﬁcacité, nous avons élaboré u.ne
indexation multi-niveaux, sous la forme de hachages de hachages sérialisés : chaque
forme pointe vers l'ensemble des lemmes correspondants ; chaque lemme pointe vers
l'ensemble de ses catégories possibles (dans le corpus) ; chaque lemme-catégorie pointe
vers l'ensemble des traits associés (dans le corpus) ; chaque lemme-catégorie-traits pointe
vers l'ensemble des relations associées ; chaque lemme-catégorie-traits-relation pointe
vers u.n ensemble de paires (collocatif,fréquence). Les expressions régulieres liées au
contraintes portant sur les catégories, traits et relations sont appliquées lors du parcours
de l'index. Les ensembles de catégories, traits et relations étant réduits (et fermés) et le
temps de recherche dans le hachage étant en 0(1), la succession de ces recherches n'est

402

pas tres couteuse.

En ce qui concerne l'implémentation, nous avons opté pour le langage Perl, pour son
traitement tres efﬁcace des expressions régulieres. Pour les index, nous avons testé deux
systemes de bases de données réputés pour leur efﬁcacité : BerkeleyDB 5.1.252 et
KyotoCabinet 1.2.483. Les résultats du tableau 3 mont:rent que le systeme qui est apparu
le plus efﬁcace pour nos requétes était celui de KyotoCabinet::BTree.

Corpus presse (fr) 2007- Tda;';° test 2 test 2 test 3
2008 (87 807 463 tokens) index 1 pivot 5 pivots 24 pivots
Berke|eyDB:Hash 1800 M0 125 s. / 1,3 s. 275 s. /206 s. 892 s. / 766 s.
KyotoCabinet::Hash 1200 Mo 50 s. /1 s. 376 s. / 180 s. 749 s. / 702 s.
KyotoCabinet::Btree 955 Mo 76 s. / 1.5 s. 247 s./ 231 s. 416 s. / 315 s.

TABLEAU 2 : comparaison des tailles et des temps de réponse pour différents types de DBM
(le 2eme temps est obtenu lorsqu'une requéte est immédiatement réitérée).

Ces temps sont donnés 5 titre de comparaison : ils ont été obtenus sur un PC ancien et
assez lent Sur notre matériel act11el (Intel Core2 Quad CPU Q9550 2.83GHz, avec 4Go
de RAM) nous obtenons des temps environ 4 fois supérieurs. La différence importante
entre le 1er et le 2eme temps indique que ce sont les acces disques qui pénalisent les
traitements, car lorsque la DBM est en cache, la réponse est presque instantanée. En
utilisant un disque SSD u.lt:ra-rapide, nous prévoyons d'améliorer les temps de réponse de
maniére drastique.

5 Prise en compte des pivots multimots

L'aspect exclusivement binaire des relations de dépendance directe peut aboutir 5 un
rétrécissement du contexte des observations et faire manquer des phénomenes
intéressants sur le plan phraséologique. Ces limitations empéchent notamment
l’extraction automatique de séquences polylexicales 5 valeur d’u.nité minimale de sens
(les << meaning units » selon Sinclair 2004), qui peuvent présenter u.ne variabilité
considérable sur le plan de l’expression.

Cependant, en ce qui concerne les « collocations lexicales », Tutin (2008) afﬁrme que la
plupart d'entre elles ont u.ne structure binaire, méme pour celles qui s'étendent 5 plus de
deux éléments, car elles correspondent sémantiquement 5 u.ne structure
prédicat-argument : "Collocations can be considered as predicate-argument structures, and as
such, are prototypically binary associations, where the predicate is the collocate and the
argument is the base. Most ternary (and over) collocations are merged collocations (collocational
clusters) or recursive collocations. ”

Et en effet, de nombreux travaux dédiés 5 l'extract:ion de collocations étendues 5 plus de
deux mots se basent en fait sur des modeles binaires, appliqués 5 deux éléments
composés : collocation d'arbres syntaxiques (Charest et al., 2010), construction itérative

ghttp://www.oracle.com/technetwork/database/berkeleydb/overview/index.html
3http://fa]labs.com/kyotocabinet/

403

de cooccurrence multimots 5 partir de cooccurrences binaires (Seretan et al., 2003), ou
encore calcul de mesure d'association multimots en combinant des mesures 5 deux
termes.

De la méme maniére, il est possible d'étendre notre architecture pour le calcul des
lexicogrammes d'un pivot donné, en la généralisant 5 des conﬁgurations plus complexes :
la solution consiste 5 déﬁnir le pivot non plus seulement 5 partir d'une forme prise
isolément, mais comme une forme associée a un certain contexte lexicmgntaxique. Une fois
déterminé ce contexte, il est possible de calculer le tableau de contingence comme
précédemment, le pivot et son contexte formant en quelque sorte une nouvelle unité
pour laquelle il est possible de calcu.ler 5 la fois les fréquences de cooccurrence (en se
basant sur les relations du pivot) et la fréquence marginale dans le corpus.

Pour l'écriture des contextes, nous utilisons le formalisme de méta-expressions réguliéres
proposé par Kraif (2008). Par exemple, pour rechercher le pattern V+ DET(poss.) +
admiration_N + POUR, nous déﬁnissons le contexte suivant :

pivot : #1 = admiration#N
contexte: <l= son> < #1 > && < #2 > && < pour,#3 > ::(.*,#1,#2)(.*,#2,#3)

Le calcu.l est seulement un peu plus long 5 mettre en oeuvre, car les pivots multimots
n'étant pas connus a priori, il n'est pas possible de les indexer tels quels. Seu.ls les tokens
(formes ou lemmes) composant le contexte, ainsi que les relations de dépendances entre
deux tokens déﬁnis, sont indexés, ce qui permet de réduire signiﬁcativement l'ensemble
des phrases 5 analyser. Pour des expressions comportant plusieurs relations, comme c'est
l'intersect:ion des phrases indexées pour chaque relation qui est retenue, la recherche est
plus rapide : en d'autres termes, plus un pivot complexe est long, plus sa recherche est
rapide. Dans le tableau 3 ci-dessous, on constate que pour le contexte donné en exemple,
la mesure du log-likelihood fait clairement ressortir les verbes cacher et dissimuler, qui
correspondent tous deux 5 la méme construction stéréotypée : X ne pas cacher/dissimuler
son admiration pour Y.

11 12 f f1 f2 N loglike
admiration_N cacher_V 4 14 527 544994 38,83
admiration_N dissimu|er_V 2 14 107 544994 22,70
admiration_N proc|amer_V 2 14 176 544994 20,70
admiration_N exprimer_V 2 14 642 544994 15,53
admiration_N redire_V 1 14 76 544994 10,57
admiration_N manifester_V 1 14 193 544994 8,70
admiration N conﬁer V 1 14 1319 544994 4,91

TABLEAU 3 - extrait de lexicogramme pour le pivot multimot son admiration pour pris en
tant qu'objet direct

Ainsi congue, l'extraction des lexicogrammes pour les pivots multimots se veut surtout
étre un outil d'observation permettant aux utilisateurs, par complexiﬁcation progressive,
de mieux préciser le contexte des phénoménes qui les intéressent (comme ici en
précisant la détermination ou la structure prépositionnelle).

Cette approche qui va du simple vers le complexe peut néanmoins, d'une certaine

404

maniére, s'automatiser. Partant d'un pivot simple, on peut retenir ses collocatifs les plus
saillants pou.r former de nouveaux pivots multimots. Et l'on peut réitérer l'opération de
maniére récursive sur les nouveaux pivots, jusqu'5 u.ne taille limite ﬁxée arbitrairement
Nous avons implémenté ce processus jusqu'5 u.ne taille maximale de 5 mots, en ne
retenant, 5 chaque itération, que les candidats 5 l'extension qui cooccu.rrent au moins 3
fois et pour lesquelles la valeu.r de loglike sont supérieu.re 5 10. Ne sont retenus que les
pivots multimots maximaux (de 5 mots) ou qui ne peuvent étre étendus par un pivot
multimot plus long.

Dans l'exemple ci-dessous, pou.r mieux cibler l'extraction autou.r du nom admiration, nous
avons imposé que le premier collocatif soit issu de la relation d'objet direct (on trouve
donc, pou.r commencer, un verbe). Voici les résultats obtenus, sans ﬁltrage, pour les 3
verbes les plus saillants.

: précision_N qui_PRON forcer_V la_DET ad.mirat:ion_N
: précision_N forcer_V la_DET ad.miration_N

: vouer_V une_DET ad.mirat:ion_N sans_PREP bome_N

: vouer_V une_DET profond_A ad.miration_N

: vouer_V une_DET grand_A ad.miration_N

: il_PRON vouer_V une_DET grand_A ad.miration_N

: qui_PRON vouer_V une_DET ad.miration_N

: qui_PRON pas_ADV cacher_V son_PRON admiration_N
: ne_ADV pas_ADV cacher_V son_PRON ad.miration_N
10 : avoir_V cacher_V son_PRON ad.miration_N

11 : il_PRON pas_ADV cacher_V son_PRON ad.miration_N
12 : qui_PRON ne_ADV cacher_V pas_ADV ad.miration_N

tD0O\l0\U1-ISWRQD-|

Comme souvent dans les extractions d'expressions multimots, on trouve un ensemble
d'expressions de natu.res diverses (collocations simples, collocations récu.rsives, locutions,
etc.), avec notamment des fragments incomplets d'expressions plus larges (cf. exemple.
2) ou des expressions qui agregent des éléments de contexte non pertinent (cf. exemple
10, avec avoir). On obtient cependant, et ceci de fagon assez précise, des constructions
récurrentes et stéréotypées caractéristiques de la combinatoire du nom admiration pris en
tant qu'objet

6 Conclusion

Nous avons présenté un nouvel outil d'exploration de la combinatoire lexico-syntaxique,
que nous avons baptisé le lexicoscope. Get outil s'appuie sur un modéle de cooccu.rrence
ﬂexible permettant 5 l'utilisateu.r de déﬁnir lui méme les unités qui l'intéressent (en
combinant forme, lemme, catégorie et traits) ainsi que l'espace de cooccu.rrence visé (en
précisant les relations de dépendance concernées). Le lexicoscope permet en out:re
d'effect11er des comparaisons des proﬁls combinatoires, synt.hétisés sous la forme de
lexicogrammes, et propose en sortie des visualisations du type AFC, MDS ou hClust

Enﬁn, pou.r permettre 5 l'utilisateu.r de ne pas se limiter aux seules dépendances directes
autou.r d'un pivot, nous avons ajouté la possibilité de déﬁnir des pivots multimots avec
leu.rs contextes syntaxiques. Ce nouvel outil est act11ellement 5 l'essai, dans le cadre des

405

observations contrastives effect11ées pour le projet Emolex. L'interface sera accessible
pour le grand public d'ici quelque mois (mais les corpus, qui sont soumis a des
restrictions de droits d'auteur, ne pourront étre diffusés dans leur intégralité). D'ici la,
nous pourrons effect11er u.ne analyse plus précise des possibilités offertes par le
lexicoscope pour la comparaison des proﬁls combinatoires de différents pivots, et en
dégager u.ne méthodologie d'observation adaptée.

7 Références

A'1"r-Mora-rmn, S., CHANOD, J.-P., Roux C. (2002) “Robustness beyond Shallowness:
Incremental Deep Parsing”, Natural Language Engineering, 8 :121-144.

ATTARDI, G., DELL'C)RLE'['[‘A, F., S1M1, M., CHANEV, A., CIARAMITA, M. (2007) “Multilingual
Dependency Parsing and Domain Adaptation using DeSR”, In Proc. of the CoNLL Shared
Task Session of EMNLP—CoNLL 2007, Prague.

CHAREST,S. BRUNELLE E., FONTAINE J. (2010) Au-dela de la paire de mots : extraction de
cooccurrences syntaxiques multilexémiques, Actes de TALN 2010, Montréal, juillet 2010

EVERT, STEFAN (2007). Corpora and collocations. in A. Liideling and M. Kyto (eds.), Corpus
Linguistics. An International Han¢ﬂ)ook, article 58. Mouton de Gruyter, Berlin

Heiden S., Tournier M. (1998) Lexicométrie text11elle, sens et stratégie discursive, actes I
Sirnposio Internacional de Andlisis del Discurso, Madrid.

Hozv, M. (2005): Lexical Priming: A New Theory of Words and Language, London,
Routledge.

KILGARIFF A.,TUGWEIL D. (2001) WORD SKETCH: Extraction and Display of Signiﬁcant
Collocations for Lexicography, Proc ACL workshop on COLLOCATION Computational
Extraction Analysis and Exploitation, Toulouse July 2001.

KRAIF, O. (2008) Comment allier la puissance du TAL et la simplicité d'utilisation ?
l'exemple du concordancier bilingue ConcQuest, JADT 2008, PUL, 625-634, vol. 2.

NIVRE, J., BOGUSLAVSKY, I. M., IOMDIN, L. L. (2008) “Parsing the SYNTAGRUS Treebank of
Russian”, Proceedings of the 22nd International Conference on Computational Linguistics
(Coling 2008), Manchester, August 2008, p. 641-648.

SERETAN V., NERIMA L., W121-mu E. (2003). Extraction of Multi-Word Collocations Using
Syntactic Bigram Composition. Proceedings of the Fourth International Conference on
Recent Advances in NLP, (RANLP-2003), 424-431.

Smcuxm, JOHN McH. (2004) Tmst the text : language, corpus and discourse, London,
Routledge.

TAPANAINEN, P., Jiinvnnm, T. (1997) “A non-projective dependency parser”, In Proceedings of
the 5th Conference on Applied Natural Language Processing, Washington, DC, p. 64-74.

Turm A. (2008), For an extended deﬁnition of lexical collocations, Proceedings of Euralex,
Barcelone 15-19 juillet 2008, Université Pompeu Fabra.

406

