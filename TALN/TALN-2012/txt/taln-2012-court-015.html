<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Traduction automatique &#224; partir de corpus comparables: extraction de phrases parall&#232;les &#224; partir de donn&#233;es comparables multimodales</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 447&#8211;454,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Traduction automatique &#224; partir de corpus comparables:
extraction de phrases parall&#232;les &#224; partir de donn&#233;es
</p>
<p>comparables multimodales
</p>
<p>Haithem AFLI Lo&#239;c BARRAULT Holger SCHWENK
Laboratoire d&#8217;Informatique de l&#8217;Universit&#233; du Maine
</p>
<p>pr&#233;nom.nom@lium.univ-lemans.fr
</p>
<p>R&#201;SUM&#201;
Les performances des syst&#232;mes de traduction automatique statistique d&#233;pendent de la disponibi-
lit&#233; de textes parall&#232;les bilingues, appel&#233;s aussi bitextes. Cependant, les corpus parall&#232;les sont
des ressources limit&#233;es et parfois indisponibles pour certains couples de langues ou domaines.
Nous pr&#233;sentons une technique pour l&#8217;extraction de phrases parall&#232;les &#224; partir d&#8217;un corpus
comparable multimodal (audio et texte). Ces enregistrements sont transcrits avec un syst&#232;me de
reconnaissance automatique de la parole et traduits avec un syst&#232;me de traduction automatique.
Ces traductions sont ensuite utilis&#233;es comme requ&#234;tes d&#8217;un syst&#232;me de recherche d&#8217;information
pour s&#233;lectionner des phrases parall&#232;les sans erreur et g&#233;n&#233;rer un bitexte. Plusieurs exp&#233;riences
ont &#233;t&#233; men&#233;es sur les donn&#233;es de la campagne IWSLT&#8217;11 (TED) qui montrent la faisabilit&#233; de
notre approche.
</p>
<p>ABSTRACT
Automatic Translation from Comparable corpora : extracting parallel sentences from mul-
timodal comparable corpora
</p>
<p>Statistical Machine Translation (SMT) systems depend on the availability of bilingual parallel text,
also called bitext. However parallel corpora are a limited resource and are often not available
for some domains or language pairs. We present an alternative method for extracting parallel
sentences from multimodal comparable corpora. This work extends the use of comparable
corpora, in using audio instead of text on the source side. The audio is transcribed by an
automatic speech recognition system and translated with a base-line SMT system. We then use
information retrieval in a large text corpus of the target language to extract parallel sentences.
We have performed a series of experiments on data of the IWSLT&#8217;11 speech translation task
(TED) that shows the feasibility of our approach.
</p>
<p>MOTS-CL&#201;S : Reconnaissance de la parole, traduction automatique statistique, corpus compa-
rables multimodaux, extraction de phrases parall&#232;les.
</p>
<p>KEYWORDS: Automatic speech recognition, statistical machine translation, multimodal compa-
rable corpora, extraction of parallel sentences.
</p>
<p>447</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>La construction d&#8217;un syst&#232;me de traduction automatique statistique (TAS) n&#233;cessite un corpus
dit parall&#232;le pour l&#8217;apprentissage du mod&#232;le de traduction et des donn&#233;es monolingues pour
construire le mod&#232;le de langue cible. Un corpus parall&#232;le est une collection de textes bilingues
align&#233;s au niveau de la phrase, c&#8217;est-&#224;-dire des textes en langue source avec leurs traductions.
</p>
<p>Malheureusement, les textes parall&#232;les librement disponibles sont aussi des ressources rares :
la taille est souvent limit&#233;e, la couverture linguistique insuffisante ou le domaine n&#8217;est pas
appropri&#233;. Il y a relativement peu de paires de langues pour lesquelles des corpus parall&#232;les de
taille raisonnable sont disponibles comme l&#8217;anglais, le fran&#231;ais, l&#8217;espagnol, l&#8217;arabe, le chinois et
quelques langues europ&#233;ennes (Hewavitharana et Vogel, 2011). De plus, ces corpus proviennent
principalement de sources gouvernementales, comme le parlement canadien ou europ&#233;en, ou
de l&#8217;Organisation des Nations Unies. Ceci est probl&#233;matique en TAS, parce que les syst&#232;mes de
traduction appris sur des donn&#233;es provenant, par exemple, d&#8217;un domaine politique ne donnent
pas de bons r&#233;sultats lorsqu&#8217;ils sont utilis&#233;s pour traduire des articles scientifiques.
</p>
<p>Une fa&#231;on de pallier ce manque de donn&#233;es parall&#232;les est d&#8217;exploiter les corpus comparables
qui sont plus abondants. Un corpus comparable est un ensemble de textes dans deux langues
diff&#233;rentes, qui ne sont pas parall&#232;les au sens strict du terme, mais qui contiennent les m&#234;mes
informations. On peut par exemple citer les actualit&#233;s multilingues produites par des organismes
de presse tels que l&#8217;Agence France Presse (AFP), Xinhua, l&#8217;agence Reuters, CNN, BBC, etc. Ces
textes sont largement disponibles sur le Web pour de nombreuses paires de langues (Resnik et
Smith, 2003). Le degr&#233; de parall&#233;lisme peut varier consid&#233;rablement, en allant de documents
peu parall&#232;les, aux documents quasi parall&#232;les ou &#171; parall&#232;les bruit&#233;s &#187; qui contiennent de
nombreuses phrases parall&#232;les (Fung et Cheung, 2004). Ces corpus comparables peuvent couvrir
diff&#233;rents sujets.
</p>
<p>Ces travaux s&#8217;inscrivent dans le cadre du projet DEPART (Documents &#201;crits et PAroles &#8211; Re-
connaissance et Traduction) dont l&#8217;un des objectifs est l&#8217;exploitation de donn&#233;es multimodales
et multilingues pour la TAS. Nous consid&#233;rons le cas, assez fr&#233;quent pour des domaines de
sp&#233;cialit&#233;, o&#249; un manque de donn&#233;es textuelles peut &#234;tre palli&#233; par l&#8217;exploitation de donn&#233;es
audio. Un domaine de sp&#233;cialit&#233; est un sous-domaine poss&#233;dant un vocabulaire sp&#233;cifique, tel que
la chirurgie dans le domaine plus large de la m&#233;decine. Nous pouvons &#233;galement consid&#233;rer les
conf&#233;rences ou s&#233;minaires scientifiques et leurs articles associ&#233;s pour un domaine de recherche
sp&#233;cifique.
</p>
<p>La question que nous nous posons alors est la suivante : un corpus comparable multimodal
permet-il d&#8217;apporter des solutions au probl&#232;me du manque de donn&#233;es parall&#232;les ? Dans ce
travail nous proposons une m&#233;thode pour l&#8217;utilisation de corpus comparables multimodaux, en
se limitant aux modalit&#233;s texte et audio, pour l&#8217;extraction de donn&#233;es parall&#232;les.
</p>
<p>2 Recherches pr&#233;c&#233;dentes
</p>
<p>Plusieurs travaux ont trait&#233; de l&#8217;extraction des donn&#233;es parall&#232;les &#224; partir d&#8217;un corpus comparable
bilingue. Un crit&#232;re de maximum de vraisemblance est propos&#233; par Zhao et Vogel (2002) qui
ont combin&#233; des mod&#232;les de longueur de phrases avec un lexique extrait d&#8217;un corpus parall&#232;le
</p>
<p>448</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>align&#233; existant. Le lexique est it&#233;rativement adapt&#233; avec un processus de r&#233;apprentissage en
utilisant les donn&#233;es extraites. Resnik et Smith (2003) ont montr&#233; qu&#8217;ils peuvent g&#233;n&#233;rer un
grand nombre de documents parall&#232;les &#224; partir du WEB en utilisant leur syst&#232;me d&#8217;extraction
de textes parall&#232;les, &#171; STRAND &#187;. Do et al. (2010) ont utilis&#233; une m&#233;thode non-supervis&#233;e pour
extraire des paires de phrases parall&#232;les &#224; partir d&#8217;un corpus comparable et ont montr&#233; que cette
approche est int&#233;ressante surtout pour les langues peu dot&#233;es. La d&#233;tection des paires de phrases
parall&#232;les est faite en utilisant un syst&#232;me de traduction automatique de base qui est am&#233;lior&#233;
avec un processus it&#233;ratif.
</p>
<p>Afin de construire un corpus parall&#232;le anglais/japonais, Utiyama et Isahara (2003) utilisent la
recherche d&#8217;information cross-langue et la programmation dynamique pour l&#8217;extraction de phrases
parall&#232;les &#224; partir d&#8217;un corpus comparable dans le domaine des actualit&#233;s. Les paires d&#8217;articles
similaires sont identifi&#233;es et trait&#233;es comme des textes parall&#232;les afin d&#8217;aligner leurs phrases. La
proc&#233;dure d&#8217;alignement commence par la traduction mot &#224; mot des textes japonais en utilisant un
dictionnaire bilingue, qui sont ensuite pris comme requ&#234;tes de recherche d&#8217;information dans la
partie anglaise des textes. L&#8217;approche de Fung et Cheung (2004) utilise la mesure &#171; cosinus &#187; pour
calculer le degr&#233; de similarit&#233; des phrases. Toutes les paires de phrases possibles d&#8217;un corpus
&#171; non-parall&#232;le &#187;ont &#233;t&#233; consid&#233;r&#233;es, et celles ayant un niveau de similarit&#233; sup&#233;rieur &#224; un certain
seuil sont conserv&#233;es pour construire un dictionnaire qui sera r&#233;appris it&#233;rativement.
</p>
<p>Une m&#233;thode d&#8217;extraction des segments de phrases parall&#232;les est pr&#233;sent&#233;e par Munteanu et
Marcu (2005). Un dictionnaire bilingue existant est utilis&#233; pour traduire chaque document
en langue source vers la langue cible afin d&#8217;extraire le document cible qui correspond &#224; cette
traduction. Pour chaque paire de documents, des paires de phrases et de segments parall&#232;les sont
extraites en utilisant un lexique de traduction et un classifieur &#224; maximum d&#8217;entropie pour le
choix final des phrases parall&#232;les. Rauf et Schwenk (2011) pr&#233;sentent une technique similaire
&#224; celle de Munteanu et Marcu (2005). Les diff&#233;rences majeures r&#233;sident dans l&#8217;utilisation d&#8217;un
syst&#232;me de TA statistique &#224; la place du dictionnaire bilingue, et dans l&#8217;utilisation de mesures
d&#8217;&#233;valuation, comme le taux d&#8217;erreur mot (WER) ou le taux d&#8217;&#233;dition de la traduction (TER),
pour &#233;valuer le degr&#233; de parall&#233;lisme des phrases extraites.
</p>
<p>Toutes ces m&#233;thodes sont pr&#233;sent&#233;es comme des techniques efficaces pour extraire des donn&#233;es
parall&#232;les &#224; partir d&#8217;un corpus comparable. Certains travaux exploitent la modalit&#233; audio pour
l&#8217;extraction de donn&#233;es parall&#232;les. Paulik et Waibel (2009) ont montr&#233; que les mod&#232;les de
traductions statistiques peuvent &#234;tre appris automatiquement d&#8217;une mani&#232;re non-supervis&#233;e &#224;
partir des donn&#233;es parall&#232;les audio. Dans notre contexte de travail, nous nous int&#233;ressons &#224;
l&#8217;exploitation des corpus comparables multimodaux avec diff&#233;rents niveaux de similitude. La
multimodalit&#233; concernera l&#8217;utilisation de documents textuels et audio.
</p>
<p>3 Architecture g&#233;n&#233;rale
</p>
<p>Notre but est d&#8217;exploiter les donn&#233;es comparables multimodales afin d&#8217;en extraire des donn&#233;es
parall&#232;les n&#233;cessaires pour construire, adapter et am&#233;liorer nos syst&#232;mes de traduction automa-
tique statistique. L&#8217;architecture g&#233;n&#233;rale de notre approche, qui se r&#233;sume en 3 &#233;tapes, est d&#233;crite
dans la figure 1.
Notre corpus comparable multimodal est constitu&#233; de donn&#233;es audio en langue source L1 et de
donn&#233;es textuelles en langue cible L2. Les donn&#233;es audio sont tout d&#8217;abord transcrites par un
syst&#232;me de Reconnaissance Automatique de la Parole (RAP). Ce syst&#232;me produit une hypoth&#232;se
</p>
<p>449</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Audio L1
</p>
<p>Trans. L1
</p>
<p>Trad. L2
</p>
<p>Texte L2
</p>
<p>RAP
</p>
<p>TAS
</p>
<p>RI Textes L2
</p>
<p>Corpus 
comparable 
multimodal
</p>
<p>Bitextes
</p>
<p>FIGURE 1 &#8211; Architecture g&#233;n&#233;rale du syst&#232;me
</p>
<p>TED audio
</p>
<p>TEDasr. En
</p>
<p>TEDasr_tran .
FR
</p>
<p>Texte FR
</p>
<p>ASR
</p>
<p>SMT
</p>
<p>IR
</p>
<p>Exp 1 Exp 2 Exp 3
</p>
<p>TEDbi. En
</p>
<p>TEDbi_tran. 
FR
</p>
<p>Texte FR
</p>
<p>SMT
</p>
<p>IR
</p>
<p>TEDbi. FR
</p>
<p>Texte FR
</p>
<p>IR
</p>
<p>ccb2+
%TrainTED.fr
</p>
<p>FIGURE 2 &#8211; Exp&#233;riences permettant de mesurer
l&#8217;impact des diff&#233;rents modules mis en jeu sur le
corpus bilingue extrait.
</p>
<p>de transcription qui est ensuite traduite par le syst&#232;me TAS. La meilleure hypoth&#232;se de traduction
est utilis&#233;e comme requ&#234;te dans le syst&#232;me de recherche d&#8217;information (RI), dont le corpus
index&#233; correspond &#224; la partie textuelle en langue cible du corpus comparable multimodal. Dans
cette approche, qui se base sur les travaux de Rauf et Schwenk (2011), nous utilisons le logiciel
libre Lemur (Ogilvie et Callan, 2001) pour effectuer la RI. Au final, nous obtenons un bitexte
constitu&#233; d&#8217;une part de la transcription automatique et d&#8217;autre part du r&#233;sultat de la RI, qui
pourra &#234;tre r&#233;inject&#233; dans le syst&#232;me de base.
</p>
<p>Ce cadre de travail soul&#232;ve toutefois plusieurs probl&#232;mes. Chaque module mis en jeu pour la
traduction de la parole introduit un certain nombre d&#8217;erreurs. Il est donc important de mettre en
&#233;vidence la faisabilit&#233; de l&#8217;approche ainsi que l&#8217;impact de chaque module sur les donn&#233;es g&#233;n&#233;r&#233;es.
Pour cela, nous avons effectu&#233; 3 types d&#8217;exp&#233;rience diff&#233;rents, d&#233;crits dans la figure 2. Le premier
type d&#8217;exp&#233;rience (Exp 1) consiste &#224; utiliser la r&#233;f&#233;rence de traduction comme requ&#234;te pour la RI.
Ce cas est le plus favorable, cela simule le fait que les modules de RAP et de TAS ne commettent
aucune erreur. Le second type d&#8217;exp&#233;rience (Exp 2) utilise la r&#233;f&#233;rence de transcription pour
alimenter le syst&#232;me de traduction automatique. Cela permet de mettre en &#233;vidence l&#8217;impact des
erreurs de traduction. Enfin, le troisi&#232;me type d&#8217;exp&#233;rience (Exp 3) met en &#339;uvre l&#8217;architecture
compl&#232;te d&#233;crite ci-dessus. Cela correspond au cas r&#233;el auquel nous sommes confront&#233;s.
</p>
<p>Une autre probl&#233;matique concerne l&#8217;importance du degr&#233; de similitude (comparabilit&#233;) des corpus
comparables utilis&#233;s. Nous avons donc artificiellement cr&#233;&#233; des corpus comparables plus ou
moins ressemblants en int&#233;grant une quantit&#233; plus ou moins grande (25%, 50%, 75% et 100%)
de donn&#233;es du domaine dans le corpus index&#233; par la RI.
</p>
<p>Les r&#233;sultats de la RI ne sont pas toujours satisfaisants, il est donc n&#233;cessaire de filtrer ces r&#233;sultats
afin de ne pas ajouter de phrases non parall&#232;les dans le bitexte final. Nous consid&#233;rons le Taux
d&#8217;Edition de la Traduction (Translation Edit Rate - TER) calcul&#233; entre les phrases retourn&#233;es par
la RI et la requ&#234;te, comme mesure de filtrage des phrases trouv&#233;es. Les phrases ayant un TER
</p>
<p>450</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>bitextes # de mots du domaine ?
nc7 3,7M non
eparl7 56,4M non
ccb2_px70 1,3M non
TEDasr 1,8M oui
TEDbi 1,9M oui
</p>
<p>TABLE 1 &#8211; Donn&#233;es utilis&#233;es pour l&#8217;apprentissage
des syst&#232;mes de traduction automatique.
</p>
<p>Dev # de mots
dev.outASR 36k
dev.refSMT 38k
</p>
<p>Test # de mots
tst.outASR 8,7k
tst.refSMT 9,1 k
</p>
<p>TABLE 2 &#8211; Donn&#233;es de d&#233;veloppement (Dev) et
de Test.
</p>
<p>sup&#233;rieur &#224; un certain seuil (d&#233;termin&#233; empiriquement) sont exclues.
</p>
<p>Dans tous les cas, l&#8217;&#233;valuation de l&#8217;approche est n&#233;cessaire. Ainsi, les donn&#233;es parall&#232;les extraites
sont r&#233;inject&#233;es dans le syst&#232;me de base, qui est ensuite utilis&#233; pour traduire les donn&#233;es de test &#224;
nouveau. L&#8217;&#233;valuation peut ensuite se faire avec une mesure automatique comme BLEU (Papineni
et al., 2002).
</p>
<p>4 Exp&#233;riences et r&#233;sultats
</p>
<p>Pour nos exp&#233;riences, nous exploitons les donn&#233;es de la campagne d&#8217;&#233;valuation IWSLT&#8217;11
dans laquelle des donn&#233;es bilingues multimodales sont disponibles. Cette t&#226;che, d&#233;taill&#233;e dans
Rousseau et al. (2011), consiste &#224; traduire des discours de TED 1 de l&#8217;anglais vers le fran&#231;ais. Le
syst&#232;me de RAP est appris sur 773 discours repr&#233;sentant 118 heures de parole. Les donn&#233;es de
d&#233;veloppement et de test officielles sont utilis&#233;es pour &#233;valuer notre approche.
</p>
<p>Le corpus de d&#233;veloppement est compos&#233; de 19 discours repr&#233;sentant un peu plus de 4 heures de
parole. Les corpus bilingues suivants sont utilis&#233;s pour l&#8217;apprentissage des mod&#232;les de traduction :
News-Commentary version 7(nc7), le corpus des actes du parlement europ&#233;en (eparl7) et le
corpus Gigaword_EnFr (ccb2_px70). 2 De ce dernier, ne sont conserv&#233;es que les paires de phrases
dont la perplexit&#233; du c&#244;t&#233; cible (calcul&#233;e avec le mod&#232;le de langue utilis&#233; pour le syst&#232;me TAS)
est inf&#233;rieure &#224; un seuil (ici 70). Le d&#233;tail des donn&#233;es disponibles est pr&#233;sent&#233; dans le tableau 1.
</p>
<p>Le syst&#232;me de reconnaissance de la parole utilis&#233; est bas&#233; sur le syst&#232;me libre CMU Sphinx
(version 3 et 4), modifi&#233; et am&#233;lior&#233;. Le syst&#232;me anglais qui &#233;t&#233; d&#233;velopp&#233; pour transcrire les
donn&#233;es audio de TED utilise cinq passes similaires &#224; celui du fran&#231;ais d&#233;crit dans Del&#233;glise et al.
(2009). Les syst&#232;mes de traduction mis en &#339;uvre sont fond&#233;s sur Moses (Koehn et al., 2007),
approche par segments (phrase-based). Le mod&#232;le de langue est un mod&#232;le 4-gramme construit
avec l&#8217;outil SRILM (Stolke, 2002). Nous avons utilis&#233; toutes les donn&#233;es monolingues disponibles
et le c&#244;t&#233; cible des bitextes.
</p>
<p>Comme mentionn&#233; pr&#233;c&#233;demment, le score TER est utilis&#233; comme m&#233;trique de filtrage des
phrases r&#233;sultantes de la RI, c&#8217;est-&#224;-dire que les phrases ayant un TER sup&#233;rieur &#224; un certain
seuil ne sont pas conserv&#233;es. Ce seuil est d&#233;termin&#233; exp&#233;rimentalement. Pour cela, nous avons
filtr&#233; les corpus extraits dans les diff&#233;rentes conditions d&#8217;exp&#233;rimentation avec diff&#233;rents seuils
TER (de 0 &#224; 100). Pour chaque seuil TER nous obtenons un nombre de phrases parall&#232;les. Le
corpus obtenu est ajout&#233; aux donn&#233;es d&#8217;entra&#238;nement du syst&#232;me de base (eparl7 et nc7) pour
</p>
<p>1. http ://www.ted.com/
2. Ces corpus sont librement disponibles sur le site de la campagne IWSLT&#8217;11 et WMT&#8217;11.
</p>
<p>451</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>obtenir le syst&#232;me adapt&#233;. Les r&#233;sultats en terme de score BLEU sur le corpus de d&#233;veloppement
obtenus avec les diff&#233;rents syst&#232;mes adapt&#233;s sont pr&#233;sent&#233;s dans la figure 3.
</p>
<p> 22.5
</p>
<p> 23
</p>
<p> 23.5
</p>
<p> 24
</p>
<p> 24.5
</p>
<p> 0  20  40  60  80  100
</p>
<p>sco
re 
</p>
<p>BL
EU
</p>
<p>seuil TER
</p>
<p>Exp1
Exp2
Exp3
</p>
<p> 22.5
</p>
<p> 23
</p>
<p> 23.5
</p>
<p> 24
</p>
<p> 24.5
</p>
<p> 0  20  40  60  80  100
sco
</p>
<p>re 
BL
</p>
<p>EU
seuil TER
</p>
<p>Exp1
Exp2
Exp3
</p>
<p>FIGURE 3 &#8211; Score BLEU de la traduction du Dev en utilisant les syst&#232;mes adapt&#233;s avec les bitextes
correspondant &#224; diff&#233;rents seuils TER, extraits d&#8217;un corpus d&#8217;index constitu&#233; par ccb2 + 100%
TEDbi (&#224; gauche) et ccb2+ 25% TEDbi (&#224; droite).
</p>
<p>Ces r&#233;sultats montrent que le choix du seuil de TER ad&#233;quat d&#233;pend de la nature des donn&#233;es. En
effet, pour la condition de l&#8217;Exp1 o&#249; les requ&#234;tes de la RI sont sans erreur, nous remarquons que
le meilleur r&#233;sultat est obtenu pour un seuil proche de 0. Dans les deux autres conditions (Exp2
et Exp3), le meilleur seuil est dans l&#8217;intervalle [80-90]. Dans nos exp&#233;riences, nous retiendrons le
seuil de 80 pour le filtrage des r&#233;sultats de la RI.
</p>
<p>Dans l&#8217;exp&#233;rience Exp2, les traductions automatiques sont utilis&#233;es en tant que requ&#234;tes pour la
RI. On peut esp&#233;rer que la RI elle-m&#234;me n&#8217;est pas trop affect&#233;e par les erreurs de traduction, mais
ceci influence bien s&#251;r le filtrage bas&#233; sur le score TER. Nous n&#8217;avons pas observ&#233; un maximum
du score BLEU en fonction du seuil sur le score TER - dans nos exp&#233;riences les performances
semblent augmenter de fa&#231;on continue. N&#233;anmoins, afin de limiter l&#8217;impact des phrases bruit&#233;es,
nous avons choisi un seuil de 70. On peut observer que le score BLEU du syst&#232;me adapt&#233; est tr&#232;s
proche de celui de Exp1. Ainsi, nous pouvons conclure que les erreurs commises par la TAS n&#8217;ont
pas une influence importante sur l&#8217;algorithme d&#8217;extraction des phrases parall&#232;les. Ceci confirme
l&#8217;analyse de (Rauf et Schwenk, 2011).
</p>
<p>Notre syst&#232;me de base entra&#238;n&#233; avec des donn&#233;es g&#233;n&#233;riques obtient un score BLEU de 22,93.
Dans Exp1, nous utilisons les traductions de r&#233;f&#233;rence en tant que requ&#234;tes et la RI devrait en
principe trouver toutes les phrases avec un TER de z&#233;ro. Les figures montrent que la RI fonctionne
comme attendu : l&#8217;am&#233;lioration du score BLEU ne d&#233;pend pas du seuil sur le score TER puisque
la plupart des phrases ont effectivement un score TER de z&#233;ro. L&#8217;am&#233;lioration du score BLEU
d&#233;pend bien s&#251;r de la quantit&#233; de donn&#233;es extraites : le score BLEU augmente de 22,93 &#224; 24,14
lorsque 100% des donn&#233;es ont &#233;t&#233; inject&#233;es, alors que nous n&#8217;obtenons que 23,62 avec 20% des
donn&#233;es TED. Ces r&#233;sultats nous donnent une borne sup&#233;rieure des r&#233;sultats envisageables avec
l&#8217;utilisation d&#8217;un corpus multimodal.
</p>
<p>Finalement, dans Exp3, la RAP est utilis&#233;e dont le taux d&#8217;erreur est d&#8217;environ 18%. Les phrases
extraites du corpus multimodal permettent d&#8217;am&#233;liorer le syst&#232;me de traduction : le score BLEU
n&#8217;est que 0,5 points en dessous de celui obtenu dans Exp1 ou Exp2. Les r&#233;sultats obtenus apr&#232;s
adaptation du syst&#232;me de base sont pr&#233;sent&#233;s dans le tableau 4. Dans ce cas, le corpus index&#233;
par la RI est constitu&#233; des corpus ccb2_px70 et TEDbi (100%).
</p>
<p>452</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Phrase extraite
Fran&#231;ais vous allez chez ibm et vous prenez un superordinateur ...
Anglais you get a supercomputer because they know ...
</p>
<p>Test audio
Sortie ASR a supercomputer has calculated that humans and only ...
R&#233;f&#233;rence a supercomputer has calculated that humans have only ...
</p>
<p>Traductions de la sortie ASR
Syst&#232;me de base un supercomputer a calcul&#233; que les humains et seulement ...
Syst&#232;me adapt&#233; un superordinateur a calcul&#233; que les humains et seulement ...
</p>
<p>R&#233;f&#233;rence un superordinateur a calcul&#233; que les humains n&#8217; avaient plus que ...
</p>
<p>Traductions am&#233;lior&#233;es
Sys de base j&#8217;ai &#233;crit un article sur la nourriture g&#233;n&#233;tiquement modifi&#233;e
Sys adapt&#233; j&#8217;ai &#233;crit un article sur les produits alimentaires g&#233;n&#233;tiquement modifi&#233;s
Sys de base yeah tu as raison de r&#233;parer
Sys adapt&#233; euh oui tu as raison il faut r&#233;parer
</p>
<p>TABLE 3 &#8211; Exemples d&#8217;am&#233;lioration du syst&#232;me de base : vocabulaire enrichi &#224; partir des phrases
parall&#232;les extraites dans la condition Exp3.
</p>
<p>Le tableau 5 pr&#233;sente les r&#233;sultats des syst&#232;mes adapt&#233;s en fonction du degr&#233; de similitude du
corpus comparable, dans les conditions d&#8217;exp&#233;rimentation Exp3. Des exemples d&#8217;adaptation sont
pr&#233;sent&#233;s dans le tableau 3. Nous pouvons remarquer que le degr&#233; de similitude est un facteur
important. Un r&#233;sultat attendu est que lorsque nous augmentons la proportion de corpus du
</p>
<p>Exp&#233;rience Dev Test
Syst&#232;me de base 22,93 23,96
Exp1 24,14 25,14
Exp2 23,90 25,15
Exp3 23,40 24,69
</p>
<p>TABLE 4 &#8211; % BLEU obtenus sur le Dev et Test
apr&#232;s l&#8217;ajout des bitextes extraits au syst&#232;me de
base, dans les conditions Exp1, Exp2 et Exp3.
</p>
<p>Exp&#233;rience Dev Test # mots
Syst&#232;me de base 22,93 23,96 -
25% TEDbi 23,11 24,40 &#8764;110k
50% TEDbi 23,27 24,58 &#8764;215k
75% TEDbi 23,43 24,42 &#8764;293k
100% TEDbi 23,40 24,69 &#8764;393k
</p>
<p>TABLE 5 &#8211; R&#233;sultats (%BLEU) obtenus avec les
syst&#232;mes adapt&#233;s lorsque le degr&#233; de similitude
du corpus comparable varie.
</p>
<p>domaine dans le corpus index&#233;, les performances sont meilleures. Il est important de noter que
lorsque les corpus sont moins similaires, le nombre de phrases conserv&#233; est r&#233;duit drastiquement
par le filtrage, et donc l&#8217;impact de l&#8217;adaptation est plus faible. Sans filtrage, les performances du
syst&#232;me de base peuvent &#234;tre d&#233;grad&#233;es.
</p>
<p>5 Conclusion
</p>
<p>Dans ce travail nous avons propos&#233; une m&#233;thode permettant d&#8217;extraire des textes parall&#232;les
&#224; partir de corpus comparables multimodaux (audio et texte) pour adapter et am&#233;liorer des
syst&#232;mes de traduction automatique statistique. Plusieurs modules sont utilis&#233;s pour extraire du
</p>
<p>453</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>texte parall&#232;le : reconnaissance automatique de la parole, traduction automatique et recherche
d&#8217;information. Nous validons notre m&#233;thode en injectant les donn&#233;es produites dans l&#8217;appren-
tissage de nouveaux syst&#232;mes de TAS. Des am&#233;liorations en termes de BLEU sont obtenues
pour diff&#233;rents cadres exp&#233;rimentaux. Il en ressort que l&#8217;encha&#238;nement des modules ne d&#233;grade
que faiblement les r&#233;sultats, mais le filtrage des r&#233;sultats de la RI est n&#233;cessaire. Le degr&#233; de
similitude du corpus comparable est un facteur important qu&#8217;il faudra prendre en compte lorsque
cette architecture sera exploit&#233;e dans des conditions r&#233;elles.
</p>
<p>Remerciements
</p>
<p>Ces recherches ont &#233;t&#233; financ&#233;es par la r&#233;gion des Pays de la Loire sous le projet DEPART 3.
</p>
<p>R&#233;f&#233;rences
</p>
<p>DEL&#201;GLISE, P., EST&#200;VE, Y., MEIGNIER, S. et MERLIN, T. (2009). Improvements to the LIUM french ASR system
based on CMU Sphinx : what helps to significantly reduce the word error rate ? In Interspeech 2009.
</p>
<p>DO, T. N. D., BESACIER, L. et CASTELLI, E. (2010). Apprentissage non supervis&#233; pour la traduction
automatique : application &#224; un couple de langues peu dot&#233;. TALN 2010.
</p>
<p>FUNG, P. et CHEUNG, P. (2004). Multi-level bootstrapping for extracting parallel sentences from a quasi-
comparable corpus. In Proceedings of COLING &#8217;04.
</p>
<p>HEWAVITHARANA, S. et VOGEL, S. (2011). Extracting parallel phrases from comparable data. In Proceedings
of the 4th Workshop on Building and Using Comparable Corpora : Comparable Corpora and the Web, BUCC
&#8217;11, pages 61&#8211;68.
</p>
<p>KOEHN, P., HOANG, H., BIRCH, A., CALLISON-BURCH, C., FEDERICO, M., BERTOLDI, N., COWAN, B., SHEN, W.,
MORAN, C., ZENS, R., DYER, C., BOJAR, O., CONSTANTIN, A. et HERBST, E. (2007). Moses : open source toolkit
for statistical machine translation. In Proceedings of ACL&#8217;07, pages 177&#8211;180.
</p>
<p>MUNTEANU, D. S. et MARCU, D. (2005). Improving Machine Translation Performance by Exploiting
Non-Parallel Corpora. Computational Linguistics, 31(4):477&#8211;504.
</p>
<p>OGILVIE, P. et CALLAN, J. (2001). Experiments using the lemur toolkit. Procedding of the Trenth Text Retrieval
Conference (TREC-10).
</p>
<p>PAPINENI, K., ROUKOS, S., WARD, T. et ZHU, W.-J. (2002). Bleu : a method for automatic evaluation of
machine translation. In Proceedings of ACL &#8217;02, pages 311&#8211;318.
</p>
<p>PAULIK, M. et WAIBEL, A. (2009). Automatic translation from parallel speech : Simultaneous interpretation
as mt training data. ASRU.
</p>
<p>RAUF, S. A. et SCHWENK, H. (2011). Parallel sentence generation from comparable corpora for improved
SMT. 25(4):341&#8211;375.
</p>
<p>RESNIK, P. et SMITH, N. A. (2003). The web as a parallel corpus. Comput. Linguist., 29:349&#8211;380.
</p>
<p>ROUSSEAU, A., BOUGARES, F., DEL&#201;GLISE, P., SCHWENK, H. et EST&#200;VE, Y. (2011). LIUM&#8217;s systems for the IWSLT
2011 speech translation tasks. In Proceedings of IWSLT&#8217;11.
</p>
<p>STOLKE, A. (2002). Srilm - an extensible language modeling toolkit. ICSLP, pages 901&#8211;904.
</p>
<p>UTIYAMA, M. et ISAHARA, H. (2003). Reliable measures for aligning japanese-english news articles and
sentences. In Proceedings of ACL&#8217;03, volume 1, pages 72&#8211;79.
</p>
<p>ZHAO, B. et VOGEL, S. (2002). Adaptive parallel sentences mining from web bilingual news collection. In
Proceedings of IEEE International Conference on Data Mining, page 745.
</p>
<p>3. http://www.projet-depart.org/
</p>
<p>454</p>

</div></div>
</body></html>