Traduction automatique £1 partir de corpus comparables:
extraction de phrases paralleles £1 partir de données
comparables multimodales

Haithem AFLI Lo'ic BARRAULT Holger SCHWENK
Laboratoire d’Inforrnatique de l’Université du Maine
prénom . nomtﬁlium . u.r1iv—lemans . fr

RESUME
Les performances des systémes de traduction automatique statistique dépendent de la disponibi-
lité de textes paralleles bilingues, appelés aussi bitextes. Cependant, les corpus paralléles sont
des ressources limitées et parfois indisponibles pour certains couples de langues ou domaines.
Nous présentons une technique pour l’extraction de phrases paralléles ‘a partir d’un corpus
comparable multimodal (audio et texte). Ces enregistrements sont transcrits avec un systéme de
reconnaissance automatique de la parole et traduits avec un systéme de traduction automatique.
Ces traductions sont ensuite utilisées comme requétes d’un systéme de recherche d’information
pour sélectionner des phrases paralléles sans erreur et générer un bitexte. Plusieurs expériences
ont été menées sur les données de la campagne IWSLT’11 (TED) qui montrent la faisabilité de
notre approche.

AB STRACT
Automatic Translation from Comparable corpora : extracting parallel sentences from mul-
timodal comparable corpora

Statistical Machine Translation (SMT) systems depend on the availability of bilingual parallel text,
also called bitext. However parallel corpora are a limited resource and are often not available
for some domains or language pairs. We present an alternative method for extracting parallel
sentences from multimodal comparable corpora. This work extends the use of comparable
corpora, in using audio instead of text on the source side. The audio is transcribed by an
automatic speech recognition system and translated with a base-line SMT system. We then use
information retrieval in a large text corpus of the target language to extract parallel sentences.
We have performed a series of experiments on data of the IWSLT’11 speech translation task
(TED) that shows the feasibility of our approach.

MOTS-CLES : Reconnaissance de la parole, traduction automatique statistique, corpus compa-
rables multimodaux, extraction de phrases paralléles.

KEYWORDS: Automatic speech recognition, statistical machine translation, multimodal compa-
rable corpora, extraction of parallel sentences.

Actes de la con_fe'rence onjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 447-454,
Grenoble, 4 au 8 juin 2012. ©2012 ATAI.A 8: AFCP

447

1 Introduction

La construction d’un systeme de traduction automatique statistique (TAS) nécessite un corpus
dit parallele pour l’apprentissage du modele de traduction et des données monolingues pour
construire le modele de langue cible. Un corpus parallele est une collection de textes bilingues
alignés au niveau de la phrase, c’est-‘a-dire des textes en langue source avec leurs traductions.

Malheureusement, les textes paralleles librement disponibles sont aussi des ressources rares :
la taille est souvent limitée, la couverture linguistique insuffisante ou le domaine n’est pas
approprié. Il y a relativement peu de paires de langues pour lesquelles des corpus paralléles de
taille raisonnable sont disponibles comme l’anglais, le frangais, l’espagnol, l’arabe, le chinois et
quelques langues européennes (Hewavitharana et Vogel, 2011). De plus, ces corpus proviennent
principalement de sources gouvernementales, comme le parlement canadien ou européen, ou
de l’Organisation des Nations Unies. Ceci est problématique en TAS, parce que les systemes de
traduction appris sur des données provenant, par exemple, d’un domaine politique ne donnent
pas de bons résultats lorsqu’ils sont utilisés pour traduire des articles scientiﬁques.

Une facon de pallier ce manque de données paralleles est d’exploiter les corpus comparables
qui sont plus abondants. Un corpus comparable est un ensemble de textes dans deux langues
différentes, qui ne sont pas paralleles au sens strict du terme, mais qui contiennent les mémes
informations. On peut par exemple citer les actualités multilingues produites par des organismes
de presse tels que l’Agence France Presse (AFP), Xinhua, l’agence Reuters, CNN, BBC, etc. Ces
textes sont largement disponibles sur le Web pour de nombreuses paires de langues (Resnik et
Smith, 2003). Le degré de parallélisme peut varier considérablement, en allant de documents
peu paralleles, aux documents quasi paralleles ou << paralleles bruités » qui contiennent de
nombreuses phrases paralléles (Fung et Cheung, 2004). Ces corpus comparables peuvent couvrir
différents sujets.

Ces travaux s’inscrivent dans le cadre du projet DEPART (Documents Ecrits et PAroles — Re-
connaissance et Traduction) dont l’un des objectifs est l’exploitation de données multimodales
et multilingues pour la TAS. Nous considérons le cas, assez fréquent pour des domaines de
spécialité, o1‘1 un manque de données textuelles peut étre pallié par l’exploitation de données
audio. Un domaine de spécialité est un sous-domaine possédant un vocabulaire spéciﬁque, tel que
la chirurgie dans le domaine plus large de la médecine. Nous pouvons également considérer les
conférences ou séminaires scientiﬁques et leurs articles associés pour un domaine de recherche
spéciﬁque.

La question que nous nous posons alors est la suivante : un corpus comparable multimodal
permet-il d’apporter des solutions au probleme du manque de données paralleles? Dans ce
travail nous proposons une méthode pour l’utilisation de corpus comparables multimodaux, en
se limitant aux modalités texte et audio, pour l’extraction de données paralléles.

2 Recherches précédentes

Plusieurs travaux ont traité de l’extraction des données paralléles a partir d’un corpus comparable
bilingue. Un critere de maximum de vraisemblance est proposé par Zhao et Vogel (2002) qui
ont combiné des modeles de longueur de phrases avec un lexique extrait d’un corpus parallele

aligné existant. Le lexique est itérativement adapté avec un processus de réapprentissage en
utilisant les données extraites. Resnik et Smith (2003) ont montré qu’ils peuvent générer un
grand nombre de documents paralleles ‘a partir du WEB en utilisant leur systeme d’extraction
de textes paralléles, « STRAND ». Do et al. (2010) ont utilisé une méthode non-supervisée pour
extraire des paires de phrases paralléles a partir d’un corpus comparable et ont montré que cette
approche est intéressante surtout pour les langues peu dotées. La détection des paires de phrases
paralleles est faite en utilisant un systeme de traduction automatique de base qui est amélioré
avec un processus itératif.

Aﬁn de construire un corpus parallele anglais/japonais, Utiyama et Isahara (2003) utilisent la
recherche d’information cross-langue et la programmation dynamique pour l’extraction de phrases
paralleles ‘a par11'r d’un corpus comparable dans le domaine des actualités. les paires d’articles
similaires sont identiﬁées et traitées comme des textes paralléles aﬁn d’aligner leurs phrases. La
procédure d’alignement commence par la traduction mot a mot des textes japonais en utilisant un
dictionnaire bilingue, qui sont ensuite pris comme requétes de recherche d’information dans la
partie anglaise des textes. L’approche de Fung et Cheung (2004) utilise la mesure « cosinus » pour
calculer le degré de similarité des phrases. Toutes les paires de phrases possibles d’un corpus
« non-paralléle »ont été considérées, et celles ayant un niveau de similarité supérieur a un certain
seuil sont conservées pour construire un dictionnaire qui sera réappris itérativement.

Une méthode d’extract1'on des segments de phrases paralleles est présentée par Munteanu et
Marcu (2005). Un dictionnaire bilingue existant est utilisé pour traduire chaque document
en langue source vers la langue cible aﬁn d’extraire le document cible qui correspond a cette
traduction. Pour chaque paire de documents, des paires de phrases et de segments paralléles sont
extraites en utilisant un lexique de traduction et un classifieur a maximum d’entropie pour le
choix final des phrases paralleles. Rauf et Schwenk (201 1) présentent une technique similaire
‘a celle de Munteanu et Marcu (2005). Les différences majeures résident dansl’ut1'lisation d’un
systeme de '13 statistique ‘a la place du dictionnaire bilingue, et dans l’utilisation de mesures
d’évaluation, comme le taux d’erreur mot (WER) ou le taux d’édition de la traduction (TER),
pour évaluer le degré de parallélisme des phrases extraites.

Toutes ces méthodes sont présentées comme des techniques efﬁcaces pour extraire des données
paralleles ‘a par11'r d’un corpus comparable. Certains travaux exploitent la modalité audio pour
l’extraction de données paralleles. Pauli.k et Waibel (2009) ont montré que les modeles de
traductions statistiques peuvent étre appris automatiquement d’une maniere non-supervisée ‘a
partir des données paralleles audio. Dans notre contexte de travail, nous nous intéressons ‘a
l’exploitation des corpus comparables multimodaux avec différents niveaux de similitude. La
multimodalité concernera l’utilisation de documents textuels et audio.

3 Architecture générale

Notre but est d’exploiter les données comparables multimodales aﬁn d’en extraire des données
paralléles nécessaires pour construire, adapter et améliorer nos systémes de traduction automa-
tique statistique. L’architecture générale de notre approche, qui se résume en 3 étapes, est décrite

dans la ﬁgure 1. _ _ , , _
Notre corpus comparable multimodal est constitue de donnees audio en langue source L1 et de

données textuelles en langue cible L2. Les données audio sont tout d’abord transcrites par un
systéme de Reconnaissance Automatique de la Parole (RAP). Ce systéme produit une hypothése

449

Exp 1 Exp 2 Exp 3

Curpus
----- - - comparable
mullimodal

E)

TAS

j TEDbi. FR TED';|;,"a '
‘E’
- l l

 
  
    

   

TEDbi. En

   

I ______ __
n
u
n

 

cco2+
°/oTrainTED.ir

FIGURE 1 — Architecture générale du systeme FIGURE 2 — Experiences permettant de mesurer
1’impact des différents modules mis en jeu sur le
corpus bilingue extrait.

     
 

de transcription qui est ensuite traduite par le systeme TAS. La meilleure hypothese de traduction
est utilisée comme requéte dans le systéme de recherche d’information (RI), dont le corpus
indexé correspond a la partie textuelle en langue cible du corpus comparable multimodal. Dans
cette approche, qui se base sur les travaux de Rauf et Schwenk (2011), nous utilisons le logiciel
libre Lemur (Ogilvie et Callan, 2001) pour effectuer la RI. Au ﬁnal, nous obtenons un bitexte
constitué d’une part de la transcription automatique et d’autre part du résultat de la RI, qui
pourra étre réinjecté dans le systeme de base.

Ce cadre de travail souleve toutefois plusieurs problémes. Chaque module mis en jeu pour la
traduction de la parole introduit un certain nombre d’erreurs. Il est donc important de mettre en
évidence la faisabilité de l’approche ainsi que l’impact de chaque module sur les données générées.
Pour cela, nous avons effectué 3 types d’expérience différents, décrits dans la ﬁgure 2. Le premier
type d’expérience (Exp 1) consiste a utiliser la référence de traduction comme requéte pour la RI.
Ce cas est le plus favorable, cela simule le fait que les modules de RAP et de TAS ne commettent
aucune erreur. Le second type d’expérience (Exp 2) utilise la référence de transcription pour
alimenter 1e systeme de traduction automatique. Cela permet de mettre en évidence 1’impact des
erreurs de traduction. Enﬁn, le troisieme type d’expérience (Exp 3) met en oeuvre l’architecture
complete décrite ci-dessus. Cela correspond au cas réel auquel nous sommes confrontés.

Une autre problématique concerne l’importance du degré de similitude (comparabilité) des corpus
comparables utilisés. Nous avons donc artiﬁciellement créé des corpus comparables plus ou
moins ressemblants en intégrant une quantité plus ou moins grande (25%, 50%, 75% et 100%)
de données du domaine dans le corpus indexé par la RI.

Les résultats de la RI ne sont pas toujours satisfaisants, il est donc nécessaire de ﬁltrer ces résultats
aﬁn de ne pas ajouter de phrases non paralleles dans le bitexte ﬁnal. Nous considérons le Taux
d’Edition de la Traduction (Translation Edit Rate - TER) calculé entre les phrases retournées par
la RI et la requéte, comme mesure de ﬁltrage des phrases trouvées. Les phrases ayant un TER

450

bitextes # de mots du domaine ? Dev # de mots
nc7 3,7M non dev.outASR 36k
eparl7 56,4M non deV.refSMT 38k
CCb2_pX70 1,3M 1'l01'l Test # de mots
TEDasr 1,8M oui t5t_0utAgR 3,7k
TEDbi 1,9M oui tst.refSMT 9,1 k

TABLE 1 - Données Utﬂisées P011T1’3PPTeT111'5538e TABLE 2 — Données de développement (Dev) et
des systémes de traduction automatique. de Test

supérieur a un certain seuil (déterminé empiriquement) sont exclues.

Dans tous les cas, l’évaluation de l’approche est nécessaire. Ainsi, les données paralléles extraites
sont réinjectées dans le systéme de base, qui est ensuite utilisé pour traduire les données de test a
nouveau. L’évaluation peut ensuite se faire avec une mesure automatique comme BLEU (Papineni
et al., 2002).

4 Expériences et résultats

Pour nos expériences, nous exploitons les données de la campagne d’évaluation IWSLT’1 1
dans laquelle des données bilingues multimodales sont disponibles. Cette tache, détaillée dans
Rousseau et al. (2011), consiste a traduire des discours de TED 1 de l’anglais vers le francais. Le
systéme de RAP est appris sur 773 discours représentant 118 heures de parole. Les données de
développement et de test ofﬁcielles sont utilisées pour évaluer notre approche.

Le corpus de développement est composé de 19 discours représentant un peu plus de 4 heures de
parole. Les corpus bilingues suivants sont utilisés pour l’apprentissage des modéles de traduction :
News-Commentary version 7(nc7), le corpus des actes du parlement européen (eparl7) et le
corpus Gigaword_EnFr (ccb2_px70). 2 De ce dernier, ne sont conservées que les paires de phrases
dont la perplexité du c6té cible (calculée avec le modéle de langue utilisé pour le systéme TAS)
est inférieure a un seuil (ici 70). Le détail des données disponibles est présenté dans le tableau 1.

Le systeme de reconnaissance de la parole utilisé est basé sur le systeme libre CMU Sphinx
(version 3 et 4), modiﬁé et amélioré. Le systeme anglais qui été développé pour transcrire les
données audio de TED utilise cinq passes similaires a celui du francais décrit dans Deléglise et aL
(2009). Les systemes de traduction mis en oeuvre sont fondés sur Moses (Koehn et al., 2007),
approche par segments (phrase-based). Le modéle de langue est un modéle 4—gramme construit
avec l’outi1 SRILM (Stolke, 2002). Nous avons utilisé toutes les données monolingues disponibles
et le cété cible des bitextes.

Comme mentionné précédemment, le score TER est utilisé comme métrique de ﬁltrage des
phrases résultantes de la RI, c’est-a-dire que les phrases ayant un TER supérieur ‘a un certain
seuil ne sont pas conservées. Ce seuil est déterminé expérimentalement. Pour cela, nous avons
ﬁltré les corpus extraits dans les différentes conditions d’expérimentau'on avec différents seuils
TER (de 0 ‘a 100). Pour chaque seuil TER nous obtenons un nombre de phrases paralleles. Le
corpus obtenu est ajouté aux données d’entrainement du systeme de base (eparl7 et nc7) pour

1. http ://www.ted.com/
2. Ces corpus sont librement disponibles sur le site de la campagne IWSLT’11 et WMT’11.

451

obtenir 1e systéme adapté. Les résultats en terme de score BLEU sur le corpus de développement
obtenus avec les différents systémes adaptés sont présentés dans la ﬁgure 3.

us

 

2:5

mamﬂlﬂl
mamﬂlﬂl

 

225

 

FIGURE 3 — Score BLEU de la traduction du Dev en utilisant les systémes adaptés avec les bitextes
correspondant a différents seuils TER, extraits d’un corpus d’index constitué par ccb2 + 100%
'I'EDbi (a gauche) et ccb2+ 25% 'I'EDbi (‘a droite).

Ces résultats montrent que le choix du seuil de TER adéquat dépend de la nature des données. En
effet, pour la condition de1’Exp1 ou les requétes de la RI sont sans erreur, nous remarquons que
le mei11eur résultat est obtenu pour un seuil proche de 0. Dans les deux autres conditions (Expz
et Exp3), 1e meilleur seuil est dans 1’intervaJle [80-90]. Dans nos expériences, nous retiendrons 1e
seuil de 80 pour le ﬁltrage des résultats de la RI.

Dans 1’expérience Exp2, les traductions automaﬁques sont utilisées en tant que requétes pour la
RI. On peut espérer que la RI e]le-méme n’est pas trop affectée par les erreurs de traduction, mais
ceci inﬂuence bien s1"1r1e ﬁltrage basé sur le score TER. Nous n’avons pas observé un maximum
du score BLEU en fonction du seuil sur le score TER - dans nos expériences les performances
semblent augmenter de fagon continue. Néanmoins, aﬁn de limiter 1’impact des phrases bruitées,
nous avons choisi un seuil de 70. On peut observer que le score BLEU du systéme adapté est trés
proche de celui de Exp1.Ainsi, nous pouvons conclure que les erreurs commises par la TAS n’ont
pas une inﬂuence importante sur1’a1gorithme d’extraction des phrases paralléles. Ceci conﬁrme
1’ana1yse de (Rauf et Schwenk, 2011).

Notre systéme de base entrainé avec des données génériques obtient un score BLEU de 22,93.
Dans Exp], nous utilisons les traductions de référence en tant que requétes et la RI devrait en
principe trouver toutes les phrases avec un TER de zéro. Les ﬁgures montrent que la RI fonctionne
comme attendu : 1’amé1ioration du score BLEU ne dépend pas du seuil sur le score TER puisque
la plupart des phrases ont effectivement un score TER de zéro. I.’amé1ioration du score BLEU
dépend bien sﬁr de la quantité de données extraites : 1e score BLEU augmente de 22,93 a 24,14
lorsque 100% des données ont été injectées, alors que nous n’obtenons que 23,62 avec 20% des
données TED. Ces résultats nous donnent une borne supérieure des résultats envisageables avec
1’ut1'1isation d’un corpus multimodal.

Finalement, dans Exp3, la RAP est utilisée dont 1e taux d’erreur est d’environ 18%. les phrases
extraites du corpus multimodal permettent d’amé]iorer 1e systéme de traduction : 1e score BLEU
n’est que 0,5 points en dessous de celui obtenu dans Exp] ou Exp2. les résultats obtenus aprés
adaptation du systéme de base sont présentés dans le tableau 4. Dans ce cas, 1e corpus indexé
par la RI est constitué des corpus ccb2_px70 et 'I'EDbi (100%).

452

Phrase extraite

Francais vous allez chez ibm et vous prenez un superordinateur 
Anglais you get a supercomputer because they know 
Test audio
Sortie ASR a supercomputer has calculated that humans and only
Référence a supercomputer has calculated that humans have only 
Traductions de la sortie ASR
Systéme de base un supercomputer a calculé que les humains et seulement 
Systéme adapté un superordinateur a calculé que les humains et seulement 
Référence un superordinateur a calculé que les humains n’ avaient plus que 
Traductions améliorées
Sys de base j’ai écrit un article sur la nourriture génétiquement modiﬁée
Sys adapté j’ai écrit un article sur les produits alimentaires génétiquement modiﬁés
Sys de base yeah tu as raison de réparer
Sys adapté euh oui tu as raison il faut réparer

TABLE 3 — Exemples d’amélioration du systéme de base : vocabulaire enrichi a partir des phrases
paralléles extraites dans la condition Exp3.

Le tableau 5 présente les résultats des systémes adaptés en fonction du degré de similitude du
corpus comparable, dans les conditions d’expérimentation Exp3. Des exemples d’adaptation sont
présentés dans le tableau 3. Nous pouvons remarquer que le degré de similitude est un facteur
important. Un résultat attendu est que lorsque nous augmentons la proportion de corpus du

Expérience Dev Test # mots
Expérience Dev Test Systéme de base 22,93 23,96 -
Systéme de base 22,93 23,96 25% TEDbi 23,11 24,40 ~110k
EXP1 24:14 25:14 50% TEDbi 23,27 24,58 ~215k
EXPZ 23,90 25:15 75% TEDbi 23,43 24,42 ~293k
EXP3 23,40 24,69 100% TEDbi 23,40 24,69 ~393k

TABLE 4 _‘ % B1-Ell °btem15 51_11” 15 D‘‘—‘’ et Test TABLE 5 — Résultats (%BLEU) obtenus avec les
3PTe5 1’3J011t des b1t_ef¢e5 extralts 311 Systeme de systémes adaptés lorsque le degré de similitude
base, dans les cond1t1ons Exp], E)q72 et Exp3. du corpus comparable Varie_

domaine dans le corpus indexé, les performances sont meilleures. Il est important de noter que
lorsque les corpus sont moins similaires, le nombre de phrases conservé est réduit drastiquement
par le ﬁltrage, et donc l’impact de l’adaptation est plus faible. Sans ﬁltrage, les performances du
systéme de base peuvent étre dégradées.

5 Conclusion

Dans ce travail nous avons proposé une méthode permettant d’extraire des textes paralléles
a partir de corpus comparables multimodaux (audio et texte) pour adapter et améliorer des
systémes de traduction automatique statistique. Plusieurs modules sont utilisés pour extraire du

453

texte paralléle : reconnaissance automatique de la parole, traduction automatique et recherche
d’information. Nous validons notre méthode en injectant les données produites dans l’appren-
tissage de nouveaux systémes de 'DkS. Des améliorations en termes de BLEU sont obtenues
pour différents cadres expérimentaux. Il en ressort que l’enchainement des modules ne dégrade
que faiblement les résultats, mais le filtrage des résultats de la RI est nécessaire. Le degré de
similitude du corpus comparable est un facteur important qu’il faudra prendre en compte lorsque
cette architecture sera exploitée dans des conditions réelles.

Remerciements

Ces recherches ont été ﬁnancées par la région des Pays de la Loire sous le projet DEPART3.

Références

DELEGLISE, P., ESTEVE, Y., MEIGNIER, S. et MERLIN, T. (2009). Improvements to the LIUM french ASR system
based on CMU Sphinx : what helps to signiﬁcantly reduce the word error rate ? In Interspeech 2009.

Do, T. N. D., BESACIER, L. et CASTELLI, E. (2010). Apprentissage non supervisé pour la traduction
automatique : application a un couple de langues peu doté. TALN 2010.

FUNG, P. et CHEUNG, P. (2004). Multi—level bootstrapping for extracting parallel sentences from a quasi-
comparable corpus. In Proceedings of COLING '04.

HEWAVITHARANA, S. et VOGEL, S. (2011). Extracting parallel phrases from comparable data. In Proceedings
of the 4th Workshop on Building and Using Comparable Corpora : Comparable Corpora and the Web, BUCC
'11, pages 61-68.

KOEHN, P., HOANG, H., BIRCH, A., CALLIsoN—BURcI-I, C., FEDERICO, M., BERTOLDI, N., CowAN, B., SHEN, W.,
MORAN, C., ZENS, R., DYER, C., BOJAR, 0., CONSTANTIN, A. et HERBST, E. (2007). Moses : open source toolkit
for statistical machine translation. In Proceedings of ACL’07, pages 177-180.

MUNTEANU, D. S. et MARCU, D. (2005). Improving Machine Translation Performance by Exploiting
Non—Parallel Corpora. Computational Linguistics, 31(4) :477-504.

OGILVIE, P. et CALLAN, J. (2001). Experiments using the lemur toolkit. Procedding of the Trenth Text Retrieval
Conference ('IREC—10).

PAPINENI, K., ROUKOS, S., WARD, T. et ZI-IU, W.—J. (2002). Bleu 2 a method for automatic evaluation of
machine translation. In Proceedings ofACL '02, pages 311-318.

PAULIK, M. et WAIBEL, A. (2009). Automatic translation from parallel speech : Simultaneous interpretation
as mt training data. ASRU.

RAUF, S. A. et SCHWENK, H. (2011). Parallel sentence generation from comparable corpora for improved
SMT. 25(4):341-375.

REsNII<, P et SMITH, N. A. (2003). The web as a parallel corpus. Comput. Linguist, 29:349-380.
ROUSSEAU, A., BOUGARES, F., DELEGLISE, P., SCHWENK, H. et ESTEVE, Y. (2011). LIUM’s systems for the IWSLT
2011 speech translation tasks. In Proceedings of IWSL'I"1 1.

STOLKE, A. (2002). Srilm — an extensible language modeling toolkit. ICSLP, pages 901-904.

UTIYAMA, M. et ISAHARA, H. (2003). Reliable measures for aligning japanese—english news articles and
sentences. In Proceedings ofACL’03, volume 1, pages 72-79.

ZHAO, B. et VOGEL, S. (2002). Adaptive parallel sentences mining from web bilingual news collection. In
Proceedings of IEEE International Conference on Data Mining, page 745.

3. h1:1:p://www.proje1:—depar1: . org/

454

