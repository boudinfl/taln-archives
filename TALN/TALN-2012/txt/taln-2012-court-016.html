<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>La reconnaissance automatique de la fonction des pronoms d&#233;monstratifs en langue arabe</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 455&#8211;462,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>La reconnaissance automatique de la fonction des 
pronoms d&#233;monstratifs en langue arabe
</p>
<p>Yacine Ben Yahia, Souha Mezghani Hammami, Lamia Hadrich Belguith
ANLP Research Group &#8211; Laboratoire MIRACL/ FSEGS Sfax, Tunisie.
</p>
<p>anlp-reserach-group@googlegroups.com
benyacine.sint@gmail.com, souha.mezghani@fsegs.rnu.tn, l.belguith@fsegs.rnu.tn
</p>
<p>RESUME____________________________________________________________________________________________________________
La r&#233;solution d'anaphores est l'une des t&#226;ches les plus difficiles du Traitement 
Automatique du Langage Naturel (TALN). La capacit&#233; de classifier les pronoms avant de 
tenter une t&#226;che de r&#233;solution d'anaphores serait importante, puisque pour traiter un
pronom cataphorique le syst&#232;me doit chercher l&#8217;ant&#233;c&#233;dent dans le segment qui suit le 
pronom. Alors que, pour le pronom anaphorique, le syst&#232;me doit chercher l&#8217;ant&#233;c&#233;dent 
dans le segment qui pr&#233;c&#232;de le pronom. En outre, le nombre des pronoms a &#233;t&#233; jug&#233;e
non-trivial dans la langue arabe. C&#8217;est dans ce cadre que se situe notre travail qui 
consiste &#224; proposer une m&#233;thode pour la classification automatique des pronoms 
d&#233;monstratifs arabes, bas&#233;e sur l&#8217;apprentissage. Nous avons &#233;valu&#233; notre approche sur un 
corpus compos&#233; de 365585  mots  contenant 14318 pronoms d&#233;monstratifs et nous 
avons obtenu des r&#233;sultats encourageants : 99.3% comme F-Mesure.
ABSTRACT _________________________________________________________________________________________________________
Automatic recognition of demonstrative pronouns function in Arabic
Anaphora resolution is one of the most difficult tasks in NLP. Classifying pronouns before 
attempting a task of anaphora resolution is important because to handle the cataphoric 
pronoun, the system should determine the antecedent into the segment following the 
pronoun. Although, for the anaphoric pronoun, the system should look for the 
antecedent into the segment before the pronoun. In addition, the number of 
demonstrative pronouns is very important in Arabic. In this paper, we describe a 
machine learning method for classifying demonstrative pronouns in Arabic. We have 
evaluated our approach on a corpus of 365585 words which contain 14318 
demonstrative pronouns and we have obtained encouraging results: 99.3% as F-Measure.
MOTS-CLES : Pronoms d&#233;monstratifs, r&#233;solution des anaphores, traitement de la langue arabe. 
KEYWORDS: Demonstrative pronouns, anaphora resolution, ANLP.
</p>
<p>1 Introduction
La r&#233;solution des anaphores pronominales est l&#8217;une des branches les plus actives du 
domaine de Traitement Automatique du langage Naturel (TALN). Elle consiste &#224; 
identifier l&#8217;ant&#233;c&#233;dent pour chaque pronom. La premi&#232;re &#233;tape de la t&#226;che de r&#233;solution 
des pronoms anaphoriques consiste &#224; distinguer les occurrences r&#233;f&#233;rentielles 
(anaphoriques et cataphoriques)  de celles non-r&#233;f&#233;rentielles. Au niveau de cette &#233;tape, le 
syst&#232;me d&#233;tecte toutes les occurrences non-r&#233;f&#233;rentielles afin d&#8217;&#233;viter la recherche d&#8217;un 
ant&#233;c&#233;dent qui n&#8217;existe pas. En outre, la classification des occurrences r&#233;f&#233;rentielles en 
anaphoriques et cataphoriques est importante pour un syst&#232;me de r&#233;solution. En effet, 
</p>
<p>455</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>pour les pronoms anaphoriques, le syst&#232;me doit chercher l&#8217;ant&#233;c&#233;dent dans le segment 
localis&#233; avant le pronom, alors que, pour les pronoms cataphoriques, le syst&#232;me doit 
chercher l&#8217;ant&#233;c&#233;dent dans le segment qui suit le pronom. Par cons&#233;quent, cette 
classification peut am&#233;liorer la performance du syst&#232;me.
Consid&#233;rons les exemples suivants :
</p>
<p>&#1726;&#1606;&#1575;&#1606;&#1605;&#1576;&#1593;&#1589;&#1604;&#1575;&#1583;&#1575;&#1580;&#1740;&#1573;&#1604;&#1581;&#1575;&#1584;&#1726;&#1604;&#1604;&#1603;&#1588;&#1605;&#1604;&#1575;(1)
/ Ain~ahu mina AlS~aEobi Ii?jaAdu HalK liha*aA Almu$okili/
</p>
<p>Il est difficile de trouver une solution &#224; ce probl&#232;me.
</p>
<p>&#1575;&#1605;&#1583;&#1606;&#1593;&#1578;&#1604;&#1582;&#1583;&#1610;&#1578;&#1582;&#1571;&#1609;&#1601;&#1588;&#1578;&#1587;&#1605;&#1604;&#1575;&#1605;&#1575;&#1593;&#1604;&#1575;&#1548;&#1610;&#1590;&#1575;&#1605;&#1604;&#1575;&#1617;&#1575;&#1606;&#1603;&#1585;&#1590;&#1581;&#1606;&#1575;&#1726;&#1604;&#1610;&#1587;&#1603;&#1587;&#1603;&#1604;&#1575;&#1606;&#1740;&#1580;&#1593;&#1604;&#1575;&#1608;&#1726;&#1593;&#1575;&#1608;&#1606;&#1571;&#1576;(2) 
/EinodamaA daxalato Oxotiy Almusota$ofaY AlEaAma AlmaADiy, kuna~A nuHaD~iru 
</p>
<p>lahaA Alkusokusiy waAlEaji?na biOanowaAEihi/
Quand ma s&#339;ur entra &#224; l'h&#244;pital l'ann&#233;e derni&#232;re, nous lui avons apport&#233; le couscous et les divers 
</p>
<p>types de p&#226;tes
</p>
<p>&#1575;&#1584;&#1726;&#1593;&#1575;&#1585;&#1578;&#1582;&#1604;&#1575;&#1575;&#1605;&#1726;&#1605;&#1575;&#1583;&#1580;(3) 
/ha*aA AlIixotiraAEu muhimN jid~FA/
</p>
<p>Cette invention est tr&#232;s importante.
</p>
<p>Le pronom (&#1726;&#1600;/hu/il), dans l&#8217;exemple (1) ne se r&#233;f&#232;re &#224; aucun syntagme nominal. Il est 
donc non-r&#233;f&#233;rentiel. Cependant, dans l&#8217;exemple (2), le pronom (&#1575;&#1726;/hA/lui) poss&#232;de 
comme ant&#233;c&#233;dent le syntagme (&#1610;&#1578;&#1582;&#1571;/&gt;xty/ma s&#339;ur) ; de ce faite il est anaphorique. Le 
pronom (&#1575;&#1584;&#1726;/h*A/cette), dans l&#8217;exemple (3) est cataphorique puisqu&#8217;il se r&#233;f&#232;re au nom 
(&#1593;&#1575;&#1585;&#1578;&#1582;&#1604;&#1575;&#1575;/AlAxtrAE/invention) situ&#233; apr&#232;s le pronom. Ainsi, un syst&#232;me de r&#233;solution des 
anaphores doit chercher les ant&#233;c&#233;dents seulement pour les pronoms des exemples (2) et 
(3).
Vu l&#8217;importance de la classification automatique des pronoms, plusieurs chercheurs se 
sont int&#233;ress&#233;s &#224; ce sujet. Certains travaux ont vis&#233; la distinction des pronoms personnels 
de ceux impersonnels ((Lappin et Leass, 1994), (Boyd et a, 2005), (Weissenbacher et 
Nazarenko, 2007), (Hammami et al, 2010)). D&#8217;autres travaux se sont int&#233;ress&#233;s aux 
pronoms d&#233;monstratifs tels que les travaux de (Muller, 2007), (Byron, 2002) pour 
l&#8217;anglais, le travail de (Navaretta, 2009) pour le danois et le travail de (Dutta et al, 2010)
pour l&#8217;Hindo. A notre connaissance, il n&#8217;existe pas de travaux similaires pour la 
classification des pronoms d&#233;monstratifs en langue arabe.
Dans cet article, nous proposons une m&#233;thode d&#8217;apprentissage pour la classification 
automatique des pronoms d&#233;monstratifs en langue arabe. Cette m&#233;thode permet de 
classifier les pronoms d&#233;monstratifs en pronoms d&#233;monstratifs cataphoriques et pronoms 
d&#233;monstratifs anaphoriques. Elle se base, d&#8217;une part, sur un ensemble de crit&#232;res 
contextuels et d&#8217;autre part sur des techniques d&#8217;apprentissage. La section 2 pr&#233;sente la 
sp&#233;cificit&#233; des pronoms d&#233;monstratifs arabes. La section 3 donne un aper&#231;u sur l&#8217;&#233;tat de 
l&#8217;art pour la classification des pronoms. Dans la quatri&#232;me section, nous d&#233;crivons la 
m&#233;thode propos&#233;e pour la classification des pronoms d&#233;monstratifs. Enfin, nous 
pr&#233;sentons nos exp&#233;rimentations et nous discutons les r&#233;sultats obtenus.
</p>
<p>456</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>2 Les pronoms d&#233;monstratifs en langue Arabe
Selon la litt&#233;rature, les pronoms d&#233;monstratifs sont fr&#233;quemment utilis&#233;s en langue 
arabe. Comme pour l&#8217;anglais (this, these&#8230;) et le fran&#231;ais (ceci, celui-ci, celle-l&#224;, celui-
l&#224;,&#8230;), il existe dans la langue arabe des pronoms qui d&#233;signent le singulier (&#1575;&#1584;&#1726;/h*A/, 
&#1607;&#1584;&#1726;/h*h/) et le pluriel (&#1569;&#1604;&#1575;&#1572;&#1726;/hWlA'/, &#1603;&#1574;&#1604;&#1608;&#1571;/Awl}k/). Ce pendant, il existe des pronoms 
d&#233;monstratifs qui d&#233;signent le duel tels que : &#1606;&#1575;&#1584;&#1726;/h*An/, &#1606;&#1575;&#1578;&#1575;&#1726;/htAn/, &#1575;&#1605;&#1603;&#1604;&#1584;/*lkmA/, 
&#1575;&#1605;&#1603;&#1604;&#1578;/tlkmA/, &#1603;&#1606;&#1575;&#1584;/*Ank/. Ce qui n&#8217;est pas le cas pour le fran&#231;ais ou l&#8217;anglais. En outre, il 
existe des pronoms, qui sont consid&#233;r&#233;s comme d&#233;monstratifs, et qui d&#233;signent le temps 
(&#1603;&#1575;&#1584;&#1606;&#1740;&#1581;/Hyn*Ak/, &#1603;&#1575;&#1584;&#1606;&#1571;/On*Ak/) et le lieu (&#1575;&#1606;&#1726;/hnA/, &#1603;&#1575;&#1606;&#1726;/hnAkA/, &#1603;&#1604;&#1575;&#1606;&#1726;/hnAlkA/, 
&#1575;&#1606;&#1726;&#1726;/hhnA/,  &#1614;&#1617;&#1605;&#1579;/vm~/). 
D&#8217;apr&#232;s notre &#233;tude statistique, il y a des pronoms qui sont utilis&#233;s beaucoup plus que 
d&#8217;autres tels que les pronoms &#1575;&#1584;&#1726;/h*A/&#1548; &#1603;&#1604;&#1578;/tlk/, &#1607;&#1584;&#1726;/h*h/&#1548; &#1603;&#1604;&#1584;/*lk/. L&#8217;utilisation des 
pronoms d&#233;monstratifs (*lkmA/&#1575;&#1605;&#1603;&#1604;&#1584;, *lkm/&#1605;&#1603;&#1604;&#1584;, tlkmA/&#1575;&#1605;&#1603;&#1604;&#1578;, *lkn/&#1606;&#1603;&#1604;&#1584;) est presque 
n&#233;gligeable (ils apparaissent dans le saint coran ou dans les anciens livres arabes).
</p>
<p>3 Travaux ant&#233;rieurs
L&#8217;anaphore pronominale est le type d&#8217;anaphore le plus fr&#233;quent (Mitkov, 2002), c&#8217;est 
pourquoi la r&#233;solution automatique des pronoms est un domaine de recherche qui a 
suscit&#233; &#233;norm&#233;ment d'attention depuis plusieurs ann&#233;es. Un syst&#232;me de r&#233;solution des 
anaphores pronominales doit &#234;tre capable de distinguer les occurrences des pronoms 
non-r&#233;f&#233;rentielles de celles r&#233;f&#233;rentielles avant de s'attaquer &#224; leur r&#233;solution. De 
nombreux travaux se sont int&#233;ress&#233;s particuli&#232;rement &#224; cette &#233;tape vue son importance 
et sa difficult&#233;.
La plus part des chercheurs se sont int&#233;ress&#233;s aux pronoms personnels. Nous pouvons 
distinguer trois types d&#8217;approches : une approche &#224; base de r&#232;gles telle que les travaux 
de (Paice et Husk, 1987), (Lappin et Leass, 1994) et (Denber, 1998) pour l&#8217;anglais, et 
(Hammami, 2009) pour l&#8217;arabe. Afin de rem&#233;dier aux inconv&#233;nients rencontr&#233;s au 
niveau de l&#8217;approche pr&#233;c&#233;dente, d&#8217;autres auteurs ont adopt&#233; une approche num&#233;rique 
bas&#233;e sur des m&#233;thodes d&#8217;apprentissages telle que les travaux d&#8217; (Evans, 2001) et 
(Bergsma, 2008).
D&#8217;autres, ont fait recours &#224; la combinaison des deux approches pr&#233;c&#233;dentes telles que les 
travaux de (Boyd et al, 2005), (Weissenbacher et Nazarenko, 2007), (Hammami et al., 
2010) et (AbdulMajeed, 2011).
Cependant, la classification des pronoms d&#233;monstratifs n'a pas encore re&#231;u beaucoup 
d'attention. (Byron, 2002) d&#233;crit un syst&#232;me pour la r&#233;solution des pronoms it, this et 
that dans les dialogues dans un domaine sp&#233;cifique. Ce syst&#232;me, appel&#233; PHORA, est 
impl&#233;ment&#233; et bas&#233; sur des connaissances s&#233;mantiques. Le r&#233;sultat d&#8217;&#233;valuation &#233;tait 
67% et 62% respectivement pour la pr&#233;cision et le rappel.
(M&#252;ller, 2007) a propos&#233; une approche bas&#233;e sur l&#8217;apprentissage automatique pour la 
r&#233;solution des pronoms it, this et that. Cet algorithme a utilis&#233; cinq corpus diff&#233;rents 
compos&#233;s de dialogues pour l&#8217;apprentissage et le test, et il repose exclusivement sur 
l&#8217;annotation du corpus. Les r&#233;sultats de cet algorithme sont moins performants que ceux 
</p>
<p>457</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>des algorithmes reposant sur des connaissances linguistiques et des structures de 
discoures complexes.
(Navaretta, 2009) d&#233;crit des exp&#233;rimentations d&#8217;apprentissage supervis&#233; (classification) 
et non supervis&#233; (clustering) dans le but de reconnaitre la fonction du pronom neutre 
singulier dans la langue danoise. Le corpus utilis&#233; est tr&#232;s h&#233;t&#233;rog&#232;ne. Il est compos&#233; de 
quatre parties : des textes &#233;crits, des transcriptions de monologue, des dialogues et une 
interview de TV. La classification de la fonction du pronom neutre singulier comprend 
neuf classes telles que  la classe expl&#233;tive (non-r&#233;f&#233;rentiel), cataphorique, d&#233;ictique, 
anaphore individuelle, etc. Le meilleur algorithme pour le clustering est Expectation 
Maximisation de l&#8217;outil Weka. Les r&#233;sultats obtenus pour les textes &#233;crits sont plus 
int&#233;ressants que pour les autres corpus. Pour la classification, plusieurs algorithmes ont 
&#233;t&#233; examin&#233;s. Pour estimer la performance de son syst&#232;me, Navaretta utilise la m&#233;thode 
d&#8217;&#233;chantillonnage validation crois&#233;e (10 cross-validation). Elle a fix&#233; l&#8217;algorithme ZeroR 
de Weka comme baseline. Les meilleurs algorithmes sont NBTree, SMO, SMO et KStar 
respectivement pour les corpus de textes, monologues, dialogue  et l&#8217;interview.
(Dutta et al., 2010) proposent une application pour la classification des pronoms 
d&#233;monstratifs &#171; yeh &#187;, &#171; veh &#187;, &#171; iss &#187; et &#171; uss &#187; en langue Hindo. Cette classification est 
bas&#233;e sur le formalisme du r&#233;seau de neurone probabiliste (PNN). Comme premi&#232;re 
&#233;tape, ils ont extrait des patrons et des caract&#233;ristiques pour l&#8217;identification des pronoms 
d&#233;monstratifs indirects. Ensuite, ils ont appliqu&#233; l&#8217;algorithme bas&#233; sur le mod&#232;le PNN en 
utilisant la validation crois&#233;e. Enfin, des exp&#233;rimentations sont effectu&#233;es pour 
l&#8217;ensemble des donn&#233;es contenant les pronoms d&#233;monstratifs et aussi les occurrences des 
pronoms d&#233;monstratifs non r&#233;f&#233;rentielles. Les meilleurs r&#233;sultats sont 94.90% pour tous 
les pronoms d&#233;monstratifs et 84.16% pour les pronoms non-r&#233;f&#233;rentiels comme taux de 
r&#233;ussite.
</p>
<p>4 M&#233;thode propos&#233;e
La m&#233;thode que nous proposons pour la classification automatique des pronoms 
d&#233;monstratifs arabes est compos&#233;e de deux phases &#224; savoir la phase d&#8217;apprentissage et la 
phase de test.
La phase d&#8217;apprentissage permet d&#8217;apprendre &#224; classifier les pronoms. Elle accepte, en 
entr&#233;e, un corpus annot&#233; et elle est compos&#233;e de trois &#233;tapes &#224; savoir la segmentation, 
l&#8217;analyse morphologique et l&#8217;extraction des r&#232;gles. L&#8217;&#233;tape de segmentation consiste &#224; 
segmenter les textes de notre corpus. Les textes sont  segment&#233;s en phrases dans le but 
de connaitre les fronti&#232;res des phrases contenant un pronom d&#233;monstratif. Le texte 
segment&#233; sera par la suite analys&#233; morphologiquement afin d&#8217;identifier les 
caract&#233;ristiques morphologiques des mots de chaque texte de notre corpus. Cette &#233;tape 
va servir &#224; d&#233;terminer les valeurs des crit&#232;res de classification que nous utilisons dans 
l&#8217;&#233;tape d&#8217;extraction des r&#232;gles. Pour &#233;tablir cette derni&#232;re, nous avons d&#233;gag&#233; huit 
crit&#232;res de classification &#224; savoir :
</p>
<p>- POS+1 : (Part Of Speech) ce crit&#232;re prend la cat&#233;gorie du mot qui suit le 
pronom. Les valeurs possibles pour ce crit&#232;re sont : Nom-propre, Nom, Particule, 
D&#233;limiteur ou Inconnu (dans le cas o&#249; la cat&#233;gorie du mot n&#8217;a pas pu &#234;tre 
identifi&#233;e).
</p>
<p>458</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>- Type : Dans le cas o&#249;  le crit&#232;re POS+1 prend la valeur Particule, alors le crit&#232;re 
Type prend le type de cette particule qui peut &#234;tre : particule de coordination, 
particule de conjonction, particule d&#8217;exception, conjonction d&#8217;appel, conjonction 
de n&#233;gation, conjonction de condition, etc.
</p>
<p>- Determine : Dans le cas o&#249; le crit&#232;re POS+1 prend la valeur Nom, le crit&#232;re 
Determine prend la valeur &#171; match &#187; si ce Nom est d&#233;fini (c'est-&#224;-dire agglutin&#233; &#224; 
&#1604;&#1575;). Sinon il prend la valeur &#171; nomatch &#187;.
</p>
<p>- Enclitique : Si le mot qui suit le pronom est un Nom, et ce nom est agglutin&#233; &#224; un 
enclitique, alors, ce crit&#232;re prend la valeur &#171; match &#187;.
</p>
<p>- Proclitique+1 : Si le mot qui suit le pronom est agglutin&#233; &#224; un proclitique, alors, 
ce crit&#232;re prend la valeur &#171; match &#187;.
</p>
<p>- Bimafidhalika : Ce crit&#232;re prend la valeur &#171; match &#187; si le pronom (*lk / &#1603;&#1604;&#1584;) est 
pr&#233;c&#233;d&#233; par une succession des deux mots (bmA &#1575;&#1605;&#1576;/) et (fy&#1610;&#1601;/).
</p>
<p>- MotSpec : Si le pronom est suivi d&#8217;un mot sp&#233;cifique ce crit&#232;re prend la valeur &#171; 
match &#187;. La liste des mots sp&#233;cifiques est compos&#233;e des mots suivants: 
OyDA/&#1575;&#1590;&#1740;&#1571;, gyr/&#1585;&#1740;&#1594;, mmA/&#1575;&#1617;&#1605;&#1605;, kl/&#1604;&#1603;.
</p>
<p>- Pronom : ce crit&#232;re re&#231;oit le pronom &#224; apprendre.
L&#8217;&#233;tape d&#8217;extraction des r&#232;gles exploite ces crit&#232;res de classification pour produire des 
r&#232;gles appel&#233;es r&#232;gles de classification, en utilisant un algorithme d&#8217;apprentissage.
La phase de test permet de classifier un nouveau pronom d&#233;monstratif en pronom 
anaphorique ou pronom cataphorique. Elle accepte en entr&#233;e un texte brut qui sera par 
la suite segment&#233; en phrases et analys&#233; morphologiquement. L&#8217;&#233;tape d&#8217;identification des 
pronoms d&#233;monstratifs consiste &#224; identifier les pronoms d&#233;monstratifs figurant dans le 
texte afin de les classifier automatiquement. La d&#233;tection des pronoms se fait d&#8217;une 
mani&#232;re automatique en examinant le texte analys&#233; morphologiquement et en faisant 
ressortir les mots qui ont comme cat&#233;gorie pronom d&#233;monstratif (Asm I$Arp/ &#1605;&#1587;&#1575;&#1577;&#1585;&#1575;&#1588;&#1573; ). 
Enfin, les pronoms identifi&#233;s seront classifi&#233;s en pronoms d&#233;monstratifs anaphoriques ou 
pronoms d&#233;monstratifs cataphoriques en se basant sur les r&#232;gles d&#8217;extraction g&#233;n&#233;r&#233;es 
par la phase d&#8217;apprentissage.
</p>
<p>5 Exp&#233;rimentations
5.1 Corpus 
</p>
<p>Le processus de classification &#224; base d&#8217;apprentissage n&#233;cessite g&#233;n&#233;ralement un corpus 
annot&#233; afin d&#8217;assurer la phase d&#8217;entra&#238;nement. Il est &#224; signaler que la constitution d&#8217;un 
corpus de r&#233;f&#233;rence (corpus d&#8217;apprentissage) est co&#251;teuse. Ainsi, et vu le manque de 
corpus &#233;tiquet&#233;s pour la langue arabe, nous avons proc&#233;d&#233; &#224; une &#233;tape d&#8217;annotation 
binaire des documents constituant notre corpus. Il s&#8217;agit d&#8217;attribuer &#224; chaque pronom 
d&#233;monstratif la classe anaphorique ou cataphorique. Pour acc&#233;l&#233;rer notre travail, nous 
avons d&#233;velopp&#233; un syst&#232;me d&#8217;annotation manuelle AnnotAr. Ce syst&#232;me accepte en 
entr&#233;e un texte segment&#233; en mot sous le format XML et permet &#224; l&#8217;utilisateur d&#8217;annoter 
les pronoms d&#233;monstratifs dans le texte en pronoms anaphoriques ou cataphoriques. Le 
texte annot&#233; est enregistr&#233; sous format XML o&#249; chaque pronom d&#233;monstratifs est 
&#233;tiquet&#233; par la balise qui lui correspond (c&#8217;est-&#224;-dire &lt;ANA&gt; pour le pronom 
anaphorique et &lt;CATA&gt; pour le pronom cataphorique). 
</p>
<p>459</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Le corpus d&#8217;apprentissage est compos&#233; d&#8217;un ensemble d&#8217;articles de presse d&#8217;ELMASRY 
ALYOUM 2010, de textes de livres scolaires, de l&#8217;enseignement Tunisien de diff&#233;rents 
niveaux (un texte contient en moyenne vingt cinq phrases), des manuels d&#8217;utilisation (la 
taille moyenne d&#8217;un manuel est de trente pages) et un extrait du Penn Arabic TreeBank 
(ATB). Nous avons choisi un corpus de nature vari&#233;e parce que nous estimons que plus le 
corpus est diversifi&#233; plus il sera repr&#233;sentatif.  Ce corpus contient un total de 365585
mots et nous a permis d&#8217;analyser 14318 pronoms d&#233;monstratifs (o&#249; 32.15% sont 
anaphoriques et 67.85% sont cataphoriques).
</p>
<p>Corpus Anaphorique Cataphorique Total
Nombre Pourcentage(%) Nombre Pourcentage(%)
</p>
<p>Livres 1072 33.29 2148 66.71 3220
</p>
<p>Journaux 2562 31.88 5472 68.12 8034
</p>
<p>Manuels 155 29.41 372 70.59 527
</p>
<p>ATB 815 47.32 1722 52.68 2537
</p>
<p>Total 4604 32.15 9714 67.85 14318
TABLE 1:Statistiques du corpus
</p>
<p>5.2 R&#233;sultats et discussion
Nous avons effectu&#233; nos exp&#233;rimentations de classification en utilisant le syst&#232;me Weka
(Frank, Witten, 2005) qui permet de tester et de comparer plusieurs algorithmes. Nous 
avons choisi de tester les algorithmes suivants: IBk, JRip, NBTree et NaiveBayes.
Nous avons proc&#233;d&#233; &#224; une validation crois&#233;e pour valider les r&#233;sultats de nos 
exp&#233;riences. Nous avons s&#233;lectionn&#233; al&#233;atoirement le neuf dixi&#232;me du corpus pour 
l&#8217;apprentissage. Nous avons ensuite appliqu&#233; notre syst&#232;me sur le un dixi&#232;me restant. 
Nous avons r&#233;it&#233;r&#233; dix fois ces op&#233;rations en changeant &#224; chaque fois la partie de test, 
pour obtenir la moyenne des performances de chaque it&#233;ration. Les attributs pertinents 
d&#8217;apr&#232;s Weka sont : POS+1, Type, Determine, procltique+1, Pronom et motSpec.
Afin de bien &#233;valuer notre syst&#232;me, nous avons impl&#233;ment&#233; un syst&#232;me Baseline &#224; base 
des r&#232;gles. Le syst&#232;me Baseline repose sur six r&#232;gles contextuelles qui se basent 
principalement sur les caract&#233;ristiques morphologiques du mot qui suit le pronom 
d&#233;monstratif (ex. pr_dem+Nom-d&#233;fini --&gt; pr-cataph, pr_dem+pr-relatif --&gt; pr-cataph). 
Les r&#233;sultats obtenus sont pr&#233;sent&#233;s dans le Tableau 2.
</p>
<p>Algorithme
R&#233;sultats avec annotation 
</p>
<p>morphologique automatique 
(MORPH2)
</p>
<p>R&#233;sultats avec annotation 
morphologique manuelle
</p>
<p>Pr&#233;cision Rappel F-Mesure Pr&#233;cision Rappel F-Mesure
IBk 94.7% 94.7% 94.7% 99.3% 99.3% 99.3%
</p>
<p>460</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>JRip 93.9% 93.9% 93.9% 99% 99% 99%
</p>
<p>NBTree 94.7% 94.7% 94.7% 99.2% 99.2% 99.2%
</p>
<p>NaiveBayes 92.8% 92.8% 92.8% 96.2% 96.2% 96.2%
</p>
<p>Baseline 78.09% 75.39% 76.72% 97.87% 98.89% 98.38%
TABLE 2 : R&#233;sultats obtenus avec la validation crois&#233;e
</p>
<p>En examinant les mesures de rappel, pr&#233;cision et F-mesure calcul&#233;es sur le corpus 
d&#8217;&#233;valuation, nous remarquons que les r&#233;sultats sont tr&#232;s encourageants. 
D&#8217;une part, l&#8217;utilisation de l&#8217;apprentissage a am&#233;lior&#233; les r&#233;sultats d&#8217;une mani&#232;re 
significative (16.61% et 15.81% respectivement pour IBk et JRip) par rapport au 
Baseline (m&#233;thode &#224; base de r&#232;gles). Cela justifie notre choix d&#8217;une m&#233;thode 
d&#8217;apprentissage qui r&#233;duit l&#8217;erreur d&#8217;estimation en d&#233;terminant le poids des attributs 
discriminants pour le domaine du corpus.
D&#8217;autre part, nous remarquons que l&#8217;algorithme IBk (K Plus Proche Voisin) donne les 
meilleurs r&#233;sultats par rapport aux autres algorithmes. Ensuite, nous avons men&#233; deux 
&#233;valuations. Au niveau de la premi&#232;re, nous avons utilis&#233; l&#8217;analyseur morphologique
MORPH2 (Chaaben et al, 2010) pour l&#8217;&#233;tiquetage morphologique de notre corpus. Au
niveau de la deuxi&#232;me &#233;valuation, nous avons corrig&#233; manuellement les r&#233;sultats de 
MORPH2. En effet, l&#8217;utilisation d&#8217;un &#233;tiquetage morphologique manuel a am&#233;lior&#233; les 
r&#233;sultats d&#8217;une mani&#232;re significative (environ 5% pour l&#8217;apprentissage et 21.66% pour le 
Baseline). 
Les principales erreurs sont dues &#224; des constructions sp&#233;cifiques de phrases contenant un 
pronom d&#233;monstratif ainsi le manque de ponctuations en langue arabe (Belguith et al., 
2005). Citons l&#8217;exemple suivant :
</p>
<p>(4) ...&#1569;&#1575;&#1605;&#1604;&#1575; &#1606;&#1605; &#1585;&#1740;&#1579;&#1603;&#1604;&#1575; &#1603;&#1604;&#1584; &#1603;&#1604;&#1726;&#1578;&#1587;&#1740; &#1583;&#1602;.
/qado yasotaholiku *alika Alkaviyra mina AlmaA'i/
</p>
<p>&#199;a peut consommer beaucoup d&#8217;eau.
Dans cet exemple, le pronom d&#233;monstratif (&#1603;&#1604;&#1584;, /*lk/, &#231;a) est suivi par le nom d&#233;fini 
(&#1585;&#1740;&#1579;&#1603;&#1604;&#1575;, /Alkvyr/, beaucoup). En appliquant l&#8217;apprentissage ou la m&#233;thode de Baseline, ce 
pronom d&#233;monstratif est class&#233; cataphorique alors qu&#8217;il est anaphorique. Cette fausse 
classification est due &#224; l&#8217;absence de la virgule apr&#232;s le pronom d&#233;monstratif.
</p>
<p>6 Conclusion
La classification des pronoms d&#233;monstratifs est une &#233;tape tr&#232;s importante dans le 
processus de la r&#233;solution de l&#8217;anaphore pronominale. Dans cet article, nous avons 
propos&#233; une m&#233;thode d&#8217;apprentissage pour la classification binaire des pronoms 
d&#233;monstratifs en langue arabe en pronom anaphoriques et cataphoriques. Cette m&#233;thode 
d&#8217;apprentissage propos&#233;e atteint des r&#233;sultats meilleurs que celle &#224; base des r&#232;gles. Ainsi 
l&#8217;algorithme K-PPV a donn&#233; un meilleur r&#233;sultat. En se basant sur ces r&#233;sultats, nous 
envisageons de chercher les ant&#233;c&#233;dents des pronoms et de terminer les &#233;tapes de la 
r&#233;solution d&#8217;anaphores.
</p>
<p>461</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;f&#233;rences
C. PAICE ET G. HUSK (1987). Towards the automatic recognition of anaphoric features in 
English text: the impersonal pronoun it. Computer Speech and Language.
D. WEISSENBACHER ET A. NAZARENKO (2007). A bayesian classifier for the recognition of the 
impersonal occurrences of the it pronoun. In Proceedings of DAARC&#8217;07, 2007.
S. LAPPIN ET H. LEASS (1994). An algorithm for pronominal anaphora resolution, 
Computational Linguistics, 20(4), 1994, p. 535&#8211;561.
S. MEZGHANI HAMMAMI., R.SELLAMI, L. HADRICH BELGUITH (2010). A Bayesian Classifier for 
the Identification of Non-referential Pronouns in Arabic. The 7th INFOS 2010.
S. HAMMAMI, L. BELGUITH, A. BEN HAMADOU (2009). A Rule-Based Method for Detecting 
Arabic Anaphoric Pronouns. Proceedings of the 7th DAARC&#8217;2009, Goa-India, 2009.
R. EVANS (2001). Applying machine learning toward an automatic classi&#999;cation of it. 
Literary and linguistic computing, 16, 2001, p. 45&#8211;57.
M. DENBER (1998). Automatic resolution of anaphora in English. Eastman Kodak Co, 1998.
ABDUL-MAGEED, M. 2011. Automatic detection of Arabic non-anaphoric pronouns for 
improving anaphora resolution. Asian Lang. Inform. Process. (March 2011).
S. BERGSMA, D. LIN ET R. GOEBEL (2008). Distributional Identification of Non-Referential 
Pronouns. ACL, Columbus Ohio, 2008, p. 10-18.
A. BOYD, W. GEGG-HARRISON ET D. BYRON (2005). Identifying non-referential it: a machine 
learning approach incorporating linguistically motivated features. Workshop on Feature 
Engineering for Machine Learning in Natural Language Processing, 2005.
C. M&#220;LLER (2007).Resolving It, This, and That in Unrestricted Multi-Party Dialog. In 
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, 2007.
D. BYRON (2002). Resolving Pronominal Reference to Abstrac Entities. In Proceedings of th 
40th Annual Meeting of the Association of Computation Linguistics (ACL), Philadelphia 2002.
C. NAVARETTA (2009). Automatic Recognition of the Function of Singular Neuter 
Pronouns in Texts and Spoken Data. In DAARC 2009.
K. DUTTA , N. PRAKASH, S. KAUSHIK (2010). Probabilistic neural network approach to the 
classification of demonstrative pronouns for indirect anaphora in Hindi. International 
Journal Information Technology and Intelligent Computing, 2010.
N. CHA&#194;BEN KAMMOUN, L. HADRICH BELGUITH ET A. BEN HAMADOU (2010). The MORPH2 
new version: A robust morphological analyzer for Arabic texts. JADT&#8217;2010.
E. FRANK, IAN H. WITTEN (2005). Practical Machine Learning Tools and Techniques, 
Second Edition. (Morgan Kaufmann series in data management systems).
BELGUITH, L., BACCOUR, L. AND MOURAD, G. (2005). Segmentation de textes arabes bas&#233;e sur 
l'analyse contextuelle des signes de ponctuations et de certaines particules (TALN&#8217;2005).
MITKOV (2002): R. Mitkov, &#171;Anaphora resolution&#187;. Longman. 2002.
</p>
<p>462</p>

</div></div>
</body></html>