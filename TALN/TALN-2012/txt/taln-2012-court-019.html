<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Combinaison de ressources g&#233;n&#233;rales pour une contextualisation implicite de requ&#234;tes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 479&#8211;486,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>TALN 2011, Montpellier, 27 juin &#8211; 1er juillet 2011
</p>
<p>Combinaison de ressources g&#233;n&#233;rales pour une
contextualisation implicite de requ&#234;tes
</p>
<p>Romain Deveaud1 Patrice Bellot2
(1) LIA - Universit&#233; d&#8217;Avignon
</p>
<p>romain.deveaud@univ-avignon.fr
(2) LSIS - Universit&#233; Aix-Marseille
patrice.bellot@lsis.org
</p>
<p>R&#201;SUM&#201;
L&#8217;utilisation de sources externes d&#8217;informations pour la recherche documentaire a &#233;t&#233; consid&#233;ra-
blement &#233;tudi&#233;e dans le pass&#233;. Des am&#233;liorations de performances ont &#233;t&#233; mises en lumi&#232;re avec
des corpus larges ou structur&#233;s. N&#233;anmoins, dans ces &#233;tudes les ressources sont souvent utilis&#233;es
s&#233;par&#233;ment mais rarement combin&#233;es. Nous pr&#233;sentons une &#233;valuation de la combinaison de
quatre diff&#233;rentes ressources g&#233;n&#233;rales, standards et accessibles. Nous utilisons une mesure de
distance informative pour extraire les caract&#233;ristiques contextuelles des diff&#233;rentes ressources et
am&#233;liorer la repr&#233;sentation de la requ&#234;te. Cette &#233;valuation est men&#233;e sur une t&#226;che de recherche
d&#8217;information sur le Web en utilisant le corpus ClueWeb09 et les topics de la piste Web de TREC.
Les meilleurs r&#233;sultats sont obtenus en combinant les quatre ressources, et sont statistiquement
significativement sup&#233;rieurs aux autres approches.
</p>
<p>ABSTRACT
Query Contextualization and Reformulation by Combining External Corpora
</p>
<p>Improving document retrieval using external sources of information has been extensively studied
throughout the past. Improvements with either structured or large corpora have been reported.
However, in these studies resources are often used separately and rarely combined together. We
present an evaluation of the combination of four different scalable corpora over a web search
task. An informative divergence measure is used to extract contextual features from the corpora
and improve query representation. We use the ClueWeb09 collection along with TREC&#8217;s Web
Track topics for the purpose of our evaluation. Best results are achieved when combining all four
corpora, and are significantly better than the results of other approaches.
</p>
<p>MOTS-CL&#201;S : Combinaison de ressources, RI contextuelle, recherche web.
</p>
<p>KEYWORDS: Resources combination, contextual IR, web search.
</p>
<p>1 Introduction
</p>
<p>La recherche d&#8217;information a pour but de satisfaire le besoin d&#8217;information d&#8217;un utilisateur.
En effet, lorsqu&#8217;un utilisateur effectue une recherche dans une base documentaire, il fournit
au syst&#232;me une repr&#233;sentation de son besoin d&#8217;information. Le r&#244;le du syst&#232;me est alors de
prendre en compte cette repr&#233;sentation et de pr&#233;senter &#224; l&#8217;utilisateur un ensemble de documents
pertinents par rapport au besoin d&#8217;information initial. Ces documents sont g&#233;n&#233;ralement pr&#233;sent&#233;s
</p>
<p>479</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>sous une forme de liste et ordonn&#233;s par ordre d&#233;croissant de pertinence. Il existe des mod&#232;les de
recherche d&#8217;information qui permettent de r&#233;cup&#233;rer efficacement des documents par rapport
&#224; une requ&#234;te, qui joue le r&#244;le de la repr&#233;sentation d&#8217;un besoin d&#8217;information. La difficult&#233;
r&#233;side donc dans la capacit&#233; de l&#8217;utilisateur &#224; repr&#233;senter son besoin d&#8217;information d&#8217;une fa&#231;on
ad&#233;quate pour le syst&#232;me. Seulement, les requ&#234;tes formul&#233;es par ces utilisateurs ne d&#233;crivent
pas toujours parfaitement ce besoin, et des connaissances additionnelles sont parfois n&#233;cessaires
pour compl&#233;ter cette description manquante. Une des mani&#232;res de mieux d&#233;finir le sujet d&#8217;une
recherche est d&#8217;enrichir la requ&#234;te originale avec des informations suppl&#233;mentaires. Celles-ci
consistent traditionnellement en des mots que l&#8217;on va ajouter &#224; la requ&#234;te form&#233;e par l&#8217;utilisateur.
Typiquement, ces mots sont extraits de documents r&#233;cup&#233;r&#233;s en utilisant la requ&#234;te initiale. Les
documents peuvent provenir de la collection cible (la base de documents au sein de laquelle le
syst&#232;me effectue la recherche) (Harman, 1992) ou de collections externes.
</p>
<p>Les collections externes utilis&#233;es peuvent &#234;tre de types tr&#232;s diff&#233;rents. Elles peuvent &#234;tre g&#233;n&#233;rales
ou sp&#233;cifiques &#224; un domaine pr&#233;cis, structur&#233;es ou non, ou encore construites automatiquement
ou manuellement. L&#8217;utilisation de ressources externes a &#233;t&#233; consid&#233;rablement &#233;tudi&#233;e dans le
pass&#233;, et elle a prouv&#233; son efficacit&#233; &#224; am&#233;liorer les performances des syst&#232;mes de recherche
d&#8217;information lorsqu&#8217;ils choisissent les donn&#233;es appropri&#233;es. Ces &#233;tudes se concentrent princi-
palement sur la mani&#232;re dont une ressource individuelle peut am&#233;liorer les performances d&#8217;un
syst&#232;me de recherche d&#8217;information, mais proposent rarement d&#8217;utiliser ces ressources conjoin-
tement. Des sources de donn&#233;es telles que Wikip&#233;dia (Li et al., 2007; Suchanek et al., 2007),
WordNet (Liu et al., 2004; Suchanek et al., 2007; Fang, 2008), des articles journalistiques ou en-
core le web lui-m&#234;me (Diaz et Metzler, 2006) ont &#233;t&#233; utilis&#233;es. Dans leur &#233;tude, (Diaz et Metzler,
2006) exp&#233;rimentent l&#8217;utilisation de ressources externes larges et g&#233;n&#233;rales. Ils pr&#233;sentent un
mod&#232;le qui permet d&#8217;incorporer des donn&#233;es additionnelles &#224; la fa&#231;on d&#8217;un retour de pertinence
simul&#233; (Lavrenko et Croft, 2001), et ils l&#8217;&#233;valuent en consid&#233;rant un corpus d&#8217;actualit&#233; et deux
corpus de pages web comme ressources externes. Ils d&#233;montrent que chaque ressource am&#233;liore
les performances du syst&#232;me de recherche d&#8217;information ind&#233;pendamment, mais ils ne reportent
pas d&#8217;exp&#233;riences sur une combinaison de ces ressources. D&#8217;un autre c&#244;t&#233;, (Mandala et al., 1999)
pr&#233;sentent dans leur travail une m&#233;thode d&#8217;enrichissement qui combine des caract&#233;ristiques
extraites de WordNet et de deux thesaurus sp&#233;cifiques cr&#233;&#233;s &#224; partir de la collection de documents.
Le premier a pour but d&#8217;identifier les relations s&#233;mantiques entre deux mots en calculant ses
co-occurrences. Le second se concentre sur la pond&#233;ration de paires de mots li&#233;s par leur relation
syntaxique. Cette &#233;tude est une des seules qui rapporte des am&#233;liorations de performance en
combinant plusieurs ressources.
</p>
<p>Dans cet article, nous &#233;valuons les performances d&#8217;un syst&#232;me de recherche pouvant combiner
un nombre quelconque de ressources externes. Cette &#233;valuation est men&#233;e sur une t&#226;che de
recherche de pages web et nous utilisons pour cela la collection ClueWeb09, qui est &#224; ce jour la
repr&#233;sentation statique la plus compl&#232;te du web. Les requ&#234;tes utilisateurs et les jugements de
pertinence proviennent de la piste Web de TREC (Clarke et al., 2009).
</p>
<p>Nous commen&#231;ons par d&#233;tailler le mod&#232;le de recherche d&#8217;information que nous utilisons dans la
section 2, puis nous pr&#233;sentons notre approche de combinaison de ressources dans la section 3.
La section 4 pr&#233;sente une &#233;valuation &#233;tendue ainsi qu&#8217;une discussion sur les r&#233;sultats obtenus et
des perspectives sur nos travaux futurs.
</p>
<p>480</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>2 Mod&#232;les de langue pour la recherche d&#8217;information
</p>
<p>Nous avons choisi de suivre une approche par mod&#232;le de langue pour la recherche d&#8217;information
et nous rappelons ici les principes du mod&#232;le &#233;tat-de-l&#8217;art que nous utilisons. Plusieurs travaux ont
en effet d&#233;montr&#233; l&#8217;efficacit&#233; de ce mod&#232;le &#224; int&#233;grer des informations provenant de diff&#233;rentes
sources, qu&#8217;elles soient intra-collection ou extra-collection (Diaz et Metzler, 2006).
</p>
<p>Le mod&#232;le de d&#233;pendance s&#233;quentielle (ou Sequential Dependence Model, SDM) est un cas
particulier du mod&#232;le MRF (Markov Random Field) pour la recherche d&#8217;information. Il a &#233;t&#233;
introduit par Metzler et Croft (Metzler et Croft, 2005) et a montr&#233; des performances &#233;tat-de-
l&#8217;art concernant plusieurs contextes de recherche dont celui sur le web (Allan et al., 2008;
Metzler et al., 2006). Ce mod&#232;le n&#8217;agit que sur les mots de la requ&#234;te et consiste &#224; mod&#233;liser les
d&#233;pendances entre les mots adjacents. Suivant le mod&#232;le SDM, la fonction calculant le poids d&#8217;un
mot de la requ&#234;te q dans un document D est donn&#233;e par l&#8217;&#233;quation :
</p>
<p>fT (q,D) = log
</p>
<p>&#63726;&#63727;&#63728; c(q,D) +&#181; &#183; c(q,C )|C ||D|+&#181;
&#63737;&#63738;&#63739;
</p>
<p>avec c(q,C ) the nombre d&#8217;occurrences du mot de la requ&#234;te q dans la collection cible C , |C | la
taille de la collection et |D| la taille du document D. &#181; est le param&#232;tre du lissage de Dirichlet,
nous fixons sa valeur &#224; 2500 comme le recommande (Zhai et Lafferty, 2004) pour les requ&#234;tes
constitu&#233;es de mots-cl&#233;s. C&#8217;est l&#8217;estimation par maximum de vraisemblance de l&#8217;unit&#233; lexicale q
dans le document D.
</p>
<p>Le mod&#232;le propose deux fonctions suppl&#233;mentaires pour deux autres types de d&#233;pendances qui
agissent sur les bigrammes de la requ&#234;te. La fonction fO(qi ,qi+1,D) consid&#232;re la correspondance
exacte de deux mots de la requ&#234;te adjacents. Elle est d&#233;not&#233;e par l&#8217;indice O. La seconde,
fU(qi ,qi+1,D), est d&#233;not&#233;e par l&#8217;indice U et consid&#232;re la correspondance non ordonn&#233;e de deux
mots au sein d&#8217;une fen&#234;tre de 8 unit&#233;s lexicales. Finalement, le score d&#8217;appariement requ&#234;te-
document qui utilise les fonctions ci-dessus d&#233;finies par le mod&#232;le de d&#233;pendance s&#233;quentielle
revient &#224; :
</p>
<p>scoreSDM (Q,D) = &#955;T
&#8721;
q&#8712;Q
</p>
<p>fT (q,D) +&#955;O
|Q|&#8722;1&#8721;
i=1
</p>
<p>fO(qi ,qi+1,D) +&#955;U
|Q|&#8722;1&#8721;
i=1
</p>
<p>fU(qi ,qi+1,D) (1)
</p>
<p>o&#249; &#955;T , &#955;O et &#955;U sont des param&#232;tres libres. Dans nos exp&#233;riences nous fixons ces param&#232;tres en
suivant les recommandations des auteurs (&#955;T = 0, 85, &#955;O = 0, 10 et &#955;U = 0, 05). Plus loin, nous
nous r&#233;f&#232;rerons &#224; la fonction de score d&#233;finie par l&#8217;&#233;quation (1) par l&#8217;acronyme SDM.
</p>
<p>3 Combinaison de ressources g&#233;n&#233;rales
</p>
<p>Certains besoins en information sont parfois trop complexes pour &#234;tre repr&#233;sent&#233;s par des
requ&#234;tes constitu&#233;es d&#8217;un petit nombre de mots. De plus, le processus de cr&#233;ation de la requ&#234;te
peut n&#233;cessiter un effort cognitif de la part de l&#8217;utilisateur, et mettre en jeu des connaissances qu&#8217;il
ne poss&#232;de pas ou qu&#8217;il souhaite acqu&#233;rir au terme de sa recherche. L&#8217;utilisation de ressources
externes permet de pallier ces manques, dans un contexte de recherche connu uniquement de
</p>
<p>481</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>l&#8217;utilisateur. Ce contexte peut &#234;tre interpr&#233;t&#233; en utilisant la masse de connaissances contenue
dans ces ressources, mais il faut pour cela se r&#233;duire &#224; des sous-ensembles contenant uniquement
des informations contextuelles par rapport &#224; la requ&#234;te.
</p>
<p>Consid&#233;rant une ressource R , nous formons un sous-ensemble contextuel RQ &#224; partir des N
premiers documents renvoy&#233;s par le mod&#232;le SDM pour une requ&#234;te Q. On peut alors calculer la
distance informative entre le mod&#232;le de langue &#952;RQ du sous-ensemble contextuel et le mod&#232;le
de langue &#952;D de chaque document D de la collection cible. Cette distance ag&#238;t naturellement
comme un processus de contextualisation : plus la distance entre les deux mod&#232;les de langue
est importante, moins le document D est li&#233; au contexte de recherche latent de la requ&#234;te Q.
Dans ce travail nous utilisons la divergence de Kullback-Leibler, ce qui nous permet de mesurer &#224;
quel point une ressource et un document donn&#233; sont proches. Formellement, la divergence de
KL entre le mod&#232;le de langue &#952;RQ d&#8217;un sous-ensemble contextuel RQ et le mod&#232;le de langue &#952;D
d&#8217;un document D s&#8217;exprime par :
</p>
<p>KL(&#952;RQ ||&#952;D) =
&#8721;
w&#8712;V
</p>
<p>p(w|&#952;RQ) log
p(w|&#952;RQ)
p(w|&#952;D)
</p>
<p>=
&#8721;
w&#8712;V
</p>
<p>p(w|&#952;RQ) log p(w|&#952;RQ)&#8722;
&#8721;
w&#8712;V
</p>
<p>p(w|&#952;RQ) log p(w|&#952;D)
&#8733; &#8722;&#8721;
</p>
<p>w&#8712;V
p(w|&#952;RQ) log p(w|&#952;D) (2)
</p>
<p>La derni&#232;re simplification de l&#8217;&#233;quation ci-dessus peut &#234;tre r&#233;alis&#233;e car son premier membre est
l&#8217;entropie de la ressource et n&#8217;affecte pas le classement des documents.
</p>
<p>Ici la contextualisation est effectu&#233;e &#224; partir des informations provenant d&#8217;une unique source
externe d&#8217;information, mais cette source peut-&#234;tre incompl&#232;te ou impr&#233;cise pour certains sujets.
Nous choisissons donc de combiner les connaissances de plusieurs ressources diff&#233;rentes en
calculant toutes les divergences possibles. Ainsi, le contexte de la requ&#234;te peut &#234;tre interpr&#233;t&#233;
d&#8217;autant de mani&#232;res qu&#8217;il y a de ressources et gagner en pr&#233;cision. Formellement, le score d&#8217;un
document D par rapport &#224; une requ&#234;te Q est donn&#233; par :
</p>
<p>score(Q,D) = SDM(Q,D)&#8722; 1|S |
&#8721;
RQ&#8712;S
</p>
<p>KL(&#952;RQ ||&#952;D) (3)
</p>
<p>o&#249; S est un ensemble de ressources. Nous utilisons ici le score de la divergence de KL pour
d&#233;grader un document ; en effet, plus la distance est importante, plus le score du document
va &#234;tre r&#233;duit. Ainsi, la combinaison de plusieurs ressource ag&#238;t intuitivement comme une
g&#233;n&#233;ralisation du contexte de recherche : plus le nombre de ressources utilis&#233;es augmente,
meilleure est la repr&#233;sentation contextuelle du besoin d&#8217;information. Il est &#224; noter que le mod&#232;le
de recherche d&#8217;information ainsi obtenu est tr&#232;s proche d&#8217;une pr&#233;c&#233;dente m&#233;thode qui avait
montr&#233; son efficacit&#233; dans le cadre d&#8217;une recherche de passages pr&#233;cis en utilisant Wikip&#233;dia
comme ressource externe (Deveaud et al., 2011).
</p>
<p>482</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4 Evaluation et r&#233;sultats
</p>
<p>Nous &#233;valuons notre approche en utilisant le corpus ClueWeb09 1, qui est &#224; ce jour la plus grande
collection de test mise &#224; disposition de la communaut&#233; de recherche d&#8217;information. Ce corpus
a servi de support &#224; de nombreuses t&#226;ches de TREC comme la Web Track, Blog Track, Million
Query Track... Nous ne consid&#233;rons ici que la cat&#233;gorie B du ClueWeb09, constitu&#233;e d&#8217;environ 50
millions de pages web. Nous utilisons pour notre &#233;valuation la cat&#233;gorie B ainsi que les topics et
les jugements de pertinence officiels mis &#224; disposition des participants de la Web Track.
</p>
<p>Concernant les ressources utilis&#233;es, nous avons souhait&#233; mod&#233;liser plusieurs contextes de re-
cherche fr&#233;quemment rencontr&#233;s sur le web, tels que la recherche de connaissances ou d&#8217;actualit&#233;s.
Nous avons donc choisi Wikip&#233;dia comme source encyclop&#233;dique, le New York Times ainsi que le
corpus GigaWord comme source journalistiques et un sous-ensemble du ClueWeb09 compos&#233;
uniquement de pages non spamm&#233;es comme source web. Le corpus GigaWord anglais de LDC 2
</p>
<p>est constitu&#233; de d&#233;p&#234;ches journalistiques provenant de quatre sources d&#8217;actualit&#233;s distinctes, dont
le New York Times. Le corpus New York Times de LDC 3 comprend quant &#224; lui des articles publi&#233;s
dans ce journal entre 1987 et 2007. La ressource Web est issue de la cat&#233;gorie B du ClueWeb09
&#224; laquelle nous avons soustrait toutes les pages web consid&#233;r&#233;es comme spam. Nous utilisons
pour cela l&#8217;ensemble &quot;Fusion&quot; de scores de spam pour le ClueWeb09 distribu&#233; par (Cormack
et al., 2010) 4. Cette liste attribue &#224; chaque document un score qui repr&#233;sente le pourcentage de
documents de la collection qui sont plus spamm&#233;s que lui. Ainsi, plus le score est grand, moins la
probabilit&#233; que le document soit un spam est importante. Pour la construction de notre ressource,
nous n&#8217;avons conserv&#233; que les documents dont le score est sup&#233;rieur &#224; 70, comme le pr&#233;conisent
les auteurs (Cormack et al., 2010). Pour finir, notre corpus Wikip&#233;dia contient tous les articles
anglais contenu dans l&#8217;encyclop&#233;die en ligne au mois de juillet 2011 5.
</p>
<p>Ressource Type Nb documents Nb mots uniques Nb mots total
</p>
<p>GigaWord (GW) Journalistique (d&#233;p&#234;ches) 4 111 240 1 288 389 1 397 727 483
New York Times (NYT) Journalistique (articles) 1 855 658 1 086 233 1 378 897 246
Wikip&#233;dia (Wiki) Encyclop&#233;dique 3 214 014 7 022 226 1 033 787 926
ClueWeb09 non spamm&#233; (Web) Web 29 038 220 33 314 740 22 814 465 842
</p>
<p>TABLE 1: R&#233;capitulatif des ressources utilis&#233;es.
</p>
<p>Les processus d&#8217;indexation et de recherche de documents sont r&#233;alis&#233;s en utilisant le moteur de
recherche Indri 6. La liste de mots-outils employ&#233;e est celle fournie par d&#233;faut avec Indri, elle com-
porte 417 mots communs en langue anglaise. Pour la racinisation nous utilisons l&#8217;impl&#233;mentation
d&#8217;Indri du raciniseur standard de Krovetz. Nous avons index&#233; le corpus ClueWeb09 ainsi que les
trois ressources externes en utilisant chaque fois ces m&#234;mes param&#232;tres. Lors de la recherche de
documents nous r&#233;solvons le probl&#232;me des probabilit&#233;s nulles avec un lissage de Dirichlet, pour
lequel nous fixons le param&#232;tre &#181; &#224; 2500. Cette m&#233;thode de lissage est en effet recommand&#233;e
lors des recherches par mots-cl&#233;s (Zhai et Lafferty, 2004), ce qui est notre cas avec les requ&#234;tes
de TREC. Les documents sont ordonn&#233;s en utilisant la formule donn&#233;e dans l&#8217;&#233;quation (3). Nous
</p>
<p>1. http://boston.lti.cs.cmu.edu/clueweb09/wiki/
2. http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC2003T05
3. http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC2008T19
4. http://plg.uwaterloo.ca/~gvcormac/clueweb09spam/
5. http://dumps.wikimedia.org/enwiki/20110722/
6. http://lemurproject.org/
</p>
<p>483</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>comparons les performances de l&#8217;approche d&#8217;enrichissement contextuel que nous proposons
avec celles de deux syst&#232;mes de base. Le premier est le mod&#232;le de d&#233;pendance s&#233;quentielle
(SDM) introduit dans la section 2, et le second est le traditionnel retour de pertinence simul&#233; (ou
Pseudo-Relevance Feedback, PRF) (Lavrenko et Croft, 2001) avec &#955; = 0, 5. Dans cette &#233;valuation,
nous utilisons les topics 1 &#224; 50 de la Web Track de TREC. Nous consid&#233;rons les 10 premiers
documents renvoy&#233;s par une requ&#234;te SDM pour chaque ressource externe R . Nous calculons
alors les probabilit&#233;s p(w|&#952;R) et nous reformulons la requ&#234;te originale en lui ajoutant les 20
mots poss&#233;dant les meilleurs probabilit&#233;s d&#8217;apparition dans la ressource. Ces mots ajout&#233;s sont
&#233;galement pond&#233;r&#233;s par la probabilit&#233; pr&#233;c&#233;demment calcul&#233;e afin de refl&#233;ter leur informativit&#233;
au sein de la ressource. Nous nous servons de la nouvelle requ&#234;te ainsi form&#233;e pour classer
les documents de la cat&#233;gorie B du ClueWeb09. Pour chaque requ&#234;te, nous renvoyons jusqu&#8217;&#224;
1000 documents. Nous reportons les r&#233;sultats de ces exp&#233;riences en terme de gain cumul&#233; &#224; 10
documents (nDCG@10), de pr&#233;cision moyenne (MAP) et de pr&#233;cision &#224; 10 documents dans le
tableau 2.
</p>
<p>Ressource nDCG@10 P@10 MAP
</p>
<p>Aucune 0,2746 0,3714 0,1837
PRF 0,2486 0,3667 0,2147&#8727;
</p>
<p>GW 0,2974 0,4014 0,1834
Wiki 0,2996 0,4255 0,2298&#8727;
Web 0,3014 0,4480&#8727; 0,2369&#8727;
NYT 0,3071 0,4395&#8727; 0,2118&#8727;
</p>
<p>Web + NYT 0,3004 0,4195 0,2257&#8727;
Wiki + GW 0,3034&#8727; 0,4253 0,2298&#8727;&#8727;
Web + Wiki 0,3088&#8727; 0,4521&#8727; 0,2374&#8727;&#8727;
NYT + GW 0,3114 0,4405&#8727; 0,2075&#8727;
Wiki + NYT 0,3119 0,4500&#8727; 0,2329&#8727;&#8727;
Web + GW 0,3120&#8727; 0,4318&#8727; 0,2241&#8727;
</p>
<p>Wiki + NYT + GW 0,3067&#8727; 0,4366&#8727; 0,2320&#8727;&#8727;
Web + NYT + GW 0,3100&#8727; 0,4359&#8727; 0,2205&#8727;&#8727;
Web + Wiki + GW 0,3202&#8727;&#8727; 0,4563&#8727; 0,2331&#8727;&#8727;
Web + Wiki + NYT 0,3246&#8727;&#8727;&#8727; 0,4563&#8727;&#8727; 0,2395&#8727;&#8727;&#8727;
</p>
<p>Web + Wiki + NYT + GW 0,3268&#8727;&#8727;&#8727; 0,4665&#8727;&#8727; 0,2353&#8727;&#8727;&#8727;
</p>
<p>TABLE 2: R&#233;sultats sur la cat&#233;gorie B du ClueWeb09 pour les topics 1 &#224; 50 de la Web Track de
TREC. Evaluation des combinaisons de Wikip&#233;dia (Wiki), le New York Times (NYT), le GigaWord
(GW) et le ClueWeb09 non spamm&#233; (Web) comme ressources externes. Nous utilisons le test
appari&#233; de Student (&#8727; : p &lt; 0,1; &#8727;&#8727; : p &lt; 0,05; &#8727;&#8727;&#8727; : p &lt; 0,01) pour d&#233;terminer les diff&#233;rences
statistiquement significatives avec le syst&#232;me de base.
</p>
<p>L&#8217;observation principale que l&#8217;on peut faire est que la combinaison des quatre ressources est
quasiment tout le temps plus performante que toutes les autres combinaisons, &#224; l&#8217;exception de la
mesure MAP. Contrairement aux autres, cette combinaison compl&#232;te tire parti de chaque ressource
individuellement, et les am&#233;liorations observ&#233;es sont toujours tr&#232;s statistiquement significatives
pour toutes les m&#233;triques. Il est d&#8217;ailleurs int&#233;ressant de voir que certaines combinaisons de
3 ressources (Wiki+NYT+GW par exemple) obtiennent des r&#233;sultats inf&#233;rieurs &#224; certaines
</p>
<p>484</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>combinaisons de 2 ressources (NYT+GW par exemple), mais o&#249; les performances sont plus
significatives. On observe le m&#234;me comportement entre les combinaisons de 2 ressources et les
ressources seules. La combinaison de plusieurs ressources apporte donc une certaine stabilit&#233; au
mod&#232;le de RI, tout en augmentant substantiellement les r&#233;sultats.
</p>
<p>Nous observons &#233;galement que les r&#233;sultats d&#233;croissent uniform&#233;ment lorsque l&#8217;on baisse le
nombre de ressources utilis&#233;es dans les combinaisons. Il est int&#233;ressant de voir que le corpus
NYT utilis&#233; seul am&#233;liore significativement les performances de recherche par rapport au corpus
GigaWord seul (t-test p-value : 0,081 pour la mesure MAP). En effet le GigaWord contient des
d&#233;p&#234;ches provenant du NYT, on pourrait donc instinctivement penser que leurs performances
pourraient &#234;tre comparables. La principale diff&#233;rence r&#233;side dans le fait que les articles du NYT
ont &#233;t&#233; &#233;crits par des journalistes utilisant un vocabulaire sp&#233;cialis&#233; et augment&#233;, contrairement
aux d&#233;p&#234;ches qui sont tr&#232;s courtes et factuelles. De plus, le corpus GigaWord est deux fois plus
gros en nombre de documents que le NYT, mais les d&#233;p&#234;ches sont tr&#232;s courtes (340 mots par
d&#233;p&#234;che en moyenne, contre 743 mots par article NYT en moyenne) et ont pour but d&#8217;&#234;tre
directes. De plus le vocabulaire employ&#233; est bien plus vari&#233; dans les articles du NYT. Ainsi, le
grand nombre de documents contenus par le corpus GigaWord n&#8217;arrive pas &#224; contrebalancer la
qualit&#233; d&#8217;&#233;criture et la compl&#233;tude du NYT.
</p>
<p>Nous avons &#233;galement exp&#233;riment&#233; diff&#233;rentes valeurs de lissage, diff&#233;rentes pond&#233;rations entre
les ressources et nous avons fait varier le nombre de pages s&#233;lectionn&#233;es pour chacune des
ressources. Les performances observ&#233;es &#233;taient comparables &#224; celles report&#233;es dans cette &#233;tude,
notre syst&#232;me peut se passer d&#8217;une &#233;tape de param&#233;trage ou d&#8217;apprentissage.
</p>
<p>5 Conclusions
</p>
<p>Nous avons pr&#233;sent&#233; dans cet article une approche permettant de contextualiser implicitement
une requ&#234;te utilisateur &#224; l&#8217;aide de plusieurs ressources externes. Cette approche permet de
p&#233;naliser les documents qui sont trop &#233;loign&#233;s d&#8217;un ensemble de ressources en calculant une
distance entre les distributions de mots dans le document et dans ces ressources. Les r&#233;sultats
de nos exp&#233;rimentations montrent qu&#8217;une combinaison de toutes les ressources &#233;tudi&#233;es per-
met d&#8217;am&#233;liorer substantiellement et tr&#232;s significativement les performances d&#8217;un syst&#232;me de
recherche d&#8217;information &#233;tat-de-l&#8217;art.
</p>
<p>Nous avons &#233;galement not&#233; que la qualit&#233; d&#8217;&#233;criture des ressources est essentielle. Ainsi, choisir
une ressource compl&#232;te et correctement &#233;crite semble plus important que choisir une ressource de
grande taille sans consid&#233;rer son contenu textuel. Nous pr&#233;voyons d&#8217;&#233;tendre cette &#233;tude avec un
plus grand nombre de ressources et d&#8217;autres m&#233;thodes de contextualisation, ainsi que plusieurs
mod&#232;les de recherche d&#8217;information. En effet nous pouvons imaginer employer n&#8217;importe quel
mod&#232;le probabiliste qui pourrait s&#8217;interpoler avec une combinaison de ressources. Nous planifions
&#233;galement de traduire les requ&#234;tes et d&#8217;adapter les jugements de pertinence afin de valider ces
exp&#233;riences sur d&#8217;autres langues que l&#8217;anglais.
</p>
<p>Remerciements Ces recherches ont b&#233;n&#233;fici&#233; du soutien financier de l&#8217;Agence Nationale de la
Recherche (ANR 2010 CORD 001 02) en faveur du projet CAAS.
</p>
<p>485</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;f&#233;rences
</p>
<p>ALLAN, J., CARTERETTE, B., ASLAM, J. A., PAVLU, V. et KANOULAS, E. (2008). Million Query Track
2008 Overview. In Proceedings of the Seventeenth Text REtrieval Conference (TREC).
</p>
<p>CLARKE, C. L. A., CRASWELL, N. et SOBOROFF, I. (2009). Overview of the TREC 2009 Web Track.
In Proceedings of the Eighteenth Text REtrieval Conference (TREC).
</p>
<p>CORMACK, G. V., SMUCKER, M. D. et CLARKE, C. L. A. (2010). Efficient and Effective Spam Filtering
and Re-ranking for Large Web Datasets. CoRR, abs/1004.5168.
</p>
<p>DEVEAUD, R., SANJUAN, E. et BELLOT, P. (2011). Ajout d&#8217;informations contextuelles issues
de Wikip&#233;dia pour la recherche de passages. In Actes de la 18e conf&#233;rence sur le Traitement
Automatique des Langues Naturelles, TALN 2011.
</p>
<p>DIAZ, F. et METZLER, D. (2006). Improving the estimation of relevance models using large
external corpora. In Proceedings of the 29th annual international ACM SIGIR conference on
Research and development in information retrieval, SIGIR &#8217;06, pages 154&#8211;161.
</p>
<p>FANG, H. (2008). A Re-examination of Query Expansion Using Lexical Resources. In Proceedings
of ACL-08 : HLT, pages 139&#8211;147, Columbus, Ohio. Association for Computational Linguistics.
</p>
<p>HARMAN, D. (1992). Relevance feedback revisited. In Proceedings of the 15th annual international
ACM SIGIR conference on Research and development in information retrieval, SIGIR &#8217;92, pages
1&#8211;10.
</p>
<p>LAVRENKO, V. et CROFT, W. B. (2001). Relevance based language models. In Proceedings of the
24th annual international ACM SIGIR conference on Research and development in information
retrieval, SIGIR &#8217;01, pages 120&#8211;127.
</p>
<p>LI, Y., LUK, W. P. R., HO, K. S. E. et CHUNG, F. L. K. (2007). Improving weak ad-hoc queries
using wikipedia as external corpus. In Proceedings of the 30th annual international ACM SIGIR
conference on Research and development in information retrieval, SIGIR &#8217;07, pages 797&#8211;798.
</p>
<p>LIU, S., LIU, F., YU, C. et MENG, W. (2004). An effective approach to document retrieval via
utilizing WordNet and recognizing phrases. In Proceedings of the 27th annual international ACM
SIGIR conference on Research and development in information retrieval, SIGIR &#8217;04, pages 266&#8211;272.
</p>
<p>MANDALA, R., TOKUNAGA, T. et TANAKA, H. (1999). Combining multiple evidence from different
types of thesaurus for query expansion. In Proceedings of the 22nd annual international ACM
SIGIR conference on Research and development in information retrieval, SIGIR &#8217;99, pages 191&#8211;197.
</p>
<p>METZLER, D. et CROFT, W. B. (2005). A markov random field model for term dependencies. In
Proceedings of the 28th annual international ACM SIGIR conference on Research and development
in information retrieval, SIGIR &#8217;05, pages 472&#8211;479.
</p>
<p>METZLER, D., STROHMAN, T. et CROFT, B. W. (2006). Indri at TREC 2006 : Lessons Learned From
Three Terabyte Tracks. In Proceedings of the Fifteenth Text REtrieval Conference (TREC).
</p>
<p>SUCHANEK, F. M., KASNECI, G. et WEIKUM, G. (2007). Yago : a core of semantic knowledge. In
Proceedings of the 16th international conference on World Wide Web, WWW &#8217;07, pages 697&#8211;706.
</p>
<p>ZHAI, C. et LAFFERTY, J. (2004). A study of smoothing methods for language models applied to
information retrieval. ACM Trans. Inf. Syst., 22:179&#8211;214.
</p>
<p>486</p>

</div></div>
</body></html>