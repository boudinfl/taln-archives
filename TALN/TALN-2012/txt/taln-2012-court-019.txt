Combinaison de ressources générales pour une
contextualisation implicite de requétes

Romain Deveaudl Patrice Bellotz
(1) LIA — Université d’Avig'non
romain . deveaud@u.niv— avignon . fr
(2) LSIS — Université Aix—Marsei11e
patrice . bellottﬁlsis . org

RESUME
L’utilisation de sources externes d’informations pour la recherche documentaire a été considéra-
blement étudiée dans le passé. Des améliorations de performances ont été mises en lumiére avec
des corpus larges ou structurés. Néanmoins, dans ces études les ressources sont souvent utilisées
séparément mais rarement combinées. Nous présentons une évaluation de la combinaison de
quatre différentes ressources générales, standards et accessibles. Nous utilisons une mesure de
distance informative pour extraire les caractéristiques contextuelles des différentes ressources et
améliorer la représentation de la requéte. Cette évaluation est menée sur une tache de recherche
d’information sur le Web en utilisant le corpus ClueWeb09 et les topics de la piste Web de TREC.
Les meilleurs résultats sont obtenus en combinant les quatre ressources, et sont statistiquement
signiﬁcativement supérieurs aux autres approches.

AB STRACT
Query Contextualization and Reformulation by Combining External Corpora

Improving document retrieval using external sources of information has been extensively studied
throughout the past. Improvements with either structured or large corpora have been reported.
However, in these studies resources are often used separately and rarely combined together. We
present an evaluation of the combination of four different scalable corpora over a web search
task. An informative divergence measure is used to extract contextual features from the corpora
and improve query representation. We use the ClueWeb09 collection along with TREC’s Web
Track topics for the purpose of our evaluation. Best results are achieved when combining all four
corpora, and are signiﬁcantly better than the results of other approaches.

MOTS-CLES : Combinaison de ressources, RI contextuelle, recherche web.

KEYWORDS: Resources combination, contextual IR, web search.

1 Introduction

La recherche d’information a pour but de satisfaire le besoin d’information d’un utilisateur.
En effet, lorsqu’un utilisateur effectue une recherche dans une base documentaire, il fournit
au systéme une représentation de son besoin d’information. Le réle du systéme est alors de
prendre en compte cette représentation et de présenter a l’utilisateur un ensemble de documents
pertinents par rapport au besoin d’information initial. Ces documents sont généralement présentés

Actes de la con_fe'rence onjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 479-486,
Grenoble, 4 au 8 juin 2012. ©2012 ATAI.A 8: AFCP

479

sous une forme de liste et ordonnés par ordre décroissant de pertinence. Il existe des modéles de
recherche d’information qui perrnettent de récupérer efficacement des documents par rapport
‘a une requéte, qui joue le réle de la représentation d’un besoin d’information. Ia difficulté
réside donc dans la capacité de l’utilisateur a représenter son besoin d’information d’une facon
adéquate pour le systéme. Seulement, les requétes formulées par ces utilisateurs ne décrivent
pas toujours parfaitement ce besoin, et des connaissances additionnelles sont parfois nécessaires
pour compléter cette description manquante. Une des maniéres de mieux déﬁnir le sujet d’une
recherche est d’enrichir la requéte originale avec des informations supplémentaires. Celles-ci
consistent traditionnellement en des mots que l’on va ajouter a la requéte formée par l’utilisateur.
Typiquement, ces mots sont extraits de documents récupérés en utilisant la requéte initiale. les
documents peuvent provenir de la collection cible (la base de documents au sein de laquelle le
systéme effectue la recherche) (Harman, 1992) ou de collections externes.

Les collections externes utilisées peuvent étre de types trés différents. Elles peuvent étre générales
ou spéciﬁques a un domaine précis, structurées ou non, ou encore construites automatiquement
ou manuellement. L’utilisation de ressources externes a été considérablement étudiée dans le
passé, et elle a prouvé son efficacité a améliorer les performances des systémes de recherche
d’information lorsqu’ils choisissent les données appropriées. Ces études se concentrent princi-
palement sur la maniére dont une ressource individuelle peut améliorer les performances d’un
systéme de recherche d’information, mais proposent rarement d’utiliser ces ressources conjoin-
tement. Des sources de données telles que Wikipédia (Li et al., 2007; Suchanek et al., 2007),
WordNet (Liu et aL, 2004; Suchanek et al., 2007; Fang, 2008), des articles journalistiques ou en-
core le web lui-méme (Diaz et Metzler, 2006) ont été utilisées. Dans leur étude, (Diaz et Metzler,
2006) expérimentent l’utilisation de ressources externes larges et générales. Ils présentent un
modéle qui permet d’incorporer des données additionnelles a la fagon d’un retour de pertinence
simulé (Lavrenko et Croft, 2001), et ils l’évaluent en considérant un corpus d’actualité et deux
corpus de pages web comme ressources externes. Ils démontrent que chaque ressource améliore
les performances du systéme de recherche d’information indépendamment, mais ils ne reportent
pas d’expériences sur une combinaison de ces ressources. D’un autre cété, (Mandala et al., 1999)
présentent dans leur travail une méthode d’enrichissement qui combine des caractéristiques
extraites de WordNet et de deux thesaurus spéciﬁques créés a partir de la collection de documents.
Le premier a pour but d’identiﬁer les relations sémantiques entre deux mots en calculant ses
co-occurrences. Le second se concentre sur la pondération de paires de mots liés par leur relation
syntaxique. Cette étude est une des seules qui rapporte des améliorations de performance en
combinant plusieurs ressources.

Dans cet article, nous évaluons les performances d’un systéme de recherche pouvant combiner
un nombre quelconque de ressources externes. Cette évaluation est menée sur une tache de
recherche de pages web et nous utilisons pour cela la collection ClueWeb09, qui est a ce jour la
représentation statique la plus complete du web. Les requétes utilisateurs et les jugements de
pertinence proviennent de la piste Web de TREC (Clarke et al., 2009).

Nous commencons par détailler le modele de recherche d’information que nous utilisons dans la
section 2, puis nous présentons notre approche de combinaison de ressources dans la section 3.
La section 4 présente une évaluation étendue ainsi qu’une discussion sur les résultats obtenus et
des perspectives sur nos travaux futurs.

480

2 Modeles de langue pour la recherche d’information

Nous avons choisi de suivre une approche par modéle de langue pour la recherche d’information
et nous rappelons ici les principes du modéle état-de-l’art que nous utilisons. Plusieurs travaux ont
en effet démontré l’efﬁcacité de ce modéle a intégrer des informations provenant de différentes
sources, qu’elles soient intra-collection ou extra-collection (Diaz et Metzler, 2006).

Le modéle de dépendance séquentielle (ou Sequential Dependence Model, SDM) est un cas
particulier du modéle MRF (Markov Random Field) pour la recherche d’information. Il a été
introduit par Metzler et Croft (Metzler et Croft, 2005) et a montré des performances état-de-
l’art concernant plusieurs contextes de recherche dont celui sur le web (Allan et al., 2008;
Metzler et aL, 2006). Ce modéle n’agit que sur les mots de la requéte et consiste a modéliser les
dépendances entre les mots adjacents. Suivant le modéle SDM, la fonction calculant le poids d’un
mot de la requéte q dans un document D est donnée par l’équation :

re:
|D|+u

c(q,D)+u- E
fT(q:D) =1og T

avec c(q, ‘6) the nombre d’occurrences du mot de la requéte q dans la collection cible ‘K, |‘6| la
taille de la collection et |D| la taille du document D. pa est le paramétre du lissage de Dirichlet,
nous ﬁxons sa valeur a 2500 comme le recommande (Zhai et Lafferty, 2004) pour les requétes
constituées de mots-clés. C’est l’estimation par maximum de vraisemblance de l’unité lexicale q
dans le document D.

Le modéle propose deux fonctions supplémentaires pour deux autres types de dépendances qui
agissent sur les bigrammes de la requéte. La fonction fO(q,-,q,-+1, D) considére la correspondance
exacte de deux mots de la requéte adjacents. Elle est dénotée par l’indice 0. La seconde,
fU(q,-,q,-+1, D), est dénotée par l’indice U et considére la correspondance non ordonnée de deux
mots au sein d’une fenétre de 8 unités lexicales. Finalement, le score d’appariement requéte-
document qui utilise les fonctions ci-dessus déﬁnies par le modéle de dépendance séquentielle
rev1ent ‘a :

|Q|—1 |Q|—1
sCOreSDM(Q:D) = )'TZfT(q:D) + A0 2 f0(qi:qi+1:D) + AU 2] fU(qi:qi+1:D) <1)

qEQ i=1 i=1

ou AT, 10 et AU sont des paramétres libres. Dans nos expériences nous ﬁxons ces paramétres en
suivant les recommandations des auteurs (AT = 0, 85, A0 = 0, 10 et AU = 0, 05). Plus loin, nous
nous référerons a la fonction de score déﬁnie par l’équation (1) par l’acronyme SDM.

3 Combinaison de ressources générales

Certains besoins en information sont parfois trop complexes pour étre représentés par des
requétes constituées d’un petit nombre de mots. De plus, le processus de création de la requéte
peut nécessiter un effort cognitif de la part de l’utilisateur, et mettre en jeu des connaissances qu’il
ne posséde pas ou qu’il souhaite acquérir au terme de sa recherche. L’utilisation de ressources
extemes permet de pallier ces manques, dans un contexte de recherche connu uniquement de

481

l’utilisateur. Ce contexte peut étre interprété en utilisant la masse de connaissances contenue
dans ces ressources, mais il faut pour cela se réduire a des sous-ensembles contenant uniquement
des informations contextuelles par rapport a la requéte.

Considérant une ressource 92, nous formons un sous-ensemble contextuel SEQ ‘a partir des N
premiers documents renvoyés par le modele SDM pour une requéte Q. On peut alors calculer la
distance informative entre le modele de langue 9% du sous-ensemble contextuel et le modele
de langue 9,, de chaque document D de la collection cible. Cette distance agit naturellement
comme un processus de contextualisation : plus la distance entre les deux modeles de langue

est importante, moins le document D est lié au contexte de recherche latent de la requéte Q.

Dans ce travail nous utilisons la divergence de Kullback-Leibler, ce qui nous permet de mesurer a
quel point une ressource et un document donné sont proches. Formellement, la divergence de
KL entre le modéle de langue 9% d’un sous-ensemble contextuel SEQ et le modéle de langue 9,,
d’un document D s’exprime par :

P(W|99zQ)
Mg:/P(W|9szQ)108m

= Zp(w|9gQ)1ogp(w|9aQ) — Zp(w|99zQ)1ogp(w|9D)

WEV WEV

cc _ZP(W|99!Q)10gP(w|9D) <2)

WEV

KL(99!Q“9D)

La derniére simpliﬁcation de l’équau'on ci-dessus peut étre réalisée car son premier membre est
l’entropie de la ressource et n’affecte pas le classement des documents.

Ici la contextualisation est effectuée ‘a partir des informations provenant d’une unique source
externe d’information, mais cette source peut-étre incomplete ou imprécise pour certains sujets.
Nous choisissons donc de combiner les connaissances de plusieurs ressources différentes en
calculant toutes les divergences possibles. Ainsi, le contexte de la requéte peut étre interprété
d’autant de maniéres qu’il y a de ressources et gagner en précision. Formellement, le score d’un
document D par rapport a une requéte Q est donné par :

1

score(Q, D) = SDM(Q, D) — H

2 KL(992Q||9D) (3)

.92Qe.7

oil 5/’ est un ensemble de ressources. Nous utilisons ici le score de la divergence de K1. pour
dégrader un document; en effet, plus la distance est importante, plus le score du document
va étre réduit. Ainsi, la combinaison de plusieurs ressource agit intuitivement comme une
généralisation du contexte de recherche : plus le nombre de ressources utilisées augmente,
meilleure est la représentation contextuelle du besoin d’information. Il est a noter que le modéle
de recherche d’information ainsi obtenu est tres proche d’une précédente méthode qui avait
montré son efficacité dans le cadre d’une recherche de passages précis en utilisant Wi.kipédia
comme ressource externe (Deveaud et aL, 2011).

482

4 Evaluation et résultats

Nous évaluons notre approche en utilisant le corpus ClueWeb09 1, qui est a ce jour la plus grande
collection de test mise a disposition de la communauté de recherche d’information. Ce corpus
a servi de support ‘a de nombreuses taches de TREC comme la Web Track, Blog Track, Million
Query Track... Nous ne considérons ici que la catégorie B du ClueWeb09, constituée d’environ 50
millions de pages web. Nous utilisons pour notre évaluation la catégorie B ainsi que les topics et
les jugements de pertinence ofﬁciels rnis a disposition des participants de la Web Track.

Concernant les ressources utilisées, nous avons souhaité modéliser plusieurs contextes de re-
cherche fréquemment rencontrés sur le web, tels que la recherche de connaissances ou d’actuaJ1'tés.
Nous avons donc choisi Wikipédia comme source encyclopédique, le New York Times ainsi que le
corpus GigaWord comme source journalistiques et un sous-ensemble du ClueWeb09 composé
uniquement de pages non spammées comme source web. Le corpus GigaWord anglais de LDC 2
est constitué de dépéches journalistiques provenant de quatre sources d’actualités distinctes, dont
le New York Times. Le corpus New York Times de LDC 3 comprend quant a lui des articles publiés
dans ce journal entre 1987 et 2007. La ressource Web est issue de la catégorie B du ClueWeb09
‘a laquelle nous avons soustrait toutes les pages web considérées comme spam. Nous utilisons
pour cela l’ensemble "Fusion" de scores de spam pour le ClueWeb09 distribué par (Cormack
et al., 2010) 4. Cette liste attribue a chaque document un score qui représente le pourcentage de
documents de la collection qui sont plus spammés que lui. Ainsi, plus le score est grand, moins la
probabilité que le document soit un spam est importante. Pour la construction de notre ressource,
nous n’avons conservé que les documents dont le score est supérieur a 70, comme le préconisent
les auteurs (Cormack et al., 2010). Pour ﬁnir, notre corpus Wi.kipédia contient tous les ar11'cles
anglais contenu dans l’encyclopédie en ligne au mois de juillet 2011 5.

Ressource Type Nb documents Nb mots uniques Nb mots total
Gigaword (GW) Journalistique (dépéches) 4 111 240 1 288 389 1 397 727 483
New York Times (NYF) Journalistique (anicles) 1 855 658 1 086 233 1 378 897 246
Wikipédia (Wiki) Encyclopédique 3 214 014 7 022 226 1 033 787 926
ClueWeb09 non spamrné (Web) Web 29 038 220 33 314 740 22 814 465 842

TABLE 1: Récapitulatif des ressources utilisées.

Les processus d’indexation et de recherche de documents sont réalisés en utilisant le moteur de
recherche Indri 5. La liste de mots-outils employée est celle fournie par défaut avec Indri, elle com-
porte 417 mots communs en langue anglaise. Pour la racinisation nous utilisons l’implémentation
d’Indri du raciniseur standard de Krovetz. Nous avons indexé le corpus ClueWeb09 ainsi que les
trois ressources externes en utilisant chaque fois ces mémes paramétres. Lors de la recherche de
documents nous résolvons le probléme des probabilités nulles avec un lissage de Dirichlet, pour
lequel nous fixons le parametre pl. ‘a 2500. Cette méthode de lissage est en effet recommandée
lors des recherches par mots-clés (Zhai et Iafferty, 2004), ce qui est notre cas avec les requétes
de TREC. Les documents sont ordonnés en utilisant la formule donnée dans l’équation (3). Nous

. http: //bost on . lti . cs . cmu . edu/ clueweb09/wiki/

. http: //www . ldc . upenn . edu/Catalog/ca1:alogEn1:ry . j sp?ca1: alogId=LDC2003T05
. http: //www . ldc . upenn . edu/Catalog/ca1:alogEn1:ry . j sp?ca1: alogId=LDC2008T19
. http: //plg . uwaterloo . ca/"gVcormac/clueweb09spam/

. http: //dumps . wikimedia. org/enwiki/201 10722/

. http: //lemurproj ect . org/

O\U'|-b<a3[0>—I

483

comparons les performances de l’approche d’enrichissement contextuel que nous proposons
avec celles de deux systemes de base. Le premier est le modele de dépendance séquentielle
(SDM) introduit dans la section 2, et le second est le traditionnel retour de pertinence simulé (ou
Pseudo-Relevance Feedback, PRF) (Lavrenko et Croft, 2001) avec A = 0, 5. Dans cette évaluation,
nous utilisons les topics 1 a 50 de la Web Track de TREC. Nous considérons les 10 premiers
documents renvoyés par une requéte SDM pour chaque ressource externe 92. Nous calculons
alors les probabilités p(w|99,) et nous reformulons la requéte originale en lui ajoutant les 20
mots possédant les meilleurs probabilités d’apparition dans la ressource. Ces mots ajoutés sont
également pondérés par la probabilité précédemment calculée aﬁn de reﬂéter leur informativité
au sein de la ressource. Nous nous servons de la nouvelle requéte ainsi formée pour classer
les documents de la catégorie B du C1ueWeb09. Pour chaque requéte, nous renvoyons jusqu"a
1000 documents. Nous reportons les résultats de ces expériences en terme de gain cumulé a 10
documents (nDCG@10), de précision moyenne (MAP) et de précision ‘a 10 documents dans le
tableau 2.

Ressource nDCG@10 P@10 MAP
Aucune 0,2746 0,3714 0,1837
PRF 0,2486 0,3667 0,2147*
GW 0,2974 0,4014 0,1834
Wild 0,2996 0,4255 0,2298*
Web 0,3014 0,4480* 0,2369*
NYT 0,3071 0,4395* 0,2 1 18*
Web + NYT 0,3004 0,4195 0,2257*
Wild + GW 0,3034* 0,4253 0,2298**
Web + Wild 0,3088* 0,4521* 0,237 **
NYT + GW 0,3114 0,4405* 0,2075*
Wild + NYT 0,3119 0,4500* 0,2329**
Web + GW 0,3120* 0,4318* 0,2241*
Wild + NYT + GW 0,3067* 0,4366* 0,2320**
Web + NYT + GW 0,3100* 0,4359* 0,2205**
Web + Wild + GW 0,3202** 0,4563* 0,2331**
Web + Wild + NYT 0,3246*** 0,4563** 0,2395***
Web + Wild + NYT + GW 0,3268*** 0,4665** 0,2353***

TABLE 2: Résultats sur la catégorie B du C1ueWeb09 pour les topics 1 ‘a 50 de la Web Track de
TREC. Evaluation des combinaisons de Wikipédia (Wild), le New York Times (NYT), le GigaWord
(GW) et le C1ueWeb09 non spammé (Web) comme ressources extemes. Nous utilisons le test
apparié de Student (* : p < 0, 1; ** : p < 0,05; *** : p < 0, 01) pour déterminer les différences
statistiquement signiﬁcatives avec le systéme de base.

L’observation principale que l’on peut faire est que la combinaison des quatre ressources est
quasiment tout le temps plus performante que toutes les autres combinaisons, a l’exception de la
mesure MAP. Contrairement aux autres, cette combinaison compléte tire parti de chaque ressource
individuellement, et les amélioraﬁons observées sont touj ours trés statistiquement signiﬁcatives
pour toutes les métriques. Il est d’ailleurs intéressant de voir que certaines combinaisons de
3 ressources (Wild+NYT+GW par exemple) obtiennent des résultats inférieurs ‘a certaines

484

combinaisons de 2 ressources (NYT+GW par exemple), mais o1‘1 les performances sont plus
signiﬁcatives. On observe le méme comportement entre les combinaisons de 2 ressources et les
ressources seules. La combinaison de plusieurs ressources apporte donc une certaine stabilité au
modéle de RI, tout en augmentant substantiellement les résultats.

Nous observons également que les résultats décroissent uniformément lorsque l’on baisse le
nombre de ressources utilisées dans les combinaisons. Il est intéressant de voir que le corpus
NYT utilisé seul améliore signiﬁcativement les performances de recherche par rapport au corpus
GigaWord seul (t-test p-value : 0,081 pour la mesure MAP). En effet le GigaWord contient des
dépéches provenant du NYT, on pourrait donc instinctivement penser que leurs performances
pourraient étre comparables. Ia principale différence réside dans le fait que les articles du NYT
ont été écrits par des journalistes utilisant un vocabulaire spécialisé et augmenté, contrairement
aux dépéches qui sont tres courtes et factuelles. De plus, le corpus GigaWord est deux fois plus
gros en nombre de documents que le NYT, mais les dépéches sont tres courtes (340 mots par
dépéche en moyenne, contre 743 mots par article NYT en moyenne) et ont pour but d’étre
directes. De plus le vocabulaire employé est bien plus varié dans les articles du NYT. Ainsi, le
grand nombre de documents contenus par le corpus GigaWord n’arrive pas a contrebalancer la
qualité d’écriture et la complétude du NY'I'.

Nous avons également expérimenté différentes valeurs de lissage, différentes pondérations entre
les ressources et nous avons fait varier le nombre de pages sélectionnées pour chacune des
ressources. Les performances observées étaient comparables a celles reportées dans cette étude,
notre systéme peut se passer d’une étape de paramétrage ou d’apprentissage.

5 Conclusions

Nous avons présenté dans cet article une approche permettant de contextualiser implicitement
une requéte utilisateur ‘a l’aide de plusieurs ressources extemes. Cette approche permet de
pénaliser les documents qui sont trop éloignés d’un ensemble de ressources en calculant une
distance entre les distributions de mots dans le document et dans ces ressources. Les résultats
de nos expérimentations montrent qu’une combinaison de toutes les ressources étudiées per-
met d’améliorer substantiellement et tres signiﬁcativement les performances d’un systeme de
recherche d’informau'on état-de-l’art.

Nous avons également noté que la qualité d’écriture des ressources est essenﬁelle. Ainsi, choisir
une ressource compléte et correctement écrite semble plus important que choisir une ressource de
grande taille sans considérer son contenu textuel. Nous prévoyons d’étendre cette étude avec un
plus grand nombre de ressources et d’autres méthodes de contextualisation, ainsi que plusieurs
modeles de recherche d’information. En effet nous pouvons imaginer employer n’importe quel
modéle probabiljste qui pourrait s’interpoler avec une combinaison de ressources. Nous planiﬁons
également de traduire les requétes et d’adapter les jugements de pertinence aﬁn de valider ces
expériences sur d’autres langues que l’anglais.

Remerciements Ces recherches ont bénéﬁcié du soutien ﬁnancier de l’Agence Nationale de la
Recherche (ANR 2010 CORD 001 02) en faveur du projet CAAS.

485

Références

ALLAN, J., CARTERETTE, B., ASLAM, J. A., PAVLU, V et KANOULAS, E. (2008). Million Query Track
2008 Overview. In Proceedings of the Seventeenth Text REtrieval Conference ('I'REC).

CLARKE, C. L. A., CRASWELL, N. et SOBOROFF, I. (2009). Overview of the TREC 2009 Web 'I'rack.

In Proceedings of the Eighteenth Text REtrieval Conference (TREC).

CORMACK, G. V, SMUCKER, M. D. et CLARKE, C. L. A. (2010). Efﬁcient and Effective Spam Filtering
and Re-ranking for Large Web Datasets. CoRR, abs/1004.5168.

DEVEAUD, R., SANJUAN, E. et BELLOT, P. (2011). Ajout d’informat1'ons contextuelles issues
de Wi.kipédia pour la recherche de passages. In Actes de la 18e conférence sur le Traitement
Automatique des Langues Naturelles, TAIN 2011.

DIAZ, F. et METZLER, D. (2006). Improving the estimation of relevance models using large
external corpora. In Proceedings of the 29th annual international ACM SIGIR conference on
Research and development in information retrieval, SIGIR ’06, pages 154-161.

FANG, H. (2008). A Re-examination of Query Expansion Using Lexical Resources. In Proceedings
ofACL-08 : HLT, pages 139-147, Columbus, Ohio. Association for Computational Linguistics.

HARMAN, D. (1992). Relevance feedback revisited. In Proceedings of the 15th annual international
ACM SIGIR conference on Research and development in information retrieval, SIGIR ’92, pages
1-10.

LAVRENKO, V et CROFT, W. B. (2001). Relevance based language models. In Proceedings of the
24th annual international ACM SIGIR conference on Research and development in information
retrieval, SIGIR ’01, pages 120-127.

1.1, Y., LUK, W. P. R., Ho, K. S. E. et CHUNG, E L. K. (2007). Improving weak ad-hoc queries
using wi.kipedia as external corpus. In Proceedings of the 30th annual international ACM SIGIR
conference on Research and development in information retrieval, SIGIR ’07, pages 797-798.

LIU, S., LIU, F., YU, C. et MENG, W. (2004). An effective approach to document retrieval via
utilizing WordNet and recognizing phrases. In Proceedings of the 27th annual international ACM

SIGIR conference on Research and development in information retrieval, SIGIR ’04, pages 266-272.

MANDALA, R., TOKUNAGA, 'I‘. et TANAKA, H. (1999). Combining multiple evidence from different
types of thesaurus for query expansion. In Proceedings of the 22nd annual international ACM

SIGIR conference on Research and development in information retrieval, SIGIR ’99, pages 191-197.

METZLER, D. et CROFT, W. B. (2005). A markov random ﬁeld model for term dependencies. In
Proceedings of the 28th annual international ACM SIGIR conference on Research and development
in information retrieval, SIGIR ’05, pages 4724179.

METZLER, D., STROHMAN, T. et CROFT, B. W. (2006). Indri at TREC 2006 : Lessons Learned From
Three Terabyte Tracks. In Proceedings of the Fifteenth Text REtrieval Conference (TREC).
SUCHANEK, E M., KASNECI, G. et WEIKUM, G. (2007). Yago : a core of semantic knowledge. In
Proceedings of the 16th international conference on World Wide Web, W ’07, pages 697-706.

ZHAI, C. et LAFFERTY, J. (2004). A study of smoothing methods for language models applied to
information retrieval. ACM Trans. Inf Syst., 22:179-214.

486

