<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Rep&#233;rage des entit&#233;s nomm&#233;es pour l'arabe : adaptation non-supervis&#233;e et combinaison de syst&#232;mes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 487&#8211;494,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Rep&#233;rage des entit&#233;s nomm&#233;es pour l&#8217;arabe : adaptation
non-supervis&#233;e et combinaison de syst&#232;mes
</p>
<p>Souhir Gahbiche-Braham1,2 H&#233;l&#232;ne Bonneau-Maynard1,2 Thomas Lavergne1
</p>
<p>Fran&#231;ois Yvon1,2
(1) LIMSI-CNRS, (2) Universit&#233; Paris-Sud
</p>
<p>{souhir.gahbiche,helene.maynard,thomas.lavergne,francois.yvon}@limsi.fr
</p>
<p>R&#201;SUM&#201;
La d&#233;tection des Entit&#233;s Nomm&#233;es (EN) en langue arabe est un pr&#233;traitement potentiellement
utile pour de nombreuses applications du traitement des langues, en particulier pour la traduction
automatique. Cette t&#226;che repr&#233;sente toutefois un s&#233;rieux d&#233;fi, compte tenu des sp&#233;cificit&#233;s de
l&#8217;arabe. Dans cet article, nous pr&#233;sentons un compte-rendu de nos efforts pour d&#233;velopper un
syst&#232;me de rep&#233;rage des EN s&#8217;appuyant sur des m&#233;thodes statistiques, en d&#233;taillant les aspects
li&#233;s &#224; la s&#233;lection des caract&#233;ristiques les plus utiles pour la t&#226;che ; puis diverses tentatives pour
adapter ce syst&#232;me d&#8217;une mani&#232;re enti&#232;rement non supervis&#233;e.
</p>
<p>ABSTRACT
Named Entity Recognition for Arabic : Unsupervised adaptation and Systems combination
</p>
<p>The recognition of Arabic Named Entities (NE) is a potentially useful preprocessing step for many
Natural Language Processing Applications, such as Machine Translation. This task is however
made very complex by some peculiarities of the Arabic language. In this paper, we present a
summary of our recent efforts aimed at developing a statistical NE recognition system, with a
specific focus on feature engineering aspects. We also report several approaches for adapting this
system in an entirely unsupervised manner to a new domain.
</p>
<p>MOTS-CL&#201;S : Adaptation non supervis&#233;e, Rep&#233;rage des entit&#233;s nomm&#233;es.
</p>
<p>KEYWORDS: Unsupervised domain adaptation, named entity recognition.
</p>
<p>1 Introduction
</p>
<p>La d&#233;tection des Entit&#233;s Nomm&#233;es (EN) est un &#233;l&#233;ment essentiel &#224; de nombreuses t&#226;ches de
TAL, qu&#8217;elles soient mono ou multilingues, comme la recherche d&#8217;information ou la traduction
automatique. En t&#233;moignent les nombreuses campagnes d&#8217;&#233;valuation internationales (MUC,
CoNLL, ACE) ou nationales (ESTER) organis&#233;es au cours des 15 derni&#232;res ann&#233;es.
</p>
<p>Nous nous int&#233;ressons &#224; cette question dans un contexte de traduction automatique statistique
depuis l&#8217;arabe vers le fran&#231;ais (ou l&#8217;anglais). Il est fr&#233;quent, en effet, qu&#8217;une EN &#224; traduire ne soit
pas pr&#233;sente dans les corpus parall&#232;les qui servent &#224; entra&#238;ner les syst&#232;mes de traduction. Dans
(Gahbiche-Braham et al., 2011), nous avons observ&#233; que parmi les 1% des formes inconnues,
environ un quart correspondent &#224; des EN. Dans ce cas, le syst&#232;me recopie, par d&#233;faut, le mot
inconnu verbatim dans la sortie, alors qu&#8217;il serait pr&#233;f&#233;rable, pour une EN, de produire une forme
</p>
<p>487</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>translitt&#233;r&#233;e en alphabet latin (Hermjakob et al., 2008; Zhang et al., 2011), ou encore de consulter
des dictionnaires. (Daum&#233; III et Jagarlamudi, 2011) adaptent leur syst&#232;me de traduction en
cr&#233;ant des dictionnaires &#224; partir de mots fr&#233;quents dans le domaine cible. L&#8217;&#233;tiquetage en EN
apparait donc comme un pr&#233;traitement potentiellement utile &#224; la traduction.
</p>
<p>L&#8217;arabe est une langue morphologiquement riche et complexe. L&#8217;analyse automatique des mots
arabes est compliqu&#233;e par l&#8217;absence de voyellation dans les textes &#233;crits d&#8217;une part (Habash,
2010), et d&#8217;autre part par l&#8217;existence de nombreuses variantes orthographiques, notamment sur
les noms propres, ce qui multiplie les formes inconnues dans les textes. L&#8217;&#233;tiquetage en EN en
langue arabe repr&#233;sente de nombreux d&#233;fis int&#233;ressants : l&#8217;arabe se caract&#233;rise par le manque de
ressources dictionnairiques et surtout par l&#8217;absence de distinction majuscule/minuscule qui est
un indicateur tr&#232;s utile pour identifier les noms propres dans les langues utilisant l&#8217;alphabet latin.
</p>
<p>&#192; la suite de nombreux travaux, nous abordons cette t&#226;che avec des outils d&#8217;apprentissage
automatique et utilisons le mod&#232;le des champs markoviens conditionnels (ou CRF (Lafferty et al.,
2001)), avec l&#8217;impl&#233;mentation pr&#233;sent&#233;e dans (Lavergne et al., 2010), qui permet de construire
des mod&#232;les int&#233;grant un tr&#232;s grand nombre de descripteurs. Cette d&#233;marche pose la question
de la pertinence des corpus d&#8217;apprentissage au regard des donn&#233;es de test. Nous traitons cette
question en explorant les possibilit&#233;s d&#8217;une adaptation non-supervis&#233;e. Nous proposons enfin
une hybridation entre un syst&#232;me statistique et un syst&#232;me symbolique. Le reste de l&#8217;article
est organis&#233; comme suit. Dans la section 2, nous passons en revue des travaux sur le rep&#233;rage
des EN dans les textes arabes, et sur l&#8217;adaptation de mod&#232;les statistiques. Nous pr&#233;sentons
dans la section 3 les exp&#233;riences qui ont conduit au d&#233;veloppement de notre syst&#232;me de base.
L&#8217;adaptation de notre syst&#232;me est d&#233;crite &#224; la section 4. La section 5 conclut ces travaux.
</p>
<p>2 &#201;tat de l&#8217;art
</p>
<p>2.1 &#201;tiquetage en EN pour l&#8217;arabe
</p>
<p>Les premiers travaux sur la reconnaissance des EN pour l&#8217;arabe datent de 1998 et reposent sur
des m&#233;thodes &#224; base de r&#232;gles (Maloney et Niv, 1998), voir &#233;galement le travail plus r&#233;cent
de (Shaalan et Raza, 2009) ou de (Zaghouani et al., 2010). (Samy et al., 2005) utilisent un
corpus parall&#232;le pour extraire des EN en arabe. Ils utilisent un &#233;tiqueteur &#224; base de r&#232;gles
enrichies avec un lexique monolingue espagnol pour extraire les EN en espagnol qui sont, par la
suite, translitt&#233;r&#233;es vers l&#8217;arabe. (Zitouni et al., 2005) utilisent des techniques d&#8217;apprentissage
automatique (des Maximum Entropy Markov Models) en consid&#233;rant des jeux de descripteurs
idoines, et parviennent &#224; de tr&#232;s bons r&#233;sultats.
</p>
<p>Ces travaux ont &#233;t&#233; prolong&#233;s en particulier par Benajiba et ses co-auteurs, et ont donn&#233; lieu
notamment &#224; la construction du corpus ANER (voir section 3). Dans une premi&#232;re approche
(Benajiba et Rosso, 2007), un &#233;tiquetage fond&#233; sur le maximum d&#8217;entropie est explor&#233;. Cette
approche est &#233;tendue ensuite en d&#233;composant la pr&#233;diction en deux temps : d&#8217;abord les fronti&#232;res
de l&#8217;EN en introduisant des cat&#233;gories morpho-syntaxiques (POS), puis &#224; la d&#233;termination de
son type. Une seconde approche, fond&#233;e sur l&#8217;utilisation des CRF (Benajiba et Rosso, 2008)
a permis d&#8217;explorer l&#8217;int&#233;gration de l&#8217;ensemble des traits dans un mod&#232;le unique, amenant &#224;
de meilleures performances. (Benajiba et al., 2008) montrent &#233;galement l&#8217;efficacit&#233; d&#8217;un pr&#233;-
traitement des textes pour s&#233;parer les diff&#233;rents constituants du mot (pr&#233;fixes, lemme, et suffixes).
(Abdul Hamid et Darwish, 2010) int&#232;grent des traits intra-mot (n-grammes de caract&#232;res) dans
</p>
<p>488</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>une mod&#233;lisation CRF. Cette approche permet de capturer implicitement les caract&#233;ristiques
morphosyntaxiques, introduites explicitement dans les exp&#233;riences de (Benajiba et Rosso, 2008).
</p>
<p>2.2 Adaptation et combinaison de syst&#232;mes
</p>
<p>En apprentissage automatique, l&#8217;adaptation consiste &#224; d&#233;velopper un syst&#232;me de traitement
pour un domaine cible &#224; partir de donn&#233;es et/ou d&#8217;un syst&#232;me de traitement d&#233;velopp&#233; pour un
domaine source. D&#8217;un point de vue statistique, cela implique que les distributions des exemples
observ&#233;s sont diff&#233;rentes au moment de l&#8217;apprentissage et au moment du test.
</p>
<p>Cette probl&#233;matique a fait l&#8217;objet de multiples propositions en mod&#233;lisation statistique des langues
(par exemple l&#8217;&#233;tude de (Bellagarda, 2001) pour les mod&#232;les statistiques de langue), utilisation
de pond&#233;rations diff&#233;rentielles pour les exemples de la source et de la cible (Jiang et Zhai, 2007),
utilisation de descripteurs sp&#233;cifiques pour les exemples source et cible (Daume III, 2007), etc.
(Daume III et al., 2010) pr&#233;sentent des travaux plus r&#233;cents. Dans un cadre non supervis&#233;, la
strat&#233;gie la plus commune est l&#8217;auto-apprentissage (self-training) g&#233;n&#233;rant automatiquement des
donn&#233;es d&#8217;apprentissage pour le domaine cible &#224; partir du syst&#232;me source (Mihalcea, 2004).
</p>
<p>Concernant le rep&#233;rage des EN, le probl&#232;me de l&#8217;adaptation se pose avec une acuit&#233; particuli&#232;re,
d&#251;e au fait que les EN (i) sont souvent associ&#233;es avec un th&#232;me particulier et (ii) ont &#233;galement
des distributions d&#8217;occurences tr&#232;s variables dans le temps. Cette probl&#233;matique est &#233;tudi&#233;e en
particulier par (B&#233;chet et al., 2011) qui (i) combinent deux approches d&#8217;&#233;tiquetage en EN pour le
fran&#231;ais : une approche symbolique avec une approche probabiliste et (ii) adaptent le syst&#232;me
probabiliste fond&#233; sur un processus discriminant &#224; base de CRF, au domaine des donn&#233;es de test.
</p>
<p>3 &#201;tiquetage en entit&#233;s nomm&#233;es : syst&#232;mes de base
</p>
<p>Dans cette section, nous d&#233;crivons les exp&#233;riences r&#233;alis&#233;es pour d&#233;velopper des syst&#232;mes de
base et en particulier pour identifier les descripteurs linguistiques utilis&#233;s. Tous ces mod&#232;les sont
entra&#238;n&#233;s avec l&#8217;impl&#233;mentation des CRF r&#233;alis&#233;e dans l&#8217;outil Wapiti1 (Lavergne et al., 2010).
Cette impl&#233;mentation permet (i) d&#8217;utiliser de tr&#232;s gros mod&#232;les incluant nominalement des
centaines de millions de descripteurs, et (ii) de s&#233;lectionner les descripteurs les plus utiles par le
biais d&#8217;une p&#233;nalit&#233; L1 (Sokolovska et al., 2009).
</p>
<p>3.1 Protocole exp&#233;rimental
</p>
<p>Les exp&#233;riences ont &#233;t&#233; r&#233;alis&#233;es sur le corpus ANER2 (Benajiba et al., 2007) constitu&#233; &#224; partir
d&#8217;articles de presse, et compos&#233; de plus de 150 000 occurrences de mots (4 871 phrases). Le
corpus distingue 4 types d&#8217;EN : localisation (LOC : 40% des EN observ&#233;es), personne (PERS :
32%), organisation (ORG : 18%) et une classe &#171; divers &#187; regroupant tous les autres types (MISC :
10%)3, et peut &#234;tre consid&#233;r&#233; comme le corpus de r&#233;f&#233;rence pour la t&#226;che. Il utilise le sch&#233;ma
d&#8217;annotation IOB-2 et distingue 9 &#233;tiquettes. Les exp&#233;riences sont produites &#224; partir de donn&#233;es
translitt&#233;r&#233;es4, sans faire d&#8217;analyse morphologique. Les scores sont calcul&#233;s en utilisant l&#8217;outil
</p>
<p>1Wapiti est librement disponible &#224; l&#8217;adresse http://wapiti.limsi.fr.
2http://users.dsic.upv.es/~ybenajiba/downloads.html
3Seuls les trois premiers types sont utilis&#233;s dans nos &#233;valuations.
4http://www.qamus.org/transliteration.htm
</p>
<p>489</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p> 40
</p>
<p> 50
</p>
<p> 60
</p>
<p> 70
</p>
<p> 80
</p>
<p> 90
</p>
<p>n&#8722;grammes +Pref/Suff +POS +Dict. +Pref.Dict.
 50
</p>
<p> 100
</p>
<p> 150
</p>
<p> 200
</p>
<p> 250
</p>
<p> 300
</p>
<p>Sc
or
</p>
<p>e 
(%
</p>
<p>)
</p>
<p>N
om
</p>
<p>br
e 
</p>
<p>de
 t
</p>
<p>ra
it
</p>
<p>s 
ac
</p>
<p>ti
fs
</p>
<p> (
en
</p>
<p> K
)
</p>
<p>Pr&#233;cision
F&#8722;mesure
</p>
<p>Rappel
Nbre de traits
</p>
<p>FIG. 1 &#8211; Pr&#233;cision (en %), rappel (en %), F-mesure et nombre de traits actifs pour des mod&#232;les
de complexit&#233; croissante (&#224; chaque nouveau mod&#232;le, de nouveaux traits sont ajout&#233;s).
</p>
<p>d&#8217;&#233;valuation de CoNLL 20025. Les mod&#232;les sont &#233;valu&#233;s par validation crois&#233;e &#224; 10 partitions,
sur des tests d&#8217;environ 25 000 mots chacun.
</p>
<p>3.2 S&#233;lection de caract&#233;ristiques et comparaison &#224; l&#8217;&#233;tat de l&#8217;art
</p>
<p>Diff&#233;rentes versions du mod&#232;le de base ont &#233;t&#233; d&#233;velopp&#233;es, qui incluent des jeux de descripteurs
de richesse croissante. Nous d&#233;crivons ci-dessous les principales familles de descripteurs ; chaque
r&#233;alisation x d&#8217;un &#233;l&#233;ment d&#8217;une de ces familles donne lieu &#224; un ensemble de fonctions bool&#233;ennes
testant x avec chaque &#233;tiquette et avec chaque bigramme d&#8217;&#233;tiquettes possibles.
N-grammes de mots : ces caract&#233;ristiques testent tous les unigrammes, les bigrammes, les
trigrammes et les quadrigrammes dans, respectivement, des fen&#234;tres de tailles 5, 3, 4 et 5.
Pr&#233;fixes et suffixes : chaque s&#233;quence d&#8217;une, deux, ou trois lettres observ&#233;e &#224; l&#8217;initiale ou &#224; la
finale d&#8217;un mot du corpus d&#8217;apprentissage donne lieu &#224; un nouveau descripteur. L&#8217;apparition
de ces pr&#233;fixes et suffixes est test&#233;e dans une fen&#234;tre de taille 5 centr&#233;e sur le mot courant.
POS-tags : ce trait concerne les &#233;tiquettes morpho-syntaxiques pr&#233;dites en utilisant un mod&#232;le
entra&#238;n&#233; par Wapiti sur l&#8217;Arabic Tree Bank6(Gahbiche-Braham et al., 2012). Les tests &#233;valuent les
unigrammes et bigrammes d&#8217;&#233;tiquettes respectivement dans des fen&#234;tres de tailles 5 et 3.
Ponctuation et nombres : ce trait teste la pr&#233;sence de caract&#232;res de ponctuations et de chiffres
dans le mot courant ainsi que dans les deux mots voisins.
Dictionnaires : Ces dictionnaires proviennent de l&#8217;ANERGazet 2, d&#8217;extraits de Wikipedia et de
la base de noms propres distribu&#233;e par JRC7. Pour chaque mot w, on teste s&#8217;il figure dans le
dictionnaire (Dict sur la figure 1), ou s&#8217;il y figure pr&#233;c&#233;d&#233; de pr&#233;fixes (Pref.Dict). Ces dictionnaires
contiennent 3 798 noms de lieux, 386 noms d&#8217;organisation et 13 648 noms de personnes.
</p>
<p>Les r&#233;sultats de ces exp&#233;riences sont report&#233;s sur la figure 1, qui repr&#233;sente la variation de la
pr&#233;cision, du rappel et de la F-mesure, ainsi que le nombre de traits actifs. On constate qu&#8217;au fur
et &#224; mesure que de nouveaux traits sont ajout&#233;s au mod&#232;le pr&#233;c&#233;dent, le rappel et la F-mesure
augmentent, parfois au prix d&#8217;une l&#233;g&#232;re d&#233;gradation de la pr&#233;cision.
</p>
<p>5http://bredt.uib.no/download/conlleval.txt
6http://www.ircs.upenn.edu/arabic/
7Joint Research Center de la Communaut&#233; europ&#233;enne : http://langtech.jrc.it/JRC-Names.html
8Le total report&#233; dans (Benajiba et Rosso, 2008) inclue l&#8217;EN MISC. Le total ici a &#233;t&#233; fait en calculant la moyenne.
</p>
<p>490</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;sultats du syst&#232;me de base R&#233;sultats de (Benajiba et Rosso, 2008)8
</p>
<p>Pr&#233;cision Rappel F&#946;=1 Pr&#233;cision Rappel F&#946;=1
LOC 90,59% 85,42% 87,83 LOC 93,03% 86,67% 89,74
ORG 78,67% 61,05% 68,75 ORG 84,23% 53,94% 65,76
PERS 81,31% 73,61% 77,27 PERS 80,41% 67,42% 73,35
Total 85,14% 76,27% 80,46 Total 85,89% 69,34% 76,28
</p>
<p>TAB. 1 &#8211; Pr&#233;cision, rappel et F-mesure du mod&#232;le de base (qui combine tous les traits) sur le
corpus ANER en comparaison avec les r&#233;sultats de (Benajiba et Rosso, 2008)
</p>
<p>Le tableau 1 donne une autre vue des performances du mod&#232;le le plus complet qui comprend
environ 275 000 traits finalement s&#233;lectionn&#233;s par Wapiti sur un potentiel d&#8217;environ 80 millions.
Afin de comparer notre syst&#232;me &#224; l&#8217;&#233;tat de l&#8217;art, le tableau 1 pr&#233;sente &#233;galement les r&#233;sultats
obtenus par (Benajiba et Rosso, 2008) sur le corpus ANER avec un syst&#232;me utilisant &#233;galement
les CRF. Notre mod&#232;le de base semble donc coh&#233;rent avec les performances d&#233;crites dans l&#8217;&#233;tat
de l&#8217;art et atteint des performances globales semblables &#224; celles d&#233;crites dans (Abdul Hamid et
Darwish, 2010).
</p>
<p>4 Adaptation du syst&#232;me d&#8217;&#233;tiquetage des entit&#233;s nomm&#233;es
</p>
<p>Les applications &#233;tudi&#233;es dans ce travail s&#8217;inscrivent dans le cadre du projet SAMAR9, qui vise
&#224; d&#233;velopper une plateforme de traitement de d&#233;p&#234;ches en langue arabe. Les donn&#233;es sont
principalement produites par l&#8217;Agence France Presse (AFP). L&#8217;&#233;tiquetage en EN est envisag&#233; ici
comme un pr&#233;-traitement pour la traduction des donn&#233;es de l&#8217;arabe vers le fran&#231;ais et l&#8217;anglais.
</p>
<p>Nous disposons dans ce cadre de ressources suppl&#233;mentaires pour adapter la d&#233;tection des EN :
&#8211; de donn&#233;es du domaine (AFP), non-annot&#233;es (130 000 phrases, 3 500K mots) ;
&#8211; d&#8217;un &#233;tiquetage automatique d&#8217;une partie des donn&#233;es r&#233;alis&#233; par un syst&#232;me symbolique
</p>
<p>d&#233;velopp&#233; par un des partenaires du projet, TEMIS (Guillemin-Lanne et al., 2007).
&#8211; d&#8217;un corpus de test annot&#233; manuellement et constitu&#233; de 900 phrases issues de l&#8217;AFP.
Les d&#233;p&#234;ches trait&#233;es dans notre application diff&#232;rent substantiellement des donn&#233;es du corpus
ANER, qui contient &#224; la fois des articles de presse, des donn&#233;es collect&#233;es en ligne, en particulier
des extraits de Wikipedia. Il existe &#233;galement un d&#233;calage temporel entre la constitution de ce
corpus (2007) et les donn&#233;es que nous devons traiter, qui sont post&#233;rieures &#224; 2009.
</p>
<p>4.1 Adaptation non-supervis&#233;e par auto-apprentissage
</p>
<p>Le syst&#232;me de base, constitu&#233; &#224; partir du corpus ANER, est utilis&#233; pour annoter automatiquement
le corpus AFP. Deux syst&#232;mes adapt&#233;s sont alors obtenus en utilisant comme corpus d&#8217;entra&#238;ne-
ment soit (i) le corpus &#233;tiquet&#233; automatiquement seul, soit (ii) les deux corpus. Le tableau 2
donne les r&#233;sultats des trois syst&#232;mes sur les donn&#233;es de test AFP. On constate une baisse sensible
des performances du syst&#232;me de base (la F-mesure passe de 80,46 sur les donn&#233;es de test ANER
&#224; 72,64 sur les donn&#233;es de test AFP). Apr&#232;s adaptation (AFP et ANER+AFP), on constate une
am&#233;lioration de la F-mesure pour les noms de lieux et d&#8217;organisations.
</p>
<p>9http://samar.fr
</p>
<p>491</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;le de base ANER Mod&#232;le AFP Mod&#232;le ANER+AFP
Pr&#233;cision Rappel F&#946;=1 Pr&#233;cision Rappel F&#946;=1 Pr&#233;cision Rappel F&#946;=1
</p>
<p>LOC 89,30% 78,85% 83,75 90,81% 77,84% 83,83 91,45% 78,18% 84,29
ORG 50,24% 37,72% 43,09 51,01% 35,94% 42,17 51,76% 36,65% 42,92
PERS 68,07% 66,03% 67,03 70,83% 69,29% 70,05 70,87% 68,75% 69,79
Total 77,61% 68,27% 72,64 79,39% 68,14% 73,34 79,86% 68,34% 73,65
</p>
<p>TAB. 2 &#8211; Comparaison et Adaptation de syst&#232;me de reconnaissance d&#8217;entit&#233;s nomm&#233;es
</p>
<p>En moyenne, nous gagnons 1 point en F-mesure pour le syst&#232;me adapt&#233;. La bonne qualit&#233;
des performances obtenues avec les annotations automatiques est principalement d&#251;e &#224; une
augmentation tr&#232;s sensible de la couverture. Alors que seules 11% environ des EN de type
personne du test sont dans le corpus ANER, on en retrouve plus de 60% quand on utilise le
corpus automatique AFP pour l&#8217;apprentissage. Des &#233;carts similaires, quoique moins importants,
sont obtenus pour les organisations, et dans une moindre mesure, pour les lieux. Ceci illustre
bien le caract&#232;re tr&#232;s localis&#233; des occurrences des EN dont la distribution fluctue en fonction de
l&#8217;actualit&#233;. D&#8217;une mani&#232;re g&#233;n&#233;rale, ces am&#233;liorations restent toutefois limit&#233;es. Il est possible que
la s&#233;lection des donn&#233;es de test (par l&#8217;AFP) conduise &#224; sous-estimer l&#8217;apport de l&#8217;adaptation : le jeu
de test contient majoritairement des d&#233;p&#234;ches ressortissant aux th&#232;mes &#171; guerre &#187; et &#171; politique &#187;,
mais aucune de la cat&#233;gorie &#171; sport &#187;, pourtant tr&#232;s pr&#233;sente dans le corpus d&#8217;entra&#238;nement.
</p>
<p>4.2 Un syst&#232;me hybride
</p>
<p>Nous pr&#233;sentons ici les performances des trois mod&#232;les d&#8217;&#233;tiquetage d&#233;crits &#224; la section 4.1 dans
un cadre de combinaison de syst&#232;mes. La d&#233;marche suivie consiste &#224; &#233;tiqueter automatiquement
le corpus de test par l&#8217;annotateur de Temis, qui atteint une pr&#233;cision de 81% et une F-measure de
74% sur le corpus de test de l&#8217;AFP.
</p>
<p>Le corpus de test est ensuite &#233;tiquet&#233; une seconde fois par Wapiti, en consid&#233;rant que les EN
annot&#233;es par Temis sont correctes et en n&#8217;utilisant Wapiti que pour pr&#233;dire les zones qui n&#8217;ont pas
&#233;t&#233; d&#233;tect&#233;es comme EN par l&#8217;&#233;tiqueteur symbolique. Les r&#233;sultats sont donn&#233;s dans le tableau 3.
</p>
<p>Mod&#232;le de base ANER Mod&#232;le AFP Mod&#232;le ANER+AFP
Pr&#233;cision Rappel F&#946;=1 Pr&#233;cision Rappel F&#946;=1 Pr&#233;cision Rappel F&#946;=1
</p>
<p>LOC 94,01% 85,12% 89,35 92,52% 81,31% 86,56 92,76% 81,31% 86,66
ORG 86,26% 66,18% 74,90 84,85% 61,09% 71,04 85,93% 62,18% 72,15
PERS 84,31% 76,01% 79,95 79,44% 72,22% 75,66 80,67% 72,73% 76,49
Total 90,24% 79,39% 84,47 87,80% 75,36% 81,11 88,45% 75,68% 81,57
</p>
<p>TAB. 3 &#8211; Adaptation et test sur un corpus pr&#233;-&#233;tiquet&#233; par un analyseur symbolique
</p>
<p>Ces r&#233;sultats montrent dans tous les cas une am&#233;lioration tr&#232;s sensible (+8 points) par rapport
aux r&#233;sultats ant&#233;rieurs, en particulier quand on utilise le mod&#232;le non-adapt&#233;, qui a de meilleures
performances que les mod&#232;les adapt&#233;s. Ceci est d&#251; au fait que le syst&#232;me ANER a &#233;t&#233; entra&#238;n&#233;
sur un corpus annot&#233; manuellement quand les syst&#232;mes adapt&#233;s utilisent des annotations
automatiques potentiellement bruit&#233;es. Par comparaison avec le tableau 2, l&#8217;hybridation am&#233;liore
les performances de chacun des syst&#232;mes pris s&#233;par&#233;ment. Ceci ouvre des perspectives, en
particulier pour mettre en place l&#8217;hybridation d&#232;s la construction du corpus d&#8217;apprentissage.
</p>
<p>492</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>5 Conclusion
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; un syst&#232;me d&#8217;&#233;tiquetage en Entit&#233;s Nomm&#233;es construit par
des m&#233;thodes d&#8217;apprentissage supervis&#233;. Ce syst&#232;me, qui embarque des centaines de milliers
de descripteurs, obtient des performances comparables aux meilleurs syst&#232;mes de l&#8217;&#233;tat de l&#8217;art.
Nous avons ensuite explor&#233; diverses mani&#232;res de r&#233;aliser une adaptation non-supervis&#233;e, par
auto-apprentissage, de ce syst&#232;me conduisant &#224; une l&#233;g&#232;re am&#233;lioration des performances. Nous
avons enfin montr&#233; qu&#8217;une hybridation du syst&#232;me statistique avec un syst&#232;me symbolique
pouvait donner lieu &#224; des gains bien sup&#233;rieurs.
</p>
<p>Ce travail ouvre de multiples perspectives portant sur les aspects li&#233;s &#224; l&#8217;adaptation comme sur les
aspects relatifs &#224; la traduction. Concernant l&#8217;adaptation, il reste &#224; reprendre les exp&#233;riences pr&#233;-
c&#233;dentes avec un corpus produit par combinaison d&#8217;annotations ; de mani&#232;re plus fondamentale,
il reste &#233;galement &#224; voir comment entra&#238;ner Wapiti avec ces pr&#233;-&#233;tiquetages partiels, en utilisant
par exemple des mod&#232;les &#224; donn&#233;es latentes. Du point de vue de l&#8217;application finale, deux
questions restent pos&#233;es. L&#8217;une concerne l&#8217;ordre dans lequel effectuer les traitements pr&#233;alables &#224;
la traduction : trois &#233;tapes s&#8217;encha&#238;nent dans notre pipeline actuel : analyse morpho-syntaxique,
d&#233;tection des EN, puis segmentation des formes complexes. Il n&#8217;est pas dit que cet ordre soit
optimal, et d&#8217;autres architectures devront &#234;tre explor&#233;es. Ensuite, l&#8217;impact de la d&#233;tection des EN
sur la qualit&#233; de la traduction doit &#234;tre &#233;valu&#233;. Un travail pr&#233;alable consistera &#224; &#233;tudier comment
les EN sont transf&#233;r&#233;es d&#8217;une langue &#224; l&#8217;autre, &#224; partir de corpus parall&#232;les annot&#233;s en EN.
</p>
<p>Remerciements
</p>
<p>Ces travaux ont &#233;t&#233; partiellement financ&#233;s par le projet Cap-Digital SAMAR et par le programme
Quaero. Merci &#224; TEMIS pour l&#8217;annotation des corpus et &#224; l&#8217;AFP pour le corpus de r&#233;f&#233;rence.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ABDUL HAMID, A. et DARWISH, K. (2010). Simplified feature set for Arabic named entity recogni-
tion. In Proc. of the 2010 Named Entities Workshop, pages 110&#8211;115, Uppsala.
</p>
<p>B&#201;CHET, F., SAGOT, B. et STERN, R. (2011). Coop&#233;ration de m&#233;thodes statistiques et symboliques
pour l&#8217;adaptation non-supervis&#233;e d&#8217;un syst&#232;me d&#8217;&#233;tiquetage en entit&#233;s nomm&#233;es. In actes de la
conf&#233;rence TALN, Montpellier, France.
</p>
<p>BELLAGARDA, J. R. (2001). An overview of statistical language model adaptation. In Proc. of the
ISCA Workshop on Adaptation Methods for Speech Recognition, pages 165&#8211;174, Sophia Antipolis.
</p>
<p>BENAJIBA, Y., DIAB, M. et ROSSO, P. (2008). Arabic named entity recognition using optimized
feature sets. In Proc. of EMNLP, EMNLP, pages 284&#8211;293.
</p>
<p>BENAJIBA, Y. et ROSSO, P. (2007). Conquering the NER task for the Arabic language by combining
the maximum entropy with POS-tag information. In Proceedings of Workshop on Natural
Language-Independant Engineering, IJCAI.
</p>
<p>BENAJIBA, Y. et ROSSO, P. (2008). Arabic named entity recognition using conditional random
fields. In Proceedings of the Conference on Language Resources and Evaluation.
</p>
<p>BENAJIBA, Y., ROSSO, P. et BENED&#205;, J.-M. (2007). Anersys : An arabic named entity recognition
system based on maximum entropy. In CICLing, pages 143&#8211;153.
</p>
<p>493</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>DAUME III, H. (2007). Frustratingly easy domain adaptation. In Proc. of the 45th Annual Meeting
of the ACL, pages 256&#8211;263, Prague, Czech Republic.
</p>
<p>DAUME III, H., DEOSKAR, T., MCCLOSKY, D., PLANK, B. et TIEDEMANN, J., &#233;diteurs (2010). Proc. of
the 2010 Workshop on Domain Adaptation for NLP. Uppsala, Sweden.
</p>
<p>DAUM&#201; III, H. et JAGARLAMUDI, J. (2011). Domain adaptation for machine translation by mining
unseen words. In ACL, Portland, OR.
</p>
<p>GAHBICHE-BRAHAM, S., BONNEAU-MAYNARD, H., LAVERGNE, T. et YVON, F. (2012). Joint segmenta-
tion and POS tagging for arabic using a CRF-based classifier. In Proc. of LREC&#8217;12.
</p>
<p>GAHBICHE-BRAHAM, S., BONNEAU-MAYNARD, H. et YVON, F. (2011). Two ways to use a noisy
parallel news corpus for improving statistical machine translation. In Proc. of Workshop on
Building and Using Comparable Corpora, pages 44&#8211;51, Portland, OR.
</p>
<p>GUILLEMIN-LANNE, S., DEBILI, F., TAHAR, Z. B. et GACI, C. (2007). Reconnaissance des entit&#233;s
nomm&#233;es en arabe. In Colloque VSST, Veille Strat&#233;gique Scientifique et Technologique.
</p>
<p>HABASH, N. (2010). Introduction to Arabic Natural Language Processing. Morgan Claypool.
</p>
<p>HERMJAKOB, U., KNIGHT, K. et DAUM&#201; III, H. (2008). Name translation in statistical machine
translation - learning when to transliterate. In Proc. of ACL-08 : HLT, pages 389&#8211;397, Ohio.
</p>
<p>JIANG, J. et ZHAI, C. (2007). Instance weighting for domain adaptation in nlp. In Proc. of the
45th Annual Meeting of the ACL, pages 264&#8211;271, Prague, Czech Republic.
</p>
<p>LAFFERTY, J., MCCALLUM, A. et PEREIRA, F. (2001). Conditional random fields : Probabilistic
models for segmenting and labeling sequence data. In Proc. ICML, pages 282&#8211;289, San Francisco.
</p>
<p>LAVERGNE, T., CAPP&#201;, O. et YVON, F. (2010). Practical very large scale CRFs. In Proceedings the
48th Annual Meeting of the Association for Computational Linguistics, pages 504&#8211;513.
</p>
<p>MALONEY, J. et NIV, M. (1998). TAGARAB : a fast, accurate Arabic name recognizer using
high-precision morphological analysis. In Proc. of the Workshop on Computational Approaches to
Semitic Languages, Semitic &#8217;98, pages 8&#8211;15, Stroudsburg, PA, USA.
</p>
<p>MIHALCEA, R. (2004). Co-training and self-training for word sense disambiguation. In NG, H. T.
et RILOFF, E., &#233;diteurs : HLT-NAACL Workshop : CoNLL-2004, pages 33&#8211;40, Boston.
</p>
<p>SAMY, D., MORENO, A. et MA GUIRAO, J. (2005). A proposal for an Arabic named entity tagger
leveraging a parallel corpus. RANLP &#8217;05.
</p>
<p>SHAALAN, K. et RAZA, H. (2009). NERA : Named entity recognition for arabic. Journal of the
American Society for Information Science and Technology, 60(9):1652&#8211;1663.
</p>
<p>SOKOLOVSKA, N., CAPP&#201;, O. et YVON, F. (2009). S&#233;lection de caract&#233;ristiques pour les champs
al&#233;atoires conditionnels par p&#233;nalisation l1. TAL, 50(3):139&#8211;171.
</p>
<p>ZAGHOUANI, W., POULIQUEN, B., EBRAHIM, M. et STEINBERGER, R. (2010). Adapting a resource-light
highly multilingual named entity recognition system to arabic. Proceedings of the Seventh
conference on International Language Resources and Evaluation (LREC&#8217;10), pages 563&#8211;567.
</p>
<p>ZHANG, M., LI, H., KUMARAN, A. et LIU, M. (2011). Report of news2011 machin transliteration
shared task. In Proceedings of the 2011 Named Entities Workshop.
</p>
<p>ZITOUNI, I., SORENSEN, J., LUO, X. et FLORIAN, R. (2005). The impact of morphological stemming
on Arabic mention detection and coreference resolution. In Proc. of Workshop on Computational
Approaches to Semitic Languages, pages 63&#8211;70, Ann Arbor, Michigan.
</p>
<p>494</p>

</div></div>
</body></html>