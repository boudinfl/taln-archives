<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Une Approche de Recherche d&#8217;Information Structur&#233;e fond&#233;e sur la Correction d&#8217;Erreurs &#224; l&#8217;Indexation des Documents</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 519&#8211;526,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Une approche de recherche d&#8217;information structur&#233;e fond&#233;e
sur la correction d&#8217;erreurs &#224; l&#8217;indexation des documents
</p>
<p>Arnaud Renard1, 2 Sylvie Calabretto1, 2 B&#233;atrice Rumpler1, 2
(1) Universit&#233; de Lyon, CNRS
</p>
<p>(2) INSA-Lyon, LIRIS, UMR 5205, F-69621 Villeurbanne Cedex
arnaud.renard@insa-lyon.fr, sylvie.calabretto@insa-lyon.fr,
</p>
<p>beatrice.rumpler@insa-lyon.fr
</p>
<p>R&#201;SUM&#201;
Dans cet article, nous nous sommes int&#233;ress&#233;s &#224; la prise en compte des erreurs dans les contenus
textuels des documents XML. Nous proposons une approche visant &#224; diminuer l&#8217;impact de ces
erreurs sur les syst&#232;mes de Recherche d&#8217;Information (RI). En effet, ces syst&#232;mes produisent des
index associant chaque document aux termes qu&#8217;il contient. Les erreurs affectent donc la qualit&#233;
des index ce qui conduit par exemple &#224; consid&#233;rer &#224; tort des documents mal index&#233;s comme
non pertinents (resp. pertinents) vis-&#224;-vis de certaines requ&#234;tes. Afin de faire face &#224; ce probl&#232;me,
nous proposons d&#8217;inclure un m&#233;canisme de correction d&#8217;erreurs lors de la phase d&#8217;indexation
des documents. Nous avons impl&#233;ment&#233; cette approche au sein d&#8217;un prototype que nous avons
&#233;valu&#233; dans le cadre de la campagne d&#8217;&#233;valuation INEX.
</p>
<p>ABSTRACT
Structured Information Retrieval Approach based on Indexing Time Error Correction
</p>
<p>In this paper, we focused on errors in the textual content of XML documents. We propose an
approach to reduce the impact of these errors on Information Retrieval (IR) systems. Indeed,
these systems rely on indexes associating each document to corresponding terms. Indexes quality
is negatively affected by those misspellings. These errors makes it difficult to later retrieve
documents (or parts of them) in an effective way during the querying phase. In order to deal
with this problem we propose to include an error correction mechanism during the indexing
phase of documents. We achieved an implementation of this spelling aware information retrieval
system which is currently evaluated over INEX evaluation campaign documents collection.
</p>
<p>MOTS-CL&#201;S : Recherche d&#8217;information, dysorthographie, correction d&#8217;erreurs, xml.
</p>
<p>KEYWORDS: Information retrieval, misspellings, error correction, xml.
</p>
<p>1 Introduction
</p>
<p>Les documents produits dans un cadre professionnel doivent satisfaire &#224; un niveau minimum
de qualit&#233; et font l&#8217;objet de multiples cycles de relecture et correction permettant d&#8217;y parvenir.
Cela constituait auparavant le principal mode de production d&#8217;informations n&#233;anmoins cette
pratique a fortement &#233;volu&#233; et &#224; l&#8217;&#233;chelle d&#8217;Internet, il s&#8217;agit d&#233;sormais d&#8217;un mode de production
de l&#8217;information qui peut &#234;tre consid&#233;r&#233; comme marginal. En effet, la plupart des documents
sont cr&#233;&#233;s par des utilisateurs hors de tout cadre professionnel. Ces derniers sont donc davantage
</p>
<p>519</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>susceptibles de commettre des erreurs en employant un lexique qu&#8217;ils ne ma&#238;trisent pas toujours
et qui peut s&#8217;av&#233;rer inadapt&#233; au sujet trait&#233;. Par ailleurs, le contenu publi&#233; sur Internet n&#8217;est pas
soumis &#224; un contr&#244;le de qualit&#233; : les blogs ont popularis&#233; l&#8217;auto-publication de masse &#224; la fois
gratuite et imm&#233;diatement disponible. Il est donc l&#233;gitime dans ce cas d&#8217;&#233;mettre des r&#233;serves
sur la qualit&#233; des documents et autres informations produits dans ce cadre (Subramaniam et al.,
2009). Les syst&#232;mes de RI constituent les principaux points d&#8217;acc&#232;s aux informations d&#8217;Internet.
Ils sont affect&#233;s par les erreurs (Kantor et Voorhees, 2000) dont la correction constitue un axe
d&#8217;am&#233;lioration important qu&#8217;il convient d&#8217;&#233;tudier (Varnhagen et al., 2009).
</p>
<p>Dans la section 2 nous pr&#233;senterons la RI dans les documents (semi-)structur&#233;s XML ainsi que
les travaux tentant de m&#234;ler RI et correction d&#8217;erreurs. Dans la section 3, nous pr&#233;senterons
notre approche int&#233;grant la gestion de la correction des erreurs durant la phase d&#8217;indexation des
documents. Nous analyserons les r&#233;sultats de l&#8217;&#233;valuation de notre syst&#232;me de RI sans et avec
prise en charge des erreurs sur la campagne d&#8217;&#233;valuation INEX dans la section 4. Enfin, nous
conclurons et nous pr&#233;senterons nos perspectives d&#8217;&#233;volution en section 5.
</p>
<p>2 Contexte g&#233;n&#233;ral et positionnement
</p>
<p>2.1 Recherche d&#8217;information structur&#233;e
</p>
<p>Les documents XML constituent un des formats de diffusion de l&#8217;information les plus r&#233;pandus sur
internet. Nous allons dans un premier temps mod&#233;liser ces documents dont la structure explicite
est plus complexe que de simples documents textuels &quot;plats&quot;. Un document XML structur&#233; ds
peut &#234;tre repr&#233;sent&#233; par un arbre dans lequel on peut distinguer 3 types de n&#339;uds diff&#233;rents :
les n&#339;uds feuilles nfi repr&#233;sentant le contenu textuel, les n&#339;uds internes nii correspondant aux
&#233;l&#233;ments ainsi que leurs attributs nai .
</p>
<p>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF&#8722;8&quot;?&gt;
&lt;article&gt;
&lt;name id=&quot;1337&quot;&gt;Lorem...&lt;/name&gt;
&lt;body&gt;
...ipsum dolor sit amet,
&lt;emph&gt;consectetur&lt;/emph&gt;
adipiscing elit.
</p>
<p>&lt;/body&gt;
&lt;/article&gt;
</p>
<p>article
</p>
<p>name
</p>
<p>Lorem...
</p>
<p>body
</p>
<p>...ipsum
dolor sit
amet,
</p>
<p>emph
</p>
<p>consectetur
</p>
<p>adipiscing
elit.&quot;1337&quot;
</p>
<p>ni
</p>
<p>na
</p>
<p>nf
</p>
<p>FIGURE 1 &#8211; Document XML (&#224; gauche) et sa repr&#233;sentation arborescente (&#224; droite).
</p>
<p>Les informations textuelles sont pr&#233;sentes principalement dans les n&#339;uds feuilles qui sont les
n&#339;uds &#224; indexer en priorit&#233; et qui constitueront le niveau de granularit&#233; le plus fin de notre
syst&#232;me de RI. Il diff&#232;re en cela des syst&#232;mes de RI classiques dont la granularit&#233; correspond
au document. Plusieurs approches de la litt&#233;rature (Kamps et al., 2009) permettent la prise en
compte de cette granularit&#233; plus fine mais aussi de la structure des documents. Nous proposons de
nous appuyer sur une adaptation du mod&#232;le vectoriel de (Salton, 1971) ainsi que sur l&#8217;approche
employ&#233;e par XFIRM (Sauvagnat et Boughanem, 2005) qui introduit une m&#233;thode de propagation
de la pertinence au travers de la structure des documents.
</p>
<p>520</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>2.1.1 Pond&#233;ration des n&#339;uds feuilles (orient&#233;e contenu)
</p>
<p>Lors de l&#8217;&#233;valuation d&#8217;une requ&#234;te le score relatif &#224; la pertinence des n&#339;uds feuilles est calcul&#233;
directement, tandis que les scores des n&#339;uds internes sont propag&#233;s dynamiquement &#224; partir
des n&#339;uds feuilles &#224; travers l&#8217;arborescence du document. Cela permet de retourner une liste
ordonn&#233;e des n&#339;uds (sous-arbres) les plus pertinents pour la requ&#234;te.
</p>
<p>Le score d&#8217;un n&#339;ud feuille snf vis-&#224;-vis d&#8217;une requ&#234;te textuelle r compos&#233;e d&#8217;une s&#233;quence de n
termes (ou mots-cl&#233;s) t1, ..., tn se calcule selon la formule suivante :
</p>
<p>snf (r) =
n&#8721;
</p>
<p>i=1
</p>
<p>prt i &#215; pnft i (1)
</p>
<p>dans laquelle, prt i et p
nf
t i sont respectivement les poids du i-&#232;me terme t i dans la requ&#234;te r (&#233;valu&#233;
</p>
<p>lors de l&#8217;interrogation), et dans le n&#339;ud feuille nf (&#233;valu&#233; lors de l&#8217;indexation). Afin d&#8217;adapter
le mod&#232;le vectoriel de Salton aux documents XML structur&#233;s, nous avons choisi un syst&#232;me de
pond&#233;ration qui refl&#232;te l&#8217;importance locale des termes dans les n&#339;uds feuilles (t f ) 1 et globale
dans les documents (id f ) 2 ainsi que dans les &#233;l&#233;ments (ie f ) 3 de la collection.
</p>
<p>prt i = t f
r
t i
</p>
<p>pnft i = t f
nf
t i &#215; id ft i &#215; ie ft i (2)
</p>
<p>o&#249;, t f rt i et t f
nf
t i sont respectivement la fr&#233;quence du terme t i dans la requ&#234;te r et dans le n&#339;ud
</p>
<p>feuille nf . La fr&#233;quence correspond au nombre d&#8217;occurences du terme t i respectivement dans
la requ&#234;te r (d&#233;not&#233; par |t ri |) et dans nf (d&#233;not&#233; par |tnfi |), divis&#233; par le nombre de termes
respectivement dans la requ&#234;te r (d&#233;not&#233; par |r|) et dans le n&#339;ud feuille nf (d&#233;not&#233; par |nf |).
</p>
<p>t f rt i =
|t ri |
|r| t f
</p>
<p>nf
t i =
</p>
<p>|tnfi |
|nf | (3)
</p>
<p>et, id ft i (resp. ie ft i ) repr&#233;sente la fr&#233;quence inverse du terme t i dans les documents (resp. les
n&#339;uds feuilles). |D| (resp. |NF |) est le nombre total de documents (resp. n&#339;uds feuilles) de la
collection et |dt i | (resp. |nft i |) le nombre de documents (resp. n&#339;uds feuilles) qui contiennent le
terme t i .
</p>
<p>id ft i = log
&#129; |D|
|dti |+1
</p>
<p>&#139;
+ 1 ie ft i = log
</p>
<p>&#129; |NF |
|nfti |+1
</p>
<p>&#139;
+ 1 (4)
</p>
<p>2.1.2 Pond&#233;ration des n&#339;uds internes (orient&#233;e structure)
</p>
<p>Lorsqu&#8217;un n&#339;ud feuille est pertinent vis-&#224;-vis d&#8217;une requ&#234;te, les n&#339;uds internes anc&#234;tres de ce
dernier le sont &#233;galement dans une certaine mesure du fait qu&#8217;ils englobent ce dernier. Le score
des n&#339;uds feuilles peut ainsi &#234;tre propag&#233; de proche en proche &#224; leurs n&#339;uds ascendants (selon
une fonction d&#8217;agr&#233;gation) jusqu&#8217;au n&#339;ud racine qui repr&#233;sente le document dans son int&#233;gralit&#233;.
</p>
<p>sni(r) = |NF snf (r)&gt;0ni |.
&#8721;
</p>
<p>nfk&#8712;NFn
&#945;dist(ni,nfk)&#8722;1 &#215; snfk(r) (5)
</p>
<p>1. tf : term frequency (fr&#233;quence du terme dans un contexte : requ&#234;te, &#233;l&#233;ment, ou document).
2. idf : inverse document frequency (fr&#233;quence inverse du terme dans les documents).
3. ief : inverse element frequency (fr&#233;quence inverse du terme dans les &#233;l&#233;ments).
</p>
<p>521</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>o&#249;, &#945; compris dans l&#8217;intervalle [0..1] repr&#233;sente le facteur d&#8217;att&#233;nuation de l&#8217;importance du n&#339;ud
feuille nfk vis-&#224;-vis du n&#339;ud interne ni et dist(ni,nfk) repr&#233;sente la distance entre le n&#339;ud
interne ni et le n&#339;ud feuille nfk dans la structure arborescente du document. Ainsi, les termes
qui apparaissent pr&#232;s de la racine d&#8217;un sous-arbre sont plus pertinents pour l&#8217;&#233;l&#233;ment racine que
ceux qui apparaissent &#224; un niveau plus profond du sous-arbre.
</p>
<p>Et |NF snf (q)&gt;0)ni | repr&#233;sente le nombre de n&#339;uds feuilles du n&#339;ud interne qui sont pertinents car
un n&#339;ud qui contient plus de n&#339;uds pertinents peut &#234;tre consid&#233;r&#233; comme plus pertinent.
</p>
<p>En pr&#233;sence d&#8217;erreurs, le calcul des scores des n&#339;uds feuilles et notamment le facteur pnft i de la
</p>
<p>formule 1 est impact&#233; car le t f nft i (cf. formule 2) est amoindri voire annul&#233; dans certain cas ce
qui diminue la pertinence du n&#339;ud. Il est donc important de consid&#233;rer la correction des erreurs.
</p>
<p>2.2 Correction des erreurs dans les syst&#232;mes de RI
</p>
<p>La plupart des approches de correction d&#8217;erreurs associ&#233;es aux syst&#232;mes de RI consid&#232;rent
uniquement la correction des requ&#234;tes. tels que les travaux de (Sitbon et al., 2007), ou encore le
&quot;Did you mean...&quot; introduit par Google qui n&#8217;est donc pas adapt&#233;. Certains des travaux li&#233;s &#224; la
campagne d&#8217;&#233;valuation TREC 4 consid&#232;rent la correction des documents.
</p>
<p>La campagne TREC-5 Confusion track a rendu disponibles diff&#233;rentes versions d&#8217;une collection
de plus de 55000 documents contenant respectivement des taux d&#8217;erreurs de 0%, 5%, et 20%.
L&#8217;article de synth&#232;se de la campagne (Kantor et Voorhees, 2000) pr&#233;sente les diff&#233;rentes approches
pour la gestion des erreurs suivies par 5 des participants. N&#233;anmoins, ils ont pu constater une
d&#233;gradation des performances de tous les syst&#232;mes de RI en pr&#233;sence de documents corrompus
contenant des erreurs essentiellement dues &#224; la non correspondance entre les termes de la requ&#234;te
et les termes par lesquels les documents ont &#233;t&#233; index&#233;s. Le m&#234;me ph&#233;nom&#232;ne d&#8217;augmentation
des silences &#224; l&#8217;interrogation et de perte de pr&#233;cision m&#234;me &#224; de faibles taux de corruption des
documents (taux d&#8217;erreurs de 3%) a &#233;t&#233; observ&#233; par (Ruch, 2002). La campagne TREC-6 Spoken
document retrieval track (Voorhees et al., 2000) consid&#232;re des documents issus de transcriptions
de m&#234;me que (Gravier et al., 2011).
</p>
<p>Dans le cadre de TREC-5, trois syst&#232;mes s&#8217;appuient sur l&#8217;expansion de requ&#234;tes en y ajoutant
des versions alt&#233;r&#233;es des termes qui la composaient. Cela pr&#233;sente l&#8217;inconv&#233;nient d&#8217;introduire
du bruit suppl&#233;mentaire dans les r&#233;sultats du syst&#232;me de RI lorsque le nombre de variations
des termes de la requ&#234;te ajout&#233;es &#224; la requ&#234;te initiale augmente. Deux autres syst&#232;mes ont suivi
des approches diff&#233;rentes et ont essay&#233; de corriger directement les erreurs pr&#233;sentes dans les
documents ce qui semble apporter un gain plus important. Cela constitue un point de d&#233;part
int&#233;ressant dans l&#8217;&#233;tude de la robustesse des syst&#232;mes de RI face aux erreurs.
</p>
<p>3 Proposition : Construction d&#8217;index corrig&#233;s
</p>
<p>Notre approche consiste &#224; corriger les erreurs lors de la phase d&#8217;indexation du syst&#232;me de RI et
plus pr&#233;cis&#233;ment pendant l&#8217;analyse du contenu textuel des documents. Notre proposition s&#8217;appuie
</p>
<p>4. TREC : Text REtrieval Conference
</p>
<p>522</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>donc sur deux sous-syst&#232;mes : un syst&#232;me de RI XML fond&#233; sur le mod&#232;le XFIRM pr&#233;sent&#233; en
section 2.1, et un syst&#232;me de correction d&#8217;erreurs qui y est int&#233;gr&#233;.
</p>
<p>En effet, le mod&#232;le XFIRM ne permet pas la prise en compte des erreurs, c&#8217;est pourquoi les
fonctions de calcul de la pond&#233;ration des termes doivent &#234;tre modifi&#233;es pour en tenir compte.
De plus, un syst&#232;me de correction d&#8217;erreurs est n&#233;cessaire afin d&#8217;identifier les termes erron&#233;s et
d&#8217;identifier les termes qui doivent leur &#234;tre substitu&#233;s dans l&#8217;index.
</p>
<p>Supposons les deux phrases suivantes p1 et p2 appartenant respectivement &#224; deux documents
XML ds1 et ds2 simples car comportant un seul &#233;l&#233;ment &#224; leur racine respectivement nf1 et nf2 :
</p>
<p>p1 : &quot;The trees are green.&quot; p2 : &quot;Green paper is made of teer.&quot;
</p>
<p>Lors de la construction de l&#8217;index, les termes sont lemmatis&#233;s (mis sous une forme standard :
noms au singulier, ...) puis filtr&#233;s en fonction d&#8217;une liste de mots non significatifs (&quot;stop-words&quot;).
L&#8217;index construit &#224; partir de ces deux documents est ainsi repr&#233;sent&#233; dans la table 1.
</p>
<p>Terme Document &#201;l&#233;ment tf idf ief
</p>
<p>green ds1 nf1 0,5 0,82 0,82
ds2 nf2 0,33
</p>
<p>paper ds2 nf2 0,33 1 1
teer ds2 nf2 0,33 1 1
tree ds1 nf1 0,5 1 1
</p>
<p>TABLE 1 &#8211; Index des documents ds1 et ds2 (les facteurs idf et ief sont &#233;gaux car les documents ne
comportent chacun qu&#8217;un seul &#233;l&#233;ment).
</p>
<p>Ainsi, une recherche comportant les mots-cl&#233;s tree et paper aboutira aux scores suivants pour
chacun des n&#339;uds des deux documents :
</p>
<p>sds1(r) = snf 1(r) = prt ree &#215; pnf 1t ree + prpaper &#215; pnf 1paper = 0, 25
sds2(r) = snf 2(r) = prt ree &#215; pnf 2t ree + prpaper &#215; pnf 2paper = 0, 165 (6)
</p>
<p>Comme cela peut &#234;tre constat&#233; sur cet exemple, le document ds1 obtient un score de 0,25
sup&#233;rieur au score de 0, 165 obtenu par ds2. N&#233;anmoins, on s&#8217;aper&#231;oit bien en lisant les 2 phrases
que p1 (et donc nf1 et ds1) devrait moins bien r&#233;pondre &#224; la requ&#234;te que p2 car elle ne contient
pas paper alors que c&#8217;est le cas de p2 (et donc nf2 et ds2). Pour pallier cela, le syst&#232;me de
correction d&#8217;erreurs est utilis&#233; afin d&#8217;associer chaque erreur &#224; sa correction avec un degr&#233; de
</p>
<p>confiance &#948; tel que ter r
&#948;7&#8722;&#8594; tcor . Cela permet ainsi de d&#233;tecter que le terme teer not&#233; ter r
</p>
<p>constitue un terme erron&#233; et qu&#8217;il doit &#234;tre remplac&#233; par le terme original tree not&#233; tcor .
</p>
<p>Afin de prendre en compte les occurrences potentielles des termes issus de la correction, il est
n&#233;cessaire de modifier les formules permettant l&#8217;obtention de la pond&#233;ration des termes dans les
n&#339;uds des documents (cf. formule 2) &#224; savoir : le t f (cf. formule 3), l&#8217;id f et l&#8217;ie f (cf. formule 4).
</p>
<p>t f nft i =
|tnfi |+
</p>
<p>&#8721;|tnfcor |
e=1 &#948;e
</p>
<p>|nf | (7)
</p>
<p>o&#249;,
&#8721;|tnfcor |
</p>
<p>e=1 &#948;e est le nombre (pond&#233;r&#233; par la confiance &#948;e) de termes erron&#233;s t
nf
er r dont la correction
</p>
<p>tnfcor est &#233;gale au terme original t
nf
i .
</p>
<p>523</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>id ft i = log
</p>
<p>&#130;
|D|
</p>
<p>|dti |+
&#8721;|dtcor |
</p>
<p>e=1 &#948;e+1
</p>
<p>&#140;
+ 1 ie ft i = log
</p>
<p>&#130;
|NF |
</p>
<p>|nfti |+
&#8721;|nftcor |
</p>
<p>e=1 &#948;e+1
</p>
<p>&#140;
+ 1 (8)
</p>
<p>o&#249;,
&#8721;|dtcor |
</p>
<p>e=1 &#948;e (resp.
&#8721;|nftcor |
</p>
<p>e=1 &#948;e) est le nombre (pond&#233;r&#233; par la confiance &#948;e) de documents dter r
(resp. d&#8217;&#233;l&#233;ments nfter r ) contenant des termes erron&#233;s dont la correction dtcor (resp. nftcor ) est
&#233;gale au terme original dt i (resp. nft i ).
</p>
<p>Ainsi, si on reprend l&#8217;exemple pr&#233;c&#233;dent en consid&#233;rant un degr&#233; de confiance plut&#244;t mod&#233;r&#233; &#948;
de 60% dans la correction (en pratique ce degr&#233; est d&#233;termin&#233; par le score attribu&#233; &#224; tcor par le
syst&#232;me de correction d&#8217;erreurs), on obtient l&#8217;index corrig&#233; selon les formules 7 et 8 pr&#233;sent&#233;
dans le tableau 2 :
</p>
<p>Terme Document &#201;l&#233;ment tf idf ief
</p>
<p>green ds1 nf1 0,5 0,82 0,82
ds2 nf2 0,33
</p>
<p>paper ds2 nf2 0,33 1 1
</p>
<p>tree ds1 nf1 0,5 0,89 0,89
ds2 nf2 0,2
</p>
<p>TABLE 2 &#8211; Index modifi&#233; des documents ds1 et ds2 (les facteurs idf et ief sont &#233;gaux car les
documents ne comportent chacun qu&#8217;un seul &#233;l&#233;ment).
</p>
<p>Une recherche comportant les mots-cl&#233;s tree et paper aboutira aux scores suivants pour chacun
des n&#339;uds des deux documents :
</p>
<p>scords1(r) = s
cor
n f 1(r) = p
</p>
<p>r
t ree &#215; pnf 1t ree + prpaper &#215; pnf 1paper = 0,19
</p>
<p>scords2(r) = s
cor
n f 2(r) = p
</p>
<p>r
t ree &#215; pnf 2t ree + prpaper &#215; pnf 2paper = 0,25 (9)
</p>
<p>Par cons&#233;quent, le document ds2 sera mieux class&#233; que le document ds1 (et cela bien que le
degr&#233; de confiance dans les corrections qui a &#233;t&#233; choisi soit relativement faible), ce qui est
correct compte tenu du fait que c&#8217;est ce premier qui est le plus pertinent des deux documents.
L&#8217;approche propos&#233;e a servi de support &#224; l&#8217;impl&#233;mentation de nos prototypes SnAIRS/SAIRS
(Spelling (non-)Aware Information Retrieval System) &#233;valu&#233;s ci-dessous.
</p>
<p>4 &#201;valuation
</p>
<p>Nos prototypes SnAIRS/SAIRS ont &#233;t&#233; &#233;valu&#233;s sur la collection de documents du track ad-hoc de
la campagne d&#8217;&#233;valuation INitiative for the Evaluation of XML retrieval (INEX) de 2008. Cette
campagne comporte une collection de 659387 documents XML issus de Wikipedia associ&#233;e &#224; 70
requ&#234;tes &#233;valu&#233;es. Le track ad-hoc est compos&#233; de 3 taches : focused, relevant in context et best in
context, qui sont associ&#233;es &#224; diff&#233;rentes m&#233;triques permettant de les &#233;valuer. L&#8217;objectif poursuivi
suite &#224; la participation &#224; de telles campagnes est d&#8217;&#233;valuer le syst&#232;me de RI complet sans puis avec
correction d&#8217;erreurs (s&#8217;appuyant sur Aspell (Atkinson, 2011)) lors de l&#8217;indexation des documents.
De cette fa&#231;on, il est possible d&#8217;obtenir &#224; la fois des indicateurs globaux sur les performances de
notre syst&#232;me de RI (en comparant ses r&#233;sultats &#224; ceux obtenus par d&#8217;autres syst&#232;mes &#233;valu&#233;s
lors de la campagne), mais aussi des indicateurs locaux nous permettant d&#8217;estimer l&#8217;impact relatif
de la correction d&#8217;erreurs sur les r&#233;sultats de notre syst&#232;me de RI.
</p>
<p>524</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Prototype SnAIRS SAIRS &#8710; (%)
Volume index (Go) 8,0 6,9 -13,75
Dur&#233;e req. min. (ms) 2 1 -50
Dur&#233;e req. max. (ms) 13320 27279 +104,80
Dur&#233;e req. moy. (ms) 605 1139 +88,26
Dur&#233;e req. 1er quartile (ms) 4 4 0
Dur&#233;e req. mediane. (ms) 5 6 +20
Dur&#233;e req. 3e quartile (ms) 16 32 +100
Dur&#233;e req. total (ms) 41775 78657 +88,29
</p>
<p>TABLE 3 &#8211; Propri&#233;t&#233;s de SnAIRS (sans correction) et SAIRS (avec correction).
</p>
<p>Bien que la collection de documents INEX ne contienne qu&#8217;un faible taux d&#8217;erreurs (les documents
issus de Wikipedia sont de relativement bonne qualit&#233;), on peut constater dans la table 3 que le
volume occup&#233; par l&#8217;index est beaucoup plus important pour les m&#234;mes documents lorsque ces
derniers contiennent des erreurs m&#234;me en faible quantit&#233;. Ce comportement peut s&#8217;expliquer
par le fait que les erreurs constituent autant de variations des termes qui viennent augmenter
le nombre d&#8217;entr&#233;es diff&#233;rentes dans l&#8217;index. On pourrait penser qu&#8217;un index plus petit devrait
permettre une ex&#233;cution plus rapide des requ&#234;tes. Bien que cela ne soit pas visible (on constate
une d&#233;gradation et non pas un gain) dans la table 3, c&#8217;est effectivement le cas mais cela est
contrebalanc&#233; par le fait qu&#8217;il y a un nombre plus important de correspondances dans l&#8217;index et
donc un nombre plus important de r&#233;sultats &#224; retourner ce qui demande plus de temps.
</p>
<p>La taille de l&#8217;index et le temps de r&#233;ponse ne sont pas les seuls facteurs impact&#233;s par les erreurs,
c&#8217;est aussi le cas de la pertinence des r&#233;sultats. Les syst&#232;mes ont ainsi &#233;t&#233; &#233;valu&#233;s sur la tache
focused qui est la plus classique car elle est d&#233;di&#233;e &#224; la recherche des &#233;l&#233;ments (parties de
documents) les plus pertinents dans les premiers rangs des r&#233;sultats de la requ&#234;te. Cette tache est
&#233;valu&#233;e en fonction de la pr&#233;cision interpol&#233;e &#224; 1% de rappel (iP[.01], la m&#233;trique principale),
mais aussi de la moyenne des pr&#233;cisions interpol&#233;es (MAiP) sur les 101 points de rappel.
</p>
<p>Participant iP[.00] iP[.01] iP[.05] iP[.10] MAiP
SnAIRS 0.3073 0.2894 0.1788 0.1501 0.0499
SAIRS 0.3592 0.3141 0.1967 0.1694 0.0598
</p>
<p>TABLE 4 &#8211; R&#233;sultats de SnAIRS (sans correction), SAIRS (avec correction).
</p>
<p>On peut observer sur la table 4 que SnAIRS obtient une pr&#233;cision inf&#233;rieure &#224; SAIRS aux diff&#233;rents
niveaux de rappels consid&#233;r&#233;s par la campagne INEX et notamment pour la mesure officielle
d&#8217;iP[.01]. La correction des erreurs &#224; l&#8217;indexation permet donc d&#8217;obtenir une pr&#233;cision accrue dans
les premiers niveaux de rappels. Ces r&#233;sultats sont prometteurs (de nombreux param&#232;tres peuvent
&#234;tre am&#233;lior&#233;s) bien qu&#8217;ils soient pour l&#8217;instant relativement &#233;loign&#233;s du Top-10 d&#8217;INEX (Kamps
et al., 2009) dont les syst&#232;mes plus aboutis int&#232;grent des m&#233;canismes tel que l&#8217;expansion de
requ&#234;tes leur permettant de mieux satisfaire aux requ&#234;tes &quot;pauvres&quot; compos&#233;es d&#8217;un seul mot-cl&#233;.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Dans cet article nous avons consid&#233;r&#233; un probl&#232;me qui touche de fa&#231;on transverse l&#8217;ensemble
des applications amen&#233;es &#224; manipuler des informations de qualit&#233; variable. Nous avons ainsi
</p>
<p>525</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>consid&#233;r&#233; le cas des informations textuelles qui sont souvent consid&#233;r&#233;es de fait comme &#233;tant
&quot;propres&quot;. Nous avons propos&#233; une solution &#224; ce probl&#232;me pour les syst&#232;mes de RI structur&#233;s en
section 3 qui pourrait &#234;tre &#233;tendue &#224; la plupart des syst&#232;mes de RI car cette derni&#232;re consiste
&#224; y int&#233;grer un syst&#232;me de correction d&#8217;erreurs lors du processus d&#8217;indexation. Nous avons dans
un premier temps identifi&#233; les contraintes sp&#233;cifiques impos&#233;es par les syst&#232;mes de RI vis-&#224;-vis
des syst&#232;mes de corrections d&#8217;erreurs, et nous les avons &#233;valu&#233;s dans (Renard et al., 2011). La
correction d&#8217;erreurs &#224; l&#8217;indexation pr&#233;sente des avantages (cf. table 3) et permet de construire des
index plus repr&#233;sentatifs du contenu r&#233;el des documents ce qui aboutit &#224; de meilleurs r&#233;sultats (cf.
table 4) que sans correction d&#8217;erreurs. De plus, la collection de documents bas&#233;e sur Wikipedia
ne contient que peu d&#8217;erreurs et il serait int&#233;ressant de corrompre volontairement cette derni&#232;re
afin de mieux mettre en lumi&#232;re l&#8217;apport de notre proposition.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ATKINSON, K. (2011). Correcteur Aspell. http://aspell.net. [consult&#233; le 15/01/2012].
GRAVIER, G., GUINAUDEAU, C., LECORV&#201;, G. et S&#201;BILLOT, P. (2011). Exploiting speech for automatic
TV delinearization : From streams to cross-media semantic navigation. EURASIP JIVP, 2011(0).
KAMPS, J., GEVA, S., TROTMAN, A., WOODLEY, A. et KOOLEN, M. (2009). Overview of the INEX
2008 Ad Hoc Track. In GEVA, S., KAMPS, J. et TROTMAN, A., &#233;diteurs : Advances in Focused
Retrieval, volume 5631 de Lecture Notes in Computer Science, pages 1&#8211;28. Springer-Verlag.
KANTOR, P. B. et VOORHEES, E. M. (2000). TREC-5 Confusion Track : Comparing Retrieval
Methods for Scanned Text. Information Retrieval, 2(2):165&#8211;176.
RENARD, A., CALABRETTO, S. et RUMPLER, B. (2011). An evaluation model for systems and
resources employed in the correction of errors in textual documents. In MORVAN, F., TJOA, A. M.
et WAGNER, R. R., &#233;diteurs : 8th International Workshop on Text-based Information Retrieval in
conjunction with the 22nd International Conference DEXA 2011, pages 160&#8211;164, Toulouse, France.
IEEE Computer Society.
RUCH, P. (2002). Using contextual spelling correction to improve retrieval effectiveness in
degraded text collections. In 19th international conference on Computational linguistics-Volume 1,
volume 1, page 7. Association for Computational Linguistics.
SALTON, G. (1971). The SMART Retrieval System - Experiments in Automatic Document Processing.
Prentice Hall.
SAUVAGNAT, K. et BOUGHANEM, M. (2005). Using a Relevance Propagation Method for Adhoc and
Heterogeneous Tracks at INEX 2004. In FUHR, N., LALMAS, M., MALIK, S. et SZLAVIK, Z., &#233;diteurs :
Advances in XML Information Retrieval, volume 3493 de Lecture Notes in Computer Science, pages
499&#8211;532. Springer-Verlag.
SITBON, L., BELLOT, P. et BLACHE, P. (2007). Traitements phrastiques phon&#233;tiques pour la
r&#233;&#233;criture de phrases dysorthographi&#233;es. In 14&#232;me conf&#233;rence TALN, Toulouse, France.
SUBRAMANIAM, L. V., ROY, S., FARUQUIE, T. A. et NEGI, S. (2009). A Survey of Types of Text Noise
and Techniques to Handle Noisy Text. Language, pages 115&#8211;122.
VARNHAGEN, C. K., MCFALL, G. P., FIGUEREDO, L., TAKACH, B. S., DANIELS, J. et CUTHBERTSON, H.
(2009). Spelling and the Web. Journal of Applied Developmental Psychology, 30(4):454&#8211;462.
VOORHEES, E. M., GAROFOLO, J. et SPARCK JONES, K. (2000). TREC-6 Spoken Document Retrieval
Track. Bulletin of the American Society for Information Science and Technology, 26(5):18&#8211;19.
</p>
<p>526</p>

</div></div>
</body></html>