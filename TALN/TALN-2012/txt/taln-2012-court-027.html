<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Utilisation des fonctions de croyance pour l'estimation de param&#232;tres en traduction automatique</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 543&#8211;550,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Utilisation des fonctions de croyance pour l&#8217;estimation de
param&#232;tres en traduction automatique
</p>
<p>Christophe Servan Simon Petitrenaud
LIUM, Le Mans
christophe.servan@lium.univ-lemans.fr
</p>
<p>simon.petit-renaud@lium.univ-lemans.fr
</p>
<p>R&#201;SUM&#201;
Cet article concerne des travaux effectu&#233;s dans le cadre du 7&#232;me atelier de traduction automatique
statistique et du projet ANR COSMAT 1. Ces travaux se focalisent sur l&#8217;estimation de param&#232;tres
contenus dans une table de traduction. L&#8217;approche classique consiste &#224; estimer ces param&#232;tres &#224;
partir de fr&#233;quences relatives d&#8217;&#233;l&#233;ments de traduction. Dans notre approche, nous proposons
d&#8217;utiliser le concept de masses de croyance afin d&#8217;estimer ces param&#232;tres. La th&#233;orie des fonctions
de croyances est une th&#233;orie tr&#232;s adapt&#233;e &#224; la gestion des incertitudes dans de nombreux
domaines. Les exp&#233;riences bas&#233;es sur notre approche s&#8217;appliquent sur la traduction de la paire
de langue fran&#231;ais-anglais dans les deux sens de traduction.
</p>
<p>ABSTRACT
Feature calculation for Statistical Machine Translation by using belief functions
</p>
<p>In this paper, we consider the translation of texts within the framework of the 7th Workshop
of Machine Translation evaluation task and the COSMAT corpus using a statistical machine
translation approach. This work is focused on the translation features calculation of the phrase
contained in a phrase table. The classical way to estimate these features are based on the direct
computation counts or frequencies. In our approach, we propose to use the concept of belief
masses to estimate the phrase probabilities. The Belief Function theory has proven to be suitable
and adapted for the management of uncertainties in many domains. The experiments based on
our approach are focused on the language pair English-French.
</p>
<p>MOTS-CL&#201;S : Traduction automatique statistique, fonctions de croyance, apprentissage automa-
tique, estimation de param&#232;tres.
</p>
<p>KEYWORDS: Statistical machine Translation, belief function, machine learning, feature estima-
tion.
</p>
<p>1 Introduction
</p>
<p>Il est classique d&#8217;utiliser une table de traduction comme &#233;l&#233;ment d&#8217;un mod&#232;le de traduction
automatique statistique (TAS). Dans un syst&#232;me de traduction automatique fond&#233; sur des
segments (ou s&#233;quences de mots), une table de traduction contient les traductions alternatives et
ses probabilit&#233;s pour un segment en une langue source donn&#233;e. Chaque ligne ou &#233;v&#233;nement d&#8217;une
table de traduction comprend deux segments, l&#8217;un en langue source et l&#8217;autre en langue cible.
</p>
<p>1. http://www.cosmat.fr
</p>
<p>543</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>On suppose que les &#233;v&#233;nements sont ind&#233;pendants les uns des autres. Les tables de traduction
peuvent contenir beaucoup de param&#232;tres comme les probabilit&#233;s de traduction des segments ou
les probabilit&#233;s lexicales. Afin d&#8217;estimer ces param&#232;tres, les syst&#232;mes de TAS utilisent de grands
corpus appel&#233;s bitextes, qui sont compos&#233;s de phrases en langue source et en langue cible qui
sont la traduction l&#8217;une de l&#8217;autre. Pour chaque phrase, les mots des deux langues sont align&#233;s en
fonction de la traduction.
</p>
<p>Dans l&#8217;approche classique, l&#8217;estimation des probabilit&#233;s est faite par l&#8217;utilisation des fonctions de
compte simples, sur la base de fr&#233;quences relatives. Dans de nombreux travaux, la th&#233;orie des
fonctions de croyance (initialement th&#233;orie de Dempster-Shafer) permet une repr&#233;sentation &#224;
la fois plus souple et plus pr&#233;cise de diff&#233;rents types d&#8217;incertitude que les mod&#232;les probabilistes
(Smets, 1988; Cobb et Shenoy, 2006). Par exemple, les mod&#232;les probabilistes peuvent difficile-
ment prendre en compte le conflit entre deux hypoth&#232;ses diff&#233;rentes de traduction, en particulier
dans le cas des exemples rares. Il est &#233;galement d&#233;licat d&#8217;estimer le degr&#233; de confiance global
que l&#8217;on a sur l&#8217;ensemble des &#233;l&#233;ments de traduction pour une source donn&#233;e.
</p>
<p>La th&#233;orie des fonctions de croyance est capable de traiter ce genre de situations en fournissant
des degr&#233;s de conflit quand il y a des hypoth&#232;ses contradictoires, ainsi que des mesures de
confiance globale. Dans cet article, nous proposons une m&#233;thode originale pour estimer les
param&#232;tres associ&#233;s aux &#233;v&#233;nements constitu&#233;s de paires de segments &#224; l&#8217;aide des fonctions de
croyance.
</p>
<p>Cet article pr&#233;sente nos premiers travaux et leurs r&#233;sultats r&#233;alis&#233;s avec cette nouvelle approche.
Il est organis&#233; comme suit : tout d&#8217;abord, nous rappelons bri&#232;vement la th&#233;orie de la traduction
automatique statistique. Dans la section 3, nous d&#233;taillons notre approche bas&#233;e sur les fonctions
de croyance. Ensuite, nous pr&#233;sentons des exp&#233;riences sur diff&#233;rents corpus de traduction
fran&#231;ais-anglais. Enfin, nous concluons cet article et proposons quelques perspectives.
</p>
<p>2 Estimation de param&#232;tres en traduction automatique sta-
tistique
</p>
<p>Soit une phrase source s traduite en un certain nombre de phrases cibles t &#8712; Ts, o&#249; Ts est
l&#8217;ensemble de toutes les traductions observ&#233;es de s dans la table de traduction. Le mod&#232;le de
traduction automatique statistique (TAS) utilise un ensemble de n fonctions fi , i = 1 . . . , n, qui
d&#233;pendent des s&#233;quences de mots sources et cibles, afin de d&#233;terminer la meilleure traduction.
Les fonctions que l&#8217;on consid&#232;re habituellement comprennent le mod&#232;le de traduction, le mod&#232;le
de distorsion, le mod&#232;le de langage cible et diff&#233;rentes p&#233;nalit&#233;s. Parmi toutes les traductions
possibles, celle qui sera choisie maximise la probabilit&#233; a posteriori, et peut s&#8217;exprimer de la fa&#231;on
suivante :
</p>
<p>t&#8727; = arg max
t=1&#8712;Ts
</p>
<p>log
</p>
<p> 
n&#8719;
</p>
<p>i=1
</p>
<p>fi(t, s)
&#955;i
</p>
<p>!
, (1)
</p>
<p>o&#249; chaque param&#232;tre &#955;i est un coefficient de pond&#233;ration pour chaque fonction fi (Och, 2003).
Ces poids sont g&#233;n&#233;ralement optimis&#233;s de fa&#231;on &#224; maximiser la performance de traduction sur
</p>
<p>544</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>langue source (s) - fr langue cible (t) - en
. . . . . .
&#233;tant donn&#233; un given a
&#233;tant donn&#233; un starting from an
&#233;tant donn&#233; given
&#233;tant donn&#233; given
&#233;tant donn&#233; starting from
&#233;tant donn&#233; starting
&#233;tant starting
. . . . . .
</p>
<p>Tableau 1 &#8211; Exemple de paires de segments extraits d&#8217;un bitexte
</p>
<p>des ensembles de donn&#233;es de d&#233;veloppement. Le travail pr&#233;sent&#233; dans cet article se focalise sur
les caract&#233;ristiques utilis&#233;es pour estimer le mod&#232;le de traduction.
</p>
<p>Dans l&#8217;outil de traduction classique &#171; Moses &#187; (Koehn et al., 2007), la table de traduction contient
cinq caract&#233;ristiques (Koehn, 2010) : les param&#232;tres de traduction des segments, la pond&#233;ration
lexicale des traductions et la p&#233;nalit&#233; des segments. Les param&#232;tres de traduction des segments
sont estim&#233;s &#224; l&#8217;aide de la r&#232;gle de d&#233;cision de Bayes dans les deux sens de traduction. Les poids
lexicaux sont estim&#233;s &#224; partir du mod&#232;le IBM 1 bas&#233;s sur les mots de chaque paire de segment.
Enfin, la p&#233;nalit&#233; d&#8217;apparition du segment est d&#233;finie par l&#8217;utilisateur. Cette fonction permet de
privil&#233;gier les segments en fonction de leur longueur et prend une valeur constante &#961; pour tous
les segments. Si &#961; &gt; e, on pr&#233;f&#233;rera des segments longs aux segments courts. Inversement, si
&#961; &lt; e, les segments courts seront privil&#233;gi&#233;s. Une fois que ces param&#232;tres sont d&#233;finis, les poids
de l&#8217;ensemble de ces caract&#233;ristiques sont optimis&#233;s au cours du processus d&#8217;entra&#238;nement par le
taux d&#8217;erreur minimum (MERT) (Och, 2003).
</p>
<p>Dans cet article, nous nous concentrons sur l&#8217;estimation des param&#232;tres associ&#233;s aux segments de
traduction dans les deux sens de traduction, nous estimons les probabilit&#233;s lexicales de mani&#232;re
classique et, enfin, nous fixons la p&#233;nalit&#233; d&#8217;apparition &#961; &#224; la valeur e.
</p>
<p>Le tableau 1 donne un exemple de paires de segments extraits d&#8217;un bitexte. A partir de cet
exemple, nous obtenons la table de traduction pr&#233;sent&#233; dans le tableau 2 contenant l&#8217;estimation
des diff&#233;rentes probabilit&#233;s. Ainsi, la probabilit&#233; de traduction de &#171; starting &#187; sachant &#171; &#233;tant
donn&#233; &#187; est une simple fr&#233;quence conditionnelle &#233;gale &#224; 0,25 et la probabilit&#233; de &#171; given &#187; sachant
&#171; &#233;tant donn&#233; &#187; est &#233;gale &#224; 0,5. La probabilit&#233; conditionnelle inverse du segment de traduction
est estim&#233;e de la m&#234;me mani&#232;re.
</p>
<p>Cette fa&#231;on d&#8217;estimer les param&#232;tres a quelques inconv&#233;nients. Lorsque certaines paires de seg-
ments apparaissent plusieurs fois, comme la paire &#171; la maison blanche|the white house &#187;, et n&#8217;ont
pas d&#8217;occurrences concurrentes, l&#8217;estimation de la probabilit&#233; du segment est &#233;gale &#224; 1, mais dans
d&#8217;autres situations, des &#233;v&#233;nements peuvent survenir tr&#232;s rarement et &#234;tre ambigus. Par exemple,
supposons que pour le mot fran&#231;ais &#171; chien &#187; (qui devrait se traduire par &#171; dog &#187; en anglais),
</p>
<p>segment source (s) - fr segment cible (t) - en p(t|s) lex(t|s) p(s|t) lex(s|t) &#961;
. . . . . .
&#233;tant donn&#233; given 0,5 0,060147 0,333333 0,306373 2,718
&#233;tant donn&#233; starting 0,25 7,15882e-06 0,333333 5,19278e-05 2,718
&#233;tant donn&#233; starting from 0,25 7,15882e-06 0,333333 0,0277778 2,718
. . . . . .
</p>
<p>Tableau 2 &#8211; Exemple de table de traduction avec les diff&#233;rents param&#232;tres
</p>
<p>545</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>deux occurrences contradictoires soient disponibles dans la table de traduction : &#171; chien|cat &#187; et
&#171; chien|dog &#187;. Pour chacun de ces deux &#233;v&#233;nements, l&#8217;estimation de la probabilit&#233; peut &#234;tre
&#233;gale &#224; 1, car ils n&#8217;ont &#233;t&#233; observ&#233;s qu&#8217;une seule fois. Par exemple, dans le cadre de notre
exp&#233;rience sur le corpus COSMAT, il existe 13 480 cas correspondant &#224; 33 900 entr&#233;es sur les
363 324 que compte la table de traduction, soit un peu moins de 10%, dans le sens de traduction
fran&#231;ais-anglais.
</p>
<p>M&#234;me si l&#8217;estimation de la probabilit&#233; de la traduction des paires invers&#233;es &#171; cat|chien &#187; et
&#171; dog|chien &#187; peut &#233;quilibrer ce probl&#232;me, si l&#8217;&#233;v&#233;nement n&#8217;est observ&#233; qu&#8217;une seule fois dans
les deux sens de traduction, l&#8217;estimation des probabilit&#233;s conditionnelles invers&#233;es est inutile. Il
existe la possibilit&#233; de lisser les probabilit&#233;s de l&#8217;ensemble des &#233;v&#233;nements (Foster et al., 2006).
Cependant, les approches de lissage optent pour une redistribution des estimations afin de donner,
notamment, une probabilit&#233; non nulle aux &#233;v&#233;nements non observ&#233;s (Chen et Goodman, 1996;
Goodman, 2001). Notre but n&#8217;est pas celui-ci, mais plut&#244;t de proposer une approche diff&#233;rente
de l&#8217;estimation des param&#232;tres des &#233;v&#233;nements observ&#233;s.
</p>
<p>L&#8217;utilisation de th&#233;ories alternatives &#224; la th&#233;orie des probabilit&#233;s permet de mieux ajuster ces
estimations. L&#8217;une d&#8217;elles est particuli&#232;rement adapt&#233;e &#224; la gestion de diff&#233;rents types d&#8217;incer-
titudes : la th&#233;orie des fonctions de croyance, qui a &#233;t&#233; propos&#233;e puis d&#233;velopp&#233;e depuis une
trentaine d&#8217;ann&#233;es. Cette th&#233;orie a &#233;t&#233; appliqu&#233;e avec succ&#232;s &#224; de nombreux domaines tels que
l&#8217;identification du locuteur (Petitrenaud et al., 2010) ou la classification en g&#233;n&#233;ral (Elouedi et al.,
2000). Dans nos travaux, nous nous utilisons certains concepts fondamentaux de cette th&#233;orie
pour notre probl&#232;me d&#8217;estimation de param&#232;tres.
</p>
<p>3 Fonctions de croyances pour les syst&#232;mes de TAS
</p>
<p>Dans cette section, nous pr&#233;sentons bri&#232;vement quelques notions de la th&#233;orie des fonctions de
croyance (Shafer, 1976; Smets et Kennes, 1994) et nous l&#8217;appliquons au probl&#232;me d&#8217;estimation
de param&#232;tres de mod&#232;les de traduction. Dans cet article, nous adoptons le point de vue propos&#233;
par Smets : le mod&#232;le de croyances transf&#233;rables (MCT) (Smets et Kennes, 1994). L&#8217;objectif de ce
mod&#232;le est de d&#233;terminer la croyance concernant diff&#233;rentes propositions, &#224; partir d&#8217;informations
disponibles.
</p>
<p>Soit &#8486; un ensemble fini, appel&#233; cadre de discernement de l&#8217;exp&#233;rience. La repr&#233;sentation de
l&#8217;incertitude est faite par le biais de la notion de fonction de croyance, d&#233;finie comme une fonction
m de 2&#8486; sur [0,1] telle que
</p>
<p>&#8721;
A&#8838;&#8486;
</p>
<p>m(A) = 1. La quantit&#233; m(A) repr&#233;sente la croyance allou&#233;e &#224; la
</p>
<p>proposition A, et &#224; aucune proposition plus restrictive. Une des op&#233;rations les plus importantes
dans le MCT est la proc&#233;dure d&#8217;agr&#233;gation des informations, c&#8217;est-&#224;-dire la combinaison de
plusieurs fonctions de croyance d&#233;finies dans un m&#234;me cadre de discernement (Smets et Kennes,
1994). En particulier, la combinaison de deux fonctions de croyance m1 et m2 ind&#233;pendantes
d&#233;finies sur &#8486; est faite en utilisant l&#8217;op&#233;rateur binaire conjonctif &#8745;, tel que m&#8242; = m1 &#8745;m2 (Smets
et Kennes, 1994) :
</p>
<p>&#8704;A&#8838; &#8486;, m&#8242;(A) = &#8721;
B&#8745;C=A
</p>
<p>m1(B)m2(C) (2)
</p>
<p>546</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Cet op&#233;rateur est associatif et commutatif, il est alors possible de d&#233;finir la combinaison de n
fonctions m1, . . . , mn sur &#8486; par la fonction de croyance m = m1&#8745; . . .&#8745;mn. Cette derni&#232;re fonction
m capture l&#8217;information globale sur l&#8217;ensemble des exp&#233;riences connues.
</p>
<p>Ici, nous proposons d&#8217;utiliser le MCT pour estimer les param&#232;tres de traduction des segments.
Tout d&#8217;abord, pour une source s, chaque cible t i &#8712; Ts donne une information particuli&#232;re pour la
traduction qui peut &#234;tre d&#233;crite par une fonction de croyance mis, telle que :&#168;
</p>
<p>mis({t i}) = p(t i |s)
mis(Ts) = p(t i |s) , (3)
</p>
<p>o&#249; p(t i |s) = 1&#8722; p(t i |s). Si nous combinons les informations d&#233;finies par toutes les hypoth&#232;ses
disponibles dans la table concernant la traduction de s, &#224; partir de l&#8217;op&#233;rateur conjonctif d&#233;fini
dans l&#8217;&#233;quation 2, nous obtenons alors une fonction de croyance ms = &#8745;t&#8712;Ts mis. La masse de t i
est obtenue par la formule suivante :
</p>
<p>ms({t i}) = p(t i |s). &#8719;
tk&#8712;Ts\{t i}
</p>
<p>p(tk|s). (4)
</p>
<p>Notons que g&#233;n&#233;ralement
&#8721;
</p>
<p>t i&#8712;Ts ms({t i}) = 1&#8722;m(Ts)&#8722;m(;) &lt; 1. Les masses m(Ts) et m(;)
peuvent &#234;tre respectivement interpr&#233;t&#233;es comme le degr&#233; d&#8217;ignorance et le degr&#233; de conflit
d&#8217;informations concernant la traduction de s. M&#234;me si m(;) n&#8217;entre pas directement dans notre
mod&#232;le de traduction, quand il y a un conflit important entre plusieurs hypoth&#232;ses de traduction,
les masses de croyance sur chacun des singletons t i &#8712; Ts s&#8217;affaiblissent. Nous obtenons alors
une estimation de la fonction d&#233;finie dans l&#8217;&#233;quation 2 par : f (t i , s j) = ms j ({t i}). De la m&#234;me
mani&#232;re, l&#8217;estimation de la fonction inverse est obtenue par l&#8217;&#233;quation suivante :
</p>
<p>mIt({s j}) = p(s j |t).
&#8719;
</p>
<p>sk&#8712;St\{s j}
p(sk|t) , (5)
</p>
<p>o&#249; St est l&#8217;ensemble des sources possibles de la cible t. Si nous appliquons ces formules &#224;
l&#8217;exemple du tableau 1, une nouvelle estimation des param&#232;tres associ&#233;s aux diff&#233;rentes paires
de segments est calcul&#233;e dans le tableau 3.
</p>
<p>ms(starting) = p(starting|&#233;tant donn&#233;) &#183; p(given|&#233;tant donn&#233;) &#183; p(starting from|&#233;tant donn&#233;)
ms(starting) = 0, 09375
ms(starting from) = 0, 09375
ms(given) = 0,28125
ms(Ts) = 0,28125
ms(;) = 0, 25
</p>
<p>Tableau 3 &#8211; Exemple d&#8217;estimation de param&#232;tres de paires de segments &#224; l&#8217;aide du MCT (s =
&#171; &#233;tant donn&#233; &#187;)
</p>
<p>Notons que si p(t i |s) = 1, les masses de croyance pour les autres hypoth&#232;ses deviennent nulles
(cf. &#233;quation 4 ). La masse de croyance indiqu&#233;e dans cette &#233;quation peut alors &#234;tre modifi&#233;e de
</p>
<p>547</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>corpus AbsTrain AbsDev AbsTest nc7 eparl7 nwtst2010 nwtst2011
langue fr en fr en fr en fr en fr en fr en fr en
# de phrases 5141 1083 1102 137k 2M 2489 3003
# de mots 135K 120K 28K 25K 28K 25K 4M 3,4M 61,7M 55,7M 62k 70k 75k 84,5k
</p>
<p>Tableau 4 &#8211; Description des bitextes.
</p>
<p>fa&#231;on suivante :
</p>
<p>ms({t i}) = 1
1+ 1|s|
</p>
<p>, (6)
</p>
<p>o&#249; |s| d&#233;signe le nombre d&#8217;occurrences de s. Ainsi, ms({t i})&lt; 1 mais plus on a d&#8217;information sur
s, plus ms({t i}) tendra vers 1. Enfin, les phrases cibles choisies sont obtenues par le processus de
d&#233;cision d&#233;fini par l&#8217;&#233;quation 2.
</p>
<p>4 Exp&#233;riences
</p>
<p>nc7 eparl7-nc7
approche BLEU TER BLEU TER
</p>
<p>Sens de la traduction : fr 7&#8594;en
newstest2010 prob. 24,58 (0,13) 57,53 (0,03) 27,22 (0,05) 57,52 (0,10)
</p>
<p>MCT 24,56 (0,08) 57,66 (0,07) 27,10 (0,10) 57,74 (0,10)
newstest2011 prob. 25,92 (0,11) 54,48 (0,09) 29,52 (0,12) 55,08 (0,12)
</p>
<p>MCT 25,83 (0,17) 54,61 (0,08) 29,47 (0,14) 55,28 (0,13)
Sens de la traduction : en 7&#8594;fr
newstest2010 prob. 24,75 (0,06) 60,17 (0,26) 28,04 (0,07) 53,77 (0,14)
</p>
<p>MCT 24,74 (0,04) 60,07 (0,18) 28,00 (0,03) 53,76 (0,03)
newstest2011 prob. 26,84 (0,19) 57,75 (0,29) 28,60 (0,25) 52,85 (0,34)
</p>
<p>MCT 26,93 (0,09) 57,63 (0,17) 28,60 (0,04) 52,74 (0,04)
</p>
<p>Tableau 5 &#8211; R&#233;sultats obtenus suivant les m&#233;triques BLEU et TER avec deux syst&#232;mes entra&#238;n&#233;s
sur les corpus : News-Commentary 7 (nc7) ; Europarl 7 - News-Commentary 7 (eparl7-nc7).
</p>
<p>Afin de valider notre m&#233;thode, plusieurs exp&#233;riences ont &#233;t&#233; r&#233;alis&#233;es. Tout d&#8217;abord, nous avons
utilis&#233; le corpus COSMAT, qui est un ensemble de bitextes de r&#233;sum&#233;s de th&#232;ses de doctorat en
fran&#231;ais et en anglais. Puis, nos exp&#233;riences ont &#233;t&#233; plac&#233;es dans le contexte de l&#8217;&#233;valuation du
septi&#232;me atelier sur la traduction automatique statistique (WMT12).
</p>
<p>4.1 Le Corpus COSMAT
</p>
<p>Le projet ANR COSMAT est compos&#233; de nombreux r&#233;sum&#233;s de th&#232;se de doctorat en fran&#231;ais et
en anglais. Ces r&#233;sum&#233;s ont &#233;t&#233; class&#233;s en fonction de plusieurs th&#232;mes. Dans nos exp&#233;riences,
nous n&#8217;avons retenu que le domaine associ&#233; &#224; l&#8217;informatique. Les corpus d&#8217;apprentissage, de
d&#233;veloppement et de tests sont d&#233;crits dans le tableau 4.
</p>
<p>Sur le corpus de d&#233;veloppement, la perplexit&#233; des mod&#232;les de langage cible est de 122 pour
le fran&#231;ais et de 196 pour l&#8217;anglais. Les mod&#232;les sont adapt&#233;s &#224; la t&#226;che gr&#226;ce &#224; l&#8217;utilisation du
corpus d&#8217;entra&#238;nement (AbsTrain) et des mod&#232;les de langage.
</p>
<p>548</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sens de traduction fr 7&#8594;en en 7&#8594;fr
corpus approche BLEU TER BLEU TER
AbsDev prob. 34,78 (0,09) 48,24 (0,29) 32,28 (0,02) 52,82 (0,25)
</p>
<p>belief 34,85 (0,06) 48,25 (0,11) 32,28 (0,01) 52,40 (0,18)
AbsTest prob. 40,03 (0,44) 44,35 (0,12) 38,80 (0,19) 47,76 (0,36)
</p>
<p>belief 40,44 (0,10) 44,18 (0,12) 38,43 (0,12) 47,66 (0,10)
</p>
<p>Tableau 6 &#8211; R&#233;sultats obtenus avec le corpus COSMAT suivant les m&#233;triques BLEU et TER.
</p>
<p>4.2 Le corpus WMT12
</p>
<p>Le cadre utilis&#233; pour l&#8217;&#233;valuation de WMT12 contient plusieurs corpus. Ceux que nous avons
utilis&#233;s dans nos exp&#233;riences sont d&#233;crits dans le tableau 4. Les corpus d&#8217;apprentissage sont
Europarl 7 (eparl7) et News-Commentary 7 (nc7). Les mod&#232;les employ&#233;s quand la langue cible
est le fran&#231;ais et l&#8217;anglais ont respectivement une perplexit&#233; de 123 et de 169.
</p>
<p>4.3 R&#233;sultats
</p>
<p>Les tableaux 6 et 5 contiennent les r&#233;sultats obtenus avec l&#8217;approche classique et avec notre
approche bas&#233;e sur les fonctions de croyance. Les m&#233;triques utilis&#233;es sont le score BLEU (Papineni
et al., 2002) et la m&#233;trique TER (Snover et al., 2005). Afin de garantir une certaine robustesse
des r&#233;sultats, trois optimisations de MERT ont &#233;t&#233; faites. Le r&#233;sultat pr&#233;sent&#233; correspond &#224; une
moyenne de ces trois optimisations et la valeur indiqu&#233;e entre parenth&#232;ses est l&#8217;&#233;cart-type. La
p&#233;nalit&#233; de bri&#232;vet&#233; (ou de longueur de phrase) associ&#233;e au score BLEU est d&#8217;environ 0,99 (0,01)
pour les deux approches, dans les deux sens de traductions et pour chacune des exp&#233;riences.
</p>
<p>Les exp&#233;riences men&#233;es sur COSMAT et sur WMT12 montrent que notre nouvelle approche
semble avoir des r&#233;sultats similaires &#224; ceux de l&#8217;approche classique. Toutefois, le score BLEU a
tendance &#224; &#234;tre plus faible dans notre approche lorsque le sens de la traduction est de l&#8217;anglais
vers le fran&#231;ais dans l&#8217;exp&#233;rience avec le corpus WMT12 mais &#224; l&#8217;inverse, dans l&#8217;exp&#233;rience
COSMAT, notre nouvelle approche est l&#233;g&#232;rement moins performante dans le sens fran&#231;ais
vers anglais. Malgr&#233; ce constat, ces premiers r&#233;sultats sont encourageants et nous poussent &#224;
poursuivre dans cette direction.
</p>
<p>5 Conclusions et perspectives
</p>
<p>Cet article pr&#233;sente les premiers r&#233;sultats sur l&#8217;utilisation du Mod&#232;le des Croyances Transf&#233;-
rables (MCT) en traduction automatique statistique. Cette th&#233;orie a &#233;t&#233; utilis&#233;e pour estimer
diff&#233;remment les param&#232;tres des paires de segments de traduction. Les r&#233;sultats obtenus dans
la traduction fran&#231;ais-anglais, dans les deux directions, sur les corpus COSMAT et WMT12 sont
encourageants. Prochainement, nous pr&#233;voyons d&#8217;appliquer le MCT en traduction de mani&#232;re
plus approfondie. D&#8217;abord, nous allons &#233;tendre cette approche &#224; l&#8217;estimation des param&#232;tres de
pond&#233;ration lexicale. Nous allons &#233;galement orienter nos recherches vers une strat&#233;gie de prise
en compte de la proximit&#233; linguistique des diff&#233;rentes hypoth&#232;ses de traduction pour une phrase
donn&#233;e. Pour reprendre l&#8217;exemple du tableau 1, &#171; star t ing &#187; serait notamment plus proche de
&#171; star t ing f rom &#187; que de &#171; given &#187;. Le MCT permet d&#8217;int&#233;grer ce genre de situations avec une
certaine souplesse.
</p>
<p>549</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>6 Remerciements
</p>
<p>Ce travail a &#233;t&#233; financ&#233; par l&#8217;Agence Nationale de la Recherche dans le cadre du projet COSMAT
et par la Commission Europ&#233;enne &#224; travers le projet EUROMATRIXPLUS.
</p>
<p>R&#233;f&#233;rences
</p>
<p>CHEN, S. F. et GOODMAN, J. (1996). An empirical study of smoothing techniques for language
modeling. In JOSHI, A. et PALMER, M., &#233;diteurs : Proceedings of the Thirty-Fourth Annual Meeting
of the Association for Computational Linguistics, pages 310&#8211;318, San Francisco, Californie,
&#201;tats-Unis d&#8217;Am&#233;rique. Morgan Kaufmann Publishers.
</p>
<p>COBB, B. R. et SHENOY, P. P. (2006). A comparison of methods for transforming belief function
models to probability models. International Journal of Approximate Reasoning, 41(3):255&#8211;266.
</p>
<p>ELOUEDI, Z., MELLOULI, K. et SMETS, P. (2000). Classification with belief decision trees. In
Proceedings of the 9th International Conference on Artificial Intelligence : Methodology, Systems,
Architectures. AIMSA 2000, Springer Lecture Notes on Articial Intelligence.
</p>
<p>FOSTER, G., KUHN, R. et JOHNSON, H. (2006). Phrasetable smoothing for statistical machine
translation. In Proc. of the Conference on Empirical Methods in Natural Language Processing,
pages 53&#8211;61.
</p>
<p>GOODMAN, J. T. (2001). A bit of progress in language modeling. Computer Speech &amp;amp ;
Language, 15(4):403 &#8211; 434.
</p>
<p>KOEHN, P. (2010). Statistical MAchine Translation. Cambridge University Press.
</p>
<p>KOEHN, P., HOANG, H., BIRCH, A., CALLISON-BURCH, C., FEDERICO, M., BERTOLDI, N., COWAN, B.,
SHEN, W., MORAN, C., ZENS, R., DYER, C., BOJAR, O., CONSTANTIN, A. et HERBST, E. (2007). Moses :
Open source toolkit for statistical machine translation. In Proc. of the 45th Annual Meeting of the
Association for Computational Linguistics (Demo and Poster Sessions), pages 177&#8211;180, Prague,
Czech Republic. Association for Computational Linguistics.
</p>
<p>OCH, F. J. (2003). Minimum error rate training in statistical machine translation. In Proc. of the
41th Annual Meeting of the Association for Computational Linguistics, pages 160&#8211;167.
</p>
<p>PAPINENI, K., ROUKOS, S., WARD, T. et ZHU, W.-J. (2002). Bleu : a method for automatic evaluation
of machine translation. In Proc. of the 40th Annual Meeting of the Association for Computational
Linguistics, pages 311&#8211;318, Philadelphia, USA.
</p>
<p>PETITRENAUD, S., JOUSSE, V., MEIGNIER, S. et EST&#201;VE, Y. (2010). Automatic named identification
of speakers using belief functions. In Information Processing and Management of Uncertainty
(IPMU&#8217;10).
</p>
<p>SHAFER, G. (1976). A Mathematical Theory of Evidence. Princeton University Press.
</p>
<p>SMETS, P. (1988). Belief functions versus probability functions. pages 17&#8211;24.
</p>
<p>SMETS, P. et KENNES, R. (1994). The transferable belief model. Artificial Intelligence, 66:191&#8211;234.
</p>
<p>SNOVER, M., DORR, B., SCHWARTZ, R., MAKHOUL, J., MICCIULA, L. et WEISCHEDEL, R. (2005). A
study of translation error rate with targeted human annotation. Rapport technique LAMP-TR-
126,CS-TR-4755,UMIACS-TR-2005-58, University of Maryland, College Park and BBN Technolo-
gies.
</p>
<p>550</p>

</div></div>
</body></html>