Une méthode d’extraction d’information fondée sur les
graphes pour le remplissage de formulaires

Ludovic Jean-Louis Romaric Besangon Olivier Ferret
CEA, LIST, Laboratoire Vision et Ingénierie des Contenus
E91191 Gif—sur—Yvette, France

{ludovic ._'jean—louis,romaric .besancon, olivier . ferre1:}@cea. fr

RESUME
Dans les systémes d’extraction d’information sur des événements, une téche importante est le
remplissage automatique de formulaires regroupant les inforrnations sur un événement donné
‘a partir d’un texte non structuré. Ce remplissage de formulaire peut s’avérer difﬁcile lorsque
l’information est dispersée dans tout le texte et mélangée a des éléments d’information liés 21 un
autre événement similaire. Nous proposons dans cet ar11'cle une approche en deux étapes pour
ce probléme : d’abord une segmentation du texte en événements pour sélectionner les phrases
relatives au méme événement; puis une méthode de sélection dans les phrases sélectionnées
des entités liées ‘a l’événement. Une évaluation de cette approche sur un corpus annoté de
dépéches dans le domaine des événements sismiques montre un F-score de 72% pour la téiche de
remplissage de formulaires.

AB STRACT
A Graph-Based Method for Template Filling in Information Extraction

In event-based Information Extraction systems, a major task is the automated ﬁlling from unstruc-
tured texts of a template gathering information related to a particular event. Such template ﬁlling
may be a hard task when the information is scattered throughout the text and mixed with similar
pieces of information relative to a different event. We propose in this paper a two-step approach
for template ﬁlling : ﬁrst, an event-based segmentation is performed to select the parts of the text
related to the target event; then, a graph-based method is applied to choose the most relevant
entities in these parts for characterizing the event. Using an evaluation of this model based on an
annotated corpus for earthquake events, we achieve a 72% F-measure for the template-ﬁlling task.

MOTS-CLES : Extraction d’information, segmentation de texte, remplissage de formulaires.

KEYWORDS: Information Extraction, Text Segmentation, Template Filling.

1 Introduction

Le domaine de l’Extraction d’Information couvre toutes les téches consistant ‘a extraire des
informations structurées ‘a partir de textes. Une téche archétypique de ce domaine est celle
déﬁnie dans les conférences MUC (Message Understanding Conferences) (Grishman et Sundheim,
1996), o1‘1les systémes doivent permettre de remplir de fagon automatique des formulaires (ou

Actes de la conférence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 29-42,
Grenoble, 4 au 8 juin 2012. ©2012 ATAI.A 8: AFCP

29

templates) concernant des événements. Ces forrnulaires perrnettent de mettre en évidence une
information spéciﬁque a un type d’événement considéré et d’ignorer tout autre type d’information
non pertinente. Ia ﬁgure 1 donne un exemple du remplissage d’un formulaire 21 partir du texte
d’une dépéche de presse.

Texte Templates

E"1Un sélsme de magnitude 7,2 sur l'échelle de Richter a 1

frappé samedl la ville de Kurlhara (préfecture de - EVENEMENT : séisme,
Mlyagl). tremblement,
secousse
E"1Le tremblement s'est produit a OSH43, heure locale. ' DATE 2 Samedi

- HEURE I 08h43

E"1La secousse a été ressentie jusqu'a Tokyo, a 500 'MAGN|TUDE I 7.2
kilometres au sud des prefectures japonaises d'lwate et ' LIEU I Kufihafa

de Mlyagl, principales zones touchées.

EV2
Les sélsmes sont courants au Japan, qui est l'une des ' EVENEMENTISéiSmE
zones sismiques les plus actives de la planete. ' DATE 2 Octobre 2004
- HEURE I I

E"2En octobre 2004, un sélsme d'une magnitude de 6,8 ' MAGNITPDE 3 5.8
avait touché la région de Nllgata, dans le nord du pays. ' LIEU 3 Nllgala

FIG. 1 — Exemple de remplissage de formulaire

Les problémes soulevés par la réalisation d’un systéme d’extraction d’information pour le rem-
plissage de formulaire comptent en particulier l’identiﬁcau'on des entités nommées ou autres
entités spéciﬁques du domaine, l’établissement des relations entre ces entités, la résolution de la
coréférence concernant les entités, le regroupement d’informations dispersées dans le texte, etc.
(Turmo et al., 2006).

I1 n’existe pas actuellement d’approche considérée comme standard pour le remplissage de
formulaire. Néanmoins, la plupart des systémes d’extraction d’information adoptent une approche
en deux temps : des patrons spéciﬁques au domaine ou des classiﬁeurs sont d’abord utilisés pour
extraire au niveau phrastique les informations constitutives du formulaire considéré (dates, lieux,
magnitudes et heures dans le cas de la ﬁgure 1) en s’appuyant sur les mentions d’événements ;
des heuristiques relatives au type d’événement ou de texte considéré sont ensuite appliquées pour
fusionner les informations extraites dans des forrnulaires globaux. Méme si ce type d’approche
est largement utilisé, elle se heurte ‘a deux problémes importants : une vision trés locale de
l’extract1'on des informations élémentaires et une prise en compte limitée et peu générique des
dépendances entre ces informations, en particulier pour le remplissage des formulaires.

La ﬁgure 1 illustre clairement le fait que les informations relatives ‘a un événement, ici EV1,
peuvent étre exprimées au-dela de la portée de la phrase. Ce probléme pose plus généralement la
question de la délimitation des parties de texte relatives a un événement ou un type d’événements
donné car les informations d’un événement ne sont pas toujours liées a une mention d’événement
proche. Notre approche pour résoudre ce probléme s’appuie sur une segmentation discursive
des textes sur la base des événements auxquels chaque phrase fait référence. Plus largement,
son objectif est de diminuer l’espace textuel a explorer pour faire le lien entre une entité et une
mention d’événement et donc in fine, pour le remplissage du formulaire associé a un événement
donné. Les notions de temps et d’événement étant fortement liées, cette segmentation s’appuie

30

77,55 77,15
74,93 74,27 74,54

74,89 74,1 74,47
73,40 73,17
72,41 71,73 72,01

 

TAB. 3 — Evaluation du remplissage des formulaires a partir des stratégies de sélection

graphe obtiennent de meilleurs scores que les autres, indépendamment des poids sur les arcs. Ce
probleme pourrait étre, dans une certaine mesure, minimisé en adoptant la version pondérée
de l’algorithme PageRank proposée dans (Mihalcea, 2004). D’aut:re part, les scores du tableau 3
montrent que la meilleure stratégie de sélection est l’approche Hybride, ce qui est cohérent
avec ses objectifs de faire correspondre ‘a un r6le du formulaire la stratégie qui lui est la mieux
adaptée.

6.4 Impact de la segmentation en événements

Dans cette section, nous proposons d’évaluer l’impact de notre approche de segmentation en
événements sur la tache de remplissage des formulaires. Cette segmentation vise a identiﬁer les
passages pertinents aﬁn de focaliser le processus d’extraction. Cependant, tous les documents ne
mentionnent pas plusieurs événements sismiques et dans le cas des documents ne mentionnant
qu’un seul événement, l’usage de la segmentation événementielle se justifie moins (toutes les
phrases font a priori référence au méme événement si elle comporte une mention d’événement).
Celle-ci est des lors susceptible d’apporter essentiellement des perturbations dans la mesure o1‘1
ses résultats ne sont nécessairement pas parfaits.

Notre but, dans cette section, est donc de mesurer l’impact de la segmentation en événements
sur les documents ne faisant référence qu’a un seul événement en comparaison avec ceux faisant
référence a plusieurs événements. Notre intuition est que la segmentation devrait avoir un impact
limité sur les documents mono-événements et devrait améliorer les scores pour les documents
multi-événements. Aﬁn de vérifier cette hypothese, nous avons manuellement divisé le corpus
initial en deux ensembles en fonction du nombre d’événements sismiques mentionnés par les
textes. Nous avons ainsi obtenu 227 documents multi-événements (M) et 274 documents mono-
événements (5). Les résultats du remplissage de formulaires pour chaque ensemble, avec ou
sans segmentation, sont présentés dans le tableau 4 en termes de F1-mesure et agrégés pour
l’ensemble des réles du formulaire.

Concernant les documents mono-événements, les scores du tableau 4 montrent que les stratégies
les plus performantes n’utilisent pas de segmentation, bien que les différences ne soient pas
tres importantes (+0,71% en moyenne). A l’opposé, les stratégies a base de segmentation sont
plus performantes pour les documents multi-événements (+2,74% en moyenne). De plus, notre
stratégie la plus performante, approche Hybride avec segmentation, obtient de meilleurs scores
que notre approche de référence, Position sans segmentation, et ce, pour les deux ensembles
de documents. Plus généralement, les résultats démontrent que notre segmentation n’introduit
qu’une perte limitée pour les documents mono-événements et améliore les performances pour

39

Sans Avec
segmentation segmentation
stratégie S(%) M(%) S(%) M(%)
Hybride 79,20 73,61 78,34 75,61
Vote 77,67 68,68 76,89 71,81
Conﬁance 72,55 66,07 71,79 69,10
Position 73,96 73,16 73,07 73,10
PageRank 70,92 59,72 70,67 65,32

TAB. 4 — Impact de la segmentation sur les documents mono/multi-événements (F1-mesure)

les documents multi-événements.

6.5 Analyse des erreurs

Dans la perspective d’approfondir les évaluations de nos stratégies de remplissage de formulaire,
nous avons mené une analyse des erreurs en cherchant a identiﬁer précisément les causes de la
présence d’une entité incorrecte (sélecﬁon d’une mauvaise entité pour un role) ou d’une entité
manquante (pas d’entité sélectionnée pour un réle) dans un formulaire. Dans ce cadre nous
avons idenﬁﬁé trois types d’erreurs prépondérants :

— les erreurs de reconnaissance des entités nommées : l’entité n’est pas reconnue lors de l’analyse
linguistique du texte ;

— les erreurs de segmentation en événements : l’entité est identiﬁée lors de l’analyse linguistique
mais elle appartient a une phrase qui n’est pas associée a l’événement principal;

— les erreurs de sélection des entités : l’entité se trouve dans le segment de l’événement principal
mais une autre entité a été retenue comme valeur pour le role dans le formulaire;

Le tableau 5 présente la répartition de chaque type d’erreurs, en comparaison avec le nombre
d’entités correctement repérées, pour deux approches de construction des formulaires : la
premiere correspond a la selection a base d’heurisu'que, sans segmentation (NonSeg+Position) ;
la seconde s’appuie sur la segmentation en événements et la stratégie Seg+Hybride.

Type
Correct 71,6% 75,1%
25 21,2%

2,8% 2,8%
— 0,8%

 

TAB. 5 — Réparﬁtion des erreurs pour le remplissage de formulaires

Le graphe montre que la stratégie de référence Position permet d’identifier correctement une
part conséquente des entités (71,6%) mais qu’un nombre important d’erreurs d’attribution de
role dans le formulaire (25, 6%) subsiste. Notre meilleure stratégie réduit ce type d’erreur tout
en améliorant le pourcentage d’entités correctes dans les formulaires. De plus, cette stratégie
n’induit qu’un nombre trés limité d’erreurs dues a la segmentation en événements (0,8%).

7 Conclusion

La plupart des approches pour l’extraction d’information s’appuient sur des éléments au niveau
phrastique pour remplir automatiquement des formulaires et peu sur des informations au niveau
discursif. Dans cet article, nous avons présenté une approche pour le remplissage de formulaires
fondée sur une segmentation du texte et une sélection des entités s’appuyant sur un graphe
global de relations entre les entités. La segmentation du texte se fait au niveau discursif et utilise
des informations temporelles pour segmenter le texte selon les événements présents en utilisant
un modéle CRF aﬁn de trouver les phrases les plus pertinentes pour remplir un formulaire donné.
Ces phrases sont ensuite utilisées pour construire un graphe d’entités a partir duquel les entités
relatives a l’événement d’intérét sont sélectionnées. Nous avons proposé plusieurs stratégies pour
sélectionner les entités (utilisant la position des entités, les scores de conﬁance des relations ou
la structure du graphe, par l’utilisation de PageRank) ainsi que plusieurs facons de combiner ces
stratégies (vote majoritaire ou approche hybride).

Nous avons également présenté une évaluation détaillée de notre approche sur un corpus de
dépéches de presse concernant les événements sismiques. Cette évaluation a montré que notre
approche a permis d’améliorer le remplissage de formulaire par rapport a une heuristique simple
(mais efficace) consistant a prendre la premiere entité du type cherché pour remplir chaque
champ du formulaire. Les résultats ont aussi montré que notre approche est particuliérement
adaptée pour les documents mentionnant plusieurs événements de méme nature. Finalement,
une analyse des erreurs a montré que l’on peut encore améliorer ces résultats puisque la part
d’erreurs liée a la sélection des entités reste de 21%.

Concernant les perspectives de nos travaux, nous allons expérimenter la généralisation de notre
approche de remplissage de formulaires ‘a d’autres contextes, et plus précisément, d’autres
langues et d’autres domaines. Nous avons déj‘a obtenu des résultats prometteurs en testant la
segmentation événementielle sur un ensemble de dépéches de presse en anglais, dans le domaine
sismique, avec peu d’efforts d’adaptation nécessaires. En ce qui conceme la généralisation ‘a
d’autres domaines, nous planiﬁons des expérimentations dans le domaine ﬁnancier.

Références

AFZAL, N. (2009). Complex Relations Extraction. In Conference on Language & Technology 2009
(CLT’09), Lahore, Pakistan.

BESANCON, R., de CHALENDAR, G., FERRET, 0., GARA, F. et SEMMAR, N. (2010). LIMA : A Multilin-
gual Framework for Linguistic Analysis and Linguistic Resources Development and Evaluation.
In 7”‘ Conference on Language Resources and Evaluation (LREC 2010), Valletta, Malta.
CHAMBERS, N. et JURAFSKY, D. (2011). Template-Based Information Extraction without the
Templates. In 49"‘ Annual Meeting of the Association for Computational Linguistics : Human
Language Technologies, pages 976-986, Portland, Oregon, USA.

DODDINGTON, G., MITCHELL, A., PRZYBOCKI, M., RAMSHAW, L., STRASSEL, S. et WEISCHEDEL, R.
(2004). The Automatic Content Extraction (ACE) Program — Tasks, Data, and Evaluation. In 4”‘
Conference on Language Resources and Evaluation (LREC 2004), pages 837-840, Lisbon, Portugal.
FENG, D., BURNS, G. et Hovv, E. (2007). Extracting Data Records from Unstructured Biomedical
Full Text. In EMNLP-CoNLL’07, pages 837-846, Prague, Czech Republic.

41

GOERTZEL, B., PINTO, H., HELJAKKA, A., Ross, M., PENNACHIN, C. et GOERTZEL, I. (2006). Using
Dependency Parsing and Probabilistic Inference to Extract Relationships between Genes, Proteins
and Malignancies Implicit Among Multiple Biomedical Research Abstracts. In HLT-NAACL BioNLP
Workshop on Linking Natural Language and Biology, pages 104-111, New York, USA.

GRISHMAN, R. et SUNDHEIM, B. (1996). Message Understanding Conference-6 : A Brief History.
In 16”‘ International Conference on Computational linguistics (COLING’96), pages 466471,
Copenhagen, Denmark.

GU, Z. et CERcoNE, N. (2006). Segment-based hidden Markov models for information extraction.
In 215‘ International Conference on Computational Linguistics and 44”‘ Annual Meeting of the
Association for Computational Linguistics, pages 481488, Sydney, Australia.

JEAN-LoU1s, L., BESANCON, R. et FERRET, O. (2010). Using temporal cues for segmenting texts
into events. In 7”‘ International Conference on Natural Language Processing (IceTAL 2010), pages
150-161. Springer Berlin / Heidelberg.

JEAN-LoU1s, L., BEsANgoN, R. et FERRET, O. (2011). Text segmentation and graph-based method
for template ﬁlling in information extraction. In 5 ‘h International Joint Conference on Natural
Language Processing (UCNLP 201 1), pages 723-731, Chiang Mai, Thailand.

J1, H., GR1sHMAN, R. et TRANG DANG, H. (2010). Overview of the TAC 2010 Knowledge Base
Population Track. In Third Text Analysis Conference (TAC 2010), Gaithersburg, Maryland, USA.

LAFFERTY, J. D., MCCALLUM, A. et PEREIRA, F C. N. (2001). Conditional Random Fields :
Probabilistic Models for Segmenting and Labeling Sequence Data. In Eighteenth International
Conference on Machine Learning (ICML’01), pages 282-289, San Francisco, CA, USA.

LIU, Y., SHI, Z. et SARKAR, A. (2007). Exploiting Rich Syntactic Information for Relationship
Extraction from Biomedical Articles. In NAACL-HLT’07, short paper session, pages 97-100,
Rochester, New York.

MANsUR1, I. R. et SARAWAGI, S. (2006). Integrating unstructured data into relational databases.
In 22"d International Conference on Data Engineering (ICDE’06), pages 29-40, Washington, USA.
McDoNALD, R., PEREIRA, E, KULICK, S., WINTERS, S., JIN, Y. et WHITE, P. (2005). Simple algorithms
for complex relation extraction with applications to biomedical IE. In ACL 2005, pages 491498,
Ann Arbor, Michigan, USA.

MIHALCEA, R. (2004). Graph-based Ran.king Algorithms for Sentence Extraction, Applied to Text
Summarization. In 425‘ Annual Meeting of the Association for Computational Linguistics (ACL
2004), Barcelona, Spain.

NAUGHTON, M. (2007). Exploiting Structure for Event Discovery Using the MDI Algorithm. In
45 ‘h Annual Meeting of the Association for Computational Linguistics (ACL 2007), Pages 31-36,
Prague, Czech Republic.

PATWARDHAN, S. et RILOFF, E. (2007). Effective Information Extraction with Semantic Affinity
Patterns and Relevant Regions. In EMNLP-CoNLE07, pages 717-727, Prague, Czech Republic.

STEvENsoN, M. (2006). Fact distribution in Information Extraction. Language Resources and
Evaluation, 40(2): 183-201.

TURMo, J ., AGENO, A. et CATALA, N. (2006). Adaptive information extraction. ACM Computer
Surveys, 38(2):147.

WICK, M., CULOTTA, A. et MCCALLUM, A. (2006). Learning Field Compatibilities to Extract
Database Records from Unstructured Text. In EMNLP’06, pages 603-611, Sydney, Australia.

42

sur des indices de nature temporelle.

Le second probléme évoqué ci-dessus a déj‘a fait l’objet de quelques travaux assimilant les
formulaires a des relations complexes. Dans ce contexte, chaque événement est vu comme
une relation n-aire dont l’arité est égale au nombre de champs ‘a remplir dans le formulaire
(n=5 dans l’exemple précédent). Cette vision a d’abord été appliquée au niveau local pour des
phrases contenant plusieurs entités d’intérét pour le méme événement (la premiere phrase de la
ﬁgure 1 en contient par exemple quatre) : dans (McDonald et al., 2005), les relations entre la
mention de cet événement et les informations qui lui sont liées ne sont ainsi plus considérées
indépendamment les unes des autres mais de facon plus globale. Au-dela, plusieurs méthodes ont
été proposées pour extraire des relations complexes, parmi lesquelles se distinguent des méthodes
a base de graphe (McDonald et al., 2005; Wick et al., 2006) et des méthodes a base d’inférences
(Goertzel et al., 2006). Dans cet article, nous présentons une méthode ‘a base de graphe, en
commencant par construire un graphe d’entités fondé sur le résultat de la segmentation et
en utilisant plusieurs stratégies génériques (i.e. indépendantes du domaine considéré) pour la
construction de la relation complexe a partir de ce graphe.

2 Motivation et état de l’art

Le remplissage de formulaire est une tache centrale des systémes d’extraction d’information et a
fait l’objet en tant que telle de nombreuses études. Ainsi, dans le contexte des campagnes d’éva-
luation MUC (Message Understanding Conferences) et ACE (Automatic Content Extraction) (Dod-
dington et aL, 2004), un des objectifs des systémes participants était de remplir automatiquement
des formulaires prédéﬁnis avec une structure ﬁxe. Bien que ce soit l’approche la plus répandue,
d’autres travaux, comme (Chambers et Jurafsky, 2011), adoptent un point de vue différent et
proposent une approche non supervisée pour remplir des formulaires sans connaissance a priori
sur leur structure. Ils exploitent dans ce cas des techniques de regroupement (clustering) pour
apprendre la structure des formulaires et des patrons syntaxiques pour en remplir les champs.

Une grande partie des systémes d’extraction d’information, en particulier ceux fondés sur des
approches a base d’apprentissage automatique, s’appuient sur l’idée qu’un événement est souvent
décrit dans une seule phrase, ce qui conduit ‘a donner une importance moindre ‘a l’information
inter-phrastique. Cette idée est nommée << hypothése de la phrase seule >> (single sentence
assumption) par (Stevenson, 2006), qui rapporte que seulement 60% des faits mentionnés dans
les corpus MUC (MUC 4-6-7) peuvent étre identifiés avec cette hypothése. Ce pourcentage a
été conﬁrmé plus récemment par (Ji et aL, 2010), montrant qu’environ 40% des relations entre
entités nécessitent l’usage de techniques d’inférences inter-phrastiques pour les extraire.

Peu d’approches ont été proposées pour faire de l’extraction d’informau'on a un niveau discursif
sans lien étroit avec le domaine abordé. Parmi elles, (Gu et Cercone, 2006) et (Patwardhan et
Riloff, 2007) sont les plus proches de l’approche présentée ici. (Gu et Cercone, 2006) déﬁnit une
approche ‘a base de modéles de Markov cachés, d’une part pour identifier les unités de textes
(phrases) pertinentes pour le remplissage de formulaire, et d’autre part pour faire l’extraction
des entités dans les phrases retenues. De fagon similaire, (Patwardhan et Riloff, 2007) propose
tout d’abord d’identifier les phrases pertinentes en utilisant un modéle SVM (Support Vector
Machine), puis d’appliquer différents niveaux de patrons d’extraction pour remplir les champs du
formulaire.

31

Une des premieres approches pour l’extraction de relations n-aires vient du domaine biomédical
(McDonald et aL, 2005) et a ensuite été appliquée dans le domaine des mouvements de personnel
dans les entreprises (Afzal, 2009). D’autIes travaux s’attaquent au probleme des relations
complexes dans le contexte de l’extraction de champs pour les bases de données (database record
extraction), en s’intéressant plus particulierement a la compatibilité d’un ensemble d’entités
données plut6t que d’une paire d’entités, ce qui les amene ‘a prendre en compte des relations
inter-phrastiques entre entités (Wick et aL, 2006; Mansuri et Sarawagi, 2006; Feng et al., 2007).

3 Description de l’approche

Le cadre applicatif de la méthode d’extraction d’événements présentée dans cet article se situe
dans un contexte de veille, dans lequel les utilisateurs ne sont en général intéressés que par les
événements les plus récents. Dans ce contexte, notre but est de synthétiser, a partir de dépéches
de presse, les informations relatives aux événements récents dans un tableau de bord. Néanmoins,
les articles font en général référence a plusieurs événements comparables, en général pour mettre
en évidence les similarités ou les différences entre l’événement récent et des événements passés
de méme nature. Dans notre application spéciﬁque de veille, nous ne nous intéressons pas aux
événements passés, que nous considérons comme une source de bruit pour la détection des
informations relatives ‘a l’événement principal de l’article. Nous avons donc fait l’hypothese,
comme (Feng et al., 2007), qu’un document est associé a un seul formulaire. Nous utilisons une
stratégie en deux étapes pour extraire cette information (Jean-I.ouis et al., 2011) :

— une segmentation du texte en événements : les informations relatives aux événements peuvent
se trouver sur plusieurs phrases. Par conséquent, nous devons découper le texte en segments
homogénes du point de vue événementiel. Ces segments regroupent fréquemment des phrases
non-contigués car la structure des articles fait souvent des aller-retours entre l’événement
principal et un ou plusieurs événements passés;

— le remplissage des formulaires : puisque les segments événementiels couvrent plus d’une phrase,
la probabilité d’y trouver des relations complexes (impliquant un grand nombre d’entités) est
plus forte que dans une seule phrase. Nous devons donc trouver dans ces segments quelles
entités sont susceptibles d’étre impliquées dans des relations complexes.

4 Segmentation événementielle des textes

L’idée de segmenter des textes en unités homogénes du point de vue événementiel a principa-
lement été abordée selon deux angles : de facon assez liée ‘a un domaine particulier dans des
travaux comme (Gu et Cercone, 2006; Patwardhan et Riloff, 2007), avec des méthodes reposant
sur des modeles tres lexicalisés; a l’inverse, en ne s’appuyant que sur la logique d’enchainement
des types d’événements dans (Naughton, 2007). Notre approche est intermédiaire : en exploitant
des informations de nature temporelle, elle fait appel a des caractéristiques des textes dépassant
leur simple appartenance a un domaine donné.

Du point de vue du processus de segmentation, un texte est vu comme une séquence de phrases,
chaque phrase étant caractérisée par un statut événementiel. Comme dans la plupart des travaux
similaires, nous faisons l’hypothese, en pratique raisonnablement simpliﬁcatrice, qu’une phrase

32

possede un statut événementiel homogene. Nous distinguons plus précisément trois statuts.
ﬁvénement principal : référence ‘a l’événement principal du texte; ﬁvénement secondaire :
référence a un événement secondaire du texte, sans distinction de l’événement particulier s’il en
existe plusieurs; Contexte : sans référence a un événement.

Dans cette perspective, nous considérons la segmentation événementielle comme une tache de
classiﬁcation visant ‘a associer ‘a chaque phrase d’un texte un statut événementiel. Néanmoins,
une telle segmentation possede un caractere intrinsequement discursif dans la mesure o1‘1 les
catégories événementielles ne s’enchainent pas de maniere arbitraire. Du point de vue de la
classiﬁcation des phrases, elles sont donc déterminées ‘a la fois par les indices repérables au
niveau phrastique mais également par les catégories et les indices des phrases précédentes. Notre
approche se focalise ainsi sur la capture des relations entre les changements événementiels et les
changements de cadre temporel, manifestées par exemple par le passage du passé composé vers
plus-que-parfait accompagnant la transition de l’événement principal a un événement secondaire
dans le texte de la ﬁgure 2.

Pour la classiﬁcation des phrases, nous avons donc utilisé un modéle de séquences, en l’occurrence
de type CRF linéaire (Champs Conditionnels Aléatoires (Lafferty et al., 2001)), s’appuyant sur les
traits de nature temporelle suivants. Temps des verbes : un trait binaire est associé a chaque temps
possible et activé des que la phrase contient au moins un verbe du temps correspondant; date :
la présence d’une date est souvent le signe de la présence d’un événement différent de celui
de la phrase précédente; expression temporelle : ce trait marque la présence d’une expression
temporelle, telle que ces derniéres années, au début de l’année, souvent associée au caractere
général d’un propos. Par ailleurs, les dépendances de succession entre les différents statuts
événementiels sont prises en compte par le caractere linéaire de notre modele CRE Ce modele
est plus amplement détaillé dans (Jean-Louis et al., 2010).

5 Remplissage de formulaires événementiels

Pour le remplissage des formulaires liés aux événements, nous proposons une approche a base de
graphe inspirée du paradigme de l’extraction de relations complexes. Sa premiere étape, dite de
construction du graphe, détecte d’abord les relations existant entre des paires de mentions d’entités
ou d’événements du domaine considéré cooccurrant dans une phrase. Il construit ensuite un
graphe d’entités sur la base de la fusion des mentions d’événements et d’entités faisant référence
a un méme événement ou a une méme entité. Sa seconde étape, dite de remplissage duformulaire,
applique des stratégies génériques ‘a ce graphe pour sélectionner les entités les plus a méme
de remplir le formulaire correspondant au type d’événement considéré. Ces deux étapes sont
détaillées dans les deux sections suivantes.

5.1 Construction du graphe d’entités

Le graphe d’entités que nous construisons dans cette premiere étape caractérise ‘a l’échelle du
document la présence ou l’absence d’une relation entre chaque paire d’entités liées au type
d’événements considéré (par exemple, la relation de localisation d’un événement sismique
dans notre cas). Il s’agit d’un graphe pondéré dont les noeuds représentent des entités ou des
événements et les arcs, les relations qui les unissent. Ces relations étant symétriques, ce graphe

33

est non dirigé. Le poids associé a chaque arc est un score de conﬁance prenant ses valeurs dans
l’intervalle [0,1] et évaluant le degré de certitude de la présence d’une relation entre les deux
entités liées. La ﬁgure 2 donne l’exemple d’un tel graphe restreint aux entités liées a l’événement
principal du document, compte tenu de notre focalisation applicative.

Texte Graphe d’entités
iPR'"°'PAL1Un séisme de magnitude 7,2 sur l‘échelle de Richter {T
a frappé samedi la ville de Kurihara (pléfecture de 7:2

Miyagi).

{PR'”°"”A"}Le tmmblement s‘est produit a 08H43, heure locale.
{PR'”°"”A"}La secoue a été ressentie jusqu‘a Tokyo, 5 500
kilometres au sud des préfectures japonaises d‘Iwate et de tr-emblemem

Miyagi, prindpales zones touchées. semusse

{°°"‘TEXTE}Les séisma sont Lourants au Japan, qui est l'une des
zones sismiques les plus actives de la planéte.

 

{5E°°"‘°A'RE}En octnbm 2004, un séisme d’une magnitude de Tnkyn _ f Iwate
6,8 avait touché la région de Niigata, dans le nord du pays. Mlyagi

WI: poids de relation

FIG. 2 — Exemple de graphe d’entités

La construction du graphe d’entités d’un texte commence en déterminant si les couples de
mentions d’entités ou d’événements apparaissant dans une méme phrase sont sous-tendus par
une relation propre au type d’événement cible, sans néanmoins préciser cette relation. A l’instar
des travaux existants comparables, nous avons réalisé cette détermination par le biais d’un
classiﬁeur statistique. Dans ce cadre, l’utilisation d’un ensemble de traits lexicalisés constitue
l’approche dominante (Afzal, 2009; Gu et Cercone, 2006; Wick et aL, 2006), méme si (Liu et al.,
2007) se démarque en conjuguant ces traits lexicalisés avec des traits de nature syntaxique.
A l’inverse, nous avons construit un modele n’intégrant que des traits syntaxiques et faisant
abstraction des informations lexicales (mots sous forme ﬂéchie ou lemmes) aﬁn de lui conférer
un degré de généralité plus important susceptible de rendre son adaptation a un autre domaine
plus facile. Pour évaluer l’intérét relatif des traits syntaxiques et lexicaux, nous avons entrainé
différents types de classiﬁeurs avec les trois ensembles de traits détaillés dans le tableau 1.

— LEXI-BASE : méme ensemble de traits lexicalisés que (Afzal, 2009) ;
— LEXI-SYN : ensemble de traits conjuguant traits lexicalisés et traits syntaxiques, dans le
prolongement de (Liu et al., 2007)1 ;
— NON-LEXI-SYN : méme ensemble de traits que LEXI-SYN, a l’exception des traits lexicalisés.

Comme dans (McDonald et al., 2005) et (Liu et al., 2007), le poids associé ‘a chaque relation
trouvée est le score de conﬁance du classiﬁeur l’ayant mise en évidence, ce score étant compris
dans l’intervalle [0,1] pour tous les classiﬁeurs expérimentés a la section 6.2.

La seconde étape de construction du graphe d’entités est une forme de condensation résultant de
la fusion des mentions d’entités et d’événements identiﬁées comme faisant référence a une méme

1Nous n’uti1isons pas exactement les mémes traits que (Liu et aL, 2007) car certains d’em1'e eux ne sont applicables
que dans le domaine biomédical.

34

LIZXI-EASE LIZXI-SYN NON-LEXI-SYN
E1 ; E2
E1 ; cat.
E1 ; mots E2
mots E1; mots E2
entre E1 et E2
mots entre E1 et E2
situées entre E1 et E2
mots entre E1 et E2
entre E1 et E2
entre E1 et E2
entre E1 et E2
+
entre E1 et E2
entre E1 et E2

mots E1
mots E2

 

1 Si E1, respectivement E2, est une mention d’événement, associe la position de E2, respectivement E1, par
rapport £1 elle (avant ou aprés) et sa catégorie morpho-syntaxique.

TAB. 1 — Traits utilisés pour la classiﬁcation de relations binaires

entité ou a un méme événement. Pour les événements, cette fusion s’appuie sur la segmentation
événementielle : toutes les mentions d’événements apparaissant dans un segment étiqueté
PRINCIPAL sont supposées faire référence ‘a l’événement principal du document et sont donc
fusionnées (cf. fusion de secousse, séisme et tremblement au niveau de la ﬁgure 2). Pour les entités,
la fusion se fait sur l’égalité de leur forme normalisée dans le cas des dates, heures et magnitudes
et sur l’égalité de la forme trouvée dans les textes pour les lieux. Lorsque l’opérau'on de fusion
entraine la présence de plusieurs relations entre deux entités ou entre une entité et l’événement
principal, ces relations sont elles-mémes fusionnées en conservant le poids le plus élevé.

5.2 Remplissage du formulaire

L’étape de remplissage du formulaire a pour objectif de choisir pour chaque r6le de ce formulaire
l’entité du graphe construit 21 l’étape précédente ayant un type compatible avec le type d’enu'té
attendu pour ce role et se montrant la plus a méme de le remplir. Cette sélection s’accompagne
implicitement du choix de ne pas remplir certains roles du formulaire lorsque les informations
correspondantes sont absentes du texte. Ce probléme de remplissage de formulaire peut étre
assimilé au probléme de la reconstruction d’une relation complexe tel qu’il est envisagé dans
(Afzal, 2009; McDonald et al., 2005). Par exemple, le graphe de la ﬁgure 2 comporte une
ambiguité relative a l’entité occupant le réle de lieu de l’événement et impose un choix entre :
Kurihara, Tokyo, Miyagi ou Iwate. Dans cette perspective, nous avons testé plusieurs approches :

Position est une heuristique simple mais trés efﬁcace dans le contexte considéré qui sélectionne

pour chaque type d’entités la premiere mention apparaissant dans un segment relatif ‘a
l’événement principal.

35

Conﬁance retient pour chaque type d’entités l’entité liée a l’événement avec le score de conﬁance
(score du classiﬁeur utilisé) le plus grand.

PageRank est une approche exploitant la structure globale du graphe d’entités par le biais de
l’algorithme PageRank. Ce dernier permet en l’occurrence d’attribuer un score d’importance
a chaque entité en fonction de sa connectivité avec les autres entités et donc de les ordonner.
Pour chaque type d’entités, est ainsi retenue l’entité ayant le plus haut score PageRank.

Vote implémente une stratégie de vote majoritaire reposant sur les approches Position, Conﬁance
et PageRank. Pour chaque type d’entités, l’entité ayant été sélectionnée par le plus grand
nombre d’approches est ainsi adoptée.

Hybride applique pour chaque type d’entités celle, parmi les stratégies précédentes, donnant le
meilleur résultat pour ce type d’entités.

La sortie des approches Conﬁance, PageRank, Vote et Hybride est en outre complétée par l’approche
Position dans le cas ou aucune entité n’est sélectionnée pour un type donné. Il est en effet possible
que certaines entités d’un formulaire apparaissent dans un texte sans étre associées dans une
phrase ‘a une mention d’entité ou d’événement, ce qui interdit leur choix par les approches
reposant sur le graphe d’entités.

6 Evaluation

Nous présentons dans cette section une évaluation de notre approche de remplissage de formu-
lairessur un corpus de dépéches de presse concernant les événements sismiques, corpus décrit a
la section 6.1. Une évaluation différenciée de chaque étape de notre approche a été menée : les
résultats de l’évaluation de la segmentation événementielle de textes sont présentés en détail
dans (Jean-Louis et al., 2010) et ont montré que le modéle de segmentation par CRF atteint
un F-score de 92,71% pour la détection de l’événement principal, ce qui constitue une bonne
base pour l’application des étapes suivantes de notre approche. Les sections 6.2 et 6.3 présentent
respectivement l’évaluation de la construction du graphe d’entités et de la sélection des entités.
Une évaluation plus ciblée de l’impact de la segmentation en événements sur le résultat ﬁnal est
présentée a la section 6.4 et une analyse des principales erreurs rencontrées et de leur répartition
est présentée dans la section 6.5.

6.1 Corpus

Les travaux présentés dans cet article ont été développés dans le cadre d’une application dédiée
a la surveillance des événements sismiques ‘a partir de dépéches de presse. Dans ce cadre, un
formulaire est associé ‘a un événement sismique et résume ses principales caractéristiques ‘a
savoir, la date, l’heure, le lieu, la magnitude, les coordonnées géographiques ainsi que la mention
d’événement qui lui est associée (séisme, réplique, etc.)2. La figure 1 donne deux exemples
illustratifs du formulaire que nous considérons. Notons que dans l’application visée, nous ne
cherchons ‘a extraire que les événements principaux et ne sommes donc pas intéressés par
l’événement secondaire EV2 de cette dépéche.

2Les dommages liés aux séismes n’ont pas été considérés car leur expression est plus variée et leur identiﬁcation
nécessiterait une analyse linguistique plus profonde.

36

[POSITIVE] : Cette secousse, d’une magnitude de 6,4 sur l’échelle de Richter, est la plus forte
enregistrée depuis le tremblement de terre d’une magnitude de 8 qui a ravagé le Sichuan, a
précisé un responsable du bureau de sismologie de cette province.

[NEGATIVE] : Cette secousse, d’une magnitude de 6,4 sur l’échelle de Richter, est la plus forte
enregistrée depuis le tremblement de terre d’une magnitude de § qui a ravagé le Sichuan, a
précisé un responsable du bureau de sismologie de cette province.

FIG. 3 — Exemples positif et négatif de présence d’une relation entre deux entités

L’ensemble des expériences ont été effectuées ‘a partir d’un corpus composé de 501 dépéches
de presse en francais concernant le domaine sismique. Ces dépéches ont été collectées entre ﬁn
février 2008 et début septembre 2008, en provenance pour partie d’un ﬂux de dépéches AFP
(1/3 du corpus), et pour partie de dépéches collectées sur Google Actualités (2/3 du corpus). Le
corpus a été manuellement annoté par des analystes du domaine qui ont rempli manuellement les
formulaires pour chaque séisme principal d’un document. Au total, les annotateurs ont idenﬁﬁé
2 775 entités, réparties en 6 types d’entités : mention d’événement (18%), lieux (34%), date
(17%), heure (12%), magnitude (17%) et coordonnées géographiques (1%)3.

Concernant l’analyse linguistique des documents, nous avons appliqué la chaine de traitements
linguistiques de l’analyseur LIMA (Besancon et al., 2010) réalisant les étapes de tokenisation,
détection des ﬁns de phrases, désambiguisaﬁon morpho-syntaxique, reconnaissance des temps
des verbes, reconnaissance des entités nommées et analyse syntaxique.

6.2 Construction du graphe d’entités

La méthode proposée pour la construction du graphe d’entités s’appuie sur un classiﬁeur pour
déterminer la présence/ absence d’une relation entre deux entités au sein d’une méme phrase.
Nous avons expérimenté différents types de classiﬁeurs statistiques, utilisant chacun les trois
ensembles de traits présentés ‘a la section 5.1 (LEXI-BASE, LEXI-SYN, NON-LEXI-SYN). Pour
l’annotation des relations binaires entre entités, nous avons considéré un sous-ensemble du
corpus composé de 44 dépéches. Sur ce sous-ensemble, nous avons obtenu 5 000 relations
binaires, parmi lesquelles 969 relations sont exprimées ‘a l’intérieur de la méme phrase. Parmi
celles-ci, 43 relations ont été écartées ‘a cause d’erreurs de reconnaissance des entités (par
exemple, lorsqu’une entité considérée est en fait incluse dans une entité plus large non reconnue
‘a cause de son type). Les autres relations ont servi pour l’entrainement des classiﬁeurs : 690
pour la catégorie POSITIVE, dans laquelle les deux entités font référence au méme événement
sismique et 236 pour la catégorie NEGA'I'IVE, dans laquelle les deux entités sont associées a des
événements sismiques différents. Ia ﬁgure 3 illustre des relations pour les deux catégories.

Ce corpus annoté nous a servi a tester trois types de c1assiﬁeurs4 : Bayésien Na'if (NB), Maximum
d’Entropie (ME) et Arbres de décision (D'I'). Nous reportons dans le tableau 2 les résultats

3La possibilité a été laissée aux annotateurs de retenir plus d’une entité pour le méme role lorsque plusieurs variantes
étaient mentionnées et étaient jugées également pertinentes. Par exemple, pour les lieux, pouvaient étre annotés A la fois
un nom de ville et un nom de pays.

‘Nous avons uti1isé1’irnp1émenta11'on fournie par 1’ou11'1 MALLET (h1:1:p:/ /mallet . cs .umass . edu).

37

obtenus par chaque algorithme, en fonction de l’ensemble de traits utilisé en termes de rappel
(R), précision (P) et F1-mesure (F). Les résultats sont obtenus par une validation croisée (4/5
des données servent ‘a l’entrainement et 1/5 pour le test). En complément, nous foumissons
pour comparaison les résultats d’une approche basique (Baseline) qui attribue la catégorie la plus
fréquente (POSI'I'IVE) a toutes les relations.

Ensemble de traits Classiﬁeur R(%) P(%) F(%)
LEXI—SYN ME 96,30 95,92 96,10
LEXI—BASE ME 91,22 96,09 93,57
NON-LEXI-SYN ME 91,66 94,99 93,26
LEXI—SYN DT 89,01 96,45 92,55
LEXI—SYN NB 93,44 90,69 92,02
NON-LEXI-SYN DT 91,17 88,74 89,83
NON-LEXI-SYN NB 89,58 89,23 89,37
LEXI—BASE DT 84,35 94,70 89,16
LEXI—BASE NB 86,73 87,86 87,27
Baseline — 100,00 25,50 40,49

TAB. 2 — Evaluation du classiﬁeur de relations binaires

En premier lieu, les résultats du tableau 2 montrent l’intérét d’utiliser des traits de nature
syntaxique : les scores obtenus ‘a partir de l’ensemble LEXI—SYN dépassent ceux de l’ensemble
LEXI—BASE pour les trois modéles. De plus, l’ensemble de traits non lexicalisés NON-LEXI-SYN
obtient des scores équivalents a ceux de l’ensemble LEXI—BASE, ce qui est intéressant pour obtenir
des modéles plus génériques. Concernant les algorithmes d’apprentissage, les performances
s’organisent selon la hiérarchie ME > DT > NE. Notons que (Afzal, 2009) obtient une hiérarchie
différente (DT > ME > NB) mais utilise un corpus différent et dans une autre langue, ce qui rend
la comparaison difﬁcile. En termes de performances générales, nos résultats sont comparables a
ceux présentés par (Afzal, 2009), ses meilleurs scores étant R=95%|P=87%|F=91%, obtenus
avec des arbres de décision. Pour la suite de notre démarche, nous avons conservé le modéle
Maximum d’Entropie reposant sur l’ensemble de traits NON-LEXI-SYN plutot que l’ensemble
LEXI—SYN. Notre motivation pour ce faire est que l’ensemble NON-LEXI-SYN permet d’obtenir
des scores satisfaisants sans étre fondé sur des informations fortement liées a un domaine, ce qui
n’est pas le cas pour les traits lexicalisés.

6.3 Sélection des entités et remplissage des formulaires

Concernant l’évaluation des stratégies de sélection, l’ensemble des documents du corpus a été
utilisé. Nous reportons dans le tableau 3 les scores de remplissage des formulaires pour ces
différentes stratégies, agrégés pour l’ensemble des r6les du formulaire, en termes de rappel (R),
précision (P) et F1-mesure (F).

Ces résultats conﬁrment en premier lieu que notre méthode de référence Position est caractérisée
par un niveau déj‘a trés élevé. De plus, cette méthode permet d’obtenir des performances
légérement supérieures a la stratégie PageRank, ce qui peut se justiﬁer en partie par le fait que la
stratégie PageRank repose uniquement sur la structure du graphe, sans tenir compte des poids
sur les arcs. Par conséquent, les entités se trouvant dans des zones densément connectées du

38

