La reconnaissance des mots composés a l’épreuve de l’analyse
syntaxique et vice-versa : évaluation de deux stratégies
discriminantes

Matthieu Constantl Anthony Sigognel Patrick Watrinz
(1) université Paris—Est, LIGM, CNRS, 5, bd Descartes 774545 Mame—1a—Va1lée
(2) Université de Louvain, CENTAL, Louvain—1a—Neuve
mcons1:an@u.niv—mlv . fr , sigog'ne@u.niv—mlv . fr , patri ck . watrinfﬁuclouvain . be

RESUME
Nous proposons deux stratégies discriminantes d’intégrau'on des mots composés dans un proces-
sus réel d’ana1yse syntaxique : (i) pré-segmentation lexicale avant analyse, (ii) post-segmentation
lexicale aprés analyse au moyen d’un réordonnanceur. Le segmenteur de l’approche (i) se fonde
sur un modéle CRF et permet d’obtenir un reconnaisseur de mots composés état-de-l’art. Le
réordonnanceur de l’approche (ii) repose sur un modéle MaxEnt intégrant des traits dédiés aux
mots composés. Nous montrons que les deux approches permettent de combler jusqu’a 18% de
l’écart entre un analyseur baseline et un analyseur avec segmentation parfaite et jusqu"a 25%
pour la reconnaissance des mots composés.

AB STRACT
Recognition of compound words tested against parsing and vice-versa : evaluation of two
discriminative approaches

We propose two discriminative strategies to integrate compound word recognition in a real
parsing context : (i) state-of-the-art compound pregrouping with Conditional Random Fields
before parsing, (ii) reranking parses with features dedicated to compounds after parsing. We
show that these two approaches help reduce up to 18% of the gap between a baseline parser and
parser with golden segmentation and up to 25% for compound recognition.

MOTS-CLES : Mots composés, analyse syntaxique, champs markoviens aléatoires, réordon-
nanceur.

KEYWORDS: Multiword expressions, parsing, Conditional random Fields, reranker.

1 Introduction

L’intégrau'on des expressions multi-mots (EMM) dans des applications réelles comme la tra-
duction automatique ou l’extraction d’information est cruciale car de telles expressions ont la
particularité de contenir un certain degré de ﬁgement. En particulier, elles forment des unités
lexicales complexes qui, si elles sont prises en compte, peuvent non seulement améliorer l’analyse
syntaxique, mais aussi faciliter les analyses sémantiques qui en découlent. Leur intégration
dans un processus d’analyse syntaxique probabiliste a déja été envisagée dans quelques études.
Toutefois, elles reposent pour la majorité sur un corpus au sein duquel l’ensemble des EMMs a

Actes de la con_fe'rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 57-70,
Grenoble, 4 an 8 juin 2012. ©2012 ATAI.A 8: AFCP

57

été parfaitement identiﬁé au préalable. Bien qu’ar11'ﬁcielles, ces études ont montré une amelio-
ration des performances d’analyse : par exemple, (N ivre et Nilsson, 2004; Eryigit et al., 2011)
pour l’analyse en dépendance et (Arun et Keller, 2005; Hogan et al., 2011) pour l’analyse en
constituants. Plus récemment, (Green et al., 2011) a intégré la reconnaissance des EMMs au sein
de la grammaire et non plus dans une phase préalable. La grammaire est entrainée sur un corpus
arboré o1‘1les EMMs sont annotées avec des noeuds non-terminaux spéciﬁques.

Dans cet article, nous nous intéressons a un type d’EMMs : les mots composés. Nous proposons
d’évaluer deux stratégies discriminantes d’intégration de ces expressions dans un contexte réel
d’analyse syntaxique en constituants : (a) pré-segmentation lexicale au moyen d’un reconnaisseur
état-de-l’art de mots composés basé sur les champs markoviens aléatoires [CRF] ; (b) analyse
basée sur une grammaire incluant l’identiﬁcation des mots composés, suivie d’une phase de
réordonnancement des analyses ‘a l’aide d’un modele maximum d’entropie intégrant des traits
dédiés aux mots composés. (a) est une implémentation réaliste de l’approche classique de pré-
regroupement des EMMs. Nous souhaitons évaluer si la reconnaissance automatique des EMMs
a toujours un impact positif sur l’analyse syntaxique, c’est-a-dire, si une segmentation lexicale
imparfaite ne provoque pas trop d’effets de bord sur les constituants supérieurs. I.’approche (b)
est innovante pour la reconnaissance des EMMs : nous sélectionnons la segmentation lexicale
ﬁnale aprés l’analyse syntaxique aﬁn d’explorer le plus d’analyses possibles (contrairement a la
méthode (a)). Cette approche ressemble a celle proposée par (Wehrli et al., 2010) qui reclasse
les hypotheses d’analyses générées par un analyseur symbolique en se basant sur la présence
ou non de collocations. Les expériences que nous avons menées ont été réalisées sur le corpus
arboré de Paris 7 [FTB] (Abeillé et al., 2003) o1‘1les mots composés sont marqués. Nous avons
ut1'lisél’analyseur syntaxique de Berkeley (Petrov et al., 2006) qui est fondé sur une stratégie
non-lexicalisée et qui obtient les meilleurs résultats en francais (Seddah et al., 2009), méme en
incorporant l’identiﬁcau'on des EMMs (Green et al., 2011).

L’artic1e est organisé comme suit : la section 2 présente les problématiques du repérage des EMMs
et de leur intégration dans un analyseur syntaxique. La section 3 décrit plus en détail les deux
stratégies proposées et les modéles sous-jacents. La section 4 détaille les ressources utilisées pour
nos expériences : corpus et lexiques. Nous décrivons ensuite (dans la section 5) l’ensemble des
traits dédiés aux EMMs intégrés dans nos deux modéles. Enﬁn, la section 6 rapporte et analyse
les résultats obtenus lors de nos expériences.

2 Les mots composés

Les expressions multi-mots sont des unités lexicales constituées de plusieurs lexémes qui contien-
nent un certain degré de ﬁgement. Elles couvrent une large gamme de phénoménes linguistiques :
les expressions figées et semi-ﬁgées, les constructions ‘a verbe support, les entités nommées,
les termes, etc. Elles sont souvent divisées en deux classes : les expressions définies au moyen
de criteres linguistiques et celles déﬁnies par des criteres purement statistiques (collocations)
(Sag et al., 2002). La plupart des criteres linguistiques pour déterminer si une combinaison
de mots est une EMM sont basés sur des tests syntaxiques et sémantiques comme ceux décrits
dans (Gross, 1986). Par exemple, l’expression caisse noire est une EMM car elle n’accepte pas
de variations lexicales (*caisse sombre) et elle n’autorise pas d’insertions (*caisse trés noire). De
telles expressions déﬁnies linguistiquement peuvent coincider en par11'e avec les collocations

58

le parenthésage général des analyses (F-mesure) 15. Par contre, on observe un gain signiﬁcatif
de +1.34 en UAS, soit une réduction relative de 18% de l’écart avec l’analyseur gold pour le
systeme intégrant tous les traits. On remarque également une amélioration signiﬁcative de la
reconnaissance des mots composés de +6.0 en F(EMM), soit une réduction relative de l’écart de
+25%. Si l’on analyse les résultats de F-mesure par catégorie, on s’apercoit que le pré-repérage
des EMMs provoque des effets de bord sur les constituants supérieurs comme les relatives et
les subordonnées, et méme les groupes nominaux. L’un des principaux problemes vient de
l’identiﬁcation des verbes composés a l’indicatif ou au subjonctif qui est dramatique (F-mesure de
l’ordre de 20%). Dans une moindre mesure, le repérage des noms communs composés et des
conjonctions de subordination composées pose également des problémes.

6.3 Analyse syntaxique avec réordonnancement

Nous avons ensuite évalué l’intégration d’un réordonnanceur aprés l’analyseur BKY. Comme dans
(Charnia.k et Johnson, 2005), le réordonnanceur se base sur un modéle maximum d’entropie dont
les paramétres sont déterminés par un algorithme d’optimisation de second ordre appelé Limited
Memory Variable Metric. Concretement, nous utilisons une implémentation de cet algorithme
disponible dans les biblioteques mathématiques PETSC 15 et TAO42 17. Dans un premier temps,
nous avons appliqué un modele incorporant uniquement les traits dédiés aux mots composés
(cf. section 5). Nous avons ensuite comparé avec un modele intégrant aussi les traits généraux
décrits dans (Charniak et Johnson, 2005) ou (Collins, 2000) par les patrons suivants : Rule, Word,
Heavy, HeadTree, Bigrams, Trigrams, Edges, WordEdges, Heads, WProj, NGram'Ii‘ee et Score. Pour
chaque expérience, le réordonnanceur prend, en entrée, les 50 meilleures analyses de Berkeley.
Les résultats sont synthétisés dans la table 3.

Analyseur Traits F UAS IA F(E1VI1Vl')
BKY - 81.13 83.88 92.95 69.3
BKY endo 81.35‘ 84.48+ 93.03 70. 7+
BKY endo+exo 81.64 84.98 93. 12 74.2
BKY sud 81.98 84.40 93.41 70.8
BKY nous 82.05+ 84.45+ 93.42 70. 2+
BKYc+ sud 81.66* 85.70 93.41 74.8

TABLE 3 — Integration d’un réordonnanceur dans l’analyse syntaxique. Les notations std et tous
correspondent respectivement aux traits généraux et a tous les traits décrits. BKYc+ correspond
a l’analyseur BKYC couplé au reconnaisseur de mots composés avec tous les traits endogenes
et exogenes. * et + indiquent que le résultat n’est pas signiﬁcatif respectivement par rapport ‘a
l’analyseur baseline BKY et ‘a l’analyseur BKY couplé au réordonnanceur avec les traits std. Les
tests sont réalisés sur FTB-P7.

L’utilisation de tous les traits dédiés aux mots composés permet d’augmenter toutes les mesures
par rapport ‘a BKY : +0.51 en E +1.10 en UAS, +0.16 en LA et +4.9 en F(EMM). Sur la
reconnaissance des mots composés, on constate une relative faiblesse par rapport a la méthode
par pré-identiﬁcation : en analysant les analyses oracles selon F, on s’aper<;oit que F(EMM) a un

15. Ces résultats sont cependant 21 mettre en perspective par rapport aux résultats sur le corpus de dévelopement ou
1’on observe des gains absolus signiﬁcatifs : emre +0.2 et +0.7.
16. http: //www.mcs . anl .gov/petsc/.
17. http: //www.mcs . anl .gov/research/projects/tao/.

67

potentiel maximum de 76.9% ce qui n’est pas tres élevé. Par ailleurs, les traits généraux seuls
sont plus efﬁcaces que les traits dédiés aux mots composés pour ce qui concerne le parenthésage
(81.98% vs. 81.64%) et le LA (93.41% vs. 93.12%). Par contre, ils dégradent 1’UAS (84.40%
vs. 84.98%) et la reconnaissance des mots composés (70.8% vs. 74.2%) Le mélange des deux
types de traits (tous) n’est pas tres concluant car on n’observe aucune variation signiﬁcative de
l’écart par rapport a l’analyseur avec les traits généraux, quelle que soit la mesure. Ces résultats
montrent qu’il est nécessaire de trouver un autre moyen de combiner ces deux types de traits.

7 Conclusions et Perspectives

Dans cet article, nous avons évalué deux stratégies discriminantes pour intégrer la reconnaissance
des mots composés dans un systeme d’analyse syntaxique probabiliste : pré-identiﬁcation e’tat-
de-l’art des mots composés; repérage final des mots composés apres réordonnancement des
n meilleures analyses. Les différents modeles comprennaient des traits spéciﬁques aux unités
polylexicales. Nous avons montré que le pré-repérage permettait d’améliorer grandement la
reconnaissance des mots composés et la qualité des liens de dépendance non typés, alors que
la F-mesure tend ‘a se stabiliser. Le réordonnanceur augmente légerement tous les scores, mais
décoit en terme d’identiﬁcation de mots composés par rapport a la premiere méthode. Par ailleurs,
l’intégration des traits généraux de (Charniak et Johnson, 2005) rend caducs les traits dédiés
aux unités polylexicales et dégrade la qualité des liens de dépendance non types. 11 semble
qu’aucune des deux méthodes ne soit entiérement satisfaisante. Mais ces expériences ouvrent de
nouvelles perspectives intéressantes. Nous pourrions combiner efﬁcacement ces deux stratégies
en permettant au pre-segmenteur de générer l’automate pondéré des segmentations lexicales
possibles et de combiner ce dernier avec l’analyseur syntaxique. Nous pourrions également
transposer ces deux solutions a l’analyse en dépendance.

Remerciements

Nous souhaitons remercier Marie Candito et Spence Green pour nous avoir mis ‘a disposition
leurs versions du corpus arboré de Paris 7.

Références

ABEILLE, A., CLEMENT, L. et TOUSSENEL, F. (2003). Building a treebank for french. In ABEILLE, A.,
éditeur : Treebanks. Kluwer, Dordrecht.

ARUN, A. et KELLER, F. (2005). Lexicalization in crosslinguistic probabilistic parsing : The case of
french. In Actes de ACL.

CAFFERKEY, C., HOGAN, D. et van GENABITH, J. (2007). Multi-word units in treebank-based
probabilistic parsing and generation. In Proceedings of the 10th International Conference on
Recent Advances in Natural Language Processing (RANLP-07).

CANDITO, M. H. et CRABBE, B. (2009). Improving generative statistical parsing with semi-
supervised word clustering. In Proceedings of IWPT 2009.

68

CI-IARNIAK, E. et JOI-INsON, M. (2005). Coarse-to-ﬁne n-best parsing and maxent discriIrIinative
reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational
Linguistics (ACL’05) .

COLLINS, M. (2000). Discriminative reranking for natural language parsing. In Proceedings of
the Seventeenth International Conference on Machine Learning (ICML 2000).

CONSTANT, M. et SIGOGNE, A. (2011). MWU-aware part-of-speech tagging with a CRF model
and lexical resources. In Proceedings of the Workshop on Multiword Expressions : from Parsing
and Generation to the Real World (MWE’11).

CONSTANT, M., TELLIER, I., DUCHIER, D., DUPONT, Y., SIGOGNE, A. et BILLOT, S. (2011). Intégrer
des connaissances linguistiques dans un crf : application ‘a l’apprentissage d’un segmenteur-
étiqueteur du francais. In Actes de Conference sur le traitement automatique des langues naturelles
(TALN’1 1) .

COURTOIS, B. (2009). Un systeme de dictionnaires électroniques pour les mots simples du
francais. Langue Francaise, 87:1941 — 1947.

COURTOIS, B., GARRIGUEs, M., GRoss, G., GRoss, M., JUNG, R., MATHIEU-COLAS, M., MoNcEAUx, A.,
PONCET-MONTANGE, A., SILBERZTEIN, M. et VIVES, R. (1997). Dictionnaire électronique DELAC :
les mots composés binaires. Rapport technique 56, University Paris 7, LADL.

DENIs, 1? et SAGOT, B. (2009). Coupling an annotated corpus and a morphosyntactic lexicon
for state-of-the-art pos tagging with less human effort. In Proceedings of the 23rd Pacific Asia
Conference on Language, Information and Computation (PACLIC 2009).

ERYIGIT, G., ILBAY, 'I'. et ARKAN CAN, 0. (2011). Multiword expressions in statistical dependency
parsing. In Proceedings of the IVVPT Workshop on Statistical Parsing of Morphologically-Rich
Languages (SPRML’1 1).

FINKEL, J. R. et MANNING, C. D. (2009). Joint parsing and named entity recognition. In
Proceedings of NAACL.

GILLIcI<, L. et Cox, S. (1989). Some statistical issues in the comparison of speech recognition
algorithms. In Proceedings of ICASSP’89.

GREEN, 5., de MARNEFFE, M.-C., BAUER, J. et MANNING, C. D. (2011). Multiword expression iden-
tiﬁcation with tree substitution grammars : A parsing tour de force with french. In Proceedings
of the conference on Empirical Method for Natural Language Processing (EMNLP’1 1).

GROSS, M. (1986). Lexicon grammar. the representation of compound words. In Proceedings of
Computational Linguistics (COLING’86).

HOGAN, D., FOSTER, J. et Van GENABITH, J. (2011). Decreasing lexical data sparsity in statistical
syntactic parsing - experiments with named entities. In Proceedings ofACL Workshop Multiword
Expressions : from Parsing and Generation to the Real World (MWE’201 1).

LAFFERTY, J., MCCALLUM, A. et PEREIRA, F. (2001). Conditional random ﬁelds : Probabilistic
models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International
Conference on Machine Learning (ICML 2001), pages 282-289.

LAVERGNE, T., CAPPE, O. et YvoN, F. (2010). Practical very large scale CRFs. In Proceedings the
48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 504-513.
Association for Computational linguistics.

NIVRE, J . et NILSSON, J . (2004). Multiword units in syntactic parsing. In Proceedings of
Methodologies and Evaluation of Multiword Units in Real-World Applications (MEMURA).

69

PETROV, S., BARRETT, L., THIBAUX, R. et KLEIN, D. (2006). Learning accurate, compact and
interpretable tree annotation. In Proceedings of ACL.

RAMISCH, C., VILLAVICENCIO, A. et BOITET, C. (2010). mwe-tool.kit : a framework for multiword
expression identiﬁcation. In Proceedings of LREC.

RAMsHAw, L. A. et MARCUS, M. P. (1995). Text chunking using transformation-based learning. In
Proceedings of the 3rd Workshop on Very Large Corpora, pages 88 — 94.

SAG, I. A., BALDWIN, T., BOND, F., COPESTAKE, A. A. et FLICKINGER, D. (2002). Multiword
expressions : A pain in the neck for nlp. In Proceedings of the Third International Conference on
Computational Linguistics and Intelligent Text Processing (CICLing ’02), pages 1-15, London, UK.
Springer-Verlag.

SAGOT, B. (2010). The lefff, a freely available, accurate and large-coverage lexicon for french. In
Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC’10).
SAMPSON, G. et BABARCZY, A. (2003). A test of the leaf-ancestor metric for parsing accuracy.
Natural Language Engineering, 9(4).

SEDDAH, D., CANDITO, M.-H. et CRABBE, B. (2009). Cross-parser evaluation and tagset variation :
a french treebank study. In Proceedings of International Workshop on Parsing Technologies
(IWPT’09).

SILBERZTEIN, M. (2000). Intex : an fst toolbox. Theoretical Computer Science, 231(1):3346.
TELLIER, I. et ToMMAs1, M. (2011). Champs Markoviens Conditionnels pour l’extraction d’in-
formation. In Eric GAUSSIER et Francois YvoN, éditeurs : Modéles probabilistes pour l’acoés c‘1
l’information textuelle. Hermés.

WATRIN, F! et FRANgo1s, T. (2011). N-gram frequency database reference to handle mwe
extraction in nlp applications. In Proceedings of the Workshop on Multiword Erqaressions : from
Parsing and Generation to the Real World (MWE’1 1).

WEHRLI, E., SERETAN, V et NERIMA, L. (2010). Sentence analysis and collocation identiﬁcation.
In Proceedings of the Workshop on Multiword Expression : From Theory to Applications (MWE’10).

70

qui constituent des associations habituelles de mots (fondées sur la notion de fréquence). Ces
derniéres sont souvent identiﬁées au moyen de mesures statistiques associatives. Dans cet article,
nous nous focalisons sur les EMMs continues qui forment des unités lexicales auxquelles on peut
associer une partie-du-discours : ex. tout c‘1fait est un adverbe, 61 cause de est une préposition,
table ronde est un nom. Les variations morphologiques et lexicales sont trés limitées — e.g. caisse
noire+caisses noires, vin (rouge+blanc+rose’+*orange+...) — et les variations syntaxiques trés
souvent interdites 1. De telles expressions sont généralement analysées au niveau lexical. Par la
suite, nous utilisons le terme mot compose’ ou unite’ polylaxicale.

2.1 Identification

L’identiﬁcation des EMMs dans les textes est souvent complexe car leur propriété de ﬁgement
les rend difficilement prédictibles. Elle repose généralement sur des stratégies lexicalisées. La
plus simple est fondée sur la consultation de lexiques comme dans (Silberztein, 2000). Le plus
grand désavantage est que cette procédure se base entiérement sur des dictionnaires et est donc
incapable de découvrir de nouveaux mots composés. L’utilisation d’extracteurs de collocations
peut donc s’avérer utile. Par exemple, (Watrin et Francois, 2011) calcule a la volée pour chaque
collocation candidate dans le texte traité, son score d’association au moyen d’une base externe
de n-grammes apprises sur un grand corpus brut. L’expression est ensuite étiquetée comme
EMM si son score d’association est plus grand qu’un seuil donné. Ils obtiennent d’excellents
résultats dans le cadre d’une tache d’extraction de mots-clés. Dans le cadre d’une évaluation sur
corpus de référence, (Ramisch et al., 2010) a développé un classiﬁeur basé sur un séparateur
‘a vastes marges intégrant des traits correspondant a différentes mesures d’associations des
collocations. Les résultats sont plutot faibles sur le corpus GENIA. (Green et aL, 2011) a conﬁrmé
ces mauvais résultats sur le corpus arboré de Paris 7. Ceci s’explique par le fait que de telles
méthodes ne font aucune distinction entre les différents types de EMMs et que les types de EMMs
annotés dans les corpus sont souvent limités. Une approche récente consiste a coupler, dans un
méme "modéle", l’annotation des mots composés avec un analyseur linguistique : un étiqueteur
morphosyntaxique dans (Constant et al., 2011) et un analyseur syntaxique dans (Green et al.,
2011). (Constant et al., 2011) apprend un modéle CRF intégrant différents traits classiques de
l’étiquetage morphosyntaxique et des traits basés sur des ressources externes. (Green et al., 2011)
a proposé que l’iden11'ﬁcau'on des mots composés soit intégrée dans la grammaire de l’analyseur,
qui est apprise sur un corpus arboré o1‘1les mots composés sont annotés au moyen de noeuds
non-terminaux spéciﬁques. Ils ont utilisé, avec succés, une grammaire a substitution d’arbres au
lieu d’une grammaire probabiliste indépendante du contexte (avec annotations latentes) aﬁn
d’apprendre des régles lexicalisées. Les deux méthodes ont l’avantage d’étre capables d’apprendre
de nouveaux mots composés. Dans cet article, nous exploitons les avantages des méthodes
décrites dans cette section en les intégrant comme traits d’un unique modéle probabiliste.

2.2 Intégration dans l’analyse syntaxique

La majorité des expériences d’intégrau'on des EMMs dans un processus d’analyse syntaxique
repose sur des corpus au sein desquels les mots composés ont été parfaitement identifiés au

1. De telles expressions acceptent trés rarernent des insertions, souvent limitées 51 des modiﬁeurs simples e.g. ti court
terme, £1 trés court terme.

59

préalable. Bien qu’artiﬁcielles, ces études ont montré une amélioration des performances d’anal-
yse : par exemple, (Nivre et Nilsson, 2004; Eryigit et al., 2011) pour l’analyse en dépendance
et (Arun et Keller, 2005; Hogan et al., 2011) pour l’analyse en constituants. Pour l’analyse en
constituants, nous pouvons noter les expériences de (Cafferkey et aL, 2007) qui ont essayé
de coupler des annotateurs réels de EMMs et différents types d’analyseurs probabilistes pour
l’anglais. Ils ont travaillé sur un corpus de référence non annoté en EMMs. Les EMMs sont
reconnues et pré-groupées automatiquement a‘1l’aide de ressources externes et d’un reconnaisseur
d’entités nommées. Ils appliquent, ensuite, un analyseur syntaxique et réinsérent ﬁnalement les
sous-arbres correspondants aux EMMs pour faire l’évaluation. Ils ont montré des gains faibles
mais signiﬁcatifs. Récemment, les travaux de (Finkel et Manning, 2009) et (Green et al., 2011)
ont proposé d’intégrer les deux taches dans le méme modéle. (Finkel et Manning, 2009) couple
analyse syntaxique et reconnaissance des entités nommées dans un modéle discriminant d’analyse
syntaxique basé sur les CRE (Green et al., 2011) a intégré l’identiﬁcation des mots composés
dans la grammaire. Ils ont, en particulier, montré, pour le frangais, que le meilleur analyseur
syntaxique était toujours l’analyseur de Berkeley (fondé sur une stratégie non-lexicalisée), bien
que l’identiﬁcation des mots composés soit moins bonne qu’avec un analyseur syntaxique fondé
sur une stratégie lexicalisée. Enﬁn, il existe les travaux de (Wehrli et al., 2010) qui reclasse les
hypotheses d’analyses générées par un analyseur symbolique en se basant sur la présence ou non
de collocations.

3 Modéles discriminants

Nous considérons deux stratégies d’intégration des mots composés dans le processus d’analyse
syntaxique : (a) une pré-identiﬁcation des mots composés, suivie d’une analyse ; et (b) une
analyse syntaxique incorporant l’identiﬁcation des mots composés suivie d’un réordonnanceur
intégrant des traits dédiés aux EMMs.

3.1 Pré-identiﬁcation des mots composés

La reconnaissance de mots composés peut étre vue comme une tache d’annotation séquentielle si
l’on utilise le schéma d’annotation IOB (Ramshaw et Marcus, 1995). Ceci implique une limitation
théorique : les mots composés doivent étre continus. Ce schéma est donc théoriquement plus
faible que celui proposé par (Green et al., 2011) qui intégre les mots composés dans la grammaire
et autorise des unités polylexicales discontinues. Cependant, en pratique, les mots composés sont
tres tres rarement discontinus et dans la majorité des cas, la discontinuité est due ‘a l’insertion
d’un simple modiﬁeur qui peut étre incorporé dans la séquence ﬁgée : (‘I court terme, (‘I trés court
terme. Dans cet article, nous proposons d’associer les composants simples des unités polylexicales
‘a une étiquette de la forme CAT+X o1‘1 CAT est la catégorie grammaticale du mot composé et X
détermine la position relative du token dans le mot composé (soit B pour le début — Beginning—,
soit I pour les autres positions —Inside—). Les mots simples sont étiquetés 0 (outside) :Jean/O
adore /O les/Ofaits/N+B divers/N+I.

Pour cette téche, nous utilisons le modele des champs aléatoires markoviens linéaires (Tellier
et Tommasi, 2011) [CRF] introduits par (Lafferty et al., 2001) pour l’annotation de séquences.

60

Etant donné une séquence de mots (graphiques) 2 en entrée x = (x1, x2, ...,xN) et une séquence
d’étiquettes en sor11'e y = (y1,y2, ...,yN), le modéle est déﬁni comme suit :

1 N K
P,x(y|x) = E22 loglk-fk(t:.yt:.yt—1:x)
t k

o1‘1 Z (x) est un vecteur de normalisation dépendant de x. Il est basé sur K traits définis par
des fonctions binaires fk dépendant de la position courante t dans x, l’étiquette courante yr,
l’étiquette précédente y,_1 et toute la séquence en entrée. Chaque mot x,- de x intégre non
seulement sa propre valeur lexicale mais aussi toutes les propriétés du mot (e.g. ses sufﬁxes, ses
éﬁquettes dans un lexique externe, il commence par une majuscule, etc.). Les traits sont activés
si une conﬁguration particuliere entre t, yr, yt_1 and x est satisfaite (i.e. fk(t, yr, yt_1,x) = 1).
Chaque trait est associé a un poids Ak. Ces poids sont les paramétres du modéle et sont estimés
lors de la phase d’apprentissage. Les traits utilisés pour notre tache sont décrits dans la section 5.
Ils sont générés ‘a partir de patrons qui sont instanciés ‘a chaque position dans la séquence a
annoter. Chaque instance x correspond a une fonction binaire fk qui retourne 1 si l’instance a la
position courante correspond a x, 0 sinon.

3.2 Réordonnanceur

Le réordonnancement discriminant consiste a reclasser les n meilleures analyses produites par
un analyseur syntaxique de base et a sélectionner la meilleure. Il utilise un modéle discriminant
intégrant des traits associés aux noeuds des analyses candidates. (Charniak et Johnson, 2005)
a introduit différents traits qui permettent d’améliorer sensiblement les performances d’un
analyseur syntaxique. Formellement, étant donné une phrase s, le réordonnanceur sélectionne la
meilleure analyse candidate p parmi l’ensemble de tous les candidats P(s) a l’aide d’une fonction
de score V9 :

P* = a7‘gmaxpeP(s)V9(P)

L’ensemble des candidats P(s) correspond aux n meilleures analyses produites par l’analyseur de
base. La fonction de score V9 est le produit scalaire d’un vecteur de paramétres 9 et d’un vecteur
de traits f :

V9(P) = 9-f(P) = E: 9;"-fj(P)
j=1

o1‘1 f]-(p) correspond au nombre d’occurences du trait fj dans l’analyse p. Selon (Charniak et
Johnson, 2005), le premier trait fl est la probabilité de p fournie par l’analyseur de base. Le
vecteur 9 est estimé lors de la phase d’apprenu'ssage a partir du corpus arboré de référence et
des analyses générées par l’analyseur de base.

Dans cet article, l’uu'lisau'on du réordonnanceur est légérement modiﬁée par rapport a ce qui se
fait traditionnellement. En effet, nous y intégrons des traits chargés d’améliorer la reconnaissance

2. Un mot (graphique) correspond £1 un token.

61

des mots composes dans le contexte de l’analyse syntaxique. Ces traits sont decrits dans la sec-
tion 5 au moyen de patrons qui sont instancies pour chaque noeud des analyses. L’apprentissage
du modele est realise ‘a l’aide de l’algorithme de maximum d’entropie utilise dans (Charniak et
Johnson, 2005).

4 Ressources

4.1 Corpus

Le corpus arbore de Paris 7 3 [FTB] (Abeille et al., 2003) est un corpus annote en constituants
syntaxiques. Il est compose d’artic1es provenant du journal Le Monde. Nous avons utilise la version
la plus recente, celle de juin 2010. Elle comporte 15 917 phrases et 473 904 mots graphiques,
et utilise 13 categories syntaxiques pour identiﬁer les constituants. Les mots composes sont
marques et forment au total plus de 5% des unites lexicales (mots simples et composes). Nous
avons realise nos experiences sur deux instances differentes provenant de cette méme version :
l’instance issue du prétraitement decrit dans (Green et al., 2011) [FTB-STF] et l’instance issue
du pretraitement realise par la chaine de traitement de l’équipe Alpage de Paris 7 [FTB-P7].
FTB-STF possede un jeu de 14 etiquettes morphosyntaxiques et a ete utilise pour avoir des
résultats comparables avec (Green et aL, 2011) en terme d’identiﬁcation des mots composes. Les
mots composes sont defaits et annotés a l’aide d’un symbole non-terminal spéciﬁque “MWX“ o1‘1 X
est la categorie grammaticale de l’expression. Ils ont une structure plate comme dans la ﬁgure 1.
Il existe 11 symboles de type EMM. FTB-P7 posséde un jeu de 28 etiquettes morphosyntaxiques
optimise pour l’analyse syntaxique et donc tres adequat pour nos experiences. Les composants
simples de chaque mot compose sont fusionnes en un seul mot. Pour pouvoir realiser nos
experiences, il a ete necessaire de defaire tous les mots composes et les representer comme
dans l’instance FTB-STF. Les etiquettes morphosyntaxiques des composants simples des unites
polylexicales ont ete ajoutees ‘a l’aide de l’etiqueteur morphosyntaxique lgtagger (Constant et
Sigogne, 2011) appris sur la version du FTB o1‘1 les mots composes ne sont pas defaits. Le
partionnement entrainement/développement/test correspond au partitionnement ofﬁciel : les
sections développement et best sont les memes que dans (Candito et Crabbe, 2009), avec 1 235
phrases chacune. La section entrainement comporte 13 347 phrases, soit 3 390 phases en plus
que la version generalement utilisee.

part de marché

FIGURE 1 — Representation des mots composes part de marche’ : le noeud MWN correspond a un
nom compose ; il a une structure interne plate N P N (nom — preposition — nom)

3. http : / / www.11f.cnrs.fr/ Gens /Abei11e/ French-Treebank-fr.php

62

4.2 Ressources lexicales

I1 existe de nombreuses resources morphologiques en francais incluant les mots composés. Nous
avons exploité deux dictionnaires de langue générale : le Dela (Courtois, 2009; Courtois et aL,
1997) et le Lefff (Sagot, 2010). Le Dela a été manuellement développé dans les années 80-90 par
l’équipe de linguistes du LADL a Paris 7. Nous utilisons la version libre intégrée a la plateforme
Unitex4. Il est composé de 840,813 entrées lexicales, incluant 104,350 entrées composées (dont
91,030 noms). Les mots composés présents dans la ressource respectent, en général, les criteres
syntaxiques déﬁnis dans (Gross, 1986). Le Lefff’; est une ressource lexicale qui a été accumulée
automatiquement ‘a partir de diverses sources et qui a ensuite été validée manuellement. Nous
avons utilisé la version se trouvant dans MeLT (Denis et Sagot, 2009). Elle comprend 553,138
entrées lexicales, incluant 26,311 entrées composées (dont 22,673 noms). Leurs différents modes
de construction rendent ces deux ressources complémentaires. Pour toutes les deux, les entrées
lexicales possédent une forme ﬂéchie, un lemme et une catégorie grammaticale. Le Dela posséde
un trait supplémentaire pour la plupart des mots composés : leur struture interne. Par exemple,
eau de vie ale code NDN car sa structure interne est de la forme nom — préposition de — nom.

En terme de collocations, (Watrin et Francois, 2011) a présenté un systeme retournant, pour
toute phrase, la liste des collocations nominales potentielles accompagnées de leur mesure
d’association. Pour le FTB, nous obtenons 17,315 collocations nominales candidates associées a
leur log-vraisemblance et leur structure interne.

5 Les traits dédiés aux mots composés

Les deux modeles décrits dans la section 3 nécessitent des traits dédiés aux mots composés.
Les traits que nous proposons sont générés ‘a partir de patrons. Dans le but de rendre ces
modeles comparables, nous avons mis en place deux jeux comparables de patrons de traits
inspirés de (Constant et aL, 2011) : l’un adapté ‘a l’annotat1'on séquentielle et l’autre adapté au
réordonnancement. Les patrons pour l’annotation séquentielle sont instanciés a chaque position
de la séquence en entrée. Les patrons pour le réordonnanceur sont seulement instanciés aux
feuilles des analyses candidates, qui sont dominées par un noeud de type EMM (c’est-a-dire qui
ont un ancétre de type EMM). Nous déﬁnissons un patron T comme suit :

— Annotation séquentielle : a chaque position n dans la séquence en entrée x,

T =f(x,n)/yn

— Réordonnancement : a chaque feuille (a la position n) dominée par un noeud de type EMM m
dans l’analyse candidate p,

T = f (P, n)/ label(m)/pos(p, n)

o1‘1 f est une fonction a définir; y,, est une étiquette de sortie ‘a la position n ; label(m) est
l’ét1'quette du noeud m et pos(p, n) indique la position relative, dans l’unité polylexicale, du mot
a l’indice n : B (position initiale), I (autres positions).

4. http ://igm.univ—m1v.fr/'unitex
5. http : / / ato11.in1ia.fr/ "saga:/leffﬁhtrnl

63

5.1 Traits endogénes

Les traits endogénes sont des traits extraits directement des mots eux-mémes ou d’un outil appris
sur le corpus d’apprentissage comme un étiqueteur morphosyntaxique.

n-grammes de mots. Nous utilisons les bigrammes et unigrammes de mots pour apprendre les
mots composés présents dans le corpus d’entrainement et pour extraire des indices lexicaux aﬁn
d’en découvrir de nouveaux. Par exemple, le bigramme coup de est souvent le préfixe d’unités
polylexicales comme coup de pied, coup de foudre, coup de main, etc.

n-grammes d’étiquettes morphosyntaxiques. Nous utilisons les unigrammes et bigrammes
d’étiquettes morphosyntaxiques dans le but d’apprendre des structures syntaxiques irréguliéres
souvent caractéristiques de présence de mots composés. Par exemple, la séquence préposition —
adverbe associée ‘a l’adverbe composé depuis peu est tres inhabituelle. Nous avons aussi intégré
des bigrammes mélangeant mots et étiquettes morphosyntaxiques.

Traits spéciﬁques. Chaque type de modéle intégre des traits particuliers car chacun s’attéle a des
taches différentes. On incorpore dans le CRF des traits spéciﬁques pour gérer les mots inconnus
et les mots spéciaux (nombres, traits d’union, etc.) : le mot en lettres minuscules; les préfixes
et sufﬁxes de taille 1 21 4, l’information si un mot commence par une majuscule, s’il contient un
chiffre, si c’est un trait d’union. Nous ajoutons en plus les bigrammes des étiquettes de sortie. Les
modéles liés au réordonnanceur intégrent des traits associés aux noeuds de type EMM, dont les
valeurs sont les formes lexicales des mots composés correspondants.

5.2 Traits exogénes.

Les traits exogénes sont des traits qui proviennent totalement ou en partie de données externes
(dans notre cas, nos ressources lexicales). Les ressources lexicales peuvent étre utiles pour
découvrir de nouvelles expressions. Généralement, les mots composés, en particulier les noms,
suivent un schéma régulier, ce qui les rend trés difﬁcilement repérables a partir de traits endogénes
uniquement. Nos ressources lexicales sont appliquées au corpus a l’aide d’une analyse lexicale qui
produit, pour chaque phrase, un automate ﬁni qui représente l’ensemble des analyses possibles.
Les traits exogénes sont calculés a partir de cet automate.

Les traits basés sur un lexique. Nous associons a chaque mot l’ensemble des étiquettes mor-
phosyntaxiques trouvées dans notre lexique morphologique exteme. Cet ensemble forme une
classe d’ambiguité ac. Si un mot appartient potentiellement a une unité polylexicale dans
son contexte d’occurrence, l’étiquette correspondante au mot composé est aussi intégrée ‘a la
classe d’ambiguité. Par exemple, le mot de dans le contexte eau de vie est associé a la classe
det_nom+I_prep. En effet, le mot simple de est soit un déterminant (det) soit une préposition
(prep). Par ailleurs, il se trouve dans une position interne (I) du nom eau de vie. Ce trait est
directement calculé a partir de l’automate généré par l’analyse lexicale. Nous utilisons également
cet automate aﬁn de réaliser une segmentation lexicale préliminaire en appliquant un algorithme
du plus court chemin pour favoriser les analyses polylexicales. Cette segmentation préliminaire
est source d’indices pour la segmentation ﬁnale, donc source de nouveaux traits. On peut associer
21 tout mot appartenant 21 un segment composé différentes propriétés : l’étiquette morphosyntax-
ique mwt du segment, ainsi que sa structure interne mws; sa position relative mwpos dans le
segment (’B’ ou ’I’).

Traits basés sur les collocations. Dans notre ressource de collocations, chaque candidat du
FTB est accompagné de sa structure syntaxique interne et de son score d’associau'on (log-
vraisemblance). Nous avons divisé ces candidats en deux classes : ceux qui ont un score supérieur
a un certain seuil et les autres. Ainsi, tout mot du corpus peut étre associé a un certain nombre
de propriétés s’il appartient a une collocation candidate : la classe de la collocation c ainsi que sa
structure interne cs, la position relative cpos du mot dans la collocation (’B’ ou ’I’). Nous avons
manuellement fixé le seuil a une valeur de 150 apres une phase de réglage sur le corpus de
développement.

Tous les patrons de traits sont donnés dans la table 1.

'11-aits endogénes

w(n +i), i E {—2,—1,0, 1, 2}

w(n +i)/w(n +i+ 1), i E {-2, -1, 0, 1}
E01 +i), i e {—2,—1,o, 1, 2}

E01 +i)/t(n+ i + 1), i e {-2, -1, 0, 1}
W(n + i)/t(n +1"). (i.J') E {(1. 0). (0. 1). (-1. 0). (0. -1)}
'11-aits exogénes

ac(n)

mwt(n)/mW1>os(n)

mws(n)/mwpos(n)

c(n)/cs(n) /c'p0s(n)

TABLE 1 — Les patrons de traits utilisés a la fois dans l’annotateur séquentiel et le réordonnanceur
(n est la position courante dans la phrase) : ils correspondent a la fonction f.

6 Evaluation

6. 1 Préliminaires

L’ensemble des expériences décrites ci-dessous ont été réalisées avec l’analyseur syntaxique de
Berkeleys. Nous notons BKYc l’analyseur dont la grammaire 7 a été apprise sur le FTB o1‘1 les
mots composés sont fusionnés; BKY l’analyseur dont la grammaire a été apprise sur le FTB o1‘1les
mots composés sont défaits et annotés par un symbole non-terminal spécial.

Les expériences sont évaluées a l’aide de plusieurs mesures classiques : la F-mesure [F], la mesure
UAS (Unlabeled Attachment Score) et la mesure LA (Leaf Ancestors). F 8 prend en compte le
parenthésage et l’étiquetage des noeuds. Le score UAS 9 évalue la qualité des liens de dépendance
non typés entre les mots. Finalement, la mesure LA 1° (Sampson et Babarczy, 2003) calcule la
similarité entre les chemins allant des noeuds terminaux a la racine de l’arbre et les chemins
de référence correspondants. L’identification des mots composés est évaluée par la F-mesure

6. Nous avons uﬁlisé la version adaptée au Francais pour la gestion des mots inconnus qui se trouve dans 1e1ogicie1Bon-
sai (Candito et Crabbe, 2009) : h1:1:p:/ / alpage . inria. fr/statgram/frdep/:Er_s1:a1:_dep_parsing.h1:ml.

7. Les gramrnaires sont apprises avec 6 cycles et une graine aléatoire de 8.

8. Cette mesure est calculée au moyen du programme Evalb qui est disponible a http://nlp. cs.nyu.edu/
evalb/. Nous avons aussi utilisé 1’éva1ua11'on par catégorie implantée dans la classe EvalbByCa1: de l’analyseur de
Stanford.

9. On converﬁt d’abord automatiquement les analyses en consituants, en analyses en dépendances au moyen du
logiciel Bonsai. Puis la mesure est calculée avec 1’ou11'1 disponible a http: / / ilk . uvt . n1/ con11/ software . html.

10. Nous utilisons 1’outil disponible a h1:1:p:/ / www. grsampson. ne1:/ Re sources .h1:ml

65

F(EMM) associée aux noeuds de type EMM. La signiﬁcativité statistique entre deux expériences
d’analyse syntaxique est calculée au moyen du t-test unidirectionnel pour deux échantillons
indépendants 11. La signiﬁcativité statistique entre deux expériences d’identificat1'on de mots
composés est établie par le test de McNemar (Gillick et Cox, 1989). Les résultats de deux
expériences sont considérés comme statistiquement signiﬁcatifs si la valeur calculée lors du test
est inférieure a 0.01.

6.2 Analyse syntaxique avec pré-identification des mots composés

Nous avons tout d’abord testé l’analyseur BKYc prenant en entrée un texte segmenté par notre
reconnaisseur CRF de mots composés (sans les étiquettes). Ce dernier se base sur le logiciel
Wapiti 12 (Lavergne et al., 2010) qui apprend et applique le modele CRE Le logiciel Unitex est
utilisé pour appliquer les ressources lexicales. I.’étiqueteur morphosyntaxique lgtagger 13 sert ‘a
extraire les traits liés aux n-grammes de catégories grammatica1es.Notre reconnaisseur intégrant
tous les traits atteint 75.9% de F(EMM) sur FTB-P7 (79.1% sans tenir compte des étiquettes). Il
est, en pratique, meilleur que celui proposé par (Green et aL, 2011) qui a une F(EMM) de 71.1%
sur les phrases inférieures ‘a 40 mots de FTB-STF 14 : notre reconnaisseur atteint, sur ce méme
corpus, 74% pour les traits endogenes (soit un gain absolu de +2.9%) et 77.3% pour tous les
traits (soit un gain absolu de +6.2%).

Pour rendre comparables les analyses générées par BKYc couplé au reconnaisseur, avec celles
de l’analyseur BKY, nous avons automatiquement transformé les analyses avec mots composés
fusionnés en leurs analyses équivalentes avec des noeuds non-terminaux spéciﬁques pour les
unités polylexicales. Les catégories grammaticales des composants internes ont été déterminées a
l’aide de l’étiqueteur morphosyntaxique lgtagger appris sur notre corpus d’apprentissage sans
intégrer de ressources lexicales externes. Les résultats sont synthétisées dans la table 3.

133113 F UAS LA F(EM1VI)
BKY 81.13 83.88 92.95 69.3

- 75.85 77.68 91.42 0.0
endo 81.07‘ 85.01 93.10 73.5
exo+endo 81.14‘ 85.22 93.11 75.3
gold 84.17 91.29 94.05 93.2

TABLE 2 — Intégration des mots composés dans l’analyse syntaxique par identiﬁcation préalable.
endo et exo indiquent que le modele CRF incorpore respectivement les traits endogenes et les
traits exogénes. gold signiﬁe que la segmentation lexicale avant analyse syntaxique est parfaite. *
indique que le résultat n’est pas signiﬁcatif par rapport a BKY. Les tests sont réalisés sur FTB-P7.

Les résultats montrent un tres grand écart de performance entre un analyseur ne tenant pas
compte des mots composés [trait -] et un analyseur avec une segmentation lexicale parfaite
[gold] : on a AF = 8.32, AUAS = 13.61, ALA: 2.69 et AF(EMM) = 93.2. L’analyseur baseline
BKY permet, en partie, de combler cet écart : 63% de AF, 46% de AUAS, 59% de ALA et 74%
de AF(EM M ). On constate qu’une reconnaissance préalable des mots composés n’améliore pas

11. Nous utilisons 1’outil de Dan Bikel disponible 21 http : //www . cis . upenn . edu/ "dbikel/ software . html.
12. Wapiti est disponible a http : //wapit i . limsi . fr/. Nous 1’avons configuré de la maniere suivante : algorithme
’rprop’ et valeurs par défaut pour les pénalités L1 et L2, ainsi que le critére d’arrét.
13. Disponible 5: http: //igm. u.niv—mlv . :Er/“mconstan/research/sof1:ware/
14. (Green et aL, 2011) ont évalué leur systérne sur les phrases inférieures £1 40 mots uniquement.

66

