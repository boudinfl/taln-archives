<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Alignement sous-phrastique hi&#233;rarchique avec Anymalign</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 113&#8211;126,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Alignement sous-phrastique hi&#233;rarchique avec Anymalign
</p>
<p>Adrien Lardilleux1 Fran&#231;ois Yvon1,2 Yves Lepage3
(1) LIMSI-CNRS
</p>
<p>(2) Universit&#233; Paris-Sud
(3) Universit&#233; Waseda, Japon
</p>
<p>adrien.lardilleux@limsi.fr, francois.yvon@limsi.fr
</p>
<p>R&#201;SUM&#201;
Nous pr&#233;sentons un algorithme d&#8217;alignement sous-phrastique permettant d&#8217;aligner tr&#232;s facilement
un couple de phrases &#224; partir d&#8217;une matrice d&#8217;alignement pr&#233;-remplie. Cet algorithme s&#8217;inspire de
travaux ant&#233;rieurs sur l&#8217;alignement par segmentation binaire r&#233;cursive ainsi que de travaux sur
le clustering de documents. Nous &#233;valuons les alignements produits sur des t&#226;ches de traduction
automatique et montrons qu&#8217;il est possible d&#8217;atteindre des r&#233;sultats du niveau de l&#8217;&#233;tat de l&#8217;art,
affichant des gains tr&#232;s cons&#233;quents allant jusqu&#8217;&#224; plus de 4 points BLEU par rapport &#224; nos
travaux ant&#233;rieurs, &#224; l&#8217;aide une m&#233;thode tr&#232;s simple, ind&#233;pendante de la taille du corpus &#224;
traiter, et produisant directement des alignements sym&#233;triques. En utilisant cette m&#233;thode en tant
qu&#8217;extension &#224; l&#8217;outil d&#8217;extraction de traductions Anymalign, nos exp&#233;riences nous permettent de
cerner certaines limitations de ce dernier et de d&#233;finir des pistes pour son am&#233;lioration.
</p>
<p>ABSTRACT
Hierarchical sub-sentential alignment with Anymalign
</p>
<p>We present a sub-sentential alignment algorithm that aligns sentence pairs from an existing
alignment matrix in a very easy way. This algorithm is inspired by previous work on alignment by
recursive binary segmentation and on document clustering. We evaluate the alignments produced
on machine translation tasks and show that we can obtain state-of-the-art results, with gains
up to more than 4 BLEU points compared to our previous work, with a method that is very
simple, independent of the size of the corpus to be aligned, and can directly produce symmetric
alignments. When using this method as an extension of the translation extraction tool Anymalign,
our experiments allow us to determine some of its limitations and to define possible leads for
further improvements.
</p>
<p>MOTS-CL&#201;S : corpus parall&#232;le ; alignement sous-phrastique ; traduction automatique statistique.
</p>
<p>KEYWORDS: parallel corpus ; sub-sentential alignment ; statistical machine translation.
</p>
<p>113</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>L&#8217;alignement sous-phrastique consiste &#224; identifier des traductions d&#8217;unit&#233;s textuelles &#224; partir
d&#8217;un corpus parall&#232;le align&#233; en phrases, c&#8217;est-&#224;-dire dont les phrases ont &#233;t&#233; pr&#233;alablement
mises en correspondance avec leur traduction. Cette t&#226;che constitue la premi&#232;re &#233;tape du
processus d&#8217;entra&#238;nement de la plupart des syst&#232;mes de traduction automatique fond&#233;e sur les
donn&#233;es (traduction statistique ou par l&#8217;exemple). L&#8217;approche la plus r&#233;pandue est actuellement
la traduction automatique statistique par segments (n-grammes de mots), o&#249; le mod&#232;le central
prend la forme d&#8217;une table de traductions, obtenue &#224; partir de correspondances sous-phrastiques.
Cette table consiste en une liste pr&#233;-calcul&#233;e de couples de segments (source, cible), &#224; chacun
desquels est associ&#233; un certain nombre de scores refl&#233;tant la probabilit&#233; que source se traduise
par cible.
</p>
<p>Le probl&#232;me de l&#8217;identification d&#8217;associations sous-phrastiques &#224; partir de textes parall&#232;les, entre
mots isol&#233;s ou n-grammes de mots par exemple, est bien connu, et de nombreuses propositions
ont &#233;t&#233; faites pour le r&#233;soudre. On peut grossi&#232;rement classer ces m&#233;thodes en deux cat&#233;gories.
La premi&#232;re, l&#8217;approche probabiliste, introduite par Brown et al. (1988), consid&#232;re le probl&#232;me
d&#8217;identifier des liens entre mots ou groupes de mots dans des phrases parall&#232;les. Cette approche
consiste &#224; d&#233;finir un mod&#232;le probabiliste du texte parall&#232;le, dont les param&#232;tres sont estim&#233;s par
un processus de maximisation global qui consid&#232;re toutes les associations possibles du corpus en
m&#234;me temps. Le but est de d&#233;terminer le meilleur ensemble de liens d&#8217;alignement entre les mots
source et cible de chaque couple de phrases parall&#232;les. Les plus connus dans cette cat&#233;gorie sont
les mod&#232;les IBM (Brown et al., 1993), permettant d&#8217;aligner des mots isol&#233;s, et qui ont donn&#233;
lieu &#224; une impressionnante liste de variantes et d&#8217;am&#233;liorations (voir par exemple les travaux
de Vogel et al. (1996); Wu (1997); Deng et Byrne (2005); Liang et al. (2006); Fraser et Marcu
(2007); Ganchev et al. (2008), pour ne citer qu&#8217;eux). La g&#233;n&#233;ralisation des mod&#232;les d&#8217;alignement
de mots &#224; l&#8217;alignement de segments s&#8217;av&#232;re &#234;tre un probl&#232;me bien plus difficile, et au vu des
d&#233;ficiences des propositions de Marcu et Wong (2002) et Vogel (2005), de tels alignements sont
g&#233;n&#233;ralement produits en combinant des alignements de mots 1&#8211;n asym&#233;triques (&#171; orient&#233;s &#187;)
dans les deux directions &#224; l&#8217;aide d&#8217;heuristiques (Koehn et al., 2003; DeNero et Klein, 2007). Une
fois l&#8217;ensemble de ces liens d&#8217;alignement constitu&#233;, il est possible d&#8217;attribuer des scores &#224; chacun
des couples de segments extraits.
</p>
<p>La seconde approche, associative (qualifi&#233;e d&#8217;heuristique par Och et Ney (2003)), a &#233;t&#233; introduite
par Gale et Church (1991). Celle-ci ne n&#233;cessite pas de mod&#232;le d&#8217;alignement : pour d&#233;tecter des
traductions, elle repose sur des mesures d&#8217;ind&#233;pendance statistique telles que, par exemple, le
coefficient de Dice, l&#8217;information mutuelle (Gale et Church, 1991; Fung et Church, 1994), ou le
rapport de vraisemblance (Dunning, 1993) &#8212; voir aussi les travaux plus r&#233;cents de Melamed
(2000) et Moore (2005). On limite g&#233;n&#233;ralement les tests &#224; une liste d&#8217;associations candidates
pr&#233;-calcul&#233;e &#224; partir de motifs et de filtres, en se concentrant par exemple uniquement sur
les n-grammes de mots les plus fr&#233;quents. Dans cette approche, on utilise un processus de
maximisation locale, o&#249; chaque segment est trait&#233; ind&#233;pendamment des autres. Cette approche
permet g&#233;n&#233;ralement d&#8217;extraire directement des couples de traductions. Dans ce courant, on
trouve par exemple les travaux de Gale et Church (1991), qui ont &#233;t&#233; depuis &#233;tendus aux corpus
non strictement parall&#232;les (Fung et Church, 1994; Fung et Yee, 1998), de Dagan et Church
(1994); Gaussier et Lang&#233; (1995); Smadja et al. (1996) pour apprendre des associations de
segments ou de termes, ou encore des travaux ayant recours &#224; diverses mesures d&#8217;association,
telles que le G2 (Gale et Church, 1991) ou le &#966;2 (Dunning, 1993; Moore, 2004, 2005). Dans
</p>
<p>114</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>un second temps, on peut induire des liens d&#8217;alignement &#224; la fa&#231;on des m&#233;thodes probabilistes,
comme l&#8217;a propos&#233; Melamed (2000) avec le competitive linking.
</p>
<p>L&#8217;approche probabiliste est la plus r&#233;pandue, principalement du fait de sa bonne int&#233;gration avec
la traduction automatique statistique, dont elle constitue un fondement depuis l&#8217;introduction
des mod&#232;les IBM (Brown et al., 1993). Les deux approches pr&#233;sentent des forces et faiblesses
compl&#233;mentaires, comme l&#8217;ont montr&#233; par exemple les travaux de Johnson et al. (2007), o&#249;
les associations extraites &#224; partir d&#8217;alignements de mots sont ensuite filtr&#233;es selon des mesures
d&#8217;association.
</p>
<p>Nous avons r&#233;cemment propos&#233; une m&#233;thode d&#8217;extraction de traductions de segments sous-
phrastiques (Lardilleux et al., 2011a), nomm&#233;e Anymalign, qui s&#8217;attaque &#224; un certain nombre de
probl&#232;mes souvent n&#233;glig&#233;s dans le domaine. En particulier, cette m&#233;thode permet le traitement
d&#8217;un nombre quelconque de langues simultan&#233;ment, ne fait aucune distinction entre source et
cible, est massivement parall&#233;lisable, passe facilement &#224; l&#8217;&#233;chelle, et est tr&#232;s simple &#224; impl&#233;menter.
Cette m&#233;thode, qui s&#8217;inscrit dans le courant des m&#233;thodes associatives, est meilleure que l&#8217;&#233;tat
de l&#8217;art sur des t&#226;ches de constitution de lexiques bilingues. Les r&#233;sultats obtenus lorsqu&#8217;on
l&#8217;utilise pour construire des mod&#232;les de traductions statistiques s&#8217;av&#232;rent toutefois inf&#233;rieurs aux
m&#233;thodes standard (Lardilleux et al., 2011b).
</p>
<p>Une des hypoth&#232;ses que nous avons pr&#233;c&#233;demment &#233;mises pour expliquer ces r&#233;sultats contrast&#233;s
est qu&#8217;Anymalign ne comporte pas de phase d&#8217;alignement &#224; proprement parler. Cette m&#233;thode ne
produit donc pas de liens &#224; la mani&#232;re des m&#233;thodes probabilistes, mais directement des tables de
traductions avec leurs scores associ&#233;s. Ces tables ont des profils tr&#232;s diff&#233;rents de celles extraites
&#224; partir d&#8217;alignements produits par les m&#233;thodes probabilistes, principalement en termes de
distribution des n-grammes (Luo et al., 2011). En particulier, malgr&#233; de r&#233;centes am&#233;liorations
(Lardilleux et al., 2011b), la quantit&#233; de traductions de longs n-grammes est relativement faible
compar&#233;e aux tables de traductions obtenues &#224; partir des m&#233;thodes probabilistes. Dans cet article,
nous proposons une extension &#224; notre m&#233;thode lui permettant de produire des liens d&#8217;alignement,
&#224; la mani&#232;re des approches probabilistes, tout en conservant le caract&#232;re local de la recherche des
traductions propre aux approches associatives. Notre but principal n&#8217;est pas ici de proposer une
nouvelle m&#233;thode d&#8217;alignement destin&#233;e &#224; am&#233;liorer les outils de l&#8217;&#233;tat de l&#8217;art, mais d&#8217;essayer de
mieux comprendre les limitations actuelles d&#8217;Anymalign, en l&#8217;utilisant ici de mani&#232;re non plus
directe, mais d&#233;tourn&#233;e, pour construire le mod&#232;le de traduction. La m&#233;thode pour construire
des alignements, tr&#232;s simple, est donc ind&#233;pendante d&#8217;Anymalign et pourrait &#234;tre remplac&#233;e par
tout autre proc&#233;d&#233; &#233;quivalent.
</p>
<p>Cet article est organis&#233; comme suit : la section 2 pr&#233;sente en d&#233;tail chacune des &#233;tapes qui
compose notre m&#233;thode d&#8217;alignement, la section 3 pr&#233;sente une &#233;valuation de la m&#233;thode sur
des t&#226;ches de traduction automatique et une analyse des r&#233;sultats obtenus, et la section 4 conclut
ces travaux.
</p>
<p>2 Description de la m&#233;thode
</p>
<p>En un mot, notre m&#233;thode consiste &#224; segmenter chaque couple de phrases d&#8217;un corpus parall&#232;le de
fa&#231;on binaire, d&#233;terminer parmi les deux segments cible obtenus lequel est la bonne traduction
de chacun des deux segments source (traduction monotone ou invers&#233;e), et recommencer
</p>
<p>115</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>r&#233;cursivement sur chacun des deux couples de segments obtenus.
</p>
<p>Ces travaux s&#8217;inspirent fortement de ceux de Wu (1997) et Deng et al. (2006). Les premiers
pr&#233;sentent des grammaires de transduction inversibles o&#249; les parties source et cible d&#8217;un couple
de phrases align&#233;es sont analys&#233;es simultan&#233;ment selon un arbre de d&#233;rivation binaire dont la
particularit&#233; est de permettre l&#8217;inversion des constituants d&#8217;une langue &#224; l&#8217;autre &#224; n&#8217;importe quel
niveau de l&#8217;arbre (approche bottom-up). On retrouve un concept similaire dans les seconds, o&#249;
on extrait des bi-segments plus ou moins grossiers &#224; partir de textes parall&#232;les non pr&#233;alablement
align&#233;s en phrases en appliquant une segmentation binaire de fa&#231;on it&#233;rative selon le principe
&#171; diviser pour r&#233;gner &#187; (approche top-down).
</p>
<p>Nos travaux se rapprochent davantage de ces derniers en ce sens que nous ne nous int&#233;ressons
qu&#8217;&#224; une proc&#233;dure simple ne reposant que sur des d&#233;comptes au niveau lexical, plut&#244;t que
sur une grammaire telle qu&#8217;utilis&#233;e par Wu. N&#233;anmoins, alors que Deng et al. produisent des
alignements de segments plus ou moins grossiers &#224; partir d&#8217;un bi-texte non pr&#233;alablement align&#233;
en phrases, dans le but de simplifier des t&#226;ches subs&#233;quentes d&#8217;alignement sous-phrastique par
exemple, notre but est plus classiquement d&#8217;aligner directement le grain le plus fin possible, ici
le mot typographique, &#224; partir de textes pr&#233;alablement align&#233;s en phrases. Le crit&#232;re que nous
utilisons pour d&#233;cider de la segmentation d&#8217;un couple de phrases est adapt&#233; en cons&#233;quence.
</p>
<p>2.1 Matrice d&#8217;alignement
</p>
<p>Notre point de d&#233;part se compose :
&#8211; d&#8217;un bi-texte pr&#233;alablement align&#233; en phrases ;
&#8211; d&#8217;une fonction w associant &#224; chaque couple de mots (source, cible) du bi-texte un score refl&#233;tant
</p>
<p>la force du lien de traduction entre source et cible.
Plusieurs d&#233;finitions de w sont possibles ; il est n&#233;anmoins naturel de la d&#233;finir de fa&#231;on endog&#232;ne
&#224; partir des occurrences des mots sur l&#8217;ensemble du bi-texte. En ce qui nous concerne, les scores
que nous utiliserons seront dans un premier temps obtenus &#224; partir des sorties d&#8217;Anymalign.
Nous verrons par la suite que ceux-ci m&#232;nent &#224; de meilleurs r&#233;sultats que d&#8217;autres scores obtenus
&#224; partir de mod&#232;les plus r&#233;pandus, principalement du fait de la grande redondance des sorties
d&#8217;Anymalign, qui permet de renforcer les scores de traductions se produisant dans des contextes
vari&#233;s.
</p>
<p>Par la suite donc, le score w(s, c) entre un mot source s et un mot cible c sera d&#233;fini comme le
produit des deux probabilit&#233;s de traduction orient&#233;es p(s|c)&#215; p(c|s), celles-ci &#233;tant calcul&#233;es &#224;
partir des d&#233;comptes associ&#233;s aux traductions produites par Anymalign :
</p>
<p>w(s, c) = p(s|c)&#215; p(c|s)
=
</p>
<p>&#8721;N
n=1&#185;(s, c) &#8712; (Sn, Cn)&#186;kn&#8721;N
</p>
<p>n&#8242;=1&#185;s &#8712; Sn&#8242;&#186;kn&#8242; &#215;
&#8721;N
</p>
<p>n=1&#185;(s, c) &#8712; (Sn, Cn)&#186;kn&#8721;N
n&#8242;=1&#185;c &#8712; Cn&#8242;&#186;kn&#8242;
</p>
<p>=
</p>
<p>&#16;&#8721;N
n=1&#185;(s, c) &#8712; (Sn, Cn)&#186;kn&#17;2&#16;&#8721;N
</p>
<p>n&#8242;=1&#185;s &#8712; Sn&#8242;&#186;kn&#8242;&#17;&#215;&#16;&#8721;Nn&#8242;=1&#185;c &#8712; Cn&#8242;&#186;kn&#8242;&#17;
avec :
&#8211; &#185;x&#186;= 1 si x est vrai, 0 sinon ;
</p>
<p>116</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Sn Cn kn
</p>
<p>pays countries 151 190
pays country 17 717
pays tiers third countries 10 865
les pays countries 6 284
mon pays my country 4 057
ces pays these countries 3 742
pays . country . 2 007
&#233;tat country 122
</p>
<p>w(pays, country) = p(pays|country)&#215; p(country|pays)
=
</p>
<p>17 717 + 4 057 + 2 007
151 190 + 17 717 + 10 865 + 6 284 + 4 057 + 3 742 + 2 007
</p>
<p>&#215; 17 717 + 4 057 + 2 007
17 717 + 4 057 + 2 007 + 122
</p>
<p>&#8776; 0, 121
</p>
<p>FIG. 1 &#8211; Exemple de calcul de score entre le mot source pays et le mot cible country sur un
sous-ensemble d&#8217;une table de traductions produite par Anymalign &#224; partir des parties fran&#231;aise et
anglaise du corpus parall&#232;le Europarl (Koehn, 2005).
</p>
<p>&#8211; N le nombre d&#8217;entr&#233;es (couples de segments source&#8211;cible) dans la table de traductions produite
par Anymalign ;
</p>
<p>&#8211; Sn (resp. Cn) le segment source (resp. cible) d&#8217;une entr&#233;e de la table de traductions ;
&#8211; kn le d&#233;compte associ&#233; au couple (Sn, Cn) dans la table de traductions. Ce nombre n&#8217;est pas en
</p>
<p>soi un indicateur de la qualit&#233; de l&#8217;entr&#233;e ; il s&#8217;agit simplement du nombre de fois o&#249; le couple
a &#233;t&#233; produit par Anymalign (voir d&#233;tails dans (Lardilleux et al., 2011a)).
</p>
<p>La figure 1 donne un exemple.
</p>
<p>En pratique, ce que nous faisons ici revient &#224; partir d&#8217;une table de traductions pour aller vers
des liens d&#8217;alignements &#8212; pour retourner ultimement vers une nouvelle table de traductions.
Cela va &#224; rebours des usages du domaine, qui construisent la table de traductions &#224; partir de
l&#8217;ensemble des liens d&#8217;alignements calcul&#233;s sur un corpus parall&#232;le. Cette particularit&#233; ouvre
de nouvelles pistes pour l&#8217;am&#233;lioration de la qualit&#233; des liens d&#8217;alignements et d&#8217;une table de
traductions, l&#8217;am&#233;lioration des uns pouvant avoir des r&#233;percussions sur l&#8217;autre, et vice-versa, de
fa&#231;on it&#233;rative, &#224; la mani&#232;re des approches probabilistes reposant par exemple sur l&#8217;algorithme
Esp&#233;rance Maximisation. Cela sort n&#233;anmoins du cadre de cet article, et nous nous consacrons
pour l&#8217;instant au passage de la table de traductions vers les liens d&#8217;alignements.
</p>
<p>2.2 Crit&#232;re de segmentation
</p>
<p>Le crit&#232;re de segmentation d&#233;crit ci-apr&#232;s est issu des travaux de Zha et al. (2001) sur le
clustering de documents. Leur probl&#232;me consiste &#224; partitionner de fa&#231;on optimale un graphe
biparti repr&#233;sentant les occurrences d&#8217;un ensemble de termes au sein d&#8217;un ensemble de documents.
Nous le transposons &#224; la recherche du meilleur alignement entre l&#8217;ensemble des mots d&#8217;une
</p>
<p>117</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>B B&#772;
c1 . . . cy&#8722;1 cy . . . cJ
</p>
<p>s1
</p>
<p>A
... W (A, B) W (A, B&#772;)
</p>
<p>sx&#8722;1
sx
</p>
<p>A&#772;
... W (A&#772;, B) W (A&#772;, B&#772;)
sI
</p>
<p>FIG. 2 &#8211; Repr&#233;sentation sch&#233;matique de la segmentation d&#8217;un couple de phrases S = A . A&#772; et
C = B . B&#772;.
</p>
<p>phrase source et l&#8217;ensemble des mots d&#8217;une phrase cible.
</p>
<p>Pour cela, nous consid&#233;rons un couple de phrases (S, C) du corpus parall&#232;le, o&#249; la phrase source
S est constitu&#233;e de I mots source et la phrase cible C est constitu&#233;e de J mots cible : S = [s1 . . . sI]
et C = [c1 . . . cJ]. Nous consid&#233;rons par ailleurs des indices de coupure x et y d&#233;finissant une
segmentation binaire des phrases source et cible (le symbole &#171; . &#187; d&#233;signe la concat&#233;nation de
cha&#238;nes de mots) :
</p>
<p>S = A . A&#772; avec A= [s1 . . . sx&#8722;1] et A&#772;= [sx . . . sI]
C = B . B&#772; avec B = [c1 . . . sy&#8722;1] et B&#772; = [cy . . . cJ]
</p>
<p>Le choix de x et y sera guid&#233; par la somme W des scores d&#8217;association entre chacun des mots
source et cible d&#8217;un couple de segments (X , Y ) &#8712; {A, A&#772;} &#215; {B, B&#772;} :
</p>
<p>W (X , Y ) =
&#8721;
</p>
<p>s&#8712;X ,c&#8712;Y
w(s, c)
</p>
<p>On retrouve l&#8217;ensemble des notations utilis&#233;es dans la figure 2, qui donne une repr&#233;sentation
sch&#233;matique de la segmentation d&#8217;un couple de phrases.
</p>
<p>On d&#233;finit alors :
cut(X , Y ) = W (X , Y&#772; ) +W (X&#772; , Y )
</p>
<p>Notons que cut(X , Y ) = cut(X&#772; , Y&#772; ). Dans notre cas, une valeur faible indique que les scores
d&#8217;association entre les mots de X et Y&#772; d&#8217;une part, et entre ceux de X&#772; et Y d&#8217;autre part, sont
faibles &#233;galement, autrement dit que ces deux couples de segments ont peu de chances d&#8217;&#234;tre
de bonnes traductions, (X , Y ) et (X&#772; , Y&#772; ) constituant alors &#233;ventuellement de bonnes traductions.
Id&#233;alement donc, nous d&#233;sirons d&#233;terminer le couple (x , y) qui m&#232;ne &#224; la plus petite valeur
de cut(X , Y ) possible. Zha et al. (2001) pointent n&#233;anmoins le fait que cette quantit&#233; tend &#224;
produire des segments (clusters de documents dans leur cas) d&#233;s&#233;quilibr&#233;s du fait de l&#8217;absence
de normalisation, et en proposent par cons&#233;quent une version normalis&#233;e :
</p>
<p>Ncut(X , Y ) =
cut(X , Y )
</p>
<p>cut(X , Y ) + 2&#215;W (X , Y ) +
cut(X&#772; , Y&#772; )
</p>
<p>cut(X&#772; , Y&#772; ) + 2&#215;W (X&#772; , Y&#772; )
Cette variante permet de rajouter une contrainte de densit&#233; sur (X , Y ) et (X&#772; , Y&#772; ), ce qui est
partiellement satisfait par l&#8217;introduction des d&#233;nominateurs dans l&#8217;expression ci-dessus. Sa valeur
est comprise entre 0 et 2.
</p>
<p>118</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>proc&#233;dure aligner(S, C) :
si longueur(S) = 1 ou longueur(C) = 1 :
</p>
<p>lier chacun des mots de S avec chacun des mots de C
arr&#234;t proc&#233;dure
</p>
<p>minNcut = 2
(X , Y ) = (S, C)
pour chaque (i, j) &#8712; {2 . . . I} &#215; {2 . . . J} :
</p>
<p>si Ncut(A, B) &lt; minNcut :
minNcut = Ncut(A, B)
(X , Y ) = (A, B)
</p>
<p>si Ncut(A, B&#772;) &lt; minNcut :
minNcut = Ncut(A, B&#772;)
(X , Y ) = (A, B&#772;)
</p>
<p>aligner(X , Y )
aligner(X&#772; , Y&#772; )
</p>
<p>FIG. 3 &#8211; Algorithme d&#8217;alignement r&#233;cursif.
</p>
<p>Notre probl&#232;me consiste finalement &#224; d&#233;terminer le couple (x , y) qui minimise Ncut. Bien que
des m&#233;thodes de recherche performantes existent et sont couramment utilis&#233;es en th&#233;orie des
graphes, nos &#171; graphes &#187; (couples de phrases) sont petits en pratique : environ 30 mots par phrase
en moyenne dans le corpus Europarl que nous utilisons pour la suite de nos exp&#233;riences. Nous
nous contentons donc par la suite de d&#233;terminer la meilleure segmentation en testant toutes les
coupures possibles.
</p>
<p>2.3 Algorithme d&#8217;alignement
</p>
<p>&#192; partir du crit&#232;re d&#233;fini pr&#233;c&#233;demment, nous pouvons segmenter et aligner un couple de
phrases de fa&#231;on r&#233;cursive. &#192; chaque &#233;tape, nous testons tous les couples (x , y) possibles afin
de d&#233;terminer le plus faible Ncut. Le pire des cas se produit lorsque la matrice est coup&#233;e
de la fa&#231;on la plus d&#233;s&#233;quilibr&#233;e possible ; la complexit&#233; de l&#8217;algorithme est donc cubique (de
l&#8217;ordre de I &#215; J &#215;min(I , J)). Pour un couple (x , y) donn&#233;, nous calculons deux valeurs : l&#8217;une
correspondant &#224; un alignement monotone (Ncut(A, B)) et l&#8217;autre &#224; une inversion des deux
segments (Ncut(A, B&#772;)). Le processus est alors appliqu&#233; sur chacun des couples de segments
correspondant au Ncut minimal. Il s&#8217;arr&#234;te lorsqu&#8217;un segment ne comporte qu&#8217;un seul mot :
les alignements produits sont tous de multiplicit&#233; 1&#8211;n ou n&#8211;1, et il en r&#233;sulte que tous les
mots sont n&#233;cessairement align&#233;s. Des variantes o&#249; le processus r&#233;cursif s&#8217;arr&#234;te plus t&#244;t sont
envisageables, en fixant un seuil sur Ncut par exemple, auquel cas les alignements produits
seraient de multiplicit&#233; m&#8211;n. Nous gardons cette possibilit&#233; pour des recherches futures.
</p>
<p>La figure 3 pr&#233;sente l&#8217;algorithme complet, et la figure 4 illustre le processus sur deux exemples
r&#233;els. Dans la suite de l&#8217;article, nous ferons r&#233;f&#233;rence &#224; cet algorithme sous le nom &#171; Cutnalign &#187;.
</p>
<p>L&#8217;algorithme en lui-m&#234;me est ind&#233;pendant de la taille du corpus parall&#232;le &#224; aligner, car chaque
couple de phrases est trait&#233; ind&#233;pendemment des autres. On peut donc tr&#232;s facilement parall&#233;liser
l&#8217;alignement d&#8217;un corpus : le temps d&#8217;alignement total est divis&#233; par le nombre de processeurs &#224;
disposition. Un autre avantage est que les alignements produits sont sym&#233;triques tout au long du
processus, contrairement &#224; des mod&#232;les plus r&#233;pandus comme les mod&#232;les IBM qui produisent de
</p>
<p>119</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>the level of budgetary implementation ;
le 0,037 &#949; 0,001 &#949; &#949; &#949;
</p>
<p>niveau &#949; 0,591 &#949; &#949; &#949; &#949;
d&#8217; &#949; &#949; 0,003 &#949; &#949; &#949;
</p>
<p>ex&#233;cution &#949; &#949; &#949; &#949; 0,060 &#949;
budg&#233;taire &#949; &#949; &#949; 0,659 &#949; &#949;
</p>
<p>; &#949; &#949; &#949; &#949; &#949; 0,287
</p>
<p>finally , what our fellow citizens are demanding is the right to information .
enfin 0,607 0,001 &#949; &#949; 0 &#949; &#949; 0 &#949; &#949; &#949; &#949; &#949; &#949;
</p>
<p>, 0,001 0,445 &#949; &#949; &#949; &#949; &#949; &#949; &#949; 0,001 &#949; 0,001 &#949; 0,001
c&#8217; &#949; &#949; 0,001 &#949; &#949; &#949; &#949; 0 0,036 0,001 &#949; &#949; &#949; &#949;
</p>
<p>est &#949; &#949; 0,001 &#949; &#949; &#949; &#949; 0 0,223 0,016 &#949; 0,001 &#949; 0,001
un &#949; &#949; &#949; &#949; &#949; &#949; &#949; &#949; 0,005 &#949; &#949; &#949; &#949; &#949;
</p>
<p>droit &#949; &#949; &#949; &#949; &#949; &#949; &#949; 0 &#949; &#949; 0,084 &#949; &#949; &#949;
&#224; &#949; &#949; &#949; &#949; &#949; &#949; 0,001 &#949; 0,001 0,003 0,001 0,018 &#949; &#949;
l&#8217; &#949; &#949; &#949; &#949; &#949; &#949; &#949; &#949; 0,002 0,009 &#949; 0,002 &#949; &#949;
</p>
<p>information &#949; &#949; &#949; &#949; &#949; &#949; &#949; &#949; &#949; &#949; &#949; &#949; 0,499 &#949;
que &#949; &#949; 0,002 &#949; &#949; &#949; 0,001 &#949; 0,002 0,001 &#949; 0,001 &#949; &#949;
</p>
<p>r&#233;clament 0 0 &#949; &#949; &#949; &#949; &#949; 0,152 &#949; &#949; 0 0 0 &#949;
nos &#949; &#949; &#949; 0,171 0,004 0,001 &#949; &#949; &#949; &#949; &#949; &#949; &#949; &#949;
</p>
<p>concitoyens 0 &#949; &#949; 0,001 0,323 0,009 &#949; &#949; &#949; &#949; 0 &#949; 0 &#949;
. &#949; &#949; &#949; &#949; &#949; &#949; &#949; &#949; 0,001 0,001 &#949; &#949; &#949; 0,954
</p>
<p>FIG. 4 &#8211; Deux exemples de segmentation-alignement. Les nombres dans les cellules correspondent
&#224; la valeur de la fonction w, avec &#949; une valeur non nulle inf&#233;rieure &#224; 0,001. Une valeur de 0
indique que les deux mots n&#8217;apparaissent jamais ensemble dans la table de traductions. Les
points d&#8217;alignement retenus par l&#8217;algorithme, correspondant au niveau de r&#233;cursion maximal,
sont indiqu&#233;s en gras. Dans le premier cas, la traduction est monotone &#224; l&#8217;exception de l&#8217;inversion
de l&#8217;ordre du nom et de l&#8217;adjectif (ex&#233;cution budg&#233;taire/budgetary implementation), la plupart des
liens d&#8217;alignement se situent donc sur la diagonale. Le second cas, plus complexe, rend compte
de l&#8217;inversion de l&#8217;ordre de propositions au sein de la phrase.
</p>
<p>meilleurs r&#233;sultats lorsqu&#8217;ex&#233;cut&#233;s dans les deux sens de traduction puis leurs sorties combin&#233;es
&#224; l&#8217;aide d&#8217;heuristiques.
</p>
<p>3 &#201;valuation
</p>
<p>3.1 Description des exp&#233;riences
</p>
<p>Nous &#233;valuons notre m&#233;thode d&#8217;alignement en tant que premier module d&#8217;un syst&#232;me de tra-
duction automatique statistique par segments. Nous utilisons pour cela le syst&#232;me de traduction
Moses (Koehn et al., 2007), et des donn&#233;es constitu&#233;es d&#8217;un &#233;chantillon du corpus parall&#232;le
Europarl (Koehn, 2005), couvrant trois couples de langues : finnois&#8211;anglais (langue agglutinante&#8211;
langue isolante), fran&#231;ais&#8211;anglais, et portugais&#8211;espagnol (langues tr&#232;s proches). Pour chacun,
nous utilisons un jeu d&#8217;entra&#238;nement de 350 000 couples de phrases (30 mots par phrase en
moyenne en anglais), et des jeux de d&#233;veloppement et de test de 2 000 couples de phrases
chacun. L&#8217;optimisation des syst&#232;mes est r&#233;alis&#233;e &#224; l&#8217;aide de la proc&#233;dure MERT (Och, 2003). Sauf
mention contraire, un mod&#232;le de r&#233;ordonnancement lexicalis&#233; est utilis&#233;.
</p>
<p>120</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Nous comparons quatre approches :
</p>
<p>MGIZA++ (Gao et Vogel, 2008), impl&#233;mentant les mod&#232;les IBM (Brown et al., 1993) et le
mod&#232;le cach&#233; de Markov de Vogel et al. (1996). Int&#233;gr&#233; &#224; Moses, il s&#8217;agit toujours de
la r&#233;f&#233;rence du domaine. Nous l&#8217;utilisons avec ses param&#232;tres par d&#233;faut, en encha&#238;nant
5 it&#233;rations de chacun des mod&#232;les IBM1, HMM, IBM3 et IBM4. Une table de traductions
est ensuite produite &#224; partir des alignements &#224; l&#8217;aide des outils de Moses.
</p>
<p>Anymalign (Lardilleux et al., 2011a), produisant directement des tables de traductions. Cet
outil pouvant &#234;tre arr&#234;t&#233; &#224; tout moment, nous fixons son temps d&#8217;ex&#233;cution de fa&#231;on
&#224; ce qu&#8217;il soit ex&#233;cut&#233; pendant la m&#234;me dur&#233;e que MGIZA++. Nous r&#233;p&#233;tons la m&#234;me
exp&#233;rience en faisant varier son param&#232;tre &#171; -i &#187;, permettant de contr&#244;ler la longueur des
segments qu&#8217;il produit en sortie, de 1 &#224; 4 (voir d&#233;tails dans (Lardilleux et al., 2011b)).
Nous y faisons r&#233;f&#233;rence par la suite sous les noms &#171; Anymalign-1 &#187; &#224; &#171; Anymalign-4 &#187;. Le
mod&#232;le de r&#233;ordonnancement utilis&#233; dans cette configuration n&#8217;est qu&#8217;un simple mod&#232;le
bas&#233; sur la distance entre mots, car Anymalign seul ne peut fournir l&#8217;information n&#233;cessaire
&#224; un mod&#232;le de r&#233;ordonnancement lexicalis&#233;.
</p>
<p>Anymalign + Cutnalign : nous appliquons l&#8217;algorithme d&#233;crit dans la section pr&#233;c&#233;dente &#224;
chacune des quatre tables de traductions produites par Anymalign-1 &#224; Anymalign-4. Les
alignements obtenus sont utilis&#233;s pour construire de nouvelles tables de traductions &#224; l&#8217;aide
du jeu d&#8217;outils de Moses.
</p>
<p>Simples probabilit&#233;s + Cutnalign : cette configuration permet d&#8217;&#233;valuer non pas l&#8217;algorithme
propos&#233; pr&#233;c&#233;demment, mais le choix de la fonction w, qui sert de base &#224; l&#8217;algorithme. Nous
utilisons pour cela un score d&#8217;association tr&#232;s simple : la probabilit&#233; qu&#8217;un mot source et un
mot cible soient traductions l&#8217;un de l&#8217;autre (produit des deux probabilit&#233;s de traduction),
cette probabilit&#233; &#233;tant calcul&#233;e &#224; partir de leurs occurrences dans le corpus d&#8217;entra&#238;nement.
La d&#233;finition de w est donc ici la m&#234;me qu&#8217;&#224; la section 2.1, &#224; deux diff&#233;rences pr&#232;s :
&#8211; les d&#233;comptes ne sont pas effectu&#233;s sur une table de traductions produite par Anymalign,
</p>
<p>mais directement sur le bi-texte d&#8217;entra&#238;nement ;
&#8211; kn = 1,&#8704;n.
</p>
<p>Les traductions sont &#233;valu&#233;es selon les mesures BLEU (Papineni et al., 2002) et TER (Snover
et al., 2006, contrairement &#224; BLEU, des scores faibles sont meilleurs).
</p>
<p>3.2 R&#233;sultats
</p>
<p>Les r&#233;sultats sont pr&#233;sent&#233;s dans le tableau 1. Sur chacune des trois t&#226;ches, Anymalign (version
&#171; de base &#187;) est plus ou moins en retrait par rapport &#224; MGIZA++. L&#8217;utilisation du param&#232;tre
&#171; -i &#187; permet de r&#233;duire cet &#233;cart de moiti&#233; environ, &#224; l&#8217;exception notable du couple finnois&#8211;
anglais (langue agglutinante&#8211;langue isolante), ce qui est conforme aux r&#233;sultats pr&#233;sent&#233;s dans
(Lardilleux et al., 2011b).
</p>
<p>L&#8217;ajout de Cutnalign m&#232;ne &#224; un gain consid&#233;rable dans toutes les configurations : de 1,6 &#224;
4,6 points BLEU (fr&#8211;en, Anymalign-1 + Cutnalign), avec un gain moyen de 2,6 points BLEU
et 2,7 points TER. Anymalign+Cutnalign est toujours en retrait de 1,1 &#224; 1,6 point BLEU en
finnois&#8211;anglais par rapport &#224; MGIZA++, mais produit des r&#233;sultats de m&#234;me qualit&#233;, voire
meilleurs mais de fa&#231;on non significative, en fran&#231;ais&#8211;anglais et portugais&#8211;espagnol.
</p>
<p>L&#8217;approche &#171; simples probabilit&#233;s + Cutnalign &#187; produit des r&#233;sultats de qualit&#233; interm&#233;diaire,
</p>
<p>121</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>T&#226;che Syst&#232;me
BLEU
(%)
</p>
<p>TER
(%)
</p>
<p>Entr&#233;es
(millions)
</p>
<p>Long. des
entr&#233;es
</p>
<p>Liens Long. des
blocs extraits
</p>
<p>MGIZA++ 22,27 62,92 22,2 3,24 26 1,16
</p>
<p>Anymalign-1 18,68 67,30 11,8 1,87
Anymalign-2 17,86 68,60 4,4 2,09
Anymalign-3 18,06 68,13 3,0 2,32
</p>
<p>fi&#8211;en Anymalign-4 18,06 68,53 2,1 2,42
</p>
<p>Anymalign-1 + Cutnalign 21,14 63,74 7,7 3,26 62 1,45
Anymalign-2 + Cutnalign 21,14 64,69 7,5 3,27 69 1,48
Anymalign-3 + Cutnalign 20,83 64,18 7,3 3,29 73 1,50
Anymalign-4 + Cutnalign 20,64 64,52 7,1 3,29 78 1,53
</p>
<p>Simples prob. + Cutnalign 19,09 67,09 5,5 3,23 74 1,78
</p>
<p>MGIZA++ 29,65 55,25 25,6 4,29 31 1,17
</p>
<p>Anymalign-1 25,10 59,36 6,1 1,27
Anymalign-2 26,60 58,16 6,3 1,99
Anymalign-3 27,02 57,96 3,9 2,29
</p>
<p>fr&#8211;en Anymalign-4 26,85 58,00 2,6 2,42
</p>
<p>Anymalign-1 + Cutnalign 29,65 55,22 12,9 4,21 50 1,49
Anymalign-2 + Cutnalign 29,69 55,44 13,1 4,22 48 1,48
Anymalign-3 + Cutnalign 29,26 55,49 13,0 4,23 50 1,49
Anymalign-4 + Cutnalign 29,16 55,46 12,8 4,23 52 1,51
</p>
<p>Simples prob. + Cutnalign 27,97 56,85 10,2 3,95 54 1,62
</p>
<p>MGIZA++ 38,53 48,46 32,2 4,30 30 1,09
</p>
<p>Anymalign-1 35,20 50,89 5,7 1,26
Anymalign-2 36,80 49,60 5,9 1,99
Anymalign-3 36,82 49,67 3,7 2,26
</p>
<p>pt&#8211;es Anymalign-4 36,96 49,80 2,4 2,37
</p>
<p>Anymalign-1 + Cutnalign 37,35 49,55 17,9 4,30 50 1,32
Anymalign-2 + Cutnalign 38,96 48,04 18,0 4,30 48 1,32
Anymalign-3 + Cutnalign 38,55 48,40 17,7 4,31 50 1,33
Anymalign-4 + Cutnalign 38,56 48,37 17,3 4,31 54 1,35
</p>
<p>Simples prob. + Cutnalign 37,71 49,04 13,9 4,09 50 1,41
</p>
<p>TAB. 1 &#8211; R&#233;capitulatif des r&#233;sultats obtenus dans nos exp&#233;riences. Les deux premi&#232;res colonnes
de nombres donnent les scores obtenus en traduction automatique. Les deux colonnes du milieu
pr&#233;sentent les caract&#233;ristiques des tables de traductions : nombre d&#8217;entr&#233;es et longueur de celles-ci
en nombre de mots. Les deux derni&#232;res colonnes pr&#233;sentent les caract&#233;ristiques des alignements
avant production de la table de traductions : nombre moyen de liens d&#8217;alignements par couple
de phrases d&#8217;entra&#238;nement et longueur moyenne de la partie source des blocs minimaux extraits
(apr&#232;s d&#233;termination des segments align&#233;s coh&#233;rents avec les liens d&#8217;alignement).
</p>
<p>122</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>g&#233;n&#233;ralement entre Anymalign &#171; de base &#187; et Anymalign + Cutnalign. Cela montre que le choix
de la fonction w a une grande influence sur le comportement de la m&#233;thode d&#8217;alignement que
nous avons propos&#233;e. En admettant que la fonction d&#233;finie dans ces exp&#233;riences est une des
plus simples qui soient, nous pouvons anticiper que de nombreuses am&#233;liorations sont possibles,
comme le montrent les r&#233;sultats obtenus en initiant la m&#233;thode &#224; partir des tables de traductions
d&#8217;Anymalign.
</p>
<p>3.3 Regard sur les alignements
</p>
<p>Comme pr&#233;cis&#233; en introduction, l&#8217;une des raisons pour laquelle nous avons propos&#233; cette m&#233;thode
d&#8217;alignement est que, malgr&#233; de r&#233;centes am&#233;liorations, Anymalign peine toujours &#224; extraire
suffisamment de traductions de longs n-grammes. Dans cette section, nous &#233;tudions quelques
caract&#233;ristiques des alignements produits par la m&#233;thode que nous avons propos&#233;e. Elles sont
pr&#233;sent&#233;es dans le tableau 1.
</p>
<p>En ce qui concerne les tables de traductions d&#8217;abord, on constate que celles qui sont obtenues
&#224; partir de Cutnalign contiennent un nombre beaucoup plus important d&#8217;entr&#233;es que les tables
correspondantes produites par Anymalign seul1 (trois fois plus en moyenne), &#224; l&#8217;exception
notable d&#8217;Anymalign-1 en finnois&#8211;anglais. Elles sont n&#233;anmoins toujours beaucoup plus petites
que les tables obtenues &#224; partir de MGIZA++ et contiennent deux fois moins d&#8217;entr&#233;es en
moyenne. La longueur moyenne de ces entr&#233;es est en outre quasiment &#233;gale &#224; celles des tables de
traductions de MGIZA++, alors que celles produites par Anymalign sont beaucoup plus courtes :
la production d&#8217;une table de traductions &#224; partir de liens d&#8217;alignement permet bien de combler le
manque de longs n-grammes comme nous le d&#233;sirions.
</p>
<p>Dans un second temps, nous &#233;tudions plus en d&#233;tail les liens d&#8217;alignement &#224; proprement parler,
tels qu&#8217;ils sont avant la production des tables de traductions. La colonne &#171; Liens &#187; du tableau 1
montre que le nombre de liens d&#8217;alignement produits par notre m&#233;thode est bien sup&#233;rieur &#224;
celui de ceux produits par MGIZA++ : entre 1,5 et 3 fois plus selon la t&#226;che. La derni&#232;re colonne
en donne la principale raison : les blocs d&#8217;alignement extraits par notre m&#233;thode, c&#8217;est-&#224;-dire
les rectangles obtenus au niveau de r&#233;cursion maximal, sont toujours plus longs que les blocs
minimums obtenus &#224; partir des alignements de MGIZA++ (+ 26 % en moyenne). Comme nous
alignons syst&#233;matiquement tous les mots source avec tous les mots cible d&#8217;un tel rectangle, et tous
les mots d&#8217;un couple de phrases &#233;tant par cons&#233;quent n&#233;cessairement align&#233;s, le nombre total de
liens produits est naturellement &#233;lev&#233;. Cela explique &#233;galement le fait que le nombre d&#8217;entr&#233;es
dans les tables de traductions est toujours beaucoup plus faible que dans celles obtenues &#224; partir
de MGIZA++, ce dernier produisant des alignements de multiplicit&#233; 0&#8211;1 qui sont &#224; l&#8217;origine de
l&#8217;extraction de tr&#232;s nombreux segments lors de la constitution de la table par Moses (heuristique
grow-diag-final-and par d&#233;faut) (Ayan et Dorr, 2006). Malgr&#233; cela, les alignements produits par
notre m&#233;thode permettent d&#8217;atteindre des scores identiques &#224; l&#8217;&#233;tat de l&#8217;art dans deux t&#226;ches de
traduction automatique sur trois dans nos exp&#233;riences.
</p>
<p>1Ces tables ont &#233;t&#233; produites en ex&#233;cutant Anymalign pendant un temps identique dans les quatre configurations,
ce qui explique pourquoi de plus grandes valeurs de l&#8217;option &#171; -i &#187; m&#232;nent &#224; de plus petites tables &#8212; voir d&#233;tails dans
(Lardilleux et al., 2011b).
</p>
<p>123</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233; une m&#233;thode d&#8217;alignement sous-phrastique fond&#233;e sur un d&#233;coupage
r&#233;cursif binaire de la matrice d&#8217;alignement entre une phrase source et sa traduction. Inspir&#233;e
des travaux de Wu (1997) et Deng et al. (2006) sur l&#8217;alignement et de Zha et al. (2001) sur le
clustering de documents, nous avons montr&#233; qu&#8217;en d&#233;pit de sa simplicit&#233;, cette m&#233;thode produit
des r&#233;sultats du niveau de l&#8217;&#233;tat de l&#8217;art dans deux t&#226;ches sur trois dans nos exp&#233;riences. Coupl&#233;e
&#224; Anymalign, elle permet des gains cons&#233;quents (jusqu&#8217;&#224; 4,6 points BLEU en fran&#231;ais&#8211;anglais) par
rapport &#224; l&#8217;utilisation d&#8217;Anymalign seul. Nos exp&#233;riences ont confirm&#233; que le principal handicap
d&#8217;Anymalign concerne bien les traductions de longs n-grammes. Une &#233;tape compl&#233;mentaire
d&#8217;alignement au sens strict du terme se r&#233;v&#232;le donc souhaitable pour am&#233;liorer ses r&#233;sultats en
traduction automatique, car elle permet de combler la plupart de ses manques en termes de
traductions de longs segments. La m&#233;thode d&#8217;alignement propos&#233;e ici est relativement simple,
sym&#233;trique du point de vue du sens de la traduction, et le caract&#232;re local du calcul des alignements
lui permet de passer facilement &#224; l&#8217;&#233;chelle. Dans l&#8217;optique d&#8217;am&#233;liorer les alignements, de
multiples enrichissements de la m&#233;thode sont possibles, comme par exemple l&#8217;int&#233;gration des
valeurs seuils lors de la recherche du meilleur d&#233;coupage de la matrice afin d&#8217;arr&#234;ter le processus
d&#8217;alignement &#224; des blocs plus larges et plus s&#251;rs, ou encore l&#8217;examen d&#8217;un d&#233;coupage ternaire
plut&#244;t que binaire afin de rendre compte de constructions linguistiques plus complexes g&#233;n&#233;rant
des constituants non connexes.
</p>
<p>Remerciements
</p>
<p>Ces travaux ont &#233;t&#233; financ&#233;s par le projet Cap Digital SAMAR.
</p>
<p>R&#233;f&#233;rences
</p>
<p>AYAN, N. F. et DORR, B. J. (2006). Going beyond AER : an extensive analysis of word alignments
and their impact on MT. In Proceedings of the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages
9&#8211;16, Sydney, Australie.
</p>
<p>BROWN, P., COCKE, J., DELLA PIETRA, S., DELLA PIETRA, V., JELINEK, F., MERCER, R. et ROOSSIN, P.
(1988). A statistical approach to language translation. In Proceedings of the 12th International
Conference on Computational Linguistics (Coling&#8217;88), pages 71&#8211;76, Budapest.
</p>
<p>BROWN, P., DELLA PIETRA, S., DELLA PIETRA, V. et MERCER, R. (1993). The mathematics of statistical
machine translation : Parameter estimation. Computational Linguistics, 19(2):263&#8211;311.
</p>
<p>DAGAN, I. et CHURCH, K. (1994). Termight : identifying and translating technical terminology.
In Proceedings of the fourth conference on Applied natural language processing, pages 34&#8211;40,
Stuttgart.
</p>
<p>DENERO, J. et KLEIN, D. (2007). Tailoring word alignments to syntactic machine translation. In
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL&#8217;07),
pages 17&#8211;24, Prague.
</p>
<p>124</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>DENG, Y. et BYRNE, W. (2005). HMM word and phrase alignment for statistical machine
translation. In Proceedings of Human Language Technology Conference and Conference on Empirical
Methods in Natural Language Processing (HLT/EMNLP), pages 169&#8211;176, Vancouver, British
Columbia, Canada.
</p>
<p>DENG, Y., KUMAR, S. et BYRNE, W. (2006). Segmentation and alignment of parallel text for
statistical machine translation. Natural Language Engineering, 13(3):235&#8211;260.
</p>
<p>DUNNING, T. (1993). Accurate methods for the statistics of surprise and coincidence. Computa-
tional Linguistics, 19(1):61&#8211;74.
</p>
<p>FRASER, A. et MARCU, D. (2007). Getting the structure right for word alignment : LEAF. In
Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing
and Computational Natural Language Learning (EMNLP-CoNLL), pages 51&#8211;60, Prague.
</p>
<p>FUNG, P. et CHURCH, K. (1994). K-vec : A new approach for aligning parallel texts. In Proceedings
of the 15th International Conference on Computational Linguistics (Coling&#8217;94), volume 2, pages
1096&#8211;1102, Kyo&#772;to.
</p>
<p>FUNG, P. et YEE, L. Y. (1998). An IR approach for translating new words from nonparallel,
comparable texts. In Proceedings of the 36th Annual Meeting of the Association for Computational
Linguistics and 17th International Conference on Computational Linguistics, volume 1, pages
414&#8211;420, Montreal.
</p>
<p>GALE, W. et CHURCH, K. (1991). Identifying word correspondences in parallel texts. In Proceedings
of the fourth DARPA workshop on Speech and Natural Language, pages 152&#8211;157, Pacific Grove.
</p>
<p>GANCHEV, K., GRA&#199;A, J. et TASKAR, B. (2008). Better alignments = better translations ? In
Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics : Human
Language Technologies (ACL-08 : HLT), pages 986&#8211;993, Columbus, Ohio.
</p>
<p>GAO, Q. et VOGEL, S. (2008). Parallel implementations of word alignment tool. In Software
Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 49&#8211;57,
Columbus (Ohio, USA).
</p>
<p>GAUSSIER, E. et LANG&#201;, J.-M. (1995). Mod&#232;les statistiques pour l&#8217;extraction de lexiques bilingues.
Traitement Automatique des Langues, 36(1-2):133&#8211;155.
</p>
<p>JOHNSON, H., MARTIN, J., FOSTER, G. et KUHN, R. (2007). Improving translation quality by
discarding most of the phrasetable. In Proceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-
CoNLL), pages 967&#8211;975, Prague.
</p>
<p>KOEHN, P. (2005). Europarl : A parallel corpus for statistical machine translation. In Proceedings
of the tenth Machine Translation Summit (MT Summit X), pages 79&#8211;86, Phuket.
</p>
<p>KOEHN, P., HOANG, H., BIRCH, A., CALLISON-BURCH, C., FEDERICO, M., BERTOLDI, N., COWAN, B.,
SHEN, W., MORAN, C., ZENS, R., DYER, C., BOJAR, O., CONSTANTIN, A. et HERBST, E. (2007). Moses :
Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting
of the Association for Computational Linguistics (ACL 2007), pages 177&#8211;180, Prague.
</p>
<p>KOEHN, P., OCH, F. et MARCU, D. (2003). Statistical phrase-based translation. In Proceedings of the
2003 Human Language Technology Conference of the North American Chapter of the Association
for Computational Linguistics (HLT-NAACL 2003), pages 48&#8211;54, Edmonton.
</p>
<p>LARDILLEUX, A., LEPAGE, Y. et YVON, F. (2011a). The contribution of low frequencies to multilingual
sub-sentential alignment : a differential associative approach. International Journal of Advanced
Intelligence, 3(2):189&#8211;217.
</p>
<p>125</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LARDILLEUX, A., YVON, F. et LEPAGE, Y. (2011b). G&#233;n&#233;ralisation de l&#8217;alignement sous-phrastique
par &#233;chantillonnage. In Actes de la 18e conf&#233;rence sur le Traitement Automatique des Langues
Naturelles (TALN 2011), volume 1, pages 507&#8211;518, Montpellier.
</p>
<p>LIANG, P., TASKAR, B. et KLEIN, D. (2006). Alignment by agreement. In Proceedings of the Human
Language Technology Conference of the NAACL, pages 104&#8211;111, New York City.
</p>
<p>LUO, J., LARDILLEUX, A. et LEPAGE, Y. (2011). Improving sampling-based alignment by inves-
tigating the distribution of n-grams in phrase translation tables. In Proceedings of the 25th
Pacific Asia Conference on Language, Information and Computation (PACLIC 25), pages 150&#8211;159,
Singapour.
</p>
<p>MARCU, D. et WONG, D. (2002). A phrase-based, joint probability model for statistical machine
translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing
(EMNLP 2002), pages 133&#8211;139, Philadelphie.
</p>
<p>MELAMED, D. (2000). Models of translational equivalence among words. Computational
Linguistics, 26(2):221&#8211;249.
</p>
<p>MOORE, R. (2004). On log-likelihood-ratios and the significance of rare events. In Proceedings
of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 333&#8211;340,
Barcelona.
</p>
<p>MOORE, R. (2005). Association-based bilingual word alignment. In Proceedings of the ACL
Workshop on Building and Using Parallel Texts, pages 1&#8211;8, Ann Arbor.
</p>
<p>OCH, F. (2003). Minimum error rate training in statistical machine translation. In Proceedings
of the 41st Annual Meeting of the Association for Computational Linguistics (ACL 2003), pages
160&#8211;167, Sapporo.
</p>
<p>OCH, F. et NEY, H. (2003). A systematic comparison of various statistical alignment models.
Computational Linguistics, 29:19&#8211;51.
</p>
<p>PAPINENI, K., ROUKOS, S., WARD, T. et ZHU, W.-J. (2002). BLEU : a method for automatic
evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association
for Computational Linguistics (ACL 2002), pages 311&#8211;318, Philadelphie.
</p>
<p>SMADJA, F., HATZIVASSILOGLOU, V. et MCKEOWN, K. (1996). Translating collocations for bilingual
lexicons : A statistical approach. Computational Linguistics, 22(1):1&#8211;38.
</p>
<p>SNOVER, M., DORR, B., SCHWARTZ, R., MICCIULLA, L. et MAKHOUL, J. (2006). A study of translation
edit rate with targeted human annotation. In Proceedings of the 7th Conference of the Association
for Machine Translation of the Americas (AMTA 2006), pages 223&#8211;231, Cambridge.
</p>
<p>VOGEL, S. (2005). PESA : Phrase pair extraction as sentence splitting. In Proceedings of the tenth
Machine Translation Summit (MT Summit X), pages 251&#8211;258, Phuket.
</p>
<p>VOGEL, S., NEY, H. et TILLMAN, C. (1996). Hmm-based word alignment in statistical translation.
In Proceedings of the 16th International Conference on Computational Linguistics (Coling&#8217;96),
pages 836&#8211;841, Copenhague.
</p>
<p>WU, D. (1997). Stochastic inversion transduction grammar and bilingual parsing of parallel
corpora. Computational Linguistics, 23(3):377&#8211;404.
</p>
<p>ZHA, H., HE, X., DING, C., SIMON, H. et GU, M. (2001). Bipartite graph partitioning and data
clustering. In Proceedings of the tenth international conference on Information and knowledge
management, pages 25&#8211;32, Atlanta.
</p>
<p>126</p>

</div></div>
</body></html>