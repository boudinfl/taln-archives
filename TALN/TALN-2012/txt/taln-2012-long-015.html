<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Validation sur le Web de reformulations locales: application &#224; la Wikip&#233;dia</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 197&#8211;210,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Validation sur le Web de reformulations locales:
application &#224; la Wikip&#233;dia
</p>
<p>Houda Bouamor Aur&#233;lien Max Gabriel Illouz Anne Vilnat
LIMSI-CNRS
</p>
<p>Univ. Paris Sud 11
Orsay, France
</p>
<p>prenom.nom@limsi.fr
</p>
<p>R&#201;SUM&#201;
Ce travail pr&#233;sente des exp&#233;riences initiales en validation de paraphrases en contexte. Les
r&#233;visions de Wikip&#233;dia nous servent de domaine d&#8217;&#233;valuation : pour un &#233;nonc&#233; ayant connu une
courte r&#233;vision dans l&#8217;encyclop&#233;die, nous disposons d&#8217;un ensemble de r&#233;&#233;critures possibles, parmi
lesquelles nous cherchons &#224; identifier celles qui correspondent &#224; des paraphrases valides. Nous
abordons ce probl&#232;me comme une t&#226;che de classification fond&#233;e sur des informations issues du
Web, et parvenons &#224; am&#233;liorer la performance de plusieurs techniques simples de r&#233;f&#233;rence.
</p>
<p>ABSTRACT
Assisted rephrasing for Wikipedia contributors through Web-based validation
</p>
<p>This works describes initial experiments on the validation of paraphrases in context. Wikipedia&#8217;s
revisions are used : we assume that a set of possible rewritings are available for a given phrase
that has been rewritten in the encyclopedia&#8217;s revision history, and we attempt to find the subset
of those rewritings that can be considered as valid paraphrases. We tackle this problem as a
classication task which we provide with features obtained from Web data. Our experiments show
that our system improves performance over a set of simple baselines.
</p>
<p>MOTS-CL&#201;S : paraphrase, Wikip&#233;dia, aide &#224; la r&#233;daction.
</p>
<p>KEYWORDS: paraphrasing, Wikipedia, authoring aids.
</p>
<p>1 Introduction
</p>
<p>Il existe plusieurs sc&#233;narios dans lesquels il est souhaitable de pouvoir faire produire du texte par
la machine. Ce probl&#232;me a traditionnellement &#233;t&#233; abord&#233; comme une t&#226;che de g&#233;n&#233;ration de texte
&#224; partir de concepts. Toutefois, ces besoins s&#8217;appliquent parfois &#224; des cas o&#249; un nouveau texte
devrait &#234;tre d&#233;riv&#233; de certains textes existants, par exemple lorsqu&#8217;il s&#8217;agit de transformer un texte
afin qu&#8217;ils aient certaines propri&#233;t&#233;s souhaitables pour un usage particulier (Zhao et al., 2009). Par
exemple, on peut souhaiter qu&#8217;un texte soit condens&#233; (Cohn et Lapata, 2008), adapt&#233; &#224; certains
profils de lecteur (Zhu et al., 2010), conforme &#224; certaines normes sp&#233;cifiques (Max, 2004), voire
m&#234;me simplement plus adapt&#233; pour des t&#226;ches de traitement automatique ult&#233;rieures.
</p>
<p>Le m&#233;canisme de r&#233;&#233;criture de texte doit donc produire un texte dont le sens est compatible
avec la d&#233;finition de la t&#226;che &#224; accomplir, tout en garantissant que celui-ci demeure grammatical.
</p>
<p>197</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La complexit&#233; de la g&#233;n&#233;ration texte-&#224;-texte, par opposition &#224; la g&#233;n&#233;ration concepts-&#224;-texte,
provient essentiellement du fait que la correspondance s&#233;mantique entre deux textes est difficile
&#224; contr&#244;ler, car les r&#233;&#233;critures mises en jeu sont tr&#232;s d&#233;pendantes du contexte. En effet, la grande
diversit&#233; des techniques d&#8217;acquisition de paraphrases sous-phrastiques (Madnani et Dorr, 2010),
la polys&#233;mie de ces unit&#233;s linguistiques ainsi que les contraintes pragmatiques associ&#233;es &#224; leur
substitution font qu&#8217;il est impossible de garantir que des paires de paraphrases candidates seront
substituables quel que soit le contexte de r&#233;&#233;criture. Ce probl&#232;me a &#233;t&#233; d&#233;j&#224; d&#233;crit au niveau
lexical (Zhao et al., 2007; McCarthy et Navigli, 2009) ; la validation automatique en contexte de
reformulations de segments demeure une question fondamentale pour la r&#233;&#233;criture de texte.
</p>
<p>Dans ce travail, nous abordons le probl&#232;me sous l&#8217;angle d&#8217;un paraphrasage cibl&#233; 1, d&#233;fini comme
la r&#233;&#233;criture d&#8217;un segment d&#8217;un &#233;nonc&#233;. Bien que ce probl&#232;me soit plus simple que la r&#233;&#233;criture
d&#8217;une phrase compl&#232;te, son &#233;tude se justifie par la n&#233;cessite de bien comprendre ce niveau moins
complexe avant d&#8217;aborder la r&#233;&#233;criture d&#8217;unit&#233;s plus &#233;tendues, ce qui en outre facilite la t&#226;che
complexe de l&#8217;&#233;valuation.
</p>
<p>Nous pr&#233;sentons ici un sc&#233;nario en r&#233;vision interactive de textes dans lequel des paraphrases sous-
phrastiques doivent &#234;tre propos&#233;es en tenant compte du contexte. Les paraphrases candidates
consid&#233;r&#233;es sont obtenues &#224; partir d&#8217;un r&#233;pertoire existant, et sont valid&#233;es en contexte &#224;
l&#8217;aide d&#8217;informations obtenues sur le Web. Les exp&#233;riences que nous avons men&#233;es ciblent plus
particuli&#232;rement les contributeurs de l&#8217;encyclop&#233;die Wikip&#233;dia dans leurs t&#226;ches de r&#233;vision des
articles. Nous avons pour cela utilis&#233; un ensemble de segments ayant fait l&#8217;objet de r&#233;&#233;critures
dans l&#8217;historique des articles de Wikip&#233;dia, que nous substituons par des paraphrases connues &#224;
l&#8217;avance. &#201;tant donn&#233; la grande vari&#233;t&#233; de segments possibles et de leurs paraphrases, nous ne
nous appuyons pas sur des mod&#232;les de substituabilit&#233; pr&#233;&#233;tablis, mais nous les construisons &#224; la
vol&#233;e &#224; partir du Web.
</p>
<p>Dans cet article, nous allons tout d&#8217;abord d&#233;crire la t&#226;che de r&#233;vision de texte sous forme de
paraphrasage cibl&#233; (section 2). Nous passerons ensuite en revue les principaux travaux pr&#233;c&#233;dents
portant sur l&#8217;acquisition de paraphrases sous-phrastiques et d&#233;crirons les sources de connaissances
que nous avons utilis&#233;es dans ce travail (section 3). Nous d&#233;taillerons ensuite notre m&#233;thode de
calcul des mod&#232;les de substitution de segments en contexte exploitant des informations issues
du Web (section 4). Les exp&#233;riences men&#233;es pour valider les paraphrases contenues dans le
r&#233;pertoire existant et leurs r&#233;sultats seront finalement pr&#233;sent&#233;s (section 5). Notre article se
conclura par une discussion de ces r&#233;sultats et une pr&#233;sentation des principales voies de recherche
( 6).
</p>
<p>2 Paraphrasage cibl&#233; pour la r&#233;vision de texte
</p>
<p>La reformulation d&#8217;un &#233;nonc&#233;, ou d&#8217;un segment plus pr&#233;cis, est une activit&#233; importante en r&#233;vision
de texte. Certaines modifications locales ont ainsi vocation &#224; am&#233;liorer sa qualit&#233; g&#233;n&#233;rale, en le
rendant par exemple plus facile d&#8217;acc&#232;s (Zhu et al., 2010) ou en l&#8217;adaptant au niveau d&#8217;expertise
de ses lecteurs (Del&#233;ger et Zweigenbaum, 2009). Les modifications de ce type, qui n&#8217;alt&#232;rent pas le
sens des textes, incluent non seulement la synonymie lexicale mais &#233;galement des transformations
lexico-syntaxiques plus complexes.
</p>
<p>1. Ce terme est utilis&#233; par Resnik et al. (2010) pour d&#233;crire l&#8217;obtention (manuelle) de paraphrases pour des segments
jug&#233;s difficiles &#224; traduire.
</p>
<p>198</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>On trouve notamment de telles reformulations dans les historiques de r&#233;vision de textes, qui
sont d&#233;sormais disponibles en grandes quantit&#233;s avec l&#8217;&#233;mergence de ressources collaboratives
sur le Web telles que l&#8217;encyclop&#233;die Wikip&#233;dia. L&#8217;historique des r&#233;visions des articles de cette
ressource constitue en effet une source importante de ph&#233;nom&#232;nes de r&#233;&#233;criture naturelle. L&#8217;&#233;tude
de Dutrey et al. (2011) a notamment montr&#233; que cet historique contient une vari&#233;t&#233; importante
de ph&#233;nom&#232;nes de reformulation, dont de nombreuses paraphrases. Cette &#233;tude a &#233;galement
montr&#233;, au travers d&#8217;une tentative d&#8217;identification automatique &#224; base de r&#232;gles, les difficult&#233;s
pour parvenir &#224; une bonne couverture de l&#8217;ensemble des ph&#233;nom&#232;nes paraphrastiques pr&#233;sents.
</p>
<p>Peu de travaux, ont, &#224; notre connaissance, port&#233; sur l&#8217;utilisation du paraphrasage contextuel
dans le cadre de l&#8217;aide &#224; la r&#233;daction. Max et Zock (2008) pr&#233;sentent une m&#233;thode proposant
aux r&#233;dacteurs des paraphrases sous-phrastiques candidates pour les segments qu&#8217;ils souhaitent
reformuler. L&#8217;approche utilis&#233;e pour la g&#233;n&#233;ration des paraphrases est fond&#233;e sur l&#8217;&#233;quivalence de
traduction (Bannard et Callison-Burch, 2005). Les travaux de Bernstein et al. (2010) portent eux
sur l&#8217;externalisation de diverses t&#226;ches d&#8217;&#233;dition de texte, dont la r&#233;vision, via le crowdsourcing.
</p>
<p>Par ailleurs, la r&#233;&#233;criture d&#8217;un texte peut &#234;tre destin&#233;e plus sp&#233;cifiquement &#224; une application
automatique. Dans (Resnik et al., 2010), des reformulations pour des segments jug&#233;s difficiles &#224;
traduire sont acquises via le crowdsourcing : des contributeurs monolingues de la langue source
proposent ainsi des reformulations en contexte pour ces unit&#233;s 2. Les reformulations collect&#233;es
sont ensuite utilis&#233;es en entr&#233;e dans un syst&#232;me de traduction automatique, qui peut ainsi
b&#233;n&#233;ficier de la vari&#233;t&#233; d&#8217;expressions pour produire de meilleures traductions (Schroeder et al.,
2009). Par exemple, le segment une optique festive dans L&#8217;usage intervient alors dans une optique
festive peut &#234;tre r&#233;&#233;crit en : 1) un cadre festif, 2) une perspective de f&#234;te. Ces r&#233;&#233;critures sont
grammaticalement correctes et ont des significations raisonnablement proches de la formulation
d&#8217;origine.
</p>
<p>Outre la reformulation des segments de texte, la r&#233;&#233;criture d&#8217;&#233;nonc&#233;s a aussi &#233;t&#233; &#224; l&#8217;origine de
plusieurs travaux (Barzilay et Lee, 2003; Quirk et al., 2004; Zhao et al., 2010; Ganitkevitch
et al., 2011). Cependant, celle-ci pose de nombreux autres d&#233;fis, notamment au niveau de
l&#8217;&#233;valuation des reformulations produites. Le jugement par des humains devient alors encore plus
complexe et n&#8217;autorise pas des distinctions fines ni des accords inter-annotateurs satisfaisants.
La g&#233;n&#233;ration de paraphrases d&#8217;&#233;nonc&#233;s peut toutefois &#234;tre &#233;valu&#233;e indirectement dans le cadre
de leur utilisation dans une application plus complexe. Par exemple, Madnani et al. (2008)
parviennent &#224; am&#233;liorer les performances d&#8217;un syst&#232;me de traduction automatique statistique en
fournissant des paraphrases automatiques des traductions de r&#233;f&#233;rence lors de l&#8217;apprentissage
des param&#232;tres du syst&#232;me. Cependant, les am&#233;liorations observ&#233;es n&#8217;indiquent pas clairement
les liens avec la qualit&#233; des paraphrases utilis&#233;es.
</p>
<p>Nous abordons dans ce travail la t&#226;che plus modeste de paraphrasage sous-phrastique appliqu&#233;
&#224; la r&#233;vision de texte. Afin d&#8217;&#233;viter tout biais, nous utilisons des r&#233;&#233;critures &#233;cologiques (que
nous entendons ici comme : produites naturellement) extraites d&#8217;une m&#233;moire de r&#233;daction
des articles de Wikip&#233;dia. Nous utilisons pour cela le corpus WICOPACO (Max et Wisniewski,
2010), qui contient de nombreux ph&#233;nom&#232;nes de r&#233;&#233;criture, dont de nombreuses instances
de reformulations lexicales, syntaxiques et s&#233;mantiques (Dutrey et al., 2011). Ce dernier type
de reformulation est illustr&#233; dans l&#8217;exemple suivant, o&#249; le remplacement du segment un mode
d&#8217;expression par sa paraphrase possible une figure de rh&#233;torique permet de pr&#233;ciser et d&#8217;affiner le
</p>
<p>2. Nous notons toutefois que les contributeurs ne re&#231;oivent aucune indication directe de l&#8217;utilit&#233; des reformulations
qu&#8217;ils proposent.
</p>
<p>199</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>sens voulu par le contributeur initial :
</p>
<p>L&#8217;antiphrase est [un mode d&#8217;expression&#8594; une figure de rh&#233;torique] consistant &#224; dire le contraire
de ce que l&#8217;on pense.
</p>
<p>Ce corpus est pertinent &#224; plusieurs titres pour la t&#226;che que nous visons. Tout d&#8217;abord, le fait
qu&#8217;il contienne des r&#233;&#233;critures obtenues hors du cadre d&#8217;exp&#233;riences offre une source riche et
int&#233;ressante d&#8217;unit&#233;s textuelles r&#233;&#233;crites en contexte. De plus, les instances de r&#233;&#233;criture o&#249; le
sens n&#8217;a pas &#233;t&#233; modifi&#233; offrent directement une paraphrase candidate qui peut &#234;tre consid&#233;r&#233;e
comme correcte, donn&#233;e pouvant s&#8217;av&#233;rer utile pour l&#8217;apprentissage automatique du processus de
validation en contexte.
</p>
<p>3 Acquisition de paraphrases sous-phrastiques
</p>
<p>La disponibilit&#233; grandissante de masses de donn&#233;es textuelles a rendu possible un grand nom-
bre de travaux en acquisition et en g&#233;n&#233;ration de paraphrases (Madnani et Dorr, 2010). Les
techniques propos&#233;es apparaissent n&#233;anmoins assez fortement li&#233;es aux types de ressources
auxquelles elles s&#8217;appliquent. Les types de corpus utilis&#233;s pour sont principalement :
</p>
<p>&#8226; des paires de paraphrases d&#8217;&#233;nonc&#233;s (corpus monolingues parall&#232;les), qui permettent
d&#8217;obtenir des paraphrases pr&#233;cises, mais en faible quantit&#233; (Barzilay et McKeown, 2001;
Pang et al., 2003; Cohn et al., 2008; Bouamor et al., 2011) ;
</p>
<p>&#8226; des paires d&#8217;&#233;nonc&#233;s en relation de traduction (corpus multilingues parall&#232;les), qui permet-
tent de g&#233;n&#233;rer de nombreuses paraphrases candidates (Bannard et Callison-Burch, 2005; Kok
et Brockett, 2010) ;
</p>
<p>&#8226; des paires d&#8217;&#233;nonc&#233;s en relation partielle (corpus monolingues parall&#232;les), qui permettent
sur le principe d&#8217;acqu&#233;rir de nombreuses paraphrases (Barzilay et Lee, 2003; Pas&#231;a et Dienes,
2005; Bhagat et Ravichandran, 2008; Del&#233;ger et Zweigenbaum, 2009).
</p>
<p>Bien que la pr&#233;cision de ces techniques d&#8217;acquisition peut se mesurer sur la base d&#8217;une r&#233;f&#233;rence
attendue portant sur une collection de paires d&#8217;&#233;nonc&#233;s (Cohn et al., 2008), il est plus utile de
pouvoir la mesurer au travers de la question de substituabilit&#233; en contexte, laquelle a d&#233;j&#224; &#233;t&#233;
abord&#233;e au niveau lexical (Connor et Roth, 2007; Zhao et al., 2007) o&#249; elle a fait l&#8217;objet de
campagnes d&#8217;&#233;valuation (McCarthy et Navigli, 2009). Celle-ci pose des d&#233;fis suppl&#233;mentaires,
d&#251;s au fait que les segments sont plus rares que les mots en corpus.
</p>
<p>4 Validation contextuelle sur le Web
</p>
<p>4.1 Cadre d&#8217;&#233;valuation
</p>
<p>Le pr&#233;sent travail porte sur la t&#226;che de validation automatique de paraphrases sous-phrastiques
en contexte. Pour cela, nous avons eu recours &#224; un r&#233;pertoire existant de paires de paraphrases.
Comme d&#233;crit plus haut, nous avons utilis&#233; le corpus WICOPACO comme corpus de reformulations
sous-phrastiques naturelles. La r&#233;&#233;criture contenue dans cette ressource peut &#234;tre utilis&#233;e comme
paraphrase potentielle. Afin d&#8217;obtenir d&#8217;autres paraphrases candidates de diff&#233;rentes qualit&#233;s,
nous avons utilis&#233; deux autres m&#233;thodes d&#8217;acquisition, qui fourniront des paraphrases aux
</p>
<p>200</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>instances extraites de WICOPACO qui ne seront pas n&#233;cessairement substituables en contexte :
a) une traduction automatique par pivot, et b) une acquisition manuelle de paraphrases.
</p>
<p>La g&#233;n&#233;ration de paraphrases par traduction s&#8217;effectue simplement en traduisant automatique-
ment un segment dans une langue pivot, puis en le r&#233;trotraduisant dans la langue d&#8217;origine, et
en retenant la premi&#232;re hypoth&#232;se diff&#233;rente du segment d&#8217;origine. Si cette technique n&#8217;offre
aucune garantie sur la qualit&#233; des r&#233;sultats, elle est ais&#233;e &#224; mettre en &#339;uvre et produit des
r&#233;sultats vari&#233;s. En outre, l&#8217;utilisation d&#8217;une langue pivot proche de la langue d&#8217;origine augmente
la probabilit&#233; d&#8217;obtenir de bonnes paraphrases (ceci sera &#233;tudi&#233; lors de nos exp&#233;riences, d&#233;crites
dans la section 5).
</p>
<p>Nous avons d&#233;fini l&#8217;acquisition manuelle de paraphrases de la fa&#231;on suivante : un corpus d&#8217;extraits
de documents du Web contenant les segments &#224; r&#233;&#233;crire est tout d&#8217;abord constitu&#233;, en s&#8217;assurant
que ce corpus ne contient pas de donn&#233;es provenant de Wikip&#233;dia. Pour chaque segment &#224; r&#233;&#233;crire
dans ce corpus, des locuteurs natifs du fran&#231;ais proposent via une interface web une r&#233;&#233;criture
possible. Ainsi, les contextes utilis&#233;s pour faire l&#8217;acquisition de paraphrases des segments sont
possiblement diff&#233;rents de ceux, extraits de WICOPACO, sur lesquels portera l&#8217;&#233;valuation : notre
syst&#232;me de validation en contexte aura donc &#224; consid&#233;rer des paraphrases potentiellement valides 3
</p>
<p>mais qui ne le sont pas dans le contexte d&#8217;une r&#233;&#233;criture particuli&#232;re.
</p>
<p>Ces deux m&#233;thodes, dont la mise en &#339;uvre est ais&#233;e, nous permettent de simuler la disponibilit&#233;
d&#8217;un r&#233;pertoire existant de paraphrases sous-phrastiques, qui nous servira pour l&#8217;&#233;valuation de la
performance de notre technique de validation en contexte.
</p>
<p>4.2 Classification automatique de r&#233;&#233;critures en contexte
</p>
<p>Nous d&#233;crivons maintenant l&#8217;approche que nous proposons pour r&#233;aliser une validation de
r&#233;&#233;critures en contexte, fond&#233;e sur une classification binaire exploitant des mod&#232;les calcul&#233;s &#224;
partir d&#8217;informations du Web. Le recours au Web semble indispensable : seule une telle &#233;chelle
nous permet d&#8217;acc&#233;der &#224; des exemple en nombre suffisants pour certains segments. En outre, il a
&#233;t&#233; montr&#233; qu&#8217;un certain nombre d&#8217;applications de Traitement Automatique des Langues peuvent
&#234;tre am&#233;lior&#233;es gr&#226;ce &#224; l&#8217;exploitation de fr&#233;quences de n-grammes sur le Web (Lapata et Keller,
2005).
</p>
<p>Consid&#233;rant un ensemble de contextes de r&#233;&#233;critures pour des segments ainsi qu&#8217;un r&#233;pertoire ex-
istant contenant des paraphrases pour ces segments, notre t&#226;che consiste &#224; classer (i.e. paraphrase
vs. pas paraphrase) chaque paraphrase possible pour chaque contexte original. Une instanciation
concr&#232;te possible de cette t&#226;che est la proposition de Max et Zock (2008), o&#249; de telles reformula-
tions candidates sont pr&#233;sent&#233;es dans un ordre d&#233;croissant de pertinence &#224; un utilisateur d&#8217;un
&#233;diteur de texte, et donc &#233;ventuellement lors de la r&#233;vision d&#8217;un article de Wikip&#233;dia.
</p>
<p>La t&#226;che d&#8217;identification automatique de paraphrases a &#233;t&#233; d&#233;j&#224; abord&#233;e par classification
automatique dans des travaux pr&#233;c&#233;dents, en utilisant des mod&#232;les calcul&#233;s sur des corpus
collect&#233;s (Brockett et Dolan, 2005) et sur des documents issus du Web (Zhao et al., 2007).
Cependant, ces travaux se sont limit&#233;s &#224; l&#8217;identification de paraphrases lexicales (McCarthy et
Navigli, 2009). Une difficult&#233; importante est que certains mots sont absents ou tr&#232;s peu fr&#233;quents
</p>
<p>3. On les suppose ici valides parce que obtenues par r&#233;&#233;criture manuelle d&#8217;un segment dans un texte. Ceci repose
cependant fortement sur la capacit&#233; de nos contributeurs natifs &#224; bien r&#233;aliser la t&#226;che demand&#233;e.
</p>
<p>201</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>dans les index des moteurs de recherche, et a fortiori dans des corpus sp&#233;cialis&#233;s, difficult&#233; qui
s&#8217;amplifie lorsque l&#8217;on consid&#232;re des segments. 4
</p>
<p>De fa&#231;on analogue aux travaux de Brockett et Dolan (2005), nous consid&#233;rons l&#8217;identification
de paraphrases comme une t&#226;che de classification : &#233;tant donn&#233; un segment d&#8217;origine s dans le
contexte d&#8217;une phrase p, nous cherchons &#224; d&#233;terminer si une paraphrase candidate s&#8217; serait une
paraphrase grammaticale de s dans le contexte de p. Nous avons abord&#233; ce probl&#232;me avec un
classifieur de type s&#233;parateur &#224; vaste marge (SVM) exploitant les traits d&#233;crits ci-dessous.
</p>
<p>Distance d&#8217;&#233;dition Les approches les plus r&#233;pandues en calcul de pertinence d&#8217;un document
relativement &#224; une requ&#234;te exploitent des mesures de similarit&#233; de surface, qui peuvent dans
certains cas &#234;tre de bons indicateurs de proximit&#233; s&#233;mantique. Un co&#251;t de transformation entre
cha&#238;nes de caract&#232;res peut par exemple &#234;tre celui donn&#233; par la mesure TER (Snover et al., 2010),
initialement d&#233;velopp&#233;e pour mesurer la similarit&#233; entre une hypoth&#232;se de traduction et une
traduction de r&#233;f&#233;rence. Cette mesure se base sur des op&#233;rations d&#8217;&#233;dition (substitution, d&#233;place-
ment, insertion, suppression) plus informatives que les m&#233;thodes bas&#233;es sur des intersections
lexicales 5. Nous effectuons en outre ce calcul sur les lemmes plut&#244;t que sur les formes de surface,
que nous avons obtenus &#224; l&#8217;aide du TREETAGGER (Schmid, 1994) 6. Nous retenons donc le score
suivant, calcul&#233; entre un segment d&#8217;origine segorig et une paraphrase segpara, o&#249; la fonction Lem
produit une forme lemmatis&#233;e de son argument :
</p>
<p>hedi t = TER(Lem(segorig), Lem(segpara)) (1)
</p>
<p>Il convient de noter que, contrairement aux autres mod&#232;les, celui-ci ne d&#233;pend pas d&#8217;informations
provenant du Web.
</p>
<p>Score de mod&#232;le de langue La vraisemblance d&#8217;une phrase peut &#234;tre un relativement bon
indicateur de sa grammaticalit&#233; locale (Mutton, 2006). Les probabilit&#233;s donn&#233;es par un mod&#232;le
de langue peuvent d&#233;sormais &#234;tre obtenues &#224; l&#8217;aide de comptes provenant du Web. Nous avons
pour cela utilis&#233; le Service Web N-gram de Microsoft (Wang et al., 2010) dans sa d&#233;clinaison &#224; des
fins de recherche 7. Afin de pouvoir utiliser correctement ce service sur des textes fran&#231;ais, nous
avons d&#251; supprimer tous les diacritiques : un examen pr&#233;cis des paraphrases candidates class&#233;es
a montr&#233; que cette transformation, bien qu&#8217;ab&#233;rante, nous a permis d&#8217;obtenir des r&#233;sultats
coh&#233;rents. 8
</p>
<p>4. Nous faisons cependant l&#8217;hypoth&#232;se que des segments absents ou tr&#232;s peu fr&#233;quents sur le Web pr&#233;sentent un
int&#233;r&#234;t moindre pour la r&#233;&#233;criture, et n&#8217;accordons donc pas pour cette &#233;tape de nos travaux d&#8217;attention particuli&#232;re &#224;
ce probl&#232;me. Il est toutefois possible d&#8217;argumenter que ces segments pourraient &#234;tre mal &#233;crits (par exemple, par un
locuteur non natif, un apprenant, voire une machine) et donc possiblement non connus des moteurs de recherche, pour
lesquels une assistance &#224; la r&#233;&#233;criture serait tout &#224; fait pertinente. Cela repr&#233;sente n&#233;anmoins une probl&#233;matique en soi.
</p>
<p>5. Il faut noter que les op&#233;rations de racinisation et de correspondance s&#233;mantique utilisant WordNet n&#8217;ont pas &#233;t&#233;
prises en compte car nos exp&#233;riences portent sur le fran&#231;ais.
</p>
<p>6. Ce calcul de lemmatisation se fait, pour le segment original et sa paraphrase, dans le contexte de la substitution
test&#233;e : il est toutefois possible que la lemmatisation produise des erreurs.
</p>
<p>7. http://research.microsoft.com/en-us/collaboration/focus/cs/web-ngram.
aspx
</p>
<p>8. La description du service n&#8217;&#233;tait pas tr&#232;s explicite lorsque nous l&#8217;avons utilis&#233; : il semblerait que l&#8217;intention de son
fournisseur &#233;tait avant tout de proposer un service pour l&#8217;anglais.
</p>
<p>202</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Un simple score de mod&#232;le de langue pour un &#233;nonc&#233; apr&#232;s r&#233;&#233;criture n&#8217;est toutefois pas suffisant,
car il ne tient pas compte de l&#8217;&#233;nonc&#233; d&#8217;origine. Nous avons donc utilis&#233; le rapport entre le score
de mod&#232;le de langue de l&#8217;&#233;nonc&#233; paraphras&#233; phrpara et le score de mod&#232;le de langue de l&#8217;&#233;nonc&#233;
d&#8217;origine phrorig , normalis&#233; par la longueur des &#233;nonc&#233;s (Onishi et al., 2010) :
</p>
<p>hM L =
M L(phrpara)1/longueur(phrpara)
</p>
<p>M L(phrorig)1/longueur(phrorig )
(2)
</p>
<p>Scores de similarit&#233; th&#233;matique hors contexte Les techniques mises en &#339;uvre pour calculer
une notion de similarit&#233; entre unit&#233;s textuelles sont fr&#233;quemment fond&#233;es sur le calcul de
repr&#233;sentations des contextes d&#8217;occurrences de ces unit&#233;s sur lesquelles sont calcul&#233;es des mesures
de similarit&#233;. Nous avons suivi ce type d&#8217;approche pour mesurer une similarit&#233; th&#233;matique entre
paraphrases entre profils de mots cooccurrents. Nous construisons tout d&#8217;abord des profils hors
contexte de la mani&#232;re suivante : un moteur de recherche est interrog&#233; afin de r&#233;cup&#233;rer les N
premiers extraits de documents (snippets) pertinents pour le segment segorig . La fr&#233;quence des
mots pleins pr&#233;sents dans ces extraits est alors calcul&#233;e et est utilis&#233;e pour obtenir les valeurs
de chaque dimension d&#8217;un vecteur de profil lexical T , dont la valeur pour un mot m est d&#233;finie
ainsi :
</p>
<p>Torig[m] =
f req(segorig , m)
</p>
<p>f req(segorig)
(3)
</p>
<p>Pour le calcul des fr&#233;quences, f req(u) correspond au nombre d&#8217;extraits de documents retourn&#233;s
contenant l&#8217;unit&#233; u, et f req(u, v) au nombre d&#8217;extraits de documents rapport&#233;s contenant les
deux simultan&#233;ment. Nous construisons de fa&#231;on analogue un profil th&#233;matique pour chaque
paraphrase possible segpara, en se limitant aux dimensions du vecteur pour le segment d&#8217;origine :
</p>
<p>Tpara[m] =
f req(segpara, m)
</p>
<p>f req(segpara)
(4)
</p>
<p>Enfin, nous mesurons la similarit&#233; entre le profil du segment d&#8217;origine et de chacune de ses
paraphrases possibles &#224; l&#8217;aide du cosinus entre les vecteurs de leur profil th&#233;matique :
</p>
<p>hthem =
Torig &#183; Tpara
</p>
<p>||Torig || &#8727; ||Tpara|| (5)
</p>
<p>Pour l&#8217;ensemble de nos exp&#233;riences, nous avons utilis&#233; le service Web Yahoo ! Search BOSS 9 pour
obtenir le nombre de documents du Web index&#233;s contenant une expression litt&#233;rale (typiquement,
un segment d&#8217;int&#233;r&#234;t) ainsi que les extraits de documents &#224; partir desquels nous construisons les
vecteurs de profils th&#233;matiques. En supposant que la distribution des mots pleins cooccurrents
n&#8217;est pas biais&#233;e par l&#8217;ordre des r&#233;sultats du moteur de recherche, notre mod&#232;le mesure donc un
certain type de similarit&#233; th&#233;matique entre segorig et segpara.
</p>
<p>9. http://developer.yahoo.com/search/boss/
</p>
<p>203</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Scores d&#8217;un mod&#232;le th&#233;matique contextuel Nous d&#233;finissons &#233;galement un mod&#232;le th&#233;ma-
tique contextuel de la fa&#231;on suivante : consid&#233;rant contorig , constitu&#233;e des deux sous-cha&#238;nes
de phrorig priv&#233;e de segorig , nous construisons un vecteur de profil T
</p>
<p>cont ayant pour dimen-
sion uniquement pour les mots pleins du contexte de la phrase o&#249; a lieu la r&#233;&#233;criture. Les
valeurs associ&#233;es &#224; chaque dimension correspondent &#224; des rapports de fr&#233;quence obtenus comme
pr&#233;c&#233;demment par interrogation du moteur de recherche. La similarit&#233; th&#233;matique contextuelle
utilis&#233;e est finalement d&#233;finie par :
</p>
<p>hcontthem =
T contorig &#183; T contpara
</p>
<p>||T contorig || &#8727; ||T contpara|| (6)
</p>
<p>5 Exp&#233;riences et r&#233;sultats
</p>
<p>Dans cette section, nous d&#233;taillons les exp&#233;riences que nous avons men&#233;es afin d&#8217;&#233;valuer les
performances de l&#8217;approche de validation automatique de paraphrases en contexte.
</p>
<p>5.1 Description des donn&#233;es utilis&#233;es
</p>
<p>Nous avons extrait al&#233;atoirement 150 &#233;nonc&#233;s en fran&#231;ais du corpus WICOPACO et leur r&#233;&#233;criture
pour des exemples annot&#233;s comme &#8220;paraphrases&#8221; lors d&#8217;une annotation manuelle r&#233;alis&#233;e par une
&#233;tudiante en linguistique francophone. Un sous-ensemble de 100 &#233;nonc&#233;s a &#233;t&#233; utilis&#233; comme
corpus d&#8217;apprentissage, les 50 &#233;nonc&#233;s restants ayant servi pour l&#8217;&#233;valuation. Les segments
originaux ainsi que leur paraphrase dans le corpus d&#8217;&#233;valuation sont d&#233;crits dans la figure 1.
</p>
<p>taille segment 1 2 3 4 5 6 7 8
# segments originaux 0 3 29 8 6 2 2 0
</p>
<p># paraphrases 39 64 74 36 21 10 5 1
</p>
<p>FIGURE 1 &#8211; R&#233;partition du nombre de segments par taille (nombre de tokens) dans le corpus
d&#8217;&#233;valuation
</p>
<p>Nous disposons finalement de 5 paraphrases par segment d&#8217;origine :
</p>
<p>&#8226; WICOPACO : la paraphrase associ&#233;e au segment dans le corpus WICOPACO ;
&#8226; HUMAIN : deux paraphrases candidates propos&#233;es par des contributeurs humains pour d&#8217;autres
</p>
<p>contextes issus du Web ;
&#8226; PIVOTES and PIVOTZH : deux paraphrases candidates obtenues par traduction par pivot. Nous
</p>
<p>avons utilis&#233; le syst&#232;me de traduction automatique sur le Web GOOGLE TRANSLATE 10, avec une
langue proche du fran&#231;ais comme pivot (l&#8217;espagnol), et une autre plus distante (chinois).
</p>
<p>La partie &#233;valuation de nos exp&#233;riences a impliqu&#233; 4 &#233;valuateurs humains 11, tous francophones.
Ceux-ci ont particip&#233; &#224; la collecte manuelle des paraphrases (HUMAIN) pour la moiti&#233; du cor-
pus d&#8217;apprentissage et d&#8217;&#233;valuation. Afin d&#8217;&#233;valuer le caract&#232;re appropri&#233; de l&#8217;utilisation des
</p>
<p>10. http://translate.google.com
11. La personne ayant r&#233;alis&#233; l&#8217;annotation originelle de WICOPACO n&#8217;a pas pris part &#224; ce nouveau travail.
</p>
<p>204</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>paraphrases issues des paraphrases collect&#233;es dans les contextes de r&#233;&#233;criture s&#233;lectionn&#233;s, les
phrases d&#8217;origine et leurs diff&#233;rentes paraphrases ont &#233;t&#233; pr&#233;sent&#233;es dans un ordre al&#233;atoire aux
deux &#233;valuateurs ayant initialement travaill&#233; sur l&#8217;autre moiti&#233; des corpus. Une interface sur le
Web, illustr&#233;e sur la figure 2, permet alors aux &#233;valuateurs d&#8217;indiquer quelles substitutions sont
acceptables, &#224; la fois au niveau de la conservation du sens et de la grammaticalit&#233; du nouvel
&#233;nonc&#233;.
</p>
<p>FIGURE 2 &#8211; Exemple d&#8217;une phrase d&#8217;origine (sur fond vert) et de ses 5 paraphrases candidates
(pr&#233;sent&#233;es dans un ordre al&#233;atoire). Le segment en gras dans la phrase d&#8217;origine, est &#224; l&#8217;origine,
est ici paraphras&#233; par est le promoteur , a popularis&#233; , origine , est &#224; la source et l&#8217;origine.
</p>
<p>La valeur d&#8217;accord inter-annotateur 12 sur l&#8217;ensemble des &#233;nonc&#233;s annot&#233;s est de &#954; = 0,65, ce
qui correspond &#224; un accord fort selon les grilles de Landis et Koch (1977). Nous pensons que le
fait d&#8217;aborder tout d&#8217;abord des t&#226;ches relativement certaines du point de vue de l&#8217;accord entre
humains comme celle-ci est n&#233;cessaire avant de s&#8217;attaquer &#224; des probl&#232;mes plus complexes, tels
que l&#8217;identification de paraphrases d&#8217;&#233;nonc&#233;s ou encore l&#8217;identification d&#8217;implications textuelles.
</p>
<p>Notre technique de validation &#233;tant tr&#232;s d&#233;pendante de la fr&#233;quence des segments consid&#233;r&#233;s
sur le Web, nous avons d&#233;cid&#233; dans ces premi&#232;res exp&#233;riences de ne conserver que les segments
ayant une fr&#233;quence minimale de 10 occurrences pour le moteur de recherche utilis&#233;. Le nombre
d&#8217;exemples du corpus d&#8217;apprentissage a ainsi &#233;t&#233; r&#233;duit de 750(=150*5) &#224; 434, et celui du corpus
d&#8217;&#233;valuation de 250(=50*5) &#224; 215. L&#8217;att&#233;nuation de cette limitation devra bien &#233;videmment faire
partie de la suite de nos travaux.
</p>
<p>Nous d&#233;taillerons nos r&#233;sultats pour les 3 conditions suivantes :
</p>
<p>&#8226; Possibles : les exemples annot&#233;s comme &quot;paraphrases&quot; par au moins l&#8217;un des juges sont utilis&#233;s :
l&#8217;ensemble d&#8217;&#233;valuation correspondant comprend 116 cas positifs et 99 cas n&#233;gatifs.
</p>
<p>&#8226; S&#251;res : les exemples que les deux juges n&#8217;ont pas annot&#233;s comme &#8220;paraphrases&#8221; ou &#8220;non
paraphrases&#8221; ne sont pas retenus : l&#8217;ensemble d&#8217;&#233;valuation correspondant comprend 76 cas
positifs et 139 cas n&#233;gatifs.
</p>
<p>&#8226; S&#251;res++ : seuls les exemples pour lesquels les deux juges proposent la m&#234;me annotation sont
retenus. Ceci r&#233;duit nos ensembles d&#8217;apprentissage et d&#8217;&#233;valuation &#224; respectivement 287 et
175 exemples, ce qui ne permet pas une comparaison directe avec les deux autres conditions.
L&#8217;ensemble d&#8217;&#233;valuation correspondant comprend 76 cas positifs et 99 cas n&#233;gatifs.
</p>
<p>12. Nous avons utilis&#233; le logiciel R (http://www.r-project.org) pour calculer la valeur de &#954; de Cohen.
Cette valeur est calcul&#233;e sur l&#8217;ensemble des donn&#233;es, chaque moiti&#233; &#233;tant annot&#233;e par les deux m&#234;mes annotateurs.
</p>
<p>205</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>5.2 Techniques de r&#233;f&#233;rence
</p>
<p>Nous pr&#233;sentons ici bri&#232;vement les techniques de r&#233;f&#233;rence auxquelles nous comparerons notre
syst&#232;me.
</p>
<p>Fr&#233;quence sur le Web Les deux premi&#232;res techniques sont fond&#233;es sur des calculs de fr&#233;quences
sur le Web. La premi&#232;re, ML_WEB consid&#232;re un &#233;nonc&#233; comme paraphrase d&#8217;un &#233;nonc&#233; d&#8217;origine
si son score de mod&#232;le de langue issu du Web est plus &#233;lev&#233; que celui de l&#8217;&#233;nonc&#233; d&#8217;origine.
La deuxi&#232;me technique, ML_FRONTI&#200;RES, consid&#232;re qu&#8217;un &#233;nonc&#233; est paraphrase d&#8217;un &#233;nonc&#233;
d&#8217;origine si la fr&#233;quence sur le Web des bigrammes traversant les fronti&#232;res gauche et droite
apr&#232;s substitution est sup&#233;rieure &#224; 10.
</p>
<p>Conservation de d&#233;pendances syntaxiques Lors de la r&#233;&#233;criture d&#8217;une partie d&#8217;un &#233;nonc&#233;, la
conservation des d&#233;pendances syntaxiques entre un segment d&#8217;origine et son contexte d&#8217;une
part, et sa paraphrase avec le m&#234;me contexte d&#8217;autre part, peut renseigner sur la substituabilit&#233;
grammaticale des deux segments (Zhao et al., 2007; Max et Zock, 2008). Nous avons calcul&#233; les
d&#233;pendances syntaxiques pour les deux segments &#224; l&#8217;aide de la version fran&#231;aise (Candito et al.,
2010) de l&#8217;analyseur probabiliste de Berkeley (Petrov et Klein, 2007). Nous consid&#233;rons donc le
sous-ensemble des d&#233;pendances qui existent entre les mots du segment d&#8217;origine et son contexte
(Deporig) et entre les mots de la paraphrase et ce contexte (Deppara). Cette technique, DEPCONT,
retient la paraphrase candidate si et seulement si Deppara = Deporig .
</p>
<p>5.3 R&#233;sultats et analyse
</p>
<p>Nous avons utilis&#233; un s&#233;parateur &#224; vastes marges (SVM) avec les traits d&#233;crits dans la section 4 13
</p>
<p>Les performances des diff&#233;rentes techniques sur les 3 conditions d&#233;crites pr&#233;c&#233;demment sont
donn&#233;es dans la figure 3.
</p>
<p>ML_WEB LM_FRONTI&#200;RES DEPCONT CLASSIFIEUR
</p>
<p>POSSIBLES 62,79 54,88 48,53 57,67
S&#219;RES 68,37 36,27 51,90 70,69
</p>
<p>S&#219;RES++ 56,79 51,41 42,69 62,85
</p>
<p>FIGURE 3 &#8211; R&#233;sultats de la performance de la classification (exactitude) pour les 3 techniques
de r&#233;f&#233;rence et notre classifieur sur le corpus d&#8217;&#233;valuation et les 3 conditions. Il convient de
noter que la condition S&#219;RES++ n&#8217;est pas directement comparable aux autres conditions puisque
les tailles des corpus d&#8217;apprentissage et d&#8217;&#233;valuation sont diff&#233;rentes &#224; celles des deux autres
conditions.
</p>
<p>La premi&#232;re observation que nous pouvons faire est que la t&#226;che de classification de paraphrases
est une t&#226;che difficile : la meilleure performance (exactitude) obtenue par l&#8217;un des syst&#232;mes
est de 70,69 pour la condition S&#219;RES. En outre, il existe une variation importante entre les
</p>
<p>13. Nous avons utilis&#233; l&#8217;impl&#233;mentation LIBSVM (Chang et Lin, 2001).
</p>
<p>206</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>diff&#233;rentes conditions test&#233;es avec un r&#233;sultat faible pour notre classifieur de 57,67 dans la
condition POSSIBLES (cas de d&#233;saccord entre annotateurs, o&#249; un seul reconna&#238;t le statut de
paraphrase).
</p>
<p>D&#8217;une mani&#232;re plus g&#233;n&#233;rale, la technique ML_WEB et notre classifieur sont plus performants que
les autres techniques de r&#233;f&#233;rences. ML_FRONTI&#200;RES et DEPCONT ne mod&#233;lisent que des contraintes
grammaticales locales, ce qui fait qu&#8217;il n&#8217;est pas surprenant que ces informations ne permettent
pas la reconnaissance de variations s&#233;mantiques licites entre paraphrases candidates. WEBLM,
qui se limite &#224; la comparaison de scores de mod&#232;les de langue d&#233;riv&#233; du Web, appara&#238;t donc
comme une technique relativement comp&#233;titive 14, mais sa performance est peu &#233;lev&#233;e (56,79)
pour la condition SURE++. Puisque cette condition ne prend en compte que les annotations
consensuelles pour l&#8217;apprentissage et l&#8217;&#233;valuation, nous consid&#233;rons cette condition comme la
plus utile pour l&#8217;interpr&#233;tation des r&#233;sultats de ces travaux pr&#233;liminaires. Ici, notre syst&#232;me
obtient la meilleur performance, avec un avantage de 6,06 points par rapport &#224; WEBLM. Ceci
montre que la seule utilisation d&#8217;un mod&#232;le de langue, aussi bien estim&#233; soit-il, est trop limit&#233;e
pour rendre compte correctement de l&#8217;ensemble des ph&#233;nom&#232;nes de paraphrases pr&#233;sents dans
notre corpus d&#8217;&#233;valuation, ce qui confirme des r&#233;sultats pr&#233;c&#233;dents o&#249; les mod&#232;les de langue
n&#8217;&#233;taient pas issus de comptes du Web (Bannard et Callison-Burch, 2005).
</p>
<p>Finalement, la figure 4 d&#233;taille les performances atteintes par chacune des m&#233;thodes d&#8217;acquisition
de paraphrases pour chacune des 3 conditions. Il n&#8217;est tout d&#8217;abord pas surprenant que les
reformulations extraites de WICOPACO soient largement identifi&#233;es comme de bonnes paraphrases
en contexte, en particulier dans les conditions POSSIBLES et S&#219;RES++. Ces paraphrases sont le
r&#233;sultat de reformulations par des contributeurs de Wikip&#233;dia dans le contexte d&#8217;&#233;valuation, et
avaient d&#233;j&#224; &#233;t&#233; reconnues comme telles par une premi&#232;re annotatrice.
</p>
<p>WICOPACO HUMAIN PIVOTES PIVOTZH
POSSIBLES 89,33 67,00 47,33 20,66
</p>
<p>S&#219;RES 64,00 44,50 31,33 10,66
S&#219;RES++ 86,03 57,34 37,71 12,60
</p>
<p>FIGURE 4 &#8211; Performance (valeurs d&#8217;exactitude) de nos diff&#233;rentes m&#233;thodes d&#8217;acquisition pour nos
trois conditions d&#8217;&#233;valuation.
</p>
<p>Les paraphrases obtenues par collecte manuelle sur des contextes issus du Web, donc d&#8217;un con-
texte possiblement diff&#233;rent de celui de l&#8217;&#233;valuation, obtiennent une performance relativement
acceptable. Les r&#233;sultats confirment cependant le fait attendu que la substituabilit&#233; des para-
phrases d&#233;pend fortement du contexte. Par exemple, la substitution du segment de l&#8217;&#233;diteur par
publi&#233;e par les &#233;ditions dans le contexte de l&#8217;&#233;nonc&#233; &quot;Neopolis est une collection de bandes dessin&#233;es
de l&#8217;&#233;diteur Delcourt. 15&quot; permet de conserver le sens d&#8217;origine ainsi que la grammaticalit&#233; de
l&#8217;&#233;nonc&#233;. A contrario, la substitution par le segment du logiciel n&#8217;est pas adapt&#233;e &#224; ce contexte.
</p>
<p>Finalement, les paraphrases obtenues automatiquement par traduction par pivot ne sont pas
de bonne qualit&#233;. Nous notons cependant que la proximit&#233; de la langue pivot avec la langue
</p>
<p>14. Une explication peut r&#233;sider dans le fait que nos m&#233;thodes d&#8217;acquisition de paraphrases utilisant Google Translate
commme un traducteur automatique par pivot ont tendance &#224; produire des segments ayant une forte valeur de probabilit&#233;
dans le mod&#232;le de langue utilis&#233;, qui est certainement assez comparable &#224; celui utilis&#233; dans nos exp&#233;riences.
</p>
<p>15. Une r&#233;&#233;criture est extraite de l&#8217;historique de r&#233;vision de l&#8217;article &quot;Neopolis&quot; sur Wikip&#233;dia accessible sur : http:
//fr.wikipedia.org/w/index.php?title=Neopolis&amp;diff=45811975&amp;oldid=2017149.
</p>
<p>207</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>de r&#233;&#233;criture joue un r&#244;le important : l&#8217;utilisation de l&#8217;espagnol m&#232;ne ainsi &#224; de bien meilleurs
r&#233;sultats que l&#8217;utilisation du chinois 16.
</p>
<p>6 Conclusions et perspectives
</p>
<p>Nous avons pr&#233;sent&#233; dans cet article une approche de paraphrasage en contexte appliqu&#233; &#224;
la r&#233;vision de texte, un sc&#233;nario soutenu par les donn&#233;es extraites des r&#233;&#233;critures contenues
dans la Wikip&#233;dia francophone. La m&#233;thode d&#8217;identification que nous avons propos&#233;e prend en
entr&#233;e un r&#233;pertoire existant de paraphrases sous-phrastiques, et d&#233;termine par classification
automatique exploitant des donn&#233;es issues du Web si les paraphrases connues peuvent se
substituer &#224; un segment dans un contexte particulier. Nous avons simul&#233; diff&#233;rents niveaux de
qualit&#233; pour les paraphrases existantes, en exploitant des paraphrases provenant de Wikip&#233;dia,
des contributions humaines acquises dans d&#8217;autres contextes, et des paraphrases obtenues par
traduction automatique par pivot.
</p>
<p>Nos exp&#233;riences ont montr&#233; que la version actuelle de notre classifieur est plus performante que
les diff&#233;rentes techniques de r&#233;f&#233;rence utilis&#233;es lorsque l&#8217;on ne consid&#232;re que les paraphrases
obtenant des jugements consensuels dans la r&#233;f&#233;rence utilis&#233;e. Bien que ces premi&#232;res exp&#233;riences
soient positives, nous sommes conscients que leurs r&#233;sultats peuvent &#234;tre am&#233;lior&#233;s sur diff&#233;rents
aspects. Tout d&#8217;abord, il est possible d&#8217;&#233;largir l&#8217;exploration des diff&#233;rentes caract&#233;ristiques que
nous mettons en jeu dans le classifieur. Nous comptons int&#233;grer d&#8217;autres traits, dont des mod&#232;les
mettant en jeu des d&#233;pendances syntaxiques calcul&#233;es sur des donn&#233;es du Web. Nous allons
&#233;galement analyser plus finement nos r&#233;sultats afin d&#8217;identifier les cas probl&#233;matiques, dont
certains ne peuvent pas &#234;tre mod&#233;lis&#233;s sans avoir recours &#224; des connaissances du monde, ce qui
sugg&#233;rera notamment l&#8217;int&#233;gration de connaissances du domaine, &#233;ventuellement d&#233;riv&#233;es de
m&#233;ta-informations provenant des articles Wikip&#233;dia concern&#233;s. L&#8217;ensemble de ces exp&#233;riences
pourra &#234;tre conduit en plusieurs langues, les donn&#233;es utilis&#233;es et les m&#233;thodes employ&#233;es
pouvant facilement &#234;tre transpos&#233;es. Finalement, nous sommes &#233;galement int&#233;ress&#233;s par le fait
d&#8217;utiliser l&#8217;approche d&#233;crite ici comme un cadre pour l&#8217;&#233;valuation des syst&#232;mes d&#8217;acquisition de
paraphrases.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BANNARD, C. et CALLISON-BURCH, C. (2005). Paraphrasing with bilingual parallel corpora. In
Actes de ACL, Ann Arbor, USA.
</p>
<p>BARZILAY, R. et LEE, L. (2003). Learning to paraphrase : an unsupervised approach using
multiple-sequence alignment. In Actes de NAACL-HLT, Edmonton, Canada.
</p>
<p>BARZILAY, R. et MCKEOWN, K. (2001). Extracting paraphrases from a parallel corpus. In Actes de
ACL, Toulouse, France.
</p>
<p>BERNSTEIN, M. S., LITTLE, G., MILLER, R. C., HARTMANN, B., ACKERMAN, M. S., KARGER, D. R.,
CROWELL, D. et PANOVICH, K. (2010). Soylent : a word processor with a crowd inside. In
Proceedings of the ACM symposium on User interface software and technology.
</p>
<p>16. Bannard et Callison-Burch (2005) ont montr&#233; que l&#8217;utilisation simultan&#233;e de plusieurs langues pivots permettait de
diminuer de fa&#231;on importante les ph&#233;nom&#232;nes de bruit.
</p>
<p>208</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BHAGAT, R. et RAVICHANDRAN, D. (2008). Large scale acquisition of paraphrases for learning
surface patterns. In Actes de ACL-HLT, Columbus, &#201;tats-Unis.
</p>
<p>BOUAMOR, H., MAX, A. et VILNAT, A. (2011). Monolingual alignment by edit rate computation
on sentential paraphrase pairs. In Proceedings of ACL, Short Papers session, Portland, USA.
</p>
<p>BROCKETT, C. et DOLAN, W. B. (2005). Support vector machines for paraphrase identification
and corpus construction. In Proceedings of The 3rd International Workshop on Paraphrasing IWP,
Jeju Island, South Korea.
</p>
<p>CANDITO, M., CRABB&#201;, B. et DENIS, P. (2010). Statistical French dependency parsing : treebank
conversion and first results. In Proceedings of LREC, Valletta, Malta.
</p>
<p>CHANG, C.-C. et LIN, C.-J. (2001). LIBSVM : a library for support vector machines. Software
available at http://www.csie.ntu.edu.tw/~cjlin/libsvm.
</p>
<p>COHN, T., CALLISON-BURCH, C. et LAPATA, M. (2008). Constructing corpora for the development
and evaluation of paraphrase systems. Comput. Linguist., 34(4).
</p>
<p>COHN, T. et LAPATA, M. (2008). Sentence compression beyond word deletion. In Proceedings of
the 22nd International Conference on Computational Linguistics (Coling 2008), Manchester, UK.
</p>
<p>CONNOR, M. et ROTH, D. (2007). Context sensitive paraphrasing with a single unsupervised
classifier. In Proceedings of ECML, Warsaw, Poland.
</p>
<p>DEL&#201;GER, L. et ZWEIGENBAUM, P. (2009). Extracting lay paraphrases of specialized expressions
from monolingual comparable medical corpora. In Proceedings of the 2nd Workshop on Building
and Using Comparable Corpora : from Parallel to Non-parallel Corpora, Singapore.
</p>
<p>DUTREY, C., BOUAMOR, H., BERNHARD, D. et MAX, A. (2011). Paraphrases et modifications locales
dans l&#8217;historique des r&#233;visions de wikip&#233;dia. In Actes de TALN 2011, Montpellier, France.
</p>
<p>GANITKEVITCH, J., CALLISON-BURCH, C., NAPOLES, C. et VAN DURME, B. (2011). Learning sentential
paraphrases from bilingual parallel corpora for text-to-text generation. In Proceedings of EMNLP,
Edinburgh, UK.
</p>
<p>KOK, S. et BROCKETT, C. (2010). Hitting the Right Paraphrases in Good Time. In Proceedings of
NAACL, Los Angeles, USA.
</p>
<p>LANDIS, J. et KOCH, G. (1977). The measurement of observer agreement for categorical data.
Biometrics, pages 159&#8211;174.
</p>
<p>LAPATA, M. et KELLER, F. (2005). Web-based Models for Natural Language Processing. ACM
Transactions on Speech and Language Processing, 2(1):1&#8211;31.
</p>
<p>MADNANI, N. et DORR, B. J. (2010). Generating Phrasal and Sentential Paraphrases : A Survey
of Data-Driven Methods . Computational Linguistics, 36(3).
</p>
<p>MADNANI, N., RESNIK, P., DORR, B. et SCHWARTZ, R. (2008). Are multiple reference transla-
tions necessary ? investigating the value of paraphrased reference translations in parameter
optimization. In Proceedings of AMTA, Waikiki, Hawai&#8217;i.
</p>
<p>MAX, A. (2004). From controlled document authoring to interactive document normalization.
In Proceedings of COLING, Geneva, Switzerland.
</p>
<p>MAX, A. et WISNIEWSKI, G. (2010). Mining Naturally-occurring Corrections and Paraphrases
from Wikipedia&#8217;s Revision History. In Proceedings of LREC, Valletta, Malta.
</p>
<p>MAX, A. et ZOCK, M. (2008). Looking up phrase rephrasings via a pivot language. In Proceedings
of the COLING Workshop on Cognitive Aspects of the Lexicon, Manchester, United Kingdom.
</p>
<p>209</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>MCCARTHY, D. et NAVIGLI, R. (2009). The english lexical substitution task. Language Resources
and Evaluation, 43(2).
</p>
<p>MUTTON, A. (2006). Evaluation of sentence grammaticality using Parsers and a Support Vector
Machine. Th&#232;se de doctorat, Macquarie University.
</p>
<p>ONISHI, T., UTIYAMA, M. et SUMITA, E. (2010). Paraphrase lattice for statistical machine transla-
tion. In Proceedings of the ACL 2010 Conference, Short Paper session, Uppsala, Sweden.
</p>
<p>PANG, B., KNIGHT, K. et MARCU, D. (2003). Syntax-based alignement of multiple translations :
Extracting paraphrases and generating new sentences. In Actes de NAACL-HLT, Edmonton,
Canada.
</p>
<p>PAS&#199;A, M. et DIENES, P. (2005). Aligning Needles in a Haystack : Paraphrase Acquisition Across
the Web. In Proceedings of IJCNLP, Jeju Island, South Korea.
</p>
<p>PETROV, S. et KLEIN, D. (2007). Improved inference for unlexicalized parsing. In Proceedings of
NAACL-HLT, Rochester, USA.
</p>
<p>QUIRK, C., BROCKETT, C. et DOLAN, W. B. (2004). Monolingual machine translation for paraphrase
generation. In Proceedings of EMNLP, volume 149, Barcelona, Spain.
</p>
<p>RESNIK, P., BUZEK, O., HU, C., KRONROD, Y., QUINN, A. et BEDERSON, B. B. (2010). Improving
translation via targeted paraphrasing. In Proceedings of the 2010 Conference on Empirical Methods
in Natural Language Processing, Cambridge, MA.
</p>
<p>SCHMID, H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings of
International Conference on New Methods in Language Processing, Manchester, UK.
</p>
<p>SCHROEDER, J., COHN, T. et KOEHN, P. (2009). Word Lattices for Multi-Source Translation. In
Proceedings of EACL, Athens, Greece.
</p>
<p>SNOVER, M., MADNANI, N., DORR, B. J. et SCHWARTZ, R. (2010). TER-Plus : paraphrase, semantic,
and alignment enhancements to Translation Edit Rate. Machine Translation, 23(2-3).
</p>
<p>WANG, K., THRASHER, C., VIEGAS, E., LI, X. et HSU, B.-j. P. (2010). An Overview of Microsoft Web
N-gram Corpus and Applications. In Proceedings of the NAACL-HLT Demonstration Session, Los
Angeles, USA.
</p>
<p>ZHAO, S., LAN, X., LIU, T. et LI, S. (2009). Application-driven Statistical Paraphrase Generation. In
Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing of the AFNLP, Suntec, Singapore.
</p>
<p>ZHAO, S., LIU, T., YUAN, X., LI, S. et ZHANG, Y. (2007). Automatic acquisition of context-specific
lexical paraphrases. In Proceedings of IJCAI, Hyderabad, India.
</p>
<p>ZHAO, S., WANG, H., LIU, T., et LI, S. (2010). Leveraging multiple mt engines for paraphrase
generation. In Proceedings of COLING, Beijing, China.
</p>
<p>ZHU, Z., BERNHARD, D. et GUREVYCH, I. (2010). A monolingual tree-based translation model for
sentence simplification. In Proceedings of COLING, Beijing, China.
</p>
<p>210</p>

</div></div>
</body></html>