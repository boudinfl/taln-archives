Validation sur le Web de reformulations locales:
application a la Wikipédia

Houda Bouamor Aurélien Max Gabriel Illouz Anne Vilnat
LIMSI—CNRS
Univ. Paris Sud 11
Orsay, France
prenom.nom@limsi . fr

RESUME
Ce travail présente des expériences initiales en validation de paraphrases en contexte. Les
révisions de W1'kipédia nous servent de dornaine d’évaluation : pour un énoncé ayant connu une
courte révision dans l’encyc1opédie, nous disposons d’un ensemble de réécritures possibles, parmi
lesquelles nous cherchons a identiﬁer celles qui correspondent 21 des paraphrases valides. Nous
abordons ce probléme comme une tache de classiﬁcation fondée sur des informations issues du
Web, et parvenons a améliorer la performance de plusieurs techniques simples de référence.

AB STRACT
Assisted rephrasing for Wikipedia contributors through Web-based validation

This works describes initial experiments on the validation of paraphrases in context. Wi.kipedia’s
revisions are used : we assume that a set of possible rewritings are available for a given phrase
that has been rewritten in the encyclopedia’s revision history, and we attempt to ﬁnd the subset
of those rewritings that can be considered as valid paraphrases. We tackle this problem as a
classication task which we provide with features obtained from Web data. Our experiments show
that our system improves performance over a set of simple baselines.

MOTS-CLES : paraphrase, Wi.kipédia, aide 5 la rédaction.
KEYWORDS: paraphrasing, Wikipedia, authoring aids.

1 Introduction

Il existe plusieurs scénarios dans lesquels il est souhaitable de pouvoir faire produire du texte par
la machine. Ce probléme a traditionnellement été abordé comme une téiche de génération de texte
‘a partir de concepts. Toutefois, ces besoins s’appliquent parfois ‘a des cas o1‘1 un nouveau texte
devrait étre dérivé de certains textes existants, par exemple lorsqu’i1 s’agit de transformer un texte
aﬁn qu’i1s aient certaines propriétés souhaitables pour un usage particulier (Zhao et al., 2009). Par
exemple, on peut souhaiter qu’un texte soit condensé (Cohn et Lapata, 2008), adapté 21 certains
proﬁls de lecteur (Zhu et al., 2010), conforme a certaines normes spéciﬁques (Max, 2004), voire
méme simplement plus adapté pour des taches de traitement automatique ultérieures.

Le mécanisme de réécriture de texte doit donc produire un texte dont le sens est compatible
avec la déﬁnition de la téiche 5 accomplir, tout en garantissant que celui-ci demeure grammatical.

Actes de la conférence onjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 197-210,
Grenoble, 4 au 8 juin 2012. ©2012 ATAI.A 8: AFCP

197

La complexité de la génération texte-c‘1-texte, par opposition ‘a la génération concepts-c‘1-texte,
provient essentiellement du fait que la correspondance sémantique entre deux textes est difﬁcile
a controler, car les réécritures mises en jeu sont trés dépendantes du contexte. En effet, 1a grande
diversité des techniques d’acquisiu'on de paraphrases sous-phrastiques (Madnani et Dorr, 2010),
la polysémie de ces unités linguistiques ainsi que les contraintes pragmatiques associées ‘a leur
substitution font qu’il est impossible de garantir que des paires de paraphrases candidates seront
substituables quel que soit le contexte de réécriture. Ce probléme a été déj‘a décrit au niveau
lexical (Zhao et al., 2007; McCarthy et Navigli, 2009) ; la validation automatique en contexte de
reformulaﬁons de segments demeure une question fondamentale pour la réécriture de texte.

Dans ce travail, nous abordons le probléme sous l’angle d’un paraphrasage cible’ 1, déﬁni comme
la réécriture d’un segment d’un énoncé. Bien que ce probléme soit plus simple que la réécriture
d’une phrase complete, son étude se justiﬁe par la nécessite de bien comprendre ce niveau moins
complexe avant d’aborder la réécriture d’unités plus étendues, ce qui en outre facilite la tache
complexe de l’évaluation.

Nous présentons ici un scénario en révision interactive de textes dans lequel des paraphrases sous-
phrastiques doivent étre proposées en tenant compte du contexte. Les paraphrases candidates
considérées sont obtenues a partir d’un répertoire existant, et sont validées en contexte ‘a
l’aide d’informations obtenues sur le Web. Les expériences que nous avons menées ciblent plus
particuliérement les contributeurs de l’encyclopédie Wikipédia dans leurs taches de révision des
articles. Nous avons pour cela utilisé un ensemble de segments ayant fait l’objet de réécritures
dans l’historique des articles de Wikipédia, que nous substituons par des paraphrases connues a
l’avance. Etant donné la grande variété de segments possibles et de leurs paraphrases, nous ne
nous appuyons pas sur des modéles de substituabilité préétablis, mais nous les construisons 61 la
volée a partir du Web.

Dans cet article, nous allons tout d’abord décrire la tache de révision de texte sous forme de
paraphrasage ciblé (section 2). Nous passerons ensuite en revue les principaux travaux précédents
portant sur l’acquisition de paraphrases sous-phrastiques et décrirons les sources de connaissances
que nous avons utilisées dans ce travail (section 3). Nous détaillerons ensuite notre méthode de
calcul des modéles de substitution de segments en contexte exploitant des informations issues
du Web (section 4). Les expériences menées pour valider les paraphrases contenues dans le
répertoire existant et leurs résultats seront finalement présentés (section 5). Notre article se
conclura par une discussion de ces résultats et une présentation des principales voies de recherche

(6)-

2 Paraphrasage ciblé pour la révision de texte

La reformulation d’un énoncé, ou d’un segment plus précis, est une activité importante en révision
de texte. Certaines modiﬁcations locales ont ainsi vocation a améliorer sa qualité générale, en le
rendant par exemple plus facile d’acces (Zhu et al., 2010) ou en l’adaptant au niveau d’expertise
de ses lecteurs (Deléger et Zweigenbaum, 2009). Les modiﬁcations de ce type, qui n’altérent pas le
sens des textes, incluent non seulement la synonymie lexicale mais également des transformations
lexico-syntaxiques plus complexes.

1. Ce tenne est uﬁlisé par Resnik et :11. (2010) pour décrire l’obtention (manuelle) de paraphrases pour des segments
jugés difﬁciles £1 traduire.

198

différentes conditions testées avec un résultat faible pour notre classiﬁeur de 57,67 dans la
condition Poss1BLEs (cas de désaccord entre annotateurs, o1‘1 un seul reconnait le statut de
paraphrase) .

D’une maniére plus générale, la technique ML_WEB et notre classiﬁeur sont plus performants que
les autres techniques de références. ML_FRoNr1EREs et DEPCONT ne modélisent que des contraintes
grammaticales locales, ce qui fait qu’il n’est pas surprenant que ces informations ne permettent
pas la reconnaissance de variations sémantiques licites entre paraphrases candidates. WEBLM,
qui se limite a la comparaison de scores de modéles de langue dérivé du Web, apparait donc
comme une technique relativement compétitive 14, mais sa performance est peu élevée (56,79)
pour la condition SURE++. Puisque cette condition ne prend en compte que les annotations
consensuelles pour l’apprentissage et l’évaluation, nous considérons cette condition comme la
plus utile pour l’interprétat1'on des résultats de ces travaux préliminaires. Ici, notre systéme
obtient la meilleur performance, avec un avantage de 6,06 points par rapport ‘a WEBLM. Ceci
montre que la seule utilisation d’un modéle de langue, aussi bien estimé soit-il, est trop limitée
pour rendre compte correctement de l’ensemble des phénoménes de paraphrases présents dans
notre corpus d’évaluation, ce qui confirme des résultats précédents o1‘1 les modéles de langue
n’étaient pas issus de comptes du Web (Bannard et Callison-Burch, 2005).

Finalement, la ﬁgure 4 détaille les performances atteintes par chacune des méthodes d’acquisition
de paraphrases pour chacune des 3 conditions. Il n’est tout d’abord pas surprenant que les
reformulations extraites de W1CoPACo soient largement identiﬁées comme de bonnes paraphrases
en contexte, en particulier dans les conditions Poss1BLEs et SI"JREs++. Ces paraphrases sont le
résultat de reformulations par des contributeurs de Wi.kipédia dans le contexte d’évaluation, et
avaient déja été reconnues comme telles par une premiere annotatrice.

WICOPACO HUMAIN PIVOTES PIVOTZH

Poss1BLEs 89,33 67,00 47,33 20,66
SI‘JREs 64,00 44,50 3 1,33 10,66

SI‘JREs++ 86,03 57,34 37,71 12,60

FIGURE 4 — Performance (valeurs d’exactitude) de nos différentes méthodes d’acquisition pour nos
trois conditions d’évaluation.

Les paraphrases obtenues par collecte manuelle sur des contextes issus du Web, donc d’un con-
texte possiblement différent de celui de l’évaluation, obtiennent une performance relativement
acceptable. Les résultats conﬁrment cependant le fait attendu que la substituabilité des para-
phrases dépend fortement du contexte. Par exemple, la substitution du segment de l’e’diteur par
publiée par les éditions dans le contexte de l’énoncé “Neopolis est une collection de bandes dessinées

de l’éditeur Delcourt. 15" permet de conserver le sens d’origine ainsi que la grammaticalité de

l’énoncé. A contrario, la substitution par le segment du logiciel n’est pas adaptée a ce contexte.

Finalement, les paraphrases obtenues automatiquement par traduction par pivot ne sont pas
de bonne qualité. Nous notons cependant que la proximité de la langue pivot avec la langue

14. Une explication peut résider dans le fait que nos méthodes d’acquisition de paraphrases uﬁlisant Google Translate
commme un traducteur automatique par pivot ont tendance a produire des segments ayant une forte valeur de probabilité
dans le modele de langue utilisé, qui est certainement assez comparable £1 celui utilisé dans nos experiences.

15. Une réécriture est ex1raite de Phistorique de révision de Particle "Neopolis" sur Wikipédia accessible sur : ht tp:
//fr . wikipedia . org/w/index . php?tit1e=Neopo1is&diff=45 8 1 1 975 &o1did=2 0 1 7 1 4 9.

207

de réécriture joue un role important : l’utilisation de l’espagnol mene ainsi ‘a de bien meilleurs

résultats que l’utilisation du chinois 15.

6 Conclusions et perspectives

Nous avons présenté dans cet article une approche de paraphrasage en contexte appliqué ‘a
la révision de texte, un scénario soutenu par les données extraites des réécritures contenues
dans la Wi.kipédia francophone. Ia méthode d’ident1'ﬁcation que nous avons proposée prend en
entrée un répertoire existant de paraphrases sous-phrastiques, et détermine par classiﬁcation
automatique exploitant des données issues du Web si les paraphrases connues peuvent se
substituer ‘a un segment dans un contexte particulier. Nous avons simulé différents niveaux de
qualité pour les paraphrases existantes, en exploitant des paraphrases provenant de Wikipédia,
des contributions humaines acquises dans d’autres contextes, et des paraphrases obtenues par
traduction automatique par pivot.

Nos expériences ont montré que la version actuelle de notre classiﬁeur est plus performante que
les différentes techniques de référence utilisées lorsque l’on ne considere que les paraphrases
obtenant desjugements consensuels dans la référence utilisée. Bien que ces premieres expériences
soient positives, nous sommes conscients que leurs résultats peuvent étre améliorés sur différents
aspects. Tout d’abord, il est possible d’élargir l’explorau'on des différentes caractéristiques que
nous mettons en jeu dans le classiﬁeur. Nous comptons intégrer d’autres traits, dont des modéles
mettant en jeu des dépendances syntaxiques calculées sur des données du Web. Nous allons
également analyser plus finement nos résultats aﬁn d’identifier les cas problématiques, dont
certains ne peuvent pas étre modélisés sans avoir recours a des connaissances du monde, ce qui
suggérera notamment l’intégration de connaissances du domaine, éventuellement dérivées de
méta-informations provenant des articles Wi.kipédia concernés. I.’ensemble de ces expériences
po11rra étre conduit en plusieurs langues, les données utilisées et les méthodes employées
pouvant facilement étre transposées. Finalement, nous sommes également intéressés par le fait
d’utiliser l’approche décrite ici comme un cadre pour l’évaluation des systémes d’acquisition de
paraphrases.

Références

BANNARD, C. et CALLIsoN-BURCH, C. (2005). Paraphrasing with bilingual parallel corpora. In
Actes de ACL, Ann Arbor, USA.

BARZILAY, R. et LEE, L. (2003). Leaming to paraphrase : an unsupervised approach using
multiple-sequence alignment. In Actes de NAACL-HLT, Edmonton, Canada.

BARZILAY, R. et McKEowN, K. (2001). Extracting paraphrases from a parallel corpus. In Actes de
ACL, Toulouse, France.

BERNSTEIN, M. S., LITTLE, G., MILLER, R. C., HARTMANN, B., ACKERMAN, M. S., KARGER, D. R.,
CROWELL, D. et PANovIcH, K. (2010). Soylent : a word processor with a crowd inside. In
Proceedings of the ACM symposium on User interface software and technology.

16. Bannard et Callison-Burch (2005) ont montré que 1’u1j]1‘sation simultanée de plusieurs langues pivots pennettait de
diminuer de fagon importante les phénoménes de bruit.

208

BHAGAT, R. et RAVICHANDRAN, D. (2008). large scale acquisition of paraphrases for learning
surface patterns. In Actes de ACL-HLT, Columbus, Etats-Unis.

BOUAMOR, H., MAX, A. et VILNAT, A. (2011). Monolingual alignment by edit rate computation
on sentential paraphrase pairs. In Proceedings ofACL, Short Papers session, Portland, USA.

BROCKETT, C. et DoLAN, W. B. (2005). Support vector machines for paraphrase identiﬁcation
and corpus construction. In Proceedings of The 3rd International Workshop on Paraphrasing IWP,
Jeju Island, South Korea.

CANDITO, M., CRABBE, B. et DENIS, P. (2010). Statistical French dependency parsing : treebank
conversion and ﬁrst results. In Proceedings of LREC, Valletta, Malta.

CHANG, C.-C. et LIN, C.-J. (2001). LIBSVIVI: a library for support vector machines. Software
available at http : / /www . cs ie . ntu . edu . tw/~cjlin/libsvm.

COHN, 'I‘., CALLISON-BURCH, C. et LAPATA, M. (2008). Constructing corpora for the development
and evaluation of paraphrase systems. Comput. Linguist., 34(4).

COHN, 'I'. et LAPATA, M. (2008). Sentence compression beyond word deletion. In Proceedings of
the 22nd International Conference on Computational Linguistics (Coling 2008), Manchester, UK.
CONNOR, M. et Rom, D. (2007). Context sensitive paraphrasing with a single unsupervised
classiﬁer. In Proceedings of ECML, Warsaw, Poland.

DELEGER, L. et ZWEIGENBAUM, P. (2009). Extracting lay paraphrases of specialized expressions
from monolingual comparable medical corpora. In Proceedings of the 2nd Workshop on Building
and Using Comparable Corpora : from Parallel to Non-parallel Corpora, Singapore.

DUTREY, C., BOUAMOR, H., BERNHARD, D. et MAX, A. (2011). Paraphrases et modiﬁcations locales
dans l’historique des révisions de wikipédia. In Actes de TALN 2011, Montpellier, France.
GANITKEVITCH, J., CALL1soN-BURCH, C., NAPOLES, C. et VAN DURME, B. (2011). Learning sentential
paraphrases from bilingual parallel corpora for text-to-text generation. In Proceedings of EMNLP,
Edinburgh, UK.

KoK, S. et BROCKETT, C. (2010). Hitting the Right Paraphrases in Good Time. In Proceedings of
NAACL, Los Angeles, USA.

LAND1s, J . et KocH, G. (1977). The measurement of observer agreement for categorical data.
Biometrics, pages 159-174.

LAPATA, M. et KELLER, F (2005). Web-based Models for Natural Language Processing. ACM
Transactions on Speech and Language Processing, 2(1):1—31.

MADNANI, N. et DORR, B. J. (2010). Generating Phrasal and Sentential Paraphrases : A Survey
of Data-Driven Methods . Computational Linguistics, 36(3).

MADNAN1, N., RESNIK, R, DORR, B. et SCHWARTZ, R. (2008). Are multiple reference transla-
tions necessary? investigating the value of paraphrased reference translations in parameter
optimization. In Proceedings ofAMTA, Waikiki, Hawai’i.

MAX, A. (2004). From controlled document authoring to interactive document normalization.
In Proceedings of COLING, Geneva, Switzerland.

MAX, A. et WISNIEWSKI, G. (2010). Mining Naturally-occurring Corrections and Paraphrases
from Wil<ipedia’s Revision History. In Proceedings of LREC, Valletta, Malta.

MAX, A. et Zoc1<, M. (2008). Looking up phrase rephrasings via a pivot language. In Proceedings
of the COLING Workshop on Cognitive Aspects of the Lexicon, Manchester, United Kingdom.

209

MCCARTHY, D. et NAVIGLI, R. (2009). The english lexical substitution task. Language Resources
and Evaluation, 43 (2).

MUTTON, A. (2006). Evaluation of sentence grammaticality using Parsers and a Support Vector
Machine. Thése de doctorat, Macquarie University.

ONISHI, 'I'., UTIYAMA, M. et SUMITA, E. (2010). Paraphrase lattice for statistical machine transla-
tion. In Proceedings of the ACL 2010 Conference, Short Paper session, Uppsala, Sweden.

PANG, B., KNIGHT, K. et MARCU, D. (2003). Syntax-based alignement of multiple translations :
Extracting paraphrases and generating new sentences. In Actes de NAACL-HLT, Edmonton,
Canada.

PASCA, M. et DIENES, P. (2005). Aligning Needles in a Haystack : Paraphrase Acquisition Across
the Web. In Proceedings of IJCNLP, Jeju Island, South Korea.

PETROV, S. et KLEIN, D. (2007). Improved inference for unlexicalized parsing. In Proceedings of
NAACL-HLT, Rochester, USA.

QUIRK, C., BROCKETT, C. et DoLAN, W. B. (2004). Monolingual machine translation for paraphrase
generation. In Proceedings of EMNLP, volume 149, Barcelona, Spain.

RESNIK, R, BUZEK, 0., HU, C., KRONROD, Y., QUINN, A. et BEDERSON, B. B. (2010). Improving
translation via targeted paraphrasing. In Proceedings of the 2010 Conference on Empirical Methods
in Natural Language Processing, Cambridge, MA.

SCHMID, H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings of
International Conference on New Methods in Language Processing, Manchester, UK.

SCHROEDER, J., CoHN, T. et KOEHN, P. (2009). Word Lattices for Multi-Source Translation. In
Proceedings of EACL, Athens, Greece.

SNOVER, M., MADNANI, N., Donn, B. J. et SCHWARTZ, R. (2010). TER-Plus : paraphrase, semantic,
and alignment enhancements to Translation Edit Rate. Machine Translation, 23 (2-3).

WANG, K., THRASHER, C., VIEGAS, E., L1, X. et HsU, B.-j. P. (2010). An Overview of Microsoft Web
N-gram Corpus and Applications. In Proceedings of the NAACL-HLT Demonstration Session, Los
Angeles, USA.

ZHAo, S., LAN, X., LIU, T. et L1, S. (2009). Application-driven Statistical Paraphrase Generation. In
Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing of the AFNLP, Suntec, Singapore.

ZHAO, S., LIU, 'I‘., YUAN, X., L1, S. et ZHANG, Y. (2007). Automatic acquisition of context-speciﬁc
lexical paraphrases. In Proceedings of IJCAI, Hyderabad, India.

ZHAO, S., WANG, H., LIU, T., et L1, S. (2010). Leveraging multiple mt engines for paraphrase
generation. In Proceedings of COLING, Beijing, China.

21-10, Z., BERNHARD, D. et GUREVYCH, I. (2010). A monolingual tree-based translation model for
sentence simpliﬁcation. In Proceedings of COLING, Beijing, China.

210

On trouve notamment de telles reformulations dans les historiques de révision de textes, qui
sont désormais disponibles en grandes quantités avec l’émergence de ressources collaboratives
sur le Web telles que l’encyclopédie Wi.kipédia. L’historique des révisions des articles de cette
ressource constitue en effet une source importante de phénoménes de réécriture naturelle. L’étude
de Dutrey et aL (2011) a notamment montré que cet historique contient une variété importante
de phénomenes de reformulation, dont de nombreuses paraphrases. Cette étude a également
montré, au travers d’une tentative d’identiﬁcation automatique ‘a base de regles, les difficultés
pour parvenir a une bonne couverture de l’ensemble des phénoménes paraphrastiques présents.

Peu de travaux, ont, ‘a notre connaissance, porté surl’ut1'lisation du paraphrasage contextuel
dans le cadre de l’aide ‘a la rédaction. Max et Zock (2008) présentent une méthode proposant
aux rédacteurs des paraphrases sous-phrastiques candidates pour les segments qu’ils souhaitent
reformuler. L’approche utilisée pour la génération des paraphrases est fondée sur l’équivalence de
traduction (Bannard et Callison-Burch, 2005). Les travaux de Bernstein et aL (2010) portent eux
sur l’externalisat1'on de diverses taches d’édition de texte, dont la révision, via le crowdsourcing.

Par ailleurs, la réécriture d’un texte peut étre destinée plus spécifiquement ‘a une application
automatique. Dans (Resnik et al., 2010), des reformulations pour des segments jugés difﬁciles a
traduire sont acquises via le crowdsourcing : des contributeurs monolingues de la langue source
proposent ainsi des reformulations en contexte pour ces unités 2. les reformulations collectées
sont ensuite utilisées en entrée dans un systeme de traduction automatique, qui peut ainsi
bénéﬁcier de la variété d’expressions pour produire de meilleures traductions (Schroeder et al.,
2009). Par exemple, le segment une optique festive dans Eusage intervient alors dans une optique
festive peut étre réécrit en : 1) un cadre festif, 2) une perspective de féte. Ces réécritures sont
grammaticalement correctes et ont des signiﬁcations raisonnablement proches de la formulation
d’origine.

Outre la reformulation des segments de texte, la réécriture d’énoncés a aussi été ‘a l’origine de
plusieurs travaux (Barzilay et Lee, 2003; Quirk et al., 2004; Zhao et al., 2010; Ganitkevitch
et aL, 2011). Cependant, celle-ci pose de nombreux autres défis, notamment au niveau de
l’évaluation des reformulations produites. Le jugement par des humains devient alors encore plus
complexe et n’autorise pas des distinctions ﬁnes ni des accords inter-annotateurs satisfaisants.
La génération de paraphrases d’énoncés peut toutefois étre évaluée indirectement dans le cadre
de leur utilisation dans une application plus complexe. Par exemple, Madnani et al. (2008)
parviennent a améliorer les performances d’un systéme de traduction automatique statistique en
fournissant des paraphrases automatiques des traductions de référence lors de l’apprentissage
des paramétres du systéme. Cependant, les améliorations observées n’indiquent pas clairement
les liens avec la qualité des paraphrases utilisées.

Nous abordons dans ce travail la tache plus modeste de paraphrasage sous-phrastique appliqué
‘a la révision de texte. Aﬁn d’éviter tout biais, nous utilisons des réécritures écologiques (que
nous entendons ici comme : produites naturellement) extraites d’une mémoire de rédaction
des articles de Wi.kipédia. Nous utilisons pour cela le corpus W1CoPACo (Max et Wisniewski,
2010), qui contient de nombreux phénomenes de réécriture, dont de nombreuses instances
de reformulations lexicales, syntaxiques et sémantiques (Dutrey et al., 2011). Ce demier type
de reformulation est illustré dans l’exemple suivant, ou le remplacement du segment un mode
d’expression par sa paraphrase possible une ﬁgure de rhe’torique permet de préciser et d’afﬁner le

2. Nous notons toutefois que les contributeurs ne regoivent aucune indication directe de 1’uti1ité des reformulations
qu’i1s proposent.

199

sens voulu par le contributeur initial :

Eantiphrase est [un mode d’expression —> une ﬁgure de rhétorique] consistant E1 dire Ze contraire
de ce que l’on pense.

Ce corpus est pertinent ‘a plusieurs titres pour la tache que nous visons. Tout d’abord, le fait
qu’il contienne des réécritures obtenues hors du cadre d’expériences offre une source riche et
intéressante d’unités textuelles réécrites en contexte. De plus, les instances de réécriture o1‘1le
sens n’a pas été modiﬁé offrent directement une paraphrase candidate qui peut étre considérée
comme correcte, donnée pouvant s’avérer utile pour l’apprentissage automatique du processus de
validation en contexte.

3 Acquisition de paraphrases sous-phrastiques

La disponibilité grandissante de masses de données textuelles a rendu possible un grand nom-
bre de travaux en acquisition et en génération de paraphrases (Madnani et Dorr, 2010). Les
techniques proposées apparaissent néanmoins assez fortement liées aux types de ressources
auxquelles elles s’appliquent. Les types de corpus utilisés pour sont principalement :

0 des paires de paraphrases d’énoncés (corpus monolingues paralléles), qui pertnettent
d’obtenir des paraphrases précises, mais en faible quantité (Barzilay et McKeown, 2001;
Pang et al., 2003; Cohn et aL, 2008; Bouamor et aL, 2011) ;

0 des paires d’énoncés en relation de traduction (corpus multilingues paralléles), qui permet-
tent de générer de nombreuses paraphrases candidates (Bannard et CaJJison-Burch, 2005; Kok
et Brockett, 2010) ;

0 des paires d’énoncés en relation partielle (corpus monolingues paralléles), qui pertnettent
sur le principe d’acquérir de nombreuses paraphrases (Barzilay et Lee, 2003 ; Pasga et Dienes,
2005 ; Bhagat et Ravichandran, 2008; Deléger et Zweigenbaum, 2009).

Bien que la précision de ces techniques d’acquisition peut se mesurer sur la base d’une référence
attendue portant sur une collection de paires d’énoncés (Cohn et al., 2008), il est plus utile de
pouvoir la mesurer au travers de la question de substituabilibé en contexte, laquelle a déja été
abordée au niveau lexical (Connor et Roth, 2007; Zhao et al., 2007) oil elle a fait l’objet de
campagnes d’évaluation (McCarthy et Navigli, 2009). Celle-ci pose des déﬁs supplémentaires,
d1"1s au fait que les segments sont plus rares que les mots en corpus.

4 Validation contextuelle sur le Web

4.1 Cadre d’évaluation

Le présent travail porte sur la tache de validation automatique de paraphrases sous-phrastiques
en contexte. Pour cela, nous avons eu recours a un répertoire existant de paires de paraphrases.
Comme décrit plus haut, nous avons utilisé le corpus W1CoPACo comme corpus de reformulations
sous-phrastiques naturelles. La réécriture contenue dans cette ressource peut étre utilisée comme
paraphrase potentielle. Afin d’obtenir d’autres paraphrases candidates de différentes qualités,
nous avons utilisé deux autres méthodes d’acquisition, qui foumiront des paraphrases aux

200

instances extraites de W1CoPACo qui ne seront pas nécessairement substituables en contexte :
a) une traduction automatique par pivot, et b) une acquisition manuelle de paraphrases.

La génération de paraphrases par traduction s’effectue simplement en traduisant automatique-
ment un segment dans une langue pivot, puis en le rétrotraduisant dans la langue d’origine, et
en retenant la premiere hypothese différente du segment d’origine. Si cette technique n’offre
aucune garantie sur la qualité des résultats, elle est aisée ‘a mettre en oeuvre et produit des
résultats variés. En outre, l’utilisation d’une langue pivot proche de la langue d’origine augmente
la probabilité d’obtem'r de bonnes paraphrases (ceci sera étudié lors de nos expériences, décrites
dans la section 5).

Nous avons déﬁni l’acquisition manuelle de paraphrases de la facon suivante : un corpus d’extraits
de documents du Web contenant les segments a réécrire est tout d’abord constitué, en s’assurant
que ce corpus ne contient pas de données provenant de Wikipédia. Pour chaque segment a réécrire
dans ce corpus, des locuteurs natifs du francais proposent via une interface web une réécriture
possible. Ainsi, les contextes utilisés pour faire l’acquisition de paraphrases des segments sont
possiblement différents de ceux, extraits de W1CoPACo, sur lesquels portera l’évaluation : notre
systéme de validation en contexte aura donc a considérer des paraphrases potentiellementvalides 3
mais qui ne le sont pas dans le contexte d’une réécriture particuliére.

Ces deux méthodes, dont la mise en oeuvre est aisée, nous permettent de simuler 1a disponibilité
d’un répertoire existant de paraphrases sous-phrastiques, qui nous servira pour l’évaluation de la
performance de notre technique de validation en contexte.

4.2 Classification automatique de réécritures en contexte

Nous décrivons maintenant l’approche que nous proposons pour réaliser une validation de
réécritures en contexte, fondée sur une classiﬁcation binaire exploitant des modeles calculés ‘a
partir d’informations du Web. Le recours au Web semble indispensable : seule une telle échelle
nous permet d’accéder a des exemple en nombre sufﬁsants pour certains segments. En outre, il a
été montré qu’un certain nombre d’applications de Traitement Automatique des Langues peuvent
étre améliorées grace a l’exploitation de fréquences de n-grammes sur le Web (Lapata et Keller,
2005).

Considérant un ensemble de contextes de réécritures pour des segments ainsi qu’un répertoire ex-
istant contenant des paraphrases pour ces segments, notre tache consiste a classer (i.e. paraphrase
vs. pas paraphrase) chaque paraphrase possible pour chaque contexte original. Une instanciation
concréte possible de cette tache est la proposition de Max et Zock (2008), ou de telles reformula-
tions candidates sont présentées dans un ordre décroissant de pertinence ‘a un utilisateur d’un
éditeur de texte, et donc éventuellement lors de la révision d’un article de Wikipédia.

La t-ache d’identificau'on automatique de paraphrases a été déj‘a abordée par classiﬁcation
automatique dans des travaux précédents, en utilisant des modeles calculés sur des corpus
collectés (Brockett et Dolan, 2005) et sur des documents issus du Web (Zhao et al., 2007).
Cependant, ces travaux se sont limités ‘a l’identification de paraphrases lexicales (McCarthy et
Navigli, 2009). Une difﬁculté importante est que certains mots sont absents ou trés peu fréquents

3. On les suppose ici valides parce que obtenues par réécriture manuelle d’un segment dans un texte. Ceci repose
cependant forternent sur la capacité de nos contributeurs natifs 21 bien réaliser la téche dernandée.

201

dans les index des moteurs de recherche, et a fortiori dans des corpus spécialisés, difﬁculté qui
s’ampliﬁe lorsque l’on considére des segments. 4

De facon analogue aux travaux de Brockett et Dolan (2005), nous considérons l’identification
de paraphrases comme une tache de classiﬁcation : étant donné un segment d’origine s dans le
contexte d’une phrase p, nous cherchons a déterminer si une paraphrase candidate s’ serait une
paraphrase grammaticale de s dans le contexte de p. Nous avons abordé ce probleme avec un
classiﬁeur de type séparateur a vaste marge (SVM) exploitant les traits décrits ci-dessous.

Distance d’édition Les approches les plus répandues en calcul de perﬁnence d’un document
relativement ‘a une requéte exploitent des mesures de similarité de surface, qui peuvent dans
certains cas étre de bons indicateurs de proximité sémantique. Un co1"1t de transformation entre
chaines de caractéres peut par exemple étre celui donné par la mesure TER (Snover et al., 2010),
initialement développée pour mesurer la similarité entre une hypothese de traduction et une
traduction de référence. Cette mesure se base sur des opérations d’édition (substitution, déplace-
ment, insertion, suppression) plus informatives que les méthodes basées sur des intersections
lexicales5. Nous effectuons en outre ce calcul sur les lemmes plut6t que sur les formes de surface,
que nous avons obtenus a l’aide du TREETAGGER (Schmid, 1994) 5. Nous retenons donc le score
suivant, calculé entre un segment d’origine segm-g et une paraphrase segp,,,,,, ou la fonction Lem
produit une forme lemmatisée de son argument :

hedit = TER(Lem(5egarig): I-em(5egpara)) (1)

Il convient de noter que, contrairement aux autres modéles, celui-ci ne dépend pas d’informations
provenant du Web.

Score de modéle de langue La vraisemblance d’une phrase peut étre un relativement bon
indicateur de sa grammaticalité locale (Mutton, 2006). Les probabilités données par un modéle
de langue peuvent désormais étre obtenues a l’aide de comptes provenant du Web. Nous avons
pour cela utilisé le Service Web N-gram de Microsoft (Wang et al., 2010) dans sa déclinaison a des
ﬁns de recherche 7. Aﬁn de pouvoir utiliser correctement ce service sur des textes francais, nous
avons dﬁ supprimer tous les diacritiques : un examen précis des paraphrases candidates classées
a montré que cette transformation, bien qu’abérante, nous a permis d’obtenir des résultats
cohérents. 8

4. Nous faisons cependant Phypothése que des segments absents ou trés peu fréquents sur le Web présentent un
intérét moindre pour la réécriture, et n’accordons donc pas pour cette étape de nos travaux d’attention paniculiére a
ce probléme. Il est toutefois possible d’argumenter que ces segments pourraient étre mal écrits (par exemple, par un
locuteur non naﬁf, un apprenant, voire une machine) et donc possiblernent non connus des moteurs de recherche, pour
lesquels une assistance a la réécriture serait tout a fait pertinente. Cela représente néanmoins une problérnatique en soi.

5. I1 faut noter que les opérations de racinisation et de correspondance sérnanﬁque utilisant WordNet n’ont pas été
prises en compte car nos expériences portent sur le frangais.

6. Ce calcul de lemmatisation se fait, pour le segment original et sa paraphrase, dans le contexte de la substitution
testée : il est toutefois possible que la lemmaﬁsation produise des erreurs.

7. http: //re search .microsoft . com/en—us/collaboration/focus/cs/web—ngram.
aspx

8. La description du service n’était pas trés explicite lorsque nous l’avons utilisé : i1 semblerait que l’inten11'on de son
foumisseur était avant tout de proposer un service pour l’anglais.

202

Un simple score de modéle de langue pour un énoncé aprés réécriture n’est toutefois pas sufﬁsant,
car il ne tient pas compte de l’énoncé d’origine. Nous avons donc utilisé le rapport entre le score
de modéle de langue de l’énoncé paraphrasé phrlnm, et le score de modéle de langue de l’énoncé
d’origine phrm-g, normalisé par la longueur des énoncés (Onishi et al., 2010) :

ML  rpam )1/langueur(phrP,,,,,)

ML(Phrarig)1/langueur(phr,,,ig) (2)

ML:

Scores de similarité thématique hors contexte Les techniques mises en oeuvre pour calculer
une notion de similarité entre unités textuelles sont fréquemment fondées sur le calcul de
représentations des contextes d’occurrences de ces unités sur lesquelles sont calculées des mesures
de similarité. Nous avons suivi ce type d’approche pour mesurer une similarité thématique entre
paraphrases entre proﬁls de mots cooccurrents. Nous construisons tout d’abord des proﬁls hors
contexte de la maniére suivante : un moteur de recherche est interrogé aﬁn de récupérer les N
premiers extraits de documents (snippets) pertinents pour le segment segm-g. La fréquence des
mots pleins présents dans ces extraits est alors calculée et est utilisée pour obtenir les valeurs
de chaque dimension d’un vecteur de proﬁl lexical T, dont la valeur pour un mot m est déﬁnie
ainsi :

-pm_g[m] =   (3)
freq(segarig)
Pour le calcul des fréquences, f req(u) correspond au nombre d’extraits de documents retournés
contenant l’unité u, et f req(u,v) au nombre d’extraits de documents rapportés contenant les
deux simultanément. Nous construisons de fagon analogue un proﬁl thématique pour chaque
paraphrase possible segp,,,,,, en se limitant aux dimensions du vecteur pour le segment d’origine :

f re<1(segpm, m)

freq(5egpara) ‘4’

Tpara  =

Enfin, nous mesurons la similarité entre le proﬁl du segment d’origine et de chacune de ses
paraphrases possibles a l’aide du cosinus entre les vecteurs de leur proﬁl thématique :

T T

orig para
”""'" ||Tm-g||*||Tpm|| ‘5’
Pour l’ensemble de nos expériences, nous avons utilisé le service Web Yahoo! Search BOSS 9 pour
obtenir le nombre de documents du Web indexés contenant une expression littérale (typiquement,
un segment d’intérét) ainsi que les extraits de documents a partir desquels nous construisons les
vecteurs de proﬁls thématiques. En supposant que la distribution des mots pleins cooccurrents
n’est pas biaisée par l’ordre des résultats du moteur de recherche, notre modéle mesure donc un
certain type de similarité thématique entre segm-g et segp,,,,,.

9. http: //developer . yahoo . com/ search/boss/

203

Scores d’un modéle thématique contextuel Nous déﬁnissons également un modele théma-
tique contextuel de la fagon suivante : considérant contm-g, constituée des deux sous-chaines
de phrm-g privée de segm-g, nous construisons un vecteur de proﬁl T‘°"‘ ayant pour dimen-
sion uniquement pour les mots pleins du contexte de la phrase oil a lieu 1a réécriture. Les
valeurs associées a chaque dimension correspondent a des rapports de fréquence obtenus comme
précédemment par interrogation du moteur de recherche. La similarité thématique contextuelle
utilisée est ﬁnalement déﬁnie par :

cant _ Tcant

cam = orig para 
W" ||T.,‘;’,-’;||*||T,§:,’;',§||

5 Expériences et résultats

Dans cette section, nous détaillons les expériences que nous avons menées aﬁn d’éva1uer1es
performances de1’approche de validation automatique de paraphrases en contexte.

5.1 Description des données utilisées

Nous avons extrait aléatoirement 150 énoncés en francais du corpus W1CoPACo et leur réécriture
pour des exemples annotés comme “paraphrases” lors d’une annotation manuelle réalisée par une
étudiante en linguistique francophone. Un sous-ensemble de 100 énoncés a été utilisé comme
corpus d’apprentissage, les 50 énoncés restants ayant servi pour 1’éva1uation. Ies segments
originaux ainsi que leur paraphrase dans le corpus d’éva1uation sont décrits dans la ﬁgure 1.

taille segment 1 2 3 4 5 6 7 8
# segments originaux 0 3 29 8 6 2 2 0
# paraphrases 39 64 74 36 21 10 5 1

FIGURE 1 — Répartition du nombre de segments par taille (nombre de tokens) dans le corpus
d’éva1uation

Nous disposons ﬁnalement de 5 paraphrases par segment d’origine :

0 Wrcomco : la paraphrase associée au segment dans le corpus W1CoPACo ;

0 HUMAIN : deux paraphrases candidates proposées par des contributeurs humains pour d’autres
contextes issus du Web ;

0 PIVOTES and Prvorm : deux paraphrases candidates obtenues par traduction par pivot. Nous
avons utilisé 1e systéme de traduction automatique sur le Web GOOGLE TRANSLATE 1°, avec une
langue proche du francais comme pivot (1’espagno1), et une autre plus distante (chinois).

La par11'e évaluation de nos expériences a impliqué 4 évaluateurs humains 11, tous francophones.
Ceux-ci ont participé ‘a la collecte manue11e des paraphrases (HUMAIN) pour la moitié du cor-
pus d’apprentissage et d’éva1uation. Afin d’éva1uer 1e caractere approprié de 1’uti1isation des

10. http: //translate . qoogle . com
11. La personne ayant réalisé Pannotation originelle de WICOPACO n’a pas pris part 51 Ce nouveau travail.

204

paraphrases issues des paraphrases collectées dans les contextes de réécriture sélectionnés, les
phrases d’origine et leurs différentes paraphrases ont été présentées dans un ordre aléatoire aux
deux évaluateurs ayant initialement travaillé sur l’autre moitié des corpus. Une interface sur le
Web, illustrée sur la ﬁgure 2, permet alors aux évaluateurs d’indiquer quelles substitutions sont
acceptables, ‘a la fois au niveau de la conservation du sens et de la grammaticalité du nouvel
enonce.

La qui l",‘uliginI’uE  I1"  .
La marque est le promoteur de nombreux concepts qui ont révolutionné Pinformatique .
La marque a popularlsé de nombreux concepts qui ont révolutionné l'informatique .
La marque origine de nombreux concepts qui ont révolutionné 1‘infor'matique .
La marque est in la source de ncmbreux concepts qui ont révoluticnné Tinfcrmatique .

‘La marque Farigine de nombreux concepts qui ont révoluticnné Pinfcrmatique .

FIGURE 2 — Exemple d’une phrase d’origine (sur fond vert) et de ses 5 paraphrases candidates
(présentées dans un ordre aléatoire). Le segment en gras dans la phrase d’origine, est (‘I l’origine,
est ici paraphrasé par est le promoteur , a popularise’ , origine , est (‘I la source et l’origine.

La valeur d’accord inter-annotateur 12 sur l’ensemble des énoncés annotés est de K = 0, 65, ce
qui correspond a un accord fort selon les grilles de Landis et Koch (1977). Nous pensons que le
fait d’aborder tout d’abord des taches relativement certaines du point de vue de l’accord entre
humains comme celle-ci est nécessaire avant de s’attaquer a des problémes plus complexes, tels
que l’identiﬁcation de paraphrases d’énoncés ou encore l’identiﬁcation d’implicau'ons textuelles.

Notre technique de validation étant tres dépendante de la fréquence des segments considérés
sur le Web, nous avons décidé dans ces premieres expériences de ne conserver que les segments
ayant une fréquence minimale de 10 occurrences pour le moteur de recherche utilisé. Le nombre
d’exemples du corpus d’apprentissage a ainsi été réduit de 750 (=150*5) a 434, et celui du corpus
d’évaluation de 250(=50*5) a 215. L’atténuation de cette limitation devra bien évidemment faire
partie de la suite de nos travaux.

Nous détaillerons nos résultats pour les 3 conditions suivantes :

0 Possibles : les exemples annotés comme “paraphrases“ par au moins l’un des juges sont utilisés :
l’ensemble d’évaluation correspondant comprend 116 cas positifs et 99 cas négatifs.

0 Sﬁres : les exemples que les deux juges n’ont pas annotés comme “paraphrases” ou “non
paraphrases” ne sont pas retenus : l’ensemble d’évaluation correspondant comprend 76 cas
positifs et 139 cas négatifs.

S1'ires++ : seuls les exemples pour lesquels les deux juges proposent la méme annotation sont
retenus. Ceci réduit nos ensembles d’apprentissage et d’évaluation ‘a respectivement 287 et
175 exemples, ce qui ne permet pas une comparaison directe avec les deux autres conditions.
1.’ensemble d’évaluation correspondant comprend 76 cas positifs et 99 cas négatifs.

12. Nous avons uﬁlisé le logiciel R (http: //www. r—project . org) pour calculer la valeur de K de Cohen.
Cette valeur est calculée sur1’ensemb1e des données, chaque moitié étant annotée par les deux mémes annotateurs.

205

5.2 Techniques de référence

Nous présentons ici briévement les techniques de référence auxquelles nous comparerons notre
systéme.

Fréquence sur le Web Les deux premiéres techniques sont fondées sur des calculs de fréquences
sur le Web. La premiére, ML_WEB considére un énoncé comme paraphrase d’un énoncé d’origine
si son score de modéle de langue issu du Web est plus élevé que celui de l’énoncé d’origine.
La deuxieme technique, ML_FRONTIl3RES, considere qu’un énoncé est paraphrase d’un énoncé
d’origine si la fréquence sur le Web des bigrammes traversant les frontieres gauche et droite
aprés substitution est supérieure 21 10.

Conservation de dépendances syntaxiques Lors de la réécriture d’une partie d’un énoncé, la
conservation des dépendances syntaxiques entre un segment d’origine et son contexte d’une
part, et sa paraphrase avec le méme contexte d’autre part, peut renseigner sur la substituabilité
grammaticale des deux segments (Zhao et al., 2007; Max et Zock, 2008). Nous avons calculé les
dépendances syntaxiques pour les deux segments 5 l’aide de la version francaise (Candito et al.,
2010) de l’analyseur probabiliste de Berkeley (Petrov et Klein, 2007). Nous considérons donc le
sous-ensemble des dépendances qui existent entre les mots du segment d’origine et son contexte
(Dep,,,,-g) et entre les mots de la paraphrase et ce contexte (Dep,,,,,,,). Cette technique, DEPCONT,
retient la paraphrase candidate si et seulement si Deplmn, = Depm-g.

5.3 Résultats et analyse

Nous avons utilisé un séparateur a vastes marges (SVM) avec les traits décrits dans la section 4 13
Les performances des différentes techniques sur les 3 conditions décrites précédemment sont
données dans la ﬁgure 3.

ML_WEB LM_FRoN'r1EREs DEPCONT CLASSIFIEUR
Poss1BLEs 62,79 54,88 48,53 57,67
SURES 68,37 36,27 51,90 70,69
S1‘1REs++ 56,79 5 1,41 42,69 62,85

FIGURE 3 — Résultats de la performance de la classiﬁcation (exactitude) pour les 3 techniques
de référence et notre classiﬁeur sur le corpus d’évaluation et les 3 conditions. Il convient de
noter que la condition SﬁREs++ n’est pas directement comparable aux autres conditions puisque
les tailles des corpus d’apprentissage et d’évaluation sont différentes ‘a celles des deux autres
conditions.

La premiére observation que nous pouvons faire est que la tache de classiﬁcation de paraphrases
est une tache difﬁcile : la meilleure performance (axactitude) obtenue par l’un des systémes
est de 70,69 pour la condition SI"JREs. En outre, il existe une variation importante entre les

13. Nous avons uti1isé1’irnp1émenta11'on LIESVM (Chang et Lin, 2001).

206

