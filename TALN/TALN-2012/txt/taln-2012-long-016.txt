Simpliﬁcation syntaxique de phrases pour le francais

Laetitia Brouwers1»2 Delphine Bernhard1’3
Anne-Laure Ligozat1»4 Thomas Francoisz» 5
(1) LIMSI—CNRS, 91403 Orsay, France
(2) Université catholique de Louvain, Belgique
(3) LiLPa, Université de Strasbourg, France
(4) ENSIIE, Evry, France
(5) University of Pennsylvania, USA

RESUME
Cet article présente une méthode de simpliﬁcation syntaxique de textes francais. La simpliﬁcation
syntaxique a pour but de rendre des textes plus abordables en simpliﬁant les éléments qui posent
probléme 5 la lecture. La méthode mise en place a cette ﬁn s’appuie tout d’abord sur une étude de
corpus visant a étudier les phénoménes linguistiques impliqués dans la simpliﬁcation de textes en
francais. Nous avons ainsi constitué un corpus paralléle a partir d’articles de Wikipédia et Vikidia,
ce qui a permis d’établir une typologie de simpliﬁcations. Dans un second temps, nous avons
implémenté un systeme qui opére des simpliﬁcations syntaxiques ‘a partir de ces observations.
Des régles de simpliﬁcation ont été décrites aﬁn de générer des phrases simpliﬁées. Un module
sélectionne ensuite le meilleur ensemble de phrases. Enﬁn, nous avons mené une évaluation de
notre systéme montrant qu’environ 80% des phrases générées sont correctes.

AB STRACT
Syntactic Simpliﬁcation for French Sentences

This paper presents a method for the syntactic simpliﬁcation of French texts. Syntactic sim-
pliﬁcation aims at making texts easier to understand by simplifying the elements that hinder
reading. It is based on a corpus study that aimed at investigating the linguistic phenomena
involved in the manual simpliﬁcation of French texts. We have ﬁrst gathered a parallel corpus of
articles from Wikipedia and Vikidia, that we used to establish a typology of simpliﬁcations. In a
second step, we implemented a system that carries out syntactic simpliﬁcations based on these
corpus observations. We described simpliﬁcation rules in order to generate simpliﬁed sentences.
A module subsequently selects the best subset of sentences. The evaluation of our system shows
that about 80% of the sentences produced by our system are accurate.

MOTS-CLES : simpliﬁcation automatique, lisibilité, analyse syntaxique.

KEYWORDS: automatic simpliﬁcation, readability, syntactic analysis.

Actes de la con_fe'rence onjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 21 1-224,
Grenoble, 4 an 8 juin 2012. ©2012 ATAI.A 8: AFCP

211

1 Introduction

Dans la majorité de nos activités quotidiennes, la capacité de lire rapidement et efﬁcacement
constitue un atout certain, voire un pré-requis. Willms (2003) souligne ainsi une corrélation
entre ces compétences et le statut socio-économique des individus. Pourtant, une tranche non
négligeable de la population n’est pas capable de traiter efﬁcacement les données textuelles
auxquelles ils sont confrontés. Richard et al. (1993) rapportent une expérience ou, sur 92
demandes d’aJlocation de chémage remplies par des personnes avec un faible niveau d’éducation,
pas moins de la moitié des informations requises (dont certaines étaient cruciales pour le
traitement de la demande) manquaient, notamment ‘a cause de probleme de compréhension.
Dans un contexte légérement différent, a savoir la pharmacologie, Patel et al. (2002) parviennent
a un constat similaire : la plupart de leurs sujets ont rencontré des problémes importants dans la
compréhension des différentes étapes a réaliser pour la bonne administration du médicament
testé.

Ces problémes de compréhension s’expliquent souvent par une trop grande complexité des textes,
en particulier au niveau du lexique et de la syntaxe. Ces deux facteurs sont connus comme étant
des causes importantes des difﬁcultés de lecture (Chall et Dale, 1995), en particulier chez les
jeunes enfants, les apprenants d’une langue étrangére ou les personnes présentant des déﬁciences
intellectuelles.

Dés lors, la simpliﬁcation automatique de textes apparait comme un moyen susceptible d’aider ces
personnes a accéder plus facilement au contenu des documents écrits auxquels ils sont confrontés.
Il s’agit d’un domaine du traitement automatique des langues (TAL) visant ‘a rendre des textes
plus abordables tout en garantissant l’intégrité de leur contenu et en veillant ‘a en respecter la
structure. Dés lors, il faut déterminer d’une part quelles informations sont secondaires aﬁn de les
supprimer et de rendre les informations primordiales plus visibles et d’autre part quelles sont les
constructions syntaxiques qui peuvent poser probléme pour les simpliﬁer.

Parmi les premiers efforts en ce sens, citons (Carroll et al., 1999) et (Inui et al., 2003), qui ont
proposé des outils pour produire des textes plus abordables pour les personnes atteintes d’un
handicap langagier tel que l’aphasie ou la surdité. Cependant, l’aide a la lecture ne s’adresse pas
qu’aux lecteurs présentant des handicaps, mais aussi a ceux qui apprennent une langue (premiere
ou seconde). Ainsi, Belder et Moens (2010) se sont intéressés a la simpliﬁcation pour des enfants
de langue matemelle anglaise, tandis que Siddharthan (2006), Petersen et Ostendorf (2007)
et Medero et Ostendorf (2011) ont étudié la simpliﬁcation pour les apprenants d’une langue
seconde. La plupart de ces travaux concernent la langue anglaise, ‘a l’exception de (Inui et al.,
2003) qui traitent également le japonais.

Parallélement, la simpliﬁcation automatique a également été utilisée comme un pré-traitement
visant a augmenter l’efﬁcacité d’opérations postérieures effectuées sur des textes. les premiers,
Chandrasekar et al. (1996) ont considéré que les phrases longues et complexes constituaient
un obstacle pour l’analyse syntaxique ou la traduction automatique et que leur simpliﬁcation
préalable pouvait conduire a de meilleures analyses. Plus récemment, Heilman et Smith (2010)
ont montré, quant ‘a eux, qu’un texte simpliﬁé produit de meilleurs résultats dans un contexte
de génération automatique de questions. Du coté du biomédical, Lin et Wilbur (2007) et Jon-
nalagadda et al. (2009) ont optimisé l’extraction de données en simpliﬁant les textes lors d’un
prétraitement.

212

programme de simpliﬁcation et les erreurs provoquées par un pré-traitement (analyse morpho-
syntaxique et syntaxique) inexact. Ainsi, parmi les 21,32% de phrases problématiques, il apparait
que 89% des erreurs proviennent de l’analyse (morpho-) syntaxique et seulement 11% d’entre
elles sont effectivement dues au systeme mis en place. Par conséquent, a partir du corpus
d’évaluation, seulement 2,4% des phrases produites par notre systéme posent probléme en raison
de l’application d’une regle de simpliﬁcation. Parmi ces rares erreurs de simpliﬁcation (notre
corpus en compte 8), il faut enﬁn distinguer les erreurs de contenu (25%) et de forme (75%).
Dans la suite de cette section, nous revenons plus en détail sur les deux types d’erreurs principales
rencontrées : morpho-syntaxiques et de simpliﬁcation.

Phrases produites par le programme
333 phrases - 100%
Phrases correctes Phrases incorrectes
262 phrases - 78,68% 71 phrases - 21,32%
Erreurs dues au pré-traitement Erreurs dues au simpliﬁcateur
63 phrases - 18,92% 8 phrases - 2,4%
Syntaxe Sens
6 phrases 2 phrases
1,8% 0,6%

TABLE 3 — Evaluation des régles de simpliﬁcation

3.2 Erreurs d’analyse (morpho-)syntaxique

La phase de pré-traitement consiste a étiqueter, annoter et structurer des phrases. Des lors, il
peut y avoir des erreurs dans les étiquettes attribuées, les relations identiﬁées, les regroupements
d’éléments et les délimitations de phrases et de parentheses.

Les erreurs d’étiquette sont les plus fréquentes et concement des entités nommées, des cas
ambigus ou des expressions ﬁgées. Par exemple, les mots ainsi que peuvent poser probleme
puisqu’il peut s’agir d’un connecteur ou des terrnes ainsi et que. I.’analyseur ne parvient pas
toujours ‘a différencier les deux cas, ce qui peut provoquer des erreurs lors de la suppression
des coordonnées (si les mots ainsi que sont identiﬁés comme un connecteur ‘a tort). La phrase
suivante en est un exemple :
(5) Les me’lodies sont accrocheuses et les arrangements tres soignés; c’est ainsi que
"Mamma Mia" et "Fernando" (malgré quelques erreurs de grammaire anglaise) occu-
perent la premiere place des palmarés mondiaux dans Ze premier semestre de cette méme
anne’e.
Puisque ainsi que est considéré comme un connecteur et non comme l’adverbe ainsi suivi du
deuxieme terme de la clivée que, la regle de suppression des coordonnées produit la phrase
suivante qui est agrammaticale : C’est.

Au-del‘a des problemes d’étiquette, les relations de dépendance posent aussi fréquemment des
difﬁcultés ‘a l’analyseur syntaxique. En effet, il est difﬁcile de déterminer o1‘1 s’arréte un groupe
ou une proposition, quels éléments le composent ou de quel élément il dépend, particuliere-
ment lorsque les constructions sont complexes et méme emboitées. A nouveau, cela peut poser
probléme si une régle de simpliﬁcation s’applique justement a un groupe mal analysé.

221

Les ponctuations constituent également des éléments difﬁciles ‘a traiter pour l’analyseur. C’est
pourquoi les phrases et les groupes entre parentheses ne sont pas toujours convenablement
délimités. De plus, l’analyseur ne distingue pas les points contenus dans les citations entre
guillemets et ceux qui marquent une ﬁn de phrase. Cela peut amener le programme, qui applique
des regles, a diviser une phrase en plusieurs propositions de maniere erronée. Les parentheses,
quant ‘a elles, ne sont pas toujours marquées ‘a un méme niveau, ce qui détruit l’unité de
l’ensemble. En effet, tous les composants de l’expression entre parentheses ne sont pas rassemblés
sous un méme élément, ce qui signiﬁe qu’une par11'e de l’expression peut étre supprimée sans le
reste et inversement.

3.3 Erreurs de simpliﬁcation

A cété des erreurs issues du pré-traitement, certaines phrases, erronées aux niveaux sémantique
et syntaxique, peuvent étre produites ‘a la suite de l’application des regles de simpliﬁcation.
Il s’agit évidemment l‘a des erreurs les plus intéressantes, qui se répartissent en deux grandes
catégories.

D’une part, les informations véhiculées par la phrase peuvent se trouver modiﬁées ou amputées.
De fait, lors de la suppression de l’inﬁnitive, il arrive qu’une partie du contenu de la phrase
soit perdue. Ainsi, dans la phrase suivante, issue de l’ar11'cle abbé, la proposition inﬁnitive, qui
explique le terme abbe’, est supprimée :

(6a) C’est aussi depuis le XVIIIe siecle le terme en usage pour designer un clerc se’culier
ayant au moins regu la tonsure.
(6b) C’est aussi depuis le XVIIIe siécle le terme en usage.

Par ailleurs, lors de la suppression du complément d’agent, le sens d’une phrase peut étre
bouleversé par ce type de modiﬁcation. 11 en est ainsi pour la phrase de l’exemple (7b). En effet,
le sens de la phrase originale (7a) était tout a fait différent :

(7a) Ils ne sont pas caracte’rise’s par leur profession comme dans la Bible : l’un pasteur;
l’aut're agriculteur.
(7b) Ils ne sont pas caracte’rise’s : l’un pasteur, l’aut're agriculteur.

D’autre part, la structure de la phrase peut étre modiﬁée de telle facon que la phrase devient
syntaxiquement incorrecte. Trois régles de simpliﬁcation sont concernées. Tout d’abord, les régles
de suppression sont sujettes a ce genre de probleme puisqu’il s’agit de supprimer une partie de
la phrase, qui est normalement secondaire au bon fonctionnement de la phrase. Pourtant, il
arrive que l’élément supprimé soit essentiel, comme dans le cas de la suppression du référent
d’un pronom. La suppression de la subordonnée ou de l’inﬁnitive peut provoquer ce type de
désagrément. De son c6té, la division de la phrase a par11'r de la relative produit un autre genre
d’erreurs. Si le verbe est suivi d’un inﬁnitif, le complément direct (l’antécédent du relatif qui
est replacé dans la relative lors de la division) peut dépendre du verbe ou de l’inﬁnitif. Le
simpliﬁcateur n’en tient pas compte et estime dans tous les cas que le complément direct dépend
du verbe et non de l’inﬁnitif, parfois de maniére erronée comme dans l’exemple (8) :

(8a) Ils ont sur leurs religieux un droit de juridiction, une autorite’ qu’il leur est recom-
mande’ de n’exeroer que par la voie de la patience et de la douceur.

(8b) Il leur est recommande’ oette autorite’ de n’exeroer que par la voie de la patience et
de la douoeur.

222

4 Conclusion et perspectives

Cet article a décrit un systéme automatique de simpliﬁcation syntaxique pour le frangais a desti-
nation des enfants en particulier. Celui-ci repose sur un ensemble de régles obtenues sur la base
d’une étude de corpus, laquelle a aussi mené a l’élaboration d’une typologie des simpliﬁcations
en francais. I1 serait aisé d’étendre notre typologie ‘a d’autres publics sur base d’autres corpus
adéquats. Notre démarche utilise également la technique de la sur-génération, qui permet de
retenir le meilleur ensemble de simpliﬁcations en fonction de criteres de lisibilité. Notons que
parmi ceux employés, certains n’avaient pas été considérés précédemment et produisent des
résultats intéressants. Enﬁn, il est apparu que les performances de notre systéme sont bonnes
(environ 80% des phrases générées sont correctes), en particulier si l’on ne tient pas compte des
erreurs dues aux outils de prétraitement.

Nous envisageons plusieurs perspectives d’amélioration pour notre systeme. Tout d’abord, la
simpliﬁcation syntaxique pourrait étre complétée par une simpliﬁcation lexicale, ainsi que cela est
fait dans certaines études pour l’anglais (Woodsend et Lapata, 2011). Il s’agit en effet d’une autre
source de problemes pour certains lecteurs. Par ailleurs, notre analyse des erreurs a souligné
la nécessité d’ajouter ou de répéter des termes lorsqu’une division de phrase est effectuée. Il
serait des lors utile de développer un outil qui gérerait les référents, aﬁn d’améliorer la qualité
du texte simpliﬁé. Enﬁn, une derniére perspective d’amélioration consisterait a rendre le systéme
de régles modulable en fonction d’un public cible. Cela demanderait d’évaluer la pertinence des
différentes transformations et des criteres de sélection des meilleures simpliﬁcations en fonction
des publics visés. Cette perspective nécessiterait d’évaluer l’efﬁcacité des regles au moyen de
tests de compréhension portant sur des phrases originales et simpliﬁés.

Remerciements Nous remercions Antoine Sylvain pour sa participation ‘a la constitution du
corpus de textes issus de Wikipédia et Vikidia. Ces travaux ont regu le soutien ﬁnancier du projet
DOXA du péle de compétitivité CAP-DIGITAL.

Références

BELDER, J. D. et MoENs, M.-E (2010). Text Simpliﬁcation for Children. In Proceedings of the
Workshop on Accessible Search Systems, in conjunction with SIGIR 2010.

CANDITO, M., NIVRE, J., DEN1s, P. et ANGUIANO, E. (2010). Benchmarking of statistical dependency
parsers for French. In Proceedings of the 23rd International Conference on Computational
Linguistics : Posters, pages 108-116. Association for Computational Linguistics.

CARROLL, J., MINNEN, G., PEARCE, D., CANNING, Y., DEVLIN, S. et TAIT, J. (1999). Simplifying Text
for Language-Impaired Readers. In Proceedings of the Ninth Conference of the European Chapter
of the Association for Computational Linguistics, pages 269-270.

CATACH, N. (1985). Les listes orthographiques de base du francais. Nathan, Paris.

CHALL, J. et DALE, E. (1995). Readability Revisited : The New Dale-Chall Readability Formula.
Brookline Books, Cambridge.

CHANDRASEKAR, R., DORAN, C. et SRINIVAS, B. (1996). Motivations and methods for text simpliﬁ-
cation. In Proceedings of the 16th conference on Computational linguistics, pages 1041-1044.

223

DEN1s, R, SAGOT, B. et aL (2009). Coupling an annotated corpus and a morphosyntactic lexicon
for state-of-the-art pos tagging with less human effort. In Proceedings of PACLIC.

GILLICK, D. et FAVRE, B. (2009). A scalable global model for summarization. In Proceedings of
the Workshop on Integer Linear Programming for Natural Language Processing, [LP ’09, pages
10-18, Stroudsburg, PA, USA.

HEILMAN, M. et SMITH, N. A. (2010). Extracting Simpliﬁed Statements for Factual Question
Generation. In Proceedings of the 3rd Workshop on Question Generation.

INU1, K., FUJITA, A., TAKAHASHI, T., IIDA, R. et IWAKURA, T. (2003). Text simpliﬁcation for reading
assistance : a project note. In Proceedings of the second international workshop on Paraphrasing,
pages 9-16.

JONNALAGADDA, S., TAR1, L., HAKENBERG, J., BARAL, C. et GONZALEZ, G. (2009). Towards Effective
Sentence Simpliﬁcation for Automatic Processing of Biomedical Text. In Proceedings of NAACL-
HLT 2009.

LEVY, R. et ANDREW, G. (2006). Tregex and tsurgeon : tools for querying and manipulating tree
data structures. In Proceedings of the ﬁfth international conference on Language Resources and
Evaluation, pages 2231-2234.

LIN, J. et WILBUR, W. J. (2007). Syntactic sentence compression in the biomedical domain :
facilitating access to related articles. Information Retrieval, 10(4):393—414.

MEDERO, J. et OSTENDORF, M. (2011). Identifying Targets for Syntactic Simpliﬁcation. In
Proceedings of the SLa'I'E 201 1 workshop.

NELKEN, R. et SHIEBER, S. (2006). Towards robust context-sensitive sentence alignment for
monolingual corpora. In Proceedings of the 11th Conference of the European Chapter of the
Association for Computational Linguistics, pages 161-168.

PATEL, VI, BRANCH, T. et ARocHA, J. (2002). Errors in interpreting quantities as procedures : The
case of pharmaceutical labels. International journal of medical informatics, 65 (3) : 193-21 1.
PETERSEN, S. E. et OSTENDORF, M. (2007). Text Simpliﬁcation for Language Learners : A Corpus
Analysis. In Proceedings of Speech and Language Technology in Education (SLaTE2007), pages
69-72.

RICHARD, J., BARCENILLA, J., BRIE, B., CHARMET, E., CLEMENT, E. et REYNARD, P. (1993). Le
traitement de documents administratifs par des populations de bas niveau de formation. Le
Travail Humain, 56(4) :345—367.

SIDDHARTHAN, A. (2006). Syntactic Simpliﬁcation and Text Cohesion. Research on Language &
Computation, 4(1) :77-109.

SPECIA, L. (2010). Translating from Complex to Simpliﬁed Sentences. In Proceedings of the 9th
International Conference on Computational Processing of the Portuguese Language (Propor-2010).,
pages 30-39.

W1LLMs, J. (2003). Literacy proﬁciency of youth : Evidence of converging socioeconomic
gradients. International Journal of Educational Research, 39(3):247-252.

WOODSEND, K. et LAPATA, M. (2011). learning to Simplify Sentences with Quasi-Synchronous
Grammar and Integer Programming. In Proceedings of the 201 1 Conference on Empirical Methods
in Natural Language Processing, pages 409-420, Edinburgh, Scotland, UK.

ZHU, Z., BERNHARD, D. et GUREVYCH, I. (2010). A Monolingual Tree-based Translation Model for
Sentence Simpliﬁcation. In Proceedings of the 23rd International Conference on Computational
Linguistics (Coling 2010), pages 1353-1361, Beijing, China.

224

La majorité des méthodes de simpliﬁcation syntaxique proposées reposent sur un ensemble de
régles de transformation déﬁnies manuellement pour étre appliquées aux phrases. La simpliﬁca-
tion semble toutefois naturellement se préter a l’utilisation de méthodes issues de la traduction
automatique ou de l’apprentissage automatique, dont les modeles sont construits ‘a partir de
corpus comparables de textes complexes et simpliﬁés (Zhu et aL, 2010; Specia, 2010 ; Woodsend
et Lapata, 201 1). Les données utilisées dans ce cas sont notamment issues de Wikipédia en anglais
et de Simple English Wi.kipedia, destinée aux enfants et aux locuteurs non natifs. L’encyclopédie
Simple English Wi.kipedia compte a ce jour plus de 75 000 articles.

Il existe des projets comparables pour le francais, Vikidia (voir Section 2.1) et Wikimini, mais ils ne
sont pas aussi fournis que leur homologue anglophone. Par ailleurs, les différentes versions d’un
article de Wi.kipédia ne sont pas strictement paralléles, ce qui complique encore l’apprentissage
automatique. La méthode proposée dans cet article repose donc sur un ensemble de regles de
simpliﬁcation automatique qui ont été déﬁnies manuellement (voir Section 2.3), aprés étude de
corpus. Nous utilisons la technique de la sur-génération, qui consiste a produire dans un premier
temps un nombre important de simpliﬁcations possibles, avant de procéder ‘a une sélection
optimale des meilleures simpliﬁcations produites, a l’aide de la programmation linéaire en
nombre entiers (PLNE, en anglais Integer Linear Programming — ILP). La PLNE permet de déﬁnir
des contraintes qui régissent le choix du résultat fourni par l’outil de simpliﬁcation automatique.
Cette méthode a notamment été appliquée a la simpliﬁcation de textes en anglais par (Woodsend
et Lapata, 2011), (Belder et Moens, 2010), ainsi que par (Gillick et Favre, 2009) pour le résumé
automatique.

Les apports de cet article sont les suivants : l’étude des procédés de simpliﬁcation en francais, et
notamment la constitution d’un corpus de phrases paralléles, et une typologie des simpliﬁcations ;
l’utilisation de criteres originaux de sélection des phrases, tels que la liste orthographique de
base de Nina Catach ou les mots-clés d’un texte. Nous présenterons tout d’abord le processus de
constitution du corpus (Section 2.1), puis la typologie des simpliﬁcations observées (Section 2.2).
Nous détaillerons ensuite le fonctionnement du systeme mis en oeuvre, qui procede en deux
temps : une surgénération de phrases simpliﬁées (Section 2.3.1), et une sélection des phrases
correspondant a des critéres de lisibilité (Section 2.3.2). Enﬁn, nous évaluerons cette simpliﬁca-
tion du point de vue de la correction des phrases générées, et analyserons les causes d’erreurs
(Section 3).

2 Méthodologie

2.1 Présentation du corpus

Pour établir une typologie des régles de simpliﬁcation, une étude sur corpus a été réalisée. Puis-
qu’il s’agit de déterminer les stratégies utilisées pour passer d’une phrase complexe a une phrase
simpliﬁée, un corpus de phrases paralleles a été construit ‘a partir d’articles des encyclopédies
en ligne Wi.kipédia 1 et Vi.kidia 2. Cette derniere est destinée aux jeunes de huit a treize ans et
rassemble des articles plus accessibles, tant au niveau de la langue que du contenu. Aﬁn de
constituer ce corpus, nous sommes partis des articles de Vikidia et avons utilisé l’API MediaWi.ki

1. http: //:Er.wikipedia. org
2. http: //:Er.vikidia. org

213

 
 
 
       
         
 
 

API

WikiE><tracto
Wikipédia ‘ Mediawikl '

 

Phrases
paralleies
alignées

alignement
monolingue

 

,/.\p| WikiExIracIor Amdes
Vikidia Med iaWikI ‘ V""d"“
(texte)

FIGURE 1 — Constitution du corpus de phrases paralléles

pour récupérer les articles de Wikipédia et Vikidia de mémes titres. Le programme WikiExtractor 3
a ensuite été appliqué a ces articles aﬁn d’en extraire les textes bruts (c’est-a-dire sans la syntaxe
wi.ki). Le corpus ainsi constitué comprend 13 638 ﬁchiers (dont 7 460 de Vikidia et 6 178 de
Wi.kipédia, certains ar11'cles de Vi.kidia n’ayant pas d’équivalent direct dans Wi.kipédia).

Ces articles ont ensuite été analysés aﬁn de repérer des phrases paralléles (phrase de Wi.kipédia
ayant un équivalent simpliﬁé dans Vikidia). Cet alignement a été effectué en partie manuellement
et en partie automatiquement grace a l’algorithme d’alignement monolingue décrit dans (Nel.ken
et Shieber, 2006), qui se fonde sur une similarité cosinus entre phrases, avec un tf.idf adapté
pour la pondération des mots. Ce programme fournit en sortie des alignements entre phrases,
avec un score de conﬁance associé. La ﬁgure 1 résume le processus de constitution de ce corpus.

Parmi ces ﬁchiers, vingt articles ou extraits d’artic1es de Wikipédia et leur équivalent dans Vikidia
ont été sélectionnés, ce qui nous donne respectivement 72 phrases et 80 phrases. Les extraits
suivants - correspondant 5 l’entrée «archipel» - ont par exemple été sélectionnés :

(la) Wi.kipédia : Un archipel est un ensemble d’i‘les relativement proches les unes des
autres. Le terme «archipel» vient du grec ancien "Archipelagos", littéralement «mer
principale» (de "archi" : «principal» et "pe’lagos" : «la haute mer»). En eﬁet, ce mot
désignait originellement la mer Egée, caractérisée par son grand nombre d’i‘les (les
Cyclades, les Sporades, Salamine, Eubée, Samothraoe, Lemnos, Samos, Lesbos, Chios,
Rhodes, etc).

(lb) Vkidia : Un archipel est un ensemble de plusieurs iles, proches les unes des autres.
Le mot «archipel» vient du grec “archipelagos“, qui signiﬁe littéralement «mer principale»
et désignait a l’origine la mer Egée, caracte’rise’e par son grand nombre d’i‘les.

Notons que les deux articles présentent les mémes informations globalement, mais de maniére
différente. I1 y a simpliﬁcation lexicale, sémantique et syntaxique. En effet, dans Vi.kidia, il n’y
a que deux phrases, qui contiennent l’essenu'el de l’explication (information nécessaire) tandis
que dans Wikipédia, trois phrases détaillent la signiﬁcation et l’origine du terme de maniére plus
précise (informations secondaires, par exemple mises entre parentheses).

3. http: //medialab . di . unipi . it/wiki/Hikipedia_Ex1:rac1:or

214

2.2 Typologie de simpliﬁcations

Les observations realisees sur ce corpus ont permis d’etablir une typologie ar1iculee selon trois
grands niveaux de transformations : lexical, sémantique et syntaxique. Dans les travaux realises,
la simpliﬁcation est communement consideree comme composee de deux categories, lexicale
et syntaxique (Carroll et al., 1999; Inui et al., 2003; Belder et Moens, 2010). Le domaine de la
sémantique quant a lui n’est pas cite. Ces trois grands niveaux peuvent étre a leur tour divisés en
sous-categories, comme le montre la table 1.

Lexique Sémantique Syntaxe
Temps

Synonyme ou hyperonyme Reorganisation Suppression
Traduction Suppression Modiﬁcation

Ajout Division

Regroupement

TABLE 1 — Typologie

En ce qui concerne le lexique, deux phenoménes sont observes. D’une part, les termes considérés
comme difﬁciles sont remplacés par un synonyme ou un hyperonyme. Dans l’exemple (1), terme
a ete remplacé par mot qui est plus courant. D’autre part, les concepts utilises dans leur langue
d’origine dans Wi.kipedia sont traduits en francais dans Vkidia.

Au niveau sémantique, les auteurs de Vikidia prétent une attention particuliére a l’organisation de
l’information qui doit étre claire et synthetique. Dans cette optique, il arrive que des propositions
soient interverties, aﬁn d’assurer une meilleure presentation de l’information. De plus, le contenu
considere comme secondaire ‘a la comprehension est supprime tandis que des explications ou
des exemples sont ajoutés pour plus de clarte. Ainsi, dans l’exemple (1), la decomposition de la
signiﬁcation du mot archipel est explicitee dans Wi.kipedia, mais pas dans Vi.kidia.

Enﬁn, du point de vue syntaxique, qui nous interesse prioritairement ici, cinq types de change-

ments sont observes : les modiﬁcations de temps, la suppression, la modiﬁcation, la division et le

regroupement. Les deux derniers types peuvent étre envisages ensemble dans la mesure o1‘1 ce
sont deux phenomenes opposes. Cette classiﬁcation peut se rapprocher de celle de (Medero et

Ostendorf, 2011) qui reprend trois categories - la division, la suppression et l’extension - ou de

(Zhu et al., 2010) (composée de la division, la suppression, la reorganisation et la substitution).

— Tout d’abord, les temps utilises dans Vkidia sont plus quotidiens et moins litteraires que ceux
utilises dans Wi.kipedia. Ainsi, le present et le passe compose sont preferes au passe simple.

— Ensuite, les informations secondaires ou redondantes, telles que certains complements cir-
constanciels, qui sont en general considerees comme supprimables au niveau syntaxique, ne
sont pas reprises dans les articles de Vi.kidia. Dans l’exemple (1), l’adverbe relativement qui
precedait proches les unes des autres a ainsi ete supprime dans Vikidia. 1.’adverbe n’ajoutait
effectivement rien au niveau informationnel.

— De plus, si certaines structures plus complexes ne sont pas supprimees, elles sont alors deplacees
ou modiﬁees pour plus de clarte. Dans Vikidia, par exemple, une construction afﬁrmative est
preferee 21 une forme negative :

(2a) Wi.kipedia : Les personnes qui ont vote’ blanc ou nul ne sont généralement pas
considerees comme abstentionnistes mais le résultat est identique : leur choix n’est pas

215

pris en compte.
(2b) Vi.kidia : Ifabstention est dijfférente du vote blanc et du vote nul.

— Finalement, les auteurs choisissent parfois de diviser des phrases longues ou a l’inverse de
réunir plusieurs phrases en une seule. Dans l’exemple (1), les deux derniéres phrases ont été
regroupées dans Vikidia, car elles ont été simpliﬁées et sont dés lors devenues beaucoup plus
courtes. Il faut d’emblée préciser que le regroupement d’éléments est beaucoup moins utilisé
que la division de phrases. Pour scinder une phrase, les auteurs prennent par exemple une
proposition secondaire (telle qu’une relative) qu’ils transforment en phrase indépendante.

Parmi les changements observés, certains d’entre eux sont difﬁcilement implémentables. C’est le
cas lorsqu’une modiﬁcation nécessite de recourir a la sémantique, c’est-a-dire qu’il n’est possible
de repérer les structures a modiﬁer que par le sens. Il est difﬁcile d’appliquer ce type de stratégies
de maniere automatique. Par exemple, il est parfois possible de supprimer les éléments qui se
rapportent au nom, alors que d’autre fois, ils sont indispensables, sans que cela ne soit marqué
typographiquement ou grammaticalement dans la phrase.

D’autres changements syntaxiques doivent s’accompagner de transformations lexicales, difﬁ-
cilement généralisables. Par exemple, la modiﬁcation d’une phrase négative en une phrase
affirmative nécessite de trouver un verbe dont la forme affirmative recouvre le sens de la
construction négative a remplacer.

Il y a également des changements qui sont effectués de maniére isolée et non systématisable.
Ils relévent plut6t d’un traitement manuel que d’un traitement automatique d’un texte, dans le
sens ou chaque cas est différent (méme s’il s’inscrit dans une régle plus globale). De plus, ils font
généralement appel a des informations sémantiques ou lexicales et pas simplement syntaxiques.
Il s’agit de changements complexes, qui sont utiles dans certains cas, mais ardus ‘a détecter
automatiquement.

Enﬁn, les changements syntaxiques qui ont un impact sur d’autres parties du texte ou qui
concement des éléments dépendants d’une autre structure demandent des modifications plus
globales du texte. Par conséquent, ils sont également difﬁciles a traiter automatiquement. Ainsi,
pour modifier le temps d’un verbe dans une phrase, il faut veiller ‘a ce que la concordance des
temps soit respectée dans l’entiéreté du texte.

2.3 Systéme de simpliﬁcation syntaxique

Nous avons utilisé cette typologie pour mettre en oeuvre un systéme de simpliﬁcation syntaxique
pour le frangais. La simpliﬁcation d’un texte y est effectuée en deux étapes : une étape de
génération de toutes les simpliﬁcations possibles pour chaque phrase du texte, et une étape de
sélection du meilleur ensemble de phrases simpliﬁées. L’architecture de ce systéme est présentée
dans la ﬁgure 2.

Le module de surgénération s’appuie sur un ensemble de regles (au nombre de 19), utilisant
des informations sur les caractéristiques (morpho-) syntaxiques des mots et sur les relations de
dépendance présentes au sein d’une phrase. C’est pourquoi les textes de notre corpus ont été
analysés par MElt4(Denis et al., 2009) et Bonsai5(Candito et aL, 2010). Ces textes ont ainsi été

4. https : //gforge . inria. fr/proj ect s/lingwb
5. http: //alpage . inria. fr/ statgram/frdep/:Er_s1:a1:_dep_pars ing . html

216

ME“ Emma‘ Tregex Tsurgeon glpsol
W
' mération de phrases Séleclion m9“‘9“'9
ifnégles syntaxloues simmmées mtéres de hswbmté phrase ,

   

  
  

‘ ensemble l

 
 

 
 

Prétraitement
analyse morpho—5ynta><Ique 1 5Vma7“We J

phrase ‘

FIGURE 2 — Organisation du systéme de simpliﬁcation syntaxique

représentés sous la forme d’arbres syntaxiques, lesquels contiennent un maximum de données
utiles a l’application de regles de simpliﬁcation. Ces dernieres peuvent alors étre appliquées de
maniere récursive, jusqu’a ce qu’il n’y ait plus aucune structure ‘a simpliﬁer dans chacune des
phrases des textes. Il faut ajouter que toutes les phrases créées a chaque application d’une régle
sont enregistrées, produisant un ensemble de variantes. Par la suite, le meilleur ensemble de
phrases sera retenu via un modéle de programmation linéaire, en fonction d’une série de critéres
détaillés par la suite.

2.3.1 Généraﬁon de phrases simpliﬁées

Les régles de simpliﬁcation syntaxique qui composent notre programme sont respectivement des
regles de suppression (12 regles), de modiﬁcation (3 regles) et de division (4 regles). Notons
que, par rapport a la typologie établie, deux types de régles n’ont pas été mises en place. D’une
part, les stratégies de regroupement de plusieurs phrases en une n’ont pas été observées de
maniere assez systématique dans le corpus d’étude. Il est des lors difﬁcile d’en retirer une
regle automatisable. De plus, les regles de regroupement pourraient entrer en conﬂit avec les
regles de suppression, puisqu’elles ont des buts opposés. D’autre part, en ce qui concerne les
aspects temporels, nous avions noté que certains temps étaient plus utilisés que d’autres dans
l’encyc1opédie pour les jeunes, Vikidia. Toutefois, cette stratégie n’a pas été implémentée car elle
demandait des changements trop globaux, pouvant toucher au texte entier. En effet, lorsqu’un
verbe au passé simple est remplacé par un verbe au présent, il faut veiller a ce que la concordance
des temps soit toujours respectée partout, ce qui demande d’examiner tout le texte, ou du moins
le paragraphe qui contient la forme verbale modiﬁée. On risque alors de détruire la cohérence du
texte et d’en altérer la qualité.

Pour appliquer ces 19 regles, il convient tout d’abord de repérer les structures concernées par
de possibles changements a l’aide d’expressions réguliéres et grace a Tregex 5(Levy et Andrew,
2006) qui gere le repérage d’éléments et de relations dans un arbre. Dans un deuxieme temps,
une série d’opérations sont effectuées par le biais de Tsurgeon qui permet de modiﬁer des arbres
syntaxiques. Par exemple, pour supprimer une coordonnée introduite par soit, il faut repérer une
proposition coordonnée, étiquetée COORD, qui domine la conjoncﬁon de coordination soit et lui
donner un nom comme Pcoord. Ensuite, l’opération Tsurgeon delete doit étre appliquée ‘a
l’ensemble repris sous Pcoord :

Repérage (Tregex) : CO0RD=Pcoord < (CC < /soit/)

Opération (Tsurgeon) : delete Pcoord

6. http: //nlp . stanford . edu/software/tregex . shtml

217

Cette régle s’appliquerait par exemple a la phrase suivante :

(3a) Phrase d’origine : Elle compte, selon les autorités du pays, en 2009, 5 878 609
habitants pour l’agglome’ration, et 3 796 677 habitants pour la ville, soit 20 % de la
population totale du pays.

(3b) Phrase aprés application de la régle : Elle compte, selon les autorités du pays, en
2009, 5 878 609 habitants pour l’agglome’ration, et 3 796 677 habitants pour la ville.

Les opérations varient en fonction du type de régle appliquée :

1. Pour les régles de suppression, il sufﬁt de supprimer tous les éléments concemés (via

l’opération Tsurgeon delete). Les éléments concernés par les régles de suppression
sont les compléments circonstanciels, les ensembles entre parentheses, une partie des
propositions subordonnées, les propositions er1tre virgules ou introduites par un terme tel
que comme, voire ou soit, les adverbes et les compléments d’agent.

. Pour les regles de modiﬁcation, il s’agit de combiner plusieurs opérations : la suppression

de certains termes (opération Tsurgeon delete), le déplacement d’éléments (opération
Tsurgeon move) et l’ajout d’étiquettes (opération Tsurgeon insert) qui signalent
un traitement éventuel par la suite. En effet, certaines régles demandent que les formes
verbales se conjuguent ‘a un autre temps, un autre mode, etc. Dans ce cas, des étiquettes
sont ajoutées autour du verbe pour indiquer qu’il doit étre modiﬁé. Il sera, dans un
traitement postérieur, conjugué a la forme voulue grace au systéme de conjugaison le
Verbiste 7. Ainsi, pour passer d’une structure passive ‘a une structure active, il faut
modiﬁer le mode, mais aussi parfois la personne, pour que le verbe s’accorde correctement
avec le complément d’agent devenu sujet. Trois régles de modiﬁcation ont été mises en
place : le déplacement a l’initiale des compléments circonstanciels, le passage a l’actif des
formes passives et la transformation d’une clivée en non clivée.

. Pour les régles de division, le processus se déroule en deux étapes. La proposition

secondaire est d’abord supprimée et la nouvelle phrase enregistrée telle quelle. Ensuite,
la phrase d’origine est reprise et la proposition principale est cette fois supprimée avant
que la proposition secondaire soit transformée de maniére ‘a devenir indépendante. En
général, il faut veiller ‘a modiﬁer la forme verbale de cette proposition secondaire pour
qu’elle puisse fonctionner comme un verbe principal. Par ailleurs, le pronom qui régit la
proposition doit étre remplacé par son antécédent et le sujet doit étre inséré lorsqu’il est
manquant. Par exemple, pour transformer une relative en une proposition indépendante,
le pronom relatif doit étre remplacé par son antécédent et il est important de tenir compte
de la fonction du pronom pour savoir o1‘1 insérer l’antécédent. Signalons que les phrases
sont scindées quand elles contiennent des propositions secondaires introduites par deux
points, des coordonnées, des participiales ou des relatives.

Ces régles de simpliﬁcation sont appliquées de maniére récursive ‘a une phrase jusqu"a ce que
toutes les variantes possibles aient été générées. Plusieurs résultats sont donc réguliérement
obtenus pour une méme phrase. Des lors, il convient de déterminer la phrase, parmi toutes celles
produites, qui est la plus appropriée pour remplacer celle d’origine. Ce processus est décrit a la

section suivante.

7. Le programme est disponible a 1’adresse http://sarrazip.com/dev/verbis1:e.h1:ml sous licence GNU

(page consultée le 6 novembre 2011). Ila été créé par Pierre Sarrazin.

218

2.3.2 Sélection de phrases simpliﬁées

Etant donné un ensemble de phrases simpliﬁées possible pour un texte, notre objectif est de
sélectionner le meilleur sous-ensemble de phrases simpliﬁées, c’est-a-dire celui qui maximise une
mesure de lisibilité. Cette mesure de lisibilité se traduit par différents criteres. Pour résoudre
ce genre de problemes, la programmation linéaire en nombres entiers constitue une technique
appropriée.

Dans notre cas, quatre critéres ont été pris en compte pour choisir la phrase adéquate : la longueur
de la phrase, la longueur des mots, la familiarité du vocabulaire et la présence de termes-clés,
c’est-‘a-dire récurrents dans le texte. Ia longueur de la phrase est exprimée en nombre de mots
tandis que la longueur des mots est donnée en nombre de caracteres. En ce qui concerne la
familiarité des mots, la liste de Catach 8 (Catach, 1985) a été utilisée pour calculer le poids de
chaque terme. Il s’agit d’une liste des 3000 mots les plus fréquents, dont il convient d’enseigner
l’orthographe en priorité aux éleves de primaire. Les termes-clés ont été déﬁnis, quant a eux,
comme les mots qui apparaissaient deux fois ou plus dans un texte.

Ces criteres sont combinés grace ‘a la formule suivante au sein du module de programmation
linéaire 9 :
Il s’agit alors de maximiser : hw + hs + ha + hc

O1‘1: hW=wps><Z:l.si—Z:.ll3"sl-
hs = cpw X Xi ll3"sl- — 1- lfsi (1)
ha = aps X Zisi — Xi lfsi
hc = Z]. wjcj

Nous avons déﬁni les paramétres et variables suivants pour la formulation du probléme :

— wps : le nombre moyen de mots par phrase souhaité

— cpw : le nombre moyen de caractéres par mot souhaité

— aps : le nombre moyen de mots absents de la liste de Catach souhaité

— si un indicateur de la présence de la phrase i dans la simpliﬁcation de texte ﬁnale

— cj un indicateur de la présence du mot-clé j dans la simpliﬁcation de texte ﬁnale

1;” la longueur en mots de la phrase i

ll.‘ la longueur en caractéres de la phrase i

— 1;’ le nombre de mots absents de la phrase i

— w 1- le nombre d’occurrences du mot-clé j

wps, cpw et aps sont des parametres constants dont les valeurs ont été ﬁxées respectivement
‘a 10, ‘a 5 et a 2 pour cette étude. Toutefois, il s’agit de parametres susceptibles de varier en
fonction du contexte d’utilisation et du public cible, puisqu’i1s déterminent directement le niveau
de difﬁculté des phrases simpliﬁées retenues.

Pour illustrer ce processus, prenons le texte de départ pour l’article de Wikipédia intitulé Abel.

Il comprenait 25 phrases, ‘a partir desquelles 67 phrases simpliﬁées ont été produites. Parmi le
texte simpliﬁé, nous observons que ce sont les phrases 3 de l’exemple (4b) qui remplacent la
phrase du texte original (exemple (4a)) :
(4a) Phrase d’origine (Phrase 1) : Cain, Paine’, cultive la terre et Abel ( étymologie : de
l’he’breu " souﬁle ", " vapeur ", " existence pre’caire " ) garde le troupeau.

8. Elle est notamment disponible sur le site h1:1:p:/ / www. ia93 . ac— creteil . fr/spip/spip. php?
art icle2900.
9. Le module repose sur glpk qui est disponible a1’adresse suivante : http: //www. gnu. org/so:E1:ware/g1pk/

219

(4b) Simpliﬁcations possibles :

Phrase 2 : Cain, l’ai‘ne’, cultive la terre et Abel garde le troupeau.

Phrases 3 : Cain, l’ai‘ne’, cultive la terre. Abel garde le troupeau.

Phrase 4 : Cain, l’ai‘ne’, cultive la terre.

Phrase 5 :Abel garde le troupeau.

Phrases 6 : Cain, l’ai‘ne’, cultive la terre. Abel ( étymologie : de l’he'breu " souﬁle ", "
vapeur ", " existence pre’caire " ) garde le troupeau.

Phrase 7 :Abel ( étymologie : de l’hébreu " souffle ", " vapeur ", " existence précaire " )
garde le troupeau.

(4c) Simpliﬁcation sélectionnée (Phrase 3) : Cain, Paine’, cultive la terre. Abel garde le
troupeau.

Les valeurs des paramétres pour chaque phrase de l’exemple (4) sont données dans la table 2.

Longueur Longueur Familiarité Terrnes clés
de la phrase des mots des mots
Valeurs souhaitées 10 mots 5 caractéres 2 mots absents
Phrase 1 19 mots 6,1 caractéres 11 mots absents 5 termes
Phrase 2 11 mots 4,3 caractéres 5 mots absents 5 termes
Phrases 3 5 mots 4,6 caractéres 2 mots absents 5 termes
Phrase 4 6 mots 4,5 caractéres 3 mots absents 3 termes
Phrase 5 4 mots 4,7 caractéres 2 mots absents 2 termes
Phrases 6 9 mots 6,3 caractéres 5 mots absents 5 termes
Phrase 7 12 mots 7,3 caractéres 8 mots absents 2 termes

TABLE 2 — Valeurs des paramétres pour les phrases de l’exemple (4)

3 Evaluation

La simpliﬁcation syntaxique implique des modiﬁcations importantes au sein de la phrase aussi
bien au niveau du contenu que de la forme. C’est pourquoi il est important de vériﬁer que
l’application d’une régle ne provoque pas des erreurs qui rendraient les phrases produites
incompréhensibles ou agrammaticales. Une évaluation manuelle de notre systéme de génération
de phrases simpliﬁées a donc été réalisée dans ce but. Elle repose sur un nouveau corpus composé
de neuf articles de Wikipédia, c’est-a-dire de 202 phrases. Les résultats obtenus sont détaillés a la
table 3 et dans la Section 3.1. Nous y détectons deux grands types d’erreurs, a savoir les erreurs
d’analyse (morpho-)syntaxique et les erreurs de simpliﬁcation. Celles-ci sont discutées dans les
Sections 3.2 et 3.3.

3.1 Données obtenues

Sur les 202 phrases qui composent le corpus d’évaluation, 113 d’entre elles (56%) ont subi
une ou plusieurs simpliﬁcations. Ces 113 phrases auxquelles des régles ont pu étre appliquées
donnent lieu ‘a 333 variantes susceptibles de comporter des erreurs. C’est effectivement le cas
de 71 d’entre elles (21,32%). Parmi celles-ci, il faut distinguer d’emblée les erreurs dues au

220

