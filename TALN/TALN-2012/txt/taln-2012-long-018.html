<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Etude s&#233;mantique des mots-cl&#233;s et des marqueurs lexicaux stables dans un corpus technique</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 239&#8211;252,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Etude s&#233;mantique des mots-cl&#233;s et des marqueurs 
lexicaux stables dans un corpus technique 
</p>
<p>Ann Bertels1,2   Dirk De Hertog2   Kris Heylen2 
(1) ILT, KU Leuven, Dekenstraat 6, B-3000 Leuven (Belgique) 
</p>
<p>(2) QLVL, KU Leuven, Faculty of Arts, Blijde-Inkomststraat 21, B-3000 Leuven (Belgique) 
ann.bertels@ilt.kuleuven.be, dirk.dehertog@arts.kuleuven.be, 
</p>
<p>kris.heylen@arts.kuleuven.be 
RESUME ____________________________________________________________________________________________________________   
&#8232;Cet article pr&#233;sente les r&#233;sultats d&#8217;une analyse s&#233;mantique quantitative des unit&#233;s 
lexicales sp&#233;cifiques dans un corpus technique, relevant du domaine des machines-outils 
pour l&#8217;usinage des m&#233;taux. L&#8217;&#233;tude vise &#224; v&#233;rifier si et dans quelle mesure les mots-cl&#233;s 
du corpus technique sont monos&#233;miques. A cet effet, nous proc&#233;dons &#224; une analyse 
statistique de r&#233;gression simple, qui permet d&#8217;&#233;tudier la corr&#233;lation entre le rang de 
sp&#233;cificit&#233; des mots-cl&#233;s et leur rang de monos&#233;mie, mais qui soul&#232;ve des probl&#232;mes 
statistiques et m&#233;thodologiques, notamment un biais de fr&#233;quence. Pour y rem&#233;dier, 
nous adoptons une approche alternative pour le rep&#233;rage des unit&#233;s lexicales sp&#233;cifiques, 
&#224; savoir l&#8217;analyse des marqueurs lexicaux stables ou Stable Lexical Marker Analysis 
(SLMA). Nous discutons les r&#233;sultats quantitatifs et statistiques de cette approche dans la 
perspective de la corr&#233;lation entre le rang de sp&#233;cificit&#233; et le rang de monos&#233;mie. 
ABSTRACT _________________________________________________________________________________________________________  
Semantic analysis of keywords and stable lexical markers in a technical corpus 
This article presents the results of a quantitative semantic analysis of typical lexical units 
in a specialised technical corpus of metalworking machinery in French. The study aims 
to find out whether and to what extent the keywords of the technical corpus are 
monosemous. A simple regression analysis, used to examine the correlation between 
typicality rank and monosemy rank of the keywords, points out some statistical and 
methodological problems, notably a frequency bias. In order to overcome these 
problems, we adopt an alternative approach for the identification of typical lexical units, 
called Stable Lexical Marker Analysis (SLMA). We discuss the quantitative and statistical 
results of this approach with respect to the correlation between typicality rank and 
monosemy rank. 
MOTS-CLES : unit&#233;s lexicales sp&#233;cifiques, analyse des mots-cl&#233;s, analyse des marqueurs 
lexicaux stables, s&#233;mantique quantitative, analyse de r&#233;gression.  
KEYWORDS : typical lexical units, Keyword Analysis, Stable Lexical Marker Analysis 
(SLMA), quantitative semantics, regression analysis. 
</p>
<p>1 Introduction 
</p>
<p>Cette communication s&#8217;inscrit dans le contexte d&#8217;une &#233;tude s&#233;mantique quantitative 
effectu&#233;e sur un corpus de textes techniques relevant du domaine technique sp&#233;cialis&#233; 
des machines-outils pour l&#8217;usinage des m&#233;taux. L&#8217;&#233;tude vise &#224; v&#233;rifier si et dans quelle 
mesure les unit&#233;s lexicales sp&#233;cifiques du corpus technique sont monos&#233;miques. Selon la 
</p>
<p>239</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Terminologie traditionnelle, qui adopte une approche onomasiologique et prescriptive, la 
langue sp&#233;cialis&#233;e se caract&#233;rise par la monos&#233;mie et l&#8217;univocit&#233; (W&#252;ster, 1991). Les 
termes de la langue sp&#233;cialis&#233;e sont id&#233;alement monos&#233;miques, tandis que la polys&#233;mie 
est r&#233;serv&#233;e aux mots de la langue g&#233;n&#233;rale. Cela aboutit &#224; une double dichotomie, qui 
oppose les termes de la langue sp&#233;cialis&#233;e aux mots de la langue g&#233;n&#233;rale et la 
monos&#233;mie &#224; la polys&#233;mie. R&#233;cemment, l&#8217;id&#233;al de monos&#233;mie dans la langue sp&#233;cialis&#233;e 
ainsi que la double dichotomie ont &#233;t&#233; remis en question par les partisans de la 
terminologie descriptive et linguistique, s&#233;masiologique, distributionnelle et 
(con)textuelle (Bourigault et Slodzian, 1999 ; Cabr&#233;, 2000 ; Temmerman, 2000 ; Gaudin, 
2003). Par ailleurs, des exp&#233;rimentations ponctuelles men&#233;es sur des corpus sp&#233;cialis&#233;s 
ont abouti &#224; l&#8217;observation de cas de polys&#233;mie dans la langue sp&#233;cialis&#233;e, m&#234;me &#224; 
l&#8217;int&#233;rieur d&#8217;un domaine sp&#233;cialis&#233; (Condamines et Rebeyrolle, 1997 ; Eriksen, 2002 ; 
Ferrari, 2002). Ces &#233;tudes s&#233;mantiques ponctuelles et qualitatives ainsi que les remises 
en question th&#233;oriques nous ont incit&#233;s &#224; &#233;valuer la th&#232;se monos&#233;miste traditionnelle &#224; 
grande &#233;chelle, dans un corpus de textes techniques, et &#224; adopter une approche 
alternative, quantitative et scalaire.  
Afin de proc&#233;der &#224; une &#233;tude s&#233;mantique &#224; grande &#233;chelle, &#224; partir d&#8217;une analyse de 
corpus, il est n&#233;cessaire de reformuler la th&#232;se monos&#233;miste traditionnelle qualitative en 
une question de recherche quantitative. S&#8217;il est vrai que les unit&#233;s lexicales d&#8217;un corpus 
sp&#233;cialis&#233; sont monos&#233;miques, ce sera d&#8217;autant plus vrai pour les unit&#233;s lexicales les plus 
sp&#233;cifiques et les plus repr&#233;sentatives de ce corpus. Nous examinons donc si les unit&#233;s 
lexicales les plus sp&#233;cifiques du corpus technique sont effectivement les plus 
monos&#233;miques, comme le pr&#233;tendent les partisans de la terminologie traditionnelle, ou 
s&#8217;il existe des unit&#233;s lexicales sp&#233;cifiques qui sont polys&#233;miques, comme le sugg&#232;rent les 
partisans de la terminologie descriptive. A cet effet, nous proc&#233;dons &#224; une double 
analyse quantitative. Pour l&#8217;extraction des unit&#233;s lexicales sp&#233;cifiques et pour le calcul de 
leur degr&#233; de sp&#233;cificit&#233;, nous recourons &#224; l&#8217;analyse des mots-cl&#233;s (Keyword Analysis) 
(Scott, 2006). Pour quantifier l&#8217;analyse s&#233;mantique, nous calculons le degr&#233; de 
monos&#233;mie des mots-cl&#233;s &#224; partir du degr&#233; de recoupement de leurs cooccurrents de 
deuxi&#232;me ordre, par le biais d&#8217;une mesure de recoupement (Bertels et al., 2010). Ces 
donn&#233;es quantitatives de sp&#233;cificit&#233; et de monos&#233;mie m&#232;nent ensuite &#224; une analyse 
statistique de r&#233;gression simple. Elle consiste &#224; &#233;tudier la corr&#233;lation entre le rang de 
sp&#233;cificit&#233; et le rang de monos&#233;mie, pour ainsi r&#233;pondre &#224; la question de recherche 
quantitative. Les r&#233;sultats de l&#8217;analyse statistique confirment les observations des &#233;tudes 
s&#233;mantiques ant&#233;rieures et permettent de r&#233;futer la th&#232;se monos&#233;miste traditionnelle, 
comme nous l&#8217;avons d&#233;crit pr&#233;c&#233;demment (Bertels et al., 2010). Dans cet article, nous 
discutons la pertinence de l&#8217;analyse des mots-cl&#233;s pour l&#8217;identification des unit&#233;s 
sp&#233;cifiques et nous proposons une approche m&#233;thodologique alternative.  
Il est &#224; noter que cet article ne se situe pas dans le domaine de l&#8217;extraction de termes. 
Cette discipline se caract&#233;rise par un classement cat&#233;goriel (termes vs non-termes), alors 
que nous visons &#224; &#233;tudier la sp&#233;cificit&#233; dans une perspective graduelle. Nous n&#8217;avons pas 
l&#8217;intention d&#8217;extraire la terminologie du domaine technique des machines-outils pour 
l&#8217;usinage des m&#233;taux. Nous cherchons avant tout &#224; r&#233;pondre &#224; notre question de 
recherche, soulev&#233;e par le corpus de langue sp&#233;cialis&#233;e, qui consiste &#224; &#233;tudier la 
corr&#233;lation entre la sp&#233;cificit&#233; et la monos&#233;mie.  
</p>
<p>240</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Dans cet article, nous expliquons d&#8217;abord la m&#233;thodologie et les r&#233;sultats de l&#8217;&#233;tude 
s&#233;mantique des mots-cl&#233;s du corpus technique (section 2), ainsi que les probl&#232;mes 
statistiques et m&#233;thodologiques (section 3). Ensuite, nous pr&#233;sentons une autre approche 
pour l&#8217;identification des unit&#233;s lexicales sp&#233;cifiques et pour le calcul de leur degr&#233; de 
sp&#233;cificit&#233;, &#224; savoir l&#8217;analyse des marqueurs lexicaux stables ou Stable Lexical Marker 
Analysis (section 4). Nous discutons finalement les r&#233;sultats quantitatifs et statistiques de 
cette approche dans la perspective de la corr&#233;lation entre le rang de sp&#233;cificit&#233; et le rang 
de monos&#233;mie (section 5). 
</p>
<p>2 Etude s&#233;mantique des mots-cl&#233;s du corpus technique 
</p>
<p>Le corpus technique constitu&#233; dans le cadre de cette &#233;tude rel&#232;ve du domaine sp&#233;cialis&#233; 
des machines-outils pour l&#8217;usinage des m&#233;taux et il comprend 1,7 million d&#8217;occurrences. 
Il a &#233;t&#233; &#233;tiquet&#233; par Cordial 7 Analyseur et consiste en 4 sous-corpus, datant de 1996 &#224; 
2002, &#224; savoir des revues &#233;lectroniques (800.000 occurrences), des fiches techniques 
(300.000), des normes ISO et directives (300.000) et 4 manuels num&#233;ris&#233;s (360.000). Le 
corpus de r&#233;f&#233;rence de langue g&#233;n&#233;rale compte 15,3 millions d&#8217;occurrences lemmatis&#233;es 
et il est constitu&#233; d&#8217;articles du journal Le Monde de la m&#234;me p&#233;riode (1998).  
</p>
<p>2.1 Identification des unit&#233;s lexicales sp&#233;cifiques 
Pour le rep&#233;rage des unit&#233;s lexicales sp&#233;cifiques, plusieurs approches m&#233;thodologiques 
sont envisageables. Elles permettent de g&#233;n&#233;rer une liste d&#8217;unit&#233;s sp&#233;cifiques, pourvues 
d&#8217;une indication de leur degr&#233; de sp&#233;cificit&#233;. Les diff&#233;rences les plus importantes r&#233;sident 
dans la m&#233;thodologie et les mesures statistiques sous-jacentes. La m&#233;thodologie du calcul 
des sp&#233;cificit&#233;s (Lafon, 1984 ; Labb&#233; et Labb&#233;, 2001) est bas&#233;e sur la distribution 
hyperg&#233;om&#233;trique et sur le test statistique de Fisher Exact 1 . Elle est impl&#233;ment&#233;e 
notamment dans Lexico32, Hyperbase3 et TermoStat4. Du point de vue m&#233;thodologique, 
le calcul des sp&#233;cificit&#233;s proc&#232;de par comparaison partie-tout. Une section d&#8217;un corpus 
est compar&#233;e au corpus entier dans le but d&#8217;identifier les mots sp&#233;cifiques de la section 
par rapport au corpus entier. Le calcul des sp&#233;cificit&#233;s utilise seulement des informations 
appartenant au domaine en question. Le r&#233;sultat est un coefficient de sp&#233;cificit&#233;. Plus 
&#233;lev&#233; ce coefficient, plus faible sera la probabilit&#233; de la fr&#233;quence observ&#233;e (par rapport 
au corpus entier) et plus sp&#233;cifique sera le mot. L&#8217;analyse des mots-cl&#233;s (Keyword 
Analysis) (Scott, 2006) se caract&#233;rise par une approche contrastive, qui consiste &#224; 
comparer les fr&#233;quences relatives des mots dans un corpus sp&#233;cialis&#233; &#224; celles dans un 
corpus de r&#233;f&#233;rence de langue g&#233;n&#233;rale. Un mot est &#171; cl&#233; &#187; ou sp&#233;cifique dans le corpus 
sp&#233;cialis&#233; si sa fr&#233;quence relative dans ce corpus est plus &#233;lev&#233;e que sa fr&#233;quence relative 
                                                   
1 Le test statistique de Fisher Exact est g&#233;n&#233;ralement utilis&#233; pour des donn&#233;es de taille modeste, des corpus peu 
volumineux et des fr&#233;quences plut&#244;t faibles (n &lt; 20). 
2 SYLED &#8211; CLA2T, Paris3 : http://www.tal.univ-paris3.fr/lexico/. [consult&#233; le 20/01/2012].  
3 Hyperbase : http://ancilla.unice.fr/~brunet/pub/hyperbase.html. [consult&#233; le 20/01/2012].  
4  TermoStat : http://olst.ling.umontreal.ca/~drouinp/termostat_web/doc_termostat/doc_termostat.html. 
[consult&#233; le 20/01/2012].  Dans TermoStat le corpus de r&#233;f&#233;rence et le corpus d&#8217;analyse sont fusionn&#233; en un 
corpus virtuel, pour v&#233;rifier si le lexique du corpus d&#8217;analyse se comporte comme celui du corpus de r&#233;f&#233;rence. 
</p>
<p>241</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>dans le corpus de r&#233;f&#233;rence et si la diff&#233;rence de fr&#233;quence est statistiquement 
significative. Une mesure statistique, comme le rapport de vraisemblance (Log-Likelihood 
Ratio ou LLR ou G&#178;) (Dunning, 1993), permet de d&#233;cider s&#8217;il s&#8217;agit d&#8217;un mot-cl&#233; du 
corpus sp&#233;cialis&#233;. L&#8217;analyse des mots-cl&#233;s est impl&#233;ment&#233;e notamment dans WordSmith5, 
AntConc6, TermoStat et AV Frequency List Tool7.  
Pour identifier le vocabulaire sp&#233;cifique de notre corpus technique, nous adoptons 
l&#8217;analyse des mots-cl&#233;s, parce qu&#8217;elle compare deux corpus diff&#233;rents.  Nous recourons &#224; 
la mesure statistique du log de vraisemblance (LLR), qui permet de conduire &#224;  des 
possibilit&#233;s de classement pr&#233;cis et donc &#224; des degr&#233;s de sp&#233;cificit&#233; avec une granularit&#233; 
aussi fine que possible. Plusieurs &#233;tudes ant&#233;rieures ont valid&#233; la mesure du LLR et 
d&#233;montr&#233; la pertinence de l&#8217;analyse des mots-cl&#233;s pour relever les unit&#233;s sp&#233;cifiques d&#8217;un 
domaine particulier (Paquot et al., 2009 ; Kwary, 2011). Nous nous limitons dans cette 
&#233;tude au niveau des unit&#233;s simples, comme fraisage, commande, machine. Des recherches 
futures devront certainement porter sur l&#8217;&#233;tude des unit&#233;s polylexicales, telles que 
machine &#224; fraiser, commande num&#233;rique, puisque la plupart des unit&#233;s terminologiques 
d&#8217;un domaine sp&#233;cialis&#233; se situent au niveau des unit&#233;s complexes8. L&#8217;analyse des mots-
cl&#233;s est effectu&#233;e dans AV Frequency List Tool, &#224; partir de deux listes de fr&#233;quence des 
lemmes des deux corpus, r&#233;alis&#233;es &#224; l&#8217;aide de scripts en Python. Le logiciel AV g&#233;n&#232;re 
une liste de lemmes sp&#233;cifiques du corpus technique et indique leur degr&#233; de sp&#233;cificit&#233;, 
&#224; savoir la valeur du LLR (keyness), et une valeur p associ&#233;e. Nous relevons 4717 mots-
cl&#233;s (p&lt;0,05), apr&#232;s suppression des mots grammaticaux, des noms propres et des 
hapax. Le degr&#233; de sp&#233;cificit&#233; ou de keyness permet de situer ces 4717 mots-cl&#233;s sur un 
continuum de sp&#233;cificit&#233; et de leur accorder un rang de sp&#233;cificit&#233;. 
</p>
<p>2.2 Quantification de l&#8217;analyse s&#233;mantique 
Les 4717 mots-cl&#233;s font ensuite l&#8217;objet d&#8217;une analyse s&#233;mantique quantitative et 
automatis&#233;e. A cet effet, nous recourons &#224; l&#8217;analyse des cooccurrences (Grossmann et al., 
2003 ; Condamines 2005 ;  Blumenthal et Hausmann, 2006 ; Mayaffre 2008), parce 
qu&#8217;elle permet de quantifier et d&#8217;objectiver la monos&#233;mie en l&#8217;impl&#233;mentant en termes 
d&#8217;homog&#233;n&#233;it&#233; s&#233;mantique (Habert et al., 2005). Une unit&#233; lexicale monos&#233;mique 
                                                   
5 WordSmith Tools : http://www.lexically.net/wordsmith/. [consult&#233; le 20/01/2012].   
6 AntConc : http://www.antlab.sci.waseda.ac.jp/software.html. [consult&#233; le 20/01/2012].  
7 AV Frequency List Tool : http://wwwling.arts.kuleuven.be/av-tools/. [consult&#233; le 20/01/2012]. 
8 Plusieurs outils d&#8217;extraction terminologique, tels que LEXTER (Bourigault et al. 2001), permettent de rep&#233;rer 
les unit&#233;s polylexicales. Toutefois celles-ci posent probl&#232;me lors du calcul des sp&#233;cificit&#233;s. Pour l&#8217;instant, il n&#8217;est 
pas possible de d&#233;terminer le degr&#233; de sp&#233;cificit&#233; des unit&#233;s complexes de fa&#231;on fiable et statistiquement 
significative, notamment parce que la plupart d&#8217;entre elles sont absentes dans un corpus de r&#233;f&#233;rence de langue 
g&#233;n&#233;rale. Par ailleurs, les techniques d&#8217;extraction automatique de termes s&#8217;appuient souvent sur un algorithme 
hybride avec une composante syntaxique importante, c&#8217;est-&#224;-dire des structures syntaxiques r&#233;currentes (Lemay 
et al., 2005). Ainsi, plusieurs variables concourent au rep&#233;rage des unit&#233;s terminologiques complexes plut&#244;t 
qu&#8217;une seule. Or, l&#8217;analyse de r&#233;gression &#224; laquelle nous proc&#233;dons pour &#233;tudier la corr&#233;lation entre les donn&#233;es 
de sp&#233;cificit&#233; et de monos&#233;mie, requiert une seule variable linguistique, c&#8217;est-&#224;-dire un crit&#232;re de sp&#233;cificit&#233; 
clair et pr&#233;cis. 
</p>
<p>242</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>appara&#238;t dans des contextes plut&#244;t homog&#232;nes s&#233;mantiquement. Par contre, une unit&#233; 
lexicale polys&#233;mique se caract&#233;rise par des cooccurrents plus h&#233;t&#233;rog&#232;nes 
s&#233;mantiquement, qui appartiennent &#224; des champs s&#233;mantiques diff&#233;rents (V&#233;ronis, 2003 ; 
Habert et al., 2004). L&#8217;acc&#232;s &#224; la s&#233;mantique des cooccurrents de premier ordre (ou c) 
peut se faire &#224; partir de leurs cooccurrents, c&#8217;est-&#224;-dire les cooccurrents de deuxi&#232;me 
ordre (ou cc). Ceux-ci se caract&#233;risent principalement par des relations paradigmatiques 
avec le mot de base (hyponymes, hyperonymes, synonymes, antonymes) et d&#232;s lors ils 
sont int&#233;ressants pour caract&#233;riser s&#233;mantiquement le mot de base. Ils ont permis entre 
autres de mettre en &#233;vidence des relations de synonymie (Martinez, 2000).  
Si les cooccurrents de premier ordre d&#8217;un mot de base, en l&#8217;occurrence un mot-cl&#233;, 
partagent beaucoup de cooccurrents de deuxi&#232;me ordre, ces derniers se recoupent 
formellement, ce qui constitue une indication de l&#8217;homog&#233;n&#233;it&#233; s&#233;mantique des 
cooccurrents de premier ordre et, d&#232;s lors, du mot de base. Le degr&#233; de monos&#233;mie d&#8217;un 
mot-cl&#233; pourra donc &#234;tre d&#233;termin&#233; en fonction du degr&#233; de recoupement formel de ses 
cooccurrents de deuxi&#232;me ordre. Une repr&#233;sentation sch&#233;matique (Cf. figure 1) fait 
intervenir un mot-cl&#233;, ses 5 c diff&#233;rents et tous leurs c (10 cc diff&#233;rents et 26 cc au total). 
Ce sch&#233;ma permettra d&#8217;expliquer le poids de chaque cc pour le recoupement global. Un 
cc partag&#233; par tous les c (p.ex. cc3), figure 5 fois dans la liste des cc, constitu&#233;e de 5 blocs 
de cc (un bloc par c). Le cc figurant 5 fois aura donc un poids maximal de 5/5. Par 
contre, un cc qui figure dans un seul bloc (p.ex. cc2 ou cc4) est un cc isol&#233; avec un poids 
minimal de 1/5. De m&#234;me, le poids d&#8217;un cc qui figure 2 fois dans la liste des cc ou dans 2 
blocs (p.ex. cc5) &#233;quivaut &#224; 2/5. Ainsi, on pourra calculer facilement le poids de chaque 
cc dans la liste des 26 cc. Le poids de chaque cc correspond au rapport entre la fr&#233;quence 
du cc dans la liste des cc et le nombre de c. Pour conna&#238;tre le recoupement global, 
calcul&#233; &#224; partir du recoupement de tous les cc, on fera d&#8217;abord la somme des poids 
individuels (donc 26 r&#233;it&#233;rations du calcul pr&#233;c&#233;dent). Ce r&#233;sultat sera divis&#233; par 26 
(nombre total de cc dans la liste), parce que chaque cc contribue pour 1/26 au 
recoupement global calcul&#233; pour le mot-cl&#233;. Le r&#233;sultat final se situe toujours entre 0 et 1 
et repr&#233;sente le degr&#233; de recoupement moyen pour un mot-cl&#233;, c&#8217;est-&#224;-dire son degr&#233; 
d&#8217;homog&#233;n&#233;it&#233; s&#233;mantique.  
</p>
<p> 
</p>
<p>FIGURE 1 &#8211; Sch&#233;ma : mot-cl&#233; + cooccurrents de premier et de deuxi&#232;me ordre. 
L&#8217;analyse des cooccurrences est effectu&#233;e, de fa&#231;on r&#233;currente, dans une fen&#234;tre 
d&#8217;observation (ou span) de 5 mots &#224; gauche et 5 mots &#224; droite, sans informations de 
position ni d&#8217;orientation. Cette fen&#234;tre apporte suffisamment d&#8217;informations s&#233;mantiques 
pertinentes, sans introduire trop de bruit, et permet un traitement informatique efficace. 
</p>
<p>243</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Les cooccurrents de premier et de deuxi&#232;me ordre sont consid&#233;r&#233;s au niveau des formes 
graphiques, ce qui permet de faire la distinction entre, par exemple, pi&#232;ce usin&#233;e 
(&#171; r&#233;sultat &#187;) et pi&#232;ce &#224; usiner (&#171; avant le processus d&#8217;usinage &#187;) et d&#232;s lors de tenir 
compte de la diff&#233;rence s&#233;mantique. La mesure d&#8217;association utilis&#233;e pour d&#233;terminer les 
cooccurrents statistiquement pertinents est la mesure statistique du LLR (log du rapport 
de vraisemblance). Le seuil de significativit&#233; tr&#232;s s&#233;v&#232;re (valeur p&lt;0,0001) permet de 
relever uniquement les cooccurrents de premier et de deuxi&#232;me ordre s&#233;mantiquement 
pertinents. La mesure de recoupement est concr&#233;tis&#233;e &#224; l&#8217;aide de scripts en Python pour 
calculer le degr&#233; de recoupement des 4717 mots-cl&#233;s &#224; partir du recoupement formel de 
leurs cooccurrents de deuxi&#232;me ordre. Ce degr&#233; de recoupement ou d&#8217;homog&#233;n&#233;it&#233; 
s&#233;mantique permet de situer les 4717 mots-cl&#233;s sur un continuum d&#8217;homog&#233;n&#233;it&#233; 
s&#233;mantique ou de monos&#233;mie et permet de leur accorder un rang de monos&#233;mie.  
Comme nous ne disposons pas de listes de sens pr&#233;&#233;tablis, ni d&#8217;autres mesures 
s&#233;mantiques comparables, nous avons proc&#233;d&#233; &#224; une validation manuelle de la mesure 
de recoupement &#224; partir de l&#8217;analyse manuelle des cooccurrents les plus pertinents, ainsi 
qu&#8217;&#224; une validation externe au moyen de dictionnaires. Les r&#233;sultats de ces validations 
confirment les r&#233;sultats de notre mesure de recoupement pour un &#233;chantillon de 50 
mots-cl&#233;s. Il est &#224; noter que des recherches suppl&#233;mentaires s&#8217;imposent pour examiner la 
relation pr&#233;cise entre, d&#8217;une part, notre mesure de monos&#233;mie, impl&#233;mentant la 
monos&#233;mie en termes d&#8217;homog&#233;n&#233;it&#233; s&#233;mantique, et, d&#8217;autre part, ce que l&#8217;on consid&#232;re 
traditionnellement comme monos&#233;mie ou polys&#233;mie. Nous recourons &#224; cette mesure, 
dans le but op&#233;rationnel de d&#233;velopper un crit&#232;re mesurable. Sans recherches 
suppl&#233;mentaires, il serait impossible d&#8217;affirmer que les degr&#233;s de monos&#233;mie calcul&#233;s 
correspondent parfaitement &#224; ce que les terminologues traditionnels consid&#232;rent comme 
monos&#233;mie ou polys&#233;mie. Notons toutefois que ces derniers omettent de fournir des 
crit&#232;res op&#233;rationnels &#224; ce sujet. 
</p>
<p>2.3 Corr&#233;lation entre la sp&#233;cificit&#233; et la monos&#233;mie  
Pour r&#233;pondre &#224; la question de recherche et pour examiner la corr&#233;lation entre le 
continuum de sp&#233;cificit&#233; et le continuum de monos&#233;mie (ou d&#8217;homog&#233;n&#233;it&#233; s&#233;mantique), 
les donn&#233;es quantitatives de sp&#233;cificit&#233; et de monos&#233;mie sont soumises &#224; une analyse 
statistique de r&#233;gression lin&#233;aire simple. Celle-ci permet d&#8217;&#233;tudier l&#8217;impact d&#8217;une variable 
ind&#233;pendante ou explicative (ici : le rang de sp&#233;cificit&#233;) sur la variable d&#233;pendante ou 
expliqu&#233;e (ici : le rang de monos&#233;mie). Le r&#233;sultat de cette analyse est le coefficient de 
d&#233;termination ou le pourcentage de variation expliqu&#233;e R&#178;. Il repr&#233;sente le pourcentage 
de la variation du rang de monos&#233;mie que l&#8217;on pourra expliquer ou pr&#233;dire &#224; partir de la 
variation du rang de sp&#233;cificit&#233; des 4717 mots-cl&#233;s.  
Les r&#233;sultats de l&#8217;analyse de r&#233;gression simple permettent d&#8217;infirmer la th&#232;se 
monos&#233;miste traditionnelle, car ils montrent une corr&#233;lation n&#233;gative (coefficient de 
corr&#233;lation Pearson de -0,72) et un pourcentage de variation expliqu&#233;e R&#178; de 51,57% 
(valeur p&lt;2,2e-16). Il s&#8217;av&#232;re donc que les mots-cl&#233;s les plus sp&#233;cifiques du corpus 
technique ne sont pas les plus monos&#233;miques, mais, au contraire, les plus h&#233;t&#233;rog&#232;nes 
s&#233;mantiquement (p.ex. machine, pi&#232;ce, tour). En plus, les mots-cl&#233;s les moins sp&#233;cifiques 
du corpus technique sont les plus homog&#232;nes s&#233;mantiquement (par exemple 
rationnellement, t&#233;l&#233;diagnostic), &#224; quelques exceptions pr&#232;s (service et objet). En effet, la 
</p>
<p>244</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>visualisation ci-dessous (Cf. figure 2) montre que la droite de r&#233;gression s&#8217;incline vers le 
bas. Parmi les mots-cl&#233;s sp&#233;cifiques qui sont h&#233;t&#233;rog&#232;nes s&#233;mantiquement, nous 
retrouvons effectivement des unit&#233;s polys&#233;miques, telles que d&#233;coupe, dont les 
sens &#171; action de d&#233;couper &#187; et &#171; r&#233;sultat de la d&#233;coupe &#187; se caract&#233;risent par une relation 
m&#233;tonymique. Nous recensons &#233;galement des homonymes (tels que tour), ainsi que des 
mots vagues (comme usinage) dont le sens sous-d&#233;termin&#233; est pr&#233;cis&#233; par le contexte 
linguistique. 
</p>
<p> 
FIGURE 2 &#8211; Visualisation de l&#8217;analyse de r&#233;gression. 
</p>
<p>3 Probl&#232;mes statistiques et m&#233;thodologiques 
</p>
<p>3.1 H&#233;t&#233;rosc&#233;dasticit&#233; : mots g&#233;n&#233;raux 
La visualisation ci-dessus (Cf. figure 2) montre que la corr&#233;lation n&#233;gative ne s&#8217;applique 
pas &#224; tous les mots-cl&#233;s et qu&#8217;elle n&#8217;est pas tout &#224; fait lin&#233;aire. Le test statistique de 
Goldfeld-Quandt soul&#232;ve effectivement un probl&#232;me statistique d&#8217;h&#233;t&#233;rosc&#233;dasticit&#233; 
(statistique F du GQ-test 2,07), ce qui veut dire que les variances des erreurs ne sont pas 
constantes. En effet, certaines observations se caract&#233;risent par un r&#233;sidu important, 
c&#8217;est-&#224;-dire par une grande diff&#233;rence entre leur valeur observ&#233;e et la valeur estim&#233;e par 
le mod&#232;le de r&#233;gression, par exemple service, objet, commercial. L&#8217;&#233;cart (ou le r&#233;sidu) 
entre leur valeur observ&#233;e (visualis&#233;e par la petite boule) et leur valeur estim&#233;e situ&#233;e 
sur la droite de r&#233;gression est tr&#232;s important, ce qui donne lieu &#224; une erreur importante 
lors de la pr&#233;diction de leur rang de monos&#233;mie &#224; partir de leur rang de sp&#233;cificit&#233;. Ces 
mots se situent principalement dans la partie sup&#233;rieure droite, c&#8217;est-&#224;-dire parmi les 
mots-cl&#233;s les moins sp&#233;cifiques. Ils sont plus polys&#233;miques qu&#8217;on n&#8217;aurait cru en prenant 
en consid&#233;ration leur rang de sp&#233;cificit&#233;. 
</p>
<p>245</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Ce sont majoritairement des mots g&#233;n&#233;raux, tr&#232;s fr&#233;quents dans le corpus de r&#233;f&#233;rence et 
d&#232;s lors peu sp&#233;cifiques dans le corpus technique, en d&#233;pit de leur fr&#233;quence &#233;lev&#233;e dans 
le corpus technique. Pour ces mots, qui se trouvent dans la zone marginale de sp&#233;cificit&#233; 
(valeur p l&#233;g&#232;rement inf&#233;rieure &#224; 0,05), le mod&#232;le de r&#233;gression n&#8217;est pas une bonne 
pr&#233;diction de leur rang de monos&#233;mie &#224; partir de leur rang de sp&#233;cificit&#233;. Ces mots sont 
h&#233;t&#233;rog&#232;nes s&#233;mantiquement et se caract&#233;risent par une polys&#233;mie &#224; la fois g&#233;n&#233;rale et 
technique : leurs (divers) sens g&#233;n&#233;raux se retrouvent aussi dans le corpus technique. Ils 
sont plut&#244;t h&#233;t&#233;rog&#232;nes s&#233;mantiquement, quel que soit leur rang de sp&#233;cificit&#233;. 
</p>
<p>3.2 Multicollin&#233;arit&#233; : fr&#233;quence technique 
Le deuxi&#232;me probl&#232;me est soulev&#233; par une analyse statistique de r&#233;gression multiple, qui 
&#233;value l&#8217;impact combin&#233; et simultan&#233; de plusieurs variables ind&#233;pendantes sur la 
variable d&#233;pendante. Parfois, deux ou plusieurs variables ind&#233;pendantes sont corr&#233;l&#233;es 
les unes avec les autres. Elles expliquent en grande partie la m&#234;me variation de la 
variable d&#233;pendante, ce que l&#8217;on qualifie de probl&#232;me de multicollin&#233;arit&#233;9. 
Pour les 4717 mots-cl&#233;s, nous observons un probl&#232;me de multicollin&#233;arit&#233; pour trois 
variables, &#224; savoir le log du LLR, le rang de sp&#233;cificit&#233; et le rang de fr&#233;quence technique. 
En effet, il y a une corr&#233;lation (trop) importante (0,87) entre la valeur du LLR, utilis&#233;e 
pour identifier et classer les mots-cl&#233;s, et la fr&#233;quence technique. Par ailleurs, la mesure 
statistique du LLR est trop sensible &#224; la fr&#233;quence technique, car pour les fr&#233;quences 
techniques (tr&#232;s) &#233;lev&#233;es, elle gonfle la valeur du LLR et d&#232;s lors le degr&#233; de sp&#233;cificit&#233;. Il 
s&#8217;ensuit que les mots tr&#232;s fr&#233;quents dans le corpus technique ont un degr&#233; de sp&#233;cificit&#233; 
relativement plus &#233;lev&#233; que les mots moyennement ou faiblement fr&#233;quents. Par 
cons&#233;quent, certains mots tr&#232;s fr&#233;quents se situent &#224; tort parmi les mots les plus 
sp&#233;cifiques. Bien entendu, dans l&#8217;analyse de r&#233;gression simple, nous consid&#233;rons le rang 
de sp&#233;cificit&#233;, qui permet tout de m&#234;me d&#8217;effacer les diff&#233;rences trop importantes en 
termes de degr&#233;s de sp&#233;cificit&#233;. Notons &#233;galement que la fr&#233;quence technique &#233;lev&#233;e de 
certains mots s&#8217;explique par leur fr&#233;quence tr&#232;s &#233;lev&#233;e dans une des parties du corpus, en 
d&#233;pit de leur fr&#233;quence plut&#244;t normale dans les autres parties. Ce biais de fr&#233;quence 
local est souvent caus&#233; par un biais de sujet (topical bias). En effet, le calcul du degr&#233; de 
sp&#233;cificit&#233; compare la fr&#233;quence relative dans le corpus technique entier (de 1,7 million 
de mots) &#224; la fr&#233;quence dans le corpus g&#233;n&#233;ral entier (de 15,3 millions de mots), sans 
tenir compte de la dispersion des mots &#224; travers les corpus. Or, la prise en consid&#233;ration 
de la dispersion des mots s&#8217;av&#232;re importante lors de l&#8217;extraction des mots-cl&#233;s (Paquot et 
al., 2009). Comme notre corpus technique consiste en 4 sous-corpus (revues, fiches 
techniques, normes et manuels), cette h&#233;t&#233;rog&#233;n&#233;it&#233; des sources aura probablement un 
impact sur la dispersion et la sp&#233;cificit&#233; des unit&#233;s lexicales sp&#233;cifiques.  
En conclusion, deux probl&#232;mes se posent. D&#8217;une part, il y a trop de mots g&#233;n&#233;raux parmi 
les mots-cl&#233;s et ils entra&#238;nent un effet perturbateur et de ce fait un probl&#232;me statistique 
d&#8217;h&#233;t&#233;rosc&#233;dasticit&#233;. D&#8217;autre part, la mesure statistique du LLR est trop sensible &#224; la 
fr&#233;quence technique &#233;lev&#233;e et elle souffre d&#8217;un biais de sujet.  
</p>
<p>                                                   
9 Valeurs VIF dans l&#8217;analyse de r&#233;gression multiple : log du LLR (VIF 36,26), rang de sp&#233;cificit&#233; (VIF 26,32) et 
rang de fr&#233;quence technique (VIF 14,72).  
</p>
<p>246</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4 Solutions 
</p>
<p>Pour rem&#233;dier &#224; ces probl&#232;mes, nous proposons d&#8217;adopter une m&#233;thode alternative, qui 
permet de prendre en consid&#233;ration &#233;galement la dispersion des mots &#224; travers les 
corpus. Ainsi, on &#233;vite qu&#8217;un mot soit sp&#233;cifique du corpus technique &#224; cause de sa 
surrepr&#233;sentation dans une seule partie. Or, la dispersion ne permet pas de r&#233;soudre tout 
le probl&#232;me de la sensibilit&#233; &#224; la fr&#233;quence. Par cons&#233;quent, nous adoptons &#233;galement 
une autre mesure statistique, capable de refl&#233;ter de fa&#231;on plus fiable les unit&#233;s lexicales 
sp&#233;cifiques du corpus technique et leur degr&#233; de sp&#233;cificit&#233;. 
</p>
<p>4.1 Stable Lexical Marker Analysis (SLMA) 
La nouvelle m&#233;thode, appel&#233;e Stable Lexical Marker Analysis (SLMA) ou analyse des 
marqueurs lexicaux stables, a &#233;t&#233; d&#233;velopp&#233;e dans le domaine de la linguistique 
variationnelle (Speelman et al., 2006). Le but &#233;tait d&#8217;identifier les variantes lexicales 
r&#233;gionales typiques ou les &#171; marqueurs lexicaux stables &#187; des diff&#233;rences r&#233;gionales entre 
le n&#233;erlandais utilis&#233; aux Pays-Bas et en Flandre (Belgique) (Speelman et al., 2008). La 
m&#233;thode s&#8217;applique aussi &#224; l&#8217;extraction d&#8217;unit&#233;s terminologiques, par exemple dans le 
domaine juridique de la l&#233;gislation financi&#232;re (De Hertog et al., 2010). La SLMA compare 
deux corpus &#224; partir de leurs listes de fr&#233;quence et permet ainsi d&#8217;identifier les 
diff&#233;rences lexicales consistantes et stables entre les corpus. Elle s&#8217;inspire de la m&#233;thode 
des mots-cl&#233;s de Scott (2006), en ce qu&#8217;elle consiste &#224; comparer des listes de fr&#233;quence 
d&#8217;un corpus d&#8217;analyse &#224; des listes de fr&#233;quence d&#8217;un corpus de r&#233;f&#233;rence. Toutefois, au 
lieu de comparer une liste de fr&#233;quence d&#8217;analyse &#224; une liste de fr&#233;quence de r&#233;f&#233;rence, 
elle compare plusieurs fois de telles listes de fr&#233;quence. Elle fait donc intervenir de 
multiples tests d&#8217;hypoth&#232;se pour ainsi rendre compte de la dispersion. 
En effet, le corpus sp&#233;cialis&#233; est subdivis&#233; en plusieurs partitions (disons n partitions), 
tout comme le corpus de r&#233;f&#233;rence (m partitions). Pour chaque partition des deux corpus, 
on &#233;tablit une liste de fr&#233;quence. Il y a donc n*m listes de fr&#233;quence. Ensuite, chaque 
partition du corpus sp&#233;cialis&#233; A (p.ex. A1, A2, &#8230;, An) est compar&#233;e &#224; chaque partition du 
corpus de r&#233;f&#233;rence B (p.ex. B1, B2, &#8230;, Bm), par le biais de leur liste de fr&#233;quence, ce qui 
revient &#224; n*m comparaisons de partitions. Chaque comparaison par paire de partitions 
permet de g&#233;n&#233;rer une liste de mots-cl&#233;s sp&#233;cifiques de la partition sp&#233;cialis&#233;e (LLR et 
valeur p&lt;0,05). Les mots qui sont sp&#233;cifiques dans la plupart de ces comparaisons (au 
maximum n*m) sont qualifi&#233;s de &#171; marqueurs lexicaux stables &#187;, parce qu&#8217;ils sont stables 
et consistants &#224; travers le corpus sp&#233;cialis&#233; entier. Le nombre de comparaisons 
significatives par paire de partitions (qualifi&#233; de SLM) est une premi&#232;re indication du 
degr&#233; de sp&#233;cificit&#233;. Ces unit&#233;s lexicales sont sp&#233;cifiques (globalement relativement plus 
fr&#233;quentes dans le corpus sp&#233;cialis&#233;) et stables (avec une dispersion uniforme &#224; travers le 
corpus sp&#233;cialis&#233;). Le d&#233;coupage des corpus en partitions peut se r&#233;aliser &#224; l&#8217;aide de 
scripts en Python, tout comme les multiples comparaisons des listes de fr&#233;quence.  
</p>
<p>4.2 Odds Ratio 
La mesure statistique du log Odds Ratio (log OR), permet d&#8217;obtenir une indication de 
sp&#233;cificit&#233; &#224; granularit&#233; plus fine que le nombre de comparaisons significatives par paire 
de partitions (SLM). Le log OR permet &#233;galement de prendre en consid&#233;ration la r&#233;elle 
</p>
<p>247</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>importance de la diff&#233;rence de fr&#233;quence d&#8217;un mot dans les deux (partitions de) corpus, 
ce que l&#8217;on qualifie de effect size. Le log OR fait intervenir la fr&#233;quence relative du mot, 
ainsi que celle de tous les autres mots, ce qui &#233;vite de gonfler le r&#233;sultat pour les 
fr&#233;quences &#233;lev&#233;es (Cf. LLR). Pour un mot wk donn&#233;, on calcule ainsi le score SMEA 
(Stable Marker Effect size Analysis), c&#8217;est-&#224;-dire SMEA(wk, A, B), en calculant le log OR 
pour chaque comparaison significative, dans un corpus sp&#233;cialis&#233; A (n partitions) et un 
corpus de r&#233;f&#233;rence B (m partitions). La somme est divis&#233;e par le nombre total de 
comparaisons de partitions.  
</p>
<p>)),,,(*)
/
</p>
<p>/
(log(
</p>
<p>*
</p>
<p>1
),,(
</p>
<p>11
</p>
<p>j
</p>
<p>k
</p>
<p>j
</p>
<p>k
</p>
<p>i
</p>
<p>k
</p>
<p>i
</p>
<p>k
j
</p>
<p>k
</p>
<p>j
</p>
<p>k
</p>
<p>i
</p>
<p>k
</p>
<p>i
</p>
<p>k B
</p>
<p>w
</p>
<p>B
</p>
<p>w
</p>
<p>A
</p>
<p>w
</p>
<p>A
</p>
<p>w
</p>
<p>m
</p>
<p>j
B
</p>
<p>w
</p>
<p>B
</p>
<p>w
</p>
<p>A
</p>
<p>w
</p>
<p>A
</p>
<p>w
n
</p>
<p>i
</p>
<p>k FFFFS
FF
</p>
<p>FF
</p>
<p>mn
BAwSMEA &#61656;&#61656;
</p>
<p>&#61501; &#61656;
</p>
<p>&#61656;
</p>
<p>&#61501;
</p>
<p>&#61669;&#61669;&#61501;  
</p>
<p>avec i
k
</p>
<p>A
</p>
<p>wF  la fr&#233;quence du mot wk dans la partition i du corpus A et 
i
</p>
<p>k
</p>
<p>A
</p>
<p>wF&#61656;  la fr&#233;quence de  
tous les mots autres que wk (et de m&#234;me pour les fr&#233;quences du corpus B). S( ) est une 
fonction bool&#233;enne qui &#233;gale 1 si la distribution des mots est significativement diff&#233;rente 
dans les corpus A et B ; sinon elle &#233;gale 0. Si le nombre de comparaisons significatives 
est plus &#233;lev&#233;, donc si le mot sp&#233;cifique est mieux dispers&#233;, le score SMEA sera plus 
&#233;lev&#233;. Le score SMEA est une indication de la sp&#233;cificit&#233; du mot ainsi que de sa 
dispersion, mais elle &#233;chappe au gonflement pour les mots tr&#232;s fr&#233;quents. Sa granularit&#233; 
tr&#232;s fine permet de classer les marqueurs lexicaux stables et de d&#233;terminer leur nouveau 
rang de sp&#233;cificit&#233;, appel&#233; rang de SMEA. De Hertog et al. (2010) ont d&#233;montr&#233; la 
fiabilit&#233; de cette approche par l'extraction de candidats-termes &#224; partir d'un corpus de 
textes juridiques europ&#233;ens et par leur validation contre la base de donn&#233;es 
terminologique officielle des services europ&#233;ens.  
</p>
<p>5 Etude s&#233;mantique des marqueurs lexicaux stables du corpus technique 
</p>
<p>5.1 Identification des marqueurs lexicaux stables 
Pour d&#233;terminer les marqueurs lexicaux stables du corpus technique, celui-ci est 
subdivis&#233; en 5 partitions, c&#8217;est-&#224;-dire une partition par sous-corpus, pour les normes, les 
fiches et les manuels (entre 300.000 et 360.000 occurrences) et 2 partitions de 400.000 
occurrences pour le sous-corpus des revues. Ces 5 partitions sont de taille comparable et 
raisonnable et respectent l&#8217;ordre des mots et les fronti&#232;res des sous-corpus th&#233;matiques et 
stylistiques. Le corpus de r&#233;f&#233;rence de langue g&#233;n&#233;rale est r&#233;parti en 36 partitions de 
taille similaire &#224; celle des partitions techniques (environ 400.000 occurrences). L&#8217;analyse 
de la SLMA est effectu&#233;e sur les lemmes au lieu des formes fl&#233;chies, &#224; l&#8217;instar de l&#8217;analyse 
des mots-cl&#233;s dans AV Frequency List Tool (Cf. section 2.1). Apr&#232;s l&#8217;extraction et avant 
l&#8217;interpr&#233;tation, la liste des marqueurs lexicaux stables rep&#233;r&#233;s subit le m&#234;me traitement 
que la liste des mots-cl&#233;s, &#224; savoir la suppression des mots grammaticaux, des noms 
propres et des hapax. Dans le corpus technique, nous recensons ainsi 3479 marqueurs 
lexicaux stables, statistiquement significatifs (p&lt;0,05), dont 3123 formes (ou presque 
90%) figurent aussi dans la liste des 4717 mots-cl&#233;s.  
</p>
<p>248</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>5.2 Marqueurs lexicaux stables versus mots-cl&#233;s 
Le tableau ci-dessous (Cf. table 1) montre que les mots-cl&#233;s les plus fr&#233;quents et les plus 
sp&#233;cifiques comme machine, outil, pi&#232;ce, visualis&#233;s dans la colonne de droite aux rangs de 
sp&#233;cificit&#233; (LLR) 1, 2 et 4 respectivement, ne figurent pas parmi les marqueurs lexicaux 
stables les plus sp&#233;cifiques, visualis&#233;s &#224; gauche du tableau. En effet, ils se retrouvent 
respectivement aux rangs de SMEA 33, 55 et 170. On observe &#233;galement que la prise en 
consid&#233;ration de la dispersion rel&#232;gue certaines unit&#233;s lexicales, tr&#232;s fr&#233;quentes dans les 
revues (p.ex. Fig) &#224; un rang moins sp&#233;cifique (37 au lieu de 9). Les vrais termes, qui sont 
sp&#233;cifiques du domaine, occupent des rangs plus sp&#233;cifiques (usinage, broche, copeau, 
fraisage, serrage, &#8230;). Ensuite, les mots g&#233;n&#233;raux, qui ont des emplois g&#233;n&#233;raux et 
techniques, occupent &#224; juste titre des rangs un peu moins sp&#233;cifiques (machine, outil, 
pi&#232;ce, &#8230;). Enfin, les mots g&#233;n&#233;raux peu fr&#233;quents et &#224; peine sp&#233;cifiques (i.e. la queue de 
la liste des 4717 mots-cl&#233;s) ne se retrouvent pas parmi les 3479 marqueurs lexicaux 
stables. Il s&#8217;av&#232;re que la fr&#233;quence technique moyenne des 4717 mots-cl&#233;s est plus faible 
(140,77) que celle des 3479 marqueurs lexicaux stables (182,16). Par ailleurs, la 
corr&#233;lation entre la fr&#233;quence dans le corpus technique et la valeur de SMEA, qui indique 
le degr&#233; de sp&#233;cificit&#233;, est moins probl&#233;matique dans la liste des marqueurs lexicaux 
stables (0,32) que dans la liste des 4717 mots-cl&#233;s, o&#249; la corr&#233;lation entre la fr&#233;quence 
technique et la valeur du LLR &#233;tait trop importante (0,87). 
</p>
<p>  lemme SMEA SLM fr&#233;q.tech.    mots-cl&#233;s 
1 usinage 85,699726 180 6720  1 machine 
2 broche 74,8200697 180 2893  2 outil 
3 copeau 73,7392965 180 2557  3 usinage 
4 fraisage 68,364653 180 1873  4 pi&#232;ce 
5 usiner 68,3239216 180 1577  5 mm 
6 machine-outil 67,6419261 180 1005  6 vitesse 
7 serrage 66,3394778 180 939  7 coupe 
8 per&#231;age 62,8188634 180 846  8 broche 
9 fraise 62,0265842 180 1571  9 Fig 
</p>
<p>10 meule 61,8557297 180 776  10 axe 
TABLE 1 &#8211; Top 10 des marqueurs lexicaux stables du corpus technique (&#224; gauche),  
</p>
<p>par rapport au top 10 des 4717 mots-cl&#233;s (&#224; droite). 
</p>
<p>5.3 Corr&#233;lation entre la sp&#233;cificit&#233; et la monos&#233;mie 
Pour &#233;tudier la corr&#233;lation entre le rang de sp&#233;cificit&#233; (rang de SMEA) et le rang de 
monos&#233;mie des 3479 marqueurs lexicaux stables, nous proc&#233;dons &#224; une analyse 
statistique de r&#233;gression simple. Elle montre une corr&#233;lation n&#233;gative entre le rang de 
</p>
<p>249</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>sp&#233;cificit&#233; et le rang de monos&#233;mie (-0,49). Il s&#8217;av&#232;re donc que les marqueurs lexicaux 
les plus stables et les plus sp&#233;cifiques ne sont pas les plus monos&#233;miques. Toutefois, la 
corr&#233;lation (-0,49) est moins convaincante que celle pour les 4717 mots-cl&#233;s (-0,72). Le 
pourcentage de variation expliqu&#233;e R&#178; de 23,87% (valeur p&lt;2,2e-16) est &#233;galement 
moins convaincant que celui pour les 4717 mots-cl&#233;s (51,57% et valeur p&lt;2,2e-16). Ces 
r&#233;sultats moins concluants pour les marqueurs lexicaux stables s&#8217;expliquent 
principalement par l&#8217;absence des mots g&#233;n&#233;raux peu fr&#233;quents et tr&#232;s peu sp&#233;cifiques, 
qui sont tr&#232;s monos&#233;miques, et par le fait que les mots les plus fr&#233;quents occupent, &#224; 
juste titre, des rangs moins sp&#233;cifiques. En raison de leur fr&#233;quence plus &#233;lev&#233;e dans le 
corpus technique, ces derniers ont plus de chances d&#8217;&#234;tre polys&#233;miques et/ou de 
constituer la t&#234;te d&#8217;unit&#233;s polylexicales, o&#249; ils sont d&#233;sambigu&#239;s&#233;s par les autres 
composants (par exemple machine &#224; fraiser, machine &#224; rainurer). 
Notons que le test de Goldfeld-Quandt soul&#232;ve aussi un probl&#232;me d&#8217;h&#233;t&#233;rosc&#233;dasticit&#233; 
(statistique F du GQ-test 1,37), mais moins important que pour les 4717 mots-cl&#233;s 
(2,07). Le probl&#232;me de l&#8217;h&#233;t&#233;rosc&#233;dasticit&#233; est donc r&#233;solu en partie, mais sugg&#232;re la 
pr&#233;sence d&#8217;une variable suppl&#233;mentaire, cach&#233;e jusqu&#8217;&#224; pr&#233;sent, qui pr&#233;dit peut-&#234;tre une 
partie de la variation du rang de monos&#233;mie. Cette variable pourrait &#234;tre li&#233;e au fait que 
les mots sp&#233;cifiques constituent la t&#234;te d&#8217;unit&#233;s polylexicales dans le corpus technique. 
Des recherches futures permettront de v&#233;rifier si elle permet d&#8217;expliquer 
l&#8217;h&#233;t&#233;rosc&#233;dasticit&#233; et dans quelle mesure. 
</p>
<p>6 Conclusion 
</p>
<p>Dans cet article, nous avons &#233;tudi&#233; les unit&#233;s lexicales sp&#233;cifiques d&#8217;un corpus technique 
relevant du domaine sp&#233;cialis&#233; restreint des machines-outils pour l&#8217;usinage des m&#233;taux. 
Nous nous sommes tout particuli&#232;rement int&#233;ress&#233;s &#224; la corr&#233;lation entre le rang de 
sp&#233;cificit&#233; et le rang de monos&#233;mie de ces unit&#233;s sp&#233;cifiques.  
Une double analyse quantitative a permis de g&#233;n&#233;rer une liste de 4717 mots-cl&#233;s, avec 
un degr&#233; de sp&#233;cificit&#233; et un degr&#233; de monos&#233;mie ou d&#8217;homog&#233;n&#233;it&#233; s&#233;mantique. Ces 
donn&#233;es quantitatives ont permis de classer les 4717 mots-cl&#233;s dans un continuum de 
sp&#233;cificit&#233; et dans un continuum de monos&#233;mie afin d&#8217;examiner la corr&#233;lation entre le 
rang de sp&#233;cificit&#233; et le rang de monos&#233;mie par le biais d&#8217;une analyse statistique de 
r&#233;gression simple. Nous avons observ&#233; une corr&#233;lation n&#233;gative, qui indique que les 
unit&#233;s lexicales les plus sp&#233;cifiques du corpus technique, relev&#233;es avec la m&#233;thodologie 
de l&#8217;analyse des mots-cl&#233;s, ne sont pas les plus homog&#232;nes s&#233;mantiquement, au contraire. 
Cette observation a permis de remettre en cause la th&#232;se monos&#233;miste traditionnelle. La 
m&#233;thode alternative de l&#8217;analyse des marqueurs lexicaux stables (Stable Lexical Marker 
Analysis ou SLMA) a permis de rem&#233;dier aux probl&#232;mes statistiques et m&#233;thodologiques 
d&#8217;h&#233;t&#233;rosc&#233;dasticit&#233; et de multicollin&#233;arit&#233;, en prenant en consid&#233;ration la dispersion et 
en utilisant une autre mesure statistique. Elle a g&#233;n&#233;r&#233; une liste de 3479 marqueurs 
lexicaux stables avec un nouveau rang de sp&#233;cificit&#233; (rang de SMEA). Les r&#233;sultats de 
l&#8217;analyse de r&#233;gression simple confirment la corr&#233;lation n&#233;gative entre le nouveau rang 
de sp&#233;cificit&#233; (rang de SMEA) et le rang de monos&#233;mie des marqueurs lexicaux stables, 
bien qu&#8217;elle soit moins forte. Ces premi&#232;res exp&#233;rimentations montrent donc que 
l&#8217;analyse des marqueurs lexicaux stables constitue une alternative valable pour l&#8217;analyse 
des mots-cl&#233;s. 
</p>
<p>250</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p> &#233;f&#233; ences 
</p>
<p>BERTELS, A., SPEELMAN, D. et GEERAERTS, D. (2010). La corr&#233;lation entre la sp&#233;cificit&#233; et la 
s&#233;mantique dans un corpus sp&#233;cialis&#233;. In Revue de S&#233;mantique et de Pragmatique n&#176;27, 
pages 79&#8211;102. 
BHREATNACH, U. et DE BARRA CUSACK, F., &#233;diteurs (2010). TKE 2010 : Presenting 
Terminology and Knowledge Engineering Resources Online: Models and Challenges, Fiontar. 
Dublin City University. 
BLUMENTHAL, P. et HAUSMANN, F.J., &#233;diteurs (2006). Collocations, corpus, dictionnaires. 
Langue fran&#231;aise, n&#176; 150. 
BOURIGAULT D., JACQUEMIN, C. et L&#8217;HOMME, M.-C., &#233;diteurs (2001). Recent advances in 
computational terminology, Amsterdam/Philadelphia. John Benjamins Publishing 
Company. 
BOURIGAULT, D. et SLODZIAN, M. (1999). Pour une terminologie textuelle. In Terminologies 
Nouvelles  n&#176;19, pages 29&#8211;32. 
CABRE, M.T. (2000). Terminologie et linguistique : la th&#233;orie des portes. In Terminologies 
Nouvelles  n&#176;21, pages 10&#8211;15. 
CONDAMINES, A. et REBEYROLLE, J. (1997). Point de vue en langue sp&#233;cialis&#233;e. In Meta, 
n&#176;42(1), pages 174&#8211;184. 
CONDAMINES, A., &#233;diteur (2005). S&#233;mantique et corpus, Paris. Herm&#232;s-Science. 
DE HERTOG, D., HEYLEN, K., SPEELMAN, D. et KOCKAERT, H. (2010). A variational linguistics 
approach to term extraction. In (Bhreatnach et de Barra Cusack, 2010), pages 229&#8211;248. 
DUNNING, T. (1993). Accurate methods for the statistics of surprise and coincidence. 
Computational Linguistics n&#176;19(1), pages 61&#8211;74. 
ERIKSEN, L. 2002. Die Polysemie in der Allgemeinsprache und in der juristischen 
Fachsprache. Oder : Zur Terminologie der &#8218;Sache&#8217; im Deutschen. In Hermes &#8211; Journal of 
Linguistics n&#176;28, pages 211&#8211;222. 
FERRARI, L. (2002). Un caso de polisemia en el discurso jur&#237;dico? In Terminology n&#176;8(2), 
pages 221&#8211;244. 
GAUDIN, F. (2003). Socioterminologie : une approche sociolinguistique de la terminologie. 
Bruxelles. Duculot. 
GROSSMANN, F. et  TUTIN, A., &#233;diteurs (2003). Les collocations, analyse et traitement, 
Travaux et Recherches en linguistique appliqu&#233;e, S&#233;rie E, vol. 1. 
HABERT, B., ILLOUZ, G., FOLCH, H. (2004). D&#233;grouper les sens : pourquoi ? comment ? In 
Actes des JADT 2004 (Journ&#233;es internationales d&#8217;analyse statistique des donn&#233;es textuelles), 
Louvain-la-Neuve, pages 565&#8211;576. 
HABERT, B., ILLOUZ, G., FOLCH, H. (2005). Des d&#233;calages de distribution aux divergences 
d&#8217;acception, In (Condamines, 2005), pages 277&#8211;318. 
 
</p>
<p>251</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>JUCKER, A., SCHREIER, D. et HUNDT, M. &#233;diteurs (2009). Corpora: Pragmatics and Discourse, 
Amsterdam. Rodopi. 
KRISTIANSEN, G. et DIRVEN, R., &#233;diteurs (2008). Cognitive Sociolinguistics: Language 
Variation, Cultural Models, Social Systems, Berlin/New York. Mouton de Gruyter. KWARY, 
D.A.  (2011). A hybrid method for determining technical vocabulary. In System  n&#176;39(2), 
pages 175-185. 
KWARY, D.A. (2011). A hybrid method for determining technical vocabulary. In System, 
n&#176;39(2), pages 175-185.LABBE, C. et LABBE, D.  (2001). Que mesure la sp&#233;cificit&#233; du 
vocabulaire ? In Lexicometrica  n&#176;3. 
LAFON, P. (1984). D&#233;pouillements et statistiques en lexicom&#233;trie, Gen&#232;ve-Paris. Slatkine-
Champion. 
LEMAY, C., L'HOMME, M.C. et DROUIN, P. (2005). Two methods for extracting specific 
single-word terms from specialized corpora. Experimentation and evaluation. In 
International Journal of Corpus Linguistics, n&#176;10(2), pages 227&#8211;255. 
MARTINEZ, W. (2000). Mise en &#233;vidence de rapports synonymiques par la m&#233;thode des 
cooccurrences. In Actes des JADT 2000 (Journ&#233;es internationales d&#8217;analyse statistique des 
donn&#233;es textuelles), Lausanne, pages 78&#8211;84. 
MAYAFFRE, D. (2008), Quand &#8216;travail&#8217;, &#8216;famille&#8217;, &#8216;patrie&#8217; co-occurrent dans le discours de 
Nicolas Sarkozy. Etude de cas et r&#233;flexion th&#233;orique sur la co-occurrence, In Actes des 
JADT 2008 (Journ&#233;es internationales d&#8217;analyse statistique des donn&#233;es textuelles), Lyon, 
pages 811&#8211;822. 
PAQUOT, M. et BESTGEN, Y. (2009). Distinctive words in academic writing: a comparison 
of three statistical tests for keyword extraction &#187;, In (Jucker et al., 2009), pages 247&#8211;269  
SCOTT, M. et TRIBBLE, C. (2006). Textual Patterns. Key words and corpus analysis in language 
education. Studies in Corpus Linguistics, vol. 22. Amsterdam. Benjamins. 
SPEELMAN, D., GRONDELAERS, S. et GEERAERTS, D. (2006). A profile-based calculation of 
region and register variation: the synchronic and diachronic status of the two main 
national varieties of Dutch. In (Wilson et al., 2006), pages 195&#8211;202. 
SPEELMAN, D., GRONDELAERS, S. et GEERAERTS, D. (2008). Variation in the choice of 
adjectives in the two main national varieties of Dutch. In (Kristiansen et Dirven, 2008), 
pages 205&#8211;233. 
TEMMERMAN, R. (2000). Towards new ways of terminology description. The sociocognitive 
approach, Amsterdam/Philadelphia. John Benjamins Publishing Company. 
VERONIS, J. (2003). Cartographie lexicale pour la recherche d&#8217;informations. Actes de 
TALN 2003(Traitement automatique des langues naturelles), Batz-sur-Mer, pages 265&#8211;274. 
WILSON, A., ARCHER, D. et RAYSON, P., &#233;diteurs (2006). Corpus Linguistics around the 
World, Amsterdam. Rodopi. 
W&#220;STER, E. (1991). Einf&#252;hrung in die allgemeine Terminologielehre und terminologische 
Lexikographie, (3. Aufl.), Bonn. Romanistischer Verlag. 
</p>
<p>252</p>

</div></div>
</body></html>