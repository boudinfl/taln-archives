Etude sémantique des mots-clés et des Ina_rqueurS
lexrcaux stables dans un corpus techmque

Ann Bertels” Dirk De Hertogz Kris Heylenz
(1) ILT, KU Leuven, Dekenstraat 6, B-3000 Leuven (Belgique)
(2) QLVL, KU Leuven, Faculty of Arts, Blijde-Inkomststraat 21, B-3000 Leuven (Belgique)
ann.bertels@ilt.kuleuven.be, dirk.dehertog@arts.kuleuver1.be,
kris.heyler1@arts.ku.leuver1.be

RESUME

Cet article présente les résultats d’une analyse sémantique quantitative des unités
lexicales spéciﬁques dans un corpus technique, relevant du domaine des machines-outils
pour l’usinage des métaux. L’étude vise 5 vériﬁer si et dans quelle mesure les mots-clés
du corpus technique sont monosémiques. A cet effet, nous procédons 5 une analyse
statistique de régression simple, qui permet d’étudier la corrélation entre le rang de
spéciﬂcité des mots-clés et leur rang de monosémie, mais qui souléve des problémes
statistiques et méthodologiques, notamment un biais de fréquence. Pour y remédier,
nous adoptons une approche alternative pour le repérage des unités lexicales spéciﬁques,
5 savoir l’analyse des marqueurs lexicaux stables ou Stable Lexical Marker Analysis
(SLMA). Nous discutons les résultats quantitatifs et statistiques de cette approche dans la
perspective de la corrélation entre le rang de spéciﬂcité et le rang de monosémie.

ABSTRACT

Semantic analysis of keywords and stable lexical markers in a technical corpus

This article presents the results of a quantitative semantic analysis of typical lexical units
in a specialised technical corpus of metalworking machinery in French. The study aims
to find out whet.her and to what extent the keywords of the technical corpus are
monosemous. A simple regression analysis, used to examine the correlation between
typicality rank and monosemy rank of the keywords, points out some statistical and
methodological problems, notably a frequency bias. In order to overcome these
problems, we adopt an alternative approach for the identification of typical lexical units,
called Stable Lexical Marker Analysis (SLMA). We discuss the quantitative and statistical
results of this approach with respect to the correlation between typicality rank and
monosemy rank.

MOTS-CLES: u.nités lexicales spéciﬁques, analyse des mots-clés, analyse des marqueu.rs
lexicaux stables, sémantique quantitative, analyse de régression.

KEYWORDS: typical lexical units, Keyword Analysis, Stable Lexical Marker Analysis
(SLMA), quantitative semantics, regression analysis.

1 Introduction

Cette communication s’inscrit dans le contexte d’une étude sémantique quantitative
effectuée sur un corpus de textes techniques relevant du domaine technique spécialisé
des machines-outils pour l’usinage des métaux. L’étude vise 5 vériﬂer si et dans quelle
mesure les unités lexicales spéciﬁques du corpus technique sont monosémiques. Selon la

Actes de la con_fe'rence onjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 239-252,
Grenoble, 4 an 8 juin 2012. ©2012 ATAI.A 8: AFCP

239

Terminologie traditionnelle, qui adopte une approche onomasiologique et prescriptive, la
langue spécialisée se caractérise par la monosémie et l’u.nivocité (Wiister, 1991). Les
termes de la langue spécialisée sont idéalement monosémiques, tandis que la polysémie
est réservée aux mots de la langue générale. Cela aboutit 5 une double dichotomie, qui
oppose les termes de la langue spécialisée aux mots de la langue générale et la
monosémie 5 la polysémie. Récemment, l’idéal de monosémie dans la langue spécialisée
ainsi que la double dichotomie ont été remis en question par les partisans de la
terminologie descriptive et linguistique, sémasiologique, distributionnelle et
(con)textuelle (Bourigault et Slodzian, 1999 ; Cabré, 2000 ; Temmerman, 2000 ; Gaudin,
2003). Par ailleurs, des expérimentations ponctuelles menées sur des corpus spécialisés
ont abouti 5 l’observation de cas de polysémie dans la langue spécialisée, meme 5
l’intérieur d’u.n domaine spécialisé (Condamines et Rebeyrolle, 1997 ; Eriksen, 2002 ;
Ferrari, 2002). Ces ét11des sémantiques ponctuelles et qualitatives ainsi que les remises
en question tl1éoriques nous ont incités 5 évaluer la these monosémiste traditionnelle 5
grande échelle, dans un corpus de textes techniques, et 5 adopter une approche
alternative, quantitative et scalaire.

Aﬁn de procéder 5 une étude sémantique 5 grande échelle, 5 partir d’u.ne analyse de
corpus, il est nécessaire de reformuler la these monosémiste traditionnelle qualitative en
une question de recherche quantitative. S’il est vrai que les unités lexicales d’u.n corpus
spécialisé sont monosémiques, ce sera d’autant plus vrai pour les unités lexicales les plus
spéciﬂques et les plus représentatives de ce corpus. Nous exarninons donc si les unités
lexicales les plus spéciﬂques du corpus technique sont effectivement les plus
monosémiques, comme le prétendent les partisans de la terminologie traditionnelle, ou
s’il existe des unités lexicales spéciﬂques qui sont polysémiques, comme le suggerent les
partisans de la terminologie descriptive. A cet effet, nous procédons 5 une double
analyse quantitative. Pour l’extraction des 11nités lexicales spéciﬂques et pour le calcul de
leur degré de spéciﬂcité, nous recourons 5 l’analyse des mots-clés (Keyword Analysis)
(Scott, 2006). Pour quantiﬁer l’analyse sémantique, nous calculons le degré de
monosémie des mots-clés 5 partir du degré de recoupement de leurs cooccurrents de
deuxieme ordre, par le biais d’u.ne mesure de recoupement (Bertels et aL, 2010). Ces
données quantitatives de spéciﬂcité et de monosémie menent ensuite 5 une analyse
statistique de régression simple. Elle consiste 5 ét11dier la corrélation entre le rang de
spéciﬂcité et le rang de monosémie, pour ainsi répondre 5 la question de recherche
quantitative. Les résultats de l’analyse statistique conﬂrment les observations des ét11des
sémantiques antérieures et permettent de réfuter la these monosémiste traditionnelle,
comme nous l’avons décrit précédemment (Bertels et aL, 2010). Dans cet article, nous
discutons la pertinence de l’analyse des mots-clés pour l’identiﬂcation des unités
spéciﬂques et nous proposons une approche métl1odologique alternative.

Il est 5 noter que cet article ne se sit11e pas dans le domaine de l’extraction de termes.
Cette discipline se caractérise par un classement catégoriel (termes vs non-termes), alors
que nous visons 5 ét11dier la spéciﬂcité dans une perspective graduelle. Nous n’avons pas
l’intention d’extraire la terminologie du domaine technique des machines-outils pour
l’usinage des métaux. Nous cherchons avant tout 5 répondre 5 notre question de

recherche, soulevée par le corpus de langue spécialisée, qui consiste a ét11dier la
corrélation entre la spéciﬂcité et la monosémie.

240

Dans cet article, nous expliquons d’abord la méthodologie et les résultats de l’étude
sémantique des mots-clés du corpus technique (section 2), ainsi que les problemes
statistiques et mét.hodologiques (section 3). Ensuite, nous présentons u.ne autre approche
pour l’identiﬂcation des unités lexicales spéciﬂques et pour le calcul de leur degré de
spéciﬂcité, 5 savoir l’analyse des marqueurs lexicaux stables ou Stable Lexical Mark.er
Analysis (section 4). Nous discutons ﬁnalement les résultats quantitatifs et statistiques de
cette approche dans la perspective de la corrélation entre le rang de spéciﬂcité et le rang
de monosémie (section 5).

2 Etude sémantique des mots-clés du corpus technique

Le corpus technique constit11é dans le cadre de cette étude releve du domaine spécialisé
des machines-outils pour l’usinage des métaux et il comprend 1,7 million d’occurrences.
Il a été étiqueté par Cordial 7 Analyseur et consiste en 4 sous-corpus, datant de 1996 5
2002, 5 savoir des revues électroniques (800.000 occurrences), des ﬂches techniques
(300.000), des normes ISO et directives (300.000) et 4 manuels numérisés (360.000). Le
corpus de référence de langue générale compte 15,3 millions d’occurrences lemmatisées
et il est constitué d’articles du journal Le Monde de la méme période (1998).

2.1 Identiﬁcation des unités lexicales spécifiques

Pour le repérage des unités lexicales spéciﬁques, plusieurs approches mét.hodologiques
sont envisageables. Elles permettent de générer u.ne liste d’u.nités spéciﬁques, pourvues
d’u.ne indication de leur degré de spéciﬂcité. Les différences les plus importantes résident
dans la mét.hodologie et les mesures statistiques sous-jacentes. La mét.hodologie du calcu.l
des spéciﬁcités (Lafon, 1984 ; Labbé et Labbé, 2001) est basée sur la distribution
hypergéométrique et sur le test statistique de Fisher Exact‘. Elle est implémentée
notamment dans Lexico3 2, Hyperbase3 et TermoStat“. Du point de vue méthodologique,
le calcul des spéciﬁcités procede par comparaison partie-tout. Une section d’u.n corpus
est comparée au corpus entier dans le but d’identiﬂer les mots spéciﬂques de la section
par rapport au corpus entier. Le calcul des spéciﬁcités utilise seu.lement des informations
appartenant au domaine en question. Le résultat est un coefﬂcient de spéciﬂcité. Plus
élevé ce coefﬂcient, plus faible sera la probabilité de la fréquence observée (par rapport
au corpus entier) et plus spéciﬁque sera le mot L’analyse des mots-clés (Keyword
Analysis) (Scott, 2006) se caractérise par une approche contrastive, qui consiste 5
comparer les fréquences relatives des mots dans un corpus spécialisé 5 celles dans un
corpus de référence de langue générale. Un mot est << clé » ou spéciﬁque dans le corpus
spécialisé si sa fréquence relative dans ce corpus est plus élevée que sa fréquence relative

1 Le tat statistique de Fisher Exact est généralement utilisé pour des données de taille modeste, des corpus peu
volumineux et des fréquences plutﬁt faibls (n < 20).

2 SYLED — CLA2T, Paris3 : ht_tp:ggv\rvvw.ta.l.univ-paris3.frg1a(icog. [consulté le 20/01/2012].

3 Hyperbase : ht§p:g ga.ncilla.unice.frg rvbrungt/pub gllyperbase.ht|n.l. [consulté le 20/01/201 2].

‘ Termostat : ht1p:ggolst.l.i1;g.umontrea.l.cg/ ~drouinp/termostat webgdoc termostat/doc termostat.ht1nl.
[consulté le 20/01/2012]. Dans Termostat le corpus de référence et le corpus d’ana1yse sont fusionné en un

corpus virtuel, pour vériﬁer si le lmdque du corpus d’a.na1yse se comporte comme celui du corpus de référence.

241

dans le corpus de référence et si la différence de fréquence est statistiquement
signiﬁcative. Une mesure statistique, comme le rapport de vraisemblance (Log—Likelihood
Ratio ou LLR ou G2) (Dunning, 1993), permet de décider s’il s’agit d’un mot-clé du
corpus spécialisé. L’analyse des mots-clés est implémentée notamment dans WordSmit.h5,
AntConc5, TermoStat et AV Frequency List Tool7.

Pour identiﬁer le vocabulaire spéciﬁque de notre corpus technique, nous adoptons
l’analyse des mots-clés, parce qu’elle compare deux corpus différents. Nous recourons 5
la mesure statistique du log de vraisemblance (LLR), qui permet de conduire 5 des
possibilités de classement précis et donc 5 des degrés de spéciﬁcité avec une granularité
aussi ﬁne que possible. Plusieurs ét11des antérieures ont validé la mesure du LLR et
démontré la pertinence de l’analyse des mots-clés pour relever les unités spéciﬁques d’un
domaine particulier (Paquot et aL, 2009 ; Kwary, 2011). Nous nous limitons dans cette
ét11de au niveau des unités simples, comme fraisage, commande, machine. Des recherches
futures devront certainement porter sur l’étude des unités polylexicales, telles que
machine 61 fraiser, commande numérique, puisque la plupart des unités terminologiques
d’un domaine spécialisé se situent au niveau des unités complexesa. L’analyse des mots-
clés est effectuée dans AV Frequency List Tool, 5 partir de deux listes de fréquence des
lemmes des deux corpus, réalisées 5 l’aide de scripts en Python. Le logiciel AV génére
une liste de lemmes spéciﬁques du corpus technique et indique leur degré de spéciﬁcité,
5 savoir la valeur du LLR (keyness), et une valeur p associée. Nous relevons 4717 mots-
clés (p< 0,05), aprés suppression des mots grammaticaux, des noms propres et des
hapax. Le degré de spéciﬁcité ou de keyness permet de sit11er ces 4717 mots-clés sur un
continuum de spéciﬁcité et de leur accorder un rang de spéciﬁcité.

2.2 Quantiﬁcation de l’analyse sémantique

Les 4717 mots-clés font ensuite l’objet d’une analyse sémantique quantitative et
automatisée. A cet effet, nous recourons 5 l’analyse des cooccurrences (Grossmann et aL,
2003; Condamines 2005; Blumenthal et Hausmann, 2006; Mayaffre 2008), parce
qu’elle permet de quantiﬁer et d’objectiver la monosémie en l’implémentant en termes
d’l1omogénéité sémantique (Habert et aL, 2005). Une u.nité lexicale monosémique

5 WordSmit.h Tools : ht_tp:ggv\rvvw.la(ica]1y.ne§gwor'dsn:itl1g. [consulté le 20/01/2012].

6 AntConc : ht_tp:1gwww.ant.lab.sci.waseda.ac.j_pgsoftwa.re.ht|n.l. [consulté le 20/01/2012].

7 AV Frequency List Tool : ht_tp:ggv\rvvwli1lg.a.1ts.lcI1le11ven.begav-toolsg. [consulté le 20/01/2012].

3 Plusie1.1rs outils d’a(ttaction terminologique, tels que LEXTER (Bourigault et a]. 2001), permettent de repérer
les unités polylacicales. Toutefois celles-ci posent probleme lors du calcul des spéciﬁcités. Pour l’instant, il n’$t
pas possible de déterminer le degré de spéciﬁcité des unités complexes de fagon ﬁable et statistiquement
signiﬁcative, notamment parce que la plupart d’en1:re ells sont absentes dans un corpus de référence de langue
générale. Par ailleurs, les techniques d’act.taction automatique de termes s’appuient souvent sur un algorithme
hybride avec une composante syntaxique importante, c’est-5-dire des structures syntaxiques récurrentes (Lemay
et a]., 2005). Ainsi, plusieurs variables concourent au repérage des unité terminologiques complexes plutﬁt
qu’une seule. Or, l’analyse de regression 5 laquelle nous procédons pour étudier la correlation entre les données
de spéciﬁcité et de monosémie, requiert une seule variable linguistique, c’est-5-dire un critere de spéciﬁcité
clair et précis.

242

apparait dans des contextes plut6t homogenes sémantiquement. Par contre, u.ne u.nité
lexicale polysémique se caractérise par des cooccurrents plus hétérogenes
sémantiquement, qui appartiennent 5 des champs sémantiques différents (Véronis, 2003 ;
Habert et aL, 2004). L’accés 5 la sémantique des cooccurrents de premier ordre (ou c)
peut se faire 5 partir de leurs cooccurrents, c’est-5-dire les cooccurrents de deuxieme
ordre (ou cc). Ceux-ci se caractérisent principalement par des relations paradigmatiques
avec le mot de base (l1yponymes, hyperonymes, synonymes, antonymes) et des lors ils
sont intéressants pour caractériser sémantiquement le mot de base. Ils ont permis entre
autres de mettre en évidence des relations de synonymie (Martinez, 2000).

Si les cooccurrents de premier ordre d’u.n mot de base, en l’occu1rence u.n mot-clé,
partagent beaucoup de cooccurrents de deuxiéme ordre, ces derniers se recoupent
formellement, ce qui constitue u.ne indication de l’homogénéité sémantique des
cooccurrents de premier ordre et, des lors, du mot de base. Le degré de monosémie d’u.n
mot-clé pourra donc étre déterminé en fonction du degré de recoupement formel de ses
cooccurrents de deuxiéme ordre. Une représentation schématique (Cf. ﬁgure 1) fait
intervenir u.n mot-clé, ses 5 c différents et tous leurs c (10 cc différents et 26 cc au total).
Ce schéma permettra d’expliquer le poids de chaque cc pour le recoupement global. Un
cc partagé par tous les c (p.ex. cc3), ﬁgure 5 fois dans la liste des cc, constituée de 5 blocs
de cc (u.n bloc par c). Le cc ﬁgurant 5 fois aura donc u.n poids maximal de 5/5. Par
contre, u.n cc qui ﬁgure dans un seul bloc (p.ex. cc2 ou cc4) est un cc isolé avec un poids
minimal de 1/5. De méme, le poids d’un cc qui ﬁgure 2 fois dans la liste des cc ou dans 2
blocs (p.ex. cc5) équivaut 5 2/5. Ainsi, on pourra calculer facilement le poids de chaque
cc dans la liste des 26 cc. Le poids de chaque cc correspond au rapport entre la fréquence
du cc dans la liste des cc et le nombre de c. Pour connaitre le recoupement global,
calcu.lé 5 partir du recoupement de tous les cc, on fera d’abord la somme des poids
individuels (donc 26 réitérations du calcul précédent). Ce résultat sera divisé par 26
(nombre total de cc dans la liste), parce que chaque cc contribue pour 1/26 au
recoupement global calculé pour le mot-clé. Le résultat ﬁnal se sit11e toujours entre 0 et 1
et représente le degré de recoupement moyen pour un mot-clé, c’est-5-dire son degré
d’l1omogénéité sémantique.

cc, cc, cc3 cc, ccs ECG cc, ccg ccg ccm

1 0 1 0 0 0 1 1 O 1
1 0 1 0 1 0 1 0 1 1
Mot-clé 1 0 0 1 0 1 1 0 1 O 0
1 1 1 0 0 0 1 1 0 1
1 0 1 1 0 0 1 1 0 0

 

FIGURE 1 — Schéma : mot-clé + cooccurrents de premier et de deuxieme ordre.

L’analyse des cooccurrences est effectuée, de facon récurrente, dans une fenétre
d’observation (ou span) de 5 mots 5 gauche et 5 mots 5 droite, sans informations de
position ni d’orientation. Cette fenétre apporte sufﬁsamment d’informations sémantiques
pertinentes, sans introduire trop de bruit, et permet u.n traitement informatique efﬁcace.

243

Les cooccurrents de premier et de deuxieme ordre sont considérés au niveau des formes
graphiques, ce qui permet de faire la distinction entre, par exemple, piece usinée
(<<résultat>>) et piece 61 usiner (<< avant le processus d’usinage ») et des lors de tenir
compte de la différence sémantique. La mesure d’association utilisée pour déterminer les
cooccurrents statistiquement pertinents est la mesure statistique du LLR (log du rapport
de vraisemblance). Le seuil de signiﬂcativité tres sévére (valeur p< 0,0001) permet de
relever u.niquement les cooccurrents de premier et de deuxieme ordre sémantiquement
pertinents. La mesure de recoupement est concrétisée 5 l’aide de scripts en Python pour
calcu.ler le degré de recoupement des 4717 mots-clés 5 partir du recoupement formel de
leu.rs cooccurrents de deuxieme ordre. Ce degré de recoupement ou d’l1omogénéité
sémantique permet de situer les 4717 mots-clés sur un continuum d’homogénéité
sémantique ou de monosémie et permet de leur accorder u.n rang de monosémie.

Comme nous ne disposons pas de listes de sens préétablis, ni d’autres mesures
sémantiques comparables, nous avons procédé 5 me validation manuelle de la mesure
de recoupement 5 partir de l’analyse manuelle des cooccurrents les plus pertinents, ainsi
qu’5 u.ne validation externe au moyen de dictionnaires. Les résultats de ces validations
conﬁrment les résultats de notre mesure de recoupement pour un échantillon de 50
mots-clés. Il est 5 noter que des recherches supplémentaires s’imposent pour examiner la
relation précise entre, d’u.ne part, notre mesure de monosémie, implémentant la
monosémie en termes d’l1omogénéité sémantique, et, d’autre part, ce que l’on considére
traditionnellement comme monosémie ou polysémie. Nous recourons 5 cette mesure,
dans le but opérationnel de développer u.n critere mesurable. Sans recherches
supplémentaires, il serait impossible d’afﬂrmer que les degrés de monosémie calculés
correspondent parfaitement 5 ce que les terminologues traditionnels considérent comme
monosémie ou polysémie. Notons toutefois que ces derniers omettent de foumir des
criteres opérationnels 5 ce sujet

2.3 Corrélation entre la spéciﬁcité et la monosémie

Pour répondre 5 la question de recherche et pour examiner la corrélation entre le
continuum de spéciﬂcité et le continuum de monosémie (ou d’homogénéité sémantique),
les données quantitatives de spéciﬂcité et de monosémie sont soumises 5 me analyse
statistique de régression linéaire simple. Celle-ci permet d’étudier l’impact d’u.ne variable
indépendante ou explicative (ici : le rang de spéciﬂcité) sur la variable dépendante ou
expliquée (ici : le rang de monosémie). Le résultat de cette analyse est le coefﬁcient de
détermination ou le pourcentage de variation expliquée R2. Il représente le pourcentage
de la variation du rang de monosémie que l’on pou1ra expliquer ou prédire 5 partir de la
variation du rang de spéciﬂcité des 4717 mots-clés.

Les résultats de l’analyse de régression simple permettent d’inﬂrmer la these
monosémiste traditionnelle, car ils montrent u.ne corrélation négative (coefﬁcient de
corrélation Pearson de -0,72) et un pourcentage de variation expliquée R2 de 51,57%
(valeur p<2,2e'15). Il s’avére donc que les mots-clés les plus spéciﬂques du corpus
technique ne sont pas les plus monosémiques, mais, au contraire, les plus hétérogenes
sémantiquement (p.ex. machine, piéce, tour). En plus, les mots-clés les moins spéciﬂques
du corpus technique sont les plus homogenes sémantiquement (par exemple
rationnellement, télédiagnostic), 5 quelques exceptions pres (service et objet). En effet, la

244

visualisation ci-dessous (Cf. ﬁgure 2) montre que la droite de régression s’incline vers le
bas. Parmi les mots-clés spéciﬁques qui sont hétérogenes sémantiquement, nous
retrouvons effectivement des unités polysémiques, telles que découpe, dont les
sens << action de découper » et « résultat de la découpe » se caractérisent par une relation
métonymique. Nous recensons également des homonymes (tels que tour), ainsi que des
mots vagues (comme usinage) dont le sens sous-déterminé est précisé par le contexte
linguistique.

    
   
     
      

autre O
to serwce 0
%odHc'§EFQe °e $om%ercIal 0 Oootjjet
D 0 orenﬁorazeroeyv éﬁaln oaim
3 — 0% “£8? °% mg on ‘% é’
roIt°
<r §o§;$: %g50®$ D00
9 0
tag ea 00 
9 8 rnfmn %°32> g §§  o%
 3 7 E o%% C‘
Ln §%
0 ° aw g ‘’
E <a°°° $3; 0
E C, §
% 8 — °
C!) ‘V ‘me
C 0
E o
désifé
C)
C: _
C)
so <» O °§ 2.
cornpacxté 3 $3888 9  %
O — électrobrocnes9°%o<?3 0
I

0 1000 2000 3000 4000

rang de spécxﬁcité

FIGURE 2 — Visualisation de l’analyse de régression.

3 P1-oblémes statistiques et méthodologiques
3.1 Hétéroscédasticité : mots généraux

La visualisation ci-dessus (Cf. ﬁgure 2) montre que la corrélation négative ne s’applique
pas a tous les mots-clés et qu’elle n’est pas tout a fait linéaire. Le test statistique de
Goldfeld-Quandt souleve effectivement u.n probleme statistique d’hétéroscédasticité
(statistique F du GQ-test 2,07), ce qui veut dire que les variances des erreurs ne sont pas
constantes. En effet, certaines observations se caractérisent par un résidu important,
c’est-a-dire par une grande différence entre leur valeu.r observée et la valeu.r estimée par
le modele de régression, par exemple service, objet, commercial. L’écart (ou le résidu)
entre leu.r valeu.r observée (visualisée par la petite boule) et leur valeur estimée située
sur la droite de régression est tres important, ce qui donne lieu a me erreu.r importante
lors de la prédiction de leur rang de monosémie a partir de leur rang de spéciﬁcité. Ces
mots se sit11ent principalement dans la partie supérieure droite, c’est-a-dire parmi les
mots-clés les moins spéciﬂques. Ils sont plus polysémiques qu’on n’aurait cru en prenant
en considération leur rang de spéciﬂcité.

245

Ce sont majoritairement des mots généraux, tres fréquents dans le corpus de référence et
des lors peu spéciﬂques dans le corpus tech.nique, en dépit de leur fréquence élevée dans
le corpus technique. Pour ces mots, qui se trouvent dans la zone marginale de spéciﬁcité
(valeur p légérement inférieure 5 0,05), le modele de régression n’est pas u.ne bonne
prédiction de leur rang de monosémie 5 partir de leur rang de spéciﬁcité. Ces mots sont
hétérogenes sémantiquement et se caractérisent par une polysémie 5 la fois générale et
technique : leurs (divers) sens généraux se retrouvent aussi dans le corpus technique. Ils
sont plut6t hétérogenes sémantiquement, quel que soit leur rang de spéciﬁcité.

3.2 Multicollinéarité : fréquence technique

Le deuxieme probleme est soulevé par une analyse statistique de régression multiple, qu.i
évalue l’impact combiné et simultané de plusieurs variables indépendantes sur la
variable dépendante. Parfois, deux ou plusieurs variables indépendantes sont corrélées
les u.nes avec les autres. Elles expliquent en grande partie la méme variation de la
variable dépendante, ce que l’on qualiﬂe de probleme de multicollinéaritég.

Pour les 4717 mots-clés, nous observons u.n probleme de multicollinéarité pour trois
variables, 5 savoir le log du LLR, le rang de spéciﬁcité et le rang de fréquence technique.
En effet, il y a u.ne corrélation (trop) importante (0,87) entre la valeur du LLR, utilisée
pour identiﬁer et classer les mots-clés, et la fréquence technique. Par ailleurs, la mesure
statistique du LLR est trop sensible 5 la fréquence technique, car pour les fréquences
techniques (tres) élevées, elle gonﬂe la valeur du LLR et des lors le degré de spéciﬁcité. Il
s’ensu.it que les mots tres fréquents dans le corpus technique ont u.n degré de spéciﬁcité
relativement plus élevé que les mots moyennement ou faiblement fréquents. Par
conséquent, certains mots tres fréquents se sit11ent 5 tort parmi les mots les plus
spéciﬂques. Bien entendu, dans l’analyse de régression simple, nous considérons le rang
de spéciﬁcité, qui permet tout de méme d’effacer les différences trop importantes en
termes de degrés de spéciﬁcité. Notons également que la fréquence technique élevée de
certains mots s’explique par leur fréquence tres élevée dans une des parties du corpus, en
dépit de leur fréquence plut6t normale dans les autres parties. Ce biais de fréquence
local est souvent causé par un biais de sujet (topical bias). En effet, le calcul du degré de
spéciﬁcité compare la fréquence relative dans le corpus technique entier (de 1,7 million
de mots) 5 la fréquence dans le corpus général entier (de 15,3 millions de mots), sans
tenir compte de la dispersion des mots 5 travers les corpus. Or, la prise en considération
de la dispersion des mots s’avére importante lors de l’extraction des mots-clés (Paquot et
aL, 2009). Come notre corpus technique consiste en 4 sous-corpus (revues, ﬂches
techniques, normes et manuels), cette hétérogénéité des sources aura probablement un
impact sur la dispersion et la spéciﬁcité des u.nités lexicales spéciﬂques.

En conclusion, deux problemes se posent. D’u.ne part, il y a trop de mots généraux parmi
les mots-clés et ils entrainent un effet perturbateur et de ce fait u.n probleme statistique
d’hétéroscédasticité. D’autre part, la mesure statistique du LLR est trop sensible 5 la
fréquence technique élevée et elle souffre d’u.n biais de sujet

9 Valeurs VIF dans l’a.nalyse de régression multiple : log du LLR (VIF 36,26), rang de spéciﬁcité (VIF 26,32) et
rang de fréquence technique (VIF 14,72).

246

4 Solutions

Pour remédier 5 ces problémes, nous proposons d’adopter u.ne méthode alternative, qui
permet de prendre en considération également la dispersion des mots 5 travers les
corpus. Ainsi, on évite qu’u.n mot soit spéciﬂque du corpus technique 5 cause de sa
surreprésentation dans une seule partie. Or, la dispersion ne permet pas de résoudre tout
le probleme de la sensibilité 5 la fréquence. Par conséquent, nous adoptons également
u.ne autre mesure statistique, capable de reﬂéter de facon plus ﬂable les u.nités lexicales
spéciﬁques du corpus technique et leur degré de spéciﬂcité.

4.] Stable Lexical Marker Analysis (SIMA)

La nouvelle méthode, appelée Stable Lexical Marker Analysis (SLMA) ou analyse des
marqueurs lexicaux stables, a été développée dans le domaine de la linguistique
variationnelle (Speelman et aL, 2006). Le but était d’identiﬁer les variantes lexicales
régionales typiques ou les << marqueurs lexicaux stables >> des différences régionales entre
le néerlandais utilisé aux Pays-Bas et en Flandre (Belgique) (Speelman et aL, 2008). La
méthode s’applique aussi 5 l’extraction d’u.nités terminologiques, par exemple dans le
domaine ju.ridique de la législation ﬂnanciére (De Hertog et aL, 2010). La SLMA compare
deux corpus 5 partir de leurs listes de fréquence et permet ainsi d’identiﬁer les
différences lexicales consistantes et stables er1tre les corpus. Elle s’inspire de la méthode
des mots-clés de Scott (2006), en ce qu’elle consiste 5 comparer des listes de fréquence
d’u.n corpus d’analyse 5 des listes de fréquence d’u.n corpus de référence. Toutefois, au
lieu de comparer u.ne liste de fréquence d’analyse 5 u.ne liste de fréquence de référence,
elle compare plusieurs fois de telles listes de fréquence. Elle fait donc intervenir de
multiples tests d’hypothése pour ainsi rendre compte de la dispersion.

En effet, le corpus spécialisé est subdivisé en plusieurs partitions (disons n partitions),
tout comme le corpus de référence (m partitions). Pour chaque partition des deux corpus,
on établit u.ne liste de fréquence. I] y a donc n*m listes de fréquence. Ensuite, chaque
partition du corpus spécialisé A (p.ex. A1, A2, ..., A,,) est comparée 5 chaque partition du
corpus de référence B (p.ex. B1, B2, ..., B,,,), par le biais de leur liste de fréquence, ce qui
revient 5 n*m comparaisons de partitions. Chaque comparaison par paire de partitions
permet de générer u.ne liste de mots-clés spéciﬁques de la partition spécialisée (LLR et
valeur p<0,05). Les mots qui sont spéciﬁques dans la plupart de ces comparaisons (au
maximum n*m) sont qualiﬂés de << marqueurs lexicaux stables », parce qu’ils sont stables
et consistants 5 travers le corpus spécialisé entier. Le nombre de comparaisons
signiﬂcatives par paire de partitions (qualiﬂé de SLM) est une premiere indication du
degré de spéciﬂcité. Ces u.nités lexicales sont spéciﬁques (globalement relativement plus
fréquentes dans le corpus spécialisé) et stables (avec une dispersion uniforme 5 travers le
corpus spécialisé). Le découpage des corpus en partitions peut se réaliser 5 l’aide de
scripts en Python, tout comme les multiples comparaisons des listes de fréquence.

4.2 Odds Ratio
La mesure statistique du log Odds Ratio (log OR), permet d’obtenir une indication de

spéciﬂcité 5 granularité plus ﬁne que le nombre de comparaisons signiﬂcatives par paire
de partitions (SLM). Le log OR permet également de prendre en considération la réelle

247

importance de la différence de fréquence d’un mot dans les deux (partitions de) corpus,
ce que l’on qualiﬂe de qfect size. Le log OR fait intervenir la fréquence relative du mot,
ainsi que celle de tous les autres mots, ce qui évite de gonﬂer le résultat pour les
fréquences élevées (Cf. LLR). Pour un mot wk donné, on calcule ainsi le score SMEA
(Stable Marker Eﬁect size Analysis), c’est-a-dire SMEA(w,, A, B), en calculant le log OR
pour chaque comparaison signiﬂcative, dans un corpus spécialisé A (n partitions) et un
corpus de référence B (m partitions). La somme est divisée par le nombre total de
comparaisons de partitions.

0 T . . . W
1 i i<1g<F“’f 5’*)*s<F“‘   »
11*ma:1 j:1 Fa]/Ff‘; wk wk wk ﬁk

SMEA(wk» A B) :

avec Ff la fréquence du mot wk dans la partition i du corpus A et Fﬁf: la fréquence de

tous les mots autres que wk (et de meme pour les fréquences du corpus B). S( ) est une
fonction booléenne qui égale 1 si la distribution des mots est signiﬂcativement différente
dans les corpus A et B ; sinon elle égale 0. Si le nombre de comparaisons signiﬁcatives
est plus élevé, donc si le mot spéciﬂque est mieux dispersé, le score SMEA sera plus
élevé. Le score SMEA est une indication de la spéciﬁcité du mot ainsi que de sa
dispersion, mais elle échappe au gonﬂement pour les mots tres fréquents. Sa granularité
tres ﬁne permet de classer les marqueurs lexicaux stables et de déterminer leur nouveau
rang de spéciﬂcité, appelé rang de SMEA. De Hertog et al. (2010) ont démontré la
ﬂabilité de cette approche par l'extraction de candidats-termes a partir d'un corpus de
textes juridiques européens et par leur validation contre la base de données
terminologique ofﬂcielle des services européens.

5 Etude sémantique des marqueurs lexicaux stables du corpus technique

5.] Identiﬁcation des marqueurs lexicaux stables

Pour déterminer les marqueurs lexicaux stables du corpus technique, celui -ci est
subdivisé en 5 partitions, c’est-a-dire une partition par sous-corpus, pour les normes, les
ﬂches et les manuels (entre 300.000 et 360.000 occurrences) et 2 partitions de 400.000
occurrences pour le sous-corpus des revues. Ces 5 partitions sont de taille comparable et
raisonnable et respectent l’ordre des mots et les frontieres des sous-corpus t.hématiques et
stylistiques. Le corpus de référence de langue générale est réparti en 36 partitions de
taille similaire 5 celle des partitions techniques (environ 400.000 occurrences). L’analyse
de la SLMA est effectuée sur les lemmes au lieu des formes ﬂéchies, 5 l’instar de l’analyse
des mots-clés dans AV Frequency List Tool (Cf. section 2.1). Apres l’extraction et avant
l’inte1prétation, la liste des marqueurs lexicaux stables repérés subit le méme traitement
que la liste des mots-clés, 5 savoir la suppression des mots grammaticaux, des noms
propres et des hapax. Dans le corpus technique, nous recensons ainsi 3479 marqueurs
lexicaux stables, statistiquement signiﬂcatifs (p<0,05), dont 3123 formes (ou presque
90%) ﬁgurent aussi dans la liste des 4717 mots-clés.

248

5.2 Marqueurs lexicaux stables versus mots-clés

Le tableau ci-dessous (Cf. table 1) montre que les mots-clés les plus fréquents et les plus
spéciﬁques comme machine, outil, piéce, visualisés dans la colonne de droite aux rangs de
spéciﬂcité (LLR) 1, 2 et 4 respectivement, ne ﬂgurent pas parmi les marqueurs lexicaux
stables les plus spéciﬁques, visualisés 5 gauche du tableau. En effet, ils se retrouvent
respectivement aux rangs de SMEA 33, 55 et 170. On observe également que la prise en
considération de la dispersion relegue certaines unités lexicales, tres fréquentes dans les
revues (p.ex. Fig) 5 un rang moins spéciﬁque (37 au lieu de 9). Les vrais termes, qui sont
spéciﬁques du domaine, occupent des rangs plus spéciﬁques (usinage, broche, copeau,
fraisage, serrage, ...). Ensuite, les mots généraux, qui ont des emplois généraux et
techniques, occupent 5 juste titre des rangs un peu moins spéciﬁques (machine, outil,
piéce, ...). Enﬂn, les mots généraux peu fréquents et 5 peine spéciﬁques (i.e. la queue de
la liste des 4717 mots-clés) ne se retrouvent pas parmi les 3479 marqueurs lexicaux
stables. Il s’avere que la fréquence technique moyenne des 4717 mots-clés est plus faible
(140,77) que celle des 3479 marqueurs lexicaux stables (182,16). Par ailleurs, la
corrélation entre la fréquence dans le corpus technique et la valeur de SMEA, qui indique
le degré de spéciﬁcité, est moins problématique dans la liste des marqueurs lexicaux
stables (0,32) que dans la liste des 4717 mots-clés, ou la corrélation entre la fréquence
technique et la valeur du LLR était trop importante (0,87).

lemme SNEEA SLM f1-éq.tech. mots-clés
1 usinage 85,699726 180 6720 1 machine
2 broche 74,8200697 180 2893 2 outil
3 copeau 73,7392965 180 2557 3 usinage
4 fraisage 68,364653 180 1873 4 piece
5 usiner 68,3239216 180 1577 5 mm
6 machine-outil 67,6419261 180 1005 6 vitesse
7 serrage 66,3394778 180 939 7 coupe
8 percage 62,8188634 180 846 8 broche
9 fraise 62,0265842 180 1571 9 Fig
10 meule 61,8557297 180 776 10 axe

TABLE 1 — Top 10 des marqueurs lexicaux stables du corpus technique (5 gauche),
par rapport au top 10 des 4717 mots-clés (5 droite).

5.3 Corrélation entre la spéciﬁcité et la monosémie

Pour étudier la corrélation entre le rang de spéciﬂcité (rang de SMEA) et le rang de
monosémie des 3479 marqueurs lexicaux stables, nous procédons 5 me analyse
statistique de régression simple. Elle montre u.ne corrélation négative entre le rang de

249

spéciﬁcité et le rang de monosémie (-0,49). Il s’avere donc que les marqueurs lexicaux
les plus stables et les plus spéciﬂques ne sont pas les plus monosémiques. Toutefois, la
corrélation (-0,49) est moins convaincante que celle pour les 4717 mots-clés (-0,72). Le
pourcentage de variation expliquée R2 de 23,87% (valeur p<2,2e'15) est également
moins convaincant que celui pour les 4717 mots-clés (51,57% et valeur p< 2,2e'15). Ces
résultats moins concluants pour les marqueurs lexicaux stables s’expliquent
principalement par l’absence des mots généraux peu fréquents et tres peu spéciﬁques,
qui sont tres monosémiques, et par le fait que les mots les plus fréquents occupent, 5
juste titre, des rangs moins spéciﬂques. En raison de leur fréquence plus élevée dans le
corpus technique, ces demiers ont plus de chances d’étre polysémiques et/ou de
constituer la téte d’unités polylexicales, oil ils sont désambiguisés par les autres
composants (par exemple machine a fraiser, machine a rainurer).

Notons que le test de Goldfeld-Quandt souleve aussi un probleme d’hétéroscédasticité
(statistique F du GQ-test 1,37), mais moins important que pour les 4717 mots-clés
(2,07). Le probleme de Phétéroscédasticité est donc résolu en partie, mais suggere la
présence d’une variable supplémentaire, cachée jusqu’a présent, qui prédit peut-étre une
partie de la variation du rang de monosémie. Cette variable pourrait étre liée au fait que
les mots spéciﬂques constituent la téte d’unités polylexicales dans le corpus technique.
Des recherches futures permettront de vérifier si elle permet d’expliquer
Phétéroscédasticité et dans quelle mesure.

6 Conclusion

Dans cet article, nous avons ét11dié les unités lexicales spéciﬂques d’un corpus technique
relevant du domaine spécialisé restreint des machines-outils pour l’usinage des métaux.
Nous nous sommes tout particulierement intéressés 5 la corrélation entre le rang de
spéciﬁcité et le rang de monosémie de ces unités spéciﬂques.

Une double analyse quantitative a permis de générer une liste de 4717 mots-clés, avec
un degré de spéciﬁcité et un degré de monosémie ou d’homogénéité sémantique. Ces
données quantitatives ont permis de classer les 4717 mots-clés dans un continuum de
spéciﬁcité et dans un continuum de monosémie aﬁn d’examiner la corrélation entre le
rang de spéciﬁcité et le rang de monosémie par le biais d’une analyse statistique de
régression simple. Nous avons observé une corrélation négative, qui indique que les
unités lexicales les plus spéciﬂques du corpus technique, relevées avec la méthodologie
de l’analyse des mots-clés, ne sont pas les plus homogenes sémantiquement, au contraire.
Cette observation a permis de remettre en cause la these monosémiste traditionnelle. La
méthode alternative de l’analyse des marqueurs lexicaux stables (Stable Lexical Marker
Analysis ou SLMA) a permis de remédier aux problemes statistiques et méthodologiques
d’l1étéroscédasticité et de multicollinéarité, en prenant en considération la dispersion et
en utilisant une autre mesure statistique. Elle a généré une liste de 3479 marqueurs
lexicaux stables avec un nouveau rang de spéciﬁcité (rang de SMEA). Les résultats de
l’analyse de régression simple conﬂrment la corrélation négative entre le nouveau rang
de spéciﬁcité (rang de SMEA) et le rang de monosémie des marqueurs lexicaux stables,
bien qu’elle soit moins forte. Ces premieres expérimentations montrent donc que
l’analyse des marqueurs lexicaux stables constit11e une alternative valable pour l’analyse
des mots-clés.

250

Références

BERTELS, A., SPEELMAN, D. et GEERAERTS, D. (2010). La corrélation ent.r'e la spéciﬁcité et la
sémantique dans un corpus spécialisé. In Revue de Sérnantique et de Pragmatique n°27,
pages 79-102.

BHREATNACH, U. et DE BARRA CUSACK, F., éditeurs (2010). TKE 2010 : Presenting
Terminology and Knowledge Engineering Resources Online: Models and Challenges, Fiontar.
Dublin City University.

BLUMENTHAL, P. et HAUSMANN, F.J., éditeurs (2006). Collocations, corpus, dictionnaires.
Languefrangaise, n° 150.

BOURIGAULT D., JACQUEMIN, C. et L’HoMME, M.-C., éditeurs (2001). Recent advances in
computational terminology, Amsterdam/Philadelphia. John Benjamins Publishing
Company.

BOURIGAULT, D. et SLODZIAN, M. (1999). Pour une terminologie textuelle. In Terminologies
Nouvelles n°19, pages 29-32.

CABRE, M.T. (2000). Terminologie et linguistique : la théorie des portes. In Terminologies
Nouvelles n°21, pages 10-15.

CONDAMINES, A. et REBEYROLLE, J. (1997). Point de vue en langue spécialisée. In Meta,
n°42(1), pages 174-184.

CONDAMINES, A., éditeur (2005). Sérnantique et corpus, Paris. Hermes-Science.

DE HERTOG, D., HEYLEN, K., SPEELMAN, D. et KOCKAERT, H. (2010). A variational linguistics
approach to term extraction. In (Bhreatnach et de Barra Cusack, 2010), pages 229-248.

DUNNING, T. (1993). Accurate methods for the statistics of su.rprise and coincidence.
Computational Linguistics n°19(1), pages 61-74.

ERIKSEN, L. 2002. Die Polysemie in der Allgemeinsprache und in der ju.ristischen
Fachsprache. Oder : Zu.r' Terminologie der ,Sache’ im Deutschen. In Hermes - Journal of
Linguistics n°28, pages 211-222.

FERRARI, L. (2002). Un caso de polisemia en el discu.r'so juridico? In Terminology n°8(2),
pages 221-244.

GAUDIN, F. (2003). Socioterminologie : une approche sociolinguistique de la terminologie.
Br11xel1es. Duculot

GROSSMANN, F. et TUTIN, A., éditeurs (2003). Les collocations, analyse et traitement,
Travaux et Recherches en linguistique appliquée, Série E, vol. 1.

HABERT, B., ILLOUZ, G., FOLCH, H. (2004). Dégrouper les sens : pou.r'quoi ? comment ? In
Actes des JADT 2004 (Joumées internationales d’anal_yse statistique des données textuelles),
Louvain-la-Neuve, pages 565-576.

HABERT, B., ILLOUZ, G., FOLCH, H. (2005). Des décalages de distribution aux divergences
d’acception, In (Condamines, 2005), pages 277-318.

251

J UCKER, A., SCHREIER, D. et HUNDT, M. éditeurs (2009). Corpora: Pragmatics and Discourse,
Amsterdam. Rodopi.

KRISTIANSEN, G. et DIRVEN, R., éditeurs (2008). Cognitive Sociolinguistics: Language
Variation, Cultural Models, Social Systems, Berlin/New York. Mouton de Gruyter. KWARY,
D.A. (2011). A hybrid method for determining technical vocabulary. In System n°39(2),
pages 175-185.

KWARY, D.A. (2011). A hybrid method for determining technical vocabulary. In System,
n°39(2), pages 175-185.LABBE, C. et LABBE, D. (2001). Que mesure la spéciﬂcité du
vocabulaire ? In Lexicometrica n°3.

LAFON, P. (1984). Dépouillements et statistiques en lexicométrie, Geneve-Paris. Slatkine-
Champion.

LEMAY, C., L'I-IOMME, M.C. et DROUIN, P. (2005). Two methods for extracting speciﬁc
single-word terms from specialized corpora. Experimentation and evaluation. In
International Journal of Corpus Linguistics, n°10(2), pages 227-255.

MARTINEZ, W. (2000). Mise en évidence de rapports synonymiques par la métl1ode des
cooccutrences. In Actes des JADT 2000 (Joumées internationales d’analyse statistique des
données textuelles), Lausanne, pages 78-84.

MAYAFFRE, D. (2008), Quand ‘travail’, ‘famille’, ‘patrie’ co-occutrent dans le discours de
Nicolas Sarkozy. Etude de cas et réﬂexion tl1éorique sur la co-occurrence, In Actes des
JADT 2008 (Joumées internationales d’analyse statistique des données textuelles), Lyon,
pages 811-822.

PAQUOT, M. et BESTGEN, Y. (2009). Distinctive words in academic writing: a comparison
of three statistical tests for keyword extraction >>, In (Jucker et aL, 2009), pages 247-269

SCOTT, M. et TRIBBLE, C. (2006). Textual Patterns. Key words and corpus analysis in language
education. Studies in Corpus Linguistics, vol. 22. Amsterdam. Benjamins.

SPEELMAN, D., GRONDELAERS, S. et GEERAERTS, D. (2006). A profile-based calculation of
region and register variation: the synchronic and diachronic status of the two main
national varieties of Dutch. In (Wilson et aL, 2006), pages 195-202.

SPEELMAN, D., GRONDELAERS, S. et GEERAERTS, D. (2008). Variation in the choice of
adjectives in the two main national varieties of Dutch. In (Kristiansen et Dirven, 2008),
pages 205-233.

TEMMERMAN, R. (2000). Towards new ways of terminology description. The sociocognitive
approach, Amsterdam/Philadelphia. John Benjamins Publishing Company.

VERONIS, J. (2003). Cartographie lexicale pour la recherche d’informations. Actes de
TALN 2003(Traiternent automatique des langues naturelles), Batz-sur-Mer, pages 265-274.

WILSON, A., ARCHER, D. et RAYSON, P., éditeurs (2006). Corpus Linguistics around the
World, Amsterdam. Rodopi.

WUSTER, E. (1991).  in die allgerneine Terminologielehre und terminologische
Lexikographie, (3. Auﬂ.), Bonn. Romanistischer Verlag.

252

