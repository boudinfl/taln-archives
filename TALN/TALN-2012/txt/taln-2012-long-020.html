<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Une &#233;tude en 3D de la paraphrase: types de corpus, langues et techniques</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 267&#8211;280,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Une &#233;tude en 3D de la paraphrase :
types de corpus, langues et techniques
</p>
<p>Houda Bouamor Aur&#233;lien Max Anne Vilnat
LIMSI-CNRS
</p>
<p>Univ. Paris-Sud
Orsay, France
prenom.nom@limsi.fr
</p>
<p>R&#201;SUM&#201;
Cet article pr&#233;sente une &#233;tude d&#233;taill&#233;e de l&#8217;impact du type du corpus sur la t&#226;che d&#8217;acquisition
de paraphrases sous-phrastiques. Nos exp&#233;riences sont men&#233;es sur deux langues et quatre types
de corpus, et incluent une combinaison efficace de quatre syst&#232;mes d&#8217;acquisition de paraphrases.
Nous obtenons une am&#233;lioration relative de plus de 27% en F-mesure par rapport au meilleur
syst&#232;me, en anglais et en fran&#231;ais, ainsi qu&#8217;une am&#233;lioration relative &#224; notre combinaison de
syst&#232;mes de 22% pour l&#8217;anglais et de 5% pour le fran&#231;ais quand tous les types de corpus sont
utilis&#233;s pour l&#8217;acquisition depuis le type de corpus le plus couramment disponible.
</p>
<p>ABSTRACT
A study of paraphrase along 3 dimensions : corpus types, languages and techniques
</p>
<p>In this paper, we report a detailed study of the impact of corpus type on the task of sub-sentential
paraphrase acquisition. Our experiments are for 2 languages and 4 corpus types, and involve an
efficient machine learning-based combination of 4 paraphrase acquisition systems. We obtain
relative improvements of more than 27% in F-measure over the best individual system on English
and French, and obtain a relative improvement over the combination system of 22% for English
and 5% for French when using all other corpus types as additional training data for our most
readily available corpus type.
</p>
<p>MOTS-CL&#201;S : acquisition de paraphrases, constitution de corpus.
</p>
<p>KEYWORDS: paraphrase acquisition, corpus collection.
</p>
<p>1 Introduction
</p>
<p>La variation paraphrastique est probablement l&#8217;une des caract&#233;ristiques les plus fascinantes
de la langue naturelle : diff&#233;rentes expressions peuvent &#234;tre utilis&#233;s pour v&#233;hiculer des sens
tr&#232;s proches. Par exemple, les segments soulign&#233;s dans les phrases elle semblait heureuse1
de retrouver sa famille2 et elle avait l&#8217;air contente1 d&#8217;&#234;tre &#224; nouveau parmi les siens2 constituent
des paires de paraphrases acceptables pouvant &#234;tre exploit&#233;es dans divers contextes.
</p>
<p>Il s&#8217;agit cependant de l&#8217;une des principales sources de complexit&#233; pour les processus de traitement
automatique des langues. Les th&#233;saurus encod&#233;s manuellement sont par nature incomplets, et
ne sont pas disponibles pour toutes les langues. De plus, ils ne comprennent souvent pas d&#8217;ex-
</p>
<p>267</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>pressions de plusieurs mots qui sont n&#233;cessaires pour produire ou reconna&#238;tre automatiquement
des paraphrases plus complexes. Le besoin d&#8217;acqu&#233;rir automatiquement des paraphrases &#224; partir
de corpus de textes a ainsi &#233;t&#233; &#224; l&#8217;origine de nombreux travaux. L&#8217;acquisition de paraphrases
sous-phrastiques, que nous appellerons simplement paraphrases dans la suite, repose la plupart
du temps sur l&#8217;appariement pr&#233;alable d&#8217;unit&#233;s de plus grande taille (des paires de phrases ou
des documents comparables). Ces unit&#233;s peuvent &#234;tre obtenues directement par un processus
supervis&#233;, tel que la traduction humaine multiple, ou l&#8217;appariement automatique fond&#233; sur la
similarit&#233; entre textes (Mihalcea et al., 2006). On observe que les techniques pour l&#8217;acquisition
de paraphrases sont g&#233;n&#233;ralement tr&#232;s d&#233;pendantes des types de corpus sur lesquels elles ont &#233;t&#233;
d&#233;velopp&#233;es (Madnani et Dorr, 2010). Dans l&#8217;ordre inverse de leur disponibilit&#233;, ces types de
corpus peuvent &#234;tre grossi&#232;rement d&#233;finis comme :
</p>
<p>1. corpus monolingues parall&#232;les : des paires d&#8217;&#233;nonc&#233;s de sens &#233;quivalents align&#233;es de
fa&#231;on supervis&#233;e (comme les traductions multiples de livres (Barzilay et McKeown, 2001)
ou les groupes de questions ayant la m&#234;me r&#233;ponse (Bernhard et Gurevych, 2008)).
</p>
<p>2. corpus multilingues parall&#232;les : des paires d&#8217;&#233;nonc&#233;s disponibles dans deux langues ou
plus (Bannard et Callison-Burch, 2005) (comme les transcriptions des d&#233;bats parlemen-
taires europ&#233;ens)
</p>
<p>3. corpus monolingues comparables : des paires de textes associ&#233;s en fonction de similarit&#233;
textuelle (comme des extraits de documents du Web (Pas&#231;a et Dienes, 2005)) en suivant
&#233;ventuellement certaines heuristiques (tels que les articles de journaux publi&#233;s dans le
m&#234;me intervalle de temps (Dolan et al., 2004))
</p>
<p>Les ressources dans lesquelles les paraphrases abondent, ce qui facilite g&#233;n&#233;ralement une ex-
traction pr&#233;cise, sont peu fr&#233;quentes &#224; l&#8217;&#233;tat naturel, alors que les unit&#233;s de textes comparables
sont potentiellement tr&#232;s nombreuses &#224; l&#8217;&#233;chelle du Web (Pas&#231;a et Dienes, 2005; Bhagat et
Ravichandran, 2008). Ces consid&#233;rations nous conduisent &#224; envisager d&#8217;am&#233;liorer les perfor-
mances des techniques d&#8217;acquisition de paraphrases sur un type de corpus en utilisant du mat&#233;riel
d&#8217;apprentissage (i.e. des exemples annot&#233;s) &#224; partir d&#8217;autres types de corpus.
</p>
<p>Dans cet article, nous pr&#233;sentons une analyse d&#233;taill&#233;e de la t&#226;che d&#8217;acquisition de paraphrases
sur quatre types de corpus monolingues repr&#233;sentatifs, que nous avons nomm&#233;s en fonction du
type de signal du contenu s&#233;mantique d&#8217;origine :
</p>
<p>&#8211; TEXTE : des paires de phrases r&#233;sultant de traductions multiples d&#8217;un m&#234;me texte.
&#8211; PAROLE : des paires d&#8217;&#233;nonc&#233;s r&#233;sultant de traductions multiples de m&#234;mes extraits de parole.
&#8211; SC&#200;NE : des paires d&#8217;&#233;nonc&#233;s r&#233;sultant de descriptions multiples d&#8217;une m&#234;me sc&#232;ne visuelle.
&#8211; &#201;V&#201;NEMENT : des paires d&#8217;&#233;nonc&#233;s r&#233;sultant de descriptions multiples d&#8217;un m&#234;me &#233;v&#233;n&#233;ment
</p>
<p>ou de deux &#233;v&#233;nements proches.
</p>
<p>Notre &#233;tude sera men&#233;e sur des collections constitu&#233;es d&#8217;un nombre identique de paires de phrases
pour chacun des types de corpus, ceci pour deux langues, l&#8217;anglais et le fran&#231;ais. Nous utiliserons
quatre syst&#232;mes d&#8217;acquisition de paraphrases (Bouamor et al., 2011) et d&#233;crirons une architecture
efficace pour valider la combinaison de leurs hypoth&#232;ses par apprentissage automatique. Nous
d&#233;taillerons les quantit&#233;s de paraphrases par type accessibles &#224; partir de chacun des types de
corpus &#233;tudi&#233;s, et nous donnerons les performances de chaque syst&#232;me individuel ainsi que notre
syst&#232;me de combinaison sur chaque type de corpus pris ind&#233;pendamment, et sur chaque type de
corpus en ajoutant d&#8217;autres types de corpus comme donn&#233;es d&#8217;entra&#238;nement pour la validation.
</p>
<p>268</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L&#8217;un de nos principaux r&#233;sultats est que, pour les deux langues &#233;tudi&#233;es, l&#8217;acquisition de para-
phrases peut &#234;tre significativement am&#233;lior&#233;e &#224; l&#8217;aide des donn&#233;es d&#8217;entra&#238;nement de types de
corpus diff&#233;rents. Ceci est notablement le cas pour le corpus &#201;V&#201;NEMENT, source la plus facile &#224; ac-
qu&#233;rir pour l&#8217;acquisition de paraphrases, ce qui ouvre d&#8217;int&#233;ressantes perspectives pour des &#233;tudes
ult&#233;rieures sur l&#8217;acquisition de paraphrases &#224; grande &#233;chelle et leur utilisation pour l&#8217;am&#233;lioration
de la performance d&#8217;applications de TAL. Nous avons &#233;galement &#233;labor&#233; une typologie, sur les
deux langues, quantifi&#233;e des types de paraphrases sur chacun des types de corpus, &#224; la fois pour
les paraphrases de r&#233;f&#233;rence et pour celles que notre syst&#232;me de combinaison, le plus performant,
parvient &#224; acqu&#233;rir sur chaque type de corpus, ce qui fournira des informations pr&#233;cieuses pour
guider la suite de ces travaux.
</p>
<p>Dans la suite de cet article, nous commencerons par un rapide &#233;tat de l&#8217;art sur l&#8217;acquisition de
paraphrases (section 2), puis nous d&#233;crirons la m&#233;thodologie de construction de nos corpus
et leurs caract&#233;ristiques (section 3). Nous d&#233;taillerons ensuite nos r&#233;sultats de l&#8217;&#233;valuation de
l&#8217;acquisition de paraphrases (section 4). &#192; la section 5.1, nous pr&#233;senterons tout d&#8217;abord la
performance d&#8217;un syst&#232;me de combinaison sur chacun des types de corpus, puis la performance
de ce syst&#232;me lorsque sont utilis&#233;es des donn&#233;es d&#8217;entra&#238;nement additionnelles provenant des
autres types de corpus (5.2). Enfin nous conclurons en &#233;voquant diff&#233;rentes pistes de recherche
ouvertes par nos travaux (section 6).
</p>
<p>2 &#201;tat de l&#8217;art
</p>
<p>Au cours du temps, l&#8217;acquisition et la g&#233;n&#233;ration de paraphrases ont attir&#233; un grand nombre de
travaux de recherche, qui sont trop nombreux pour &#234;tre correctement r&#233;sum&#233;s ici : Madnani et
Dorr (2010) pr&#233;sentent une revue relativement compl&#232;te des principales approches. L&#8217;acquisition
de paraphrases au niveau de phrases enti&#232;res a &#233;t&#233; abord&#233;e &#224; partir de ressources sp&#233;cifiques
augmentant la probabilit&#233; de trouver des phrases en relation de paraphrase (Dolan et al., 2004;
Bernhard et Gurevych, 2008; Wubben et al., 2009), &#224; partir de corpus monolingues comparables
(Barzilay et Elhadad, 2003; Fung et Cheung, 2004; Nelken et Shieber, 2006) ainsi qu&#8217;&#224; partir du
Web (Pas&#231;a et Dienes, 2005; Bhagat et Ravichandran, 2008).
</p>
<p>Diverses techniques ont &#233;t&#233; propos&#233;es pour l&#8217;acquisition de paraphrases &#224; partir de paires
de phrases en relation (Barzilay et McKeown, 2001; Pang et al., 2003) et &#224; partir de corpus
parall&#232;les bilingues (Bannard et Callison-Burch, 2005; Kok et Brockett, 2010). Le lien entre
la construction du corpus et le d&#233;veloppement et l&#8217;&#233;valuation des techniques d&#8217;acquisition est
l&#8217;objet de (Cohn et al., 2008; Callison-Burch et al., 2008). &#192; notre connaissance, il n&#8217;existe pas
d&#8217;autres travaux portant sur l&#8217;acquisition de paraphrases qui soient men&#233;s sur plusieurs types de
corpus et sur plusieurs langues de fa&#231;on comparable. Pour sa part, le travail de Chan et al. (2011)
explore la compl&#233;mentarit&#233; de corpus bilingues et monolingues en acquisition de paraphrases.
Faruqui et Pad&#243; (2011) s&#8217;int&#233;ressent &#224; l&#8217;acquisition de paires en relation d&#8217;implication (pr&#233;misse
et hypoth&#232;se), en menant des exp&#233;riences dans trois langues sur des corpus journalistiques de
diff&#233;rents domaines pour une langue. Bien que leur travail ne soit pas directement comparable
au n&#244;tre, ces auteurs montrent que la robustesse entre domaines est difficile &#224; obtenir.
</p>
<p>Enfin, l&#8217;&#233;valuation de paraphrases g&#233;n&#233;r&#233;es automatiquement a &#233;t&#233; l&#8217;objet de quelques travaux
r&#233;cents (Liu et al., 2010; Chen et Dolan, 2011; Metzler et al., 2011), bien que ce probl&#232;me reste
difficile et globalement peu r&#233;solu. La g&#233;n&#233;ration de paraphrases motiv&#233;e par une application
</p>
<p>269</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>particuli&#232;re offre un moyen indirect pour l&#8217;&#233;valuation de la performance de la g&#233;n&#233;ration
de paraphrases (Zhao et al., 2009). Par exemple, le domaine de la Traduction Automatique
Statistique est &#224; l&#8217;origine de travaux montrant l&#8217;utilit&#233; &#224; la fois de paraphrases produites par des
humains (Schroeder et al., 2009; Resnik et al., 2010) et produites automatiquement (Madnani
et al., 2008; Marton et al., 2009; Max, 2010) pour am&#233;liorer la performance en traduction.
</p>
<p>3 Collecte de corpus de paires de phrases
</p>
<p>Dans cet article, nous nous int&#233;ressons &#224; l&#8217;acquisition de paraphrases &#224; partir de paires de phrases
en relation, caract&#233;ristiques de quatre types de corpus. Un corpus pour chaque type a &#233;t&#233; construit
en deux langues, l&#8217;anglais et le fran&#231;ais, et comporte 625 paires de phrases par langue. Nous
d&#233;taillons maintenant la m&#233;thode de constitution de ces corpus.
</p>
<p>TEXTE Pour l&#8217;anglais, nous avons utilis&#233; le corpus MTC 1 (d&#233;crit dans (Cohn et al., 2008)), qui
regroupe des ensembles d&#8217;articles d&#8217;actualit&#233; traduits plusieurs fois depuis le chinois, et pour
le fran&#231;ais le corpus CESTA 2 regroupant des ensembles d&#8217;articles d&#8217;actualit&#233; traduits depuis
l&#8217;anglais. Pour chaque groupe de phrases, nous retenons les paires de phrases ayant la plus petite
distance d&#8217;&#233;dition au-dessus d&#8217;un seuil fix&#233; empiriquement, en les extrayant d&#8217;abord de chacun
des groupes et en reconsid&#233;rant par la suite des groupes d&#233;j&#224; utilis&#233;s pour atteindre le nombre
vis&#233; de paires de phrases.
Exemple : &#171; Dans l&#8217; autre cas , le gel des terres est destin&#233; &#224; ma&#238;triser l&#8217; offre . &#8596; Le deuxi&#232;me type de gel de
terres doit servir &#224; la gestion de l&#8217; offre . &#187;
</p>
<p>PAROLE Pour l&#8217;anglais, nous avons utilis&#233; des fichiers 3 librement disponibles de sous-titres
de films tourn&#233;s en fran&#231;ais, Le Fabuleux Destin d&#8217;Am&#233;lie Poulain et Les Choristes, et pour le
fran&#231;ais nous avons pris les fichiers de la s&#233;rie t&#233;l&#233;vis&#233;e tourn&#233;e en anglais am&#233;ricain Desperate
Housewives. Nous avons d&#8217;abord align&#233; chaque corpus parall&#232;le en utilisant l&#8217;algorithme d&#233;crit
dans (Tiedemann, 2007), bas&#233; sur des indices de dur&#233;e et d&#233;velopp&#233; pour des sous-titres
multilingues, puis nous avons extrait des paires de phrases en dessous d&#8217;un seuil minimal de
distance d&#8217;&#233;dition, et filtr&#233; manuellement les erreurs apparentes de l&#8217;algorithme pr&#233;c&#233;dent.
Exemple : &#171; Vous pourriez passer ce soir et regarder ma tuyauterie ? &#8596; Pourriez-vous venir inspecter ma
tuyauterie ce soir ? &#187;
</p>
<p>SC&#200;NE Nous avons utilis&#233; le Multiple Video Description Corpus (Chen et Dolan, 2011) obtenu
&#224; partir de descriptions multiples de courtes vid&#233;os. De fa&#231;on analogue &#224; ce qui a &#233;t&#233; fait pour
TEXTE, nous avons choisi des paires de phrases au sein de ces groupes en fonction d&#8217;une distance
minimale d&#8217;&#233;dition au-dessus d&#8217;un certain seuil. Un point important est que pour l&#8217;anglais nous
avons pu utiliser des descriptions qualifi&#233;es de &#8220;v&#233;rifi&#233;es&#8221;. Cependant, les descriptions en fran&#231;ais
dans cette ressource sont disponibles dans des quantit&#233;s bien moins importantes, et en outre
aucune n&#8217;a le statut de &#8220;v&#233;rifi&#233;e&#8221;. Nous avons tout de m&#234;me d&#233;cid&#233; d&#8217;utiliser ce corpus, mais en
gardant &#224; l&#8217;esprit que cette source est de nettement moins bonne qualit&#233;. 4
</p>
<p>Exemple : &#171; une personne met du lait sur du riz. &#8596; un homme fait du riz au lait. &#187;
1. http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2002T01
2. http://www.elda.org/article125.html
3. http://www.opensubtitles.org
4. Ce type de corpus sera d&#233;sign&#233; entre parenth&#232;se pour le fran&#231;ais (&#8220;(SC&#200;NE)&#8221;) dans tous les tableaux dans la suite
</p>
<p>pour rappeler son caract&#232;re particulier.
</p>
<p>270</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#201;V&#201;NEMENT Nous avons utilis&#233; des titres de groupes d&#8217;articles d&#8217;actualit&#233; provenant du service
d&#8217;agr&#233;gation Google News 5. Nous avons ensuite affin&#233; l&#8217;algorithme de regroupement en retenant
les paires de titres dont les dates de publication des articles n&#8217;&#233;taient pas s&#233;par&#233;es de plus d&#8217;un
jour. Nous avons reproduit la m&#234;me proc&#233;dure de s&#233;lection que pour TEXTE et SC&#200;NE pour obtenir
une couverture maximale sur l&#8217;ensemble des groupes.
Exemple : &#171; 700 000 d&#233;c&#232;s li&#233;s au Sida ont pu &#234;tre &#233;vit&#233;s en 2010 &#8596; Forte baisse des d&#233;c&#232;s et des infections li&#233;s
au sida en 2010 &#187;
</p>
<p>Statistiques du corpus Accords inter-annotateur Stat. sur les formes dans les paraphrases
500 paires de phrases 50 paires de phrases sans les paraphrases identiques
</p>
<p>para. s&#251;res para. possibles
# formes # formes para. para. % formes # formes % formes # formes
</p>
<p>par phrases s&#251;res possibles
ANGLAIS
</p>
<p>TEXTE 21 473 21,0 66,1 20,4 18,6 4 004 12,3 2 651
PAROLE 11 049 10,5 79,1 10,9 17,5 1 942 31,6 3 500
SC&#200;NE 7 783 7,5 80,5 35,2 10,9 851 14,0 1 094
</p>
<p>&#201;V&#201;NEMENT 8 609 8,0 65,3 20,5 17,5 1 506 14,5 1 251
FRAN&#199;AIS
</p>
<p>TEXTE 24 641 24,0 64,6 16,6 29,2 7 218 6,2 1 527
PAROLE 11 850 11,5 82,7 20,8 22,5 2 667 16,7 1 981
(SC&#200;NE) 7 012 6,5 42,8 9,3 3,9 275 9,4 664
</p>
<p>&#201;V&#201;NEMENT 9 121 9,1 67,8 3,8 19,6 1 793 9,6 876
</p>
<p>TABLE 1 &#8211; Description de l&#8217;ensemble des corpus collect&#233;s et des annotations de r&#233;f&#233;rence pour
les paraphrases en anglais et en fran&#231;ais. Pour rappel, SC&#200;NE pour le fran&#231;ais appara&#238;t entre
parenth&#232;ses car nous ne le consid&#233;rons pas de la m&#234;me qualit&#233; que les autres corpus.
</p>
<p>Nous avons ensuite r&#233;alis&#233; une annotation des paraphrases dans ces corpus, en suivant l&#8217;essentiel
des consignes d&#233;crites dans (Cohn et al., 2008) 6 &#224; l&#8217;aide de l&#8217;outil YAWAT (Germann, 2008), mis &#224;
part le fait que nous ne sommes pas partis d&#8217;alignements initiaux obtenus automatiquement afin
de ne pas biaiser le travail des annotateurs. Les principales consignes &#233;taient que les paraphrases
s&#251;res et possibles devaient &#234;tre distingu&#233;es, que les alignements les plus petits devaient &#234;tre
privil&#233;gi&#233;s sans d&#233;courager n&#233;anmoins les alignements groupe-&#224;-groupe (i.e. n-m), et que les
phrases devaient &#234;tre align&#233;es autant que possible. Nous ne consid&#233;rerons dans la suite, pour
toutes les statistiques et les exp&#233;riences, que les paraphrases qui ne sont pas des paires identiques
(telles que &#171; petit pont de bois &#8596; petit pont de bois &#187;), car on peut les consid&#233;rer comme triviales
au regard de la t&#226;che d&#8217;acquisition.
</p>
<p>La table 1 indique diff&#233;rentes statistiques pour les corpus collect&#233;s. La premi&#232;re observation
est que TEXTE contient des phrases significativement plus longues que les autres types, plus
de deux fois plus longues que celles de PAROLE par exemple. La table contient &#233;galement les
valeurs d&#8217;accords inter-annotateurs 7 calcul&#233;es sur des sous-ensembles de 50 paires de phrases
annot&#233;es ind&#233;pendamment par deux annotateurs. Nous consid&#233;rons comme acceptables les
valeurs obtenues pour les paraphrases s&#251;res, mais les valeurs obtenues pour les paraphrases
possibles sont faibles. Ce dernier r&#233;sultat &#233;tait relativement pr&#233;visible, &#233;tant donn&#233; le nombre d&#8217;in-
</p>
<p>5. http://news.google.com
6. Voir http://staffwww.dcs.shef.ac.uk/people/T.Cohn/paraphrase_guidelines.pdf
7. Pour chaque type de paraphrase, nous calculons la moyenne des valeurs de rappel obtenues par chaque annotateur
</p>
<p>comme r&#233;f&#233;rence et nous effectuons la moyenne.
</p>
<p>271</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>  
</p>
<p>COSINE*100 BLEU 1-TER METEOR
0
</p>
<p>10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>60
</p>
<p>70
TEXT SPEECH SCENE EVENT
</p>
<p>  
</p>
<p>COSINE*100 BLEU 1-TER METEOR
0
</p>
<p>10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>60
</p>
<p>70
</p>
<p>FIGURE 1 &#8211; Moyenne des similarit&#233;s des paires de phrases pour tous les corpus pour l&#8217;anglais (&#224;
gauche) et le fran&#231;ais (&#224; droite) en utilisant le cosinus des vecteurs de formes, BLEU (Papineni
et al., 2002), TER (Snover et al., 2006) et METEOR (Lavie et Agarwal, 2007) (&#224; noter que les
synonymes de WordNet ne pourraient &#234;tre utilis&#233;s que pour l&#8217;anglais).
</p>
<p>terpr&#233;tations pour les paraphrases entrant possiblement dans cette cat&#233;gorie. Cela ne constituera
toutefois pas un probl&#232;me dans la suite dans nos exp&#233;riences : comme nous le verrons dans la
section 4, notre m&#233;trique d&#8217;&#233;valuation ne les consid&#232;rera pas comme des solutions attendues, et
se limitera &#224; ne pas les consid&#233;rer comme fausses lorsqu&#8217;elles apparaitront parmi les hypoth&#232;ses
d&#8217;un syst&#232;me.
</p>
<p>La table 1 montre enfin les pourcentages et les nombres de paraphrases pour chaque niveau de
certitude pour chacun des corpus. Nous obtenons approximativement le m&#234;me nombre total de
paraphrases pour l&#8217;anglais (16 799) et le fran&#231;ais (17 001). Les corpus anglais ont &#224; peu pr&#232;s le
m&#234;me nombre de paraphrases s&#251;res et possibles (8 303 par rapport &#224; 8 496) alors qu&#8217;en fran&#231;ais
on trouve davantage de paraphrases s&#251;res (11 953 contre 5 048). Ceci peut s&#8217;expliquer par le
fait que les annotateurs ont travaill&#233; ind&#233;pendemment, avec des interpr&#233;tations possiblement
diff&#233;rentes de la t&#226;che, et que les corpus, aussi comparables soient-ils entre langue, sont diff&#233;rents
par nature. Les autres faits remarquables sont que TEXTE contient beaucoup plus de paraphrases
que les autres corpus et que PAROLE comporte proportionnellement plus de paraphrases possibles
que les autres corpus, et que SC&#200;NE contient nettement moins de paraphrases, en pourcentage et
en nombre.
</p>
<p>Dans la figure 1 diff&#233;rentes mesures typiquement utilis&#233;es, notamment en Traduction Automa-
tique, de similarit&#233; entre paires de phrases sont donn&#233;es. TEXTE contient les paires de phrases les
plus similaires selon toutes les m&#233;triques, suivi de pr&#232;s par &#201;V&#201;NEMENT (dont les phrases sont
beaucoup plus courtes). SC&#200;NE contient des paires de phrases qui sont plus similaires que celles
de PAROLE pour l&#8217;anglais, ce qui n&#8217;est pas le cas pour le fran&#231;ais.
</p>
<p>4 &#201;valuation de l&#8217;acquisition de paraphrases
</p>
<p>Nous adoptons la m&#233;thodologie PARAMETRIC de Callison-Burch et al. (2008) pour &#233;valuer la
performance des syst&#232;mes sur la t&#226;che d&#8217;acquisition de paraphrases sur les corpus d&#233;crits dans la
section pr&#233;c&#233;dente. Dans PARAMETRIC, un ensemble de paraphrases candidates extraites d&#8217;une
paire de phrases en relation est compar&#233; &#224; un ensemble de paraphrases de r&#233;f&#233;rence, obtenues
</p>
<p>272</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>par annotation manuelle, en calculant les mesures habituelles de pr&#233;cision (P) et rappel (R). La
premi&#232;re valeur correspond &#224; la proportion de paires d&#8217;hypoth&#232;ses de paraphrases, ensemble not&#233;
H, produites par un syst&#232;me qui sont correctes par rapport &#224; l&#8217;ensemble de r&#233;f&#233;rence contenant
les paraphrases s&#251;res et possibles, not&#233; Rtout. Le rappel est obtenu en calculant la proportion de
l&#8217;ensemble de r&#233;f&#233;rence de paraphrases s&#251;res, not&#233; Rs&#251;r,qui sont trouv&#233;es par un syst&#232;me. Nous
calculons &#233;galement une valeur de F-mesure (F1), qui consid&#232;re le rappel et la pr&#233;cision comme
&#233;galement importants. Ces valeurs sont donc donn&#233;es par les formules suivantes :
</p>
<p>P =
|H &#8745; Rtout|
|H| R=
</p>
<p>|H &#8745; Rs&#251;r|
|Rs&#251;r| F1 =
</p>
<p>2PR
</p>
<p>P + R
</p>
<p>Il est &#224; noter que la fa&#231;on dont les ensembles Rtout et Rs&#251;r de paires de paraphrases de r&#233;f&#233;rence
sont d&#233;finis garantit que les hypoth&#232;ses de paraphrases incluant les paraphrases de r&#233;f&#233;rence
annot&#233;es comme possibles ne p&#233;naliseront pas la pr&#233;cision sans toutefois augmenter le rappel.
</p>
<p>Toutes les valeurs de performance fournies dans les sections suivantes sont obtenues en effectuant
une validation crois&#233;e 10 fois 8 au lieu d&#8217;utiliser le d&#233;coupage des corpus en corpus de test/ corpus
d&#8217;apprentissage. Nous moyennons, par la suite, les r&#233;sultats sur chaque ensemble d&#8217;&#233;valuation
individuel pour obtenir des valeurs stables. Tous nos ensembles de donn&#233;es pour la validation
crois&#233;e contiennent 500 paires de phrases. 9
</p>
<p>5 Exp&#233;riences bilingues
</p>
<p>5.1 Une architecture pour l&#8217;acquisition de paraphrases sous-phrastiques
</p>
<p>Nous allons maintenant d&#233;crire les syst&#232;mes qui seront test&#233;s sur nos divers corpus d&#233;crits dans
la section 3 utilisant la m&#233;thodologie d&#233;crite dans la section 4. Ces syst&#232;mes individuels sont
d&#233;crits plus en d&#233;tails dans (Bouamor et al., 2011). Un syst&#232;me de combinaison est en outre
utilis&#233; pour valider automatiquement les hypoth&#232;ses de paraphrases produites par les syst&#232;mes
individuels en utilisant un ensemble de traits visant &#224; reconna&#238;tre des paraphrases. Quatre
syst&#232;mes individuels ont &#233;t&#233; utilis&#233;s et sont d&#233;crits ci-dessous : les raisons pour avoir retenu ces
syst&#232;mes incluent leur libre disponibilit&#233; et/ou le co&#251;t raisonnable de leur d&#233;veloppement, la
possibilit&#233; d&#8217;utiliser des ressources comparables l&#224; o&#249; pertinent pour les deux langues &#233;tudi&#233;es,
ainsi que les caract&#233;ristiques sp&#233;cifiques &#224; chaque technique.
</p>
<p>Apprentissage statistique d&#8217;alignements de mots (GIZA) L&#8217;outil GIZA++ (Och et Ney, 2004)
calcule des mod&#232;les statistiques d&#8217;alignement de mots de complexit&#233; croissante &#224; partir de corpus
parall&#232;les. Il a &#233;t&#233; lanc&#233; sur chacun des corpus monolingues de paires de phrases dans les
deux directions, les alignements ont &#233;t&#233; sym&#233;tris&#233;s puis les heuristiques classiques d&#8217;extraction
de bi-segments coh&#233;rents ont &#233;t&#233; appliqu&#233;es (Koehn et al., 2003), sans toutefois agrandir les
bi-segments par ajout de mots non align&#233;s aux fronti&#232;res.
</p>
<p>Connaissances linguistiques sur la variation de termes (FASTR) L&#8217;outil FASTR (Jacquemin,
1999) permet de rep&#233;rer des variantes de termes dans de grands corpus, les variations &#233;tant
d&#233;crites &#224; l&#8217;aide de m&#233;tar&#232;gles sp&#233;cifiant les d&#233;rivations morpho-syntaxiques possibles &#224; partir
</p>
<p>8. La validation crois&#233;e nous permet d&#8217;utiliser la totalit&#233; des donn&#233;es disponibles.
9. Il faut noter que, sur les 625 paires de phrases de d&#233;part pour chaque corpus, 125 paires de phrases sont extraites
</p>
<p>pour optimiser les param&#232;tres d&#8217;un syst&#232;me bas&#233; sur la m&#233;trique TERp (voir section 5.1).
</p>
<p>273</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>d&#8217;un terme donn&#233; au moyen d&#8217;expressions r&#233;guli&#232;res sur les cat&#233;gories morpho-syntaxiques. La
variation paradigmatique peut aussi s&#8217;exprimer au moyen de contraintes entre mots, imposant
qu&#8217;ils appartiennent &#224; la m&#234;me famille morphologique ou s&#233;mantique en utilisant des ressources
existantes disponibles pour nos deux langues. Les variantes pour tous les groupes de mots d&#8217;une
des phrases d&#8217;une paire sont extraites dans l&#8217;autre phrase, et l&#8217;on conserve l&#8217;intersection des
ensembles obtenus dans les deux directions.
</p>
<p>Transformations optimales entre s&#233;quences de mots (TERp) L&#8217;outil TERp (Snover et al.,
2010) peut &#234;tre utilis&#233; pour calculer un ensemble optimal (modulo quelques approximations)
d&#8217;&#233;ditions au niveau des mots et des segments qui permettent de transformer une phrase en une
autre. 10 Les types d&#8217;&#233;ditions sont param&#233;tr&#233;s par un ou plusieurs poids qui sont optimis&#233;s par
hill climbing pour maximiser la F-mesure, avec 100 red&#233;marrages al&#233;atoires, en utilisant les 125
paires de phrases r&#233;serv&#233;es &#224; cette fin dans chaque type de corpus.
</p>
<p>&#201;quivalence de traduction (PIVOT) Nous avons exploit&#233; la probabilit&#233; de paraphrase d&#233;finie
par Bannard et Callison-Burch (2005) pour des paraphrases extraites de corpus parall&#232;les
multilingues. Nous avons utilis&#233; le corpus Europarl 11 de d&#233;bats parlementaires en anglais et en
fran&#231;ais, comprenant environ 1,7 millions de phrases parall&#232;les, en prenant chaque langue comme
source et pivot &#224; tour de r&#244;le. GIZA++ a &#233;t&#233; utilis&#233; pour aligner les mots et les probabilit&#233;s de
traduction de segments ont &#233;t&#233; estim&#233;es &#224; partir de ces alignements par les m&#233;thodes standards
du syst&#232;me de traduction statistique MOSES (Koehn et al., 2007). Pour chaque segment d&#8217;une
paire de phrases, nous avons construit son ensemble de paraphrases, et extrait sa paraphrase de
l&#8217;autre phrase ayant la plus grande probabilit&#233;. Nous avons r&#233;it&#233;r&#233; ce processus dans les deux
directions, et finalement conserv&#233; pour chaque segment la paire de paraphrases issue d&#8217;une des
deux directions avec la probabilit&#233; la plus forte.
</p>
<p>Combinaison de syst&#232;mes par validation En calculant l&#8217;union de toutes les hypoth&#232;ses de
paraphrases issues de tous les syst&#232;mes pr&#233;c&#233;dents pour chaque paire de phrases, nous avons
proc&#233;d&#233; &#224; une classification en deux classes (soit, &#8220;paraphrase&#8221; ou &#8220;non paraphrase&#8221;) en utilisant
un classifieur &#224; maximum d&#8217;entropie MAXENT 12. Ceci permet d&#8217;inclure des traits qui n&#8217;&#233;taient
pas n&#233;cessairement pris en compte ou possibles &#224; consid&#233;rer dans les syst&#232;mes individuels.
Plus g&#233;n&#233;ralement, ceci permet de tenter d&#8217;apprendre une caract&#233;risation plus g&#233;n&#233;rique des
paraphrases, qui pourrait s&#8217;adapter trivialement &#224; un nombre quelconque de syst&#232;mes en entr&#233;e.
Les exemples positifs pour le classifieur sont ceux provenant de l&#8217;union des hypoth&#232;ses qui sont
&#233;galement pr&#233;sentes dans l&#8217;ensemble de r&#233;f&#233;rence Rs&#251;r. Les exemples n&#233;gatifs sont constitu&#233;s du
compl&#233;ment de cet ensemble dans l&#8217;union. Les traits que nous utilisons sont r&#233;sum&#233;s dans la
table 2.
</p>
<p>R&#233;sultats exp&#233;rimentaux Les r&#233;sultats pour les syst&#232;mes individuels, leur union et nos sys-
t&#232;mes de combinaison entra&#238;n&#233;s sur chaque type de corpus (colonne &#8220;appr.=C&#8221;) sont donn&#233;s
dans la Figure 3. Nous constatons tout d&#8217;abord que tous les syst&#232;mes obtiennent de meilleurs
r&#233;sultats sur TEXTE, pour lequel il y avait plus de donn&#233;es d&#8217;apprentissage disponibles et dans
lequel les &#233;quivalences s&#233;mantiques entre les paires de phrases &#233;taient plus probables. &#201;V&#201;NEMENT
appara&#238;t comme le type de corpus le plus difficile, ce qui pourrait &#234;tre consid&#233;r&#233; comme un
</p>
<p>10. Il est &#224; noter que contrairement &#224; ce que TERp permet, nous n&#8217;utilisons pas les &#233;quivalents de mots ou de segments
propos&#233;s par d&#233;faut car ceux-ci ne sont disponibles que pour l&#8217;anglais. Ce type de connaissance sera n&#233;anmoins apport&#233;
par les syst&#232;mes FASTR et PIVOT.
</p>
<p>11. http://statmt.org/europarl
12. Nous avons utilis&#233; l&#8217;impl&#233;mentation disponible &#224; : http://homepages.inf.ed.ac.uk/lzhang10/maxent_
toolkit.html
</p>
<p>274</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Traits d&#233;riv&#233;s des paires de segments &#8211; distance d&#8217;&#233;dition entre les paraphrases, racines
identiques, m&#234;mes formes, longueur de la phrase
Traits d&#233;riv&#233;s des paires de phrases &#8211; similarit&#233; entre paires de phrases (cosinus, BLEU, TER,
METEOR), position relative des paraphrases, pr&#233;sence de formes communes aux fronti&#232;res des
paraphrases, pr&#233;sence d&#8217;une autre paire de paraphrases de chaque syst&#232;me aux fronti&#232;res de la
paraphrase, pr&#233;sence d&#8217;une paraphrase &#224; un autre endroit dans l&#8217;autre phrase
Traits distributionnels &#8211; similarit&#233; (cosinus) des vecteurs de formes du contexte pour chaque
segment d&#8217;une paraphrase (d&#233;riv&#233;e de fr&#233;quences obtenues dans le grand corpus parall&#232;le anglais-
fran&#231;ais fourni pour la campagne d&#8217;&#233;valuation WMT&#8217;11 (http://www.statmt.org/wmt11/
translation-task.html, soit environ 30 millions de phrases parall&#232;les)
Traits d&#233;riv&#233;s des syst&#232;mes &#8211; combinaison des syst&#232;mes individuels qui proposent la paire de
paraphrase
</p>
<p>TABLE 2 &#8211; Principaux traits utilis&#233;s par nos classifieurs. Des intervalles discr&#233;tis&#233;s bas&#233;s sur les
valeurs m&#233;dianes sont utilis&#233;s pour les valeurs r&#233;elles, et des valeurs binaris&#233;es sont utilis&#233;es
pour indiquer les configurations pr&#233;sentes pour les combinaisons.
</p>
<p>Syst&#232;mes individuels Combinaison de syst&#232;mes
Corpus GIZA FASTR TER&#8594;F PIVOT union appr.=C appr.=tout
type (C) P R F1 P R F1 P R F1 P R F1 P R F1 P R F1 P R F1
</p>
<p>ANGLAIS
TEXTE 48,2 58,9 53,0 63,1 5,9 10,7 41,2 66,4 50,9 73,4 25,8 38,2 20,8 80,8 33,1 68,4 62,8 65,5 77,5 56,1 65,1
PAROLE 39,7 44,2 41,8 27,1 3,5 6,3 25,0 50,3 33,4 79,2 15,3 25,7 25,5 71,4 37,6 51,0 56,3 53,5 67,7 48,7 56,6
SC&#200;NE 44,8 57,7 50,5 47,4 5,2 9,5 40,1 67,9 50,4 84,6 14,6 25,0 36,2 83,4 50,5 44,9 66,8 53,7 33,2 59,7 42,7
&#201;V&#201;N. 19,0 33,9 24,3 62,9 3,1 6,0 28,8 68,7 40,6 97,4 11,2 20,1 20,8 75,5 32,7 35,0 67,1 46,0 56,4 56,1 56,2
</p>
<p>FRAN&#199;AIS
TEXTE 52,5 58,9 55,5 56,9 4,9 9,1 46,4 61,4 52,8 64,5 30,3 41,2 41,5 77,9 54,1 74,7 61,0 67,1 74,5 60,2 66,6
PAROLE 44,0 54,9 48,9 30,7 4,3 7,6 34,8 60,2 44,1 75,5 19,0 30,4 31,4 76,2 44,5 60,2 59,7 60,0 55,1 61,0 57,9
(SC&#200;NE) 14,4 43,6 21,7 53,0 4,0 7,4 13,8 75,3 23,4 94,6 5,21 9,8 12,7 86,4 22,2 19,9 59,8 29,8 12,5 69,4 21,1
&#201;V&#201;N. 28,7 44,2 34,8 34,4 2,3 4,3 29,9 58,9 39,7 79,5 15,0 25,2 25,2 72,5 37,4 40,0 56,3 46,8 62,4 40,7 49,3
</p>
<p>TABLE 3 &#8211; R&#233;sultats de l&#8217;&#233;valuation pour chaque syst&#232;me individuel (&#224; gauche) et les syst&#232;mes
combin&#233;s (&#224; droite) sur tous les types de corpus, pour l&#8217;anglais (en haut) et le fran&#231;ais (en bas).
Les valeurs en gras indiquent les meilleurs r&#233;sultats pour une m&#233;trique donn&#233;e pour chaque type
de corpus et chaque langue.
</p>
<p>r&#233;sultat d&#233;cevant dans la mesure o&#249; il s&#8217;agit du type pour lequel il existe le plus de donn&#233;es
pr&#234;tes &#224; &#234;tre utilis&#233;es : nous reviendrons sur ce point dans la section 5.2.
</p>
<p>En termes de performance en F-mesure par type de corpus, GIZA obtient de meilleurs r&#233;sultats sur
TEXTE et PAROLE, qui contiennent des phrases longues, avec d&#8217;&#233;ventuelles r&#233;p&#233;titions, alors que
TER&#8594;F a de meilleurs r&#233;sultats sur SC&#200;NE et &#201;V&#201;NEMENT, o&#249; les &#233;quivalences qui sont rares au
niveau corpus sont plus fr&#233;quentes. Pour des raisons de place, nous ne d&#233;taillerons pas plus dans
cet article les performances des syst&#232;mes individuels, pour nous concentrer sur nos combinaisons
de syst&#232;mes.
</p>
<p>Dans toutes les configurations, la combinaison de syst&#232;mes am&#233;liore de fa&#231;on importante la
F-mesure relativement au meilleur des syst&#232;mes individuels pour chaque type de corpus, ainsi
que relativement &#224; l&#8217;union des r&#233;sultats de l&#8217;ensemble des syst&#232;mes. Les am&#233;liorations sont
importantes sur TEXTE (respectivement +12,5 et +11,6 sur l&#8217;anglais et le fran&#231;ais) et sur PAROLE
(+11,7 et +11,1) et assez bonnes sur SC&#200;NE (+3,2 et +6,4) et sur &#201;V&#201;NEMENT (+5,4 et +7,1).
</p>
<p>275</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>+TEXTE +PAROLE +SC&#200;NE +&#201;V&#201;NEMENT +Tous
ANGLAIS
</p>
<p># ex+ 7 342 2 296 1 784 1 171 12 593
</p>
<p>TEXTE 65,5 66,2 65,1 66,2 65,1
</p>
<p>PAROLE 56,0 53,5 52,8 54,8 56,6
</p>
<p>SC&#200;NE 49,7 54,3 53,7 53,8 42,7
</p>
<p>&#201;V&#201;NEMENT 51,1 45,3 42,5 46,0 56,2
</p>
<p>FRAN&#199;AIS
</p>
<p># ex+ 12 961 3 340 966 2 160 19 427
</p>
<p>TEXTE 67,1 67,2 66,7 67,0 66,6
</p>
<p>PAROLE 57,6 60,0 56,4 59,6 57,9
</p>
<p>(SC&#200;NE) 23,7 22,0 29,8 23,9 21,1
</p>
<p>&#201;V&#201;NEMENT 45,2 45,6 44,3 46,8 49,3
</p>
<p>TABLE 4 &#8211; R&#233;sultats de l&#8217;&#233;valuation (scores F1) pour tous les types de corpus pour l&#8217;anglais (en
haut) et le fran&#231;ais (en bas) quand sont ajout&#233;es les donn&#233;es d&#8217;entra&#238;nement des autres types de
corpus (les valeurs sur fond gris&#233; de la diagonale correspondent aux cas o&#249; aucune donn&#233;e n&#8217;est
ajout&#233;e). Les rang&#233;es &#8220;#ex+&#8221; indiquent le nombre d&#8217;exemples positifs de paraphrases apport&#233;
par chaque type de corpus suppl&#233;mentaire sur le m&#234;me nombre de paires de phrases.
</p>
<p>Nous avons constat&#233; (voir la table 1) que TEXTE et PAROLE sont les deux types de corpus ayant
le plus grand nombre d&#8217;exemples de paraphrases s&#251;res pour les deux langues : les r&#233;sultats
montrent que notre classifieur a &#233;t&#233; capable de les utiliser efficacement.
</p>
<p>Les valeurs de rappel pour l&#8217;union sont assez grandes pour tous les types de corpus, allant de
71,4 (pour PAROLE en anglais) &#224; 83,4 (pour SC&#200;NE en anglais). Il y a, cependant, une nette baisse
entre les valeurs de rappel pour les unions et pour les r&#233;sultats de nos classifieurs, bien que ces
derni&#232;res soient toutes autour de 6/10, ce qui peut &#234;tre consid&#233;r&#233; comme une valeur acceptable
pour une t&#226;che de cette complexit&#233;. Une &#233;tude plus approfondie des faux n&#233;gatifs pourrait nous
aider &#224; d&#233;terminer de nouveaux traits pour reconna&#238;tre des paraphrases plus difficiles &#224; identifier.
Enfin, nous pouvons noter que la pr&#233;cision est en g&#233;n&#233;ral meilleure pour un des syst&#232;mes (PIVOT),
et atteint des valeurs int&#233;ressantes en particulier sur TEXTE, o&#249; nous disposons du plus grand
nombre d&#8217;exemples (F-mesure de respectivement 68,4 et 74,6 pour l&#8217;anglais et le fran&#231;ais).
</p>
<p>5.2 Exp&#233;riences sur l&#8217;apport des autres types de corpus
</p>
<p>Nous consid&#233;rons &#224; pr&#233;sent la possibilit&#233; d&#8217;am&#233;liorer la performance de notre syst&#232;me de
combinaison par l&#8217;utilisation de donn&#233;es d&#8217;apprentissage provenant d&#8217;autres types de corpus.
Pour cela, nous construisons des syst&#232;mes en utilisant tout d&#8217;abord les donn&#233;es additionnelles
provenant d&#8217;un autre type de corpus, puis de l&#8217;ensemble des types de corpus disponibles. Les
r&#233;sultats obtenus sont donn&#233;s dans la table 4 13.
</p>
<p>Nous observons qu&#8217;il existe deux cas de figure. Dans le premier, la performance en F-mesure est
am&#233;lior&#233;e pour l&#8217;anglais sur TEXTE (+0,7), PAROLE (+3,1) et SC&#200;NE (+0,6) en utilisant soit un seul
type de corpus suppl&#233;mentaire, soit l&#8217;ensemble des corpus disponibles, alors que pour le fran&#231;ais
</p>
<p>13. Nos r&#233;sultats sont toujours donn&#233;s en proc&#233;dant &#224; une validation crois&#233;e qui r&#233;alise une moyenne des r&#233;sultats
obtenus sur 10 ensembles de test pour chaque type de corpus test&#233;.
</p>
<p>276</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>aucun ajout de donn&#233;es d&#8217;apprentissage n&#8217;am&#233;liore la performance pour ces types de corpus.
Dans le second cas, &#201;V&#201;NEMENT est am&#233;lior&#233; &#224; la fois pour l&#8217;anglais (+10,2) et pour le fran&#231;ais
(+2,5) en utilisant toutes les donn&#233;es d&#8217;apprentissage suppl&#233;mentaires disponibles. Hormis la
condition o&#249; les donn&#233;es provenant de TEXTE sont ajout&#233;es pour l&#8217;anglais, tous les ajouts d&#8217;autres
types de corpus diminuent la performance quand ils sont ajout&#233;s individuellement : on observe
donc ici nettement une contribution collective attribuable &#224; l&#8217;ajout d&#8217;au moins deux sources. La
nature des exemples pertinents ainsi ajout&#233;s retiendra notre attention pour de futurs travaux :
la s&#233;lection plus fine d&#8217;exemples pourrait effectivement repousser davantage la performance
atteinte.
</p>
<p>On peut encore noter que TEXTE n&#8217;est pratiquement pas touch&#233; par l&#8217;ajout de donn&#233;es suppl&#233;-
mentaires, ce qui peut s&#8217;expliquer en partie par le fait que ce type de corpus contient &#224; lui seul la
moiti&#233; du nombre total d&#8217;exemples dans les deux langues. &#192; l&#8217;oppos&#233;, SC&#200;NE, qui a le plus petit
nombre d&#8217;exemples d&#8217;entra&#238;nement, voit sa performance baisser sensiblement, assez fortement
par exemple avec l&#8217;ajout des donn&#233;es provenant de TEXTE (respectivement -4,0 et -6,1 pour
l&#8217;anglais et le fran&#231;ais) et par tous les corpus ensemble (respectivement -11,0 et -8,7). Ceci
souligne &#224; nouveau la nature sp&#233;cifique de ce type de corpus : des descriptions ind&#233;pendantes de
la m&#234;me sc&#232;ne vid&#233;o peuvent &#234;tre verbalis&#233;es de fa&#231;ons tr&#232;s diverses, &#224; diff&#233;rents niveaux. Finale-
ment, il y a nettement plus d&#8217;exemples positifs en fran&#231;ais (19 427) qu&#8217;en anglais (12 593) : ceci
peut s&#8217;expliquer par le fait que les phrases en fran&#231;ais dans nos corpus contiennent plus de formes
(voir Table 1) et que les paraphrases en fran&#231;ais contiennent plus de variantes morphologiques
telles que diff&#233;rentes formes conjugu&#233;es des verbes.
</p>
<p>6 Discussion et perspectives
</p>
<p>Dans cet article, nous nous sommes int&#233;ress&#233;s au probl&#232;me de l&#8217;acquisition de paraphrases sur des
types de corpus et entre ces types de corpus, en d&#233;finissant les types de corpus &#224; partir de l&#8217;origine
du signal du contenu s&#233;mantique des paires de phrases utilis&#233;es : un texte dans diff&#233;rentes
langues (TEXTE), de la parole transcrite dans une autre langue (PAROLE), une sc&#232;ne visualis&#233;e
(SC&#200;NE), et une courte description (un titre d&#8217;article) d&#8217;un &#233;v&#233;nement donn&#233; (&#201;V&#201;NEMENT). Nous
avons d&#233;crit un grand corpus annot&#233;, contenant 2 500 paires de phrases pour l&#8217;anglais et pour le
fran&#231;ais, et nous avons r&#233;utilis&#233; les principes g&#233;n&#233;raux d&#8217;une m&#233;thodologie existante pour &#233;valuer
l&#8217;acquisition automatique de paraphrases (Callison-Burch et al., 2008). Nous avons &#233;valu&#233; un
syst&#232;me efficace de combinaison exploitant les hypoth&#232;ses de quatre syst&#232;mes, ainsi que l&#8217;impact
produit par l&#8217;utilisation des donn&#233;es d&#8217;entra&#238;nement des autres types de corpus.
</p>
<p>Notre r&#233;sultat le plus prometteur est certainement l&#8217;am&#233;lioration obtenue sur le type de corpus
&#201;V&#201;NEMENT en utilisant les donn&#233;es d&#8217;entra&#238;nement de tous les corpus disponibles. &#201;tant donn&#233;
que les autres types de corpus sont beaucoup plus rares par nature, il semble que la disponi-
bilit&#233; de tels corpus permet n&#233;anmoins d&#8217;apporter des connaissances utiles pour am&#233;liorer la
reconnaissance des paraphrases sur ce qui s&#8217;est av&#233;r&#233; &#234;tre le type de corpus le plus difficile dans
notre &#233;tude. Un r&#233;sultat de cette nature incite &#224; appliquer et am&#233;liorer nos techniques pour
l&#8217;acquisition de paraphrases &#224; l&#8217;&#233;chelle du Web (Pas&#231;a et Dienes, 2005; Bhagat et Ravichandran,
2008), o&#249; les paires de phrases en relation peuvent &#234;tre tr&#232;s nombreuses.
</p>
<p>Une piste int&#233;ressante porte sur l&#8217;am&#233;lioration des traits de d&#233;termination du statut de para-
phrases, en particulier si l&#8217;on travaille sur les r&#233;sultats d&#8217;un moteur de recherche sur le Web,
</p>
<p>277</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>incluant des mesures de similarit&#233;s entre paires de texte plus inform&#233;es, par exemple en ex-
ploitant les structures th&#233;matiques des documents (Barzilay et Elhadad, 2003), des mesures de
similarit&#233; lexicale en contexte (Dinu et Lapata, 2010; Erk et Pado, 2010), ou des r&#233;sultats de
syst&#232;mes d&#8217;implication textuelle (Kouylekov et Negri, 2010) 14
</p>
<p>Une analyse fine des diff&#233;rents types de paraphrases serait n&#233;cessaire pour servir de guide pour
des travaux futurs afin de repousser les limites des syst&#232;mes actuels : de premiers r&#233;sultats
d&#8217;une telle analyse quantitative, pour tous les types de corpus et les deux langues de notre
&#233;tude, sont donn&#233;s dans la Table 5. La principale observation est que la synonymie (comme dans
dans l&#8217;affirmative &#8596; le cas &#233;ch&#233;ant) est le ph&#233;nom&#232;ne le plus courant, qui de plus repr&#233;sente
le principal type d&#8217;hypoth&#232;ses correctes propos&#233;es par nos syst&#232;mes. En revanche, il n&#8217;est pas
surprenant de voir que nos syst&#232;mes ne sont pas comp&#233;tents pour reconna&#238;tre des paraphrases
dans la cat&#233;gorie &#8220;pragmatique&#8221;, ce qui requiert de nombreuses et co&#251;teuses informations sur le
monde et sur le contexte des paires de phrases. Enfin, il est int&#233;ressant de noter que le type de
corpus &#201;V&#201;NEMENT contient des paraphrases de r&#233;f&#233;rence de tous les types.
</p>
<p>synonymie typographie inclusion pragmatique syntaxe d&#233;rivation flexion
%r&#233;f %sys %r&#233;f %sys %r&#233;f %sys %r&#233;f %sys %r&#233;f %sys %r&#233;f %sys %r&#233;f %sys
</p>
<p>ANGLAIS
</p>
<p>TEXTE 51,2 43,5 7,6 7,0 12,1 16,4 0,6 0,0 4,4 4,7 12,1 10,5 11,5 17,6
PAROLE 39,8 34,0 25,6 38,2 12,3 6,3 1,7 0,0 3,5 0,0 3,5 2,1 13,2 19
SC&#200;NE 50,0 46,8 1,3 2,1 21,6 23,4 0,0 0,0 1,3 0,0 5,4 8,5 20,2 19,1
</p>
<p>&#201;V&#201;NEMENT 36,9 41,6 15,0 22,2 19,1 16,6 1,3 0,0 6,8 2,7 6,8 2,7 13,6 13,8
FRAN&#199;AIS
</p>
<p>TEXTE 46,9 26,0 9,0 20,6 2,1 1,0 3,6 1,0 6,6 0,0 3,0 3,2 28,5 47,7
PAROLE 45,5 43,9 14,2 19,5 8,0 7,3 2,6 0,0 11,6 2,4 3,5 2,4 14,2 24,3
(SC&#200;NE) 46,4 51,3 5,3 2,7 8,9 5,4 0,0 0,0 5,3 0,0 0,0 0,0 33,8 40,5
</p>
<p>&#201;V&#201;NEMENT 28,3 16,6 19,7 27,7 16,0 11,1 7,4 0,0 8,6 5,5 7,4 0,0 12,2 38,8
</p>
<p>TABLE 5 &#8211; Distribution des types de paraphrases mesur&#233;e dans 50 paires de phrases annot&#233;es
(%r&#233;f) choisies al&#233;atoirement et des hypoth&#232;ses de paraphrases sur ces phrases pour notre
meilleur syst&#232;me (%sys) pour l&#8217;anglais (en haut) et le fran&#231;ais (en bas). &#192; noter que %sys doit
&#234;tre examin&#233; en relation avec le rappel du syst&#232;me donn&#233; dans la table 3. Les types sont illustr&#233;es
par les exemples suivants : (dans l&#8217;affirmative &#8596; le cas &#233;ch&#233;ant) (synonymie), (Classement &#8596;
Class.) (typographie)&#8222; (BNP &#8596; BNP Paribas) (inclusion), (de plus en plus sales &#8596; ne se brossent
plus les dents) (pragmatique), (il y a 6 mois &#8596; six mois avant) (syntaxe), (refroidie &#8596; froide)
(d&#233;rivation), (crevette &#8596; crevettes, moque &#8596; moquait) (flexion)
</p>
<p>R&#233;f&#233;rences
</p>
<p>BANNARD, C. et CALLISON-BURCH, C. (2005). Paraphrasing with bilingual parallel corpora. In
Actes de ACL, Ann Arbor, USA.
</p>
<p>BARZILAY, R. et ELHADAD, N. (2003). Sentence alignment for monolingual comparable corpora.
In Proceedings of EMNLP, Sapporo, Japan.
</p>
<p>14. Concernant les syst&#232;mes d&#8217;implication textuelle, nous nous trouvons face &#224; un probl&#232;me de d&#233;pendance circulaire,
car ces syst&#232;mes se fondent typiquement sur des connaissances pr&#233;alables, notamment des paraphrases. Nous pensons
quand m&#234;me que l&#8217;utilisation de telles connaissances doit &#234;tre faite quand celles-ci sont disponibles, comme nous l&#8217;avons
fait nous-m&#234;mes par l&#8217;utilisation du syst&#232;me FASTR et de ses ressources lexico-s&#233;mantiques associ&#233;es.
</p>
<p>278</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BARZILAY, R. et MCKEOWN, K. (2001). Extracting paraphrases from a parallel corpus. In Actes de
ACL, Toulouse, France.
</p>
<p>BERNHARD, D. et GUREVYCH, I. (2008). Answering Learners&#8217; Questions by Retrieving Question
Paraphrases from Social Q&amp;A Sites. In Proceedings of the 3rd Workshop on Innovative Use of NLP
for Building Educational Applications, Columbus, USA.
</p>
<p>BHAGAT, R. et RAVICHANDRAN, D. (2008). Large scale acquisition of paraphrases for learning
surface patterns. In Actes de ACL-HLT, Columbus, USA.
</p>
<p>BOUAMOR, H., MAX, A. et VILNAT, A. (2011). Combinaison d&#8217;informations pour l&#8217;alignement
monolingue. In Actes de TALN, Montpellier, France.
</p>
<p>CALLISON-BURCH, C., COHN, T. et LAPATA, M. (2008). Parametric : An automatic evaluation metric
for paraphrasing. In Actes de COLING, Manchester, UK.
</p>
<p>CHAN, T. P., CALLISON-BURCH, C. et VAN DURME, B. (2011). Reranking bilingually extracted
paraphrases using monolingual distributional similarity. In Proceedings of the EMNLP Workshop
on Geometrical Models of Natural language Semantics, Edinburgh, UK.
</p>
<p>CHEN, D. et DOLAN, W. (2011). Collecting highly parallel data for paraphrase evaluation. In
Proceedings of ACL-HLT, Portland, Oregon, USA.
</p>
<p>COHN, T., CALLISON-BURCH, C. et LAPATA, M. (2008). Constructing corpora for the development
and evaluation of paraphrase systems. Comput. Linguist., 34(4).
</p>
<p>DINU, G. et LAPATA, M. (2010). Measuring distributional similarity in context. In Proceedings of
EMNLP, Cambridge, USA.
</p>
<p>DOLAN, B., QUIRK, C. et BROCKETT, C. (2004). Unsupervised construction of large paraphrase
corpora : Exploiting massively parallel news sources. In Proceedings of Coling, Switzerland.
</p>
<p>ERK, K. et PADO, S. (2010). Exemplar-based models for word meaning in context. In Proceedings
of ACL, Uppsala, Sweden.
</p>
<p>FARUQUI, M. et PAD&#211;, S. (2011). Acquiring entailment pairs across languages and domains : A
data analysis. In Proceedings of IWCS, Oxford, UK.
</p>
<p>FUNG, P. et CHEUNG, P. (2004). Multi-level bootstrapping for extracting parallel sentences from a
quasi-comparable corpus. In Proceedings of COLING, Geneva, Switzerland.
</p>
<p>GERMANN, U. (2008). Yawat :Yet Another Word Alignment Tool. In Proceedings of the ACL-HLT,
Columbus, Ohio.
</p>
<p>JACQUEMIN, C. (1999). Syntagmatic and paradigmatic representations of term variation. In
Actes de ACL, College Park, USA.
</p>
<p>KOEHN, P., HOANG, H., BIRCH, A., CALLISON-BURCH, C., FEDERICO, M., BERTOLDI, N., COWAN, B.,
SHEN, W., MORAN, C., ZENS, R., DYER, C., BOJAR, O., CONSTANTIN, A. et HERBST, E. (2007). Moses :
Open source toolkit for statistical machine translation. In Proceedings of ACL, Czech Republic.
</p>
<p>KOEHN, P., OCH, F. J. et MARCU, D. (2003). Statistical Phrase-Based Translation. In Proceedings of
NAACL HLT, Edmonton, Canada.
</p>
<p>KOK, S. et BROCKETT, C. (2010). Hitting the Right Paraphrases in Good Time. In Proceedings of
NAACL, Los Angeles, USA.
</p>
<p>KOUYLEKOV, M. et NEGRI, M. (2010). An open-source package for recognizing textual entailment.
In Proceedings of the ACL, Uppsala, Sweden.
</p>
<p>279</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LAVIE, A. et AGARWAL, A. (2007). METEOR : An automatic metric for MT evaluation with high
levels of correlation with human judgments. In Proceedings of the ACL Workshop on Statistical
Machine Translation, Prague, Czech Republic.
</p>
<p>LIU, C., DAHLMEIER, D. et NG, H. T. (2010). PEM : A paraphrase evaluation metric exploiting
parallel texts. In Proceedings of EMNLP, Cambridge, MA.
</p>
<p>MADNANI, N. et DORR, B. J. (2010). Generating Phrasal and Sentential Paraphrases : A Survey
of Data-Driven Methods . Computational Linguistics, 36(3).
</p>
<p>MADNANI, N., RESNIK, P., DORR, B. et SCHWARTZ, R. (2008). Are multiple reference transla-
tions necessary ? investigating the value of paraphrased reference translations in parameter
optimization. In Proceedings of AMTA, Waikiki, Hawaii.
</p>
<p>MARTON, Y., CALLISON-BURCH, C. et RESNIK, P. (2009). Improved Statistical Machine Translation
Using Monolingually-derived Paraphrases. In Proceedings of EMNLP, Singapore.
</p>
<p>MAX, A. (2010). Example-based paraphrasing for improved phrase-based statistical machine
translation. In Proceedings of EMNLP, Cambridge, MA.
</p>
<p>METZLER, D., HOVY, E. et ZHANG, C. (2011). An empirical evaluation of data-driven paraphrase
generation techniques. In Proceedings of ACL-HLT, Portland, USA.
</p>
<p>MIHALCEA, R., CORLEY, C. et STRAPPARAVA, C. (2006). Corpus-based and knowledge-based
measures of text semantic similarity. In Proceedings of AAAI, Boston, USA.
</p>
<p>NELKEN, R. et SHIEBER, S. M. (2006). Towards robust context-sensitive sentence alignment for
monolingual corpora. In Proceedings of EACL, Trento, Italy.
</p>
<p>OCH, F. J. et NEY, H. (2004). The alignment template approach to statistical machine translation.
Computational Linguistics, 30(4).
</p>
<p>PANG, B., KNIGHT, K. et MARCU, D. (2003). Syntax-based alignement of multiple translations :
Extracting paraphrases and generating new sentences. In Actes de NAACL-HLT, Canada.
</p>
<p>PAPINENI, K., ROUKOS, S., WARD, T. et ZHU, W.-J. (2002). Bleu : a method for automatic evaluation
of machine translation. In Proceedings of ACL, Philadelphia, USA.
</p>
<p>PAS&#199;A, M. et DIENES, P. (2005). Aligning Needles in a Haystack : Paraphrase Acquisition Across
the Web. In Proceedings of IJCNLP, Jeju Island, South Korea.
</p>
<p>RESNIK, P., BUZEK, O., HU, C., KRONROD, Y., QUINN, A. et BEDERSON, B. B. (2010). Improving
translation via targeted paraphrasing. In Proceedings of EMNLP, Cambridge, MA.
</p>
<p>SCHROEDER, J., COHN, T. et KOEHN, P. (2009). Word Lattices for Multi-Source Translation. In
Proceedings of EACL, Athens, Greece.
</p>
<p>SNOVER, M., DORR, B. J., SCHWARTZ, R., MICCIULLA, L. et MAKHOUL, J. (2006). A Study of
Translation Edit Rate with Targeted Human Annotation. In Proceedings of AMTA, Boston, USA.
</p>
<p>SNOVER, M., MADNANI, N., DORR, B. J. et SCHWARTZ, R. (2010). TER-Plus : paraphrase, semantic,
and alignment enhancements to Translation Edit Rate. Machine Translation, 23(2-3).
</p>
<p>TIEDEMANN, J. (2007). Building a multilingual parallel subtitle corpus. In CLIN17, Belgium.
</p>
<p>WUBBEN, S., van den BOSCH, A., KRAHMER, E. et MARSI, E. (2009). Clustering and matching
headlines for automatic paraphrase acquisition. In EWNLG, Athens, Greece.
</p>
<p>ZHAO, S., LAN, X., LIU, T. et LI, S. (2009). Application-driven Statistical Paraphrase Generation.
In Proceedings of ACL-AFNLP, Suntec, Singapore.
</p>
<p>280</p>

</div></div>
</body></html>