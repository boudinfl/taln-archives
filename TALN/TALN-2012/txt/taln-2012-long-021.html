<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>D&#233;tection et correction automatique d'erreurs d'annotation morpho-syntaxique du French TreeBank</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 281&#8211;291,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>D&#233;tection et correction automatique d&#8217;erreurs
d&#8217;annotation morpho-syntaxique du French TreeBank
</p>
<p>Florian Boudin Nicolas Hernandez
Universit&#233; de Nantes
</p>
<p>pr&#233;nom.nom@univ-nantes.fr
</p>
<p>R&#201;SUM&#201;
La qualit&#233; de l&#8217;annotation morpho-syntaxique d&#8217;un corpus est d&#233;terminante pour l&#8217;entra&#238;nement
et l&#8217;&#233;valuation de m&#233;thodes d&#8217;&#233;tiquetage. Cet article pr&#233;sente une s&#233;rie d&#8217;exp&#233;riences que nous
avons men&#233;e sur la d&#233;tection et la correction automatique des erreurs du French Treebank.
Deux m&#233;thodes sont utilis&#233;es. La premi&#232;re consiste &#224; identifier les mots sans &#233;tiquette et leur
attribuer celle d&#8217;une forme correspondante observ&#233;e dans le corpus. La seconde m&#233;thode utilise
les variations de n-gramme pour d&#233;tecter et corriger les anomalies d&#8217;annotation. L&#8217;&#233;valuation des
corrections apport&#233;es au corpus est r&#233;alis&#233;e de mani&#232;re extrins&#232;que en comparant les scores de
performance de diff&#233;rentes m&#233;thodes d&#8217;&#233;tiquetage morpho-syntaxique en fonction du niveau de
correction. Les r&#233;sultats montrent une am&#233;lioration significative de la pr&#233;cision et indiquent
que la qualit&#233; du corpus peut &#234;tre sensiblement am&#233;lior&#233;e par l&#8217;application de m&#233;thodes de
correction automatique des erreurs d&#8217;annotation.
</p>
<p>ABSTRACT
Detecting and correcting POS annotation in the French TreeBank
</p>
<p>The quality of the Part-Of-Speech (POS) annotation in a corpus has a large impact on training
and evaluating POS taggers. In this paper, we present a series of experiments that we have
conducted on automatically detecting and correcting annotation errors in the French TreeBank.
Two methods are used. The first simply relies on identifying tokens with missing tags and correct
them by assigning the tag the same token observed in the corpus. The second method uses
n-gram variations to detect and correct conflicting annotations. The evaluation of the automatic
correction is performed extrinsically by comparing the performance of different POS taggers
in relation to the level of correction. Results show a statistically significant improvement in
precision and indicate that the POS annotation quality can be noticeably enhanced by using
automatic correction methods.
</p>
<p>MOTS-CL&#201;S : &#201;tiquetage morpho-syntaxique, correction automatique, qualit&#233; d&#8217;annotation.
</p>
<p>KEYWORDS: Part-Of-Speech tagging, automatic correction, annotation quality.
</p>
<p>1 Introduction
</p>
<p>Le corpus arbor&#233; de Paris 7, &#233;galement appel&#233; French Treebank (FTB), est la plus grande ressource
disponible de textes annot&#233;s syntaxiquement et morpho-syntaxiquement pour le fran&#231;ais (Abeill&#233;
</p>
<p>281</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>et al., 2003). Il est le r&#233;sultat d&#8217;un projet d&#8217;annotation supervis&#233;e d&#8217;articles du journal Le
Monde men&#233; depuis plus d&#8217;une dizaine d&#8217;ann&#233;es. La quasi-totalit&#233; des m&#233;thodes d&#8217;&#233;tiquetage
morpho-syntaxique du fran&#231;ais utilisent cet ensemble de donn&#233;es que ce soit pour leur phase
d&#8217;entra&#238;nement ou d&#8217;&#233;valuation, e.g. (Crabb&#233; et Candito, 2008; Denis et Sagot, 2010). La qualit&#233;
de l&#8217;annotation du corpus est donc d&#233;terminante.
</p>
<p>De la m&#234;me mani&#232;re que la plupart des corpus annot&#233;s morpho-syntaxiquement, e.g. le Penn
TreeBank (Marcus et al., 1993) pour l&#8217;anglais, le FTB a &#233;t&#233; construit de mani&#232;re semi-automatique.
Un &#233;tiqueteur automatique est d&#8217;abord appliqu&#233; sur l&#8217;ensemble des textes. Les sorties sont ensuite
corrig&#233;es manuellement des &#233;ventuelles erreurs commises par l&#8217;outil. Malgr&#233; cette derni&#232;re &#233;tape,
il est presque certain que des erreurs existantes ne sont pas corrig&#233;es et que de nouvelles erreurs
sont introduites (les humains n&#8217;&#233;tant pas infaillibles). Plusieurs &#233;tudes illustrent d&#8217;ailleurs cette
probl&#233;matique en d&#233;crivant quelques unes des erreurs d&#8217;annotation r&#233;currentes du FTB telles que
l&#8217;absence d&#8217;&#233;tiquette ou la pr&#233;sence d&#8217;&#233;l&#233;ments XML vides 1 (Arun et Keller, 2005; Green et al.,
2011).
</p>
<p>Dans cette &#233;tude, nous pr&#233;sentons une s&#233;rie d&#8217;exp&#233;riences que nous avons men&#233;e sur la correction
automatique du FTB. Nous d&#233;taillons les diff&#233;rentes erreurs que nous avons rencontr&#233;es ainsi
que les solutions que nous appliquons. Deux m&#233;thodes sont utilis&#233;es. La premi&#232;re consiste &#224;
identifier les mots sans &#233;tiquette et leur attribuer celle d&#8217;une forme correspondante observ&#233;e
dans le corpus. La seconde m&#233;thode utilise les variations de n-gramme pour d&#233;tecter et corriger
les anomalies d&#8217;annotation. L&#8217;&#233;valuation de la correction du corpus est r&#233;alis&#233;e de mani&#232;re
extrins&#232;que en &#233;tudiant l&#8217;impact du niveau de correction sur les performances de plusieurs
m&#233;thodes d&#8217;&#233;tiquetage morpho-syntaxique.
</p>
<p>Le reste de cet article est organis&#233; comme suit. La section 2 pr&#233;sente le corpus French Treebank
que nous utilisons dans cette &#233;tude. La section 3 est consacr&#233;e &#224; la description de la m&#233;thode
que nous proposons. Nous d&#233;crivons ensuite en section 4 nos r&#233;sultats exp&#233;rimentaux avant de
pr&#233;senter les travaux connexes aux n&#244;tres. La section 6 conclut cette &#233;tude et donne quelques
perspectives de travaux futurs.
</p>
<p>2 Description du corpus French Treebank
</p>
<p>Notre int&#233;r&#234;t pour le FTB est motiv&#233; par deux objectifs : d&#8217;une part r&#233;aliser des traitements
automatiques sur le corpus, et d&#8217;autre part, construire des mod&#233;lisations permettant de pr&#233;dire
l&#8217;&#233;tiquette grammaticale d&#8217;un mot &#224; l&#8217;aide d&#8217;approches statistiques ; ce deuxi&#232;me objectif est un
cas particulier du premier. Nos observations concernent donc &#224; la fois la structure du corpus qui
porte les annotations et la qualit&#233; de ses annotations grammaticales.
</p>
<p>Le corpus est toujours en d&#233;veloppement. La version que nous utilisons dans cette &#233;tude est dat&#233;e
de juillet 2010, elle est compos&#233;e de 21 562 phrases pour 628 767 mots (tokens). Les fichiers qui
composent le corpus sont au format XML (voir la Figure 1). Les mots sont r&#233;partis en 13 cat&#233;gories
principales (attribut cat), elles m&#234;mes r&#233;parties en 34 sous-cat&#233;gories (attribut subcat). De
plus, les traits flexionnels (attribut mph), les lemmes (attribut lemma) et les mots compos&#233;s
</p>
<p>1. Certaines des erreurs recenc&#233;es ne sont que des choix de repr&#233;sentation qui ne sont pas forc&#233;ment des choix
les plus adapt&#233;s dans une perspective de traitement automatique du corpus. C.f. http://www.llf.cnrs.fr/Gens/
Abeille/guide-morpho-synt.02.pdf pour la repr&#233;sentation de &#171; du&#187; en deux balises tokens &#171; de&#187; et &#171; le&#187;, la
seconde ayant un contenu textuel vide.
</p>
<p>282</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>(e.g. &#171; aujourd&#8217;hui &#187;, &#171; mettre en garde &#187;) sont explicit&#233;s. Ces derniers sont tr&#232;s nombreux dans le
corpus : &#8776;14% des occurrences de tokens entrent dans un mot compos&#233;. On peut noter que la
structure originale de la phrase (avec les caract&#232;res espaces) ainsi que l&#8217;identifiant du document
source ne figurent pas dans le corpus.
</p>
<p>&lt;SENT nb=&quot;226&quot;&gt;
&lt;NP&gt;
&lt;w cat=&quot;D&quot; [...] lemma=&quot;son&quot; mph=&quot;1fss&quot; subcat=&quot;poss&quot;&gt;Ma&lt;/w&gt;
&lt;w cat=&quot;N&quot; [...] lemma=&quot;position&quot; mph=&quot;fs&quot; subcat=&quot;C&quot;&gt;position &lt;/w&gt;
</p>
<p>&lt;/NP&gt;
&lt;VN&gt;
&lt;w cat=&quot;V&quot; [...] lemma=&quot;&#234;tre&quot; mph=&quot;P3s&quot; subcat=&quot;&quot;&gt;est&lt;/w&gt;
</p>
<p>&lt;/VN&gt;
&lt;NP&gt;
&lt;w cat=&quot;D&quot; [...] lemma=&quot;le&quot; mph=&quot;fs&quot; subcat=&quot;def&quot;&gt;la&lt;/w&gt;
&lt;w cat=&quot;N&quot; [...] lemma=&quot;suivant&quot; mph=&quot;fs&quot; subcat=&quot;C&quot;&gt;suivante &lt;/w&gt;
</p>
<p>&lt;/NP&gt;
&lt;w cat=&quot;PONCT&quot; [...] lemma=&quot;.&quot; subcat=&quot;S&quot;&gt;.&lt;/w&gt;
</p>
<p>&lt;/SENT&gt;
</p>
<p>FIGURE 1 &#8211; Exemple de phrase annot&#233;e extraite du fichier lmf300_13000ep.cat.xml, certains
attributs ont &#233;t&#233; supprim&#233;es pour faciliter la lecture ([...]).
</p>
<p>L&#8217;encodage natif du corpus est iso-8859-1. Le premier traitement que nous avons op&#233;r&#233; est sa
conversion en utf-8 via l&#8217;outil GNU iconv. L&#8217;encodage utf-8 est utilis&#233; par d&#233;faut par l&#8217;ensemble des
outils et des applications que nous utilisons. Seul le fichier lmf7ad1co.aa.xml fut r&#233;calcitrant
et nous avons &#233;t&#233; amen&#233; &#224; corriger les caract&#232;res accentu&#233;s &#224; l&#8217;aide de quelques r&#232;gles de
conversion ad hoc. Le FTB n&#233;cessite ensuite de nombreux pr&#233;-traitements avant de pouvoir &#234;tre
utilis&#233; pour l&#8217;entra&#238;nement et l&#8217;&#233;valuation d&#8217;&#233;tiqueteurs morpho-syntaxiques. Le format XML
d&#8217;origine doit tout d&#8217;abord &#234;tre converti au format d&#8217;entr&#233;e standard 2. Cette premi&#232;re conversion
du corpus nous a permis d&#8217;identifier et de corriger quelques probl&#232;mes li&#233;s &#224; sa structure : absence
d&#8217;attribut, &#233;tiquette de cat&#233;gorie morpho-syntaxique non valide, etc.
</p>
<p>2.1 Choix du jeu d&#8217;&#233;tiquettes et du d&#233;coupage en unit&#233;s lexicales
</p>
<p>Plusieurs possibilit&#233;s s&#8217;offrent &#224; nous quant au choix du jeu d&#8217;&#233;tiquettes morpho-syntaxiques.
(Crabb&#233; et Candito, 2008) ont propos&#233; un jeu d&#8217;&#233;tiquettes optimis&#233; en 29 cat&#233;gories (utilisant
l&#8217;information suppl&#233;mentaire du mode des verbes et de certaines sous-cat&#233;gories). Les r&#233;sultats
obtenus avec leur m&#233;thode indiquent une am&#233;lioration de la pr&#233;cision par rapport &#224; l&#8217;utilisation
du jeu de 13 &#233;tiquettes du FTB. Cependant, les tokens pr&#233;sents dans les mots compos&#233;s ne
contiennent que l&#8217;information de la cat&#233;gorie principale (attribut catint). Il n&#8217;est donc pas
toujours possible de leur attribuer une &#233;tiquette optimis&#233;e automatiquement. La solution retenue
par (Arun et Keller, 2005) et les travaux suivants consiste &#224; fusionner les tokens et de leur affecter
l&#8217;&#233;tiquette du mot compos&#233;. Par exemple, les tokens du mot compos&#233; illustr&#233; dans la Figure 2
seront fusionn&#233;s en &#171; lev&#233;e_de_boucliers &#187; avec l&#8217;&#233;tiquette NC (cat=&quot;N&quot;+subcat=&quot;C&quot;).
Cette m&#233;thodologie simplifie artificiellement la t&#226;che d&#8217;&#233;tiquetage mais facilite la comparaison
avec les approches pr&#233;c&#233;dentes.
</p>
<p>2. Une phrase par ligne dans laquelle chaque mot est suivi d&#8217;un s&#233;parateur et de son &#233;tiquette. Par exemple, la phrase
de la Figure 1 doit &#234;tre converti en : Ma/D position/N est/V la/D suivante/N ./PONCT
</p>
<p>283</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&lt;w cat=&quot;N&quot; [...] lemma=&quot;lev&#233;e de boucliers&quot; mph=&quot;fs&quot; subcat=&quot;C&quot;&gt;
&lt;w catint=&quot;N&quot;&gt;lev&#233;e&lt;/w&gt;
&lt;w catint=&quot;P&quot;&gt;de&lt;/w&gt;
&lt;w catint=&quot;N&quot;&gt;boucliers &lt;/w&gt;
</p>
<p>&lt;/w&gt;
</p>
<p>FIGURE 2 &#8211; Exemple de mot compos&#233; extrait du fichier lmf300_13000ep.cat.xml.
</p>
<p>N&#233;anmoins, entra&#238;ner des m&#233;thodes d&#8217;&#233;tiquetage avec un ensemble de donn&#233;es dans lequel
les mots compos&#233;s sont fusionn&#233;s suppose par la suite l&#8217;utilisation d&#8217;un tokenizer capable de
d&#233;tecter les mots compos&#233;s. Or, les m&#233;thodes existantes ne sont pas encore arriv&#233;es &#224; un niveau
de maturit&#233; satisfaisant. De plus, la notion de mot compos&#233; reste encore ambigu&#235; et sp&#233;cifique
aux choix faits par les annotateurs du FTB. En effet, la d&#233;finition du mot compos&#233; dans le FTB est
assez large, avec par exemple &#171; &#224; tout prix &#187; ou &#171; seconde guerre mondiale &#187;. Nous avons fait ici
un choix restrictif en ne fusionnant que les mots compos&#233;s lexicaux dont le lemme ne contient
pas le caract&#232;re espace (e.g. &#171; aujourd&#8217; &#187; + &#171; hui &#187;&#8594; &#171; aujourd&#8217;hui &#187;, &#171; celles &#187; + &#171; - &#187; + &#171; ci &#187;&#8594;
&#171; celles-ci &#187;) ainsi que les nombres d&#233;cimaux (e.g. &#171; 16 &#187; + &#171; , &#187; + &#171; 7 &#187;&#8594; &#171; 16,7 &#187;) et d&#233;coup&#233;s
(e.g. &#171; 500 &#187; + &#171; 000 &#187;&#8594; &#171; 500000 &#187;). Un total de 8 967 mots-compos&#233;s sont fusionn&#233;s de cette
mani&#232;re.
</p>
<p>Pour l&#8217;ensemble des raisons que nous avons &#233;voqu&#233;es pr&#233;c&#233;demment, nous utilisons dans cette
&#233;tude le jeu de 13 &#233;tiquettes d&#233;riv&#233;es des cat&#233;gories principales du FTB. Ce choix est &#233;galement
appuy&#233; par le fait que nous souhaitons proposer un ensemble de r&#232;gles de corrections automa-
tiques ne n&#233;cessitant pas de ressources externes ou d&#8217;intervention manuelle. Le corpus g&#233;n&#233;r&#233; &#224;
partir de cette conversion directe du FTB contient 7 747 tokens pour lesquels aucune &#233;tiquette n&#8217;a
pu &#234;tre affect&#233;e, i.e. soit l&#8217;&#233;tiquette est manquante, soit l&#8217;&#233;tiquette pr&#233;sente n&#8217;est pas valide. Au
total, le corpus g&#233;n&#233;r&#233; contient 2 090 phrases dans lesquelles au moins un token sans &#233;tiquette
est pr&#233;sent.
</p>
<p>D&#8217;un point de vue pratique, la plupart des syst&#232;mes d&#8217;&#233;tiquetage n&#233;cessitent des donn&#233;es d&#8217;en-
tra&#238;nement compl&#232;tement &#233;tiquet&#233;es (i.e. sans &#233;tiquette manquante). Nous attribuons donc
l&#8217;&#233;tiquette U (pour Unknown) aux tokens pour lesquels aucune &#233;tiquette n&#8217;a pu &#234;tre affect&#233;e.
</p>
<p>3 Correction automatique des erreurs d&#8217;annotation
</p>
<p>La m&#233;thodologie de correction automatique des erreurs d&#8217;annotation peut &#234;tre d&#233;compos&#233;e
en deux &#233;tapes : i. identifier les occurrences des mots incorrectement &#233;tiquet&#233;s (ou ayant
une &#233;tiquette manquante) dans le corpus ; ii. assigner les bonnes &#233;tiquettes correspondant &#224;
ces occurrences. Concernant la seconde &#233;tape, nous avons avant tout cherch&#233; &#224; privil&#233;gier la
pr&#233;cision des corrections. Ainsi, notre choix s&#8217;est port&#233; sur des m&#233;thodes cherchant &#224; assigner
une &#233;tiquette corrective avec la plus grande confiance possible au d&#233;triment du nombre d&#8217;erreurs
candidates corrig&#233;es.
</p>
<p>Nous proposons deux m&#233;thodes pour corriger les erreurs : la premi&#232;re vise la correction des
&#233;tiquettes manquantes de certains mots &#224; l&#8217;aide de la fr&#233;quence d&#8217;occurrence des &#233;tiquettes
associ&#233;es &#224; d&#8217;autres occurrences du mot (Section 3.1), que nous d&#233;signerons par FTB+corr. 1. La
seconde vise la correction des erreurs d&#8217;annotation par la d&#233;tection des variations d&#8217;&#233;tiquetage
pour des n-grammes de mots (Section 3.2), que nous d&#233;signerons par FTB+corr. 2.
</p>
<p>284</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3.1 Correction des &#233;tiquettes manquantes
</p>
<p>Une solution simple au probl&#232;me des &#233;tiquettes manquantes consiste &#224; attribuer l&#8217;&#233;tiquette de la
forme correspondante dans le corpus. Dans le cas ou plusieurs &#233;tiquettes ont &#233;t&#233; attribu&#233;es &#224;
un m&#234;me token, la plus fr&#233;quente sera choisie. Cette strat&#233;gie peut s&#8217;av&#233;rer &#234;tre probl&#233;matique
dans le cas o&#249; les fr&#233;quences des diff&#233;rentes &#233;tiquettes d&#8217;un token sont &#233;gales ou tr&#232;s proches.
Par exemple, &#171; quelque &#187; appara&#238;t 47 fois en tant qu&#8217;adverbe, 46 fois en tant que d&#233;terminant et
34 fois en tant qu&#8217;adjectif. Le choix de l&#8217;&#233;tiquette serait dans ce cas ambigu. Pour minimiser le
risque d&#8217;introduire des erreurs d&#8217;annotations, nous n&#8217;attribuons l&#8217;&#233;tiquette la plus fr&#233;quente que
si sa fr&#233;quence dans le corpus est sup&#233;rieure &#224; la somme des fr&#233;quences des autres &#233;tiquettes
candidates. Seules les &#233;tiquettes avec une fr&#233;quence sup&#233;rieure &#224; 1 sont utilis&#233;es.
</p>
<p>Le nombre de tokens sans &#233;tiquette est ainsi ramen&#233; &#224; 901, tandis que le nombre de phrases
contenant au moins une &#233;tiquette manquante est r&#233;duit de 2 090 &#224; 582. Malgr&#233; les contraintes
que nous avons mises en place, il est probable que cette m&#233;thode de correction introduit des
&#233;tiquettes erron&#233;es. La seconde m&#233;thode que nous d&#233;crivons dans la section suivante permet de
d&#233;tecter et de corriger les &#233;ventuelles s&#233;quences d&#8217;&#233;tiquettes erron&#233;es.
</p>
<p>3.2 D&#233;tection et correction des variations d&#8217;annotation
</p>
<p>Afin de d&#233;tecter les erreurs d&#8217;annotation nous mettons en oeuvre l&#8217;approche propos&#233;e par
(Dickinson et Meurers, 2003) puis reprise par (Loftsson, 2009) pour &#233;valuer les corpus Wall
Street Journal (WSJ) et Icelandic Frequency Dictionary (IFD). L&#8217;approche repose sur la d&#233;tection de
variations d&#8217;&#233;tiquetage pour un m&#234;me n-gramme de mots. On utilisera le terme de variation de
n-gramme (variation n-gram) pour d&#233;signer un n-gramme de mots dans un corpus qui contient un
mot annot&#233; diff&#233;remment dans une autre occurrence du m&#234;me n-gramme dans le corpus. Le(s)
mot(s) sujet(s) &#224; la variation (qui ont une &#233;tiquette diff&#233;rente dans les diff&#233;rentes occurrences)
est(sont) appel&#233;(s) noyau de variation (variation nucleus).
</p>
<p>La pr&#233;sence au sein d&#8217;un corpus d&#8217;une variation d&#8217;annotations pour un m&#234;me n-gramme de mots
peut s&#8217;expliquer soit par l&#8217;ambigu&#239;t&#233; des mots noyaux de la variation (une m&#234;me forme peut
admettre des &#233;tiquettes distinctes dans un contexte d&#8217;occurrence diff&#233;rent) soit par une erreur.
L&#8217;hypoth&#232;se que l&#8217;on pose est : plus des contextes d&#8217;une variation sont similaires, plus grande est
la probabilit&#233; qu&#8217;il s&#8217;agisse d&#8217;une erreur. La notion de contexte se traduit ici par le nombre de
mots, n, que l&#8217;on consid&#232;re dans les n-grammes observ&#233;s. La table 1 rapporte une comparaison
en chiffres des observations men&#233;es sur les diff&#233;rents corpus trait&#233;s par cette m&#233;thode.
</p>
<p>Comme l&#8217;explique (Loftsson, 2009), une m&#234;me erreur candidate peut &#234;tre d&#233;tect&#233;e plusieurs
fois du fait du fait qu&#8217;un n-gramme de mots peut se retrouver contenu dans un autre pour une
valeur de n sup&#233;rieure. De plus, une variation de n-gramme contient &#224; minima deux annotations
possibles pour le m&#234;me n-gramme de mots. Il n&#8217;est ainsi pas facile de calculer la pr&#233;cision de
cette m&#233;thode (i.e. le ratio d&#8217;erreurs correctement d&#233;tect&#233;es sur toutes les erreurs candidates).
</p>
<p>(Dickinson et Meurers, 2003; Loftsson, 2009) avaient pour objectif d&#8217;&#233;valuer manuellement
le nombre de variations distinctes correctes. Pour cette raison, ils ont choisi un n minimal
suffisamment grand pour que le contexte soit discriminant. Ils ont par ailleurs consid&#233;r&#233; la plus
longue variation de n-grammes pour chaque occurrence de mot pr&#233;sentant une variation afin
d&#8217;avoir le plus de mat&#233;riel sous les yeux pour permettre la lev&#233;e de l&#8217;ambigu&#239;t&#233;. Notre objectif
</p>
<p>285</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Corpus WSJ IDP FTB+corr. 2 FTB+corr. 1&amp;2
</p>
<p># tokens 1,3 M 590 297 628 767
# &#233;tiquettes 36 700 13&#8727;&#8727;
+ longue variation 224 20 87
Valeur de n observ&#233; n&#8805; 6 n&#8805; 5 n&#8805; 5
Variations distinctes 2495 752 293 147
Vraies erreurs 2436 (97,6%) 254 &#8211; &#8211;
# tokens corrig&#233;s 4417 (0,34%) 236&#8727; (0,04%) 741 169
</p>
<p>TABLE 1 &#8211; Comparatifs des corpus en chiffres sur lesquels des variations de n-gramme ont &#233;t&#233;
calcul&#233;es. &#8727; Nous constatons que le nombre r&#233;el de tokens corrig&#233;s, calcul&#233; &#224; partir du pourcentage
fourni par (Loftsson, 2009), est inf&#233;rieur au nombre de variations &#233;tant de vraies erreurs ; nous
supposons que cela est peut &#234;tre d&#251; &#224; une erreur dans le recensement des variations distinctes
observ&#233;es. &#8727;&#8727; A ce nombre il faut rajouter une &#233;tiquette suppl&#233;mentaire que l&#8217;on utilise pour tous
les mots qui n&#8217;ont pas nativement une des 13 &#233;tiquettes retenues.
</p>
<p>diff&#232;re puisque nous souhaitons d&#233;tecter et corriger des erreurs automatiquement. Nous sommes
n&#233;anmoins sensibles au fait de poser un n suffisamment grand pour discriminer mais aussi
suffisamment petit pour que la diff&#233;rence du nombre d&#8217;occurrences entre les variations puisse
&#234;tre utilis&#233;e pour filtrer les variations les moins probables. Du fait que l&#8217;IDP et le FTB ont une taille
proche, nous suivons le choix de (Loftsson, 2009) et optons pour n&#8805; 5.
Nous proposons une heuristique pour corriger certaines variations. Celle-ci est la suivante : nous
consid&#233;rons les n-grammes par taille d&#233;croissante, puis par nombre d&#8217;occurrences d&#233;croissant.
Nous s&#233;lectionnons les candidats pour une correction selon deux contraintes : i. la pr&#233;sence
d&#8217;au moins deux unit&#233;s lexicales et ii. la pr&#233;sence d&#8217;une variation, sans &#233;tiquette manquante,
dont le nombre d&#8217;occurrence est strictement sup&#233;rieur &#224; la somme des occurrences des autres
variations. De fait seuls les n-grammes apparaissant au moins trois fois sont consid&#233;r&#233;s. Cette
derni&#232;re contrainte nous sert aussi de base pour proposer une correction. En effet, la variation
qui valide la contrainte est consid&#233;r&#233;e comme la s&#233;quence d&#8217;&#233;tiquettes correcte.
</p>
<p>Les exemples 1, 2 et 3 illustrent des corrections op&#233;r&#233;es avec cette heuristique. Les mots corrig&#233;s
sont soulign&#233;s.
</p>
<p>(1) ,/PONCT l&#8217;/D une/N des/P plus/ADV&#8594; ,/PONCT l&#8217;/D une/PRO des/P plus/ADV
(2) produit/N int&#233;rieur/N brut/A (/PONCT PIB/N )/PONCT &#8594; produit/N int&#233;rieur/A
brut/A (/PONCT PIB/N )/PONCT
</p>
<p>(3) d&#8217;/P &#233;tat/N charg&#233;/N de/P la/D&#8594; d&#8217;/P &#233;tat/N charg&#233;/V de/P la/D
Pour n &#8805; 5, lorsque l&#8217;on applique cette m&#233;thode directement sur le FTB, nous comptons 293
variations distinctes (v&#233;rifiant les contraintes cit&#233;es ci-dessus) et le nombre de tokens corrig&#233;
est 741 (dont 593 &#233;taient sans &#233;tiquette). Le nombre de tokens corrig&#233;s augmente lorsque l&#8217;on
diminue la taille minimale des n-grammes trait&#233;s. Nous avons n&#233;anmoins pr&#233;f&#233;r&#233; garder un n
suffisamment haut pour maintenir une certaine confiance dans le choix de consid&#233;rer certaines
des variations d&#233;tect&#233;es comme erreurs.
</p>
<p>Intrins&#232;quement la m&#233;thode par d&#233;tection de variations de n-gramme repose sur le nombre
d&#8217;occurrences des n-grammes. La m&#233;thode est donc sensible &#224; la taille du corpus et l&#8217;on peut
</p>
<p>286</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>s&#8217;attendre &#224; ce qu&#8217;elle fournisse de meilleurs r&#233;sultats sur des corpus homog&#232;nes (i.e. d&#8217;un genre
sp&#233;cifique) utilisant un jeu d&#8217;&#233;tiquette &#224; gros grain ; caract&#233;ristiques que nous retrouvons dans
le FTB.
</p>
<p>4 R&#233;sultats
</p>
<p>L&#8217;&#233;valuation des corrections apport&#233;es au corpus est r&#233;alis&#233;e de mani&#232;re extrins&#232;que. L&#8217;id&#233;e
derri&#232;re cette m&#233;thodologie est simple, il s&#8217;agit de comparer les scores de performance de
diff&#233;rentes m&#233;thodes d&#8217;&#233;tiquetage morpho-syntaxique en fonction du niveau de correction du
FTB. Une am&#233;lioration de la pr&#233;cision de l&#8217;&#233;tiquetage est une indication indirecte de la bonne
correction du corpus.
</p>
<p>Les m&#233;thodes d&#8217;&#233;tiquetage morpho-syntaxique fond&#233;es sur des mod&#232;les probabilistes discrimi-
nants atteignent des niveaux de performance tr&#232;s &#233;lev&#233;s. Dans cette &#233;tude, nous avons choisi
deux syst&#232;mes utilisant des mod&#232;les par maximum d&#8217;entropie (MaxEnt) : la version 3.0.4 du
Stanford POS Tagger (Toutanova et al., 2003) et l&#8217;&#233;tiqueteur morpho-syntaxique de la suite Apache
OpenNLP 3. Le Stanford POS Tagger a &#233;t&#233; entra&#238;n&#233; avec un ensemble standard 4 de traits bidirec-
tionnels sur les mots et les &#233;tiquettes. L&#8217;&#233;tiqueteur d&#8217;Apache OpenNLP a, quant &#224; lui, &#233;t&#233; entra&#238;n&#233;
avec l&#8217;impl&#233;mentation par d&#233;faut qui caract&#233;rise chaque mot &#224; l&#8217;aide de traits caract&#233;ristiques des
trois mots pr&#233;c&#233;dents et suivants. Ces traits sont les pr&#233;fixes et les suffixes de quatre caract&#232;res,
la classe rudimentaire d&#8217;information de ces caract&#232;res (e.g. d&#233;bute avec une majuscule, est un
nombre, est un symbole), l&#8217;&#233;tiquette grammaticale et la forme de surface des mots. On note
que les ensembles de traits que nous utilisons n&#8217;ont pas &#233;t&#233; optimis&#233;s pour le fran&#231;ais, cette
t&#226;che sortant du cadre de notre &#233;tude. Les r&#233;sultats que nous pr&#233;sentons ici ne correspondent
donc pas &#224; la performance maximale des syst&#232;mes. De plus, nous souhaitons pr&#233;ciser que nous
n&#8217;entendons pas comparer ici les deux syst&#232;mes. Il faudrait utiliser les m&#234;mes ensembles de traits
pour discuter a minima de leur impl&#233;mentation de l&#8217;algorithme MaxEnt. Les r&#233;sultats sont donc
donn&#233;s &#224; titre informatif principalement parce qu&#8217;ils sont tous deux utilis&#233;s dans la communaut&#233;.
</p>
<p>Les deux syst&#232;mes sont entra&#238;n&#233;es et &#233;valu&#233;es &#224; partir des diff&#233;rents niveaux de correction du
FTB. L&#8217;ensemble de donn&#233;es FTB+corr. 1 correspond &#224; la correction des &#233;tiquettes manquantes
par la fr&#233;quence (Section 3.1), FTB+corr. 2 correspond &#224; la correction des erreurs d&#8217;annotation
par la m&#233;thode des variations de n-grammes (Section 3.2). FTB+corr. 1&amp;2 et FTB+corr. 2&amp;1
correspondent &#224; l&#8217;utilisation successive des deux m&#233;thodes de correction : corr. 1 puis +corr. 2 et
inversement.
</p>
<p>Dans la litt&#233;rature, les m&#233;thodes d&#8217;&#233;tiquetage morpho-syntaxique pour le fran&#231;ais ont presque
toujours &#233;t&#233; &#233;valu&#233;es &#224; partir d&#8217;un d&#233;coupage du FTB en trois sous-ensembles : 80% pour
l&#8217;entra&#238;nement, 10% pour le d&#233;veloppement et 10% pour le test, e.g. (Denis et Sagot, 2010;
Constant et al., 2011). Intuitivement, une &#233;valuation fond&#233;e uniquement sur 10% des donn&#233;es
ne peut pas &#234;tre repr&#233;sentative du niveau de performance r&#233;el d&#8217;une m&#233;thode. Une premi&#232;re
s&#233;rie d&#8217;exp&#233;riences nous a confort&#233; dans cette id&#233;e puisque nous avons observ&#233; une variation
de plus de 2% (en absolu) de la pr&#233;cision en fonction du d&#233;coupage effectu&#233;. La construction
incr&#233;mentale du FTB ainsi que la nature des documents annot&#233;s joue un r&#244;le pr&#233;pond&#233;rant dans
ce ph&#233;nom&#232;ne. Pour palier ce probl&#232;me, les r&#233;sultats que nous pr&#233;sentons dans cette &#233;tude ont
</p>
<p>3. http://incubator.apache.org/opennlp/
4. Nous avons utilis&#233; la macro naacl2003unknowns d&#233;crite dans (Toutanova et al., 2003).
</p>
<p>287</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>tous &#233;t&#233; obtenus en validation crois&#233;e en 10 strates, ils ne sont donc pas directement comparables
&#224; ceux pr&#233;sent&#233;s dans les travaux pr&#233;c&#233;dents.
</p>
<p>Trois mesures d&#8217;&#233;valuation sont consid&#233;r&#233;es comme pertinentes pour nos exp&#233;riences : la pr&#233;cision
sur les tokens, la pr&#233;cision sur les phrases (nombre de phrases dans lesquelles tous les tokens ont
&#233;t&#233; correctement &#233;tiquet&#233;s par rapport au nombre de phrases total) et la pr&#233;cision sur les mots
inconnus. L&#8217;&#233;cart type (&#963;) des scores sur les 10 strates est &#233;galement calcul&#233;.
</p>
<p>Les r&#233;sultats sont pr&#233;sent&#233;s dans les tables 2 et 3. Les corrections apport&#233;es au corpus permettent
d&#8217;am&#233;liorer les scores de pr&#233;cision des m&#233;thodes d&#8217;&#233;tiquetage de mani&#232;re significative. Ainsi, la
pr&#233;cision sur les tokens passe de 96,39 &#224; 97,53 pour le Stanford POS tagger et de 95,70 &#224; 97,05
pour Apache OpenNLP. De plus, on peut observer que l&#8217;&#233;cart type des scores calcul&#233; sur les 10
strates diminue fortement. Cette mesure est un indicateur de l&#8217;am&#233;lioration de la stabilit&#233; du
niveau de performance des syst&#232;mes. Une am&#233;lioration encore plus importante est observ&#233;e sur
la pr&#233;cision au niveau des phrases, elle passe de 53,05% &#224; 57,05% pour le Stanford POS tagger et
de 47,56% &#224; 51,67% pour Apache OpenNLP. Cette augmentation s&#8217;explique par la r&#233;duction du
nombre de phrases contenant au moins un token auquel aucune &#233;tiquette n&#8217;a pu &#234;tre affect&#233;e.
Concernant la pr&#233;cision au niveau des mots inconnus, la stabilit&#233; des scores est normale puisque
nous n&#8217;introduisons pas de nouveaux tokens dans les donn&#233;es.
</p>
<p>Correction
Stanford POS Tagger
</p>
<p>Prec. tokens Prec. phrases Prec. inconnus
</p>
<p>FTB non corrig&#233; 96,39 (&#963; = 0,96) 53,05 (&#963; = 3,71) 83,36 (&#963; = 3, 43)
FTB + corr. 1 97,52&#8224;(&#963; = 0, 26) 56, 76&#8224;(&#963; = 2, 15) 83,52&#8224;(&#963; = 3, 40)
FTB + corr. 2 96,51&#8224;(&#963; = 0, 89) 53, 57&#8224;(&#963; = 3, 61) 83,37 (&#963; = 3, 42)
</p>
<p>FTB + corr. 1&amp;2 97, 53&#8224;(&#963; = 0, 26) 57, 05&#8224;(&#963; = 1, 15) 83, 50 (&#963; = 3, 38)
FTB + corr. 2&amp;1 97, 53&#8224;(&#963; = 0, 27) 57, 02&#8224;(&#963; = 2, 25) 83, 51 (&#963; = 3, 40)
</p>
<p>TABLE 2 &#8211; Scores de pr&#233;cision obtenus avec le Stanford POS tagger en fonction du niveau de
correction du FTB. &#963; correspond &#224; l&#8217;&#233;cart type des scores calcul&#233; sur les 10 strates. Les scores
indiqu&#233;s par les caract&#232;res &#8224; sont statistiquement significatifs par rapport au FTB non corrig&#233;
(&#961; &lt; 0, 01 avec un t-test de Student).
</p>
<p>Correction
Apache OpenNLP
</p>
<p>Prec. tokens Prec. phrases Prec. inconnus
</p>
<p>FTB non corrig&#233; 95, 82 (&#963; = 0, 95) 47, 56 (&#963; = 3, 25) 85, 50 (&#963; = 1, 57)
FTB + corr. 1 97, 03&#8224;(&#963; = 0,26) 51,40&#8224;(&#963; = 2, 04) 85, 68 (&#963; = 1, 57)
FTB + corr. 2 95, 94&#8224;(&#963; = 0,88) 48,08&#8224;(&#963; = 3,21) 85, 50 (&#963; = 1, 60)
</p>
<p>FTB + corr. 1&amp;2 97,05&#8224;(&#963; = 0,26) 51,67&#8224;(&#963; = 2, 13) 85, 70 (&#963; = 1, 55)
FTB + corr. 2&amp;1 97,04&#8224;(&#963; = 0,26) 51,67&#8224;(&#963; = 2, 11) 85, 68 (&#963; = 1,57)
</p>
<p>TABLE 3 &#8211; Scores de pr&#233;cision obtenus avec Apache OpenNLP en fonction du niveau de correction
du FTB. &#963; correspond &#224; l&#8217;&#233;cart type des scores calcul&#233; sur les 10 strates. Les scores indiqu&#233;s par
les caract&#232;res &#8224; sont statistiquement significatifs par rapport au FTB non corrig&#233; (&#961; &lt; 0.01 avec
un t-test de Student).
</p>
<p>288</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>La m&#233;thode de correction par d&#233;tection de variations de n-grammes permet de ramener davantage
d&#8217;erreurs candidates lorsque l&#8217;on traite des n-grammes de taille inf&#233;rieure &#224; 5. De plus nous avons
constat&#233; que pour une taille strictement sup&#233;rieure &#224; 1, les r&#233;sultats des &#233;tiqueteurs morpho-
syntaxiques &#233;taient am&#233;lior&#233;s. Nous n&#8217;avons pas gard&#233; ces r&#233;sultats car un premier retour au
corpus nous conduisait &#224; nous interroger sur la qualit&#233; des corrections op&#233;r&#233;es et par cons&#233;quent
sur l&#8217;am&#233;lioration qui pourrait bien &#234;tre due &#224; un ph&#233;nom&#232;ne de lissage des annotations du
corpus. Ce dernier point n&#233;cessitera une &#233;valuation plus approfondie dans le futur.
</p>
<p>5 Travaux connexes
</p>
<p>Les m&#233;thodes d&#8217;&#233;tiquetage morpho-syntaxique actuelles, bas&#233;es sur des mod&#232;les probabilistes,
offrent un niveau de performance &#233;lev&#233;. L&#8217;analyse des erreurs restantes sugg&#232;rent n&#233;anmoins que
le gain de pr&#233;cision potentiel venant de meilleurs traits ou d&#8217;une m&#233;thode d&#8217;apprentissage plus
performante reste tr&#232;s limit&#233;. Les probl&#232;mes relev&#233;s montrent que les inconsistances et les erreurs
d&#8217;annotations pr&#233;sentes dans les donn&#233;es d&#8217;entra&#238;nement et de test sont en partie responsables
du palier auquel les m&#233;thodes sont confront&#233;es. Partant de ce constat, (Manning, 2011) propose
un ensemble de r&#232;gles manuelles visant &#224; corriger les erreurs d&#8217;annotation pr&#233;sentes dans le
Penn Treebank. Une &#233;valuation comparative de la pr&#233;cision d&#8217;un syst&#232;me d&#8217;&#233;tiquetage morpho-
syntaxique sur les donn&#233;es ainsi corrig&#233;es a permis de montrer l&#8217;efficacit&#233; des r&#232;gles de correction
propos&#233;es.
</p>
<p>Concernant la probl&#233;matique de d&#233;tection et de correction automatique d&#8217;erreurs d&#8217;annotation,
la majorit&#233; des travaux s&#8217;est pench&#233;e sur le premier probl&#232;me avec une attention particuli&#232;re
sur l&#8217;&#233;tiquetage grammatical (Loftsson, 2009). Outre la question d&#8217;annotation d&#8217;unit&#233; lexicale,
le projet DECCA 5 aborde aussi les probl&#232;mes de d&#233;tection d&#8217;erreurs d&#8217;annotations 6 continues
(concernant une s&#233;quence de mots), discontinues et de type d&#233;pendance.
</p>
<p>Quelles que soient les approches et le type d&#8217;annotations observ&#233;, le principe de d&#233;tection
d&#8217;une erreur repose sur la recherche d&#8217;annotations inconsistantes au sein du corpus ; c&#8217;est-&#224;-dire
d&#8217;&#233;tiquetages diff&#233;rents pour des occurrences comparables du ph&#233;nom&#232;ne observ&#233;.
</p>
<p>Concernant la d&#233;tection d&#8217;erreur d&#8217;&#233;tiquetage grammatical, cinq approches ont &#233;t&#233; propos&#233;es.
(Loftsson, 2009) compare trois m&#233;thodes de d&#233;tection : la premi&#232;re fond&#233;e sur la d&#233;tection de
variation de n-gramme, la seconde fond&#233;e sur l&#8217;utilisation de plusieurs &#233;tiqueteurs automatiques
et la troisi&#232;me fond&#233;e sur de l&#8217;analyse syntaxique en constituants. La seconde m&#233;thode consiste
&#224; utiliser plusieurs &#233;tiqueteurs (l&#8217;auteur en a utilis&#233; cinq) et &#224; les combiner en utilisant un
simple m&#233;canisme de vote (chaque &#233;tiqueteur vote pour une &#233;tiquette et l&#8217;&#233;tiquette avec le plus
grand nombre de votes est s&#233;lectionn&#233;). La troisi&#232;me m&#233;thode consiste &#224; exploiter l&#8217;&#233;tiquette
syntaxique produite par l&#8217;analyse en constituants pour corriger certaines erreurs &#233;ventuelles
d&#8217;&#233;tiquetage grammatical interne. Cette m&#233;thode requiert d&#8217;identifier dans un premier temps les
types d&#8217;erreurs d&#8217;&#233;tiquetage grammatical possibles sous chaque constituant puis d&#8217;&#233;crire les r&#232;gles
de correction correspondante. Les r&#233;sultats de (Loftsson, 2009) montrent que ces m&#233;thodes
permettent toutes de d&#233;tecter effectivement des erreurs et qu&#8217;elles agissent en compl&#233;mentarit&#233;.
</p>
<p>(Loftsson, 2009) rapporte aussi les travaux de (Nakagawa et Matsumoto, 2002) et de (Kveton
</p>
<p>5. http://decca.osu.edu
6. La nature syntaxique ou s&#233;mantique de l&#8217;annotation est discut&#233;e mais le probl&#232;me est secondaire.
</p>
<p>289</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>et Oliva, 2002). (Nakagawa et Matsumoto, 2002) ont utilis&#233; le poids de confiance que leur
algorithme de classification (machines &#224; vecteurs de support) utilise pour d&#233;cider de la classe
d&#8217;un mot afin de d&#233;terminer si la classe assign&#233;e &#233;tait une erreur candidate. Cette m&#233;thode
est int&#233;ressante m&#234;me si l&#8217;entra&#238;nement des mod&#232;les peut &#234;tre co&#251;teuse pour de larges jeux
d&#8217;&#233;tiquettes.
</p>
<p>(Kveton et Oliva, 2002) d&#233;crivent, quant &#224; eux, une m&#233;thode semi-automatique pour d&#233;tecter des
n-grammes d&#8217;&#233;tiquettes grammaticales invalides en partant d&#8217;un ensemble construit &#224; la main
de paires d&#8217;&#233;tiquettes adjacentes invalides (e.g. un d&#233;terminant suivi d&#8217;un verbe). La m&#233;thode
consiste pour chaque bigramme invalide &#224; construire par collecte successive dans les phrases du
corpus l&#8217;ensemble d&#8217;&#233;tiquettes pouvant appara&#238;tre entre deux &#233;tiquettes du bigramme invalide.
Tout n-gramme d&#8217;&#233;tiquettes d&#233;butant et finissant par les &#233;tiquettes d&#8217;un bigramme invalide et
ayant une &#233;tiquette n&#8217;appartenant pas &#224; l&#8217;ensemble d&#8217;&#233;tiquettes av&#233;r&#233;es est consid&#233;r&#233; comme une
erreur potentielle dans un nouveau corpus. Cette m&#233;thode requiert d&#8217;une part une construction
manuelle (par un linguiste) de bigrammes invalides et d&#8217;autre part ne permet pas de d&#233;tecter des
n-grammes valides d&#8217;&#233;tiquettes utilis&#233;s incorrectement dans certains contextes.
</p>
<p>6 Conclusion et perspectives
</p>
<p>Nous avons pr&#233;sent&#233; une &#233;tude men&#233;e sur la d&#233;tection et la correction automatique des er-
reurs d&#8217;annotation morpho-syntaxique du French TreeBank. Deux m&#233;thodes ont &#233;t&#233; utilis&#233;es. La
premi&#232;re consiste &#224; identifier les mots sans &#233;tiquette et leur attribuer celle d&#8217;une forme corres-
pondante observ&#233;e dans le corpus. La seconde m&#233;thode utilise les variations de n-gramme pour
d&#233;tecter et corriger les anomalies d&#8217;annotation. Les r&#233;sultats que nous avons obtenus montrent
que les corrections apport&#233;es au corpus permettent d&#8217;am&#233;liorer de mani&#232;re significative les scores
de pr&#233;cision de deux diff&#233;rentes m&#233;thodes d&#8217;&#233;tiquetage morpho-syntaxique.
</p>
<p>Les perspectives de cette &#233;tude sont nombreuses. Dans un premier temps, nous souhaitons
poursuivre nos travaux en utilisant un jeu d&#8217;&#233;tiquettes plus &#233;tendu. Nous envisageons &#233;galement
d&#8217;am&#233;liorer la d&#233;tection des erreurs en utilisant conjointement les variations de n-gramme et
la combinaison des sorties de plusieurs &#233;tiqueteurs (Loftsson, 2009). A plus long terme, nous
voulons &#233;tudier la possibilit&#233; d&#8217;utiliser la correction automatique des erreurs d&#8217;annotation soit
comme une &#233;tape pr&#233;liminaire &#224; la v&#233;rification manuelle des annotations, soit comme une
alternative. Pour ce dernier point, l&#8217;objectif serait d&#8217;&#233;tendre le FTB par l&#8217;ajout de donn&#233;es annot&#233;es
et corrig&#233;es automatiquement.
</p>
<p>Les mod&#232;les construits &#224; partir des donn&#233;es corrig&#233;es pour les &#233;tiqueteurs Stanford POS tagger et
Apache OpenNLP sont disponibles &#224; l&#8217;adresse : http://www.lina.univ-nantes.fr/?-TALN-.html
</p>
<p>R&#233;f&#233;rences
</p>
<p>ABEILL&#201;, A., CL&#201;MENT, L. et TOUSSENEL, F. (2003). Building a treebank for French. Treebanks :
building and using parsed corpora, pages 165&#8211;188.
ARUN, A. et KELLER, F. (2005). Lexicalization in crosslinguistic probabilistic parsing : The case of
French. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics
(ACL&#8217;05), pages 306&#8211;313, Ann Arbor, Michigan. Association for Computational Linguistics.
</p>
<p>290</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CONSTANT, M., TELLIER, I., DUCHIER, D., DUPONT, Y., SIGOGNE, A. et BILLOT, S. (2011). Int&#233;grer
des connaissances linguistiques dans un CRF : application &#224; l&#8217;apprentissage d&#8217;un segmenteur-
&#233;tiqueteur du fran&#231;ais. In Actes de Traitement automatique des langues naturelles (2011).
</p>
<p>CRABB&#201;, B. et CANDITO, M. (2008). Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais. In
Actes de Traitement automatique des langues naturelles (2008).
</p>
<p>DENIS, P. et SAGOT, B. (2010). Exploitation d&#8217;une ressource lexicale pour la construction d&#8217;un
&#233;tiqueteur morphosyntaxique &#233;tat-de-l&#8217;art du fran&#231;ais. In Actes de Traitement automatique des
langues naturelles (2010).
</p>
<p>DICKINSON, M. et MEURERS, W. D. (2003). Detecting errors in part-of-speech annotation. In
Proceedings of the 10th Conference of the European Chapter of the Association for Computational
Linguistics (EACL-03), pages 107&#8211;114, Budapest, Hungary.
</p>
<p>GREEN, S., de MARNEFFE, M.-C., BAUER, J. et MANNING, C. D. (2011). Multiword expression iden-
tification with tree substitution grammars : A parsing tour de force with french. In Proceedings
of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 725&#8211;735,
Edinburgh, Scotland, UK. Association for Computational Linguistics.
</p>
<p>KVETON, P. et OLIVA, K. (2002). (semi-)automatic detection of errors in pos-tagged corpora. In
COLING.
</p>
<p>LOFTSSON, H. (2009). Correcting a POS-tagged corpus using three complementary methods.
In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages
523&#8211;531, Athens, Greece. Association for Computational Linguistics.
</p>
<p>MANNING, C. (2011). Part-of-speech tagging from 97linguistics ? In GELBUKH, A., &#233;diteur :
Computational Linguistics and Intelligent Text Processing, volume 6608 de Lecture Notes in
Computer Science, pages 171&#8211;189. Springer Berlin / Heidelberg.
</p>
<p>MARCUS, M., MARCINKIEWICZ, M. et SANTORINI, B. (1993). Building a large annotated corpus of
English : The Penn Treebank. Computational linguistics, 19(2):313&#8211;330.
</p>
<p>NAKAGAWA, T. et MATSUMOTO, Y. (2002). Detecting errors in corpora using support vector
machines. In COLING.
</p>
<p>TOUTANOVA, K., KLEIN, D., MANNING, C. et SINGER, Y. (2003). Feature-rich part-of-speech tagging
with a cyclic dependency network. In Proceedings of the 3rd Conference of the North American
Chapter of the ACL (NAACL 2003), pages 173&#8211;180. Association for Computational Linguistics.
</p>
<p>291</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div>
</div></div>
</body></html>