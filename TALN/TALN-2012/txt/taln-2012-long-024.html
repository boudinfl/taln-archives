<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Le corpus Sequoia : annotation syntaxique et exploitation pour l'adaptation d'analyseur par pont lexical</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 321&#8211;334,
Grenoble, 4 au 8 juin 2012. c&#169;2012 ATALA &amp; AFCP
</p>
<p>Le corpus Sequoia : annotation syntaxique et exploitation
pour l&#8217;adaptation d&#8217;analyseur par pont lexical
</p>
<p>Marie Candito1 Djam&#233; Seddah1, 2
(1) Alpage (Univ. Paris Diderot &amp; INRIA), 175 rue du Chevaleret, 75013 Paris, France
</p>
<p>(2) Univ. Paris Sorbonne, 28, rue Serpente, 75006 Paris, France
marie.candito@linguist.jussieu.fr, djame.seddah@paris-sorbonne.fr
</p>
<p>R&#201;SUM&#201;
Nous pr&#233;sentons dans cet article la m&#233;thodologie de constitution et les caract&#233;ristiques du corpus
Sequoia, un corpus en fran&#231;ais, syntaxiquement annot&#233; d&#8217;apr&#232;s un sch&#233;ma d&#8217;annotation tr&#232;s
proche de celui du French Treebank (Abeill&#233; et Barrier, 2004), et librement disponible, en
constituants et en d&#233;pendances. Le corpus comporte des phrases de quatre origines : Europarl
fran&#231;ais, le journal l&#8217;Est R&#233;publicain, Wikip&#233;dia Fr et des documents de l&#8217;Agence Europ&#233;enne du
M&#233;dicament, pour un total de 3204 phrases et 69246 tokens. En outre, nous pr&#233;sentons une
application de ce corpus : l&#8217;&#233;valuation d&#8217;une technique d&#8217;adaptation d&#8217;analyseurs syntaxiques
probabilistes &#224; des domaines et/ou genres autres que ceux du corpus sur lequel ces analyseurs
sont entra&#238;n&#233;s. Cette technique utilise des clusters de mots obtenus d&#8217;abord par regroupement
morphologique &#224; l&#8217;aide d&#8217;un lexique, puis par regroupement non supervis&#233;, et permet une
nette am&#233;lioration de l&#8217;analyse des domaines cibles (le corpus Sequoia), tout en pr&#233;servant
le m&#234;me niveau de performance sur le domaine source (le FTB), ce qui fournit un analyseur
multi-domaines, &#224; la diff&#233;rence d&#8217;autres techniques d&#8217;adaptation comme le self-training.
</p>
<p>ABSTRACT
The Sequoia corpus : syntactic annotation and use for a parser lexical domain adaptation
method
</p>
<p>We present the building methodology and the properties of the Sequoia treebank, a freely
available French corpus annotated following the French Treebank guidelines (Abeill&#233; et Barrier,
2004). The Sequoia treebank comprises 3204 sentences (69246 tokens), from the French Europarl,
the regional newspaper L&#8217;Est R&#233;publicain, the French Wikipedia and documents from the European
Medicines Agency. We then provide a method for parser domain adaptation, that makes use of
unsupervised word clusters. The method improves parsing performance on target domains (the
domains of the Sequoia corpus), without degrading performance on source domain (the French
treenbank test set), contrary to other domain adaptation techniques such as self-training.
</p>
<p>MOTS-CL&#201;S : Corpus arbor&#233;, analyse syntaxique statistique, adaptation de domaine.
</p>
<p>KEYWORDS: Treebank, statistical parsing, parser domain adaptation.
</p>
<p>1 Introduction
</p>
<p>L&#8217;analyse syntaxique statistique a fait de grands progr&#232;s ces quinze derni&#232;res ann&#233;es, avec de tr&#232;s
nombreux travaux, majoritairement sur l&#8217;anglais, fond&#233;s sur un apprentissage sur les sections du
</p>
<p>321</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Wall Street Journal du Penn Treebank (Marcus et al., 1993). D&#8217;autres langues ont b&#233;n&#233;fici&#233; de
ces avanc&#233;es, &#224; la condition, de taille, que soit disponible pour ces langues un corpus arbor&#233;, en
constituants ou en d&#233;pendances. Cependant, les analyseurs ainsi obtenus, appris sur un corpus
bien pr&#233;cis, ont leur performance maximale sur des textes similaires &#224; ce corpus, mais sont peu
robustes : ils montrent une qualit&#233; nettement d&#233;grad&#233;e lorqu&#8217;ils sont &#233;valu&#233;s sur des textes de
domaine ou genre diff&#233;rents. C&#8217;est particuli&#232;rement vrai pour l&#8217;anglais, car le WSJ montre peu
de vari&#233;t&#233; de th&#232;mes : (McClosky et al., 2006) rapporte que l&#8217;analyseur de Charniak (Charniak,
2000) obtient une F-mesure en constituants label&#233;s de 89.7% sur la section de test du WSJ, mais
chute &#224; 82.9% sur le corpus de test du Brown corpus (Francis et Kucera, 1964), corpus anglais
de genres vari&#233;s.
</p>
<p>Pour le fran&#231;ais, le French Treebank (ci-apr&#232;s FTB) (Abeill&#233; et Barrier, 2004) a servi de corpus
d&#8217;entra&#238;nement pour des analyseurs initialement d&#233;velopp&#233;s pour l&#8217;anglais (voir (Seddah et al.,
2009) pour une comparaison de plusieurs analyseurs en constituants, et (Candito et al., 2010b)
pour une comparaison d&#8217;analyseurs en d&#233;pendances, pour le fran&#231;ais). Le FTB est un corpus
de phrases du journal Le Monde, annot&#233;es en morphologie et en constituants. Les &#233;valuations
disponibles des analyseurs appris sur le FTB sont dites intra-domaine : elles sont classiquement
faites sur une partie du FTB, non vue &#224; l&#8217;apprentissage. Les &#233;valuations dites hors-domaine,
c&#8217;est-&#224;-dire simplement sur des phrases d&#8217;origine diff&#233;rente de celles du corpus d&#8217;apprentissage
se heurtent &#224; l&#8217;absence de corpus annot&#233;s dans le m&#234;me sch&#233;ma que le FTB. Le corpus EASy
(Paroubek et al., 2005) comprend des phrases de domaines et genres textuels divers, mais son
format mixte entre constituants (chunks) et d&#233;pendances (d&#233;pendances entre chunks) rend
difficile l&#8217;&#233;valuation des performances d&#8217;un analyseur en constituants sur ces textes.
</p>
<p>Pour cette raison, nous avons entrepris l&#8217;annotation syntaxique de quatre corpus en suivant,
&#224; quelques exceptions pr&#232;s, le sch&#233;ma d&#8217;annotation du FTB, regroup&#233;s sous le nom de corpus
Sequoia 1. Nous pr&#233;sentons ici la m&#233;thodologie d&#8217;annotation et les caract&#233;ristiques du corpus
arbor&#233; obtenu, ainsi que l&#8217;application sur ces corpus d&#8217;une m&#233;thode d&#8217;adaptation &#224; de nouveaux
domaines d&#8217;un analyseur statistique appris sur le FTB 2. Si l&#8217;objectif premier est de pouvoir tester
et am&#233;liorer la robustesse d&#8217;analyseurs statistiques, ces corpus, librement disponibles 3, sont
utilisables &#224; d&#8217;autres fins, en particulier pour des &#233;tudes linguistiques.
</p>
<p>Nous d&#233;crivons section 2 la m&#233;thodologie d&#8217;annotation et les caract&#233;ristiques du corpus, puis
section 3 la m&#233;thode d&#8217;adaptation d&#8217;analyseur et les travaux ant&#233;rieurs dans ce domaine, et en
section 4 les exp&#233;riences r&#233;alis&#233;es et les r&#233;sultats obtenus. Enfin nous concluons en section 5.
</p>
<p>2 Les corpus Sequoia
</p>
<p>2.1 Origine et m&#233;thode de s&#233;lection
</p>
<p>Le corpus Sequoia comporte des phrases ou textes de quatre origines diff&#233;rentes : l&#8217;agence
europ&#233;enne du m&#233;dicament, Europarl, le journal r&#233;gional l&#8217;Est R&#233;publicain et Wikipedia Fr. Le
choix de ces quatre origines est en partie conjoncturel, car li&#233; &#224; la disponibilit&#233; des corpus :
nous avons en effet eu le souci que les corpus soient librement disponibles, et qu&#8217;ils offrent une
</p>
<p>1. Du nom du projet (SEQUOIA ANR-08-EMER-013) ayant financ&#233; l&#8217;annotation manuelle.
2. Cet article &#233;tend un article court publi&#233; &#224; IWPT 2011 (Candito et al., 2011), relatant des exp&#233;riences d&#8217;adaptation
</p>
<p>d&#8217;analyseurs sur un des quatre sous-corpus aujourd&#8217;hui disponibles.
3. https ://www.rocq.inria.fr/alpage-wiki/tiki-index.php ?page=CorpusSequoia
</p>
<p>322</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>diversit&#233; variable par rapport au genre journalistique du FTB (diversit&#233; &#233;valu&#233;e a priori, non
pr&#233;cis&#233;ment). D&#8217;autres crit&#232;res ont guid&#233; notre choix, comme l&#8217;existence d&#8217;autres annotations
pour les phrases s&#233;lectionn&#233;es et la disponibilit&#233; de gros volume de corpus brut de m&#234;me origine,
en vue d&#8217;exp&#233;riences d&#8217;apprentissage semi-supervis&#233;.
</p>
<p>2.1.1 Domaine m&#233;dical
</p>
<p>Nous avons s&#233;lectionn&#233; le domaine m&#233;dical comme domaine potentiellement tr&#232;s &#233;loign&#233; de
celui du FTB. Plus pr&#233;cis&#233;ment, nous avons retenu deux documents provenant de la partie en
fran&#231;ais du corpus EMEA, lui-m&#234;me inclus dans le corpus OPUS (Tiedemann, 2009) 4.
</p>
<p>Le corpus EMEA contient des documents concernant des m&#233;dicaments, essentiellement des
rapports public d&#8217;&#233;valuation (EPAR), chaque rapport &#233;tant d&#233;di&#233; &#224; la justification de l&#8217;autorisation
ou l&#8217;interdiction de la mise sur le march&#233; d&#8217;un m&#233;dicament. La partie fran&#231;aise que nous utilisons
contient environ 1000 documents convertis d&#8217;un format pdf, et concat&#233;n&#233;s. Il s&#8217;agit pour la
majorit&#233; de traductions de versions originales anglaises. D&#8217;apr&#232;s les proc&#233;dures standards de
l&#8217;Agence Europ&#233;enne du m&#233;dicament pour les EPARs 5 les documents sont d&#8217;abord &#233;crits en
anglais, dans des termes &#8220;compr&#233;hensibles par quelqu&#8217;un qui n&#8217;est pas expert du domaine&#8221;. La
traduction dans les diff&#233;rentes langues officielles de l&#8217;Union Europ&#233;enne est g&#233;r&#233;e par le Centre
de Traduction de l&#8217;UE (CdT), avec une terminologie standardis&#233;e pour la biom&#233;decine. D&#8217;apr&#232;s
ce que nous avons pu juger, la traduction est de tr&#232;s bonne qualit&#233;.
</p>
<p>Pour l&#8217;annotation manuelle, nous avons s&#233;lectionn&#233; deux EPARs, pour constituer un corpus
de d&#233;veloppement et un corpus de test (ci-apr&#232;s EMEA-dev et EMEA-test). Ces deux sous-
corpus sont particuli&#232;rement &#233;loign&#233;s des phrases journalistiques, pour ce qui est du domaine
(ici m&#233;dical) et du genre textuel (rapport scientifique). Lexicalement, ils contiennent de la
terminologie sp&#233;cialis&#233;e (protocoles de test et administration de m&#233;dicaments, descriptions
de maladies, sympt&#244;mes et contre-indications). Syntaxiquement on peut noter de nombreux
imp&#233;ratifs (pour les instructions d&#8217;utilisation), la description de dosages, et un usage fr&#233;quent de
pr&#233;cisions apparaissant entre parenth&#232;ses (gloses de termes savants, abr&#233;viations, information
de fr&#233;quence).
</p>
<p>2.1.2 FrWiki
</p>
<p>La deuxi&#232;me source retenue est la Wikip&#233;dia en fran&#231;ais. Nous avons pioch&#233; dans le corpus
Wikipedia Fr faisant partie du corpus PASSAGE (Villemonte De La Clergerie et al., 2008) 6, le texte
correspondant &#224; 19 entr&#233;es Wikipedia, concernant des &#8220;affaires&#8221; sociales ou politiques c&#233;l&#232;bres,
pour la plupart r&#233;centes. Chaque entr&#233;e correspond &#224; une description, en g&#233;n&#233;ral chronologique,
de l&#8217;affaire en question. Ainsi nous obtenons un sous-corpus d&#8217;un genre textuel narratif, pour
lequel d&#8217;autres annotations existent (PASSAGE).
</p>
<p>2.1.3 EstR&#233;publicain
</p>
<p>Le corpus L&#8217;Est R&#233;publicain est un corpus librement disponible au CNRTL 7, rassemblant les articles
de deux ann&#233;es de ce quotidien r&#233;gional (pour un total de 150 millions de tokens ponctuation
</p>
<p>4. opus.lingfil.uu.se/EMEA.php
5. Document 3131, sur : www.ema.europa.eu
6. Les 19 premi&#232;res entr&#233;es du fichier frwiki_50.txt
7. http ://www.cnrtl.fr/corpus/estrepublicain
</p>
<p>323</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>comprise). Nous avons retenu 39 articles, qui sont ceux s&#233;lectionn&#233;s dans le cadre du projet ANR
ANNODIS 8 d&#233;di&#233; &#224; l&#8217;annotation discursive pour le fran&#231;ais, avec comme crit&#232;re d&#8217;obtenir des
textes int&#233;ressants du point de vue discursif.
</p>
<p>Avec ce choix, d&#8217;une part nous esp&#233;rons qu&#8217;il sera profitable de disposer pour ce corpus &#224; la
fois des annotations syntaxiques et des annotations discursives. D&#8217;autre part, nous obtenons
un sous-corpus dont le domaine est &#233;loign&#233; du FTB. En effet les articles retenus relatent des
informations essentiellement locales (faits divers, inaugurations, ...), ce qui n&#8217;est pas le cas du
FTB.
</p>
<p>2.1.4 Europarl
</p>
<p>Enfin, nous avons s&#233;lectionn&#233; des phrases manuellement annot&#233;es dans le cadre du projet
PASSAGE (Villemonte De La Clergerie et al., 2008), en choisissant une sous-partie des phrases
d&#8217;Europarl s&#233;lectionn&#233;es dans le cadre de ce projet.
</p>
<p>Trois raisons principales expliquent ce choix : (i) Europarl constitue un corpus tr&#232;s utilis&#233; en
TAL, un corpus arbor&#233; peut en permettre une &#233;tude fine ; (ii) le type textuel d&#8217;Europarl, d&#233;bat
parlementaire, montre a priori des caract&#233;ristiques syntaxiques qui peuvent diff&#233;rer du type
journalistique, ne serait-ce que par exemple le recours fr&#233;quent &#224; la premi&#232;re personne et au
vocatif, et enfin (iii) les phrases choisies ont &#233;galement &#233;t&#233; annot&#233;es dans le sch&#233;ma d&#8217;annotation
Easy (pour le projet PASSAGE), ce qui peut aider &#224; la conversion de sch&#233;mas des corpus PASSAGE,
Easy vers FTB et vice-versa.
</p>
<p>2.2 Annotation morpho-syntaxique
</p>
<p>2.2.1 Sch&#233;ma d&#8217;annotation
</p>
<p>Choix linguistiques
</p>
<p>Notre objectif est d&#8217;obtenir des corpus compatibles avec le FTB, et donc en suivant les choix lin-
guistiques du FTB, caract&#233;ris&#233; comme un sch&#233;ma syntagmatique surfacique, avec des annotations
fonctionnelles pour les d&#233;pendants des verbes. Ainsi avons-nous suivi autant que possible les
guides d&#8217;annotation du FTB (Abeill&#233; et Cl&#233;ment, 2006; Abeill&#233; et al., 2004; Abeill&#233;, 2004).
</p>
<p>Une exception notable concerne le traitement des mots compos&#233;s. Pour les compos&#233;s ni nominaux
ni verbaux, nous nous sommes appuy&#233;s sur les compos&#233;s existants dans le FTB. Pour les compos&#233;s
verbaux &#224; syntaxe r&#233;guli&#232;re, nous avons pr&#233;f&#233;r&#233; n&#8217;en annoter aucun, et privil&#233;gier une analyse
syntagmatique. En effet ils sont potentiellement discontinus, et leur notation est alors variable
dans le FTB (par exemple, annotation il est_en_train de... versus il est justement en train de ...).
Concernant les compos&#233;s nominaux, le FTB contient de nombreuses incoh&#233;rences (s&#233;quences
de m&#234;me s&#233;mantique parfois cod&#233;es comme compos&#233;s, parfois cod&#233;es par un syntagme), en
particulier pour les compos&#233;s syntaxiquement r&#233;guliers &#224; s&#233;mantique tout ou partiellement
compositionnelle 9. Nous avons donc choisi de syst&#233;matiquement coder syntagmatiquement des
s&#233;quences syntaxiquement r&#233;guli&#232;res (comme N prep N ou N A par exemple), y compris celles
pouvant &#234;tre consid&#233;r&#233;es comme des noms compos&#233;s. Cela a le m&#233;rite de l&#8217;uniformit&#233;, mais
</p>
<p>8. http ://w3.erss.univ-tlse2.fr/annodis
9. Par exemple pays industrialis&#233;s appara&#238;t deux fois comme compos&#233;, et 41 fois comme deux mots ; taux d&#8217;int&#233;r&#234;t
</p>
<p>appara&#238;t 80 comme compos&#233;, et 25 fois comme trois mots.
</p>
<p>324</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>appelle des traitements ult&#233;rieurs pour rep&#233;rer en particulier les cas de compos&#233;s s&#233;mantiquement
non compositionnels.
</p>
<p>Format
</p>
<p>En ce qui concerne le format, au lieu de reproduire le format XML du FTB, nous avons opt&#233; pour
un format certes moins riche mais beaucoup plus souple : un format parenth&#233;s&#233; avec une ligne
par phrase syntagmatiquement annot&#233;e, qui fournit la cat&#233;gorie morpho-syntaxique des tokens,
et leur structure syntagmatique. Ce format est celui du PennTreebank, qui s&#8217;est impos&#233; comme
format d&#8217;apprentissage des analyseurs syntagmatiques probabilistes pour diverses langues et c&#8217;est
sous cette forme que nous utilisons le FTB dans nos exp&#233;riences d&#8217;analyse syntaxique probabiliste.
</p>
<p>Voici un exemple dans le format en constituants parenth&#233;s&#233;, provenant du corpus m&#233;dical :
</p>
<p>( (SENT (PP-MOD (P Afin_de) (VPinf (VN (VINF diminuer)) (NP-OBJ (DET le) (NC risque) (PP (P de) (NP (ADJ faibles)
</p>
<p>(NC valeurs) (PP (P d&#8217;) (NP (NC ACT)))))))) (PONCT ,) (NP-SUJ (DET le) (NC produit) (VPpart (VPP reconstitu&#233;)
</p>
<p>(COORD (CC et) (VPpart (VPP dilu&#233;))))) (VN (V doit)) (VPinf-OBJ (VN (VINF &#234;tre) (ADV bien) (VPP m&#233;lang&#233;))) (COORD
</p>
<p>(CC puis) (VN (V doit)) (VPinf (VN (VINF &#234;tre) (VPP administr&#233;)) (PP-MOD (P en) (NP (NC bolus))) (PP-MOD (P par)
</p>
<p>(NP (NC pouss&#233;e) (AP (ADJ intraveineuse)) (AP (ADJ rapide)))))) (PONCT .)))
</p>
<p>Le jeu de cat&#233;gories morpho-syntaxiques que nous utilisons est celui mis ou point par (Crabb&#233;
et Candito, 2008), contenant 28 cat&#233;gories, qui correspondent aux combinaisons entre une des
13 cat&#233;gories grossi&#232;res du FTB et des informations cod&#233;es dans le FTB sous forme de traits
(essentiellement distinction nom commun, nom propre, mode du verbe). Il y a appauvrissement
des annotations par rapport au FTB, pour ce qui est des informations morphologiques. En effet,
si une partie de celles disponibles dans le FTB est encod&#233;e dans l&#8217;&#233;tiquette morpho-syntaxique,
d&#8217;autres comme le lemme, le genre et le nombre ne sont pas repr&#233;sent&#233;s. En outre, les cat&#233;gories
des composants de compos&#233;s n&#8217;ont pas &#233;t&#233; explicit&#233;es (un compos&#233; est directement cod&#233; comme
un seul token, avec ses composants s&#233;par&#233;s par &#8217;_&#8217;). Cet appauvrissement relatif est compens&#233; par
la souplesse d&#8217;utilisation de ce format, et la disponibilit&#233; d&#8217;outils de visualisation et validation, ce
qui favorise clairement la qualit&#233; des annotations, par rapport &#224; une validation faite directement
sur format XML. D&#8217;autre part, comme indiqu&#233; supra, c&#8217;est ce format parenth&#233;s&#233; qui est utilis&#233;
pour l&#8217;analyse syntaxique probabiliste.
</p>
<p>Conversion en d&#233;pendances
</p>
<p>Le corpus annot&#233; en constituants a &#233;t&#233; automatiquement converti en d&#233;pendances en utilisant
le convertisseur d&#233;velopp&#233; pour la conversion automatique du FTB (Candito et al., 2010a). Au
final, le corpus Sequoia est donc disponible sous deux formes : un format parenth&#233;s&#233; annot&#233; en
constituants 10 d&#233;cor&#233; de fonctions syntaxiques, et un format tabul&#233; CoNLL 11 pour la version en
d&#233;pendances label&#233;es.
</p>
<p>2.2.2 M&#233;thodologie d&#8217;annotation
</p>
<p>Pour obtenir le corpus Sequoia, nous avons proc&#233;d&#233; en alternant traitements automatiques et
validation de ces traitements pour passer &#224; l&#8217;&#233;tape suivante. A toutes les &#233;tapes (segmentation,
tagging, parsing, annotations des fonctions), les annotations pr&#233;c&#233;dentes pouvaient &#234;tre remises
</p>
<p>10. Plus pr&#233;cis&#233;ment, deux formats en constituants sont disponibles : le format standard FTB, et un format avec
une repr&#233;sentation modifi&#233;e des infinitives introduites par des pr&#233;positions, et un syntagme suppl&#233;mentaire dans les
compl&#233;tives, tel que d&#233;crit dans (Candito et Crabb&#233;, 2009). Ces modifications facilitent la conversion en d&#233;pendances. La
conversion de l&#8217;un vers l&#8217;autre format est automatique.
</p>
<p>11. http://ilk.uvt.nl/conll/#dataformat
</p>
<p>325</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>en cause. La s&#233;quence a &#233;t&#233; la suivante :
</p>
<p>&#8211; Pr&#233;traitements automatiques : Segmentation en phrases, reconnaissance hors contexte de
compos&#233;s et tokenisation via l&#8217;outil Bonsai 12
</p>
<p>&#8211; Etiquetage morpho-syntaxique en utilisant le tagger MElt (Denis et Sagot, 2009)
&#8211; Validation manuelle en &#233;diteur simple, par un seul annotateur expert, du tagging, de la
</p>
<p>segmentation en phrases, et de la reconnaissance de compos&#233;s
&#8211; Pour tous les sous-corpus sauf EMEA : Analyse syntagmatique automatique au moyen de deux
</p>
<p>parsers statistiques diff&#233;rents, en guidant les analyseurs avec les tags manuellement valid&#233;s :
les analyses doivent se conformer aux cat&#233;gories fournies en entr&#233;e. Les analyseurs sont le
parser de Berkeley (Petrov et Klein, 2007) et l&#8217;analyseur de Charniak (Charniak, 2000), tous
deux adapt&#233;s et entra&#238;n&#233;s sur le FTB. Pour EMEA : la validation syntaxique a &#233;t&#233; faite par un
annotateur expert.
</p>
<p>&#8211; Validation manuelle ind&#233;pendante des deux sorties d&#8217;analyseurs, via l&#8217;outil graphique Word-
Freak (Morton et LaCivita, 2003) adapt&#233; pour le tagset et le jeu de fonctions du FTB, puis
adjudication.
</p>
<p>&#8211; Annotation automatique des fonctions des d&#233;pendants des verbes finis, en utilisant l&#8217;annotateur
en fonctions int&#233;gr&#233; &#224; Bonsai
</p>
<p>&#8211; Validation manuelle des annotations fonctionnelles par deux annotateurs ind&#233;pendamment,
via WordFreak, puis adjudiction.
</p>
<p>&#8211; V&#233;rifications syst&#233;matiques par un expert de points rep&#233;r&#233;s comme difficiles 13 ; v&#233;rification
syst&#233;matique de la coh&#233;rence du traitement des compos&#233;s.
</p>
<p>2.2.3 Evaluation de l&#8217;annotation
</p>
<p>Pour &#233;valuer l&#8217;accord inter-annotateurs, et la distance au corpus de r&#233;f&#233;rence apr&#232;s adjudication
et v&#233;rifications syst&#233;matiques, nous utilisons l&#8217;outil Evalb servant habituellement &#224; l&#8217;&#233;valuation
des sorties d&#8217;un analyseur par rapport &#224; des analyses de r&#233;f&#233;rence. Pour les sous-corpus Europarl,
EstR&#233;publicain et FrWiki, nous fournissons table 1 l&#8217;accord deux &#224; deux entre trois r&#233;sultats
d&#8217;annotations : l&#8217;annotation A, l&#8217;annotation B et le r&#233;sultat de l&#8217;adjudication de A et B plus
v&#233;rification. La mesure utilis&#233;e est la moyenne harmonique (F-mesure) entre la pr&#233;cision et
le rappel en constituants label&#233;s. Nous avons d&#251; contourner le probl&#232;me de tokenisations
divergentes, o&#249; une s&#233;quence de tokens analys&#233;e comme un mot compos&#233; dans un des fichiers et
pas dans l&#8217;autre. Par exemple la s&#233;quence en fait peut avoir &#233;t&#233; cod&#233;e (ADV en_fait) d&#8217;un c&#244;t&#233;
et (CLO en) (V fait) de l&#8217;autre. Pour r&#233;soudre ce probl&#232;me, nous transformons les annotations
avant l&#8217;&#233;valuation de l&#8217;accord : tous les compos&#233;s sont transform&#233;s en structure contenant les
composants, avec une cat&#233;gorie unique pour les composants. Pour notre exemple &#8217;(ADV en_fait)&#8217;
est transform&#233; en (ADV (Z en) (Z fait)). Ainsi les divergences de tokenisation non seulement ne
bloquent pas evalb, mais sont en outre prises en compte dans l&#8217;&#233;valuation.
</p>
<p>L&#8217;&#233;valuation montre des r&#233;sultats assez satisfaisants pour Europarl et EstR&#233;pu, avec une nette
am&#233;lioration lors de l&#8217;&#233;valuation avec la r&#233;f&#233;rence. Pour FrWiki, l&#8217;accord entre les deux annota-
tions simples est bas : il est comparable avec les r&#233;sultats obtenus par l&#8217;analyseur sur le domaine
neutre (section 4). C&#8217;est en effet par ce corpus que l&#8217;annotation a commenc&#233;. On voit ici que la
phase de formation est longue. Sachant cela, la v&#233;rification pour ce corpus a &#233;t&#233; plus pouss&#233;e.
</p>
<p>12. http ://alpage.inria.fr/statgram/frdep/fr_stat_dep_parsing.html
13. Entre autres : les cliv&#233;es versus relatives, le causatif, les compl&#233;tives en de objet direct versus oblique (de-obj), le
</p>
<p>rep&#233;rage d&#8217;incoh&#233;rences comme par exemple des verbes finis sans sujet.
</p>
<p>326</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Annotations A vs. B Annotation A vs. r&#233;f&#233;rence Annotation B vs. r&#233;f&#233;rence
FrWiki 83.96 91.59 88.64
Europarl 90.14 94.20 92.26
EstR&#233;pu 90.45 94.22 93.72
</p>
<p>TABLE 1 &#8211; Evaluation deux &#224; deux (moyenne des F-mesures) des annotations simple A, simple B
et de la r&#233;f&#233;rence (apr&#232;s adjudication de A et B et v&#233;rifications syst&#233;matiques).
</p>
<p>2.3 Caract&#233;ristiques
</p>
<p>La table 2 fournit les caract&#233;ristiques des diff&#233;rents corpus annot&#233;s, en regard de celle des corpus
de d&#233;veloppement et d&#8217;entra&#238;nement du FTB (FTB-dev et FTB-train) utilis&#233;s pour les exp&#233;riences
(section 4) 14.
</p>
<p>Corpus Sequoia FTB
M&#233;dical Neutre
</p>
<p>EMEA EMEA Est Euro Fr
dev test R&#233;p. Parl Wiki dev train
</p>
<p>Nb de phrases 574 544 529 561 996 1235 9881
Longueur moyenne 16,3 22,0 21,0 26,3 22,2 29,6 28,1
Ecart type sur la longueur 14,7 15,0 12,9 15,0 18,0 16,0 16,5
Donn&#233;es pour tout type de formes fl&#233;chies (ponctuation y compris)
Taille du vocabulaire 1916 1737 3337 3300 4687 7222 24110
% d&#8217;inconnus 41.4 35.8 29,2 20,6 34,2 22,5 -
Nb d&#8217;occ. 9343 11964 11114 14745 22080 36508 278083
% d&#8217;occ. d&#8217;inconnus 23.0 19.7 11,2 6,6 12,9 5,2 -
% d&#8217;occ. de Noms propres 1,7 2.7 5,1 2,9 9,7 4,1 4,0
Donn&#233;es pour les formes alphanum&#233;riques minusculis&#233;s
Taille du vocabulaire 1695 1599 3173 3165 4410 6904 22526
% d&#8217;inconnus 36.6 34.0 28,0 20,1 32,6 21,6 -
Nb d&#8217;occ. 8107 10451 9552 13073 18619 30940 235105
% d&#8217;occ. d&#8217;inconnus 23.2 20.9 12,1 7,0 13,8 5,7 -
</p>
<p>TABLE 2 &#8211; Caract&#233;ristiques chiffr&#233;es des corpus manuellement annot&#233;s. Les inconnus sont les
formes absentes du FTB-train.
</p>
<p>Les diff&#233;rents nouveaux corpus ont chacun environ 500 phrases, sauf FrWiki (961 phrases). Si la
longueur moyenne des phrases varie nettement entre les diff&#233;rents corpus, on peut noter une
grande variance. Ce sont les phrases du FTB qui sont les plus longues en moyenne (29,6 pour
</p>
<p>14. Pour comparabilit&#233; avec nos r&#233;sultats ant&#233;rieurs, nous utilisons la partie du FTB annot&#233;e en fonctions grammaticales,
telle que distribu&#233;e en 2007, qui contient 12351 phrases. La version actuellement disponible du FTB contient environ
4000 phrases suppl&#233;mentaires. Nous utilisons le d&#233;coupage initialement propos&#233; par (Crabb&#233; et Candito, 2008) en corpus
de test (1235 premi&#232;res phrases), corpus de d&#233;veloppement (1235 phrases suivantes) et 9881 phrases restantes comme
corpus d&#8217;apprentissage. Le corpus original XML est pr&#233;trait&#233; tel que d&#233;crit dans (Candito et Crabb&#233;, 2009). En particulier
les compos&#233;s nominaux et verbaux syntaxiquement r&#233;guliers sont d&#233;faits et repr&#233;sent&#233;s syntagmatiquement, et chaque
occurrence de compos&#233; restante trait&#233;e comme un seul token (par exemple (N (P &#224;) (N cause) (P de)) est remplac&#233; par
(N &#224;_cause_de)).
</p>
<p>327</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FTB-dev et 28, 1 pour FTB-train), devant m&#234;me Europarl (26, 3).
La table fournit &#233;galement la taille des vocabulaires (de formes fl&#233;chies), et en leur sein la
proportion de formes qui sont absentes du FTB-train. Nous fournissons les chiffres calcul&#233;s
en utilisant tous les tokens (y compris la ponctuation) ainsi que ceux calcul&#233;s sur les tokens
alphanum&#233;riques minusculis&#233;s 15, pour mieux &#233;valuer la diversit&#233; lexicale. On peut constater que
le corpus m&#233;dical comporte de loin le vocabulaire le plus &#233;loign&#233; de celui du FTB (plus d&#8217;une
forme sur trois est absente du FTB-train). Pour le corpus EMEA-dev, la proportion d&#8217;inconnus en
comptant tous les types de formes fl&#233;chies est tr&#232;s haute, du fait d&#8217;un grand nombre de mots
enti&#232;rement capitalis&#233;s (la proportion passe de 41,4 &#224; 36,6 en ignorant la ponctuation et en
minusculisant). Pour le corpus FrWiki, la forte proportion d&#8217;inconnus (34,2%) peut s&#8217;expliquer
par une grande fr&#233;quence des noms propres (cf. la ligne % d&#8217;occurrences de noms propres : environ
une occurrence sur 10 est un nom propre dans FrWiki).
</p>
<p>Les lignes sur les nombres d&#8217;occurrences et le pourcentage d&#8217;inconnus parmi ces occurrences
donnent une vision plus pr&#233;cise de la diversit&#233; lexicale des corpus. Dans les corpus m&#233;dicaux, une
occurrence sur 5 (et presque une sur 4 pour EMEA-dev) correspond &#224; un inconnu du FTB-train,
ce qui, avec la faible proportion d&#8217;occurrences de noms propres (1, 7 et 2, 7) indique que les mots
inconnus sont plut&#244;t des mots fr&#233;quemment utilis&#233;s dans ces corpus. Au contraire, pour FrWiki
on voit que, calcul&#233;e sur les occurrences, la proportion d&#8217;inconnus tombe &#224; 12,9 (la majorit&#233;
des inconnus du vocabulaire sont des noms propres, apparaissant rarement). Le corpus le plus
proche lexicalement du FTB semble &#234;tre Europarl : seulement 6,6% des occurrences sont des
inconnus, formant un cinqui&#232;me du vocabulaire, ce qui constitue moins d&#8217;occurrences d&#8217;inconnus
que dans le FTB-dev.
</p>
<p>3 Adaptation de domaine par pont lexical
</p>
<p>Notre objectif est d&#8217;explorer une m&#233;thode d&#8217;am&#233;lioration des performances d&#8217;un analyseur
statistique sur des textes d&#8217;origine diff&#233;rente de celle du corpus d&#8217;entra&#238;nement de l&#8217;analyseur, les
diff&#233;rences pouvant relever du domaine et/ou du genre des textes. Pour simplifier, nous utilisons
par la suite les termes domaine source pour les caract&#233;ristiques (domaine, genre, registre) du
corpus d&#8217;entra&#238;nement, domaines cibles pour celles des textes d&#8217;origine diff&#233;rente et analyse
hors-domaine pour l&#8217;analyse de textes des domaines cibles.
</p>
<p>Pour am&#233;liorer l&#8217;analyse hors-domaine, nous proposons d&#8217;adapter une technique test&#233;e au d&#233;part
pour le parsing intra-domaine. S&#8217;inspirant de l&#8217;utilisation par (Koo et al., 2008) de clusters de
mots comme traits d&#8217;un analyseur discriminatif en d&#233;pendances, (Candito et Crabb&#233;, 2009)
ont propos&#233; une technique qui, en r&#233;duisant la dispersion des donn&#233;es lexicales, am&#233;liore les
performances de parsing intra-domaine. Ils entra&#238;nent un analyseur statistique sur un corpus
o&#249; les mots sont remplac&#233;s par des identifiants de clusters de mots, obtenus de mani&#232;re non
supervis&#233;e sur un corpus brut de grande taille. Le parsing se fait ensuite de la m&#234;me mani&#232;re,
en rempla&#231;ant chaque mot par leur cluster correspondant, de mani&#232;re d&#233;terministe et non
contextuelle, puis en r&#233;ins&#233;rant les tokens originaux pour obtenir les sorties d&#8217;analyse.
</p>
<p>Plus pr&#233;cis&#233;ment, le regroupement de formes fl&#233;chies en clusters se fait en deux &#233;tapes :
&#8211; Les formes fl&#233;chies sont d&#8217;abord group&#233;es en clusters morphologiques via un lexique morpholo-
</p>
<p>gique. Il s&#8217;agit de ramener un ensemble de formes fl&#233;chies &#224; une forme canonique, dite forme
</p>
<p>15. Plus pr&#233;cis&#233;ment les tokens comportant au moins une lettre ou un chiffre, et ramen&#233;s &#224; une forme minusculis&#233;e.
</p>
<p>328</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>d&#233;fl&#233;chie, avec comme principe de conserver exactement la m&#234;me ambigu&#239;t&#233; de cat&#233;gories
morpho-syntaxiques (contrairement par exemple &#224; une lemmatisation). On veut en effet d&#233;l&#233;-
guer la d&#233;sambiguisation de cat&#233;gories &#224; l&#8217;analyseur, et ne pas trancher par pr&#233;-traitement.
Pour cela, pour une forme donn&#233;e, on r&#233;cup&#232;re la liste de ses cat&#233;gories recens&#233;es dans le
dictionnaire, puis, tant que cette liste de cat&#233;gories ne varie pas, le pluriel est ramen&#233; au
singulier, le f&#233;minin au masculin, et pour les formes verbales conjugu&#233;es non ambigu&#235;s, les
personnes, mode et temps verbaux sont ramen&#233;es &#224; la deuxi&#232;me personne pr&#233;sent pluriel
(moyen rapide de trouver une forme n&#8217;introduisant pas de nouvelles ambigu&#239;t&#233;s). Par exemple,
analys&#233;es est ramen&#233; &#224; analys&#233;, mais entr&#233;es est ramen&#233; &#224; entr&#233;e, de mani&#232;re &#224; conserver
l&#8217;ambigu&#239;t&#233; nom/participe. Toutes les formes finies de augmenter sont ramen&#233;es &#224; augmentez,
mais par exemple joue est inchang&#233; pour pr&#233;server son ambigu&#239;t&#233; cat&#233;gorielle.
</p>
<p>&#8211; Ensuite un algorithme de clustering non supervis&#233; (Brown et al., 1992) est appliqu&#233; sur gros
corpus pr&#233;alablement segment&#233; en phrases, tokenis&#233; et d&#233;fl&#233;chi (i.e. o&#249; les formes fl&#233;chies sont
remplac&#233;es par leur forme d&#233;fl&#233;chie correspondante). On obtient ainsi des clusters de formes
d&#233;fl&#233;chies. Il s&#8217;agit d&#8217;un algorithme hi&#233;rarchique et agglom&#233;ratif, o&#249; le crit&#232;re de fusion de
deux clusters est la perte minimale de vraisemblance dans un mod&#232;le bigramme de s&#233;quences
de clusters.
</p>
<p>Dans cet article, nous adaptons cette technique au probl&#232;me sp&#233;cifique de la non robustesse des
analyseurs statistiques, en utilisant des clusters de mots appris sur la concat&#233;nation de corpus du
domaine source (ou proche du domaine source) et des domaines cibles. L&#8217;objectif est d&#8217;obtenir
que soient group&#233;s sous le m&#234;me cluster des mots appartenant au domaine source et des mots
appartenant aux domaines cibles, de fa&#231;on &#224; r&#233;aliser un pont entre les vocabulaires respectifs de
ces domaines (d&#8217;o&#249; le nom d&#8217;adaptation &#224; de nouveaux domaines par &#8220;pont lexical&#8221;).
</p>
<p>3.1 Travaux ant&#233;rieurs reli&#233;s
</p>
<p>Diff&#233;rentes techniques ont &#233;t&#233; propos&#233;es pour adapter des mod&#232;les d&#8217;analyse existants &#224; de
nouveaux genres :
&#8211; Adaptation au domaine via de l&#8217;auto-entra&#238;nement (self-training) (Bacchiani et al., 2006;
</p>
<p>McClosky et al., 2006; Sagae, 2010) : un analyseur entra&#238;n&#233; sur le domaine source est utilis&#233;
pour analyser du domaine cible, et on r&#233;entra&#238;ne un analyseur sur les donn&#233;es valid&#233;es source
et les donn&#233;es pr&#233;dites cibles. Le corpus d&#8217;entra&#238;nement ainsi obtenu, bien que bruit&#233;, capture
suffisamment de r&#233;gularit&#233;s du domaine cible pour am&#233;liorer les performances d&#8217;analyse sur
ce domaine (tout en d&#233;gradant les performances sur le domaine source) ;
</p>
<p>&#8211; co-entra&#238;nement avec s&#233;lection d&#8217;exemples (Steedman et al., 2003) : deux analyseurs sont
it&#233;rativement re-entra&#238;n&#233;s sur leurs sorties respectives, les phrases du domaine cible &#224; utiliser
&#233;tant choisies de mani&#232;re &#224; minimiser les erreurs d&#8217;analyse tout en maximisant l&#8217;utilit&#233; &#224;
l&#8217;entra&#238;nement ;
</p>
<p>&#8211; transformation de treebank et adaptation du domaine cible (Foster, 2010) ;
&#8211; adaptation m&#233;ticuleuse du domaine cible &#224; la source d&#8217;entra&#238;nement (Foster et al., 2007) ;
Bien que diff&#233;rentes, les techniques ici &#233;voqu&#233;es sont toutes con&#231;ues pour combler la variation
syntaxique et lexicale entre le domaine source et les domaines cibles. La variation lexicale est en
particulier probl&#233;matique dans le cas d&#8217;une langue &#224; la morphologie plus riche que l&#8217;anglais, la
flexion augmentant la dispersion des donn&#233;es lexicales.
</p>
<p>329</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4 Exp&#233;riences et r&#233;sultats
</p>
<p>4.1 Clusters de mots
</p>
<p>Pour calculer les clusters de mots nous utilisons diverses concat&#233;nations de quatre corpus, avec
d&#8217;une part le corpus L&#8217;Est R&#233;publicain d&#233;j&#224; cit&#233; section 2, de 150 millions de tokens, qui va jouer
le r&#244;le de corpus proche du domaine source malgr&#233; des diff&#233;rences manifestes concernant les
sujets trait&#233;s 16. Et d&#8217;autre part, nous utilisons des tron&#231;ons de corpus de m&#234;me origine que les
sous-corpus Sequoia annot&#233;s : Europarl, Wikipedia Fr et domaine m&#233;dical. Cela donne quatre
corpus :
&#8211; ER : 150 millions de tokens L&#8217;Est R&#233;publicain
&#8211; MED : 12 millions de tokens du domaine m&#233;dical, dont 5 millions du corpus EMEA fran&#231;ais 17
</p>
<p>cit&#233; section 2 et 7 millions de tokens provenant du site doctissimo 18.
&#8211; EP : la m&#234;me taille, soit 12 millions de tokens, d&#8217;Europarl fran&#231;ais,
&#8211; FW : et 12 millions de tokens de Wikipedia Fr
Pour le calcul des clusters, les phrases contenues dans le corpus arbor&#233; Sequoia ont &#233;t&#233; retir&#233;es.
</p>
<p>Le corpus ER, en tant que corpus journalistique r&#233;gional, est choisi comme corpus proche du FTB,
malgr&#233; des diff&#233;rences manifestes concernant les sujets trait&#233;s. La concat&#233;nation du corpus ER et
du corpus MED+EP+FW va jouer le r&#244;le de pont lexical entre le domaine source (journalistique)
et les domaines cibles.
</p>
<p>Les corpus bruts ER, MED, EP et FW sont d&#8217;abord pr&#233;trait&#233;s par l&#8217;outil Bonsai (segment&#233;s en
phrases, tokenis&#233;s, et des mots compos&#233;s sont reconnus hors-contexte). Puis nous appliquons le
processus de d&#233;fl&#233;chissement d&#233;crit section 3, pour remplacer chaque forme fl&#233;chie par sa forme
d&#233;fl&#233;chie &#233;quivalente. Le lexique morphologique utilis&#233; est le Lefff(Sagot, 2010).
</p>
<p>Enfin nous calculons des clusters de formes d&#233;fl&#233;chies 19 en utilisant l&#8217;impl&#233;mentation par (Liang,
2005) de l&#8217;algorithme de (Brown et al., 1992) :
&#8211; les clusters source sont obtenus en appliquant l&#8217;outil sur le corpus ER,
&#8211; les clusters pont mixtes sont obtenus sur la concat&#233;nation de ER + MED + EP + FW (soit
</p>
<p>environ 186 millions de tokens).
&#8211; les clusters pont er-med sont obtenus sur la concat&#233;nation de ER + MED uniquement (soit
</p>
<p>environ 162 millions de tokens), pour tester la m&#233;thode avec des clusters plus cibl&#233;s sur le
vocabulaire m&#233;dical.
</p>
<p>Dans les trois cas, le nombre de clusters g&#233;n&#233;r&#233;s est de 1000, et les formes d&#233;fl&#233;chies consid&#233;r&#233;es
sont celles apparaissant au moins 100 fois dans le corpus d&#8217;apprentissage 20.
</p>
<p>16. D&#8217;apr&#232;s les indicateurs de la table 2, c&#8217;est plut&#244;t Europarl qui est le plus proche en termes de vocabulaire.
17. Le corpus fait initialement environ 14 millions de tokens, mais contient &#233;norm&#233;ment de formules r&#233;p&#233;titives. La
</p>
<p>suppression des phrases doublons r&#233;duit sa taille &#224; 5 millions de tokens.
18. Il s&#8217;agit des pages m&#233;dicaments et des pages du glossaire. Le texte est bien form&#233; et proche du corpus EMEA dans
</p>
<p>les th&#233;matiques. Les phrases doublons ont &#233;t&#233; retir&#233;es.
19. Nous avons r&#233;alis&#233; des tests en utilisant des clusters calcul&#233;s sur formes fl&#233;chies (sans le processus de d&#233;fl&#233;chisse-
</p>
<p>ment), ce qui donne syst&#233;matiquement des r&#233;sultats moins bons qu&#8217;en utilisant les clusters sur formes d&#233;fl&#233;chies.
20. Nous avons constat&#233; lors de tests qu&#8217;un seuil plus bas, a peu d&#8217;impact sur les r&#233;sultats. Un seuil de 100 r&#233;duit le
</p>
<p>vocabulaire consid&#233;r&#233; ce qui limite le temps de calcul des clusters.
</p>
<p>330</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4.2 Protocole et exp&#233;riences
</p>
<p>Nous r&#233;alisons ces premiers tests en analyse en constituants sans annotations fonctionnelles.
Tous les traitements (entra&#238;nement d&#8217;analyseur et tests) se font donc sur des versions des corpus
o&#249; les annotations fonctionnelles sont supprim&#233;es 21. Nous utilisons l&#8217;algorithme d&#8217;apprentissage
et d&#8217;analyse de PCFG avec annotations latentes (ci-apr&#232;s PCFG-LA) de (Petrov et Klein, 2007), et
son impl&#233;mentation 22, avec mod&#232;le de lissage pour les mots rares et inconnus adapt&#233; au fran&#231;ais.
</p>
<p>Pour cet algorithme, (Petrov, 2010) montre une variabilit&#233; des r&#233;sultats selon les valeurs al&#233;a-
toires choisies &#224; l&#8217;initialisation de l&#8217;algorithme EM d&#8217;apprentissage des probabilit&#233;s de r&#232;gles
avec annotations latentes. Aussi, nous r&#233;alisons pour chaque exp&#233;rience quatre ex&#233;cutions de
l&#8217;apprentissage, avec quatre graines al&#233;atoires diff&#233;rentes. Tous les apprentissages se font en
utilisant 5 cycles de fission-fusion.
</p>
<p>Pour l&#8217;&#233;valuation des performances, nous utilisons l&#8217;outil Evalb, et fournissons la moyenne des
F-mesures de constituants label&#233;s (moyenne sur les quatre graines al&#233;atoires) pour les phrases de
moins de 40 mots ainsi que pour toutes les phrases.
</p>
<p>Nous utilisons PCFG-LA pour apprendre quatre analyseurs, sur quatre versions du FTB-train (cf.
section 2) diff&#233;rant par les symboles terminaux utilis&#233;s (les feuilles lexicales) :
&#8211; forme fl&#233;chie : les formes fl&#233;chies sont laiss&#233;es telles quelles
&#8211; forme d&#233;fl&#233;chie : chaque forme fl&#233;chie est remplac&#233; par sa forme d&#233;fl&#233;chie &#233;quivalente
&#8211; cluster source : chaque forme d&#233;fl&#233;chie est ensuite remplac&#233;e par son cluster source &#233;quivalent
</p>
<p>(clusters appris sur le corpus ER)
&#8211; cluster pont mixte : idem mais en utilisant les clusters appris sur ER + MED + EP + FW
&#8211; cluster pont er-med : idem mais en utilisant les clusters appris sur ER + MED
</p>
<p>4.3 R&#233;sultats et discussion
</p>
<p>Nous avons r&#233;alis&#233; des tests en comparant les r&#233;sultats sur le FTB et sur le corpus Sequoia.
Plus pr&#233;cis&#233;ment, d&#8217;une part avons consid&#233;r&#233; trois &#8220;domaines&#8221; : le domaine source (FTB), un
domaine tr&#232;s &#233;loign&#233; (domaine m&#233;dical, corpus Emea), et un domaine que nous appelons
neutre, regroupant les autres parties du corpus Sequoia (phrases de Wikip&#233;dia Fr, Europarl et Est
R&#233;publicain). D&#8217;autre part, pour chaque domaine (source, m&#233;dical et neutre) nous avons s&#233;par&#233;
corpus de test pour les tests finaux, et corpus de d&#233;veloppement pour la phase exploratoire, de la
mani&#232;re suivante :
&#8211; domaine source : FTB-dev et FTB-train tels que d&#233;crits note 14
&#8211; domaine m&#233;dical : EMEA-dev et EMEA-train, cf. les colonnes 2 et 3 de la table 2
&#8211; domaine neutre : SequoiaN-dev et SequoiaN-test obtenus en d&#233;coupant en deux chacun des
</p>
<p>sous-corpus annot&#233;s FrWiki, EstRep et Europarl (colonnes 4,5 et 6 table 2). Cela donne 1043
phrases pour SequoiaN-dev et autant pour SequoiaN-test.
</p>
<p>La table 3 fournit les r&#233;sultats obtenus. Dans le cas standard, o&#249; les symboles terminaux sont
simplement les formes fl&#233;chies, on observe sans surprise une nette d&#233;gradation des performances
entre le domaine source (F=83.6) et le domaine m&#233;dical (F=78.5). La d&#233;gradation est nettement
</p>
<p>21. En outre, nous utilisons une instantiation des corpus o&#249; des modifications automatiques de structure ont &#233;t&#233; faites,
comme d&#233;crit dans (Candito et Crabb&#233;, 2009), ceci pour faciliter la conversion en d&#233;pendances de tous les r&#233;sultats
d&#8217;analyse. Les modifications introduisent des syntagmes suppl&#233;mentaires pour les pr&#233;positions introduisant une infinitive
et les compl&#233;tives.
</p>
<p>22. http://code.google.com/p/berkeleyparser
</p>
<p>331</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>moindre pour le domaine &#8220;neutre&#8221; avec F=82.2 pour le corpus SequoiaN-test. L&#8217;apprentissage
sur les phrases du journal Le Monde se g&#233;n&#233;ralise donc assez bien sur ces trois autres types de
corpus (FrWiki, Europarl et Est R&#233;publicain).
</p>
<p>Les r&#233;sultats obtenus avec d&#233;fl&#233;chissement (ligne 2) sont meilleurs dans toutes les configurations.
On note cependant que l&#8217;incr&#233;ment est moindre pour les domaines cibles que pour le domaine
source (les diff&#233;rences restent statistiquement significatives, p &lt; 0.05) 23
</p>
<p>Enfin, les trois derni&#232;res lignes donnent les r&#233;sultats lorsque les formes sont remplac&#233;es par des
clusters. La technique am&#233;liore les r&#233;sultats pour le parsing du domaine source, ce qui confirme
des r&#233;sultats pr&#233;c&#233;dents. Ici nous montrons qu&#8217;elle est valable &#233;galement pour les deux domaines
cibles. Cela constitue donc une technique qui rend plus robuste l&#8217;analyseur, en am&#233;liorant les
performances sur les domaines cibles tout en am&#233;liorant &#233;galement sur le domaine source, au
contraire par exemple de la technique d&#8217;auto-entra&#238;nement.
</p>
<p>En revanche, les trois configurations qui varient selon le corpus utilis&#233; pour le calcul des clusters
offrent peu de variation dans les r&#233;sultats (la plupart des diff&#233;rences entre ces 3 lignes ne sont
pas significatives (p-value &gt; 0.05). Ceci invalide l&#8217;hypoth&#232;se selon laquelle il serait b&#233;n&#233;fique
d&#8217;utiliser un corpus permettant de faire un pont entre le vocabulaire du domaine source et celui
du domaine cible. 24
</p>
<p>Toutes les phrases Phrases de moins de 40 mots
M&#233;dical Neutre Source M&#233;dical Neutre Source
</p>
<p>EMEA-test SequoiaN-test FTB-test EMEA-test SequoiaN-test FTB-test
Nombre de phrases 544 1043 1235 486 919 969
Terminaux
formes fl&#233;chies 78.5 82.2 83.6 80.5 84.4 85.7
</p>
<p>formes d&#233;fl&#233;chies 79.0 83.1 85.0 81.0 85.0 87.4
</p>
<p>clusters source 80.8 84.1 86.0 82.6 86.0 88.3
clusters pont mixtes 80.2 84.4 86.0 82.2 86.3 88.2
clusters pont er-med 80.7 84.1 85.9 82.8 86.1 88.2
</p>
<p>TABLE 3 &#8211; F-mesures calcul&#233;es via evalb, en ignorant la ponctuation, chacune &#233;tant moyenn&#233;e sur
quatre graines al&#233;atoires diff&#233;rentes.
</p>
<p>5 Conclusion
Nous avons pr&#233;sent&#233; le corpus arbor&#233; Sequoia, comportant quatre sous-corpus annot&#233;s syntaxi-
quement en suivant le sch&#233;ma du French Treebank, &#224; quelques exceptions pr&#232;s. Les corpus sont
librement disponibles sous forme de constituants et de d&#233;pendances.
</p>
<p>Nous avons exploit&#233; ces corpus pour &#233;valuer une m&#233;thode d&#8217;adaptation d&#8217;un analyseur statistique
&#224; des domaines autres que celui de son corpus d&#8217;entra&#238;nement, m&#233;thode fond&#233;e sur l&#8217;utilisation
de clusters de mots, propos&#233;e dans une version pr&#233;liminaire de ce travail (Candito et al., 2011).
Nous montrons que cette technique am&#233;liore les performances sur les domaines cibles, tout
en ne d&#233;gradant pas les r&#233;sultats sur le domaine source, contrairement &#224; toutes les techniques
d&#8217;adaptation de parsers statistiques &#224; notre connaissance. En revanche, les tests r&#233;alis&#233;s en faisant
</p>
<p>23. En utilisant l&#8217;outil http://www.cis.upenn.edu/~dbikel/software.html#comparator.
24. Nous contredisons ici les r&#233;sultats publi&#233;s &#224; IWPT (Candito et al., 2011) o&#249; pour le corpus m&#233;dical, les r&#233;sultats
</p>
<p>&#233;taient l&#233;g&#232;rement meilleurs avec les clusters pont er-med. D&#8217;une part le corpus m&#233;dical a l&#233;g&#232;rement &#233;t&#233; modifi&#233; lors de
la phase de v&#233;rification syst&#233;matique d&#8217;erreurs d&#8217;annotation, d&#8217;autre part, il semble que cette am&#233;lioration n&#8217;&#233;tait pas
stable lors des tests avec diff&#233;rentes graines al&#233;atoires.
</p>
<p>332</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>varier le corpus brut sur lequel calculer les clusters ne montrent pas d&#8217;avantage clair &#224; utiliser du
texte brut du domaine cible.
</p>
<p>Remerciements
Nous remercions chaleureusement les trois annotatrices Vanessa Combet, Catherine Moreau-
Mocquay et Virginie Mouilleron pour leur travail tr&#232;s consciencieux. L&#8217;annotation a &#233;t&#233; financ&#233;e
par l&#8217;ANR (projet SEQUOIA ANR-08-EMER-013).
</p>
<p>R&#233;f&#233;rences
</p>
<p>ABEILL&#201;, A. (2004). Annotation fonctionnelle, version du 1er mars 2004. http://www.llf.
cnrs.fr/Gens/Abeille.
</p>
<p>ABEILL&#201;, A. et BARRIER, N. (2004). Enriching a french treebank. In Proc. of LREC&#8217;04, Lisbon,
Portugal.
</p>
<p>ABEILL&#201;, A. et CL&#201;MENT, L. (2006). Annotation morpho-syntaxique, version du 10 nov. 2006.
http://www.llf.cnrs.fr/Gens/Abeille.
</p>
<p>ABEILL&#201;, A., TOUSSENEL, F. et CH&#201;RADAME, M. (2004). Corpus le monde, annotation en consti-
tuants, guide pour les correcteurs, version du 31 mars 2004. http://www.llf.cnrs.fr/
Gens/Abeille.
</p>
<p>BACCHIANI, M., RILEY, M., ROARK, B. et SPROAT, R. (2006). Map adaptation of stochastic
grammars. Computer speech &amp; language, 20(1):41&#8211;68.
</p>
<p>BROWN, P. F., DELLA, V. J., DESOUZA, P. V., LAI, J. C. et MERCER, R. L. (1992). Class-based n-gram
models of natural language. Computational linguistics, 18(4):467&#8211;479.
</p>
<p>CANDITO, M. et CRABB&#201;, B. (2009). Improving generative statistical parsing with semi-supervised
word clustering. In Proceedings of IWPT 2009, pages 138&#8211;141, Paris, France.
</p>
<p>CANDITO, M., CRABB&#201;, B. et DENIS, P. (2010a). Statistical french dependency parsing : Treebank
conversion and first results. In Proceedings of LREC&#8217;2010, Valletta, Malta.
</p>
<p>CANDITO, M., HENESTROZA ANGUIANO, E. et SEDDAH, D. (2011). A word clustering approach to
domain adaptation : Effective parsing of biomedical texts. In Proceedings of IWPT 2011, pages
37&#8211;42, Dublin, Ireland.
</p>
<p>CANDITO, M., NIVRE, J., DENIS, P. et ANGUIANO, E. H. (2010b). Benchmarking of statistical
dependency parsers for french. In Proceedings of COLING 2010, Beijing, China.
</p>
<p>CHARNIAK, E. (2000). A maximum entropy inspired parser. In Proceedings of NAACL 2000, pages
132&#8211;139, Seattle, WA.
</p>
<p>CRABB&#201;, B. et CANDITO, M. (2008). Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais. In
Actes de TALN 2008, pages 45&#8211;54, Avignon, France.
</p>
<p>DENIS, P. et SAGOT, B. (2009). Coupling an annotated corpus and a morphosyntactic lexicon for
state-of-the-art pos tagging with less human effort. In Proc. of PACLIC, Hong Kong, China.
</p>
<p>FOSTER, J. (2010). &#8220;cba to check the spelling&#8221; : Investigating parser performance on discussion
forum posts. In Proceedings of HLT-NAACL 2010, pages 381&#8211;384, Los Angeles, California.
</p>
<p>333</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FOSTER, J., WAGNER, J., SEDDAH, D. et VAN GENABITH, J. (2007). Adapting wsj-trained parsers
to the british national corpus using in-domain self-training. In Proceedings of the Tenth IWPT,
pages 33&#8211;35.
</p>
<p>FRANCIS, W. N. et KUCERA, H. (1964). Manual of Information to accompany A Standard Corpus
of Present-Day Edited American English, for use with Digital Computers. Brown University,
Providence, Rhode Island.
</p>
<p>KOO, T., CARRERAS, X. et COLLINS, M. (2008). Simple semi-supervised dependency parsing. In
Proceedings of ACL-08, pages 595&#8211;603, Columbus, USA.
</p>
<p>LIANG, P. (2005). Semi-supervised learning for natural language. In MIT Master&#8217;s thesis,
Cambridge, USA.
</p>
<p>MARCUS, M., MARCINKIEWICZ, M. et SANTORINI, B. (1993). Building a large annotated corpus of
english : The penn treebank. Computational linguistics, 19(2):313&#8211;330.
</p>
<p>MCCLOSKY, D., CHARNIAK, E. et JOHNSON, M. (2006). Reranking and self-training for parser
adaptation. In Proceedings of COLING-ACL 2006, pages 337&#8211;344, Sydney, Australia.
</p>
<p>MORTON, T. et LACIVITA, J. (2003). Wordfreak : an open tool for linguistic annotation. In
Proceedings of NAACL 2003, Demonstrations, pages 17&#8211;18.
</p>
<p>PAROUBEK, P., POUILLOT, L.-G., ROBBA, I. et VILNAT, A. (2005). Easy : Campagne d&#8217;&#233;valuation des
analyseurs syntaxiques. In Proceedings of TALN&#8217;05, EASy workshop : campagne d&#8217;&#233;valuation des
analyseurs syntaxiques, Dourdan.
</p>
<p>PETROV, S. (2010). Products of random latent variable grammars. In Proceedings of HLT-NAACL
2010, pages 19&#8211;27, Los Angeles, California.
</p>
<p>PETROV, S. et KLEIN, D. (2007). Improved inference for unlexicalized parsing. In Proceedings of
HLT-NAACL 2007, pages 404&#8211;411, Rochester, New York.
</p>
<p>SAGAE, K. (2010). Self-training without reranking for parser domain adaptation and its impact
on semantic role labeling. In Proceedings of the 2010 Workshop on Domain Adaptation for Natural
Language Processing, pages 37&#8211;44, Uppsala, Sweden.
</p>
<p>SAGOT, B. (2010). The Lefff, a freely available and large-coverage morphological and syntactic
lexicon for french. In Proceedings of LREC&#8217;10, Valetta, Malta.
</p>
<p>SEDDAH, D., CANDITO, M. et CRABB&#201;, B. (2009). Cross parser evaluation and tagset variation : a
french treebank study. In Proceedings of IWPT 2009, IWPT &#8217;09, pages 150&#8211;161, Stroudsburg, PA,
USA.
</p>
<p>STEEDMAN, M., HWA, R., CLARK, S., OSBORNE, M., SARKAR, A., HOCKENMAIER, J., RUHLEN, P., BAKER,
S. et CRIM, J. (2003). Example selection for bootstrapping statistical parsers. In Proceedings of
the NAACL 2003, pages 157&#8211;164.
</p>
<p>TIEDEMANN, J. (2009). News from opus - a collection of multilingual parallel corpora with tools
and interfaces. Recent advances in natural language processing V : selected papers from RANLP
2007, 309:237.
</p>
<p>VILLEMONTE DE LA CLERGERIE, E., HAMON, O., MOSTEFA, D., AYACHE, C., PAROUBEK, P. et VILNAT,
A. (2008). Passage : from french parser evaluation to large sized treebank. In Proceedings of
LREC&#8217;2008.
</p>
<p>334</p>

</div></div>
</body></html>