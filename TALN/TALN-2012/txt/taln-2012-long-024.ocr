Le corpus Sequoia : annotation syntaxique et exploitation
pour l’adaptation d’analyseur par pont lexical

Marie Canditol Djamé Seddahlr Z
(1) Alpage (Univ. Paris Diderot 8: INRIA), 175 rue du Chevaleret, 75013 Paris, France
(2) Univ. Paris Sorbonne, 28, rue Serpente, 75006 Paris, France
marie . canditofﬁlinguist . jussieu . fr , dj ame . seddah@paris—sorbon.r1e . fr

RESUME

Nous présentons dans cet article la méthodologie de constitution et les caractéristiques du corpus
Sequoia, un corpus en francais, syntaxiquement annoté d’apres un schéma d’annotation trés
proche de celui du French Treebank (Abeillé et Barrier, 2004), et librement disponible, en
constituants et en dépendances. Le corpus comporte des phrases de quatre origines : Europarl
frangais, le journal l’Est Républicain, Wikipédia Fr et des documents de l’Agence Européenne du
Médicament, pour un total de 3204 phrases et 69246 tokens. En outre, nous présentons une
application de ce corpus : l’évaluation d’une technique d’adaptation d’analyseurs syntaxiques
probabilistes ‘a des domaines et/ou genres autres que ceux du corpus sur lequel ces analyseurs
sont entrainés. Cette technique utilise des clusters de mots obtenus d’abord par regroupement
morphologique a l’aide d’un lexique, puis par regroupement non supervisé, et permet une
nette amélioration de l’analyse des domaines cibles (le corpus Sequoia), tout en préservant
le méme niveau de performance sur le domaine source (le FTB), ce qui fournit un analyseur
multi-domaines, 21 la différence d’autres techniques d’adaptation comme le self-training.

ABSTRACT

The Sequoia corpus : syntactic annotation and use for a parser lexical domain adaptation
method

We present the building methodology and the properties of the Sequoia treebank, a freely
available French corpus annotated following the French Treebank guidelines (Abeillé et Barrier,
2004). The Sequoia treebank comprises 3204 sentences (69246 tokens), from the French Europarl,
the regional newspaper EEst Républicain, the French Wikipedia and documents from the European
Medicines Agency. We then provide a method for parser domain adaptation, that makes use of
unsupervised word clusters. The method improves parsing performance on target domains (the
domains of the Sequoia corpus), without degrading performance on source domain (the French
treenbank test set), contrary to other domain adaptation techniques such as self-training.

MOTS-CLES : Corpus arboré, analyse syntaxique statistique, adaptation de domaine.

KEYWORDS: Treebank, statistical parsing, parser domain adaptation.

1 Introduction

L’analyse syntaxique statistique a fait de grands progrés ces quinze derniéres années, avec de trés
nombreux travaux, majoritairement sur l’anglais, fondés sur un apprentissage sur les sections du

Actes de la con_fe'rence onjointe JEP-TALN-RECITAL 2012, volume 2: TALN, pages 321-334,
Grenoble, 4 an 8 juin 2012. ©2012 ATAI.A 8: AFCP

321

Wall Street Journal du Penn Treebank (Marcus et al., 1993). D’autres langues ont bénéficié de
ces avancées, a la condition, de taille, que soit disponible pour ces langues un corpus arboré, en
constituants ou en dépendances. Cependant, les analyseurs ainsi obtenus, appris sur un corpus
bien précis, ont leur performance maximale sur des textes similaires a ce corpus, mais sont peu
robustes : ils montrent une qualité nettement dégradée lorqu’ils sont évalués sur des textes de
domaine ou genre différents. C’est particuliérement vrai pour l’anglais, car le WSJ montre peu
de variété de themes : (McClosky et al., 2006) rapporte que l’analyseur de Charniak (Charniak,
2000) obtient une F-mesure en constituants labelés de 89.7% sur la section de test du WSJ, mais
chute a 82.9% sur le corpus de test du Brown corpus (Francis et Kucera, 1964), corpus anglais
de genres variés.

Pour le francais, le French Treebank (ci-apres FTB) (Abeillé et Barrier, 2004) a servi de corpus
d’entrainement pour des analyseurs initialement développés pour l’anglais (voir (Seddah et aL,
2009) pour une comparaison de plusieurs analyseurs en constituants, et (Candito et al., 2010b)
pour une comparaison d’analyseurs en dépendances, pour le frangais). Le FTB est un corpus
de phrases du joumal Le Monde, annotées en morphologie et en constituants. Les évaluations
disponibles des analyseurs appris sur le FTB sont dites intra-domaine : elles sont classiquement
faites sur une partie du FTB, non vue ‘a l’apprentissage. Les évaluations dites hors-domaine,
c’est-a-dire simplement sur des phrases d’origine différente de celles du corpus d’apprentissage
se heurtent ‘a l’absence de corpus annotés dans le méme schéma que le FTB. Le corpus EASy
(Paroubek et al., 2005) comprend des phrases de domaines et genres textuels divers, mais son
format mixte entre constituants (chunks) et dépendances (dépendances entre chunks) rend
difﬁcile l’évaluation des performances d’un analyseur en constituants sur ces textes.

Pour cette raison, nous avons entrepris l’annotation syntaxique de quatre corpus en suivant,
‘a quelques exceptions pres, le schéma d’annotation du FTB, regroupés sous le nom de corpus
Sequoia 1. Nous présentons ici la méthodologie d’annotation et les caractéristiques du corpus
arboré obtenu, ainsi que l’application sur ces corpus d’une méthode d’adaptation a de nouveaux
domaines d’un analyseur statistique appris sur le FTB 2. Si l’objectif premier est de pouvoir tester
et améliorer la robustesse d’analyseurs statistiques, ces corpus, librement disponiblesa, sont
utilisables a d’autres ﬁns, en particulier pour des études linguistiques.

Nous décrivons section 2 la méthodologie d’annotation et les caractéristiques du corpus, puis
section 3 la méthode d’adaptation d’analyseur et les travaux antérieurs dans ce domaine, et en
section 4 les expériences réalisées et les résultats obtenus. Enﬁn nous concluons en section 5.

2 Les corpus Sequoia
2.1 Origine et méthode de sélection

Le corpus Sequoia comporte des phrases ou textes de quatre origines différentes : l’agence
européenne du médicament, Europarl, le journal régional l’Est Républicain et Wi.kipedia Fr. Le
choix de ces quatre origines est en par11'e conjoncturel, car lié a la disponibilité des corpus :
nous avons en effet eu le souci que les corpus soient librement disponibles, et qu’ils offrent une

1. Du nom du projet (SEQUOIA ANR-08-EMER-013) ayant ﬁnancé l’annotation manuelle.
2. Cet article étend un anicle court publié 51 IWPT 2011 (Candito et aL, 2011), relatant des expériences d’adaptation
d’analyseurs sur un des quatre sous-corpus aujourd’hui disponibles.
3. https : //www.rocq.inria.fr/a1page-wiki/index.php ?page=CorpusSequoia

322

diversité variable par rapport au genre journalistique du FTB (diversité évaluée a priori, non
précisément). D’autres criteres ont guidé notre choix, comme l’existence d’autres annotations
pour les phrases sélectionnées et la disponibilité de gros volume de corpus brut de méme origine,
en vue d’expériences d’apprenu'ssage semi-supervisé.

2.1. 1 Domaine médical

Nous avons sélectionné le domaine médical comme domaine potentiellement tres éloigné de
celui du FTB. Plus précisément, nous avons retenu deux documents provenant de la partie en
francais du corpus EMEA, lui-méme inclus dans le corpus OPUS ('I'iedemann, 2009) 4.

Le corpus EMEA contient des documents concemant des médicaments, essentiellement des
rapports public d’évaluation (EPAR), chaque rapport étant dédié a la justiﬁcation de l’autorisation
ou l’interdiction de la mise sur le marché d’un médicament. La partie francaise que nous utilisons
contient environ 1000 documents convertis d’un format pdf, et concaténés. Il s’agit pour la
majorité de traductions de versions originales anglaises. D’apres les procédures standards de
l’Agence Européenne du médicament pour les EPARs 5 les documents sont d’abord écrits en
anglais, dans des termes “compréhensibles par quelqu’un qui n’est pas expert du domaine”. Ia
traduction dans les différentes langues ofﬁcielles de l’Union Européenne est gérée par le Centre
de Traduction de l’UE (CdT), avec une terminologie standardisée pour la biomédecine. D’aprés
ce que nous avons pu juger, la traduction est de trés bonne qualité.

Pour l’annotation manuelle, nous avons sélectionné deux EPARs, pour constituer un corpus
de développement et un corpus de test (ci-apres EMEA-dev et EMEA-test). Ces deux sous-
corpus sont particulierement éloignés des phrases journalistiques, pour ce qui est du domaine
(ici médical) et du genre textuel (rapport scientifique). Lexicalement, ils contiennent de la
terminologie spécialisée (protocoles de test et administration de médicaments, descriptions
de maladies, symptomes et contre-indications). Syntaxiquement on peut noter de nombreux
impératifs (pour les instructions d’utilisation), la description de dosages, et un usage fréquent de
précisions apparaissant entre parentheses (gloses de termes savants, abréviations, information
de fréquence).

2.1.2 FrWi.ki

La deuxieme source retenue est la Wikipédia en francais. Nous avons pioché dans le corpus
Wikipedia Fr faisant partie du corpus PASSAGE (Vﬂlemonte De La Clergerie et al., 2008) 5, le texte
correspondant a 19 entrées Wi.kipedia, concernant des “affaires” sociales ou politiques célébres,
pour la plupart récentes. Chaque entrée correspond a une description, en général chronologique,
de l’affaire en question. Ainsi nous obtenons un sous-corpus d’un genre textuel narratif, pour
lequel d’autres annotations existent (PASSAGE).

2.1.3 EstRépub1icain

Le corpus EEst Républicain est un corpus librement disponible au CNRTL 7, rassemblant les articles
de deux années de ce quotidien régional (pour un total de 150 millions de tokens ponctuation

4. opus.1ingﬁl.uu.se/EMEA.php

5. Document 3131, sur : www.ema.europa.eu

6. Les 19 premieres entrées du ﬁchier frwiki_50.txt
7. http ://wvvw.cnrtLfr/corpus/estrepublicain

323

comprise). Nous avons retenu 39 articles, qui sont ceux sélectionnés dans le cadre du projet AN R
ANNODIS 8 dédié ‘a l’annotau'on discursive pour le francais, avec comme critére d’obtenir des
textes intéressants du point de vue discursif.

Avec ce choix, d’une part nous espérons qu’il sera proﬁtable de disposer pour ce corpus a la
fois des annotations syntaxiques et des annotations discursives. D’autIe part, nous obtenons
un sous-corpus dont le domaine est éloigné du FTB. En effet les articles retenus relatent des
informations essentiellement locales (faits divers, inaugurations, ...), ce qui n’est pas le cas du
FTB.

2.1.4 Europarl

Enﬁn, nous avons sélectionné des phrases manuellement annotées dans le cadre du projet
PASSAGE (Villemonte De la Clergerie et al., 2008), en choisissant une sous-partie des phrases
d’Europarl sélectionnées dans le cadre de ce projet.

Trois raisons principales expliquent ce choix : (i) Europarl constitue un corpus trés utilisé en
TAL, un corpus arboré peut en permettre une étude ﬁne; (ii) le type textuel d’Europarl, débat
parlementaire, montre a priori des caractéristiques syntaxiques qui peuvent différer du type
journalistique, ne serait-ce que par exemple le recours fréquent ‘a la premiere personne et au
vocatif, et enﬁn (iii) les phrases choisies ont également été annotées dans le schéma d’annotation
Easy (pour le projet PASSAGE), ce qui peut aider a la conversion de schémas des corpus PASSAGE,
Easy vers FTB et vice-versa.

2.2 Annotation morpho-syntaxique

2.2.1 Schéma d’annotation

Choix linguistiques

Notre objectif est d’obtenir des corpus compaﬁbles avec le FTB, et donc en suivant les choix lin-
guistiques du FTB, caractérisé comme un schéma syntagmatique surfacique, avec des annotations
fonctionnelles pour les dépendants des verbes. Ainsi avons-nous suivi autant que possible les
guides d’annotation du FTB (Abeillé et Clément, 2006; Abeillé et aL, 2004; Abeillé, 2004).

Une exception notable concerne le traitement des mots composés. Pour les composés ni nominaux
ni verbaux, nous nous sommes appuyés sur les composés existants dans le FTB. Pour les composés
verbaux ‘a syntaxe réguliére, nous avons préféré n’en annoter aucun, et privilégier une analyse
syntagmatique. En effet ils sont potentiellement discontinus, et leur notation est alors variable
dans le FTB (par exemple, annotation il est_en_train de... versus il est justement en train de ...).
Concernant les composés nominaux, le FTB contient de nombreuses incohérences (séquences
de méme sémantique parfois codées comme composés, parfois codées par un syntagme), en
particulier pour les composés syntaxiquement réguliers ‘a sémantique tout ou partiellement
compositionnelle 9. Nous avons donc choisi de systématiquement coder syntagmaﬁquement des
séquences syntaxiquement réguliéres (comme N prep N ou NA par exemple), y compris celles
pouvant étre considérées comme des noms composés. Cela a le mérite de l’uniforrnité, mais

8. http ://w3.erss.univ-t1se2.fr/annodis
9. Par exemple pays irLdustrialise’s apparait deux fois comme composé, et 41 fois comme deux mots; tawc d’inte’re‘t
apparaft 80 comme compose’, et 25fo1's comme trois mots.

324

appelle des traitements ultérieurs pour repérer en particulier les cas de composés sémantiquement
non compositionnels.

Format

En ce qui concerne le format, au lieu de reproduire le format XML du FTB, nous avons opté pour
un format certes moins riche mais beaucoup plus souple : un format parenthésé avec une ligne
par phrase syntagmatiquement annotée, qui fournit la catégorie morpho-syntaxique des tokens,
et leur structure syntagmatique. Ce format est celui du PennTreebank, qui s’est imposé comme
format d’apprentissage des analyseurs syntagmatiques probabilistes pour diverses langues et c’est

sous cette forme que nous utilisons le FTB dans nos expériences d’analyse syntaxique probabiliste.

Voici un exemple dans le format en constituants parenthésé, provenant du corpus médical :

( (SENT (PP-MOD (P Aﬁn_de) (VPinf (VN (VH\1'F diminuer)) (NP-OBJ (DET1e) (NC risque) (PP (P de) (NP (ADJ faibles)
(NC valeurs) (PP (P :21’) (NP (NC ACT)))))))) (PONCT ,) (NP-SUJ (DET le) (NC produit) (VPpart (VPP reconstitué)
(COORD (CC et) (VPpart (VPP dj1ué))))) (VN (V doit)) (VPinf-OBJ (VN (VINF étre) (ADV bien) (VPP mé1angé))) (COORD
(CC puis) (VN (V doit)) (VPinf (VN (VINF étre) (VPP adminis11'é)) (PP-MOD (P en) (NP (NC bo1us))) (PP-MOD (P par)
(NP (NC poussée) (AP (ADJ in1raveineuse)) (AP (ADJ rapide)))))) (PONCT .)))

Le jeu de catégories morpho-syntaxiques que nous utilisons est celui mis ou point par (Crabbé
et Candito, 2008), contenant 28 categories, qui correspondent aux combinaisons entre une des
13 catégories grossiéres du FTB et des informations codées dans le FTB sous forme de traits
(essentiellement distinction nom commun, nom propre, mode du verbe). H y a appauvrissement
des annotations par rapport au FTB, pour ce qui est des informations morphologiques. En effet,
si une partie de celles disponibles dans le FTB est encodée dans l’étiquette morpho-syntaxique,
d’autres comme le lemme, le genre et le nombre ne sont pas représentés. En outre, les catégories
des composants de composés n’ont pas été explicitées (un composé est directement codé comme
un seul token, avec ses composants séparés par ’_’). Cet appauvrissement relatif est compensé par
la souplesse d’uti1isation de ce format, et la disponibilité d’outils de visualisation et validation, ce
qui favorise clairement la qualité des annotations, par rapport a une validation faite directement
sur format XML. D’autre part, comme indiqué supra, c’est ce format parenthésé qui est utilisé
pour l’analyse syntaxique probabiliste.

Conversion en dépendances

Le corpus annoté en constituants a été automatiquement converti en dépendances en utilisant
le converﬁsseur développé pour la conversion automatique du FTB (Candito et al., 2010a). Au
ﬁnal, le corpus Sequoia est donc disponible sous deux formes : un format parenthésé annoté en
constituants 1° décoré de fonctions syntaxiques, et un format tabulé CoN1.L 11 pour la version en
dépendances labelées.

2.2.2 Méthodo1ogied’annotaﬁon
Pour obtenir le corpus Sequoia, nous avons procédé en altemant traitements automatiques et

validation de ces traitements pour passer ‘a l’étape suivante. A toutes les étapes (segmentation,
tagging, parsing, annotations des fonctions), les annotations précédentes pouvaient étre remises

10. Plus précisément, deux formats en constituants sont disponibles : le format standard FTE, et un format avec
une représentation modiﬁée des inﬁnitives introduites par des préposiﬁons, et un syntagme supplémentaire dans les
complétives, tel que décrit dans (Candito et Crabbé, 2009). Ces modifications facilitent la conversion en dépendances. La
conversion de1’un vers1’au1re format est automatique.

11. http: //ilk . uvt . nl/conll/#da1:a:Eorma1:

325

en cause. La séquence a été la suivante :

— Prétraitements automatiques : Segmentation en phrases, reconnaissance hors contexte de
composés et tokenisation via l’outil Bonsai 12

— Etiquetage morpho-syntaxique en utilisant le tagger MElt (Denis et Sagot, 2009)

— Validation manuelle en éditeur simple, par un seul annotateur expert, du tagging, de la
segmentation en phrases, et de la reconnaissance de composés

— Pour tous les sous-corpus sauf EMEA : Analyse syntagmatique automatique au moyen de deux
parsers statistiques différents, en guidant les analyseurs avec les tags manuellement validés :
les analyses doivent se conformer aux catégories foumies en entrée. Les analyseurs sont le
parser de Berkeley (Petrov et Klein, 2007) et l’analyseur de Charniak (Charniak, 2000), tous
deux adaptés et entrainés sur le FTB. Pour EMEA : la validation syntaxique a été faite par un
annotateur expert.

— Validation manuelle indépendante des deux sorties d’analyseurs, via l’outil graphique Word-
Freak (Morton et LaCivita, 2003) adapté pour le tagset et le jeu de fonctions du FTB, puis
adjudication.

— Annotation automatique des fonctions des dépendants des verbes ﬁnis, en uti1isantl’annotateur
en fonctions intégré a Bonsai

— Validation manuelle des annotations fonctionnelles par deux annotateurs indépendamment,
via WordFreak, puis adjudiction.

— Vériﬁcations systématiques par un expert de points repérés comme difficiles 13 ; vériﬁcation
systématique de la cohérence du traitement des composés.

2.2.3 Evaluation de1’annotal1'on

Pour évaluer l’accord inter-annotateurs, et la distance au corpus de référence aprés adjudication
et Vériﬁcations systématiques, nous utilisons l’outil Evalb servant habituellement ‘a l’évaluation
des sorties d’un analyseur par rapport a des analyses de référence. Pour les sous-corpus Europarl,
EstRépublicain et FrWiki, nous fournissons table 1 l’accord deux ‘a deux entre trois résultats
d’annotations : l’annotation A, l’annotation B et le résultat de l’adjudication de A et B plus
vériﬁcation. La mesure utilisée est la moyenne harmonique (F-mesure) entre la précision et
le rappel en constituants labelés. Nous avons dﬁ contourner le probleme de tokenisations
divergentes, ou une séquence de tokens analysée comme un mot composé dans un des ﬁchiers et
pas dans l’autre. Par exemple la séquence en fait peut avoir été codée (ADV en_fait) d’un coté
et (CLO en) (V fait) de l’autre. Pour résoudre ce probleme, nous transformons les annotations
avant l’évaluation de l’accord : tous les composés sont transformés en structure contenant les
composants, avec une catégorie unique pour les composants. Pour notre exemple ’(ADV en_fait)’
est transformé en (ADV (Z en) (2 fait)). Ainsi les divergences de tokenisation non seulement ne
bloquent pas evalb, mais sont en outre prises en compte dans l’évaluation.

L’évaluation montre des résultats assez satisfaisants pour Europarl et EstRépu, avec une nette
amélioration lors de l’évaluation avec la référence. Pour FrWi.ki, l’accord entre les deux annota-
tions simples est bas : il est comparable avec les résultats obtenus par l’analyseur sur le domaine
neutre (section 4). C’est en effet par ce corpus que l’annotation a commencé. On voit ici que la
phase de formation est longue. Sachant cela, la vériﬁcation pour ce corpus a été plus poussée.

12. http ://a1page.inria.fr/statgram/frdep/fr_stat_dep_parsing.htrn1

13. Em:re autres : les clivées versus relatives, le causatif, les complétives en de objet direct versus oblique (de-obj), le
repérage d’incohérences comme par exemple des verbes ﬁnis sans sujet.

326

Annotations A vs. B Annotation A vs. référence Annotation B vs. référence
FrWi.ki 83.96 91.59 88.64
Europarl 90.14 94.20 92.26
EstRépu 90.45 94.22 93.72

TABLE 1 — Evaluation deux a deux (moyenne des F-mesures) des annotations simple A, simple B
et de la référence (aprés adjudication de A et B et vériﬁcations systématiques).

2.3 Caractéristiques

La table 2 fournit les caractéristiques des différents corpus annotés, en regard de celle des corpus
de développement et d’entrainement du FTB (FTB-dev et FTB-train) utilisés pour les expériences
(section 4) 14.

Corpus Sequoia FTB
Médical Neutre
EMEA EMEA Est Euro Fr
dev test Rép. Parl Wild dev train

Nb de phrases 574 544 529 561 996 1235 9881
Longueur moyenne 16,3 22,0 21,0 26,3 22,2 29,6 28,1
Ecart type sur la longueur 14,7 15,0 12,9 15,0 18,0 16,0 16,5
Données pour tout type de formes ﬂéchies (ponctuation y compris)

Taille du vocabulaire 1916 1737 3337 3300 4687 7222 24110
% d’inconnus 41.4 35.8 29,2 20,6 34,2 22,5 -
Nb d’occ. 9343 1 1964 1 1 1 14 14745 22080 36508 278083
% d’occ. d’inconnus 23.0 19.7 1 1,2 6,6 12,9 5,2 -

% d’occ. de Noms propres 1,7 2.7 5,1 2,9 9,7 4,1 4,0
Données pour les formes alphanumériques minusculisés

Taille du vocabulaire 1695 1599 3173 3165 4410 6904 22526
% d’inconnus 36.6 34.0 28,0 20,1 32,6 21,6 -
Nb d’occ. 8107 10451 9552 13073 18619 30940 235105
% d’occ. d’inconnus 23.2 20.9 12,1 7,0 13,8 5,7 -

TABLE 2 — Caractéristiques chiffrées des corpus manuellement annotés. Les inconnus sont les
formes absentes du FTB-train.

Les différents nouveaux corpus ont chacun environ 500 phrases, sauf FrWiki (961 phrases). Si la
longueur moyenne des phrases varie nettement entre les différents corpus, on peut noter une
grande variance. Ce sont les phrases du FTB qui sont les plus longues en moyenne (29, 6 pour

14. Pour comparabﬂité avec nos résultats arttérieurs, nous utilisons la partie du FTB armotée en fonctions grammaticales,
telle que distribuée en 2007, qui contient 12351 phrases. la version actuellement disponible du FTE contient environ
4000 phrases upplémentaires. Nous utilisons 1e découpage iuitialement proposé par (Crabbe et Cartdito, 2008) en corpus
de test (1235 premieres phrases), corpus de développement (1235 phrases suivantes) et 9881 phrases restantes comme
corpus d’apprentissage. Le corpus original XML est prétraité tel que décrit darts (Cartdito et Crabbe, 2009). En particulier
les composés nominaux et verbaux syntaxiquement réguliers sont défaits et représentés syntagmatiquement, et chaque
occurrence de composé restante traitée comme un seul token (par exemple (N (P £1) (N cause) (P de)) est remplacé par
(N z‘1_cause_de)).

327

FTB-deV et 28, 1 pour FTB-train), devant méme Europarl (26, 3).

La table fournit également la taille des vocabulaires (de formes ﬂéchies), et en leur sein la
proportion de formes qui sont absentes du FTB-train. Nous foumissons les chiffres calculés
en utilisant tous les tokens (y compris la ponctuation) ainsi que ceux calculés sur les tokens
alphanumériques minusculisés 15, pour mieux évaluer la diversité lexicale. On peut constater que
le corpus médical comporte de loin le vocabulaire le plus éloigné de celui du FTB (plus d’une
forme sur 1Iois est absente du FTB-train). Pour le corpus EMEA-dev, la proportion d’inconnus en
comptant tous les types de formes ﬂéchies est tres haute, du fait d’un grand nombre de mots
entierement capitalisés (la proportion passe de 41, 4 ‘a 36, 6 en ignorant la ponctuation et en
minusculisant). Pour le corpus FrWiki, la forte proportion d’inconnus (34, 2%) peut s’expliquer
par une grande fréquence des noms propres (cf. la ligne % d’occurrences de noms propres : environ
une occurrence sur 10 est un nom propre dans FrWi.ki).

Les lignes sur les nombres d’occurrences et le pourcentage d’inconnus parmi ces occurrences
donnent une vision plus précise de la diversité lexicale des corpus. Dans les corpus médicaux, une
occurrence sur 5 (et presque une sur 4 pour EMEA-dev) correspond a un inconnu du FTB-train,
ce qui, avec la faible proportion d’occurrences de noms propres (1, 7 et 2, 7) indique que les mots
inconnus sont plutot des mots fréquemment utilisés dans ces corpus. Au contraire, pour FrWi.ki
on voit que, calculée sur les occurrences, la proportion d’inconnus tombe a 12,9 (la majorité
des inconnus du vocabulaire sont des noms propres, apparaissant rarement). Le corpus le plus
proche lexicalement du FTB semble étre Europarl : seulement 6, 6% des occurrences sont des
inconnus, formant un cinquiéme du vocabulaire, ce qui constitue moins d’occurrences d’inconnus
que dans le FTB-deV.

3 Adaptation de domaine par pont lexical

Notre objectif est d’explorer une méthode d’amélioration des performances d’un analyseur
statistique sur des textes d’origine différente de celle du corpus d’entrainement de l’analyseur, les
différences pouvant relever du domaine et/ou du genre des textes. Pour simpliﬁer, nous utilisons
par la suite les termes domaine source pour les caractéristiques (domaine, genre, registre) du
corpus d’entrainement, domaines cibles pour celles des textes d’origine différente et analyse
hors-domaine pour l’analyse de textes des domaines cibles.

Pour améliorer l’analyse hors-domaine, nous proposons d’adapter une technique testée au départ
pour le parsing intra-domaine. S’inspirant de l’utilisation par (Koo et al., 2008) de clusters de
mots comme traits d’un analyseur discriminatif en dépendances, (Candito et Crabbé, 2009)
ont proposé une technique qui, en réduisant la dispersion des données lexicales, améliore les
performances de parsing intra-domaine. Ils entrainent un analyseur statistique sur un corpus
o1‘1les mots sont remplacés par des identiﬁants de clusters de mots, obtenus de maniere non
supervisée sur un corpus brut de grande taille. Le parsing se fait ensuite de la méme maniere,
en remplacant chaque mot par leur cluster correspondant, de maniere déterministe et non
contextuelle, puis en réinsérant les tokens originaux pour obtenir les sorties d’analyse.

Plus précisément, le regroupement de formes ﬂéchies en clusters se fait en deux étapes :
— Les formes ﬂéchies sont d’abord groupées en clusters morphologiques via un lexique morpholo-
gique. Il s’agit de ramener un ensemble de formes ﬂéchies a une forme canonique, dite forme

15. Plus précisément les tokens comportant au moins une lettre ou un chiffre, et ramenés £1 une forme minusculisée.

328

de’fle’chie, avec comme principe de conserver exactement la méme ambiguité de catégories
morpho-syntaxiques (contrairement par exemple a une lemmatisation). On veut en effet délé-
guer la désambiguisation de categories ‘a l’analyseur, et ne pas trancher par pré-traitement.
Pour cela, pour une forme donnée, on récupere la liste de ses catégories recensées dans le
dictionnaire, puis, tant que cette liste de catégories ne varie pas, le pluriel est ramené au
singulier, le féminin au masculin, et pour les formes verbales conjuguées non ambigues, les
personnes, mode et temps verbaux sont ramenées ‘a la deuxieme personne présent pluriel
(moyen rapide de trouver une forme n’introduisant pas de nouvelles ambiguités). Par exemple,
analysées est ramené ‘a analyse’, mais entrées est ramené a entrée, de maniere ‘a conserver
l’ambigu'ité nom/participe. Toutes les formes ﬁnies de augmenter sont ramenées a augmentez,
mais par exemple joue est inchangé pour préserver son ambiguité catégorielle.

— Ensuite un algorithme de clustering non supervisé (Brown et al., 1992) est appliqué sur gros
corpus préalablement segmenté en phrases, tokenisé et déﬂéchi (i.e. o1‘1 les formes ﬂéchies sont
remplacées par leur forme déﬂéchie correspondante). On obtient ainsi des clusters de formes
déﬂéchies. I1 s’agit d’un algorithme hiérarchique et agglomératif, o1‘1le critere de fusion de
deux clusters est la perte minimale de vraisemblance dans un modéle bigramme de séquences
de clusters.

Dans cet anicle, nous adaptons cette technique au probléme spéciﬁque de la non robustesse des
analyseurs statistiques, en utilisant des clusters de mots appris sur la concaténation de corpus du
domaine source (ou proche du domaine source) et des domaines cibles. 1.’objectif est d’obtenir
que soient groupés sous le méme cluster des mots appartenant au domaine source et des mots
appartenant aux domaines cibles, de facon a réaliser un pont entre les vocabulaires respectifs de
ces domaines (d’o1‘1le nom d’adaptau'on a de nouveaux domaines par “pont lexical”).

3.1 Travaux antérieurs reliés

Différentes techniques ont été proposées pour adapter des modeles d’analyse existants ‘a de

nouveaux genres :

— Adaptation au domaine via de l’auto-entrainement (self-training) (Bacchiani et al., 2006;
McClosky et al., 2006; Sagae, 2010) : un analyseur entrainé sur le domaine source est utilisé
pour analyser du domaine cible, et on réentraine un analyseur sur les données validées source
et les données prédites cibles. Le corpus d’entrainement ainsi obtenu, bien que bruité, capture
sufﬁsamment de régularités du domaine cible pour améliorer les performances d’analyse sur
ce domaine (tout en dégradant les performances sur le domaine source) ;

— co-entrainement avec sélection d’exemples (Steedman et al., 2003) : deux analyseurs sont
itérativement re-entrainés sur leurs sor11'es respeclives, les phrases du domaine cible a uﬁliser
étant choisies de maniere a minimiser les erreurs d’analyse tout en maximisant l’utilité ‘a
l’entrainement ;

— transformation de treebank et adaptation du domaine cible (Foster, 2010) ;

— adaptation méticuleuse du domaine cible a la source d’entrainement (Foster et al., 2007) ;

Bien que différentes, les techniques ici évoquées sont toutes concues pour combler la variation

syntaxique et lexicale entre le domaine source et les domaines cibles. La variation lexicale est en

particulier problématique dans le cas d’une langue a la morphologie plus riche que l’anglais, la
ﬂexion augmentant la dispersion des données lexicales.

329

4 Expériences et résultats
4.1 Clusters de mots

Pour calculer les clusters de mots nous utilisons diverses concaténations de quatre corpus, avec

d’une part le corpus L’Est Républicain déja cité section 2, de 150 millions de tokens, qui va jouer

le r6le de corpus proche du domaine source malgré des différences manifestes concernant les

sujets traités 15. Et d’autre part, nous utilisons des troncons de corpus de méme origine que les

sous-corpus Sequoia annotés : Europarl, Wikipedia Fr et domaine médical. Cela donne quatre

corpus :

— ER : 150 millions de tokens L’Est Républicain

— MED : 12 millions de tokens du domaine médical, dont 5 millions du corpus EMEA francais 17
cité section 2 et 7 millions de tokens provenant du site doctissimo 18.

— EP : la méme taille, soit 12 millions de tokens, d’Europarl francais,

— FW : et 12 millions de tokens de Wikipedia Fr

Pour le calcul des clusters, les phrases contenues dans le corpus arboré Sequoia ont été retirées.

Le corpus ER, en tant que corpus journalistique régional, est choisi comme corpus proche du FTB,
malgré des différences manifestes concernant les sujets traités. La concaténation du corpus ER et
du corpus MED+EP+FW va jouer le role de pont lexical entre le domaine source (journalistique)
et les domaines cibles.

Les corpus bruts ER, MED, EP et FW sont d’abord prétraités par l’outil Bonsai (segmentés en
phrases, tokenisés, et des mots composés sont reconnus hors-contexte). Puis nous appliquons le
processus de déﬂéchissement décrit section 3, pour remplacer chaque forme ﬂéchie par sa forme
déﬂéchie équivalente. Le lexique morphologique utilisé est le Leﬂf(Sagot, 2010).

Enﬁn nous calculons des clusters de formes déﬂéchies 19 en utilisant l’implémentation par (Liang,

2005) de l’algorithme de (Brown et al., 1992) :

— les clusters source sont obtenus en appliquant l’outil sur le corpus ER,

— les clusters pont mixtes sont obtenus sur la concaténation de ER + MED + EP + FW (soit
environ 186 millions de tokens).

— les clusters pont er-med sont obtenus sur la concaténation de ER + MED uniquement (soit
environ 162 millions de tokens), pour tester la méthode avec des clusters plus ciblés sur le
vocabulaire médical.

Dans les trois cas, le nombre de clusters générés est de 1000, et les formes déﬂéchies considérées

sont celles apparaissant au moins 100 fois dans le corpus d’apprentissage 2°.

16. D’aprés les indicateurs de la table 2, c’est plutét Europarl qui est le plus proche en tennes de vocabulaire.

17. Le corpus fait initialement environ 14 millions de tokens, mais contient énorrnément de forrnules répétitives. La
suppression des phrases doublons réduit sa taille a 5 millions de tokens.

18. I1 s’agit des pages médicaments et des pages du glossaire. Le texte est bien forrné et proche du corpus EMEA dans
les thématiques. Les phrases doublons ont été retirées.

19. Nous avons réalisé des tests en utilisant des clusters calculés sur formes ﬂéchies (sans le processus de déﬂéchisse-
ment), ce qui donne systérnatiquement des résultats moins bons qu’en utilisant les clusters sur formes déﬂéchies.

20. Nous avons constaté lors de tests qu’un seuil plus has, a peu d’impact sur les résultats. Un seuil de 100 réduit le
vocabulaire considéré ce qui limite le temps de calcul des clusters.

330

4.2 Protocole et expériences

Nous réalisons ces premiers tests en analyse en constituants sans annotations fonctionnelles.
Tous les traitements (entrainement d’analyseur et tests) se font donc sur des versions des corpus
o1‘1 les annotations fonctionnelles sont supprimées 21. Nous utilisons l’algorithme d’apprentissage
et d’analyse de PCFG avec annotations latentes (ci-aprés PCFG-LA) de (Petrov et Klein, 2007), et
son implémentation 22, avec modéle de lissage pour les mots rares et inconnus adapté au francais.

Pour cet algorithme, (Petrov, 2010) montre une variabilité des résultats selon les valeurs aléa-
toires choisies ‘a l’init1'alisation de l’algorithme EM d’apprentissage des probabilités de regles
avec annotations latentes. Aussi, nous réalisons pour chaque expérience quatre exécutions de
l’apprentissage, avec quatre graines aléatoires différentes. Tous les apprentissages se font en
utilisant 5 cycles de ﬁssion-fusion.

Pour l’évaluation des performances, nous utilisons l’outil Evalb, et fournissons la moyenne des
F-mesures de constituants labelés (moyenne sur les quatre graines aléatoires) pour les phrases de
moins de 40 mots ainsi que pour toutes les phrases.

Nous utilisons PCFG-LA pour apprendre quatre analyseurs, sur quatre versions du FTB-train (cf.
section 2) différant par les symboles terminaux utilisés (les feuilles lexicales) :

— forme ﬂéchie : les formes ﬂéchies sont laissées telles quelles

— forme déﬂéchie : chaque forme ﬂéchie est remplacé par sa forme déﬂéchie équivalente

— cluster source : chaque forme déﬂéchie est ensuite remplacée par son cluster source équivalent

(clusters appris sur le corpus ER)
— cluster pont mixte : idem mais en utilisant les clusters appris sur ER + MED + EP + FW
— cluster pont er-med : idem mais en utilisant les clusters appris sur ER + MED

4.3 Résultats et discussion

Nous avons réalisé des tests en comparant les résultats sur le FTB et sur le corpus Sequoia.

Plus précisément, d’une part avons considéré trois “domaines” : le domaine source (FTB), un

domaine tres éloigné (domaine médical, corpus Emea), et un domaine que nous appelons

neutre, regroupant les autres parties du corpus Sequoia (phrases de Wikipédia Fr, Europarl et Est

Républicain). D’autre part, pour chaque domaine (source, médical et neutre) nous avons séparé

corpus de test pour les tests ﬁnaux, et corpus de développement pour la phase exploratoire, de la

maniére suivante :

— domaine source : FTB-deV et FTB-train tels que décrits note 14

— domaine médical : EMEA-dev et EMEA-train, cf. les colonnes 2 et 3 de la table 2

— domaine neutre : SequoiaN-dev et SequoiaN-test obtenus en découpant en deux chacun des
sous-corpus annotés FrWi.ki, EstRep et Europarl (colonnes 4,5 et 6 table 2). Cela donne 1043
phrases pour SequoiaN-dev et autant pour SequoiaN-test.

La table 3 foumit les résultats obtenus. Dans le cas standard, o1‘1les symboles terminaux sont
simplement les formes ﬂéchies, on observe sans surprise une nette dégradation des performances
entre le domaine source (F=83.6) et le domaine médical (F=78.5). La dégradation est nettement

21. En outre, nous utilisons une instantiation des corpus o1‘.1 des modiﬁcations automatiques de structure ont été faites,
comme décrit dans (Candito et Crabbe, 2009), ceci pour faciliter la conversion en dépendances de tous les résultats
d’analyse. Les modiﬁcations introduisent des syntagmes up; lémentait es pour les prépositions introduisant une inﬁnitive
et les compléﬁves.

22. http: //code . google . com/p/berkeleyparser

331

moindre pour le domaine “neutre” avec F=82.2 pour le corpus SequoiaN-test. L’apprentissage
sur les phrases du journal Le Monde se généralise donc assez bien sur ces trois autres types de
corpus (FrWiki, Europarl et Est Républicain).

Les résultats obtenus avec déﬂéchissement (ligne 2) sont meilleurs dans toutes les conﬁgurations.
On note cependant que l’incrément est moindre pour les domaines cibles que pour le domaine
source (les différences restent statistiquement signiﬁcatives, p < 0.05) 23

Enﬁn, les trois derniéres lignes donnent les résultats lorsque les formes sont remplacées par des
clusters. La technique améliore les résultats pour le parsing du domaine source, ce qui conﬁrme
des résultats précédents. Ici nous montrons qu’e]le est valable également pour les deux domaines
cibles. Cela constitue donc une technique qui rend plus robuste l’analyseur, en améliorant les
perforrnances sur les domaines cibles tout en améliorant également sur le domaine source, au
contraire par exemple de la technique d’auto-entrainement.

En revanche, les trois conﬁgurations qui varient selon le corpus utilisé pour le calcul des clusters
offrent peu de variation dans les résultats (la plupart des differences entre ces 3 lignes ne sont
pas signiﬁcatives (p-value > 0.05). Ceci invalide l’hypothese selon laquelle il serait bénéﬁque
d’utiliser un corpus permettant de faire un pont entre le vocabulaire du domaine source et celui
du domaine cible. 24

111013

Neutre Neutre
EMEA-test SequoiaN-test FTB-test EMEA-test SequoiaN-test Fm-test
544 1043 1235 486 919 969

7

source

 

TABLE 3 — F-mesures calculées via evalb, en ignorant la ponctuation, chacune étant moyennée sur
quatre graines aléatoires différentes.

5 Conclusion

Nous avons présenté le corpus arboré Sequoia, comportant quatre sous-corpus annotés syntaxi-
quement en suivant le schéma du French Treebank, a quelques exceptions prés. Les corpus sont
librement disponibles sous forme de constituants et de dépendances.

Nous avons exploité ces corpus pour évaluer une méthode d’adaptation d’un analyseur statistique
a des domaines autres que celui de son corpus d’entrainement, méthode fondée sur l’utilisation
de clusters de mots, proposée dans une version préliminaire de ce travail (Candito et al., 2011).
Nous montrons que cette technique améliore les performances sur les domaines cibles, tout
en ne dégradant pas les résultats sur le domaine source, contrairement ‘a toutes les techniques
d’adaptation de parsers statistiques a notre connaissance. En revanche, les tests réalisés en faisant

23. En utilisant1’outi1 http : //www . cis . upenn . edu/“dbikel/software . h1:ml#compara1:or.

24. Nous contredisons ici les résultats publiés 51 IWPT (Candito et aL, 2011) ou pour le corpus médical, les résultats
étaient légerement meilleurs avec les clusters pont er-med. D’une part le corpus médical a légérement été modjfié lors de
la phase de vériﬁcaﬁon systémaﬁque d’erreurs d’annota11'on, d’au1Ie part, i1 semble que cette amélioration n’était pas
stable lors des tests avec différentes graines aléatoires.

332

varier le corpus brut sur lequel calculer les clusters ne montrent pas d’avantage clair a utiliser du
texte brut du domaine cible.

Remerciements

Nous remercions chaleureusement les trois annotatrices Vanessa Combet, Catherine Moreau-
Mocquay et Virginie Mouilleron pour leur travail trés consciencieux. L’annotation a été ﬁnancée
par l’ANR (projet SEQUOIA ANR-08-EMER-013).

Références

ABEILLE, A. (2004). Annotation fonctionnelle, version du 1er mars 2004. http://www.11f .

cnrs . fr/Gens/Abeille.

ABEILLE, A. et BARRIER, N. (2004). Enriching a french treebank. In Proc. of LREC’04, Lisbon,
Portugal.

ABEILLE, A. et CLEMENT, L. (2006). Annotation morpho-syntaxique, version du 10 nov. 2006.
http : //www . llf . cnrs . fr/Gens/Abeille.

ABEILLE, A., TOUSSENEL, E et CHERADAME, M. (2004). Corpus le monde, annotation en consti-
tuants, guide pour les correcteurs, version du 31 mars 2004. http://www.11f . cnrs .fr/
Gens/Abeille.

BACCHIANI, M., RILEY, M., RoARK, B. et SPROAT, R. (2006). Map adaptation of stochastic
grammars. Computer speech & language, 20(1):41—68.

BRowN, P. F., DELLA, V J., DESOUZA, P. V, LA1, J. C. et MERCER, R. L. (1992). Class-based n-gram
models of natural language. Computational linguistics, 18(4):467479.

CANDITO, M. et CRABBE, B. (2009). Improving generative statistical parsing with semi-supervised
word clustering. In Proceedings of IVVPT 2009, pages 138-141, Paris, France.

CANDITO, M., CRABBE, B. et DENIS, P (2010a). Statistical french dependency parsing : Treebank
conversion and ﬁrst results. In Proceedings of LREC’2010, Valletta, Malta.

CANDITO, M., HENESTROZA ANGUIANO, E. et SEDDAH, D. (2011). A word clustering approach to
domain adaptation : Effective parsing of biomedical texts. In Proceedings of IWPT 201 1 , pages
37-42, Dublin, Ireland.

CANDITO, M., NIVRE, J., DENIS, P. et ANGUIANO, E. H. (2010b). Benchmarking of statistical
dependency parsers for french. In Proceedings of COLING 2010, Beijing, China.

CHARNIAK, E. (2000). A maximum entropy inspired parser. In Proceedings of NAAC1 2000, pages
132-139, Seattle, WA.

CRABBE, B. et CANDITO, M. (2008). Experiences d’analyse syntaxique statistique du francais. In
Actes de TALN 2008, pages 45-54, Avignon, France.

DENIS, P et SAGOT, B. (2009). Coupling an annotated corpus and a morphosyntactic lexicon for
state-of-the-art pos tagging with less human effort. In Proc. of PACLIC, Hong Kong, China.

FOSTER, J. (2010). “cba to check the spelling” : Investigating parser performance on discussion
forum posts. In Proceedings of HL'11NAACL 2010, pages 381-384, Los Angeles, California.

333

FOSTER, J., WAGNER, J., SEDDAH, D. et VAN GENABITH, J. (2007). Adapting wsj-trained parsers
to the british national corpus using in-domain self-training. In Proceedings of the Tenth IWPT,
pages 33-35.

FRANCIS, W. N. et KUCERA, H. (1964). Manual of Information to accompanyA Standard Corpus
of Present-Day Edited American English, for use with Digital Computers. Brown University,
Providence, Rhode Island.

KOO, T., CARRERAS, X. et COLLINS, M. (2008). Simple semi-supervised dependency parsing. In
Proceedings ofACL-08, pages 595-603, Columbus, USA.

LIANG, P. (2005). Semi-supervised learning for natural language. In MIT Master’s thesis,
Cambridge, USA.

MARCUS, M., MARCINKIEWICZ, M. et SANTORINI, B. (1993). Building a large annotated corpus of
english : The penn treebank. Computational linguistics, 19(2) :313—330.

MCCLOSKY, D., CHARNIAK, E. et JOHNSON, M. (2006). Reranking and self-training for parser
adaptation. In Proceedings of COLING-ACL 2006, pages 337-344, Sydney, Australia.

MORTON, T. et LACIVITA, J. (2003). Wordfreak : an open tool for linguistic annotation. In
Proceedings of NAACL 2003, Demonstrations, pages 17-18.

PAROUBEK, R, POUILLOT, L.-G., ROBBA, I. et VILNAT, A. (2005). Easy : Campagne d’évaluation des
analyseurs syntaxiques. In Proceedings of TALN’05, EASy workshop : campagne d’e’valuation des
analyseurs syntaxiques, Dourdan.

PETROV, S. (2010). Products of random latent variable grammars. In Proceedings of HLT-NAACL
2010, pages 19-27, Ios Angeles, California.

PETROV, S. et KLEIN, D. (2007). Improved inference for unlexicalized parsing. In Proceedings of
HLT-NAACL 2007, pages 404-411, Rochester, New York.

SAGAE, K. (2010). Self-training without reranking for parser domain adaptation and its impact
on semantic role labeling. In Proceedings of the 2010 Workshop on Domain Adaptation for Natural
Language Processing, pages 37-44, Uppsala, Sweden.

SAGOT, B. (2010). The Lejﬁ‘, a freely available and large-coverage morphological and syntactic
lexicon for french. In Proceedings of LREC’1 0, Valetta, Malta.

SEDDAI-I, D., CANDITO, M. et CRAEEE, B. (2009). Cross parser evaluation and tagset variation : a
french treebank study. In Proceedings of IWPT 2009, IWPT ’09, pages 150-161, Stroudsburg, PA,
USA.

STEEDMAN, M., HwA, R., CLARK, S., OSBORNE, M., SARKAR, A., HOCKENMAIER, J., RUHLEN, R, BAKER,
S. et CRIM, J . (2003). Example selection for bootstrapping statistical parsers. In Proceedings of
the NAACL 2003, pages 157-164.

TIEDEMANN, J. (2009). News from opus - a collection of multilingual parallel corpora with tools
and interfaces. Recent advances in natural language processing V: selected papers from RANLP
2007, 309:237.

VILLEMONTE DE LA CLERGERIE, E., HAMON, 0., MOSTEFA, D., AYACHE, C., PAROUBEK, P. et VILNAT,
A. (2008). Passage : from french parser evaluation to large sized treebank. In Proceedings of
LREC’2008.

334

