<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Vers un d&#233;codage guid&#233; pour la traduction automatique</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Vers un d&#233;codage guid&#233; pour la traduction automatique
</p>
<p>Benjamin Lecouteux et Laurent Besacier
Laboratoire d&#8217;Informatique de Grenoble (LIG), Universit&#233; de Grenoble
benjamin.lecouteux@imag.fr, laurent.besacier@imag.fr
</p>
<p>R&#201;SUM&#201;
R&#233;cemment, le paradigme du d&#233;codage guid&#233; a montr&#233; un fort potentiel dans le cadre de la
reconnaissance automatique de la parole. Le principe est de guider le processus de d&#233;codage via
l&#8217;utilisation de transcriptions auxiliaires. Ce paradigme appliqu&#233; &#224; la traduction automatique per-
met d&#8217;envisager de nombreuses applications telles que la combinaison de syst&#232;mes, la traduction
multi-sources etc. Cet article pr&#233;sente une approche pr&#233;liminaire de l&#8217;application de ce paradigme
&#224; la traduction automatique (TA). Nous proposons d&#8217;enrichir le mod&#232;le log-lin&#233;aire d&#8217;un syst&#232;me
primaire de TA avec des mesures de distance relatives &#224; des syst&#232;mes de TA auxiliaires. Les
premiers r&#233;sultats obtenus sur la t&#226;che de traduction Fran&#231;ais/Anglais issue de la campagne
d&#8217;&#233;valuation WMT 2011 montrent le potentiel du d&#233;codage guid&#233;.
</p>
<p>ABSTRACT
Driven Decoding for machine translation
</p>
<p>Recently, the concept of driven decoding (DD), has been sucessfully applied to the automatic
speech recognition (speech-to-text) task : an auxiliary transcription guide the decoding process.
There is a strong interest in applying this concept to statistical machine translation (SMT). This
paper presents our approach on this topic. Our first attempt in driven decoding consists in adding
several feature functions corresponding to the distance between the current hypothesis decoded
and the auxiliary translations available. Experimental results done for a french-to-english machine
translation task, in the framework of the WMT 2011 evaluation, show the potential of the DD
approach proposed.
</p>
<p>MOTS-CL&#201;S : D&#233;codage guid&#233;, traduction automatique, combinaison de syst&#232;mes.
KEYWORDS: Driven Decoding, machine translation, system combination.
</p>
<p>1 Introduction
</p>
<p>Le concept du d&#233;codage guid&#233; (Lecouteux et al., 2012, 2013) a montr&#233; un fort potentiel dans le
cadre de la reconnaissance automatique de la parole. Le principe est de guider le processus de
d&#233;codage via l&#8217;utilisation de transcriptions auxiliaires. Ce paradigme appliqu&#233; &#224; la traduction au-
tomatique permet d&#8217;envisager de nombreuses applications telles que la combinaison de syst&#232;mes,
la traduction multi-sources (&#224; partir de diff&#233;rentes langues, ou &#224; partir de sorties de diff&#233;rents
syst&#232;mes de reconnaissance de la parole dans le cas de la traduction de la parole), l&#8217;utilisation
de syst&#232;mes en ligne (comme Google traduction), le recalcul en temps r&#233;el d&#8217;hypoth&#232;ses de
traduction dans une interface de post-&#233;dition, etc.
</p>
<p>Cet article pr&#233;sente un travail pr&#233;liminaire concernant l&#8217;application du paradigme de d&#233;codage
guid&#233; &#224; la traduction automatique (TA). Nous proposons d&#8217;utiliser les syst&#232;mes de TA Fran-
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>531 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#231;ais/Anglais de deux laboratoires (le LIA et le LIG) pr&#233;sent&#233;s dans (Potet et al., 2011). Ces
syst&#232;mes sont des syst&#232;mes de traduction statistiques &#224; base de s&#233;quences (phrase-based (Koehn,
2010)). Dans ces approches, un score de vraisemblance est calcul&#233; pour chaque phrase candidate
&#224; la traduction, en fonction de la phrase source ; et ce score r&#233;sulte de la combinaison log-lin&#233;aire
d&#8217;un ensemble de param&#232;tres.
</p>
<p>Notre premi&#232;re approche introduisant le d&#233;codage guid&#233; consiste en l&#8217;addition de param&#232;tres,
dans le mod&#232;le log-lin&#233;aire, mod&#233;lisant la distance entre l&#8217;hypoth&#232;se courante (not&#233;e H) et la
transcription auxiliaire (not&#233;e T) : d(T,H). Avec l&#8217;introduction de ces nouveaux param&#232;tres, les N
meilleures hypoth&#232;ses sont alors r&#233;&#233;valu&#233;es et r&#233;ordonn&#233;es.
</p>
<p>L&#8217;article s&#8217;articule ainsi : la section 2 propose un &#233;tat de l&#8217;art relatif au travail pr&#233;sent&#233;. La section
3 pr&#233;sente notre approche, les sections 4 et 5 d&#233;crivent respectivement le syst&#232;me de traduction
&#233;talon utilis&#233; et nos exp&#233;rimentations qui sont analys&#233;es plus finement dans la section 6. La
derni&#232;re section est consacr&#233;e &#224; nos conclusions et &#224; quelques perspectives.
</p>
<p>2 &#201;tat de l&#8217;art
</p>
<p>Contrairement &#224; la reconnaissance automatique de la parole, la traduction automatique propose
une grande vari&#233;t&#233; de syst&#232;mes bas&#233;s sur des concepts diff&#233;rents. M&#234;me parmi les syst&#232;mes
statistiques, on trouve de nombreuses variantes telles que les syst&#232;mes &#224; base de segments, les
syst&#232;mes hi&#233;rarchiques ou les approches syntaxiques. Ceci complique la combinaison d&#8217;hypoth&#232;ses
en TA car on est confront&#233; &#224; des hypoth&#232;ses potentiellement tr&#232;s diff&#233;rentes en terme de fluidit&#233;,
d&#8217;ordre de mots, etc.
</p>
<p>Dans un premier temps, nous pr&#233;sentons le concept de d&#233;codage guid&#233; utilis&#233; dans les syst&#232;mes
de reconnaissance automatique de la parole (SRAP). Ensuite, nous pr&#233;sentons les approches de
combinaison de syst&#232;mes existantes dans le cadre de la TA.
</p>
<p>2.1 Reconnaissance de la parole guid&#233;e par des transcriptions approch&#233;es
</p>
<p>Dans (Lecouteux et al., 2012, 2013), nous proposons l&#8217;utilisation de transcriptions auxiliaires
pour am&#233;liorer les performances d&#8217;un SRAP. Nous montrons que m&#234;me des informations bruit&#233;es
peuvent apporter une aide pr&#233;cieuse et exploitable. Pour ce faire, deux m&#233;thodes compl&#233;mentaires
sont exploit&#233;es : la combinaison d&#8217;un mod&#232;le de langage g&#233;n&#233;rique avec un mod&#232;le estim&#233; sur la
transcription imparfaite (permettant de r&#233;duire l&#8217;espace linguistique et de le focaliser sur la t&#226;che)
et la r&#233;estimation dynamique de la fonction de co&#251;t du SRAP en fonction de la ressemblance de
l&#8217;hypoth&#232;se courante avec la transcription auxiliaire. Ainsi, la probabilit&#233; de l&#8217;hypoth&#232;se courante
est biais&#233;e par la transcription auxiliaire. Diff&#233;rents types de transcriptions auxiliaires peuvent
&#234;tre utilis&#233;s, comme par exemple des transcriptions issues d&#8217;autres SRAP, aboutissant finalement
&#224; une combinaison. Ainsi, en associant une hypoth&#232;se auxiliaire et ses scores de confiance, il
est possible d&#8217;influencer dynamiquement la probabilit&#233; linguistique. Cette approche a montr&#233;
des gains sup&#233;rieurs aux m&#233;thodes de combinaison classiques (i.e. ROVER) pour des t&#226;ches de
transcription de parole.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>532 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>2.2 Combinaison de syst&#232;mes de traduction automatique
</p>
<p>2.2.1 D&#233;codage de r&#233;seaux de confusion
</p>
<p>De nombreux probl&#232;mes se pr&#233;sentent pour la fusion de r&#233;seaux de confusion (RC), dans le
cadre de la TA. L&#8217;un des plus importants est relatif aux erreurs d&#8217;alignement entre hypoth&#232;ses,
qui g&#233;n&#232;rent des erreurs grammaticales. Le d&#233;codage de r&#233;seaux de confusion pour la TA a
&#233;t&#233; propos&#233; par (Bangalore, 2001). Les hypoth&#232;ses sont align&#233;es en utilisant une distance de
Levensthein, en vue de les fusionner en RC. L&#8217;&#233;tape la plus importante consiste &#224; s&#233;lectionner une
hypoth&#232;se &#8220;patron&#8221; servant de base &#224; l&#8217;alignement. Dans (Rosti et al., 2007b), les sorties 1-best de
chaque syst&#232;me sont utilis&#233;es &#224; tour de r&#244;le comme patron et la mesure TER (Term Error Rate)
entre le patron et les hypoth&#232;ses concurrentes est estim&#233;e dans chaque cas. Au final, le score TER
minimal permet de retenir l&#8217;hypoth&#232;se patron Es telle que : Es = argminE&#8712;Ei
</p>
<p>&#65535;Ns
j=1 T ER(Ej , Ei) o&#249;
</p>
<p>Ns est le nombre de syst&#232;mes.
</p>
<p>Finalement, un r&#233;seau est construit en agr&#233;geant toutes les hypoth&#232;ses. Dans cette approche les
auteurs montrent que des param&#232;tres suppl&#233;mentaires peuvent &#234;tre rajout&#233;s dans le mod&#232;le log-
lin&#233;aire, comme les probabilit&#233;s a posteriori relatives &#224; chaque arc du RC. Dans cette approche,
l&#8217;ordre de la combinaison est fortement influenc&#233; par la qualit&#233; de l&#8217;hypoth&#232;se patron.
</p>
<p>Dans (Rosti et al., 2007a), une combinaison bas&#233;e sur les scores de confiance a posteriori de
diff&#233;rents syst&#232;mes est introduite. Dans la partie exp&#233;rimentale de leurs travaux, les auteurs
combinent trois syst&#232;mes &#224; base de segments, deux syst&#232;mes hi&#233;rarchiques et un syntaxique. Tous
les syst&#232;mes sont entra&#238;n&#233;s sur les m&#234;mes donn&#233;es. Les poids des d&#233;codeurs sont optimis&#233;s selon
TER ou BLEU en fonction du syst&#232;me. Les r&#233;sultats de combinaison montrent une am&#233;lioration
significative par rapport au meilleur syst&#232;me initial.
</p>
<p>2.2.2 R&#233;ordonnancement des meilleures hypoth&#232;ses.
</p>
<p>L&#8217;article (Hildebrand et Vogel, 2009) pr&#233;sente une approche o&#249; les scores des N meilleures
hypoth&#232;ses sont r&#233;estim&#233;s. Les N meilleures hypoth&#232;ses de chaque syst&#232;me sont combin&#233;es et des
param&#232;tres sont rajout&#233;s au mod&#232;le log-lin&#233;aire (mod&#232;le de langage, informations lexicales, etc.).
Les poids du mod&#232;le sont alors recalcul&#233;s en vue de r&#233;ordonner optimalement les hypoth&#232;ses.
Les exp&#233;riences d&#233;crites dans (Hildebrand et Vogel, 2009) montrent la n&#233;cessit&#233; de s&#233;lectionner
un nombre N de meilleures hypoth&#232;ses optimal, 50 dans ce cas pr&#233;cis. Avec cette m&#233;thode, les
auteurs combinent incr&#233;mentalement 4 syst&#232;mes, montrant une am&#233;lioration corr&#233;l&#233;e au nombre
de syst&#232;mes introduits.
</p>
<p>Des approches bas&#233;es sur le r&#233;ordonnancement d&#8217;hypoth&#232;ses sont &#233;galement pr&#233;sent&#233;es dans (Li
et al., 2009) et (Hildebrand et Vogel, 2008) o&#249; les auteurs s&#233;lectionnent les hypoth&#232;ses faisant
consensus avec diff&#233;rents syst&#232;mes : pour cela ils introduisent dans le mod&#232;le log-lin&#233;aire des
param&#232;tres de consensus. &#192; la diff&#233;rence de notre approche, les syst&#232;mes auxiliaires ne sont pas
consid&#233;r&#233;s comme des bo&#238;tes noires.
</p>
<p>La prochaine section pr&#233;sente le paradigme du d&#233;codage guid&#233; o&#249; seules les meilleures hypoth&#232;ses
(1-best) issues des syst&#232;mes auxiliaires sont exploit&#233;es en vue d&#8217;am&#233;liorer un syst&#232;me primaire. Il
est donc important de mentionner que notre approche consid&#232;re les syst&#232;mes auxiliaires comme
&#233;tant des &quot;boites noires&quot;.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>533 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3 D&#233;codage guid&#233; pour la traduction automatique
</p>
<p>3.1 Principe g&#233;n&#233;ral
</p>
<p>Dans un premier temps, notre impl&#233;mentation consiste en l&#8217;ajout de plusieurs param&#232;tres dans le
mod&#232;le log-lin&#233;aire, afin de r&#233;ordonner les hypoth&#232;ses. D&#8217;un point de vue pratique, ces scores sont
rajout&#233;s aux N-meilleures hypoth&#232;ses directements issues du d&#233;codeur. Les scores additionnels
correspondent &#224; la distance entre l&#8217;hypoth&#232;se courante (not&#233;e H) et la traduction auxiliaire
(not&#233;e T) : d(T,H). Nous utilisons dans notre cas les hypoth&#232;ses fournies par le syst&#232;me du LIA
et utilisons deux transcriptions auxiliaires (LIG et Google). Dans cette situation, deux scores
de distance sont rajout&#233;s au mod&#232;le log-lin&#233;aire. La distance utilis&#233;e est d&#233;crite dans la section
suivante.
</p>
<p>3.2 Mesure de distance utilis&#233;e
</p>
<p>Nous proposons d&#8217;utiliser le BLEU comme distance entre les syst&#232;mes. Le score BLEU correspond
&#224; la moyenne g&#233;om&#233;trique de la pr&#233;cision n-gramme. Un score BLEU &#233;lev&#233; sugg&#232;re donc une
traduction de meilleure qualit&#233;, d&#8217;o&#249; son utilisation comme m&#233;trique d&#8217;&#233;valuation de similarit&#233;
entre diff&#233;rents syst&#232;mes. Pour le d&#233;codage guid&#233;, nous utilisons une distance BLEU liss&#233;e au
niveau de la phrase comme pr&#233;sent&#233; dans (Lin et Och, 2004). &#201;videmment, nous souhaitons
introduire des mesures de distance suppl&#233;mentaires dans des travaux futurs, mais seul BLEU est
utilis&#233; dans cet article qui peut &#234;tre vu comme une &quot;preuve de concept&quot;.
</p>
<p>3.3 R&#233;ordonnancement des hypoth&#232;ses et combinaison
</p>
<p>La combinaison est appliqu&#233;e sur les 500 meilleures hypoth&#232;ses extraites du syst&#232;me primaire
(LIA) en utilisant l&#8217;option distinct de Moses (ceci &#233;limine les doublons). Chaque hypoth&#232;se
comporte un ensemble de 14 scores : 1 pour le mod&#232;le de langage, 5 pour le mod&#232;le de
traduction, 1 score de distorsion, 7 scores de r&#233;ordonnancement et un score de p&#233;nalit&#233;. A ces
scores, nous ajoutons donc une mesure de similarit&#233; pour chaque syst&#232;me auxiliaire.
</p>
<p>Les poids de combinaison sont optimis&#233;s en maximisant le score BLEU au niveau de la phrase en
utilisant l&#8217;algorithme MIRA (Margin Infused Relaxed Algorithm) (Hasler et al., 2011). Le choix
de MIRA est motiv&#233; par une meilleure stabilit&#233; observ&#233;e dans le cas d&#8217;optimisation de nombreux
param&#232;tres. Nous effectuons une centaine d&#8217;it&#233;rations et le param&#232;tre C est fix&#233; &#224; 0.001.
</p>
<p>En ce qui concerne le d&#233;codage, un score est calcul&#233; pour chaque phrase (via la combinaison
log-lin&#233;aire) et les phrases sont r&#233;ordonn&#233;es en fonction des nouveaux scores calcul&#233;s.
</p>
<p>4 Syst&#232;me de r&#233;f&#233;rence
4.1 Donn&#233;es
</p>
<p>Les syst&#232;mes LIG et LIA ont &#233;t&#233; entra&#238;n&#233;s &#224; partir des donn&#233;es fournies lors de la campagne
d&#8217;&#233;valuation WMT 2011 et sur le corpus Gigaword fourni par le LDC. La Table 4.1 r&#233;capitule
l&#8217;ensemble des donn&#233;es utilis&#233;es et introduit les notations pour les corpus qui seront utilis&#233;es
dans la suite de l&#8217;article. Quatre corpus ont &#233;t&#233; utilis&#233;s pour construire le mod&#232;le de traduction :
news-c, euro, UN et giga et trois corpus sont utilis&#233;s pour apprendre le mod&#232;le de langage. Enfin,
deux corpus parall&#232;les ont servi &#224; optimiser les param&#232;tres : tuning-mt-LIG-LIA a &#233;t&#233; utilis&#233; pour
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>534 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CORPUS D&#201;SIGNATION NB PHRASES
</p>
<p>Apprentissage News Commentary v6 news-c 116 k
bilingue Europarl v6 euro 1.8M
Anglais/Fran&#231;ais UN corpus UN 12M
</p>
<p>109 corpus giga 23M
</p>
<p>Apprentissage News Commentary v6 mono-news-c 181 k
monolingue Shuffled News Crawl (2007 &#224; 2011) news-s 25M
Anglais Europarl v6 mono-euro 1.8M
</p>
<p>D&#233;veloppement newstest2008 + newssyscomb2009 dev 2553
newstest2009 optimisation-LIG-LIA 2525
</p>
<p>Test newstest2010 test10 2489
newstest2011 test11 3005
</p>
<p>TABLE 1 &#8211; Corpus utilis&#233;s pour construire les syst&#232;mes LIG et LIA (dans la campagne d&#8217;&#233;valuation
WMT 2011).
</p>
<p>le d&#233;veloppement des deux syst&#232;mes LIG et LIA (via MERT (Och, 2003)) tandis que le corpus
dev a &#233;t&#233; utilis&#233; pour estimer les poids d&#233;di&#233;s au d&#233;codage guid&#233;. Les corpus test10 et test11 ont
quant &#224; eux servi pour l&#8217;&#233;valuation du d&#233;codage guid&#233;.
</p>
<p>4.2 Caract&#233;ristiques du syst&#232;me primaire utilis&#233; (LIA)
</p>
<p>Le syst&#232;me LIA est un syst&#232;me &#224; base de segments (phrase-based). L&#8217;ensemble des donn&#233;es
utilis&#233;es provient de la campagne d&#8217;&#233;valuation WMT 2011 et les donn&#233;es sont tokenis&#233;es avec
les outils fournis lors de la campagne. Le mod&#232;le de langage 4-gramme a &#233;t&#233; appris &#224; l&#8217;aide
de la bo&#238;te &#224; outils SRILM (Stolcke, 2002) avec un mod&#232;le de repli Kneyser-Ney modifi&#233;. Le
corpus parall&#232;le a &#233;t&#233; align&#233; au niveau des mots en utilisant Giza++ (Och et Ney, 2003) et
MGiza++ (Gao et Vogel, 2008) pour les corpus tr&#232;s volumineux. La table de phrases et les
mod&#232;les de r&#233;ordonnancement ont &#233;t&#233; appris en utilisant les outils d&#8217;apprentissage de la suite
Moses (Koehn et al., 2007). Au final, un ensemble de 14 param&#232;tres a &#233;t&#233; utilis&#233; dans le syst&#232;me
(cf 3.3). Ces scores ont &#233;t&#233; optimis&#233;s sur le corpus newstest2009 comprenant 2525 phrases en
utilisant l&#8217;algorithme MERT. Plus de d&#233;tails se trouvent dans (Potet et al., 2011).
</p>
<p>4.3 Performances du syst&#232;me primaire et des syst&#232;mes auxiliaires
</p>
<p>La Table 2 r&#233;sume les scores BLEU obtenus par le syst&#232;me LIA sans la casse (tous les r&#233;sultats de
l&#8217;article sont donn&#233;s sans la casse). L&#8217;&#233;valuation des performances est effectu&#233;e sur 3 corpus : dev
qui correspond aux corpus newstest2008 + newssyscomb2009 de WMT (2553 phrases) ; tst10
qui correspond &#224; newstest2010 (2489 phrases) et tst11 qui correspond &#224; newstest2011 (3005
phrases). Nous pr&#233;sentons &#233;galement les scores obtenus par les syst&#232;mes auxiliaires LIG (non
d&#233;crit ici faute de place mais pr&#233;sent&#233; dans (Potet et al., 2011)) et Google (syst&#232;me en ligne dans
sa version de F&#233;vrier 2012). Nous sommes conscients du risque que le syst&#232;me Google utilis&#233; en
2012 puisse contenir des donn&#233;es issues de WMT 2011, mais &#224; la vue des performances, &#231;a ne
semble pas &#234;tre le cas. C&#8217;est principalement pour cette raison que nous avons &#233;galement introduit
le syst&#232;me du LIG dont nous contr&#244;lons parfaitement les donn&#233;es d&#8217;apprentissage.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>535 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Syst&#232;me dev tst10 tst11
LIA (1) 25.45 29.30 29.30
LIG (2) 24.38 27.64 28.54
Google (3) 24.62 28.38 29.83
MANY 1,2,3 26.3 30.46 30.6
ORACLE 1,2,3 29.5 34.0 34.63
</p>
<p>Syst&#232;me dev tst10 tst11
DDA Google 26.37 30.16 30.52
DDA LIG 25.71 29.57 29.51
DDA LIG+G (4) 26.41 30.44 30.91
ORACLE 2,3,4 29.16 33.8 34.35
ORACLE 1,2,3,4 30.0 34.7 35.2
</p>
<p>TABLE 2 &#8211; Performances des syst&#232;mes LIA, LIG et Google , d&#8217;une combinaison &#233;tat de l&#8217;art via
MANY et performances du d&#233;codage guid&#233; du syst&#232;me LIA par les syst&#232;mes LIG et/ou Google
</p>
<p>Afin de nous comparer &#224; un syst&#232;me de combinaison de r&#233;f&#233;rence, nous proposons aussi une
combinaison utilisant MANY (Barrault, 2010). MANY utilise un mod&#232;le de langage (dans notre
cas, celui du LIA) afin de d&#233;coder un r&#233;seau de confusion constitu&#233; de l&#8217;ensemble des meilleures
hypoth&#232;ses des diff&#233;rents syst&#232;mes.
</p>
<p>Pour finir, l&#8217;algorithme MIRA (Hasler et al., 2011) est utilis&#233; pour recalculer tous les poids relatifs
au d&#233;codage guid&#233; (entra&#238;n&#233;s sur le corpus dev).
</p>
<p>5 Exp&#233;riences et r&#233;sultats
Le d&#233;codage guid&#233; (Driven Decoding Algorithm, DDA) a &#233;t&#233; utilis&#233; avec le LIA comme syst&#232;me
primaire dont les 500 meilleures hypoth&#232;ses ont &#233;t&#233; extraites. Les transcriptions auxiliaires sont
ici les transcriptions issues des syst&#232;mes LIG et Google dont les performances sont donn&#233;es dans
la Table 2. Cette table pr&#233;sente &#233;galement les r&#233;sultats du d&#233;codage guid&#233;.
</p>
<p>Nous constatons que le syst&#232;me LIA est meilleur que le syst&#232;me LIG. Cependant, la transcription
auxiliaire du LIG permet tout de m&#234;me d&#8217;am&#233;liorer ses performances par d&#233;codage guid&#233;. Nous
observons &#233;galement une am&#233;lioration qui se cumule lorsqu&#8217;on ajoute le syst&#232;me de Google. Le
d&#233;codage guid&#233; du syst&#232;me LIA am&#233;liore son score BLEU d&#8217;environ 1 point en comparaison du
meilleur syst&#232;me individuel. De plus, les scores Oracle des combinaisons entre diff&#233;rents syst&#232;mes
sont donn&#233;s &#224; titre d&#8217;information. Il est int&#233;ressant de noter qu&#8217;en substituant le syst&#232;me LIA
au syst&#232;me DDA, le score Oracle baisse m&#233;caniquement puisque le d&#233;codage guid&#233; d&#233;gage un
consensus.
</p>
<p>Les r&#233;sultats sont &#233;galement tr&#232;s l&#233;g&#232;rement sup&#233;rieurs &#224; ceux obtenus avec MANY, qui est un
syst&#232;me de combinaison &#233;tat de l&#8217;art. Cependant, tandis que MANY n&#233;cessite un red&#233;codage &#224;
l&#8217;aide d&#8217;un mod&#232;le de langage cible, le d&#233;codage guid&#233; permet une combinaison diff&#233;rente et peu
co&#251;teuse &#224; mettre en oeuvre.
</p>
<p>6 Analyse plus fine du d&#233;codage guid&#233;
La Table 3 et la Figure associ&#233;e montrent les distances BLEU entre le d&#233;codage guid&#233; par
LIG+Google, LIG, Google et l&#8217;ensemble des syst&#232;mes utilis&#233;s seuls. Les similarit&#233;s pr&#233;sent&#233;es ont
&#233;t&#233; calcul&#233;es sur le corpus test11 (elles sont similaires sur les autres ensembles). Nous observons
que le d&#233;codage guid&#233; LIG+Google se rapproche &#224; la fois des syst&#232;mes Google et LIG. Lorsqu&#8217;il
utilise uniquement le syst&#232;me auxiliaire Google, au contraire il s&#8217;&#233;loigne du LIG. En revanche, en
utilisant uniquement le syst&#232;me auxiliaire LIG, l&#8217;hypoth&#232;se obtenue ne s&#8217;&#233;loigne pas de Google.
Ceci s&#8217;explique sans doute que le LIG et le LIA sont entra&#238;n&#233;s sur des donn&#233;es similaires, et les
syst&#232;mes sont du m&#234;me type, tandis que les hypoth&#232;ses de Google diff&#232;rent un peu plus.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>536 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Syst&#232;me LIA DDA tout DDA LIG DDA Google
LIG 63.13 66.14 72.8 61.02
LIA 100 77.2 83.6 77.19
Google 51.01 66.29 51.76 65.93
DDA tout 77.2 100 79.68 90.96
</p>
<p>TABLE 3 &#8211; Similarit&#233; entre les syst&#232;mes. La m&#233;trique utilis&#233;e est le BLEU : Chaque sommet du
graphe correspond &#224; un syst&#232;me qui est consid&#233;r&#233; comme r&#233;f&#233;rence par rapport aux autres.
DDA tout correspond au syst&#232;me DDA guid&#233; &#224; la fois par les syst&#232;mes Google et LIA
</p>
<p>La Figure montre le comportement induit par le d&#233;codage guid&#233; : les hypoth&#232;ses se rapprochent
ou s&#8217;&#233;loignent des syst&#232;mes auxiliaires. Il est int&#233;ressant de noter que le syst&#232;me LIG, a priori
moins performant que le syst&#232;me LIA a finalement une similarit&#233; tr&#232;s &#233;lev&#233;e avec ce dernier.
L&#8217;utilisation d&#8217;une similarit&#233; BLEU entre les syst&#232;mes permet donc de trouver un consensus
inter-hypoth&#232;ses.
</p>
<p>7 Conclusion et perspectives
Nous avons pr&#233;sent&#233; une adaptation pr&#233;liminaire du d&#233;codage guid&#233; &#224; la traduction automatique.
Ce paradigme permet une combinaison efficace de syst&#232;mes de traduction automatique, en
r&#233;&#233;valuant le mod&#232;le log-lin&#233;aire au niveau des N meilleures hypoth&#232;ses, en utilisant des syst&#232;mes
auxiliaires. Le principe est de guider le processus de recherche en utilisant des sorties existantes.
Nous avons &#233;valu&#233; diff&#233;rentes configurations sur le corpus WMT 2011. Les r&#233;sultats montrent que
l&#8217;approche est efficace et obtient des gains significatifs en terme de score BLEU. Par ailleurs, ces
r&#233;sultats pr&#233;liminaires sont &#233;quivalents (voire l&#233;g&#232;rement meilleurs) &#224; ceux obtenus en utilisant
des m&#233;thodes de combinaison &#233;tat de l&#8217;art. Enfin, cette m&#233;thode a &#233;t&#233; r&#233;cemment utilis&#233;e avec
succ&#232;s lors de deux campagnes d&#8217;&#233;valuation :
</p>
<p>&#8211; Une campagne d&#8217;&#233;valuation arabe/fran&#231;ais (TRAD) o&#249; nous avons utilis&#233; Google comme
syst&#232;me auxiliaire et le syst&#232;me du LIG comme syst&#232;me primaire.
</p>
<p>&#8211; La campagne d&#8217;&#233;valuation IWSLT 2012 (anglais/fran&#231;ais) o&#249; nous avons utilis&#233; le m&#234;me
syst&#232;me en ligne pour am&#233;liorer les performances du syst&#232;me primaire LIG. Les r&#233;sultats de
cette campagne se trouvent dans (Besacier et al., 2012).
</p>
<p>Nos futurs travaux vont se concentrer sur l&#8217;int&#233;gration du d&#233;codage guid&#233; au sein du d&#233;codeur
Moses, au niveau de la fonction objective. Le second axe envisag&#233; est l&#8217;utilisation de mesures de
confiance associ&#233;es aux transcriptions auxiliaires, afin de les exploiter plus finement.
</p>
<p>R&#233;f&#233;rences
</p>
<p>BANGALORE, S. (2001). Computing consensus translation from multiple machine translation
systems. In In Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop
(ASRU-2001, pages 351&#8211;354.
</p>
<p>BARRAULT, L. (2010). Many : Open source machine translation system combination. In In
Prague Bulletin of Mathematical Linguistics, Special Issue on Open Source Tools for Machine
Translation(93), p.145-155.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>537 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BESACIER, L., LECOUTEUX, B., AZOUZI, M. et LUONG NGOC, Q. (2012). The LIG English to French
Machine Translation System for IWSLT 2012. In In proceedings of the 9th International Workshop
on Spoken Language Translation (IWSLT).
GAO, Q. et VOGEL, S. (2008). Parallel implementations of word alignment tool. In Proceedings of
the ACL Workshop : Software Engineering, Testing, and Quality Assurance for Natural Language
Processing, pages 49&#8211;57, Columbus, OH, USA.
HASLER, E., HADDOW, B. et KOEHN, P. (2011). Margin infused relaxed algorithm for moses. In
The Prague Bulletin of Mathematical Linguistics, pages 96 :69&#8211;78.
HILDEBRAND, A. S. et VOGEL, S. (2008). Combination of machine translation systems via
hypothesis selection from combined n-best lists. In AMTA conference.
HILDEBRAND, A. S. et VOGEL, S. (2009). Combination of machine translation systems via
hypothesis selection from combined n-best lists. In Proceedings of Association for Machine
Translation in the Americas (AMTA), Hawa&#239;, USA.
KOEHN, P. (2010). Statistical Machine Translation. Cambridge University Press, New York.
KOEHN, P., HOANG, H., BIRCH, A., CALLISON-BURCH, C., FEDERICO, M., BERTOLDI, N., COWAN, B.,
SHEN, W., MORAN, C., ZENS, R., DYER, C., BOJAR, O., CONSTANTIN, A. et HERBST, E. (2007). Moses :
Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting
of the Association for Computational Linguistics (ACL), Companion Volume, pages 177&#8211;180,
Prague, Czech Republic.
LECOUTEUX, B., LINARES, G., EST&#200;VE, Y. et GRAVIER, G. (2013). Dynamic combination of automatic
speech recognition systems by driven decoding. IEEE Transactions on Audio, Speech and Signal
Processing, 21, issue 6:1251 &#8211; 1260.
LECOUTEUX, B., LINARES, G. et OGER, S. (2012). Integrating imperfect transcripts into speech
recognition systems for building high-quality corpora. Computer Speech and Language, 26(2):67
&#8211; 89.
LI, M., DUAN, N., ZHANG, D., LI, C.-H. et ZHOU, M. (2009). Collaborative decoding : Partial
hypothesis re-ranking using translation consensus between decoders. In Proceedings of the 47th
Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP.
LIN, C.-Y. et OCH, F. J. (2004). Orange : a method for evaluating automatic evaluation metrics
for machine translation. In In COLING &#8217;04 : Proceedings of the 20th international conference on
Computational Linguistics.
OCH, F. J. (2003). Minimum error rate training in statistical machine translation. In Proceedings
of the 41st Annual Meeting on Association for Computational Linguistics (ACL), Sapporo, Japan.
OCH, F. J. et NEY, H. (2003). A systematic comparison of various statistical alignment models.
Computational Linguistics, 29(1):19&#8211;51.
POTET, M., RUBINO, R., LECOUTEUX, B., HUET, S., BESACIER, L., BLANCHON, H. et LEFEVRE, F. (2011).
The LIGA machine translation system for WMT 2011. In Proceedings EMNLP and ACL Workshop
on Machine Translation (WMT), Edinburgh (Scotland).
ROSTI, A.-v., AYAN, N.-F., XIANG, B., MATSOUKAS, S., SCHWARTZ, R. et DORR, B. (2007a). Combining
outputs from multiple machine translation systems. In In Proceedings of the North American
Chapter of the Association for Computational Linguistics Human Language Technologies, pages
228&#8211;235.
ROSTI, A.-v., MATSOUKAS, S. et SCHWARTZ, R. (2007b). Improved word-level system combination
for machine translation. In In Proceedings of ACL.
STOLCKE, A. (2002). SRILM &#8212; an extensible language modeling toolkit. In Proceedings of the
7th International Conference on Spoken Language Processing (ICSLP), Denver, CO, USA.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>538 c&#65535; ATALA</p>

</div></div>
</body></html>