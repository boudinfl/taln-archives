<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S BANGALORE</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems. In</title>
<date>2001</date>
<booktitle>In Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop (ASRU-2001,</booktitle>
<pages>351--354</pages>
<marker>BANGALORE, 2001</marker>
<rawString>BANGALORE, S. (2001). Computing consensus translation from multiple machine translation systems. In In Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop (ASRU-2001, pages 351–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L BARRAULT</author>
</authors>
<title>Many : Open source machine translation system combination.</title>
<date>2010</date>
<booktitle>In In Prague Bulletin of Mathematical Linguistics, Special Issue on Open Source Tools for Machine Translation(93),</booktitle>
<pages>145--155</pages>
<marker>BARRAULT, 2010</marker>
<rawString>BARRAULT, L. (2010). Many : Open source machine translation system combination. In In Prague Bulletin of Mathematical Linguistics, Special Issue on Open Source Tools for Machine Translation(93), p.145-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>c ATALA TALN-RÉCITAL</author>
</authors>
<date>2013</date>
<booktitle>The LIG English to French Machine Translation System for IWSLT 2012. In In proceedings of the 9th International Workshop on Spoken Language Translation (IWSLT).</booktitle>
<pages>17--21</pages>
<contexts>
<context position="2934" citStr="TALN-RÉCITAL 2013" startWordPosition="413" endWordPosition="414"> nombreuses applications telles que la combinaison de systèmes, la traduction multi-sources (à partir de différentes langues, ou à partir de sorties de différents systèmes de reconnaissance de la parole dans le cas de la traduction de la parole), l’utilisation de systèmes en ligne (comme Google traduction), le recalcul en temps réel d’hypothèses de traduction dans une interface de post-édition, etc. Cet article présente un travail préliminaire concernant l’application du paradigme de décodage guidé à la traduction automatique (TA). Nous proposons d’utiliser les systèmes de TA Fran531 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne çais/Anglais de deux laboratoires (le LIA et le LIG) présentés dans (Potet et al., 2011). Ces systèmes sont des systèmes de traduction statistiques à base de séquences (phrase-based (Koehn, 2010)). Dans ces approches, un score de vraisemblance est calculé pour chaque phrase candidate à la traduction, en fonction de la phrase source ; et ce score résulte de la combinaison log-linéaire d’un ensemble de paramètres. Notre première approche introduisant le décodage guidé consiste en l’addition de paramètres, dans le modèle log-linéaire, modélisant la distance entre</context>
<context position="6148" citStr="TALN-RÉCITAL 2013" startWordPosition="882" endWordPosition="883">ante avec la transcription auxiliaire. Ainsi, la probabilité de l’hypothèse courante est biaisée par la transcription auxiliaire. Différents types de transcriptions auxiliaires peuvent être utilisés, comme par exemple des transcriptions issues d’autres SRAP, aboutissant finalement à une combinaison. Ainsi, en associant une hypothèse auxiliaire et ses scores de confiance, il est possible d’influencer dynamiquement la probabilité linguistique. Cette approche a montré des gains supérieurs aux méthodes de combinaison classiques (i.e. ROVER) pour des tâches de transcription de parole. 532 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 2.2 Combinaison de systèmes de traduction automatique 2.2.1 Décodage de réseaux de confusion De nombreux problèmes se présentent pour la fusion de réseaux de confusion (RC), dans le cadre de la TA. L’un des plus importants est relatif aux erreurs d’alignement entre hypothèses, qui génèrent des erreurs grammaticales. Le décodage de réseaux de confusion pour la TA a été proposé par (Bangalore, 2001). Les hypothèses sont alignées en utilisant une distance de Levensthein, en vue de les fusionner en RC. L’étape la plus importante consiste à sélectionner une hypothè</context>
<context position="9563" citStr="TALN-RÉCITAL 2013" startWordPosition="1398" endWordPosition="1399">urs sélectionnent les hypothèses faisant consensus avec différents systèmes : pour cela ils introduisent dans le modèle log-linéaire des paramètres de consensus. À la différence de notre approche, les systèmes auxiliaires ne sont pas considérés comme des boîtes noires. La prochaine section présente le paradigme du décodage guidé où seules les meilleures hypothèses (1-best) issues des systèmes auxiliaires sont exploitées en vue d’améliorer un système primaire. Il est donc important de mentionner que notre approche considère les systèmes auxiliaires comme étant des &amp;quot;boites noires&amp;quot;. 533 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 3 Décodage guidé pour la traduction automatique 3.1 Principe général Dans un premier temps, notre implémentation consiste en l’ajout de plusieurs paramètres dans le modèle log-linéaire, afin de réordonner les hypothèses. D’un point de vue pratique, ces scores sont rajoutés aux N-meilleures hypothèses directements issues du décodeur. Les scores additionnels correspondent à la distance entre l’hypothèse courante (notée H) et la traduction auxiliaire (notée T) : d(T,H). Nous utilisons dans notre cas les hypothèses fournies par le système du LIA et utilisons deux </context>
<context position="12708" citStr="TALN-RÉCITAL 2013" startWordPosition="1885" endWordPosition="1886">Données Les systèmes LIG et LIA ont été entraînés à partir des données fournies lors de la campagne d’évaluation WMT 2011 et sur le corpus Gigaword fourni par le LDC. La Table 4.1 récapitule l’ensemble des données utilisées et introduit les notations pour les corpus qui seront utilisées dans la suite de l’article. Quatre corpus ont été utilisés pour construire le modèle de traduction : news-c, euro, UN et giga et trois corpus sont utilisés pour apprendre le modèle de langage. Enfin, deux corpus parallèles ont servi à optimiser les paramètres : tuning-mt-LIG-LIA a été utilisé pour 534 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne CORPUS DÉSIGNATION NB PHRASES Apprentissage News Commentary v6 news-c 116 k bilingue Europarl v6 euro 1.8M Anglais/Français UN corpus UN 12M 109 corpus giga 23M Apprentissage News Commentary v6 mono-news-c 181 k monolingue Shuffled News Crawl (2007 à 2011) news-s 25M Anglais Europarl v6 mono-euro 1.8M Développement newstest2008 + newssyscomb2009 dev 2553 newstest2009 optimisation-LIG-LIA 2525 Test newstest2010 test10 2489 newstest2011 test11 3005 TABLE 1 – Corpus utilisés pour construire les systèmes LIG et LIA (dans la campagne d’évaluation WMT 2011). le déve</context>
<context position="15541" citStr="TALN-RÉCITAL 2013" startWordPosition="2339" endWordPosition="2340">respond à newstest2011 (3005 phrases). Nous présentons également les scores obtenus par les systèmes auxiliaires LIG (non décrit ici faute de place mais présenté dans (Potet et al., 2011)) et Google (système en ligne dans sa version de Février 2012). Nous sommes conscients du risque que le système Google utilisé en 2012 puisse contenir des données issues de WMT 2011, mais à la vue des performances, ça ne semble pas être le cas. C’est principalement pour cette raison que nous avons également introduit le système du LIG dont nous contrôlons parfaitement les données d’apprentissage. 535 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Système dev tst10 tst11 Système dev tst10 tst11 LIA (1) 25.45 29.30 29.30 DDA Google 26.37 30.16 30.52 LIG (2) 24.38 27.64 28.54 DDA LIG 25.71 29.57 29.51 Google (3) 24.62 28.38 29.83 DDA LIG+G (4) 26.41 30.44 30.91 MANY 1,2,3 26.3 30.46 30.6 ORACLE 2,3,4 29.16 33.8 34.35 ORACLE 1,2,3 29.5 34.0 34.63 ORACLE 1,2,3,4 30.0 34.7 35.2 TABLE 2 – Performances des systèmes LIA, LIG et Google , d’une combinaison état de l’art via MANY et performances du décodage guidé du système LIA par les systèmes LIG et/ou Google Afin de nous comparer à un système de combinaison de </context>
<context position="18748" citStr="TALN-RÉCITAL 2013" startWordPosition="2849" endWordPosition="2850">ésentées ont été calculées sur le corpus test11 (elles sont similaires sur les autres ensembles). Nous observons que le décodage guidé LIG+Google se rapproche à la fois des systèmes Google et LIG. Lorsqu’il utilise uniquement le système auxiliaire Google, au contraire il s’éloigne du LIG. En revanche, en utilisant uniquement le système auxiliaire LIG, l’hypothèse obtenue ne s’éloigne pas de Google. Ceci s’explique sans doute que le LIG et le LIA sont entraînés sur des données similaires, et les systèmes sont du même type, tandis que les hypothèses de Google diffèrent un peu plus. 536 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Système LIA DDA tout DDA LIG DDA Google LIG 63.13 66.14 72.8 61.02 LIA 100 77.2 83.6 77.19 Google 51.01 66.29 51.76 65.93 DDA tout 77.2 100 79.68 90.96 TABLE 3 – Similarité entre les systèmes. La métrique utilisée est le BLEU : Chaque sommet du graphe correspond à un système qui est considéré comme référence par rapport aux autres. DDA tout correspond au système DDA guidé à la fois par les systèmes Google et LIA La Figure montre le comportement induit par le décodage guidé : les hypothèses se rapprochent ou s’éloignent des systèmes auxiliaires. Il est intéress</context>
</contexts>
<marker>TALN-RÉCITAL, 2013</marker>
<rawString>537 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne BESACIER, L., LECOUTEUX, B., AZOUZI, M. et LUONG NGOC, Q. (2012). The LIG English to French Machine Translation System for IWSLT 2012. In In proceedings of the 9th International Workshop on Spoken Language Translation (IWSLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q et VOGEL GAO</author>
<author>S</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL Workshop : Software Engineering, Testing, and Quality Assurance for Natural Language Processing,</booktitle>
<pages>49--57</pages>
<location>Columbus, OH, USA.</location>
<marker>GAO, S, 2008</marker>
<rawString>GAO, Q. et VOGEL, S. (2008). Parallel implementations of word alignment tool. In Proceedings of the ACL Workshop : Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 49–57, Columbus, OH, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E HASLER</author>
<author>B et KOEHN HADDOW</author>
<author>P</author>
</authors>
<title>Margin infused relaxed algorithm for moses.</title>
<date>2011</date>
<booktitle>In The Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>96--69</pages>
<marker>HASLER, HADDOW, P, 2011</marker>
<rawString>HASLER, E., HADDOW, B. et KOEHN, P. (2011). Margin infused relaxed algorithm for moses. In The Prague Bulletin of Mathematical Linguistics, pages 96 :69–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A S et VOGEL HILDEBRAND</author>
<author>S</author>
</authors>
<title>Combination of machine translation systems via hypothesis selection from combined n-best lists.</title>
<date>2008</date>
<booktitle>In AMTA conference.</booktitle>
<marker>HILDEBRAND, S, 2008</marker>
<rawString>HILDEBRAND, A. S. et VOGEL, S. (2008). Combination of machine translation systems via hypothesis selection from combined n-best lists. In AMTA conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A S et VOGEL HILDEBRAND</author>
<author>S</author>
</authors>
<title>Combination of machine translation systems via hypothesis selection from combined n-best lists.</title>
<date>2009</date>
<booktitle>In Proceedings of Association for Machine Translation in the Americas (AMTA),</booktitle>
<location>Hawaï, USA.</location>
<marker>HILDEBRAND, S, 2009</marker>
<rawString>HILDEBRAND, A. S. et VOGEL, S. (2009). Combination of machine translation systems via hypothesis selection from combined n-best lists. In Proceedings of Association for Machine Translation in the Americas (AMTA), Hawaï, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P KOEHN</author>
</authors>
<title>Statistical Machine Translation.</title>
<date>2010</date>
<publisher>Cambridge University Press,</publisher>
<location>New York.</location>
<marker>KOEHN, 2010</marker>
<rawString>KOEHN, P. (2010). Statistical Machine Translation. Cambridge University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P KOEHN</author>
<author>H HOANG</author>
<author>A BIRCH</author>
<author>C CALLISON-BURCH</author>
<author>M FEDERICO</author>
<author>N BERTOLDI</author>
<author>B COWAN</author>
<author>W SHEN</author>
<author>C MORAN</author>
<author>R ZENS</author>
<author>C DYER</author>
<author>O BOJAR</author>
<author>A et HERBST CONSTANTIN</author>
<author>E</author>
</authors>
<title>Moses : Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL), Companion Volume,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<marker>KOEHN, HOANG, BIRCH, CALLISON-BURCH, FEDERICO, BERTOLDI, COWAN, SHEN, MORAN, ZENS, DYER, BOJAR, CONSTANTIN, E, 2007</marker>
<rawString>KOEHN, P., HOANG, H., BIRCH, A., CALLISON-BURCH, C., FEDERICO, M., BERTOLDI, N., COWAN, B., SHEN, W., MORAN, C., ZENS, R., DYER, C., BOJAR, O., CONSTANTIN, A. et HERBST, E. (2007). Moses : Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL), Companion Volume, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B LECOUTEUX</author>
<author>G LINARES</author>
<author>Y et GRAVIER ESTÈVE</author>
<author>G</author>
</authors>
<title>Dynamic combination of automatic speech recognition systems by driven decoding.</title>
<date>2013</date>
<journal>IEEE Transactions on Audio, Speech and Signal Processing,</journal>
<volume>21</volume>
<pages>6--1251</pages>
<marker>LECOUTEUX, LINARES, ESTÈVE, G, 2013</marker>
<rawString>LECOUTEUX, B., LINARES, G., ESTÈVE, Y. et GRAVIER, G. (2013). Dynamic combination of automatic speech recognition systems by driven decoding. IEEE Transactions on Audio, Speech and Signal Processing, 21, issue 6:1251 – 1260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B LECOUTEUX</author>
<author>G et OGER LINARES</author>
<author>S</author>
</authors>
<title>Integrating imperfect transcripts into speech recognition systems for building high-quality corpora.</title>
<date>2012</date>
<journal>Computer Speech and Language,</journal>
<volume>26</volume>
<issue>2</issue>
<marker>LECOUTEUX, LINARES, S, 2012</marker>
<rawString>LECOUTEUX, B., LINARES, G. et OGER, S. (2012). Integrating imperfect transcripts into speech recognition systems for building high-quality corpora. Computer Speech and Language, 26(2):67 – 89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M LI</author>
<author>N DUAN</author>
<author>D ZHANG</author>
<author>C-H et ZHOU LI</author>
<author>M</author>
</authors>
<title>Collaborative decoding : Partial hypothesis re-ranking using translation consensus between decoders.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP.</booktitle>
<marker>LI, DUAN, ZHANG, LI, M, 2009</marker>
<rawString>LI, M., DUAN, N., ZHANG, D., LI, C.-H. et ZHOU, M. (2009). Collaborative decoding : Partial hypothesis re-ranking using translation consensus between decoders. In Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-Y et OCH LIN</author>
<author>F J</author>
</authors>
<title>Orange : a method for evaluating automatic evaluation metrics for machine translation. In</title>
<date>2004</date>
<booktitle>In COLING ’04 : Proceedings of the 20th international conference on Computational Linguistics.</booktitle>
<marker>LIN, J, 2004</marker>
<rawString>LIN, C.-Y. et OCH, F. J. (2004). Orange : a method for evaluating automatic evaluation metrics for machine translation. In In COLING ’04 : Proceedings of the 20th international conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J OCH</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics (ACL),</booktitle>
<location>Sapporo, Japan.</location>
<marker>OCH, 2003</marker>
<rawString>OCH, F. J. (2003). Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics (ACL), Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J et NEY OCH</author>
<author>H</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<marker>OCH, H, 2003</marker>
<rawString>OCH, F. J. et NEY, H. (2003). A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M POTET</author>
<author>R RUBINO</author>
<author>B LECOUTEUX</author>
<author>S HUET</author>
<author>L BESACIER</author>
<author>H et LEFEVRE BLANCHON</author>
<author>F</author>
</authors>
<date>2011</date>
<marker>POTET, RUBINO, LECOUTEUX, HUET, BESACIER, BLANCHON, F, 2011</marker>
<rawString>POTET, M., RUBINO, R., LECOUTEUX, B., HUET, S., BESACIER, L., BLANCHON, H. et LEFEVRE, F. (2011).</rawString>
</citation>
<citation valid="true">
<title>The LIGA machine translation system for WMT</title>
<date>2011</date>
<booktitle>In Proceedings EMNLP and ACL Workshop on Machine Translation (WMT),</booktitle>
<location>Edinburgh (Scotland).</location>
<marker>2011</marker>
<rawString>The LIGA machine translation system for WMT 2011. In Proceedings EMNLP and ACL Workshop on Machine Translation (WMT), Edinburgh (Scotland).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A-v ROSTI</author>
<author>N-F AYAN</author>
<author>B XIANG</author>
<author>S MATSOUKAS</author>
<author>R et DORR SCHWARTZ</author>
<author>B</author>
</authors>
<title>Combining outputs from multiple machine translation systems.</title>
<date>2007</date>
<booktitle>In In Proceedings of the North American Chapter of the Association for Computational Linguistics Human Language Technologies,</booktitle>
<pages>228--235</pages>
<marker>ROSTI, AYAN, XIANG, MATSOUKAS, SCHWARTZ, B, 2007</marker>
<rawString>ROSTI, A.-v., AYAN, N.-F., XIANG, B., MATSOUKAS, S., SCHWARTZ, R. et DORR, B. (2007a). Combining outputs from multiple machine translation systems. In In Proceedings of the North American Chapter of the Association for Computational Linguistics Human Language Technologies, pages 228–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A-v ROSTI</author>
<author>S et SCHWARTZ MATSOUKAS</author>
<author>R</author>
</authors>
<title>Improved word-level system combination for machine translation. In</title>
<date>2007</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>ROSTI, MATSOUKAS, R, 2007</marker>
<rawString>ROSTI, A.-v., MATSOUKAS, S. et SCHWARTZ, R. (2007b). Improved word-level system combination for machine translation. In In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A STOLCKE</author>
</authors>
<title>SRILM — an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the 7th International Conference on Spoken Language Processing (ICSLP),</booktitle>
<location>Denver, CO, USA.</location>
<note>538 c ATALA</note>
<marker>STOLCKE, 2002</marker>
<rawString>STOLCKE, A. (2002). SRILM — an extensible language modeling toolkit. In Proceedings of the 7th International Conference on Spoken Language Processing (ICSLP), Denver, CO, USA. 538 c ATALA</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>