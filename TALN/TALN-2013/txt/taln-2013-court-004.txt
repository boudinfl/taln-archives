TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Vers un décodage guidé pour la traduction automatique

Benjamin Lecouteux et Laurent Besacier
Laboratoire d’Informau'que de Grenoble (LIG), Université de Grenoble

benj amin . 1ecouteux<0imag. fr , laurent .besacier<Oimag. fr

RESUME
Récemment, le paradigme du décodage guidé a montré un fort potentiel dans le cadre de la
reconnaissance automatique de la parole. Le principe est de guider le processus de décodage via
l’utilisation de transcriptions auxiliaires. Ce paradigme appliqué a la traduction automatique per-
met d’envisager de nombreuses applications telles que la combinaison de systemes, la traduction
mult1'-sources etc. Get article présente une approche préliminaire de l’application de ce paradigme
a la traduction automatique (TA). Nous proposons d’enrichir le modéle log—linéaire d’un systéme
primaire de TA avec des mesures de distance relatives a des systémes de TA auxiliaires. Les
premiers résultats obtenus sur la tache de traduction Francais/Anglais issue de la campagne
d’évaluation WMT 2011 montrent le potentiel du décodage guidé.

ABSTRACT
Driven Decoding for machine translation

Recently, the concept of driven decoding (DD), has been sucessfully applied to the automatic
speech recognition (speech—to—text) task : an auxiliary transcription guide the decoding process.
There is a strong interest in applying this concept to statistical machine translation (SMT). This
paper presents our approach on this topic. Our ﬁrst attempt in driven decoding consists in adding
several feature functions corresponding to the distance between the current hypothesis decoded
and the auxiliary translations available. Experimental results done for a french-to-english machine
translation task, in the framework of the WMT 2011 evaluation, show the potential of the DD
approach proposed.

MOTS-CLES : Décodage guidé, traduction automatique, combinaison de systemes.

KEYWORDS: Driven Decoding, machine translation, system combination.

1 Introduction

Le concept du décodage guidé (Lecouteux et al., 2012, 2013) a montré un fort potentiel dans le
cadre de la reconnaissance automatique de la parole. Le principe est de guider le processus de
décodage via l’utilisation de transcriptions auxiliaires. Ce paradigme appliqué a la traduction au-
tomatique perrnet d’envisager de nombreuses applications telles que la combinaison de systemes,
la traduction mu1ti—sources (a partir de différentes langues, ou a partir de sorties de différents
systémes de reconnaissance de la parole dans le cas de la traduction de la parole), l’utilisation
de systémes en ligne (comme Google traduction), le recalcul en temps réel d’hypothéses de
traduction dans une interface de post—édition, etc.

Get article présente un travail préliminaire concernant l’application du paradigme de décodage
guidé a la traduction automatique (TA). Nous proposons d’utiliser les systémes de TA Fran-

531 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

cais/Anglais de deux laboratoires (le LIA et le LIG) présentés dans (Potet et al., 2011). Ces
systemes sont des systemes de traduction statistiques a base de séquences (phrase-based (Koehn,
2010)). Dans ces approches, un score de vraisemblance est calculé pour chaque phrase candidate
a la traduction, en fonction de la phrase source; et ce score résulte de la combinaison log—linéaire
d’un ensemble de parametres.

Notre premiere approche introduisant le décodage guidé consiste en l’addition de parametres,
dans le modele log—1inéaire, modélisant la distance entre l’hypothese courante (notée H) et la
transcription auxiliaire (notée T) : d('I',H). Avec l’introduction de ces nouveaux parametres, les N
meilleures hypotheses sont alors réévaluées et réordonnées.

L’aru'cle s’art1'cule ainsi : la section 2 propose un état de l’art relatif au travail présenté. La section
3 présente notre approche, les sections 4 et 5 décrivent respectivement le systeme de traduction
étalon utilisé et nos expérimentations qui sont analysées plus ﬁnement dans la section 6. La
derniere section est consacrée a nos conclusions et a quelques perspectives.

2 Etat de 1’art

Contrairement a la reconnaissance automatique de la parole, la traduction automatique propose
une grande variété de systemes basés sur des concepts différents. Meme parmi les systemes
statistiques, on trouve de nombreuses variantes telles que les systemes a base de segments, les
systemes hiérarchiques ou les approches syntaxiques. Ceci complique la combinaison d’hypotheses
en TA car on est confronté a des hypotheses potentiellement tres différentes en terme de ﬂuidité,
d’ordre de mots, etc.

Dans un premier temps, nous présentons 1e concept de décodage guidé utilisé dans les systemes
de reconnaissance automatique de la parole (SRAP). Ensuite, nous présentons les approches de
combinaison de systemes existantes dans le cadre de la TA.

2. 1 Reconnaissance de la parole guidée par des transcriptions approchées

Dans (Lecouteux et al., 2012, 2013), nous proposons l’utilisation de transcriptions auxiliaires
pour améliorer les performances d’un SRAP Nous montrons que méme des informations bruitées
peuvent apporter une aide précieuse et exploitable. Pour ce faire, deux méthodes complémentaires
sont exploitées : la combinaison d’un modele de langage générique avec un modele estimé sur la
transcription imparfaite (permettant de réduire l’espace linguistique et de le focaliser sur la tache)
et la réestimation dynamique de la fonction de coﬁt du SRAP en fonction de la ressemblance de
l’hypothese courante avec la transcription auxiliaire. Ainsi, la probabilité de l’hypothese courante
est biaisée par la transcription auxiliaire. Différents types de transcriptions auxiliaires peuvent
étre utilisés, comme par exemple des transcriptions issues d’autres SRAB aboutissant ﬁnalement
a une combinaison. Ainsi, en associant une hypothese auxiliaire et ses scores de conﬁance, il
est possible d’inﬂuencer dynamiquement la probabilité linguistique. Cette approche a montré
des gains supérieurs aux méthodes de combinaison classiques (i.e. ROVER) pour des taches de
transcription de parole.

532 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
2.2 Combinaison de systemes de traduction automatique

2.2.1 Décodage de réseaux de confusion

De nombreux problemes se présentent pour la fusion de réseaux de confusion (RC), dans le
cadre de la TA. L’un des plus importants est relatif aux erreurs d’alignement entre hypotheses,
qui génerent des erreurs grammaticales. Le décodage de réseaux de confusion pour la TA a
été proposé par (Bangalore, 2001). Les hypotheses sont alignées en utilisant une distance de
Levensthein, en vue de les fusionner en RC. L’étape la plus importante consiste a sélectionner une
hypothese “patron” servant de base a l’alignement. Dans (Rosti et al., 2007b), les sotties 1-best de
chaque systeme sont utilisées a tour de réle comme patron et la mesure TER (Term Error Rate)
entre le patron et les hypotheses concurrentes est estimée dans chaque cas. Au ﬁnal, le score TER
minimal permet de retenir l’hypothese patron Es telle que : E5 = arg minEEEi 29:1 TER(EJ-, El) 011
NS est le nombre de systemes.

Finalement, un réseau est construit en agrégeant toutes les hypotheses. Dans cette approche les
auteurs montrent que des parametres supplémentaires peuvent étre rajoutés dans le modele log-
linéaire, comme les probabilités a posteriori relatives a chaque arc du RC. Dans cette approche,
l’ordre de la combinaison est fortement inﬂuencé par la qualité de l’hypothese patron.

Dans (Rosti et al., 2007a), une combinaison basée sur les scores de conﬁance a posteriori de
différents systemes est introduite. Dans la partie expérimentale de leurs travaux, les auteurs
combinent trois systemes a base de segments, deux systemes hiérarchiques et un syntaxique. Tous
les systemes sont entrainés sur les memes données. Les poids des décodeurs sont optimisés selon
TER ou BLEU en fonction du systeme. Les résultats de combinaison montrent une amélioration
signiﬁcative par rapport au meilleur systeme initial.

2.2.2 Réordonnancement des meilleures hypotheses.

L’article (Hildebrand et Vogel, 2009) présente une approche ou les scores des N meilleures
hypotheses sont réestimés. Les N meilleures hypotheses de chaque systeme sont combinées et des
parametres sont rajoutés au modele log—linéaire (modele de langage, informations lexicales, etc.).
Les poids du modele sont alors recalculés en vue de réordonner optimalement les hypotheses.
Les expériences décrites dans (Hildebrand et Vogel, 2009) montrent la nécessité de sélectionner
un nombre N de meilleures hypotheses optimal, 50 dans ce cas précis. Avec cette méthode, les
auteurs combinent incrémentalement 4 systemes, montrant une amélioration corrélée au nombre
de systemes introduits.

Des approches basées sur le réordonnancement d’hypotheses sont également présentées dans (Li
et al., 2009) et (Hildebrand et Vogel, 2008) ou les auteurs sélectionnent les hypotheses faisant
consensus avec différents systemes : pour cela ils introduisent dans le modele log—linéaire des
parametres de consensus. A la différence de notre approche, les systemes auxiliaires ne sont pas
considérés comme des boites noires.

La prochaine section présente le paradigme du décodage guidé ou seules les meilleures hypotheses
(1—best) issues des systemes auxiliaires sont exploitées en vue d’améliorer un systeme primaire. Il
est donc important de mentionner que notre approche considere les systemes auxiliaires comme
étant des "boites noires".

533 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
3 Décodage guidé pour la traduction automatique

3. 1 Principe général

Dans un premier temps, notre implémentation consiste en l’ajout de plusieurs parametres dans le
modele log—linéaire, aﬁn de réordonner les hypotheses. D’un point de vue pratique, ces scores sont
rajoutés aux N—meilleures hypotheses directements issues du décodeur. Les scores additionnels
correspondent a la distance entre l’hypothese courante (notée H) et la traduction auxiliaire
(notée T) : d(T,H). Nous utilisons dans notre cas les hypotheses fournies par le systeme du LIA
et utilisons deux transcriptions auxiliaires (LIG et Google). Dans cette situation, deux scores
de distance sont rajoutés au modele log—linéaire. La distance utilisée est décrite dans la section
suivante.

3.2 Mesure de distance utilisée

Nous proposons d’utiliser le BLEU comme distance entre les systemes. Le score BLEU correspond
a la moyenne géométrique de la précision n—gramme. Un score BLEU élevé suggere donc une
traduction de meilleure qualité, d’o1‘1 son utilisation comme métrique d’évaluation de similarité
entre différents systemes. Pour le décodage guidé, nous utilisons une distance BLEU lissée au
niveau de la phrase comme présenté dans (Lin et Och, 2004). Evidemment, nous souhaitons
introduire des mesures de distance supplémentaires dans des travaux futurs, mais seul BLEU est
utilisé dans cet article qui peut étre vu comme une "preuve de concept".

3.3 Réordonnancement des hypotheses et combinaison

La combinaison est appliquée sur les 500 meilleures hypotheses extraites du systeme primaire
(LIA) en utilisant l’option distinct de Moses (ceci élimine les doublons). Chaque hypothese
comporte un ensemble de 14 scores : 1 pour le modele de langage, 5 pour le modele de
traduction, 1 score de distorsion, 7 scores de réordonnancement et un score de pénalité. A ces
scores, nous ajoutons donc une mesure de similarité pour chaque systeme auxiliaire.

Les poids de combinaison sont optimisés en maximisant le score BLEU au niveau de la phrase en
utilisant l’algorithme MIRA (Margin Infused Relaxed Algorithm) (Hasler et al., 2011). Le choix
de MIRA est motivé par une meilleure stabilité observée dans le cas d’optimisation de nombreux
parametres. Nous effectuons une centaine d’itérations et le parametre C est ﬁxé a 0.001.

En ce qui concerne le décodage, un score est calculé pour chaque phrase (via la combinaison
log—linéaire) et les phrases sont réordonnées en fonction des nouveaux scores calculés.

4 Systeme de référence

4. 1 Données

Les systemes LIG et LIA ont été entrainés a partir des données fournies lors de la campagne
d’évaluation WMT 2011 et sur le corpus Gigaword fourni par le LDC. La Table 4.1 récapitule
l’ensemble des données utilisées et introduit les notations pour les corpus qui seront utilisées
dans la suite de l’article. Quatre corpus ont été utilisés pour construire le modele de traduction :
news—c, euro, UN et giga et trois corpus sont utilisés pour apprendre le modele de langage. Enﬁn,
deux corpus paralleles ont servi a optimiser les parametres : tuning—mt—LIG—LIA a été utilisé pour

534 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

CORPUS DESIGNATION NB PHRASES
Apprentissage News Commentary V6 news—c 1 16 k
bilingue Europarl V6 euro 1.8 M
Anglais/Francais UN corpus UN 12 M
109 corpus giga 23 M
Apprentissage News Commentary V6 mono—news-c 181 k
monolingue Shufﬂed News Crawl (2007 a 2011) news—s 25 M
Anglais Europarl V6 mono—euro 1.8 M
Développement newstest2008 + newssyscomb2009 dev 2553
newstest2009 optimisation-LIG-LIA 2525
Test newstest2010 test] 0 2489
newstest201 1 test] 1 3005

TABLE 1 — Corpus utilisés pour construire les systémes LIG et LIA (dans la campagne d’éValuau'on
WMT 201 1).

le développement des deux systémes LIG et LIA (Via MERT (Och, 2003)) tandis que le corpus
dev a été utilisé pour estimer les poids dédiés au décodage guidé. Les corpus test10 et test] 1 ont
quant a eux servi pour l’éValuau'on du décodage guidé.

4.2 Caractéristiques du systéme primaire utilisé (LIA)

Le systéme LIA est un systéme a base de segments (phrase-based). L’ensemble des données
utilisées provient de la campagne d’éValuation WMT 2011 et les données sont tokenisées aVec
les outils fournis lors de la campagne. Le modéle de langage 4-gramme a été appris a l’aide
de la boite a outils SRILM (Stolcke, 2002) aVec un modéle de repli Kneyser—Ney modiﬁé. Le
corpus paralléle a été aligné au niVeau des mots en utilisant Giza++ (Och et Ney, 2003) et
MGiza++ (Gao et Vogel, 2008) pour les corpus trés Volumineux. La table de phrases et les
modéles de réordonnancement ont été appris en utilisant les outils d’apprentissage de la suite
Moses (Koehn et al., 2007). Au ﬁnal, un ensemble de 14 parametres a été utilisé dans le systeme
(cf 3.3). Ces scores ont été optimisés sur le corpus newstest2009 comprenant 2525 phrases en
utilisant l’algorithme MER'I‘. Plus de détails se trouvent dans (Potet et al., 2011).

4.3 Performances du systéme primaire et des systémes auxiliaires

La Table 2 résume les scores BLEU obtenus par le systéme LIA sans la casse (tous les résultats de
l’article sont donnés sans la casse). L’éValuation des performances est effectuée sur 3 corpus : dev
qui correspond aux corpus newstest2008 + newssyscomb2009 de WMT (2553 phrases) ; tst10
qui correspond a newstest2010 (2489 phrases) et tst11 qui correspond a newstest2011 (3005
phrases). Nous présentons également les scores obtenus par les systémes auxiliaires LIG (non
décrit ici faute de place mais présenté dans (Potet et al., 2011)) et Google (systeme en ligne dans
sa Version de Février 2012). Nous sommes conscients du risque que le systeme Google utilisé en
2012 puisse contenir des données issues de WMT 2011, mais a la Vue des performances, ca ne
semble pas étre le cas. C’est principalement pour cette raison que nous avons également introduit
le systeme du LIG dont nous controlons parfaitement les données d’apprentissage.

535 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Systeme  dev tst10 tst11 Systeme  dev tst10 tst11
LIA (1) 25.45 29.30 29.30 DDA Google 26.37 30.16 30.52
LIG (2) 24.38 27.64 28.54 DDA LIG 25.71 29.57 29.51
Google (3) 24.62 28.38 29.83 DDA LIG-l-G (4) 26.41 30.44 30.91
MANY 1,2,3 26.3 30.46 30.6 ORACLE 2,3,4 29.16 33.8 34.35
ORACLE 1,2,3 29.5 34.0 34.63 ORACLE 1,2,3,4 30.0 34.7 35.2

TABLE 2 — Performances des systemes LIA, LIG et Google , d’une combinaison état de l’art via
MANY et performances du décodage guidé du systeme LIA par les systemes LIG et/ou Google

Aﬁn de nous comparer a un systeme de combinaison de référence, nous proposons aussi une
combinaison utilisant MANY (Barrault, 2010). MANY utilise un modele de langage (dans notre
cas, celui du LIA) afin de décoder un réseau de confusion constitué de l’ensemble des meilleures
hypotheses des différents systemes.

Pour ﬁnir, l’algorithme MIRA (Hasler et al., 2011) est utilisé pour recalculer tous les poids relatifs
au décodage guidé (entrainés sur le corpus dev).

5 Expériences et résultats

Le décodage guide’ (Driven Decoding Algorithm, DDA) a été utilise’ avec le LIA comme systeme
primaire dont les 500 meilleures hypotheses ont été extraites. Les transcriptions auxiliaires sont
ici les transcriptions issues des systemes LIG et Google dont les performances sont données dans
la Table 2. Cette table présente également les résultats du décodage guidé.

Nous constatons que le systeme LIA est meilleur que le systeme LIG. Cependant, la transcription
auxiliaire du LIG permet tout de meme d’améliorer ses performances par décodage guidé. Nous
observons également une amélioration qui se cumule 1orsqu’on ajoute le systeme de Google. Le
décodage guidé du systeme LIA améliore son score BLEU d’enViron 1 point en comparaison du
meilleur systeme individuel. De plus, les scores Oracle des combinaisons entre différents systemes
sont donnés a titre d’information. Il est intéressant de noter qu’en substituant le systeme LIA
au systeme DDA, le score Oracle baisse mécaniquement puisque le décodage guidé dégage un
consensus.

Les résultats sont également tres légerement supérieurs a ceux obtenus avec MANY, qui est un
systeme de combinaison état de l’art. Cependant, tandis que MANY nécessite un redécodage a
l’aide d’un modele de langage cible, le décodage guidé permet une combinaison différente et peu
coﬁteuse a mettre en oeuvre.

6 Analyse plus ﬁne du décodage guidé

La Table 3 et la Figure associée montrent les distances BLEU entre le décodage guidé par
I.IG+Goog1e, LIG, Google et1’ensemb1e des systemes utilisés seuls. Les similarités présentées ont
été calculées sur le corpus test11 (elles sont similaires sur les autres ensembles). Nous observons
que le décodage guidé LIG+Google se rapproche a la fois des systemes Google et LIG. Lorsqu’i1
utilise uniquement le systeme auxiliaire Google, au contraire il s’éloigne du I.IG. En revanche, en
utilisant uniquement le systeme auxiliaire LIG, l’hypothese obtenue ne s’éloigne pas de Google.
Ceci s’explique sans doute que le LIG et le LIA sont entrainés sur des données similaires, et les
systemes sont du meme type, tandis que les hypotheses de Google different un peu plus.

536 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Systéme || LIA DDA tout DDA LIG DDA Google

   

LIG 63.13 66.14 72.8 61.02 . , ,

LIA 100 77.2 83.6 77.19 LIG I , y , DDA
Google 51.01 66.29 51.76 65.93 ”
DDA tout 77.2 100 79.68 90.96

—o—LlG
—I- LIA
—.-— OOGLE
—><—DDA

GOOGLEV

TABLE 3 — Similarité entre les systemes. La métrique utilisée est le BLEU : Chaque sommet du
graphe correspond a un systeme qui est considéré comme référence par rapport aux autres.
DDA tout correspond au systéme DDA guidé a la fois par les systémes Google et LIA

La Figure montre le comportement induit par le décodage guidé : les hypotheses se rapprochent
ou s’éloignent des systemes auxiliaires. Il est intéressant de noter que le systeme LIG, a priori
moins performant que le systeme LIA a ﬁnalement une similarité tres élevée avec ce dernier.
L’utilisation d’une similarité BLEU entre les systemes permet donc de trouver un consensus
inter-hypotheses.

7 Conclusion et perspectives

Nous avons présenté une adaptation préliminaire du décodage guidé a la traduction automatique.
Ce paradigme permet une combinaison efﬁcace de systemes de traduction automatique, en
réévaluant le modéle log—linéaire au niveau des N meilleures hypotheses, en utilisant des systémes
auxiliaires. Le principe est de guider le processus de recherche en utilisant des sorties existantes.
Nous avons évalué différentes conﬁgurations sur le corpus WMT 2011. Les résultats montrent que
l’approche est efﬁcace et obtient des gains signiﬁcatifs en terrne de score BLEU. Par ailleurs, ces
résultats préliminaires sont équivalents (voire légérement meilleurs) a ceux obtenus en utilisant
des méthodes de combinaison état de l’art. Enﬁn, cette méthode a été récemment utilisée avec
succés lors de deux campagnes d’évaluation :

— Une campagne d’évaluation arabe/francais (TRAD) ou nous avons utilisé Google comme
systéme auxiliaire et le systéme du LIG comme systéme primaire.

— La campagne d’évaluation IWSLT 2012 (anglais/francais) o1‘1 nous avons utilisé le méme
systeme en ligne pour améliorer les performances du systéme primaire LIG. Les résultats de
cette campagne se trouvent dans (Besacier et al., 2012).

Nos futurs travaux vont se concentrer sur l’intégration du décodage guidé au sein du décodeur
Moses, au niveau de la fonction objective. Le second axe envisagé est l’utilisau'on de mesures de
conﬁance associées aux transcriptions auxiliaires, aﬁn de les exploiter plus ﬁnement.

Références

BANGALORE, S. (2001). Computing consensus translation from multiple machine translation
systems. In In Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop
(ASRU-2001, pages 351-354.

BARRAULT, L. (2010). Many : Open source machine translation system combination. In In
Prague Bulletin of Mathematical Linguistics, Special Issue on Open Source Tools for Machine
Translation(93), p. 145-155.

537 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

BESACIER, L., LECOUTEUX, B., AZOUZI, M. et LUONG NGOC, Q. (2012). The LIG English to French
Machine Translation System for IWSLT 2012. In In proceedings of the 9th International Workshop
on Spoken Language Translation (IWSLT).

GAO, Q. et VOGEL, S. (2008). Parallel implementations of word alignment tool. In Proceedings of
the ACL Workshop : Software Engineering, Testing, and Quality Assurance for Natural Language
Processing, pages 49-57, Columbus, OH, USA.

HASLER, E., HADDOW, B. et KOEHN, P. (2011). Margin infused relaxed algorithm for moses. In
The Prague Bulletin of Mathematical Linguistics, pages 96 :69—78.

HILDEBRAND, A. S. et VOGEL, S. (2008). Combination of machine translation systems via
hypothesis selection from combined n—best lists. In AMTA conference.

HILDEBRAND, A. S. et VOGEL, S. (2009). Combination of machine translation systems via
hypothesis selection from combined n—best lists. In Proceedings of Association for Machine
Translation in the Americas (AMTA), Hawa'i, USA.

KOEHN, P (2010). Statistical Machine Translation. Cambridge University Press, New York.
KOEHN, P, HOANG, H., BIRCH, A., CALLIsoN—BURCH, C., FEDERICO, M., BERTOLDI, N., CowAN, B.,
SHEN, W., MORAN, C., ZENS, R., DYER, C., BOJAR, 0., CONSTANTIN, A. et HERBST, E. (2007). Moses :
Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting
of the Association for Computational Linguistics (ACL), Companion Volume, pages 177-180,
Prague, Czech Republic.

LECOUTEUX, B., LINARES, G., ESTEVE, Y. et GRAVIER, G. (2013). Dynamic combination of automatic
speech recognition systems by driven decoding. IEEE Transactions on Audio, Speech and Signal
Processing, 21, issue 6:1251 — 1260.

LECOUTEUX, B., LINARES, G. et OCER, S. (2012). Integrating imperfect transcripts into speech
recognition systems for building high—quality corpora. Computer Speech and Language, 26(2):67
— 89.

L1, M., DUAN, N., ZHANC, D., LI, C.—H. et ZHoU, M. (2009). Collaborative decoding : Partial
hypothesis re—ranking using translation consensus between decoders. In Proceedings of the 47th
Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP.

LIN, C.-Y. et OCH, E J. (2004). Orange : a method for evaluating automatic evaluation metrics
for machine translation. In In COLING '04 : Proceedings of the 20th international conference on
Computational Linguistics.

OCH, E J. (2003). Minimum error rate training in statistical machine translation. In Proceedings
of the 41st Annual Meeting on Association for Computational Linguistics (ACL), Sapporo, Japan.
OCH, E J. et NEY, H. (2003). A systematic comparison of various statistical alignment models.
Computational Linguistics, 29(1):19—51.

POTET, M., RUBINO, R., LECOUTEUX, B., HUET, S., BESACIER, L., BLANCHON, H. et LEFEVRE, E (2011).
The LIGA machine translation system for WMT 2011. In Proceedings EMNLP and ACL Workshop
on Machine Translation (WMT), Edinburgh (Scotland).

ROSTI, A.—v., AYAN, N.—E, XIANG, B., MATSOUKAS, S., SCHWARTZ, R. et DoRR, B. (2007a). Combining
outputs from multiple machine translation systems. In In Proceedings of the North American
Chapter of the Association for Computational Linguistics Human Language Technologies, pages
228-235.

ROSTI, A.—v., MATSOUKAS, S. et SCHWARTZ, R. (2007b). Improved word—level system combination
for machine translation. In In Proceedings of ACL.

STOLCKE, A. (2002). SRILM — an extensible language modeling toolkit. In Proceedings of the
7th International Conference on Spoken Language Processing (ICSLP), Denver, CO, USA.

538 © ATALA

