TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Edition interactive d’énoncés en langue des signes
francaise dédiée aux avatars signeurs

Ludovic Hamon-1 Sylvie Gibet-1 Sabah Boustilaz
(1) IRISA, Université Bretagne Sud, Campus de Tohannic, Rue Yves Mainguy, 56000 Vannes
(2) ICUBE, Université de Strasbourg, 300 bd Sébastien Brant, BP 10413, 67412 IIIkirch Cedex, France
ludovic .hamon@univ—ubs .fr , Sylvie . Gibet©univ—ubs . fr , boustila©unistra . fr

RESUME

Les avatars signeurs en Langue des Signes Francaise (LSF) sont de plus en plus utilisés en
tant qu’interface de communication a destination de la communauté sourde. L’un des critéres
d’acceptation de ces avatars est l’aspect naturel et réaliste des gestes produits. Par conséquent,
des méthodes de synthése de gestes ont été élaborées 31 l’aide de corpus de mouvements
capturés et annotés provenant d’un signeur réel. Néanmoins, l’enrichissement d’un tel corpus,
en faisant ﬁ des séances de captures supplémentaires, demeure une problématique certaine.
De plus, l’application automatique d’opérations sur ces mouvements (e.g. concaténation,
mélange, etc.) ne garantit pas la consistance sémantique du geste résultant. Une alternative
est d’insérer l’opérateur humain dans la boucle de construction des énoncés en LSE Dans
cette optique, cet article propose un premier systéme interactif d’édition de gestes en LSE

I

base "données capturées" et dédié aux avatars signeurs.

ABSTRACT
Interactive editing of utterances in French sign language dedicated to signing avatars

Signing avatars dedicated to French Sign Language (LSF) are more and more used as a
communication interface for the deaf community. One of the acceptation criteria of these
avatars is the natural and realistic aspect of the constructed gestures. Consequently, gestures
synthesis methods have been designed thanks to some corpus of captured and annotated
motions, performed by a real signer. However, the enlarging of such a corpus, without
requiring of some additional capture sessions, is a major issue. Furthermore, the automatic
application of motion transformations (e.g. concatenation, blending, etc.) does not guarantee
the semantic consistency of the resulting gesture. Another option is to insert the human
operator in the utterance building loop. In this context, this paper provides a ﬁrst interactive
editing system of FSL gestures, based on captured motions and dedicated to signing avatars.

MOTS—CLES : Langue des Signes Francaise, édition, geste, base de données sémantiques,
signeur virtuel, interaction.

KEYWORDS: French sign language, editing, gesture, semantic data base, virtual signer,
interaction.

547 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
1 Introduction

La Langue des Signes Francaise (LSF) est une langue a part entiere et constitue l’un des piliers
de l’identité et de la culture sourdes. La loi 2005-102 du 11 février 2005 << pour l’égalité
des droits et des chances, la participation et la citoyenneté des personnes handicapées >> a
favorisé l’émergence d’applications dédiées a la promotion des moyens de communication et
de diffusion de l’information en LSE Dans le cadre de ces applications, l’utilisation de Signeurs
Virtuels (SV) pour produire des messages en LSF semble étre une alternative intéressante a la
production de vidéos, dans la mesure o1‘1 elle préserve l’anonymat des personnes sourdes et
permet de manipuler, transférer et Visualiser de nouveaux énoncés.

Dans ce contexte, les SV dédiés aux langues des signes font l’objet de recherches et d’études
avancées, alliant l’analyse linguistique a la synthese de gestes a partir de langages de construc-
tion dédiés. Quelle que soient la précision et l’expressivité du systeme d’édition, la construction
d’un SV souléve des problématiques nombreuses dont l’une est commune a tous les SV : la
recherche d’une cohérence linguistique des mouvements produits.

Parmi les techniques de synthese de gestes en LSE celles basées sur des mouvements capturés
par un signeur réel, offrent l’avantage, d’un point de vue subjectif, d’obtenir des mouvements
plus naturels et acceptables pour la communauté sourde (Gibet et al., 2011), (Héloir, 2008),
(Parisot et al., 2010). Néanmoins, ce type de synthése nécessite la déﬁnition d’un corpus
préalable, obtenu apres plusieurs séances de captures de mouvements coﬁteuses et fastidieuses.
Par conséquent, le corpus initial est généralement réduit. Son enrichissement conduit a des
solutions discutables telles que des séances de captures supplémentaires ou l’application de
transformations complexes sur des mouvements pré—enregistrés, entrainant des modiﬁcations
sémantiques incertaines.

Cet article présente une méthode alternative sous la forme d’un premier "framework" d’édition
de la LSF a partir de corpus de gestes capturés. A l’aide de ce systeme, l’utilisateur peut créer
de nouveaux énoncés en LSF et identiﬁer/évaluer la sémantique résultant des gestes créés
durant la simulation virtuelle. La deuxiéme partie de ce document présente un état de l’art
relatif aux langages de description et de spéciﬁcation des gestes dans le contexte des SV La
troisiéme section présente une analyse sur les principaux déﬁs et contraintes d’un systéme
d’édition de mouvements de la LSF. Le systeme d’édition est décrit dans la quatrieme section
avec des exemples illustrant ses possibilités et limites. Enﬁn, des perspectives sur les travaux
futurs concluent ce document.

2 ﬁtat de l’art

Cette section présente, de maniere non exhaustive, les langages de description et de spéciﬁca-
tion des gestes en LSF relatifs aux S\l ainsi que les systemes d’animation a partir de données
capturées, du point de we de l’édition de gestes en LSE

Les systémes de description ou de notation des gestes en LSF ont généralement pour but de
décrire des mouvements plus ou moins structurés et codiﬁés. Des éléments constituant des
signes sont généralement identiﬁés ainsi que, si possible, des régles syntaxiques et séman-
tiques régissant leur agencement. On distingue ainsi les unités atomiques appelées gestémes

548 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

(Gibet et al., 2001; Vogler, 2003) (phonemes dans les langues parlées), les morphemes (plus
petites unités porteuses de sens, encore appelées unités phonologiques), les signes ou gloses
(combinaisons de signes), les phrases (séquence de signes), les discours. Plusieurs systémes
de notation existent, l’un des plus utilisés aujourd’hui étant HamNoSys (Prillwitz et al., 1989).
D’autres systemes de description suivent différentes approches telles que la description para-
métrique (Stokoe, 2005), l’approche structurelle phonétique (Liddell, 1989), la visée iconique
(Cuxac, 2000) ou la représentation géométrique (Filhol, 2008).

Les langages de spéciﬁcation permettent de décrire le comportement d’un SV 31 l’aide d’un
formalisme de description de commandes gestuelles. Les données (e.g. signes, phrases, suites
de syrnboles, fonctions, etc.) issues de ces formalismes sont généralement interprétées en
une séquence de paramétres de bas niveau, qui sont directement utilisés pour produire
l’animation du SV Un langage de spéciﬁcation peut étre vu comme une premiere Interface
Homme—Machine (IHM) ou l’utilisateur peut éditer, avant le lancement de l’animation, les
mouvements générés par le SV Les formalismes de spéciﬁcation des gestes peuvent aller du
script basé sur la structure des éléments phonétiques ou morphémiques (Gibet et al., 2001 ;
Elliott et al., 2008) jusqu’a des langages prenant en compte d’autres aspects linguistiques
des langues des signes, tels que les classiﬁeurs traduisant l’iconicité des signes (Huenerfauth,
2006), la description de l’espace de signation (Lenseigne et Dalle, 2006) ou la construction
syntaxique de phrases en LSF (Losson, 2000; Kervajan, 2011) par exemple.

Les contributions apportées par ces langages sont multiples et vont de la description non
ambigué des signes en termes de structures séquentielles, uni-modales et évoluant dans le
temps, jusqu’a la prise en compte de leurs aspects modulatoires. Cependant, les langues des
signes transmettent un message exprimé simultanément via différents canaux i.e. plusieurs
parties du corps (e.g. mains, expression faciale, regard, etc.) (Huenerfauth, 2006; Vogler,
2003). Cette organisation parallélisée des gestes associée a la signiﬁcation linguistique de
leurs composants est rarement prise en compte par ces langages. De plus, l’édition des
phrases en LSF reste complexe et fastidieuse, peu intuitive, elle nécessite de connaitre le
langage informatique et son paramétrage ainsi que de maitriser la structure phonétique et
morphologique des signes. 11 en résulte que les langages de spéciﬁcation ne permettent pas,
dans la majorité des cas, de déﬁnir en un temps de spéciﬁcation satisfaisant le comportement
du SV ni de générer des animations réalistes.

La synthése de phrases en LSF requiert la mise en place de méthodes traduisant un scénario
spéciﬁé dans l’un des formalismes décrit précédemment, en une séquence de commandes
gestuelles interprétable par le moteur d’animation. Les méthodes basées sur des mouvements
enregistrés lors d’une séance de captures avec un acteur réel, permettent généralement
de rendre l’avatar virtuel plus "expressif" et "naturel" que les méthodes procédurales et
descriptives (Gibet et al., 201 1). Néanmoins, dans le cadre d’un signeur virtuel, deux difﬁcultés
apparaissent : (i) la combinaison et le parallélisme de plusieurs canaux, i.e. la production de
gestes exécutés simultanément par plusieurs parties du corps incluant le torse, les épaules,
les mains et le visage et (ii), la concaténation d’unités de mouvements qui ne garantit pas
la consistance sémantique du mouvement résultant. Dans ce contexte, aucune équipe de
recherche ne s’est intéressée a cette double problématique.

549 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d'Olonne
3 Besoins et contraintes d’un systéme d’édition de gestes

L’un des points centraux d’un systeme d’édition interactive de gestes en LSF est d’utiliser,
pour la synthese des mouvements de l’avatar, des données capturées sur un signeur réel.
Nous proposons le schéma conceptuel suivant, centré autour de la gestion de données de
la LSF pour construire de nouveaux énoncés et générer en sortie une animation d’un SV
(Figure 1). Nous détaillons ci—aprés les différents modules de cette architecture, en précisant
les défis a relever ainsi que les principales contraintes et limites d’un tel systéme d’édition. Ils
comprennent (i) l’annotation sémantique des données, (ii) la base de données hétérogénes
associée au moteur de requétes, (iii) l’IHM permettant la construction d’énoncés en LSF, (iv)
le moteur d’animation et de visualisation 3D.

IHM

Q:

T #

'"d°X3‘i°" Bdd indexée ‘ 4'

texmelle Annotations ‘e '
""°gE”" Moteur ‘ ‘

_ FIEOUETES d'an|mat|on
'"d°"3"°" Bdd indexée '
du Signal Mauvements r

Base de données hétérogénes

Annotation

        
      

Capture du
mouvement

   

FIGURE 1 — Schéma conceptuel d’un systéme d’édition de gestes en LSF

Annotation sémantique des données : L’annotation des données capturées a partir des
vidéos réelles est une étape située au coeur du processus d’édition. En effet, c’est a ce
niveau que s’effectue réellement le lien entre la structuration linguistique des données et la
caractérisation ﬁne des éléments servant a contréler l’animation de l’avatar. Aﬁn de réaliser
ce couplage, il est nécessaire de considérer plusieurs pistes d’annotation ou canaux tels que
la conﬁguration et l’emplacement des mains, l’expression faciale, la direction du regard, etc.
La segmentation temporelle permet de déﬁnir les fragments temporels sur chacune des pistes
correspondant aux gloses, signes, éléments phonologiques et morphémiques. Chaque fragment
comporte une étiquette propre aux Valeurs/attributs sémantiques déﬁnis suivant un schéma
de spéciﬁcation phonétique/phonologique/syntaxique (Duarte, 2012). Cette annotation, a
la fois spatiale et temporelle, réalisée a partir des vidéos enregistrées lors de la séance de
captures de mouvements avec le logiciel ELANTM , a notamment été exploitée dans le cadre
du projet SignCom (Gibet et al., 2011).

Base de données hétérogénes : Aﬁn de générer des animations a partir des données préa—
lablement enregistrées, il est nécessaire de construire une base de données, par nature
hétérogénes, constituée de deux parties : (i) une base de données de mouvements, contenant
les mouvements bruts, (ii) une base de données sémantiques, permettant d’indexer chaque
fragment de mouvement selon une catégorisation linguistique. Le principal déﬁ technique
revient ici a déﬁnir les meilleures structures d’indexation a la fois pour le texte (données
d’annotation) et pour le signal (données issues de la capture), tout en maintenant la cohé—

550 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

rence et la consistance entre ces deux niveaux d’information. Il est important a ce niveau de
considérer l’efﬁcacité de l’accés aux données et la capacité du langage d’interrogation de la
base de données a extraire des informations précises et pertinentes. Un dictionnaire met en
correspondance les annotations et les fragments de mouvements représentés par un ensemble
de paramétres formels incluant l’identiﬁant du mouvement, la partie du corps concernée,
les postures de début et de ﬁn, etc. Pour extraire / charger un fragment de mouvement, il est
possible d’interroger directement la base de données brutes avec les paramétres formels ou
d’interroger la base de données sémantiques avec une glose, qui délivrera les paramétres
formels, correspondant a un fragment de mouvement de la base de données brutes.

Interface et construction d’énoncés en LSF : La manipulation d’énoncés en LSF nécessite
la mise en oeuvre de mécanismes interactifs a la fois intuitifs et efﬁcaces pour caractériser les
différents niveaux du langage : choix des signes/gloses, ordonnancement des gloses induisant
la syntaxe des énoncés, aspects clausaux (négation, interrogation, etc.) souvent liés aux
expressions faciales, informations émotionnelles (liées a la prosodie), etc. 11 est nécessaire
également de déﬁnir la facon de rechercher les mouvements dans le contexte de l’énoncé,
ainsi que les paramétres de l’animation caractérisant la ﬂuidité du mouvement. Enﬁn, on
précise a ce niveau les choix d’apparence de l’avatar et les paramétres liés a la visualisation
3D (modélisation 3D, habillage, scene, éclairage, etc.).

  CM bras droit 1 CM bras droit 2 CM bras droit 3

EEEETEM

[CM dos ﬂ [CM dos 2] [CM 41053] [CB bras droit 1] Pfiofité

CM corps 1

 

[CM bras droit 1] [CM bras droit 2] [CM bras droit 3]

Temps

(8) (b)

FIGURE 2 — Systéme de contréleurs dans le projet SignCom (Gibet et al., 201 1). (a) arborescence
des contréleurs, (b) structures spatiale et temporelle des contréleurs. CM : contréleur de type
rejeu i.e. "Motion player", CB : controleur de type "mélangeur" i.e. "Blender".

Animation du signeur virtuel : La création de nouveaux mouvements peut étre réalisée par
un assemblage de deux types de composants d’animation nommés "contréleurs" (Figure 2).
Le controleur de type "rejeu" (CM), associé a une partie du corps, récupére un fragment de
mouvement de la base de données. Le controleur de type "mélangeur" (CB) mélange les CM
temporellement, par interpolation ou concaténation et spatialement, en donnant une priorité
dans l’ordre d’exécution du mouvement, selon la partie du corps concemée (Figure 2(b)).
Dans le cadre du projet SignCom, des controleurs ont été déﬁnis a l’aide d’une arborescence
(Figure 2(a)) spéciﬁée dans un script textuel simple. Du point de vue de l’édition, chaque
CM représentant un geste, un énoncé est ici déﬁni comme une organisation séquentielle et
parallele des gestes en LSF par cette arborescence.

551 © ATALA

TALN-RFCITAL 2013, 17-21 Iuin, Les Sables d’Olonne
4 Mise en oeuvre d’un systeme d’édition de gestes

RE“"€‘E Gluse(s)

-Id de mov.
-Pattie corps
-ﬂrame deb.
4rame ﬁn

Mouvemenll
Marceau de : 1 Squeleltel ch; amen
mouvement Posture Mote." de rend"

FIGURE 3 — Architecture du systéme d’édition de gestes

   
    
 

  
       
    
  
       

Créatlon/Elditicm
des oanlréleu rs

Requéte

 

  
  

  

Base de
données

 

Les capacités du projet SignCom, en termes d’édition de gestes, possédent certaines limites
telles que la non—édition des controleurs lors de la simulation, l’utilisation de paramétres
formels peu intuitifs et la non-exploitation de la base de données sémantiques (Gibet et al.,
2011).

Pour palier ces limites, un nouveau systéme d’édition a été créé (Figure 3). Ce systéme
repose sur l’évolution de l’architecture du projet SignCom et sur un couple "module d’édi-
tion"/ "interface graphique". Ce couple offre les moyens de créer et de spéciﬁer les contréleurs
ainsi que d’observer une représentation de leur arborescence (Figure 5). Ce systéme permet,
de plus, d’interroger la base de données avec une glose (i.e. interrogation de la base de
données sémantiques) ou avec l’ensemble des paramétres formels (i. e. interrogation de la
base de données brutes) dans le but d’extraire un fragment de mouvement et de le charger
dans un CM.

| Moi /Je-n'aime-pas / Ie-jus—d‘orange |

| Head | | Head |

| Right arm | | Right arm |

| Torso I Lower body / Left arm |

 

(b)

FIGURE 4 — (a) Visualisation de l’avatar signeur (b) Construction d’énoncés a partir de la
spéciﬁcation de la séquence de signes / gloses et des controleurs associés sur les différents
canaux gestuels

Par conséquent, créer et éditer de nouveaux énoncés revient a spéciﬁer et a éditer, de maniere
complete, la séquence de signes, a identiﬁer les controleurs correspondants sur chaque
partie du corps et leur hiérarchie par l’intermédiaire de l’interface graphique; la qualité de
l’animation résultante peut étre évaluée en temps réel (Figure 4).

L’interface graphique est illustrée par la partie gauche de la ﬁgure 5(a). La partie "Bvh File
search" permet de spéciﬁer le type de contréleurs ainsi que ses paramétres formels pour les
CM et son type d’algorithme de mélange pour les CB. La création d’un CM, par une recherche

552 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Sﬂlﬂt An imatmn

Body Part
Blend Type

Bvh FVIE‘
farms in
frame out

Dccuren ca 5

 

(b)

 

FIGURE 5 — (a) Apergu de l’interface graphique (b) Extrait d’un scénario construit o1‘.1 l’avatar
décrit la préparation d’un cocktail

selon une ou plusieurs glose(s) dans la base de données, peut étre effectuée par la section
"Search by keywords". La partie "Up to date" est dédiée a l’édition de chaque type de paramétre
d’un contréleur, avec une sous—section propre a chaque type. La hiérarchie des contréleurs est
afﬁchée "textuellement" (Figure 5(a) haut gauche). Enﬁn, la ﬁgure 5(b) montre un extrait
d’un scénario construit sur le théme de la description de l’élaboration d’un cocktail.

5 Conclusion et perspectives

Cet article présente un premier systéme original d’édition interactive de gestes de la Langue
des Signes Francaise (LSF) dédié aux Signeurs Virtuels (SV). Reposant sur une base de données
hétérogénes de mouvements capturés et annotés, ce systéme perrnet la concaténation et le
mélange de gestes temporellement et spatialement a l’aide d’une interface graphique.

L’enrichissement d’un corpus de mouvements capturés de la LSF pour les SV demeure un
probleme complexe. Les solutions existantes peuvent étre coﬁteuses et laborieuses (e.g.
séances de captures de mouvements supplémentaires) ou incertaines (e.g. application de
transformations sur des fragments de mouvements modiﬁant leur sémantique). La ou le
mouvement est étroitement he a une sémantique, les systemes d’édition de gestes en LSF
dédiés aux SV semblent étre de plus en plus nécessaires pour construire, éditer et enrichir de
tels corpus.

Les perspectives de ces travaux reposent sur l’enregistrement, dans la base de données
hétérogenes, des nouveaux mouvements créés ainsi que de leurs sémantiques associées de
maniere optimale. Pour cela, la recherche d’une interface d’édition plus complete et plus
intuitive (e.g. édition graphique de la hiérarchie des contréleurs) sera poursuivie selon deux
directions : (i) l’abstraction de tout paramétre numérique pour les non—experts du domaine de
l’animation et (ii) l’édition aux niveaux spatial et temporel de la sémantique des mouvements
créés a l’image des systémes d’annotation vidéo actuels (e.g. logiciel ELAN). Des algorithmes
d’apprentissage seront, par la suite, étudiés pour construire un systeme de "suggestions
sémantiques" des mouvements créés par l’utilisateur, en fonction des opérations d’édition
effectuées.

553 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
Références

CUXAC, C. (2000). La langue des signes francaise (lsf) : les voies de l’iconocité. In Faits de
langues, numéro 15-16. Ophrys.

DUARTE, K. (2012). Motion capture and avatars as portals for analyzing the linguistic
structure of signed languages. In PhD thesis, Universite' de Bretagne Sud.

ELLIOTT, R., GLAUERT, J. R. W., KENNAWAY, J. R., MARSHALL, I. et SAFAR, E. (2008). Linguistic
modelling and language—processing technologies for avatar—based sign language presentation.
In Universal Access in the Information Society, volume 6, pages 375-391.

FILHOL, M. (2008). Modéle descriptif des signes pour un traitement automatique des langues
des signes. In These de doctorat, Universite' Paris—Sud.

GIBET, S., COURTY, N., DUARTE, K. et NAOUR, T. L. (2011). The signcom system for data-
driven animation of interactive virtual signers : Methodology and evaluation. http : //
www— irisa . univ-ubs . fr/Valoria/signcom/en/.

GIBET, S., LEBOURQUE, T. et MARTEAU, P. (2001). High level speciﬁcation and animation of
communicative gestures. In Journal of Visual Languages and Computing, volume 12, pages
657-687.

HELOIR, A. (2008). Systéme de communication par agent virtuel, aide a la communication
des personnes sourdes. In These de doctorat, Universite' de Bretagne Sud, pages 168-171.

HUENERFAUTH, M. (2006). Generating american sign language classiﬁer predicates for
english-to-asl machine translation. In These de doctorat, University of Pennsylvania.

KERVAJAN, L. (2011). Contribution a la traduction automatique francais / langue des signes
francaise (lsf) au moyen de personnages virtuels. In PhD thesis, Universite' d’Aix/Marseille.

LENSEIGNE, B. et DALLE, P. (2006). Using signing space as a representation for sign language
processing. In GIBET, S. et al., éditeurs : Gesture in Human—Computer Interaction and
Simulation, GI/I5 Lecture Notes in Computer Science, volume 3881, pages 256-260. Kluwer
Academic.

LIDDELL, S K et Johnson, R. E. (1989). American sign language : The phonological base. In
Studies in the Linguistic Sciences, volume 64, pages 197-277.

LOSSON, O. (2000). Modélisation du geste communicatif et réalisation d’un signeur virtuel
de phrases en langue des signes francaise. In PhD thesis, Universite' de Lille.

PARISOT, A. M., S, R., S, V et A, V (2010). Construire et déconstruire l’espace dans une langue
des signes : démonstration d’un protocole d’enregistrement simultané des mouvements des
membres supérieurs et du globe oculaire. In Atelier TALS 2010 dans le cadre du congrés TAIN
201 0.

PRILLWITZ, S., LEVEN, R., ZIENERT, H., HANKE, T. et HENNING, J. (1989). Hamburg Notation
System for Sign Languages — An Introductory Guide. University of Hamburg Press.

STOKOE, W. C. (2005). Sign language structure : an outline of the communication systems
of the american deaf. In Linguistics, Occasional Papers 8 (1960), Journal of Deaf Studies and
Deaf Education, volume 10, pages 3-37.

VOGLER, C. (2003). American sign language recognition : Reducing the complexity of the
task with phoneme—based modeling and parallel hidden markov models. In PhD Thesis,
University of Pennsylvania.

554 © ATALA

