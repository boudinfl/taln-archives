TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Segmentation Multilingue des Mots Composés

Elizaveta Loginova—Clouet1 Béatrice Daillel
(1) LINA, 2, rue de la Houssiniere 44322 Nantes Cedex 03
elizaveta. loginova@u.uiv-nantes . fr , beatrice . daille@u.uiv-nantes . fr

RESUME:
La composition est un phénomene fréquent dans plusieurs langues, surtout dans des langues
ayant une morphologie riche. Le traitement des mots composés est un déﬁ pour les systemes
de TAL car pour la plupart, ils ne sont pas présents dans les lexiques. Dans cet article, nous
présentons une méthode de segmentation des composés qui combine des caractéristiques
indépendantes de la langue (mesure de similarité, données du corpus) avec des régles de
transformation sur les frontiéres des composants spéciﬁques a une langue. Nos expériences de
segmentation de termes composés allemands et russes montrent une exactitude jusqu’a 95 %
pour l’allemand et jusqu’a 91 % pour le russe. Nous constatons que l’utilisation de corpus
spécialisés relevant du meme domaine que les composés améliore la qualité de segmentation.

ABSTRACT
Multilingual Compound Splitting

Compounding is a common phenomenon for many languages, especially those with a rich
morphology. Dealing with compounds is a challenge for natural language processing systems
since all compounds can not be included in lexicons. In this paper, We present a compound
splitting method combining language independent features (similarity measure, corpus data)
and language dependent features (component transformation rules). We report on our
experiments in splitting of German and Russian compound terms giving accuracy up to 95%
for German and up to 91% for Russian language. We observe that the usage of a corpus of
the same domain as compounds improves splitting quality.

MOTS—CL]:3S I segmentation des mots composés, outil multilingue, mesure de similarité,
regles de transformation des composants, corpus spécialisés.

KEYWORDS: compound splitting, multilingual tool, similarity measure, component trans-
formation rules, specialized corpora.

564 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
1 Introduction

La composition est un mécanisme de formation des mots qui consiste a combiner deux (ou
plusieurs) éléments lexicaux autonomes pour former une unité de sens. Ce phénoméne est
notamment présent dans les langues allemande, néerlandaise, grecque, suédoise, danoise,
ﬁnlandaise et russe. Le traitement des mots composés est une difﬁculté pour les systémes
de traitement automatique des langues parce que la plupart des composés ne sont pas
recensés dans les ressources lexicales. Ainsi leur reconnaissance et leur segmentation seraient
bénéﬁques pour des taches variées du TAL : traduction automatique (Macherey et al. (2011),
Weller et Heid (2012)), recherche d’information (Braschler et Ripplinger, 2004), recherche
d’information multilingue (Chen et Gey, 2001), etc.

Les mécanismes de composition sont plus ou moins complexes en fonction des langues. Dans
les langues trés analytiques comme les langues frangaise et anglaise les composants sont
simplement concaténés : FR kilowatt-heure, EN parrotﬁshl, « poisson perroquet >>.

Dans les langues ayant une morphologie riche, des transformations sont possibles aux frontiéres
des parties composantes. La terminaison du mot peut étre omise, et/ou des morphémes
« frontieres » rajoutés, par exemple en allemand :

Staatsfeind (« ennemie d’état >>) = Staat (« état ») + Feind (« ennemie »);

Pour certaines langues, les régles sont peu nombreuses et exhaustives. Pour d’autres, des
phénomenes plus complexes interviennent comme la modiﬁcation du radical en russe :

13eTporeHepaTop (« générateur éolien >>)
vetrogenerator2 = vetg (« vent >>) + generator (« générateur »);

Les « composés néoclassiques >>, c’est-a-dire des composés ayant un ou plusieurs éléments
d’origine latine ou grecque (Namer, 2009), sont un cas particulier de composition on les
éléments lexicaux ne sont pas autonomes : FR multimédia, DE Turbomaschine (« turboma-
chine »), etc. Ces éléments néoclassiques sont généralement absents des dictionnaires ou des
bases de données lexicales.

Certains systémes de TAL optent pour le stockage de tous les composants connus dans
le lexique (a notre connaissance, c’est généralement le cas des systémes pour le russe).
Cette solution nous semble insatisfaisante pour des taches multilingues car ceci augmente
considérablement la couverture du dictionnaire.

Dans cet article, nous faisons le tour d’horizon des méthodes de segmentation automatique
des mots composés. Ensuite, nous proposons une méthode combinant des traits dépendants
et indépendants de la langue. Enﬁn, nous présentons nos expériences de segmentation des
composés allemands et russes.

2 Méthodes de segmentation des mots composés

Parmi les méthodes de segmentation des composés, on peut distinguer les méthodes utilisant
des regles formulées manuellement et des méthodes completement statistiques.

1. EN - langue anglaise, DE - langue allemande, RU - langue russe
2. Les exemples russes sont translittérés.

565 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Le premier type de méthodes déﬁnit des regles de segmentation telles que celles de trans-
formations aux frontiéres des composants en allemand. Généralement celles-ci utilisent des
régles de formation des composés décrites par Langer (1998).

Pour choisir parmi plusieurs segmentations, les composants ainsi identiﬁés sont ensuite
recherchés soit dans un dictionnaire (segmenteur Banana Split 3), soit dans un corpus
monolingue (Koehn et Knight (2003), IMS Splitter4). Les approches basées sur le corpus
affectent également une probabilité a chaque segmentation, estimée sur la base de la fréquence
des composants dans le corpus. Un corpus parallele allemand-anglais peut étre exploité aﬁn
d’y vériﬁer les correspondances des parties décomposées (Koehn et Knight, 2003).

Les approches du deuxieme groupe ne requierent pas de regles spéciﬁques pour chaque
langue donnée. Macherey et al. (2011) proposent d’extraire automatiquement des opérations
morphologiques sur les frontiéres de composants. L’entrainement du modéle pour une nouvelle
langue nécessite un corpus parallele contenant une partie anglaise. Hewlett et Cohen (2011)
détectent automatiquement la place des frontiéres de composants. L’algorithme est basé sur
la probabilité des séquences de caractéres dans une langue.

Actuellement, les modeles purement statistiques ne sont pas aussi précis que des modeles
utilisant des régles, leur avantage réside toutefois dans la possibilité de réutilisation pour des
langues variées.

3 Algorithme de segmentation

Notre objectif est de créer un outil de segmentation des mots composés générique et multilingue
qui pourrait étre appliqué a des différentes langues grace aux traits indépendants de la langue
sans nécessiter de connaissances préalables. Néanmoins si des regles existent, cet outil doit
étre capable de les intégrer. Les caractéristiques indépendantes de la langue exploitées sont
la fréquence des mots dans un corpus monolingue, et la similarité entre une sous-chaine du
mot et les lemmes candidats.

Pour segmenter un composé, nous commengons par générer toutes ses segmentations possibles
en deux parties, de taille supérieure ou égale a la longueur minimale acceptée pour un
composant. Par exemple DE Tmktionsbattema (« batterie de traction >>) :

traktionsbatterie —> tr + aktionsbatterie
traktionsbatterie —> tra + ktionsbatterie

traktionsbatterie —> traktionsbatter + ie

Si des regles de transformation des composants en lexemes indépendants sont disponibles
pour la langue donnée, elles sont appliquées aux composants candidats. Ce sont des régles de
type : « s » —> « », (of. DE exemple Staatsfeind), « en » —> « um », etc.

Pour chaque segmentation candidate, les deux parties sont recherchées dans un dictionnaire
monolingue, et optionnellement dans un corpus monolingue. Le corpus permet de calculer
les fréquences des mots, ce qui aide a choisir les composants candidats les plus plausibles
lorsque plusieurs variantes sont possibles.

3. http : //niels . drni . de/s9y/pages/bananasplit . html
4. http : //www . ims . u.ui- stuttgart . de/~wellerm.u/tools . html

566 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Nous calculons ensuite la similarité entre chacune des deux parties de segmentation et les
lemmes du dictionnaire/corpus aﬁn de choisir les lemmes « les plus proches ». Nous utilisons
« la distance d’édition normalisée » basée sur la distance de Levenshtein comme mesure de
similarité (pour la description détaillée des mesures existantes cf. (Frunza et Inkpen, 2009)) :

_ nbEdz'tOper
maa:(length(X), length(Y))

ou nbEditOper est le nombre minimal d’opérations d’édition (substitution, suppression,
insertion) nécessaires pour transformer un composant X en un lemme Y.

sz'm(X, Y) = 1

Si certains lemmes sont acceptables (i.e. avec une similarité supérieure ou égale a un seuil
déﬁni) pour la partie gauche de la segmentation courante, mais non pour la partie droite,
nous réitérons la segmentation jusqu’a trouver des composants attestés ou jusqu’a un nombre
maximal de composants.

RU KnJIo3JIeKTpoHBo.7ILT (« kiloélectronvolt >>) :

kiloelektronvolt —> kilo + elektronvolt

elektronvolt —> elektron + volt
Dans le cas 011 des lemmes candidats sont acceptables pour chaque composant, nous calculons
le score de cette segmentation a chaque niveau de décomposition :

  si correspondance exacte
_ 2
S(segm) _ S(compA)+S(compB) Simon
nbComp

ou nbComp est le nombre de composants dans le mot, et « correspondance exacte » signiﬁe
que tous les composants ont été trouvés en l’état dans le dictionnaire/ corpus. Le score d’un
composant est calculé de la maniére suivante :

S'(comp) = sz'm(comp, lemma)"bC°m” X (inDico + inCorpus + freqCorpus)

ou inDico et inCorpus sont des valeurs attestant la présence ou l’absence du lemme dans le
dictionnaire et le corpus, et freqCorpus est égale a la fréquence relative du lemme dans le
corpus. La mesure de similarité est élevée a la puissance nbComp pour augmenter son impact
lorsque le niveau de décomposition croit : plus il y a de composants dans la segmentation
candidate, plus il est accordé d’importance au fait que les composants soient proches des
lemmes trouvés (le cas le plus favorable étant celui d’une mesure de similarité égale a 1).

Enﬁn, l’algorithme retourne le Top N des meilleures segmentations classées par score décrois-
sant. Par exemple, pour DE Tinktionsbatterie (« batterie de traction ») le résultat aﬂiché est
le suivant :

traktion + batterie 1.50

trakt + ion + batterie 1.25
La segmentation correcte est Traktion + Batterie, et celle-ci obtient le meilleur score d’aprés
le programme.

4 Expériences et données

Dans cette section, nous décrivons nos expériences en utilisant le précédent algorithme.
Jusqu’a présent il a été appliqué a deux langues : l’allemande et le russe. La composition en

567 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

allemand est tres productive et bien décrite. La composition en russe l’est moins, méme si
elle est plus fréquente dans les domaines de spécialité que dans la langue générale.

Pour les deux langues, nous avons analysé des mots composés appartenant au domaine de
l’énergie éolienne. Pour la langue allemande, nous avons pris Comme jeu de tests 445 composés
extraits des expériences de Weller et Heid (2012) 5. Pour la langue russe, nous avons compilé
le jeu de tests a partir d’un corpus de l’énergie éolienne6. Parmi les 7 000 lexemes les plus
fréquents du corpus, 348 sont des composés.

Nous avons fait varier les paramétres pour observer l’impact de l’utilisation du corpus et des
regles de transformation sur la qualité de segmentation. Comme la segmentation de base,
nous avons retenu la segmentation avec le dictionnaire, ce qui correspond a la technique
utilisée dans les systémes n’ayant pas de module élaboré de segmentation. Nous avons enrichi
cette segmentation de base premiérement avec la prise en compte de régles de transformation
et l’utilisation de la mesure de similarité, et deuxiémement avec le ﬁltrage dans le corpus.

Pour l’allemand, nous avons utilisé la partie allemande du dictionnaire libre allemand-anglais
Dict.cc 7. Pour le russe, nous avons exploité la version électronique du dictionnaire de
Ozhegovs, complétée par une liste d’éléments néoclassiques extraits du travail de Béchade
(1992) et traduits en russe. Les éléments néoclassiques sont trés fréquents dans les composés
russes et leur repérage s’avere nécessaire pour une segmentation correcte. Comme nous
travaillons avec des composés spécialisés, nous avons exploité des corpus thématiques du
domaine de l’énergie éolienne compilés a partir du web9 (environ 300 000 mots pour le russe
et 1.7 million mots pour l’allemand) et lemmatisés par TreeTagger 10.

Les régles pour l’allemand sont basées sur (Langer, 1998). Pour la langue russe nous avons testé
deux jeux de régles. Le premier jeu contient deux régles exprimant une connaissance basique
du russe selon laquelle les morphémes « 0 » and « e » servent de morphémes « frontiéres » pour
des composés. Le jeu de regles élargi (13 regles) integre des connaissances morphologiques
approfondies extraites de (Zaliznjak, 1977).

Un parametre important pour notre algorithme est le seuil de similarité qui désigne la
valeur minimale acceptable de similarité entre un composant candidat et un lemme du
dictionnaire / corpus. Pour trouver la valeur optimale, nous avons testé l’algorithme avec des
seuils différents sur le meme corpus de l’énergie éolienne (cf. Figure 1). Sur nos données la
valeur de 0.7 s’avére la plus satisfaisante pour les deux langues.

Pour évaluer les résultats, nous avons calculé l’eXactitude (EN « accuracy ») de décomposition
en position 1 (« Top 1 ») et en position 5 (« Top 5 ») dans la liste de segmentations candidates
classées par l’algorithme. L’exactitude est obtenue en divisant le nombre de composés qui
ont une segmentation correcte dans Top N produit par l’algorithme par le nombre total de
composés. Jusqu’a présent, nous avons effectué l’évaluation seulement sur des mots composés,
et nous n’avons pas évalué le bruit introduit par les faux positifs (non-composés qui sont
segmentés par l’algorithme par erreur). L’identiﬁcation des composés potentiels d’une langue
reléve d’une autre problématique.

. http://www.ims.uni-stuttgart.de/~wellermn/tools.html
http://www.lina.univ-nantes.fr/?Linguistic-Resources-from-the.html
http://www.dict.cc

http://speakrus.ru/dict/ozhegovw.zip

. http://www.lina.univ-nantes.fr/?Linguistic-Resources-from-the.html
. http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/

568 © ATALA

P—‘
owwsww

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

 
   

RU avec corpus .
RU sans corpus - - - - - - '- _ _ —
50 — DE avec corpus ' ' '
40 - DIE sanIs corpus - -I- - -- I I I I -

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

Seuil de Similarité

Exactitude Top 5
®
o
I

FIGURE 1 — Exactitude de la segmentation des mots composés (Top 5) en fonction du seuil
de similarité

Dictionnaire Dictionnaire Dictionnaire Banana IMS Splitter
+ Régles + + Régles + Split
Similarité Similarité +
Corpus
Top 1 57 % 91 % 91 % 86 % 87 %
Top 5 57 % 94 % 95 % - 92 %

TABLE 1 — Exactitude de segmentation pour l’allemand

5 Résultats

Les résultats de la segmentation pour les langues allemande et russe sont présentés dans les
tableaux 1 et 2.

5. 1 Composés allemands

Les résultats en ajoutant les regles de transformation et la mesure de similarité sont nettement
meilleurs que ceux obtenus dans l’expérience de base (seulement avec le dictionnaire).

L’utilisation du corpus améliore légérement l’exactitude pour le Top 5. Cela permet la
segmentation correcte d’un nombre supérieur de mots dont les composants ne sont pas présents
dans le dictionnaire (Netzanschluﬂ, « connexion réseau »). Dans certains cas, cela améliore
aussi le classement : Tmktionsbattenc sans corpus retourne deux segmentations classées a
égalité tmkt1'on+batte7"ie 1.0 et tmkt+ion+batte7‘1'e 1.0. L’utilisation de corpus fait apparaitre
la segmentation correcte avant celle incorrecte : tmktz'0n+batte1"ie 1.50, tmkt+z'0n+batte1"ie
1.25.

Dans d’autres cas le corpus nuit au classement parce qu’il favorise les segmentations constituées
de composants plus courts et plus fréquents : Aussichtsplattforrn, « observation deck », est
correctement segmenté sans corpus en aussicht+plattfo7‘m, alors qu’avec le corpus la meilleure
segmentation est aus+sicht+plattf0rm. Ce probléme peut étre résolu en remplagant la
fréquence simple du corpus par la spéciﬁcité qui rend compte du caractére terminologique
des composés. La spéciﬁcité est obtenue en divisant la fréquence dans le corpus spécialisé
par la fréquence dans un corpus général (Ahmad et al., 1992).

569 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

. . . Dictionnaire + Regles + Similarité Dictionnaire + Regles + Simila-
Dictionnaire . ,
rite + Corpus
Regles restreintes Régles élargies Regles restreintes Régles élargies
Topl 35% 62% 78% 72% 82%
Top5 35% 68% 80% 81% 91%

TABLE 2 — Exactitude de segmentation pour le russe

Nous avons comparé notre outil a deux outils libres disponibles pour l’allemand : Banana
Split 11 et IMS Splitter 12. Sur les memes 445 composés, le segmenteur Banana Split donne
une exactitude de 86 % pour le Top 1 ; IMS Splitter aboutit a une exactitude de 87 % pour
le Top 1 et 92 % pour le Top 5.

5.2 Composés russes

Nous avons observé une différence signiﬁcative entre les résultats de l’expérience de base
et ceux avec les regles et la mesure de similarité (cf. tableau. 2). L’utilisation de corpus a
été également bénéﬁque. Notons que les résultats avec l’utilisation des regles élargies sans
corpus sont proches de ceux avec les régles restreintes mais avec corpus. En fait pour certains
Composés le corpus compense l’absence de regles. Ainsi l’adjectif « électromagnétique >>
a71eKTpoMarHnTHm171 (elektromagnitnyi) ne pouvait pas étre segmenté correctement avec la
méthode de base, parce que son composant de droite magnitnyi (« magnétique ») n’est pas
présent dans le dictionnaire. Il peut étre segrnenté soit en utilisant le corpus (011 « magnétique »
est présent), soit grace 53. une régle qui permet de retrouver le nom associé magnit (« aimant »).

6 Conclusion

Nous avons présenté un algorithme de segmentation des mots Composés combinant des
caractéristiques indépendantes de la langue (mesure de similarité, fréquence des mots) avec
des caractéristiques dépendantes de la langue (regles de transformation des composants).
Cette méthode est beaucoup plus performante que celle de base consistant a vériﬁer la
présence des composants dans un dictionnaire. Elle donne des résultats comparables aux
méthodes de segmentation monolingues : pour le Top 5, exactitude jusqu’a 95 % pour
l’allemand et jusqu’a 91 % pour le russe.

L’utilisation d’un corpus est globalement bénéﬁque. Un corpus spécialisé permet de segmenter
correctement plus de mots dont les composants sont inconnus du dictionnaire et de ﬁltrer
des mauvaises segmentations. Le corpus permet dans une certaine mesure de compenser des
régles morphologiques. Il peut cependant dégrader le classement des candidats dans certains
cas.

Le code source avec une description détaillée de l’algorithme sont accessibles en ligne 13. Le
programme peut étre appliqué a des langues différentes en changeant les sources lexicales

11. http : //niels . drni . de/s9y/pages/bananasplit . html
12. http : //www . ims . u.ni- stuttgart . de/~wellerm.n/tools . html
13. http : //www . lina . univ-nantes . fr/?Compou.nd- Splitting-Tool . html

570 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

et en ajoutant éventuellement des régles de transformation. Néanmoins un paramétrage
préliminaire est préférable pour obtenir de meilleurs résultats pour une nouvelle langue.
Nous prévoyons de tester l’algorithn1e pour d’autres langues et domaines ainsi que d’évaluer
l’impact de la segmentation sur la qualité de la traduction automatique.

Remerciements

Les travaux ayant mené a ces résultats ont regu le ﬁnancement du programme European
Community’s Seventh Framework (FP7/ 2007-2013), sous l’agrément de bourse no. 248005.

Références

AHMAD, K., DAVIES, A., FULFORD, H. et ROGERS, M. (1992). What is a term? the
semi-automatic extraction of terms from text. In Translation Studies : An Interdiscipline,
pages 267—278, Amsterdam/ Philadelphia. John Benjamins.

BRASCHLER, M. et RIPPLINGER, B. (2004). How effective is stemming and decompounding
for german text retrieval. In Information Retrieval, volume 7, pages 291—316.

BECHADE, H.-D. (1992). Phonétique et morphologie du francais moderne et contemporain.
Presses Universitaires de France, Paris.

CHEN, A. et GEY, F. (2001). Translation term weighting and combining translation resources
in cross-language retrieval. In Proceedings of TREC’ Conference.

FRUNZA, O. et INKPEN, D. (2009). Identiﬁcation and disambiguation of cognates, false
friends, and partial cognates using machine learning techniques. In International Journal
of Linguistics, volume 1.

HEWLETT, D. et COHEN, P. (2011). Fully unsupervised Word segmentation with bve and
mdl. In Proceedings of AOL 2011, pages 540—545, Portland, Oregon.

KOEHN, P. et KNIGHT, K. (2003). Empirical methods for compound splitting. In Proceedings
of EAC’ 2003, Budapest, Hungary.

LANGER, S. (1998). Zur Morphologie und Semantik von Nominalkomposita. In Proceedings
of KONVENS 1998, pages 83—97, Bonn.

MACHEREY, K., DAI, A., TALBOT, D., POPAT, A. et OCH, F. (2011). Language-independent
compound splitting with morphological operations. In Proceedings of AOL 2011, pages
1395—1404, Portland, Oregon.

NAMER, F. (2009). Morphologie, lexique et traitement automatique des langues. Lavoisier,
Paris.

OTT, N. (2005). Measuring semantic relatedness of german compounds using germanet. http:
//niels . drni . de/n3files/ba.na.nasplit/Compound- GermaNet-Slides .pdf. [consulté le
20/03/2013}

WELLER, M. et HEID, U. (2012). Analyzing and aligning german compound nouns. In
Proceedings of LREC’ 2012, Istanbul.

ZALIZNJAK, A. A. (1977). Grammaticheskij Slouar’ Russkogo Jazyka [Grammatical Dictio-
nary of the Russian Language]. Russkij jazyk, Moscow.

571 © ATALA

