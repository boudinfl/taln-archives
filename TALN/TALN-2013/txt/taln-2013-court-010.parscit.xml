<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>TALN-RÉCITAL</author>
</authors>
<title>17-21 Juin, Les Sables d’Olonne</title>
<date>1994</date>
<booktitle>Symposium on Document Analysis and Information Retrieval (SDAIR-94).</booktitle>
<marker>TALN-RÉCITAL, 1994</marker>
<rawString>TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Références Cavnar, W. and Trenkle, J. (1994). N-gram-based text catogorization. 3rd Symposium on Document Analysis and Information Retrieval (SDAIR-94).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics - Special Issue on Using Large Corpora,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="9190" citStr="Dunning, 1993" startWordPosition="1373" endWordPosition="1374">ord n-gram-based methods outperform knowledge-rich features, we believe that these features are still worth experimenting with. Firstly, from an NLP perspective, these new features model a different aspect of language that cannot be addressed by neither character nor word n-grams. Secondly, because the average results obtained and the corresponding most informative features might be an important resource for contrastive linguistics providing an indication of how varieties converge and diverge. The classification method is based on n-gram language models and document log-likelihood estimation (Dunning, 1993) as described in Zampieri and Gebre (2012). Its performance is comparable to state-of-the-art methods in language identification which focus on similar languages. It was tested on Bosnian, Croatian and Serbian documents 3 achieving 91.0% accuracy. Models described in Ljubešić et al. (2007) achieved 90.3% and 95.7% accuracy using the same dataset. The method calculates language models using Laplace probability distribution for smoothing and after this calculation computes the probability of each document to belong to a certain class using a log-likelihood function as shown in equation 1. N P(</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Dunning, T. (1993). Accurate methods for the statistics of surprise and coincidence. Computational Linguistics - Special Issue on Using Large Corpora, 19(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Statistical identification of language.</title>
<date>1994</date>
<tech>Technical report,</tech>
<institution>Computing Research Lab - New Mexico State University.</institution>
<contexts>
<context position="2505" citStr="Dunning, 1994" startWordPosition="349" endWordPosition="350">uage varieties (Thompson, 1992). Each of these national varieties has their own characteristics in terms of phonetics, lexicon and syntax. Computational applications can benefit from identifying the correct variety of Spanish texts when undertaking tasks such as Machine Translation or Information Extraction, as they are able to handle lexical, orthographic and syntactic variation more accurately. The task is modelled as a classification problem with very similar methods to those applied to general 580 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne purpose language identification (Dunning, 1994). To the best of our knowledge, very few attempts have been made to address the problem of identifying language varieties as evidenced in 2.1. In this work we try to classify texts retrieved from newspapers published in 2008 from four different Spanish speaking countries : Spain, Argentina, Mexico and Peru. Moreover, we propose the use of new features, not limited to the classical word and character n-grams. We experimented features based on POS distribution and morphosyntactic information. The use of knowledge-rich features is not an attempt to outperform word and character n-gram-based metho</context>
<context position="3979" citStr="Dunning (1994)" startWordPosition="576" endWordPosition="577">uage models at the character and sometimes word-level with results usually above 95% accuracy. This level of success is very common when dealing with languages which are typologically not closely related. This is however not the case of language varieties in which the distinction is based on very subtle differences that algorithms can be trained to recognize. One of the first general purpose language identification approaches was the work of Ingle (1980). Ingle applied Zipf’s law distribution to order the frequency of stop words in a text and used this information for language identification. Dunning (1994) introduced the use of character n-grams and statistics for language identification. In this study, the likelihood of ngrams was calculated using Markov models and this was used as the most informative feature for identification. Other studies applying n-gram language models for language identification include Cavnar and Trenkle (1994) implemented as TextCat 1, Grefenstette (1995), and Vojtek and Belikova (2007). In the recent years, a number of language identification methods were developed for internet data such as Martins and Silva (2005) and Rehurek and Kolkus (2009). The most recent gener</context>
</contexts>
<marker>Dunning, 1994</marker>
<rawString>Dunning, T. (1994). Statistical identification of language. Technical report, Computing Research Lab - New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Grefenstette</author>
</authors>
<title>Comparing two language identification schemes.</title>
<date>1995</date>
<booktitle>In Proceedings of JADT 1995, 3rd International Conference on Statistical Analysis of Textual Data,</booktitle>
<location>Rome.</location>
<contexts>
<context position="4362" citStr="Grefenstette (1995)" startWordPosition="631" endWordPosition="632"> general purpose language identification approaches was the work of Ingle (1980). Ingle applied Zipf’s law distribution to order the frequency of stop words in a text and used this information for language identification. Dunning (1994) introduced the use of character n-grams and statistics for language identification. In this study, the likelihood of ngrams was calculated using Markov models and this was used as the most informative feature for identification. Other studies applying n-gram language models for language identification include Cavnar and Trenkle (1994) implemented as TextCat 1, Grefenstette (1995), and Vojtek and Belikova (2007). In the recent years, a number of language identification methods were developed for internet data such as Martins and Silva (2005) and Rehurek and Kolkus (2009). The most recent general purpose language identification method to our knowledge is the one published by Lui and Baldwin (2012). Their software, called langid.py, has language models for 97 languages, using various data sources. The method achieved results of up to 94.7% accuracy, thus outperforming similar tools. All models described in this section neglect language varieties. Pluricentric languages, </context>
</contexts>
<marker>Grefenstette, 1995</marker>
<rawString>Grefenstette, G. (1995). Comparing two language identification schemes. In Proceedings of JADT 1995, 3rd International Conference on Statistical Analysis of Textual Data, Rome.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Huang</author>
<author>L Lee</author>
</authors>
<title>Contrastive approach towards text source classification based on top-bag-of-word similarity.</title>
<date>2008</date>
<booktitle>In Proceedings of PACLIC</booktitle>
<pages>404--410</pages>
<contexts>
<context position="5916" citStr="Huang and Lee (2008)" startWordPosition="858" endWordPosition="861">the identification of Croatian texts in comparison to other South Slavic languages reporting 99% recall and precision in three processing stages. One of these processing stages, includes a so-called black list, a list of forbidden words that appear only in 1. http ://odur.let.rug.nl/vannoord/TextCat/ 581 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Croatian texts, making the algorithm perform better. Ranaivo-Malancon (2006) presents a semi-supervised character-based model to distinguish between Indonesian and Malay, two closely related languages from the Austronesian family and Huang and Lee (2008) proposes a bag-of-words approach to distinguish Chinese texts from Mainland and Taiwan reporting results of up to 92% accuracy. More recently, Trieschnigg et al. Trieschnigg et al. (2012) described classification experiments for a set of sixteen Dutch dialects using the Dutch Folktale Database. For romance languages, the DEFT2010 2 shared task aimed to classify French journalistic texts not only with respect to their geographical location but also incorporating a temporal dimension. For Portuguese, Zampieri and Gebre (2012) proposed a log-likelihood estimation method to distinguish between Eu</context>
</contexts>
<marker>Huang, Lee, 2008</marker>
<rawString>Huang, C. and Lee, L. (2008). Contrastive approach towards text source classification based on top-bag-of-word similarity. In Proceedings of PACLIC 2008, pages 404–410.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ingle</author>
</authors>
<title>A Language Identification Table.</title>
<date>1980</date>
<tech>Technical Translation International.</tech>
<contexts>
<context position="3823" citStr="Ingle (1980)" startWordPosition="552" endWordPosition="553">rk Language identification is the task of automatically identifying the language contained in a given document. State-of-the-art methods apply n-gram language models at the character and sometimes word-level with results usually above 95% accuracy. This level of success is very common when dealing with languages which are typologically not closely related. This is however not the case of language varieties in which the distinction is based on very subtle differences that algorithms can be trained to recognize. One of the first general purpose language identification approaches was the work of Ingle (1980). Ingle applied Zipf’s law distribution to order the frequency of stop words in a text and used this information for language identification. Dunning (1994) introduced the use of character n-grams and statistics for language identification. In this study, the likelihood of ngrams was calculated using Markov models and this was used as the most informative feature for identification. Other studies applying n-gram language models for language identification include Cavnar and Trenkle (1994) implemented as TextCat 1, Grefenstette (1995), and Vojtek and Belikova (2007). In the recent years, a numb</context>
</contexts>
<marker>Ingle, 1980</marker>
<rawString>Ingle, N. (1980). A Language Identification Table. Technical Translation International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ljubešić</author>
<author>N Mikelic</author>
<author>D Boras</author>
</authors>
<title>Language identification : How to distinguish similar languages ?</title>
<date>2007</date>
<booktitle>In Proceedings of the 29th International Conference on Information Technology Interfaces.</booktitle>
<marker>Ljubešić, Mikelic, Boras, 2007</marker>
<rawString>Ljubešić, N., Mikelic, N., and Boras, D. (2007). Language identification : How to distinguish similar languages ? In Proceedings of the 29th International Conference on Information Technology Interfaces.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lui</author>
<author>T Baldwin</author>
</authors>
<title>langid.py : An off-the-shelf language identification tool.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Meeting of the ACL.</booktitle>
<contexts>
<context position="4684" citStr="Lui and Baldwin (2012)" startWordPosition="680" endWordPosition="683">. In this study, the likelihood of ngrams was calculated using Markov models and this was used as the most informative feature for identification. Other studies applying n-gram language models for language identification include Cavnar and Trenkle (1994) implemented as TextCat 1, Grefenstette (1995), and Vojtek and Belikova (2007). In the recent years, a number of language identification methods were developed for internet data such as Martins and Silva (2005) and Rehurek and Kolkus (2009). The most recent general purpose language identification method to our knowledge is the one published by Lui and Baldwin (2012). Their software, called langid.py, has language models for 97 languages, using various data sources. The method achieved results of up to 94.7% accuracy, thus outperforming similar tools. All models described in this section neglect language varieties. Pluricentric languages, such as the case of Spanish, are represented by a unique class. 2.1 Models for Similar Languages, Varieties and Dialects The identification of closely related languages is one of the bottlenecks of most n-gram-based models and there are only a few studies published about it. Ljubešić et al. (2007) propose a computationa</context>
</contexts>
<marker>Lui, Baldwin, 2012</marker>
<rawString>Lui, M. and Baldwin, T. (2012). langid.py : An off-the-shelf language identification tool. In Proceedings of the 50th Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Martins</author>
<author>M Silva</author>
</authors>
<title>Language identification in web pages.</title>
<date>2005</date>
<booktitle>Proceedings of the 20th ACM Symposium on Applied Computing (SAC), Document Engineering Track.</booktitle>
<pages>763--768</pages>
<location>Santa Fe, EUA.,</location>
<contexts>
<context position="4526" citStr="Martins and Silva (2005)" startWordPosition="655" endWordPosition="658"> a text and used this information for language identification. Dunning (1994) introduced the use of character n-grams and statistics for language identification. In this study, the likelihood of ngrams was calculated using Markov models and this was used as the most informative feature for identification. Other studies applying n-gram language models for language identification include Cavnar and Trenkle (1994) implemented as TextCat 1, Grefenstette (1995), and Vojtek and Belikova (2007). In the recent years, a number of language identification methods were developed for internet data such as Martins and Silva (2005) and Rehurek and Kolkus (2009). The most recent general purpose language identification method to our knowledge is the one published by Lui and Baldwin (2012). Their software, called langid.py, has language models for 97 languages, using various data sources. The method achieved results of up to 94.7% accuracy, thus outperforming similar tools. All models described in this section neglect language varieties. Pluricentric languages, such as the case of Spanish, are represented by a unique class. 2.1 Models for Similar Languages, Varieties and Dialects The identification of closely related langu</context>
</contexts>
<marker>Martins, Silva, 2005</marker>
<rawString>Martins, B. and Silva, M. (2005). Language identification in web pages. Proceedings of the 20th ACM Symposium on Applied Computing (SAC), Document Engineering Track. Santa Fe, EUA., pages 763–768.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Ranaivo-Malancon</author>
</authors>
<title>Automatic identification of close languages - case study : Malay and indonesian.</title>
<date>2006</date>
<journal>ECTI Transactions on Computer and Information Technology,</journal>
<volume>2</volume>
<pages>126--134</pages>
<contexts>
<context position="5738" citStr="Ranaivo-Malancon (2006)" startWordPosition="836" endWordPosition="837">lated languages is one of the bottlenecks of most n-gram-based models and there are only a few studies published about it. Ljubešić et al. (2007) propose a computational model for the identification of Croatian texts in comparison to other South Slavic languages reporting 99% recall and precision in three processing stages. One of these processing stages, includes a so-called black list, a list of forbidden words that appear only in 1. http ://odur.let.rug.nl/vannoord/TextCat/ 581 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Croatian texts, making the algorithm perform better. Ranaivo-Malancon (2006) presents a semi-supervised character-based model to distinguish between Indonesian and Malay, two closely related languages from the Austronesian family and Huang and Lee (2008) proposes a bag-of-words approach to distinguish Chinese texts from Mainland and Taiwan reporting results of up to 92% accuracy. More recently, Trieschnigg et al. Trieschnigg et al. (2012) described classification experiments for a set of sixteen Dutch dialects using the Dutch Folktale Database. For romance languages, the DEFT2010 2 shared task aimed to classify French journalistic texts not only with respect to their </context>
</contexts>
<marker>Ranaivo-Malancon, 2006</marker>
<rawString>Ranaivo-Malancon, B. (2006). Automatic identification of close languages - case study : Malay and indonesian. ECTI Transactions on Computer and Information Technology, 2 :126– 134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rehurek</author>
<author>M Kolkus</author>
</authors>
<title>Language identification on the web : Extending the dictionary method.</title>
<date>2009</date>
<booktitle>In Proceedings of CICLing. Lecture Notes in Computer Science,</booktitle>
<pages>357--368</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="4556" citStr="Rehurek and Kolkus (2009)" startWordPosition="660" endWordPosition="663">tion for language identification. Dunning (1994) introduced the use of character n-grams and statistics for language identification. In this study, the likelihood of ngrams was calculated using Markov models and this was used as the most informative feature for identification. Other studies applying n-gram language models for language identification include Cavnar and Trenkle (1994) implemented as TextCat 1, Grefenstette (1995), and Vojtek and Belikova (2007). In the recent years, a number of language identification methods were developed for internet data such as Martins and Silva (2005) and Rehurek and Kolkus (2009). The most recent general purpose language identification method to our knowledge is the one published by Lui and Baldwin (2012). Their software, called langid.py, has language models for 97 languages, using various data sources. The method achieved results of up to 94.7% accuracy, thus outperforming similar tools. All models described in this section neglect language varieties. Pluricentric languages, such as the case of Spanish, are represented by a unique class. 2.1 Models for Similar Languages, Varieties and Dialects The identification of closely related languages is one of the bottlenecks</context>
</contexts>
<marker>Rehurek, Kolkus, 2009</marker>
<rawString>Rehurek, R. and Kolkus, M. (2009). Language identification on the web : Extending the dictionary method. In Proceedings of CICLing. Lecture Notes in Computer Science, pages 357–368. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Thompson</author>
</authors>
<title>Spanish as a pluricentric language.</title>
<date>1992</date>
<booktitle>Pluricentric Languages : Different Norms in Different Nations,</booktitle>
<pages>45--70</pages>
<editor>In Clyne, M., editor,</editor>
<publisher>CRC Press.</publisher>
<contexts>
<context position="1922" citStr="Thompson, 1992" startWordPosition="266" endWordPosition="267">ledge new and we aim to explore the extent to which it is possible to identify language varieties solely based on grammatical differences. Four journalistic corpora from different countries were used in these experiments : Spain, Argentina, Mexico and Peru. MOTS-CLÉS : classification automatique, ngrammes, espagnol, variétés nationales. KEYWORDS: automatic classification, n-grams, Spanish, language varieties. 1 Introduction Spanish is a world language with official status in 21 countries. It is regarded to be a Pluricentric language with a number of interacting centres and language varieties (Thompson, 1992). Each of these national varieties has their own characteristics in terms of phonetics, lexicon and syntax. Computational applications can benefit from identifying the correct variety of Spanish texts when undertaking tasks such as Machine Translation or Information Extraction, as they are able to handle lexical, orthographic and syntactic variation more accurately. The task is modelled as a classification problem with very similar methods to those applied to general 580 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne purpose language identification (Dunning, 1994). To the best of </context>
</contexts>
<marker>Thompson, 1992</marker>
<rawString>Thompson, R. (1992). Spanish as a pluricentric language. In Clyne, M., editor, Pluricentric Languages : Different Norms in Different Nations, pages 45–70. CRC Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Trieschnigg</author>
<author>D Hiemstra</author>
<author>M Theune</author>
<author>F de Jong</author>
<author>T Meder</author>
</authors>
<title>An exploration of language identification techniques for the dutch folktale database.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC2012.</booktitle>
<marker>Trieschnigg, Hiemstra, Theune, de Jong, Meder, 2012</marker>
<rawString>Trieschnigg, D., Hiemstra, D., Theune, M., de Jong, F., and Meder, T. (2012). An exploration of language identification techniques for the dutch folktale database. In Proceedings of LREC2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vojtek</author>
<author>M Belikova</author>
</authors>
<title>Comparing language identification methods based on markov processess.</title>
<date>2007</date>
<booktitle>In Slovko, International Seminar on Computer Treatment of Slavic and East European Languages.</booktitle>
<contexts>
<context position="4394" citStr="Vojtek and Belikova (2007)" startWordPosition="634" endWordPosition="637"> identification approaches was the work of Ingle (1980). Ingle applied Zipf’s law distribution to order the frequency of stop words in a text and used this information for language identification. Dunning (1994) introduced the use of character n-grams and statistics for language identification. In this study, the likelihood of ngrams was calculated using Markov models and this was used as the most informative feature for identification. Other studies applying n-gram language models for language identification include Cavnar and Trenkle (1994) implemented as TextCat 1, Grefenstette (1995), and Vojtek and Belikova (2007). In the recent years, a number of language identification methods were developed for internet data such as Martins and Silva (2005) and Rehurek and Kolkus (2009). The most recent general purpose language identification method to our knowledge is the one published by Lui and Baldwin (2012). Their software, called langid.py, has language models for 97 languages, using various data sources. The method achieved results of up to 94.7% accuracy, thus outperforming similar tools. All models described in this section neglect language varieties. Pluricentric languages, such as the case of Spanish, are</context>
</contexts>
<marker>Vojtek, Belikova, 2007</marker>
<rawString>Vojtek, P. and Belikova, M. (2007). Comparing language identification methods based on markov processess. In Slovko, International Seminar on Computer Treatment of Slavic and East European Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zampieri</author>
<author>B G Gebre</author>
</authors>
<title>Automatic identification of language varieties : The case of Portuguese.</title>
<date>2012</date>
<booktitle>In Proceedings of KONVENS2012,</booktitle>
<pages>233--237</pages>
<location>Vienna, Austria.</location>
<contexts>
<context position="6446" citStr="Zampieri and Gebre (2012)" startWordPosition="935" endWordPosition="938"> and Malay, two closely related languages from the Austronesian family and Huang and Lee (2008) proposes a bag-of-words approach to distinguish Chinese texts from Mainland and Taiwan reporting results of up to 92% accuracy. More recently, Trieschnigg et al. Trieschnigg et al. (2012) described classification experiments for a set of sixteen Dutch dialects using the Dutch Folktale Database. For romance languages, the DEFT2010 2 shared task aimed to classify French journalistic texts not only with respect to their geographical location but also incorporating a temporal dimension. For Portuguese, Zampieri and Gebre (2012) proposed a log-likelihood estimation method to distinguish between European and Brazilian Portuguese texts with results above 99.5% for character n-grams. The model was later applied to a multilingual setting with French and Spanish texts (Zampieri et al., 2012). 3 Methods We collected four comparable corpora to use in our experiments, one for each language variety. To collect comparable samples, we retrieved texts published in the same year from local newspapers regarded to have similar register, as follows : Country Newspaper Year Argentina La Nación 2008 Mexico El Universal 2008 Peru El Co</context>
<context position="9232" citStr="Zampieri and Gebre (2012)" startWordPosition="1378" endWordPosition="1381">form knowledge-rich features, we believe that these features are still worth experimenting with. Firstly, from an NLP perspective, these new features model a different aspect of language that cannot be addressed by neither character nor word n-grams. Secondly, because the average results obtained and the corresponding most informative features might be an important resource for contrastive linguistics providing an indication of how varieties converge and diverge. The classification method is based on n-gram language models and document log-likelihood estimation (Dunning, 1993) as described in Zampieri and Gebre (2012). Its performance is comparable to state-of-the-art methods in language identification which focus on similar languages. It was tested on Bosnian, Croatian and Serbian documents 3 achieving 91.0% accuracy. Models described in Ljubešić et al. (2007) achieved 90.3% and 95.7% accuracy using the same dataset. The method calculates language models using Laplace probability distribution for smoothing and after this calculation computes the probability of each document to belong to a certain class using a log-likelihood function as shown in equation 1. N P(L|tex t) = argmax log P(ni |L) + log P(L) </context>
</contexts>
<marker>Zampieri, Gebre, 2012</marker>
<rawString>Zampieri, M. and Gebre, B. G. (2012). Automatic identification of language varieties : The case of Portuguese. In Proceedings of KONVENS2012, pages 233–237, Vienna, Austria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zampieri</author>
<author>B G Gebre</author>
<author>S Diwersy</author>
</authors>
<title>Classifying pluricentric languages : Extending the monolingual model.</title>
<date>2012</date>
<booktitle>In Proceedings of the Fourth Swedish Language Technlogy Conference (SLTC2012),</booktitle>
<pages>79--80</pages>
<location>Lund,</location>
<note>587 c ATALA</note>
<contexts>
<context position="6709" citStr="Zampieri et al., 2012" startWordPosition="973" endWordPosition="976">igg et al. (2012) described classification experiments for a set of sixteen Dutch dialects using the Dutch Folktale Database. For romance languages, the DEFT2010 2 shared task aimed to classify French journalistic texts not only with respect to their geographical location but also incorporating a temporal dimension. For Portuguese, Zampieri and Gebre (2012) proposed a log-likelihood estimation method to distinguish between European and Brazilian Portuguese texts with results above 99.5% for character n-grams. The model was later applied to a multilingual setting with French and Spanish texts (Zampieri et al., 2012). 3 Methods We collected four comparable corpora to use in our experiments, one for each language variety. To collect comparable samples, we retrieved texts published in the same year from local newspapers regarded to have similar register, as follows : Country Newspaper Year Argentina La Nación 2008 Mexico El Universal 2008 Peru El Comércio 2008 Spain El Mundo 2008 TABLE 1 – Corpora Each sub-corpus contains a set of 1,000 documents randomly sampled to avoid bias towards a given topic or genre. These sub-corpora were divided in training and test settings of 500 documents each. Following the co</context>
</contexts>
<marker>Zampieri, Gebre, Diwersy, 2012</marker>
<rawString>Zampieri, M., Gebre, B. G., and Diwersy, S. (2012). Classifying pluricentric languages : Extending the monolingual model. In Proceedings of the Fourth Swedish Language Technlogy Conference (SLTC2012), pages 79–80, Lund, Sweden. 587 c ATALA</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>