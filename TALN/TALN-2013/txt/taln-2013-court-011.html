<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>L&#8217;apport des Entit&#233;s Nomm&#233;es pour la classification des opinions minoritaires</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>L&#8217;apport des Entit&#233;s Nomm&#233;es pour la classification des
opinions minoritaires
</p>
<p>Amel Fraisse1 Patrick Paroubek1 Gil Francopoulo2
(1) LIMSI-CNRS, B&#226;t. 508 Universit&#233; Paris-Sud, 91403 Orsay Cedex, France
</p>
<p>(2) TAGMATICA, 126 rue de Picpus, 75012 Paris France
</p>
<p>R&#201;SUM&#201;
La majeure partie des travaux en fouille d&#8217;opinion et en analyse de sentiment concerne le
classement des opinions majoritaires. Les m&#233;thodes d&#8217;apprentissage supervis&#233; &#224; base de n-
grammes sont souvent employ&#233;es. Elles ont l&#8217;inconv&#233;nient d&#8217;avoir un biais en faveur des opinions
majoritaires si on les utilise de mani&#232;re classique. En fait la pr&#233;sence d&#8217;un terme particulier,
fortement associ&#233; &#224; la cible de l&#8217;opinion dans un document peut parfois suffire &#224; faire basculer le
classement de ce document dans la classe de ceux qui expriment une opinion majoritaire sur la
cible. C&#8217;est un ph&#233;nom&#232;ne positif pour l&#8217;exactitude globale du classifieur, mais les documents
exprimant des opinions minoritaires sont souvent mal class&#233;s. Ce point est un probl&#232;me dans
le cas o&#249; l&#8217;on s&#8217;int&#233;resse &#224; la d&#233;tection des signaux faibles (d&#233;tection de rumeur) ou pour
l&#8217;anticipation de renversement de tendance. Nous proposons dans cet article d&#8217;am&#233;liorer la
classification des opinions minoritaires en prenant en compte les Entit&#233;s Nomm&#233;es dans le calcul
de pond&#233;ration destin&#233; &#224; corriger le biais en faveur des opinions majoritaires.
</p>
<p>ABSTRACT
Improving Minor Opinion Polarity Classification with Named Entity Analysis
</p>
<p>The main part of the work on opinion mining and sentiment analysis concerns polarity
classification of majority opinions. Supervised machine learning with n-gram features is a
common approach to polarity classification, which is often biased towards the majority of
opinions about a given opinion target, when using this kind of approach with traditional settings.
The presence of a specific term, strongly associated to the opinion target in a document, is often
enough to tip the classifier decision toward the majority opinion class. This is actually a good
thing for overall accuracy. Howeverm documents about the opinion taget, but expressing a
polarity different from the majority one, get misclassified. It is a problem if we want to detect
weak signals (rumor detection) or for anticipating opinion reversal trends. We propose in this
paper to improve minor reviews polarity classification by taking into account Named Entity
information in the computation of specific weighting scheme used for correcting the bias toward
majority opinions.
</p>
<p>MOTS-CL&#201;S : Fouille d&#8217;opinions, Opinion minoritaires, Entit&#233;s Nomm&#233;es, Apprentissage,
N-grammes, Pond&#233;ration.
</p>
<p>KEYWORDS: Opinion Mining, Minor Opinion, Named Entities, Machine Learning, N-grams,
Weighting Scheme.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>588 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>Il est devenu de nos jours tr&#232;s facile d&#8217;assembler de grandes quantit&#233;s de textes d&#8217;opinion &#224; partir
des r&#233;seaux sociaux, de forums et de sites de critique en ligne pour construire un classifieur de
documents bas&#233; sur les opinions, qui fonctionnera avec un niveau de performance suffisant pour
une utilisation industrielle. Cependant, un tel syst&#232;me est souvent biais&#233; en faveur des opinions
majoritaires exprim&#233;s &#224; propos d&#8217;une cible particuli&#232;re pr&#233;sente dans les donn&#233;es d&#8217;entrainement.
Si nous utilisons un tel syst&#232;me pour analyser de nouveaux documents concernant la m&#234;me cible,
il est tr&#232;s vraisemblable qu&#8217;ils seront affect&#233;s par le classifieur au courant d&#8217;opinion majoritaire,
essentiellement du fait de la pr&#233;sence de termes sp&#233;cifiques &#224; la cible de l&#8217;opinion dans ces
documents. Bien s&#251;r cela s&#8217;applique &#224; n&#8217;importe quel type de document, en particulier les
critiques de produits, films etc. Par exemple, si l&#8217;on cherche &#224; classer un document qui parle d&#8217;un
film &#224; succ&#232;s, la simple mention du titre, d&#8217;un acteur de la distribution, du producteur, ou du
metteur en sc&#232;ne, sera suffisante pour que le classifieur lui assigne une cat&#233;gorie positive.
</p>
<p>Paradoxallement, ce biais en faveur de l&#8217;opinion majoritaire favorise l&#8217;exactitude globale des
syst&#232;mes d&#8217;analyse d&#8217;opinion lorsque seules deux ou trois classes d&#8217;opinion sont consid&#233;r&#233;es, car la
distribution des diff&#233;rents types de documents des donn&#233;es d&#8217;entra&#238;nement est suppos&#233;e refl&#233;ter
la distribution pr&#233;sente des diff&#233;rents types de document des donn&#233;es de test. En fait, c&#8217;est une
consid&#233;ration qui a m&#234;me servi d&#8217;hypoth&#232;se de travail pour constituer le corpus d&#8217;apprentissage.
Si une cible d&#8217;opinion est majoritairement positive dans les donn&#233;es d&#8217;entra&#238;nement on s&#8217;attend a
ce que les donn&#233;es de test contiennent plus de documents &#224; teneur positive que de documents
n&#233;gatifs &#224; propos de cette cible.
</p>
<p>Mais dans cetains cas, il est souhaitable d&#8217;avoir un syst&#232;me qui soit aussi capable de d&#233;terminer
correctement la polarit&#233; d&#8217;un document exprimant une opinion minoritaire, par exemple lorsque
l&#8217;on cherche &#224; d&#233;tecter des signaux faibles (pour la d&#233;tection de rumeur) ou bien si l&#8217;on cherche
&#224; anticiper des retournements d&#8217;opinion majoritaire. Ce dernier point est particuli&#232;rement
strat&#233;gique pour toutes les industries reposant sur la fourniture de service, o&#249; l&#8217;on cherche &#224;
fid&#233;liser ses abonn&#233;s. Un syst&#232;me de fouille d&#8217;opinion capable d&#8217;effectuer un classement correct
des opinions minoritaires peut &#234;tre compar&#233; &#224; un expert qui prend des d&#233;cisions de classement
uniquement en fonction des opinions exprim&#233;es dans un document particulier &#224; propos d&#8217;une
cible, sans tenir compte de l&#8217;opinion g&#233;n&#233;rale sur cette cible.
</p>
<p>2 Sch&#233;mas de pond&#233;ration
</p>
<p>Nous repr&#233;sentons un document donn&#233; d comme un ensemble de traits : d = {g1, g2, ..., gk}, nous
d&#233;finissons son vecteur de poids wd = {w(g1),w(g2), ...,w(gk)}, o&#249; w(gi) est le poids du trait gi
dans le document d. Dans un premier temps, nous utilisons les deux sch&#233;mas de pond&#233;ration
les plus utilis&#233;s dans le domaine de l&#8217;analyse de sentiment : Binaire et DELTA-TFIDF (Martineau
et Finin, 2009) (Paltoglou et Thelwall, 2010). Ensuite, nous utilisons les trois sch&#233;mas de
pond&#233;rations propos&#233;s par (Pak et Parboubek, 2011) pour am&#233;liorer la classification des opinions
minoritaires. Le principe de base de ces trois m&#233;triques consiste &#224; r&#233;duire l&#8217;importance des
traits qui pourraient introduire un biais dans le classement d&#8217;une critique minoritaire. Comme
d&#233;crit dans (Pak, 2012), la premi&#232;re m&#233;trique est bas&#233;e sur la fr&#233;quence moyenne d&#8217;un trait.
La deuxi&#232;me m&#233;trique appel&#233;e proportion d&#8217;entit&#233; (ep) est bas&#233;e sur les occurrences d&#8217;un trait &#224;
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>589 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>travers l&#8217;ensemble des entit&#233;s e 1, comparativement &#224; sa fr&#233;quence d&#8217;apparition dans l&#8217;ensemble
de documents. La troisi&#232;me m&#233;trique, combine la fr&#233;quence moyenne d&#8217;un trait et sa proportion
d&#8217;entit&#233;.
</p>
<p>2.1 Fr&#233;quence moyenne d&#8217;un trait
</p>
<p>La fr&#233;quence moyenne d&#8217;un trait (agv.tf) est le nombre moyen de fois qu&#8217;un trait appara&#238;t dans
un document, {d|gi &#8712; d} est l&#8217;ensemble de documents qui contient gi , (Pak, 2012).
</p>
<p>avg.tf(gi) =
</p>
<p>&#65535;
{d|gi&#8712;d} tf(gi)
</p>
<p>&#65535;{d|gi &#8712; d}&#65535; (1)
</p>
<p>La normalisation &#224; base de fr&#233;quence moyenne d&#8217;un trait est bas&#233;e sur l&#8217;observation que les
auteurs de critiques ont tendance &#224; utiliser un vocabulaire riche quand ils expriment leur attitude
par rapport &#224; un film ou un produit. Ainsi, les traits exprimant des sentiments comme remarquable
(outstanding) ou adorable (lovingly) ont une fr&#233;quence moyenne proche ou &#233;gale a 1, tandis
que les traits non subjectifs ont une fr&#233;quence moyenne plus &#233;lev&#233;e. Afin de normaliser le
vecteur repr&#233;sentatif d&#8217;un document qui associe &#224; chaque trait pr&#233;sent dans le document un
poids repr&#233;sentatif de son importance, nous divisons chaque poids par la fr&#233;quence moyenne du
trait correspondant (Pak, 2012) :
</p>
<p>w(gi)&#8727; =
w(gi)
</p>
<p>avg.tf(gi)
(2)
</p>
<p>2.2 Proportion d&#8217;entit&#233;
</p>
<p>La proportion d&#8217;entit&#233; (ep) est la proportion des occurrences d&#8217;un trait par rapport aux diff&#233;rentes
entit&#233;s comparativement &#224; la fr&#233;quence des documents (Pak, 2012).
</p>
<p>ep(gi) = log (
&#65535;{e|gi &#8712; e}&#65535;
&#65535;{d|gi &#8712; d}&#65535; &#183;
</p>
<p>&#65535;D&#65535;
&#65535;E&#65535; ) (3)
</p>
<p>o&#249; {e|gi &#8712; e} est l&#8217;ensemble des entit&#233;s qui contiennent gi , &#65535;D&#65535; est le nombre total de documents,&#65535;E&#65535; est le nombre total d&#8217;entit&#233;. La normalisation de proportion d&#8217;entit&#233; favorise les traits
qui apparaissent dans nombreuses entit&#233;s mais rarement dans l&#8217;ensemble de documents. Nous
distinguons trois types de traits : (a) le vocabulaire d&#8217;une e, tels que le num&#233;ro de s&#233;rie d&#8217;un
film, la puissance d&#8217;une machine 2. Ce type de trait est associ&#233; &#224; peu d&#8217;entit&#233; et donc devraient
appara&#238;tre dans peu de documents. La valeur de ep devrait &#234;tre proche de celle de la constante
de normalisation NC = ||D||||E|| , (b) les mots-outils, tels que les d&#233;terminants et les pr&#233;positions,
devraient appara&#238;tre dans presque tous les documents, et donc associ&#233;s &#224; presque toutes les
entit&#233;s. La valeur de ep sera proche de celle de la NC et enfin (c) les termes subjectifs, tels que
&#171; remarquable &#187; ou &#171; adorable &#187;, qui devraient appara&#238;tre associ&#233;s &#224; beaucoup de produits et
dans un nombre relativement restreint de documents, car les auteurs utilisent un vocabulaire
vari&#233;. La valeur de ep sera plus grande que la constante de normalisation NC . Pour normaliser
</p>
<p>1. (Pak, 2012) d&#233;signe par entit&#233; (e) l&#8217;ensemble de documents ayant la m&#234;me cible d&#8217;opinion.
2. Les termes du vocabulaire d&#8217;entit&#233; ne sont pas reconnus, en g&#233;n&#233;ral, comme entit&#233;s nomm&#233;es.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>590 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>le vecteur repr&#233;sentatif d&#8217;un document, nous multiplions chaque poids associ&#233; &#224; un trait par sa
proportion d&#8217;entit&#233; (Pak, 2012).
</p>
<p>w(gi)&#8727; = w(gi) &#183; ep(gi) (4)
Le troisi&#232;me sch&#233;ma de pond&#233;ration propos&#233; par (Pak, 2012), consiste &#224; combiner la fr&#233;quence
moyenne d&#8217;un trait et la proportion d&#8217;entit&#233; selon la formule suivante :
</p>
<p>w(gi)&#8727; = w(gi) &#183; ep(gi)avg.tf(gi) (5)
</p>
<p>2.3 Notre contribution : pond&#233;ration des entit&#233;s nomm&#233;es
</p>
<p>C&#8217;est en effet en faveur du d&#233;veloppement de la t&#226;che d&#8217;extraction d&#8217;information que la t&#226;che de
reconnaissance des entit&#233;s nomm&#233;es (EN) est apparue. Cette t&#226;che a gagn&#233; en maturit&#233; et s&#8217;est
pr&#233;cis&#233;e gr&#226;ce &#224; la s&#233;rie des conf&#233;rences MUC (Message Understanding Conferences) (Grouin
et al., 2011). Ensuite, le concept des entit&#233;s nomm&#233;es a &#233;t&#233; repris dans le cadre des campagnes
d&#8217;&#233;valuation du projet europ&#233;en QUAERO (Galibert et al., 2012).
</p>
<p>La majorit&#233; des mod&#232;les d&#8217;opinion comprennent 3 &#233;l&#233;ments : l&#8217;expression d&#8217;opinion, la source, et
la cible de l&#8217;opinion (Paroubek et al., 2010). Nous nous int&#233;ressons ici &#224; la cible, &#224; laquelle, dans la
plupart des cas, on fait r&#233;f&#233;rence au moyen d&#8217;entit&#233;s nomm&#233;es (personne, produit, organisation,
lieu etc.) et auxquelles est souvent associ&#233; un ensemble d&#8217;entit&#233;s nomm&#233;es contextuelles, propre
&#224; la cible, comme par exemple la distribution d&#8217;un film ou le nom de son metteur en sc&#232;ne.
</p>
<p>Les syst&#232;mes de fouille d&#8217;opinion et plus particuli&#232;rement de classement en polarit&#233;, bas&#233;s sur les
approches traditionnelles, c&#8217;est-&#224;-dire les approches &#224; base d&#8217;apprentissage automatique supervis&#233;
utilisant les simples mod&#232;les &#224; sac-de-mots (Pak, 2012), ont tendance &#224; s&#8217;appuyer sur les traits
sp&#233;cifiques des entit&#233;s et, par voie de cons&#233;quences, ils sont biais&#233;s en faveur des opinions
majoritaires pr&#233;sents dans les donn&#233;es d&#8217;apprentissage. En particulier les traits r&#233;pr&#233;sentant des
EN utilis&#233;s pour r&#233;f&#233;rencer la cible de l&#8217;opinion sont identifi&#233;s par le syst&#232;me comme indicateurs
de polarit&#233; pour les opinions majoritaires. Prenons l&#8217;exemple d&#8217;un film qui a eu un grand succ&#232;s
comme AVATAR, non seulement la mention du titre du film, dans le commentaire, qui pourrait
entra&#238;ner une classification positive du commentaire mais aussi la citation du nom du directeur
du film James Cameron, et cela m&#234;me dans le cas, o&#249; il s&#8217;agit d&#8217;un commentaire n&#233;gatif sur le film.
En outre, les entit&#233;s nomm&#233;es ne font pas parti du vocabulaire g&#233;n&#233;ral pour l&#8217;expression d&#8217;opinion
et de sentiments. De notre point de vue, un syst&#232;me de fouille d&#8217;opinion doit &#234;tre capable de faire
la distinction entre les indicateurs d&#8217;opinion exprim&#233;s de fa&#231;on explicite, dans l&#8217;expression de
l&#8217;opinion, et ceux qui sont li&#233;s &#224; la pr&#233;sence des traits contextuels 3 comme par exemple les EN.
Afin d&#8217;am&#233;liorer la classification des opinions minoritaires, il faut donc r&#233;duire l&#8217;importance des
traits contextuels qui souvent, introduisent un biais dans le processus de classification de ce type
d&#8217;opinion. Nous proposons donc de compl&#233;ter la normalisation des sch&#233;mas de pond&#233;ration de
(Pak, 2012) en se basant sur un syst&#232;me de reconnaissance des EN. Dans un premier ensemble
d&#8217;exp&#233;rimentation, nous avons proc&#233;d&#233; de la fa&#231;on suivante : si un trait gi est reconnu comme
une EN alors son poids est &#233;cart&#233; du vecteur de poids du document (voir Eq. 6).
</p>
<p>3. Ensemble de traits associ&#233; &#224; une cible d&#8217;opinion et qui d&#233;finissent le contexte de la cible. Par exemple, les traits
Quentin Tarantino et Jamie Foxx apparaissent souvent dans le contexte d&#8217;une critique du film Django.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>591 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>wNEd = wd \ {w(gi), gi &#8712; NE} (6)
</p>
<p>3 Exp&#233;rimentations
</p>
<p>3.1 Donn&#233;es
</p>
<p>Nous utilisons le jeu de donn&#233;es : Large Movie Review Dataset (A.L. Maas A.L. et al., 2011)
qui a &#233;t&#233; utilis&#233; par le pass&#233; pour des recherches en analyse de sentiment. Il contient 50 000
critiques de film r&#233;partis selon une proportion &#233;gale entre les critiques n&#233;gatives et les critiques
positives. Pour pr&#233;parer le jeu de donn&#233;es, nous avons suivi la proc&#233;dure d&#233;crite dans (Pak, 2012).
Pour chaque film, nous avons pris trois documents pour le test et sept pour l&#8217;apprentissage. Ces
valeurs ont &#233;t&#233; choisies de mani&#232;re heuristique afin de maximiser le nombre total de critiques. La
constitution des donn&#233;es est illustr&#233;e dans la figure 1. Pour s&#233;parer l&#8217;ensemble de donn&#233;es en
</p>
<p>FIGURE 1 &#8211; Processus de composition de jeu de donn&#233;es (Pak, 2012).
</p>
<p>sous-ensembles d&#8217;apprentissage et test, au d&#233;part, nous avons group&#233; toutes les critiques par e
(c&#8217;est-&#224;-dire le film), identifi&#233;e par un identifiant unique dans l&#8217;ensemble des donn&#233;es. A partir
de ces groupes, pour chaque e nous avons choisi toutes les critiques d&#8217;une polarit&#233; dominante
dans ce groupe et nous les avons transf&#233;r&#233; dans le corpus d&#8217;apprentissage. Les critiques restantes
de chaque groupe sont transf&#233;r&#233;es dans le corpus de test. Nous appelons ce corpus &quot;biais&#233; de
mani&#232;re minoritaire&quot; car le corpus de test contient des critiques avec une polarit&#233;e minoritaire.
Afin de prouver que la baisse de performance est due effectivement aux traits biais&#233;s, nous avons
construit un corpus de test compos&#233; des m&#234;mes critiques mais r&#233;-organis&#233; de telle mani&#232;re que
les critiques aient la m&#234;me polarit&#233; que la polarit&#233; dominante dans le corpus d&#8217;apprentissage pour
chaque e. Nous appelons ce corpus &quot;biais&#233; de mani&#232;re majoritaire&quot;. Enfin, nous avons construit
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>592 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>le corpus &quot;non-biais&#233;&quot; de telle mani&#232;re que le corpus du test et le corpus d&#8217;apprentissage ne
contiennent aucun document en commun.
</p>
<p>3.2 R&#233;sultats
</p>
<p>Pour nos exp&#233;rimentations, nous avons utilis&#233; la biblioth&#232;que LIBLINEAR avec un noyau lin&#233;aire
et un param&#233;trage par d&#233;faut (R.E. Fan et al., 2008). Les entit&#233;s nomm&#233;es ont &#233;t&#233; marqu&#233;es
par G. Francopoulo avec l&#8217;outil industriel TagParser de TAGMATICA (Francopoulo et Demay,
2011). En premier lieu, nous prouvons l&#8217;effet n&#233;gatif des traits contextuels et sp&#233;cifiques aux e sur
l&#8217;exactitude de classification des critiques minoritaires. Nous avons effectu&#233; des exp&#233;rimentations
sur trois variantes des corpus : non-biais&#233; (unb), biais&#233; de mani&#232;re minoritaire (minb), biais&#233; de
mani&#232;re majoritaire (majb). Nous avons utilis&#233; les unigrammes (uni) et les bigrammes (bi) avec
des poids : binaire (bin) et Delta-TFIDF. Les r&#233;sultats sur l&#8217;exactitude de la classification selon les
corpus et les n-grammes sont pr&#233;sent&#233;s dans la table 1.
</p>
<p>unb. &#8710; minb. &#8710; majb. &#8710;
Unigrammes + binaire
</p>
<p>bin 80.7 69.4 83.4
avg.tf 81.5 +0.8 72.3 +2.9 84.8 +1.4
ep 80.1 -0.6 71.3 +1.9 83.5 +0.1
comb 80.7 +0.0 73.0 +3.6 84.4 +1.0
comb.ex.NE 79.5 -1.2 73.6 +4.2 84.6 +1.2
</p>
<p>Unigrammes + Delta TF-IDF
Delta TF-IDF 83.3 63.5 89.2
avg.tf 81.1 -2.2 69.4 +5.9 87.6 -1.6
ep 82.3 -1.0 67.2 +3.7 87.8 -1.4
comb 81.7 -1.6 69.0 +5.5 87.5 -1.7
comb.ex.NE 81.2 -2.1 71.4 +7.9 87.5 -2.1
</p>
<p>Bigrammes + binaire
bin 79.6 71.9 83.5
avg.tf 79.7 +0.1 72.8 +0.9 84.0 +0.5
ep 80.3 +0.7 74.0 +2.1 84.2 +0.7
comb 80.8 +1.2 74.9 +3.0 84.6 +1.1
comb.ex.NE 81.1 +1.5 76.1 +4.2 84.8 +1.3
</p>
<p>Bigrammes + Delta TF-IDF
Delta TF-IDF 83.0 69.9 87.6
avg.tf 82.9 -0.1 76.0 +6.0 86.1 -1.5
ep 83.2 +0.2 74.4 +4.5 86.2 -1.4
comb 83.3 +0.3 75.1 +5.2 85.8 -1.8
comb.ex.NE 83.9 +0.9 78.1 +8.2 85.2 -2.4
</p>
<p>TABLE 1 &#8211; Exactitude de classification des critiques des films en utilisant les diff&#233;rents sch&#233;mas
de normalisation.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>593 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Impact des traits contextuels et sp&#233;cifiques aux entit&#233;s. En observant la table 1, nous
constatons que les traits associ&#233;s aux entit&#233;s provoquent une baisse des performances sur le
corpus biais&#233; de mani&#232;re minoritaire quand on le compare avec le corpus non-biais&#233; (unb
vs. minb). Nous observons aussi une augmentation des performance sur le corpus biais&#233; de
mani&#232;re majoritaire malgr&#233; une taille du corpus d&#8217;apprentissage plus petite (unb vs majb). Cela
montre que notre classifieur apprend &#224; associer les traits contextuels et sp&#233;cifiques &#224; une e &#224; sa
polarit&#233; majoritaire. Les r&#233;sultats sont similaires d&#8217;un corpus &#224; l&#8217;autre, d&#8217;une variante &#224; l&#8217;autre
et d&#8217;une propri&#233;t&#233; &#224; l&#8217;autre. Le Delta TFIDF bien qu&#8217;am&#233;liorant l&#8217;exactitude globale provoque
des mauvaises classifications de critiques minoritaires car il donne de l&#8217;importance aux traits
sp&#233;cifiques y compris donc les traits repr&#233;sentants des EN. Nous l&#8217;observons en comparant les
r&#233;sultats en utilisant Delta TFIDF (uni + &#8710; et bi + &#8710;) sur le corpus biais&#233; de mani&#232;re minoritaire
avec les corpus non-biais&#233;s et biais&#233;s de mani&#232;re majoritaire. Enfin, nous avons &#233;valu&#233; les effets
du sch&#233;ma de normalisation propos&#233; sur l&#8217;exactitude de la classification. Ainsi que nous l&#8217;avons
observ&#233; sur les pr&#233;c&#233;dentes exp&#233;rimentations, le fait d&#8217;exclure les poids des traits repr&#233;sentant
des EN augmente la performance comme pr&#233;sent&#233; dans les parties mises en exergue dans la table
1.
</p>
<p>4 Conclusion
</p>
<p>Les m&#233;thodes que nous avons propos&#233;es dans cet article permettent de diminuer l&#8217;importance
des EN sp&#233;cifiques &#224; une cible d&#8217;opinion particuli&#232;re, en normalisant leur poids dans le vecteur
de poids qui est utilis&#233; par les repr&#233;sentations classiques &#224; base de n-grammes en apprentissage
automatique. Les &#233;valuations que nous avons effectu&#233;es sur des jeux de donn&#233;s sp&#233;cialement
construit &#224; partir de jeux de donn&#233;es standard pour tester nos hypoth&#232;ses, ont montr&#233; que le
classement des documents exprimant des opinions minoritaires est grandement am&#233;lior&#233; ( +8%),
ce qui prouve que notre mode de pond&#233;ration prenant en compte les EN a un impact positif
sur la mesure d&#8217;exactitude de classification pour les documents d&#8217;opinion minoritaires, une
n&#233;cessit&#233; pour la d&#233;tection de signaux faibles ou l&#8217;anticipation de renversement de tendance.
Il faut cependant noter que l&#8217;accroissement de performance n&#8217;est pas aussi important pour les
mod&#232;les &#224; base de bigrammes ( +1%) entra&#238;n&#233;s avec des donn&#233;es naturellement biais&#233;es, mais il
reste positif, ce qui prouve que notre mode de pond&#233;ration fonctionne au moins aussi bien que
les approches classiques sur ces donn&#233;es.
</p>
<p>R&#233;f&#233;rences
</p>
<p>FRANCOPOULO, G. et DEMAY, F. (2011). A deep ontology for named entities.
In Proceedings of the Int. Conf. on Computational Semantics, Interoperable Se-
mantic Annotation workshop. ACL. .
</p>
<p>. .
</p>
<p>GALIBERT, O., ROSSET, S., GROUIN, C., ZWEIGENBAUM, P. et QUINTARD, L. (2012). Extended named
entity annotation on ocred documents : From corpus constitution to evaluation campaign. In
Proceedings of the 8th LREC, pages 3126&#8211;3131, Istanbul, Turkey. ELDA.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>594 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>GROUIN, C., S., S. R., ZWEIGENBAUM, P., FORT, K., GALIBERT, O. et QUINTARD, L. (2011). Proposal
for an extension of traditional named entities : From guidelines to evaluation, an overview. In
Proceedings of the Fifth Law Workshop (LAW V), pages 92&#8211;100, Portland, Oregon. ACL.
</p>
<p>MARTINEAU, J. et FININ, T. (2009). Delta tfidf : An improved feature space for sentiment analysis.
In Proceedings of the Third AAAI Int. Conf. on Weblogs and Social Media, San Jose, CA. AAAI
Press.
</p>
<p>A.L. MAAS A.L., R.E. DALY, P.T. PHAM, HUANG, D., A.Y. NG et POTTS, C. (2011). Learning word
vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the ACL, pages
142&#8211;150, Portland, Oregon, USA. ACL. http ://www.aclweb.org/anthology/P11-1015.
R.E. FAN, K.W. CHANG, C.J. HSIEH, X.R. WANG et C.J. LIN (2008). Liblinear : A library
for large linear classification. J. Mach. Learn. Res., 9:1871&#8211;1874. URL http ://por-
tal.acm.org/citation.cfm ?id=1390681.1442794.
PAK, A. (2012). Automatic, Adaptive,and Applicative Sentiment Analysis. Th&#232;se de doctorat,
Th&#232;se de l&#8217;&#201;cole Doctorale d&#8217;Informatique de l&#8217;Universit&#233; Paris-Sud, Orsay.
</p>
<p>PAK, A. et PARBOUBEK, P. (2011). Normalization of term weighting scheme for sentiment analysis.
In Language and Technology Conference : Human Language Technologies as a Challenge for
Computer Science and Linguistics, pages 415&#8211;419, Poznan&#769;, Poland.
</p>
<p>PALTOGLOU, G. et THELWALL, M. (2010). A study of information retrieval weighting schemes for
sentiment analysis. In Proceedings of the 48th Annual Meeting of the ACL, pages 1386&#8211;1395,
Morristown, NJ, USA,. ACL.
</p>
<p>PAROUBEK, P., PAK, A. et MOSTEFA, D. (2010). Annotations for opinion mining evaluation in the
industrial context of the doxa project. In Proceedings of the 7th International Conference on
Language Resources and Evaluation (LREC), Valetta, Malta. ELDA.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>595 c&#65535; ATALA</p>

</div></div>
</body></html>