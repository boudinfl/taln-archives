TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

L’apport des Entités Nommées pour la classiﬁcation des
opinions minoritaires

Amel Fraissel Patrick Paroubekl Gil Francopouloz
(1) LIMSI-CNRS, Bét. 508 Université Paris-Sud, 91403 Orsay Cedex, France
(2) TAGMATICA, 126 rue de Picpus, 75012 Paris France
fraisse@limsi . fr , pap©limsi . fr , gil . francopoulo©tagmatica. com

RESUME
La majeure partie des travaux en fouille d’opinion et en analyse de sentiment concerne le
classement des opinions majoritaires. Les méthodes d’apprentissage supervisé a base de n-
grammes sont souvent employées. Elles ont l’inconvénient d’avoir un biais en faveur des opinions
majoritaires si on les utilise de maniére classique. En fait la présence d’un terme particulier,
fortement associé a la cible de 1’opinion dans un document peut parfois sufﬁre a faire basculer le
classement de ce document dans la classe de ceux qui expriment une opinion majoritaire sur la
cible. C’est un phénoméne positif pour l’exactitude globale du classiﬁeur, mais les documents
exprimant des opinions minoritaires sont souvent mal classés. Ce point est un probléme dans
le cas o1‘1 l’on s’intéresse a la détection des signaux faibles (détection de rumeur) ou pour
l’anticipation de renversement de tendance. Nous proposons dans cet article d’améliorer la
classiﬁcation des opinions minoritaires en prenant en compte les Entités Nommées dans le calcul
de pondération destiné a corriger le biais en faveur des opinions majoritaires.

ABSTRACT
Improving Minor Opinion Polarity Classiﬁcation with Named Entity Analysis

The main part of the work on opinion mining and sentiment analysis concerns polarity
classiﬁcation of majority opinions. Supervised machine learning with n—gram features is a
common approach to polarity classiﬁcation, which is often biased towards the majority of
opinions about a given opinion target, when using this kind of approach with traditional settings.
The presence of a speciﬁc term, strongly associated to the opinion target in a document, is often
enough to tip the classiﬁer decision toward the majority opinion class. This is actually a good
thing for overall accuracy. Howeverm documents about the opinion taget, but expressing a
polarity different from the majority one, get misclassiﬁed. It is a problem if we want to detect
weak signals (rumor detection) or for anticipating opinion reversal trends. We propose in this
paper to improve minor reviews polarity classiﬁcation by taking into account Named Entity
information in the computation of speciﬁc weighting scheme used for correcting the bias toward
majority opinions.

MOTS-CLES : Fouille d’opinions, Opinion minoritaires, Entités Nommées, Apprentissage,
N—grammes, Pondération.

KEYWORDS: Opinion Mining, Minor Opinion, Named Entities, Machine Learning, N-grams,
Weighting Scheme.

588 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
1 Introduction

11 est devenu de nos jours tres facile d’assembler de grandes quantités de textes d’opinion a partir
des réseaux sociaux, de forums et de sites de critique en ligne pour construire un classiﬁeur de
documents basé sur les opinions, qui fonctionnera avec un niveau de performance sufﬁsant pour
une utilisation industrielle. Cependant, un tel systéme est souvent biaisé en faveur des opinions
majoritaires exprimés a propos d’une cible particuliere présente dans les données d’entrainement.
Si nous utilisons un tel systeme pour analyser de nouveaux documents concemant la meme cible,
il est tres vraisemblable qu’ils seront affectés par le classiﬁeur au courant d’opinion majoritaire,
essentiellement du fait de la présence de termes spéciﬁques a la cible de l’opinion dans ces
documents. Bien sﬁr cela s’applique a n’importe quel type de document, en particulier les
critiques de produits, ﬁlms etc. Par exemple, si l’on cherche a classer un document qui parle d’un
ﬁlm a succes, la simple mention du titre, d’un acteur de la distribution, du producteur, ou du
metteur en scene, sera sufﬁsante pour que le classiﬁeur lui assigne une catégorie positive.

Paradoxallement, ce biais en faveur de l’opinion majoritaire favorise l’exactitude globale des
systemes d’analyse d’opinion lorsque seules deux ou trois classes d’opinion sont considérées, car la
distribution des différents types de documents des données d’entrainement est supposée reﬂéter
la distribution présente des différents types de document des données de test. En fait, c’est une
considération qui a méme servi d’hypothése de travail pour constituer le corpus d’apprentissage.
Si une cible d’opinion est majoritairement positive dans les données d’entrainement on s’attend a
ce que les données de test contiennent plus de documents a teneur positive que de documents
négatifs a propos de cette cible.

Mais dans cetains cas, il est souhaitable d’avoir un systéme qui soit aussi capable de déterminer
correctement la polarité d’un document exprimant une opinion minoritaire, par exemple lorsque
l’on cherche a détecter des signaux faibles (pour la détection de rumeur) ou bien si l’on cherche
a anticiper des retournements d’opinion majoritaire. Ce dernier point est particulierement
stratégique pour toutes les industries reposant sur la fourniture de service, ou l’on cherche a
ﬁdéliser ses abonnés. Un systeme de fouille d’opinion capable d’effectuer un classement correct
des opinions minoritaires peut étre compare a un expert qui prend des décisions de classement
uniquement en fonction des opinions exprimées dans un document particulier a propos d’une
cible, sans tenir compte de l’opinion générale sur cette cible.

2 Schémas de pondération

Nous représentons un document donné d comme un ensemble de traits : d = {g1, g2, ..., gk}, nous
déﬁnissons son vecteur de poids wd = {w(g1), w(g2), ..., w(gk)}, o1‘1 w(g,-) est le poids du trait g,-
dans le document d. Dans un premier temps, nous utilisons les deux schémas de pondération
les plus utilisés dans le domaine de l’analyse de sentiment : Binaire et DELTA—TFIDF (Martineau
et Finin, 2009) (Paltoglou et Thelwall, 2010). Ensuite, nous utilisons les trois schémas de
pondérations proposés par (Pak et Parboubek, 2011) pour améliorer la classiﬁcation des opinions
minoritaires. Le principe de base de ces trois métriques consiste a réduire l’importance des
traits qui pourraient introduire un biais dans le classement d’une critique minoritaire, Comme
décrit dans (Pak, 2012), la premiere métrique est basée sur la fréquence moyenne d’un trait.
La deuxieme métrique appelée proportion d’entite’ (ep) est basée sur les occurrences d’un trait a

589 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

travers l’ensemble des entités e 1, comparativement a sa fréquence d’apparition dans l’ensemble
de documents. La troisieme métrique, combine la fréquence moyenne d’un trait et sa proportion
d’entité.

2.1 Fréquence moyenne d’un trait

La fréquence moyenne d’un trait (agv.tf) est le nombre moyen de fois qu’un trait apparait dans
un document, {dlgi E d} est l’ensemble de documents qui contient g,-, (Pak, 2012).

Zldlgied} “<39
llldlgi E d}||

La normalisation a base de fréquence moyenne d’un trait est basée sur l’observation que les
auteurs de critiques ont tendance a utiliser un vocabulaire riche quand ils expriment leur attitude
par rapport a un ﬁlm ou un produit. Ainsi, les traits exprimant des sentiments comme remarquable
(outstanding) ou adorable (lovingly) ont une fréquence moyenne proche ou égale a 1, tandis
que les traits non subjectifs ont une fréquence moyenne plus élevée. Aﬁn de normaliser le
vecteur représentatif d’un document qui associe a chaque trait présent dans le document un
poids représentatif de son importance, nous divisons chaque poids par la fréquence moyenne du
trait correspondant (Pak, 2012) :

avg.tf(g,-) = (1)

wtg,-)* = %(''g_) (2)

2.2 Proportion d’entité

La proportion d’entité (ep) est la proportion des occurrences d’un trait par rapport aux différentes
entités comparativement a la fréquence des documents (Pak, 2012).

llielgi Ee}|| _@
llidlgi Ed}|| nan

o1‘1 {elgi E e} est l’ensemble des entités qui contiennent g,-, ||D|| est le nombre total de documents,
||E|| est le nombre total d’entité. La normalisation de proportion d’entité favorise les traits
qui apparaissent dans nombreuses entités mais rarement dans l’ensemble de documents. Nous
distinguons trois types de traits : (a) le vocabulaire d’une e, tels que le numéro de série d’un
ﬁlm, la puissance d’une machine 2. Ce type de trait est associé a peu d’entité et donc devraient
apparaitre dans peu de documents. La valeur de ep devrait étre proche de celle de la constante

de normalisation NC = %, (b) les mots—outils, tels que les déterminants et les prépositions,

devraient apparaitre dans presque tous les documents, et donc associés a presque toutes les
entités. La valeur de ep sera proche de celle de la NC et enﬁn (c) les termes subjectifs, tels que
« remarquable » ou « adorable >>, qui devraient apparaitre associés a beaucoup de produits et
dans un nombre relativement restreint de documents, car les auteurs utilisent un vocabulaire
Varié. La valeur de ep sera plus grande que la constante de normalisation NC. Pour normaliser

ep(g1-) = log( (3)

1. (Pak, 2012) désigne par entire’ (e) l’ensemble de documents ayant la méme cible d’opinion.
2. Les termes du vocabulaire d’entité ne sont pas reconnus, en général, comme entités nommées.

590 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

le vecteur représentatif d’un document, nous mulﬁplions chaque poids associé a un trait par sa
proportion d’entité (Pak, 2012).

w(g1-)* = w(g.-)~ep(g1-) (4)

Le troisieme schéma de pondération propose’ par (Pak, 2012), consiste a combiner la fréquence
moyenne d’un trait et la proportion d’entité selon la formule suivante :

ep(g1-)

' avg-tf(gi) (5)

W(gi)* = W(gi)

2.3 Notre contribution : pondération des entités nommées

C’est en effet en faveur du développement de la tache d’extraction d’informaﬁon que la tache de
reconnaissance des entités nommées (EN) est apparue. Cette tache a gagné en maturité et s’est
précisée grace a la série des conférences MUC (Message Understanding Conferences) (Grouin
et al., 2011). Ensuite, le concept des entités nommées a été repris dans le cadre des campagnes
d’évaluation du projet européen QUAERO (Galibert et al., 2012).

La majorité des modéles d’opinion comprennent 3 éléments : l’expression d’opinion, la source, et
la cible de l’opinion (Paroubek et al., 2010). Nous nous intéressons ici a la cible, a laquelle, dans la
plupart des cas, on fait référence au moyen d’entités nommées (personne, produit, organisation,
lieu etc.) et auxquelles est souvent associé un ensemble d’entités nommées contextuelles, propre
a la cible, comme par exemple la distribution d’un ﬁlm ou le nom de son metteur en scene.

Les systémes de fouille d’opinion et plus parﬁculiérement de classement en polarité, basés sur les
approches traditionnelles, c’est—a—dire les approches a base d’apprentissage automatique supervisé
utilisant les simples modéles a sac—de—mots (Pak, 2012), ont tendance a s’appuyer sur les traits
spéciﬁques des entités et, par voie de conséquences, ils sont biaisés en faveur des opinions
majoritaires présents dans les données d’apprentissage. En particulier les traits réprésentant des
EN utilisés pour référencer la cible de l’opinion sont identiﬁés par le systéme comme indicateurs
de polarité pour les opinions majoritaires. Prenons l’exemple d’un ﬁlm qui a eu un grand succés
comme AVATAR, non seulement la mention du titre du ﬁlm, dans le commentaire, qui pourrait
entrainer une classiﬁcation positive du commentaire mais aussi la citation du nom du directeur
du ﬁlm James Cameron, et cela méme dans le cas, o1‘1 il s’agit d’un commentaire négatif sur le ﬁlm.
En outre, les entités nommées ne font pas parti du vocabulaire général pour l’expression d’opinion
et de sentiments. De notre point de vue, un systéme de fouille d’opinion doit étre capable de faire
la distinction entre les indicateurs d’opinion exprimés de facon explicite, dans l’expression de
l’opinion, et ceux qui sont lie’s a la pre’sence des traits contextuels 3 comme par exemple les EN.
Aﬁn d’améliorer la classiﬁcation des opinions minoritaires, il faut donc réduire l’importance des
traits contextuels qui souvent, introduisent un biais dans le processus de classiﬁcation de ce type
d’opinion. Nous proposons donc de comple’ter la normalisation des schémas de pondération de
(Pak, 2012) en se basant sur un systeme de reconnaissance des EN. Dans un premier ensemble
d’expérimentation, nous avons procédé de la facon suivante : si un trait gi est reconnu comme
une EN alors son poids est écarté du vecteur de poids du document (voir Eq. 6).

3. Ensemble de traits associé 21 une cible d’opinion et qui déﬁnissent le contexte de la cible. Par exemple, les traits
Quentin Tarantino et Jamie Foxx apparaissent souvent dans le contexte d’une critique du ﬁlm Django.

591 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

WQIE =Wd \{W(g:-L 81 ENE} (53

3 Expérimentations

3. 1 Données

Nous utilisons le jeu de données : Large Movie Review Dataset (A.L. Maas A.L. et al., 2011)
qui a été utilisé par le passé pour des recherches en analyse de sentiment. Il contient 50 000
critiques de ﬁlm répartis selon une proportion égale entre les critiques négatives et les critiques
positives. Pour préparer le jeu de données, nous avons suivi la procédure décrite dans (Pak, 2012).
Pour chaque ﬁlm, nous avons pris trois documents pour le test et sept pour 1’apprenu'ssage. Ces
valeurs ont été choisies de maniére heuristique aﬁn de maximiser le nombre total de critiques. La
constitution des données est illustrée dans la ﬁgure 1. Pour séparer l’ensemble de données en

3-r5~”:I-e I"£”eI‘.9-
.-.-gr;;.-..- nu-.-,..

.~' 1 .".-< 3'."

g  3 :_ 
’-'5'-5

      

      

.._- ;_- _
>- - . .
h\ K . . . 4'5-
ﬂ $ -:3
P-‘hr I-9:1: nest t'Irr' rr.?'I'.
nr-.29.-.5 rmrtrr hinsszc n*,.1]r.r ninsrn-'. I.nl'.4'.1v:'.‘
'. Lr I’;-‘lul da|.:|y.': srtl.-'I§.'5 :»:'L‘uI'!g:- sun ’I;5

ff

     

'r:'I;Ir :I~:I:4.-:I emludeu 5£'.t|I7i;I:-l|“?V.E1'-E‘.||.'|'\E-I’

FIGURE 1 — Processus de composition de jeu de données (Pak, 2012).

sous—ensembles d’apprentissage et test, au départ, nous avons groupé toutes les critiques par e
(c’est-a-dire le ﬁlm), identiﬁée par un identiﬁant unique dans l’ensemble des données. A partir
de ces groupes, pour chaque e nous avons choisi toutes les critiques d’une polarité dominante
dans ce groupe et nous les avons transféré dans le corpus d’apprentissage. Les critiques restantes
de chaque groupe sont transférées dans le corpus de test. Nous appelons ce corpus "biaisé de
maniere minoritaire" car le corpus de test contient des critiques avec une polaritée minoritaire.
Aﬁn de prouver que la baisse de performance est due effectivement aux traits biaisés, nous avons
construit un corpus de test composé des mémes critiques mais ré—organisé de telle maniere que
les critiques aient la méme polarité que la polarité dominante dans le corpus d’apprentissage pour
chaque e. Nous appelons ce corpus "biaisé de maniére majoritaire". Enﬁn, nous avons construit

592 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

le corpus "non—biaisé" de telle maniére que le corpus du test et le corpus d’apprentissage ne
contiennent aucun document en commun.

3.2 Résultats

Pour nos expérimentations, nous avons utilisé la bibliothéque LIBLINEAR avec un noyau linéaire
et un paramétrage par défaut (R.E. Fan et al., 2008). Les entités nommées ont été marquées
par G. Francopoulo avec l’outil industriel TagParser de TAGMATICA (Francopoulo et Demay,
2011). En premier lieu, nous prouvons l’effet négatif des traits contextuels et spéciﬁques aux e sur
l’exactitude de classiﬁcation des critiques minoritaires. Nous avons effectué des expérimentations
sur trois variantes des corpus : non—biaisé (unb), biaisé de maniére minoritaire (minb), biaisé de
maniére majoritaire (majb). Nous avons utilisé les unigrammes (uni) et les bigrammes (bi) avec
des poids : binaire (bin) et Delta-TFIDE Les résultats sur l’exacu'tude de la classiﬁcation selon les
corpus et les n—grammes sont présentés dans la table 1.

| unb. | A | minb. | A | majb. | A
Unigrammes + binaire

bin 80.7 69.4 83.4

aVg.tf 81.5 +0.8 72.3 +2.9 84.8 +1.4
ep 80.1 -0.6 71.3 +1.9 83.5 +0.1
comb 80.7 +0.0 73.0 +3.6 84.4 +1.0

comb.ex.NE 79.5 -1.2 73.6 +4.2 84.6 +1.2
Unigrammes + Delta TF-IDF

Delta TF-IDF 83.3 63.5 89.2

avg.tf 81.1 -2.2 69.4 +5.9 87.6 -1.6
ep 82.3 -1.0 67.2 +3.7 87.8 -1.4
comb 81.7 -1.6 69.0 +5.5 87.5 -1.7

comb.ex.NE 81.2 -2.1 71.4 +7.9 87.5 -2.1
Bigrammes + binaire

bin 79.6 71.9 83.5

aVg.tf 79.7 +0.1 72.8 +0.9 84.0 +0.5
ep 80.3 +0.7 74.0 +2.1 84.2 +0.7
comb 80.8 +1.2 74.9 +3.0 84.6 +1.1

comb.ex.NE 81.1 +1.5 76.1 +4.2 84.8 +1.3
Bigrammes + Delta TF-IDF

Delta TF-IDF 83.0 69.9 87.6

aVg.tf 82.9 -0.1 76.0 +6.0 86.1 -1.5
ep 83.2 +0.2 74.4 +4.5 86.2 -1.4
comb 83.3 +0.3 75.1 +5.2 85.8 -1.8

comb.ex.NE 83.9 +0.9 78.1 +8.2 85.2 -2.4

TABLE 1 — Exactitude de classiﬁcation des critiques des ﬁlms en utilisant les différents schémas
de normalisation.

593 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Impact des traits contextuels et spéciﬁques aux entités. En observant la table 1, nous
constatons que les traits associés aux entités provoquent une baisse des performances sur le
corpus biaisé de maniere minoritaire quand on le compare avec le corpus non—biaisé (unb
vs. minb). Nous observons aussi une augmentation des performance sur le corpus biaisé de
maniére majoritaire malgré une taille du corpus d’apprentissage plus petite (unb vs majb). Cela
montre que notre classiﬁeur apprend a associer les traits contextuels et spéciﬁques a une e a sa
polarité majoritaire. Les résultats sont similaires d’un corpus a l’autre, d’une variante a l’autre
et d’une propriété a l’autre. Le Delta TFIDF bien qu’améliorant l’exactitude globale provoque
des mauvaises classiﬁcations de critiques minoritaires car il donne de l’importance aux traits
spéciﬁques y compris donc les traits représentants des EN. Nous l’observons en comparant les
résultats en utilisant Delta TFIDF (uni + A et bi + A) sur le corpus biaisé de maniére minoritaire
avec les corpus non—biaisés et biaisés de maniére majoritaire. Enﬁn, nous avons évalué les effets
du schéma de normalisation proposé sur l’exactitude de la classiﬁcation. Ainsi que nous l’avons
observé sur les précédentes expérimentations, le fait d’exclure les poids des traits représentant
des EN augmente la performance comme présenté dans les parties mises en exergue dans la table
1.

4 Conclusion

Les méthodes que nous avons proposées dans cet article permettent de diminuer l’importance
des EN spéciﬁques a une cible d’opinion particuliere, en normalisant leur poids dans le vecteur
de poids qui est utjlisé par les représentations classiques a base de n—grammes en apprentissage
automatique. Les évaluations que nous avons effectuées sur des jeux de donnés spécialement
construit a partir de jeux de données standard pour tester nos hypotheses, ont montré que le
classement des documents exprimant des opinions minoritaires est grandement amélioré ( +8%),
ce qui prouve que notre mode de pondération prenant en compte les EN a un impact positif
sur la mesure d’exactitude de classiﬁcation pour les documents d’opinion minoritaires, une
nécessité pour la détection de signaux faibles ou l’anticipation de renversement de tendance.
Il faut cependant noter que l’accroissement de performance n’est pas aussi important pour les
modéles a base de bigrammes ( +1%) entrainés avec des données naturellement biaisées, mais il
reste positif, ce qui prouve que notre mode de pondération fonctionne au moins aussi bien que
les approches classiques sur ces données.

Références

FRANCOPOULO, G. et DEMAY, F. (2011). A deep ontology for named entities.
In Proceedings of the Int. Conﬁ on Computational Semantics, Interoperable Se-
mantic Annotation workshop. ACL. http://tagmatica.fr/publications/

FrancopouloACLI SOl/Jorkshopwithinlnternat ionalConference0nComput at ional
Semantics201 1.pdf.

GALIBERT, 0., ROSSET, S., GROUIN, C., ZWEIGENBAUM, P. et QUINTARD, L. (2012). Extended named
entity annotation on ocred documents : From corpus constitution to evaluation campaign. In
Proceedings of the 8th LREC, pages 3126-3131, Istanbul, Turkey ELDA.

594 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

GROUIN, C., S., S. R., ZWEIGENBAUM, P, FORT, K., GALIBERT, O. et QUINTARD, L. (2011). Proposal
for an extension of traditional named entities : From guidelines to evaluation, an overview. In
Proceedings of the Fifth Law Workshop (LAW \0, pages 92-100, Portland, Oregon. ACL.

MARTINEAU, J. et FININ, T. (2009). Delta tﬁdf : An improved feature space for sentiment analysis.
In Proceedings of the Third AAAI Int. Conf on Weblogs and Social Media, San Jose, CA. AAAI
Press.

A.L. MAAS A.L., R.E. DALY, RT. PHAM, HUANG, D., A.Y. NG et PoTTs, C. (2011). Learning word
vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the ACL, pages
142-150, Portland, Oregon, USA. ACL. http ://wWv\Laclweb.org/anthology/P11-1015.

R.E. FAN, K.VV. CHANG, C.J. HSIEH, X.R. WANG et C.J. LIN (2008). Liblinear : A library
for large linear classiﬁcation. J. Mach. Learn. Res., 9:1871—1874. URL http ://por-
tal.acm.org/citation.cfm ?id=1390681 . 1442794.

PAK, A. (2012). Automatic, Adaptive,and Applicative Sentiment Analysis. These de doctorat,
These de l’F.cole Doctorale d’Informau'que de l’Université Paris-Sud, Orsay.

PAK, A. et PARBOUBEK, P. (2011). Normalization of term weighting scheme for sentiment analysis.
In Language and Technology Conference : Human Language Technologies as a Challenge for
Computer Science and Linguistics, pages 415-419, Poznan, Poland.

PALTOGLOU, G. et THELWALL, M. (2010). A study of information retrieval weighting schemes for
sentiment analysis. In Proceedings of the 48th Annual Meeting of the ACL, pages 1386-1395,
Morristown, NJ, USA,. ACL.

PAROUBEK, R, PAK, A. et MOSTEFA, D. (2010). Annotations for opinion mining evaluation in the
industrial context of the doxa project. In Proceedings of the 7th International Conference on
Language Resources and Evaluation (LREC), Valetta, Malta. ELDA.

595 © ATALA

