TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Inﬂuence des annotations sémantiques sur un systeme de
détection de coréférence a base de perceptron multi-couches

Eric Charton Michel Gagnon Ludovic Jean-Louis
Ecole Polytechnique de Montréal, Montréal, QC, Canada
{eric . charton, michel . gagnon, ludovic . jean—louis } @polymtl . ca

RESUME
La série de campagnes d’évaluation CoNLL-2011/2012 a permis de comparer diverses proposi-
tions d’architectures de systemes de détection de co—références. Cet article décrit le systeme de
résolution de coréférence Poly—co développé dans le cadre de la campagne d’évaluation CoNLL-
2011 et évalue son potentiel d’amélioration en introduisant des propriétés sémantiques dans son
modele de détection. Notre systeme s’appuie sur un classiﬁeur perceptron multi—couches. Nous
décrivons les heuristiques utilisées pour la sélection des paires de mentions candidates, ainsi que
l’approche de sélection des traits caractéristiques que nous avons utilisée lors de la campagne
CoNLL—2011. Nous introduisons ensuite un trait sémantique complémentaire et évaluons son
inﬂuence sur les performances du systeme.

ABSTRACT
Semantic annotation inﬂuence on coreference detection using perceptron approach

The ConLL—2011/ 2012 evaluation campaign was dedicated to coreference detection systems.
This paper presents the coreference resolution system Poly—co submitted to the closed track of
the CoNLL-2011 Shared Task and evaluate is potential of evolution when it includes a semantic
feature. Our system integrates a multilayer perceptron classiﬁer in a pipeline approach. We
describe the heuristic used to select the candidate coreference pairs that are fed to the network
for training, and our feature selection method. We introduce a complementary semantic feature
and evaluate the performances improvement.

MOTS-CLES : Coréférence, Perceptron multi—couches.

KEYWORDS: Coreference, Multilayer perceptron.

1 Introduction

La résolution de coréférence a pour objet de déterminer si deux séquences textuelles (par
exemple une entité nommée, un pronom, un syntagme nominal) font référence a une méme
entité sémantique (par exemple une personne ou un événement). Le principe de résolution
consiste a détecter au sein d’un texte des séquences intitulées mentions coréférentes et a les
regrouper au sein de chaines de coréférences. Cette téiche du TAL fait l’objet d’un ensemble de
propositions algorithmiques récemment revisitées par deux campagnes d’évaluation CoNLL
Shared Tasks proposées en 2011 et 2012. Ces campagnes ont démontré la prédominance des
systemes de résolution de co—référence par apprentissage automatique appliqués sur des paires
candidates. Le systeme présenté dans cet article est une évolution de celui que nous avons

612 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

présenté dans le cadre de notre participation at l’édition 2011 de cette campagne (Pradhan et al.,
2011). Notre approche tente de déﬁnir un vecteur de traits d’apprentissage original reposant sur
des informations issues d’un processus d’extraction d’information et d’analyse linguistique. Dans
cette communication, nous complétons ces travaux antérieurs en intégrant un trait sémantique
dans le vecteur d’apprentissage.

Cet article est organisé comme suit. Nous commentons l’état de 1’art établi par les campagnes
CoNLL en section 2. Puis nous présentons notre systéme de détection de coréférences en section 3.
Nous décrivons comment nous proposons d’enrichir son vecteur en lui adjoignant un trait de
nature sémantique, c’est a dire déﬁnissant précisément l’identité de certaines des mentions
candidates utilisées dans le processus de classiﬁcation par paires. Cette amélioration induit une
progression intéressante du systeme tel qu’évalué lors de la campagne CoNLL. Nous commentons
les résultats de ce systéme modiﬁé en section 4.1 puis nous concluons.

2 Propositions existantes

De nombreux systemes fondés sur l’apprentissage automatique ont été proposés pour traiter
la résolution de coréférences. Les approches les plus récentes a base de réseaux logiques de
Markov (MLNs) (Poon et Domingos, 2008), cu fondées sur une approche de partitionnement
de graphe (Sapena et al., 2010) sont prometteuses et demeurent peu explorées. Le modele de
classiﬁcation proposé par Soon (Soon et al., 2001) est prédominant et trés largement implémenté.
Dans cette approche, les mentions coréférentes potentielles, contenues dans un document
d’entrainement, sont localisées via différents modules dits de détection de mentions. Les exemples
d’entrainements sont ensuite générés sous la forme de vecteurs de traits qui représentent une
paire de mentions potentiellement coréférentes.

En mode applicatif toutes les paires de mentions potentiellement coréférentes d’un document
sont soumises sous forme d’un vecteur au classiﬁeur, qui valide ou non leur relation en donnant
une réponse binaire ou probabilisée. Un processus d’assemblage, postérieur a la classiﬁcation,
regroupe ensuite au sein de chaines toutes les mentions coréférentes. L’atout principal de la
méthode de Soon est sa grande ﬂexibilité : la réduction du probléme de construction de chaines
de coréférences a la reconnaissance préalable de paires coréférentes laisse une grande latitude
de conception de systéme. Cette approche rend aussi la méthode de Soon compatible avec des
familles de classiﬁeurs trés variées : (Versley et al., 2008) a montré qu’un modéle de type SVM
permet d’obtenir un systéme efﬁcace et lors de la campagne CoNLL 2012, (Fernandes et al., 2012)
a montré le potentiel d’un perceptron multicouche pour cette tache.

Le contenu du vecteur de trait utilisé dans l’architecture de Soon offre également un champ
de recherche fertile : on a pu ainsi voir dans la proposition de (Stamborg et Medved, 2012)
que des dépendances syntaxiques utilisées en tant que traits pouvaient offrir un bon niveau de
performance. Certains travaux soulignent la souplesse de l’approche de Soon en ne retenant que
le principe de ses paires et vecteurs de traits qu’ils associent non plus a des classiﬁeurs, mais
a des méthodes heuristiques. C’est le cas de la proposition de (Lee et al., 2011) qui a obtenu
les meilleures performances lors de la campagne CoNLL 2011. Le principe est de remplacer
l’apprentissage automatique et la classiﬁcation par une approche incrémentale a base de regles
pré—établies dites tamis. Au cours de 13 étapes successives, ces tamis trient les différentes paires
de coréférences candidates et les assemblent au sein de chaines. On notera que (Huang et al.,

613 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

 
  
    

Corpus d'entrainement Corpus de test

  

I ¢ _ Modulededetection
MOCIUIE d extraction des des mentions candidates
mentions Détection des alias

candidates Annotation sémantiques

V
i / Mesures de simiiarité i
l

Hr , ‘ W Corpusdenombie
| I K / Detectiondegenreetdenombre | eigeme
i V Corpus étiqueté
Générationdes traits Génération des traits

" V , .
EntrainementPerceptron Classiﬁcation Perceptron}—> Selectiondeco-reference

FIGURE 1 — Architecture du systeme Poly-co.

2009) propose aussi de ne conserver que les paires de vecteurs de traits de l’architecture de Soon,
mais utilise un modele MLN pour assembler les chaines.

3 Systéme proposé

La qualité des détecteurs de mentions potentielles jouant un role essentiel dans le processus
de détection de coréférence (Lee et al., 2011), des efforts d’ingénierie importants sont néces-
saires pour élaborer les composants d’un systeme complet. Notre systeme n’échappe pas a cette
contrainte et une part importante de son implémentation concerne la détection des éléments
textuels utilisés pour produire les vecteurs de traits. Nous avons choisi ici de conserver l’architec-
ture de (Soon et al., 2001), alimentée par des vecteurs contenant de nombreux traits de degrés
supérieurs. Le corpus Ontonotes (Pradhan et al., 2007) proposé pour entrainer et évaluer les
systemes de détection de coréférences contenant déja de nombreuses informations telles que la
relation syntaxique, la nature syntagmatique, les entités nommées (Voir ﬁgure 2), nos efforts
se sont concentrés sur l’ajout de propriétés évoluées (par exemple les similarités lexicales entre
mentions ou les genres des mentions). L’architecture globale présentée dans la ﬁgure 1 contient
deux parties, la premiere est dédiée a l’entrainement du systeme, la seconde a la résolution de
coréférence avec un systeme entrainé.

3.1 Modules de détection et de construction des traits

Les traits des vecteurs de notre systéme reprennent directement depuis le corpus Ontonotes
les catégories morpho-syntaxiques, les syntagmes nominaux et les types d’entités nommées.
Nous complétons ces traits en utilisant des modules supplémentaires pour la détection des
genres et des nombres, évaluons la détection des alias entre mentions, les similarités entre
mentions et introduisons une annotation sémantique. Cinq modules de préparation de vecteurs
d’apprentissage sont intégrés a notre systeme :

614 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

An or (roE(5(m:LN1=-r
Iraq NNF lNl‘{L"
we: mu ~w
vet mu -1
Whn W17 lS3RR(W.ilNF")

called VBD ISEVF" cal]

Pxesndent mm: mm —
Bush NNF ‘J ’

— cnna_ma:meus -
— cr.na_M.a:c.-mu: (Gym
1 chna_n.a:mew: -
— cnna_ma:meus - :3 x —

— cnna_n.a:cnev.m - tR—mzso—J K —

5 chns_ma:mev.u ~ EV"? -

— chus_na::,—teu; - aims:-v ~ (102 nap://abpeasa.uzg/page/senxge_w._2uu
— Chrla naccneua IPERSDN) *3 ~ 109)

(minor (A1150 x (1 1
* * P3 hctp: //dbpedia. om/page/Iraq

ll!!!
.3
tthdttttt

FIGURE 2 — Exemple de corpus Ontonotes avec en derniere colonne l’annotation sémantique.

1. Module de détection des mentions candidates, fondé sur des regles d’extraction utilisant
les annotations issues de Ontonotes. I1 exploite ces annotations pour remplir certains traits
(notamment syntaxiques).

2. Module de détection des alias entre entités nommées, qui fait intervenir une version
précédente du systéme Poly—co présentée dans (Charton et al., 2010). L’objectif de ce
module est d’identiﬁer les différentes variations lexicales d’une méme entité en comparant
des formes de surface.

3. Module de calcul de similarité, qui sert a mesurer la similarité de deux mentions en
comparant les chaines de caractéres qui leur sont associées.

4. Module de détection en genre et en nombre, détermine le genre et le nombre pour
toutes les mentions candidates a l’aide de la ressource fournie par (Bergsma, 2005).

5. Module de détection sémantique, détermine par un identiﬁant unique l’identité de l’objet
annoté. Nous évaluons l’inﬂuence de ce paramétre dans cette communication.

Lors de la phase d’entrainement, les modules de détection des mentions candidates et de
détection des alias sont remplacés par un seul module d’extraction des mentions candidates
qui s’appuie directement sur les mentions coréférentes déja annotées dans le corpus d’entraine—
ment. On obtient ainsi pour entrainer le classiﬁeur un ensemble de paires de mentions candidates
positives dont on est certain de la qualité et que l’on complete par un ensemble de paires né—
gatives sélectionnées aléatoirement (cet aspect est détaillé en section 3.3). On se reportera a
(Charton et Gagnon, 2011) pour une déﬁnition plus précise des modules 1 a 4. Nous décrivons
ci—dessous le parametre sémantique que nous introduisons dans le systeme Poly—co.

3.1.1 Module de détection sémantique

Nous ajoutons au systéme Poly—co un trait dit sémantique. Ce trait consiste en une annotation
composée d’une URI vers DBPedia. Ce trait vient en complément des annotations fournies sur
le corpus Ontonotes 1, tel que présenté dans la ﬁgure 2. Le protocole utilisé pour attribuer ces
annotations consiste, pour chaque entité nommée candidate, a rechercher son lien correspondant
en utilisant un annotateur sémantique 2. Les corpus d’apprentissage et de test sont traités avec
cette méthode. Une correction des erreurs aprés étiquetage est réalisée visuellement sur le
seul corpus d’apprentissage pour limiter l’inﬂuence des erreurs d’annotation sur le processus
d’entrainement.

Ce lien unique attribué aux entités nommées (GPE, ORG, PERS,LOC, PROD) déﬁnit précisément
leur identité. Pour l’introduire dans le vecteur de trait sous forme de valeur numérique, nous

1. conll.cemantix.org/2012/data.htn1l
2. Nous utilisons pour cette communication wwwwikimeta.org

615 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Nom Type—valeur Valeur de
trait prise

Propriétés de (A,B)

IsAlias vrai/faux 1/0
Issimilar réel 0,00 / 1,00
Distance entier 0/ d

Sent entier 0/ x
Référence A

IsNE vrai/faux 1/0

ISPRP vrai/faux 1/0

IsNP vrai/faux 1/0
NE_SEMANTIC TYPE null / EN 0 / 1-18
PRP_NAME null / PRP 0 / 1-30
NP_DET null / DT 0 / 1-15
NP_TYPE null / TYPE 0 / 1-3
GENDER M/F/N/U 1/2/3/0
NUMBER S/P/U 1/2/0
SEMANTIQUE 0/URI 0 - 1 a n
Référence B

Identique a la référence A

TABLE 1 — Parametres des vecteurs d’apprentissage. Les propriétés communes aux mentions A et
B sont détaillées dans la section Propriétés de (A,B). Les traits de la mention A sont détaillés dans
la section Référence A. Les traits de la mention B sont identiques a ceux de la mention A.

établissons un index de tous les liens sémantiques contenus dans le document dans lequel nous
cherchons les chaines de coréférences et lui attribuons un numéro d’ordre (dans l’exemple de
la ﬁgure 2, par exemple, le numéro 1 est attribué 51 Iraq et 2 a Georges Bush. La valeur 0 est
attribuée en l’absence de liens.

3.2 Construction des vecteurs de traits

Le vecteur d’entrainement du systéme Poly—co (voir tableau 1) est constitué de 24 traits qui
décrivent, conformément a l’architecture de Soon, une paire de mentions, (A,B), dans laquelle
B est l’antécédent potentiel et A est l’anaphore. Les paramétres sont extraits en utilisant les
différents modules de détection. Le role du classiﬁeur est ici de fournir une réponse binaire ou
probabilisée : A et B co—référent ou non. Quatre paramétres déﬁnissent la paire (A,B) (section
Propriétés de (A,B) du tableau 1) :

— IsAlias : il s’agit d’une variable binaire retournée par le module alias. La variable prend la
valeur vrai lorsque A et B sont identiﬁes comme décrivant la meme entité.

Issimilar : il s’agit du score de similarité calculée par le module de calcul de similarité.
Distance : cette valeur représente la distance, c’est—a—dire la différence entre les deux rangs
occupées par A et B dans la liste des mentions candidates.

Sent : indique le nombre de marqueurs de ﬁn de phrases (ex : « . ! ? ») qui séparent les mentions
A et B.

Pour chacun des candidats A et B, un ensemble de neuf traits est ajouté au vecteur. Dans un
premier temps, trois variables binaires déterminent si la mention est une entité nommée (ISNE),
s’il s’agit d’un pronom personnel (ISPRP) ou d’un syntagme nominal (IsNP). Ensuite, les variables
ci—dessous déﬁnissent les caractéristiques d’une mention :

616 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

NE_SEMANTIc TYPE est un des 18 types d’entité nommée prédéﬁni (PERSON, ORG, TIME, etc).
PRP_NAME s’app1ique aux pronoms et correspond a une Valeur numérique attribuée a chacun
des 30 pronoms prédéterminés (ex. : my, she, it, etc).

NP_DET est une Valeur qui indique quel de’terminant accompagne un syntagme nominal (par

exemple, the, this, these, etc).

NP_TYPE précise si un syntagme nominal est démonstratif, déﬁnitif ou quantiﬁcateur.

— GENDER et NUMBER indiquent, lorsque les valeurs sont connues, le genre de la mention parmi
Masculin, Féminin ou Neutre et son nombre (Singulier or Pluriel). Lorsque les valeurs sont
inconnues les variables prennent la Valeur U.

— SEMANTIQUE : la Valeur du trait est déﬁnie selon les modalités présentées en section 3.1.1.

Une Valeur null (ou 0) est utilisée lorsqu’il n’est pas nécessaire de déﬁnir une variable : par
exemple, la variable PRP_NAME est positionnée sur 0 lorsque la mention est une entité nommée.

3.3 Entrainement et application du classiﬁeur

Pour entrainer le classiﬁeur, nous utilisons l’algorithme suivant pour préparer les paires. Sup-
posons que la liste des mentions candidates contient k mentions M1,M2, . . .,Mk, apparaissant
dans cet ordre dans le document. L’algorithme commence par la derniere mention du document,
c’est—a—dire Mk. Il compare de facon séquentielle Mk avec les mentions précédentes en remontant
la liste et s’arréte lorsque (i) une mention en situation de coréférence MC est trouvée (ii) il a
traité un nombre maximum de n mentions (ici n est ﬁxé a 10). Lorsqu’une mention coréférente
MC a été détectée, un vecteur est construit pour toutes les paires de mentions (Mk, M,-) ou M,-
est une mention qui a été traitée. Ces vecteurs sont ajoutés a l’ensemble d’entrainement : MC est
considéré comme exemple positif et tous les autres sont considérés comme négatifs. Le processus
est répété avec Mk_1, et ainsi de suite, jusqu’a ce que chaque mention soit traitée. Si aucune des
n mentions précédentes n’a de lien de coréférence avec Mk, l’ensemble des n paires est écarté et
n’est pas utilisé pour les données d’entrainement.

Pour l’application, le processus de détection de coréférence s’appuie sur un algorithme similaire.
La mention Mk est comparée aux n mentions précédentes jusqu’a ce que l’on en trouve une
pour laquelle le modéle perceptron multi—couches retourne une probabilité supérieure au seuil
de 0,5 (ou une Valeur binaire dans le cas du classiﬁeur SVM). Si aucun référent n’est trouvé
dans la limite des n mentions, Mk est considérée comme une mention non coréférente. Une fois
cette procédure appliquée a toutes les mentions d’un document, les coréférences détectées sont
utilisées pour construire les chaines de coréférences.

4 Expériences

Le systéme complet d’annotation de coréférences Poly—Co 3 est entrainé sur le corpus d’entraine—
ment Ontonotes 4 sur lequel les annotations sémantiques complémentaires ont été apposées. Il
est ensuite testé sur le corpus de développement gold dev—set. Le tableau 2 présente les résultats
obtenus lors de ConLL 2011, sans que le classiﬁeur n’exploite les traits sémantiques, le tableau
3 présente les résultats en intégrant les traits sémantiques. Notre systéme est entrainé avec

3. Poly-co est téléchargeable sur https : / /code . google . com/p/polyco—2 /
4. Le corpus Ontonotes est diffusé par LDC. Un échantillon est téléchargeable sur le site de la conférence ConNLL
http : / /conll . cemantix . org/2 0 12 /data . html

617 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Scores Poly—co Mentions B3 CEAF MUC

R P F R P F R P F R P F
Perceptron multi—couches (MLP) 65,91 64,84 65,37 66,61 62,09 64,27 50,18 50,18 50,18 54,47 50,86 52,60
SVM 65,06 66,1 1 65,58 65,28 57,68 61,24 46,31 46,31 46,31 53,30 50,00 51,60
Arbres de décision (J48) 66,06 64,57 65,31 66,53 62,27 64,33 50,59 50,59 50,59 54,24 50,60 52,36

TABLE 2 — Résultats du systéme, obtenus en appliquant différents classiﬁeurs utilisant les mémes
vecteurs de parametres sur les données << gold dev—set » du corpus Ontonotes.

Scores Poly—co Mentions B3 CEAF MUC

R P F R P F R P F R P F
Perceptron multi—couches (MLP) 66,50 65,81 66,15 66,70 62,18 64,36 52,31 52,31 52,31 54,97 51,86 53,36
SVM 65,46 66,60 66,02 65,37 58,79 61,90 48,03 48,03 48,03 54,35 51,00 52,61
Arbres de décision (J48) 66,56 64,97 65,75 67,01 62,5 64,67 52,19 52,19 52,19 54,64 51,30 52,91

TABLE 3 — Résultats du systéme avec les traits sémantiques, obtenus en appliquant différents
classiﬁeurs sur les données << gold dev—set » du corpus Ontonotes.

trois types de classiﬁeurs : perceptron multi—couches (MLP), SVM, arbres de décision (J48). Les
métriques d’évaluation retenues sont celles adoptées par la campagne ConLL 2011-12, a savoir
une mesure de la capacité des systemes a détecter des mentions d’une part (une simple F-Mesure
est retenue), et une moyenne non pondérée des métriques B3, CEAE et MUC.

4. 1 Résultats

Pour la phase d’évaluation de la campagne CoNLL ST 2011, nous avons retenu le modele MLP qui
obtient les meilleures performances sur1’ensemble de données sans annotation sémantique. En
raison des faibles différences entre les modeles MLP et J48 il était difﬁcile de déﬁnir clairement
lequel était le plus adapté avec le modéle de classiﬁcation retenu. L’introduction de traits
sémantiques améliore les performances du modele Perceptron en regard des deux autres modeles
de classiﬁcation. On observe que l’utilisation d’un identiﬁant sémantique pour les entités nommées
permet d’améliorer d’un point les capacités de détection de mentions du systeme : ceci s’explique
par le fait que l’introduction de cet identiﬁant améliore la robustesse de classiﬁcation lorsque
les paires sont constituées d’entités nommées. 11 en résulte moins de paires mal sélectionnées et
donc une augmentation du nombre de mentions correctement détectées. De maniére globale,
l’introduction de traits sémantiques améliore les performances du classiﬁeur.

5 Conclusions

Cet article présente Poly—co, un systéme de résolution de coréférence pour l’anglais, facile a
adapter 31 d’autres langues. La version initiale de Poly—co a été construite dans le cadre de la cam-
pagne d’évaluation CoNLL ST 2011. Le corpus d’évaluation proposé, Ontonotes, d’un haut niveau
de complexité, nous a donné 1’opportunité d’éValuer nos algorithmes de détection de mentions
dans le cadre d’une tache complete, regroupant des coréférences entre des entités nommées, des
syntagmes nominaux et des pronoms. En introduisant de nouveaux traits sémantiques dans les
vecteurs d’apprentissage, nous observons un gain global de performance et soulignons que notre
approche a base perceptron multi—couches est une solution intéressante pour la reconnaissance
de chaines de coréférence.

618 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
Références

BERGSMA, S. (2005). Automatic acquisition of gender information for anaphora resolution.
Advances in Artiﬁcial Intelligence, pages 342-353.

CHARTON, E. et GAGNON, M. (2011). Poly-co : a multilayer perceptron approach for coreference
detection. In CoNLL : Shared Task.

CHARTON, E., GAGNON, M. et OZELL, B. (2010). Po1y—co : an unsupervised co-reference detection
system. In BELZ, A. et Kow, E., éditeurs : INLG 2010-GREC, Dublin. ACL SIGGEN.

FERNANDEs, E., dos SANTOS, C. et MILIDIU, R. (2012). Latent structure perceptron with feature
induction for unrestricted coreference resolution. Proceedings of the Joint Conference on EMNLP
and CoNLL : Shared Task, pages 41-48.

HUANG, S., ZHANG, Y., ZHOU, J. et CHEN, J. (2009). Coreference Resolution using Markov Logic
Network. In The 10th International Conference on Intelligent Text Processing and Computational
Linguistics, volume 41, pages 157-168.

LEE, H., PE1RsMAN, Y., CHANG, A., CHAMBERS, N., SURDEANU, M. et JURAFSKY, D. (2011). Stanford’s
Multi—Pass Sieve Coreference Resolution System at the CoNLL—2011 Shared Task. In CoNLL
Shared Task, numéro June, page 73.

P0oN, H. et DoM1NG0s, P. (2008). Joint unsupervised coreference resolution with Markov logic.
In Proceedings of the Conference on Empirical Methods in Natural Language Processing — EMNLP
'08, page 650, Morristown, NJ, USA. Association for Computational Linguistics.

PRADHAN, S., RAMsHAw., L., MARCUS, M., PALMER, M., WEISCHEDEL, R. et NIANwEN, X. (2011).
CoNLL-2011 Shared Task : Modeling Unrestricted Coreference in OntoNotes. In Proceedings of
the Fifteenth Conference on Computational Natural Language Learning (CoNLL 201 1), Portland,
Oregon.

PRADHAN, S., RAMsHAw, L., WEISCHEDEL, R., MACBRIDE, J. et MICCIULLA, L. (2007). Unrestricted
coreference : Identifying entities and events in OntoNotes. In International Conference on
Semantic Computing, 2007. ICSC 2007., pages 446-453. IEEE.

SAPENA, E., PADRO, L. et 'I‘URMO, J. (2010). RelaxCor : A global relaxation labeling approach to
coreference resolution. In Proceedings of the 5 th International Workshop on Semantic Evaluation,
numéro July, pages 88-91. Association for Computational Linguistics.

SooN, W. M., NG, H. T. et LIM, D. C. Y. (2001). A Machine Learning Approach to Coreference
Resolution of Noun Phrases. Computational Linguistics, 27(4):521—544.

STAMBORG, M. et MEDVED, D. (2012). Using syntactic dependencies to solve coreferences.
Proceedings of the Joint Conference on EMNLP and CoNLL : Shared Task, pages 64—70.

VERSLEY, Y., PONzETTo, S., PoEsI0, M., EIDELMAN, V, JERN, A., SMITH, J., YANG, X. et MOSCHITTI,
A. (2008). BART : A modular toolkit for coreference resolution. In Proceedings of the Sixth Inter-
national Language Resources and Evaluation (LREC’08), numéro 2006, pages 9-12, Marrakech.
European Language Resources Association (ELRA).

619 © ATALA

