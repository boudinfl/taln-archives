TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Expériences de formalisation d’un guide d’annotation :
vers l’annotation agﬂe assistée

Bruno Guillaume” Karen Fort1:3
(1) LORIA 54500 Vandoeuvre-les-Nancy
(2) Inria Nancy Grand-Est
(3) Université de Lorraine
bru.no.gui11aume@1oria.:Er, karen.:Eort@1oria.fr

RESUME
Nous proposons dans cet article une méthodologie, qui s’inspire du développement agile et
qui permettrait d’assister la préparation d’une campagne d’annotation . Le principe consiste a
formaliser au maximum les instructions contenues dans le guide d’annotation aﬁn de vériﬁer
automatiquement si le corpus en construction est cohérent avec le guide en cours d’écriture.
Pour exprimer la partie formelle du guide, nous utilisons la réécriture de graphes, qui permet
de décrire par des motifs les constructions déﬁnies. Cette formalisation permet de repérer les
constructions prévues par le guide et, par contraste, celles qui ne sont pas cohérentes avec le
guide. En cas d’incohérence, un expert peut soit corriger l’annotation, soit mettre a jour le guide
et relancer le processus.

ABSTRACT
Formalizing an annotation guide : some experiments towards assisted agile annotation

This article presents a methodology, inspired from the agile development paradigm, that helps
preparing an annotation campaign. The idea behind the methodology is to formalize as much as
possible the instructions given in the guidelines, in order to automatically check the consistency
of the corpus being annotated with the guidelines, as they are being written. To formalize the
guidelines, we use a graph rewriting tool, that allows us to use a rich language to describe the
instructions. This formalization allows us to spot the rightfully annotated constructions and, by
contrast, those that are not consistent with the guidelines. In case of inconsistency, an expert can
either correct the annotation or update the guidelines and rerun the process.

MOTS-CLES : annotation, guide d’annotation, annotation agile, réécriture de graphes.

KEYWORDS: annotation, annotation guide, agile annotation, graph rewriting.

1 Introduction

11 est aujourd’hui un consensus clair, non seulement que les corpus annotés sont indispensables
aux outils de traitement automatique des langues (TAL) pour leur entrainement et leur éva—
luation, mais également que l’annotation doit étre consistante pour étre proﬁtable (Voir, par
exemple (Reidsma et Carletta, 2008)). Or, l’obtention d’une annotation manuelle de qualité
requiert l’utilisation d’un guide d’annotation sufﬁsamment complet et cohérent (Nédellec et al.,

628 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

2006). La mise au point d’un tel guide est cependant, comme le soulignent Sampson (2000)
et (Scott et al., 2012), loin d’étre triviale.

En outre, il est rare, une fois une campagne d’annotation terminée, que le guide d’annotation et
le corpus annoté soient cornplétement cohérents, ce qui n’est pas sans poser problérne pour les
systénies ou les linguistes utilisant le corpus (Voir par exemple (Candito et Seddah, 2012), en ce
qui concerne le corpus arboré du francais).

Une solution pour remédier a ces deux difﬁcultés consiste a développer le guide et a annoter
le corpus selon des cycles courts de prototypage. Cette méthodologie est appelée Agile Annota-
tion 0/oormann et Gut, 2008) Ea l’image de l’Ag1'le Development (voir ﬁgure 1). Elle n’a, Ea notre
connaissance, été appliquée que dans un seul cas d’annotation réel (Alex et al., 2010).

time ; time
Querying T  
Annotation H i W  3”
Schema ‘  

Annotation ‘  - -- ‘

Analysis ‘ I J

FIGURE 1 — Phases de l’annotation traditionnelle (a gauche) et cycles de l’annotation agile (Ea
droite). Reproduction de la ﬁgure 2 de 0/oormann et Gut, 2008)

 

Indépendamment de la notion d’annotation agile, nous avions utilisé la réécriture de graphes
pour rechercher des erreurs récurrentes dans le corpus Sequoia 1 (Candito et Seddah, 2012).
Cette application directe de la réécriture a la détection d’erreurs a permis d’identiﬁer une centaine
d’erreurs d’annotation et a conduit Ea la publication d’une nouvelle version (3.3) du corpus en
juillet 2012.

Nous présentons ici les expériences que nous avons menées plus récemment dans le cadre de
la correction d’annotations syntaxiques, pour laquelle nous avons transformé les instructions
d’un guide d’annotation existant en regles de réécriture appliquées sur le corpus annoté. Ces
expériences ont montré l’intérét d’une telle formalisation et nous proposons donc son intégration
dans le processus d’annotation manuelle, ce qui conduirait Ea la mise en place d’une annotation
agile assistée.

2 Formaliser un guide d’annotation

La méthode que nous proposons consiste Ea travailler de facon systématique Ea partir du guide
d’annotation. En effet, pour chaque type d’annotation (pour chaque relation de dépendance
syntaxique dans l’exemple utilisé plus loin) le guide énumere les cas ou cette annotation doit étre
réalisée. On utilise alors la réécriture de graphes pour repérer les occurrences des annotations
correspondant Ea chacun des cas énumérés dans le guide. Dans un deuxieme temps, on liste

1. https : //mm . rocq . inria . fr/a1page-wiki/tiki- index .php'?page=CorpusSequoia
629 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

les annotations qui n’ont pas été repérées lors de la premiere phase. En théorie, pour chaque
annotation identiﬁée par cette méthode, se présente l’un des deux cas suivants :

— l’annotation est incorrecte, on doit alors corriger le corpus;

— l’annotation est correcte et elle correspond a un cas d’usage qui n’a pas été identiﬁé par le

rédacteur du guide, on doit alors mettre le guide a jour.

évidemment, dans le cas ou le guide est mis a jour, il faut relancer le processus pour mettre en
évidence d’éventuelles nouvelles incohérences entre le guide et le corpus. La principale difficulté
dans la mise en place de cette méthode réside dans le passage de la version usuelle du guide a sa
version formalisée en terme de réécriture de graphes.

2.1 Guide d’annotation et implicite

Un guide d’annotation est rédigé par des humains pour des lecteurs humains. Plus précisément,
il est rédigé par des experts pour des lecteurs plus ou moins spécialistes en fonction de la tache
d’annotation. Le guide repose donc souvent sur des informations implicites. L’introducu'on décrit
généralement le cadre théorique dans lequel l’annotation est réalisée. Ce cadre permet de donner
les principes généraux qui s’appliquent a l’ensemble du guide. 11 faut, dans la suite du document,
qui décrit des parties plus spéciﬁques de l’annotation, connaitre ces éléments généraux pour
interpréter les informations correctement.

Dans le guide (Candito et al., 2009), il est expliqué, d’une part que la fonction A—OBJ (ﬁgure 2)
concerne des objets indirects en « c‘: » et, d’autre part que cette fonction peut étre réalisée par
un pronom clitique. Tout lecteur francophone sait que, dans le cas de la réalisation clitique,
la préposition n’est pas présente. Cette information n’est pas dans le guide mais elle doit étre
rendue explicite dans la regle. Dans cet exemple, il est facile de construire la bonne regle, mais
en général l’information implicite est plus compliquée a formaliser.

2.2 Limites de la formalisation

Il est bien évidemment impossible de formaliser complétement le guide sous forme de régles. En
effet, dans le cas contraire, cela signiﬁerait que l’annotation peut-étre faite de facon completement
automatique sans avoir recours a un jugement humain. Par exemple, dans le cas de la fonction
A—OBJ (cf. ﬁgure 2), le guide indique qu’un objet indirect introduit par la préposition « c‘z » peut-
étre annoté par une relation A—OBJ entre le verbe et la préposition, mais peut aussi dans certains
cas étre annoté comme un locatif (avec la relation P—OBJ_LOC). Le choix entre l’une des deux
annotations se fait a l’aide d’un test basé sur la cliticisation ou sur la forme interrogative. On
ne peut donc pas automatiquement détecter une erreur d’annotation qui consiste a utiliser la
relation A—OBJ au lieu de P—OBJ_LOC ou l’inverse.

3 Expériences

Nous décrivons ici une premiere expérience d’applicau'on de notre méthodologie sur un corpus et
le guide associé.

630 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

3. 1 Corpus Sequoia

Il existe peu de ressources annotées syntaxiquement pour le francais. Le corpus arboré du
francais (Abeillé et al., 2003), cu French Treebank (FTB), existe depuis une dizaine d’années
mais il n’est pas librement accessible et redistribuable. L’an dernier, un corpus comparable au FTB
mais librement accessible a été propose’, le corpus Sequoia (Candito et Seddah, 2012). Celui—ci
contient environ 3 000 phrases provenant de quatre sources différentes (Wikipédia, Parlement
européen, Est Républicain et Emea). Ces phrases ont été annotées en constituants. L’annotation
en constituants a ensuite été convertie en une annotation en dépendances. L’annotation en
dépendances visée est décrite dans le guide 2 (Candito et al., 2009).

3.2 Réécriture de graphes

Pour formaliser les informations du guide, nous utilisons GREW (Guillaume et al., 2012), un
outil de réécriture de graphes spécialisé pour les applications en TAL. En effet, GREW propose
un langage de description riche qui permet de repérer automatiquement un motif de graphe
dans un ensemble de phrases. Dans un motif, on peut exprimer des combinaisons complexes de
contraintes sur les noeuds, sur les traits et sur les relations de dépendances. De plus, un motif
peut étre sous-spéciﬁé et peut également exprimer des contraintes négatives sur le contexte.

La réécriture de graphes permet, une fois qu’un motif est repéré, de modiﬁer la structure du

ra he. Ici, on n’uu'lisera cette fonctionnalité ue our mar uer cha ue occurrence reconnue (a
8 P (1 P (1 <1
l’aide de suffixes ok ou fail sur les étiquettes de dépendances).

GREW dispose également d’un mécanisme de modules qui permet d’appliquer successivement
plusieurs ensembles de regles de réécriture. Dans notre application, on utjlisera deux modules :
le premier pour repérer les occurrences correctes des dépendances et un second pour mettre en
évidence les dépendances restantes et donc considérées comme incorrectes.

3.3 Un exemple de formalisation : la fonction A-OBJ

La section du guide spéciﬁque a la relation A-OBJ est reproduite dans la ﬁgure 2, ci—dessous.

En général, quelques itéraﬁons sont nécessaires pour coder correctement les parties implicites ou
les parties décrites ailleurs dans le guide.

1. Une traductjon na'1've des informations du guide nous amene a déﬁnir 4 regles : une pour
chacune des réalisations possibles de l’objet indirect : un nom, un pronom clitique, un
pronom non-clitique ou une proposition inﬁnitive.

2. Si l’objet indirect est un clitique, la préposition n’est pas présente (« Il lui parle. ») ; il faut
donc modiﬁer la regle correspondante.

3. En cas d’élision « au », le lemme reste bien « £1 » mais la catégorie est P+D et non pas P; il
faut généraliser les regles.

4. Par contre, en cas d’élision « auquel »; le lemme n’est « c‘1 » mais « auquel» et la catégorie
P+PRO; il faut une cinquieme regle.

2. http : //alpage . inria . fr/statgram/frdep/Publications /FTB—GuideDepSurface . pdf
631 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

3.5 La fonction A-OBJ

Les objets indirects en A , notés A-OBJ, sont des complements obligajoires soit nominaux ou
pronominaux (catégorie PP), soit clitiques (CLO), soit des infnitives phmstiques (VPinI)
immduites par A

Le test pour identifier les A-OBJ est la cliticisation par lui, leur.

(56)
(57)

OBJ :
(53)
(59)

Il ressemble dMart1'n => A-0BJ(ressemble-I,d), 0BJ(d,Mart1'n-3)
J 'encourage Marie d venir => A-0Bl(encourage-I, d), 0BJ(d,ven1'r-4)

La cliticisation en y indique génséralemem un locaﬁf sauf dans certajns cas on‘: on notera A-

Jean pense dMzm'e => A-0BJ(pense-I,d), 0Bl(d,Mzm'e-3)
Jean va dPzm's => P-OB/_LOC(va-I,d), 0BJ(d,Par1's-3)

CaronapasoiipenseJeani/maisbienofivalean?

FIGURE 2 — Extrait du guide d’annotation : la fonction A-OBJ

5. Pour les clitiques, le guide demande la catégorie clitique objet (avec le trait s=ob j ), mais
le corpus contient des relations A-OBJ dont le dépendant est un clitique réﬂéchi (avec
le trait s=ref 1) : «je me pose des questions »; cette annotation est correcte; il faut donc

mettre a jour le guide et ajouter une regle pour ce cas.

Au ﬁnal, on obtient donc les six motifs suivants :

Il reste alors cinq occurrences de la relation A-OBJ qui ne correspondent a aucune des régles

nominal pronominal « c‘z » ou « au » pronominal « auquel »
A-OBJ 053 A-OBJ 053 A-OBJ
cat=V cat=P | P+D cat=N cat=V cat=P| P+D cat=PRO cat=V cat=P+PRO
1emma=é 1emma=é 1emma=auque1
clitique objet clitique réﬂexif inﬁnitif
A-OBJ A-OBJ A-OBJ 053
cat=V cat=CL cat=V cat=CL cat=V cat=P| P+D cat=V
s=obj s=ref1 1emma=é m=inf
L’application de ces motifs sur les 3 203 phrases de Sequoia donne les résultats ci—dessous 3 :
nominal pronominal pronominal clitique clitique inﬁnitif
« (‘l » ou « au » « auquel » objet réﬂexif
nb d’occurrences 476 17 3 84 16 87

ci-dessus. Trois de ces occurrences correspondent a une erreur d’annotation :
— une erreur de POS : « [. . .] on ne condamne pas (‘z mort [. . .]» avec « mort » adjectif;

— dans la construction « répondre c‘1 c6te’ de la question », le groupe prépositionnel « c‘1 c6te’ de la
question » est un complément circonstanciel de maniere, on doit donc avoir la relation MOD;
— utilisation de la préposition « auprés du » dans la construction « se renseigner auprés du comité » :

l’argument du verbe est un P—OBJ introduit par le préposition « auprés de »;

3. Tous les résultats sont disponibles sur : http : //wikilligramme . loria. f r/ doku .php?id=ta1n_2013

632

© ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Les deux autres occurrences sont correctes mais mériteraient de ﬁgurer d’une facon ou d’une
autre dans le guide :

— le dépendant de la préposition a un POS inattendu : par exemple ET (POS pour étiqueter les

mots d’origine étrangére) dans « [. . .] délivre’ (‘z The Medecine Company [. . .] »;

— le gouverneur de la relation A—OBJ est une coordination;

On peut facilement imaginer le type de précisions qu’il est nécessaire d’apporter a cette partie du
guide et donc le type de modiﬁcations qu’il faudra apporter aux régles a la prochaine étape pour
tenir compte des deux derniers points.

4 Méthodologie proposée

L’expérience décrite ci—dessus a été réalisée sur un corpus et son guide ﬁgé : le guide n’a pas été
mis a jour depuis plusieurs années et l’annotation du corpus Sequoia est terminée depuis plus d’un
an. Par ailleurs, le guide n’est pas complet et il reste des sections qui ne sont pas complétement
rédigées, notamment a propos de la coordination. Le corpus n’est donc pas toujours annoté
de maniere consistante, notamment en ce qui concerne les phénomenes non ﬁnalisés dans le
guide. Le corpus Sequoia, auquel nous nous intéressons, est annoté en dépendances syntaxiques,
mais l’annotation de départ et celle sur laquelle les développeurs du corpus travaillent est une
annotation en constituants, et la conversion des constituants vers les dépendances est réalisée de
maniere automatique. Cela ajoute une difﬁculte’ dans la tache de corrections du corpus : quand
une erreur d’annotation est détectée dans les dépendances, il faut retrouver l’origine de l’erreur
dans les constituants ou dans la conversion.

4.1 Intégration dans le processus d’annotation manuelle

Les expériences que nous avons menées nous ont convaincus que notre outil de réécriture de
graphes peut étre un allié précieux dans la recherche de cohérence entre le guide et le corpus.
S’il est intéressant de l’utiliser sur des données statiques, nous pensons qu’il a un r6le encore plus
important a jouer sur des données en construction. Nous proposons donc d’utiliser ce type d’outil
trés tét dans le processus d’annotation, notamment au moment de la création du guide.

Dans l’idéal, chaque application de la réécriture de graphes permet de repérer des erreurs
d’annotation et des erreurs, des manques ou des imprécisions dans le guide. On peut donc
imaginer un processus comme celui décrit dans le schéma de la ﬁgure 3 qui représente un pas
du cycle de développement menant de la version i du guide et du corpus a la version i + 1 de
ceux-ci. Par souci de simplicité, le schéma ci—dessous ne fait pas intervenir de facon explicite
le travail de conversion du guide en régle de réécriture. Ce travail n’est pour autant pas trivial,
comme nous l’avons vu sur notre exemple d’annotation syntaxique.

4.2 Mise en oeuvre

La méthodologie d’annotation agile décrite ci—dessus coﬁte cher et ne peut probablement pas
étre appliquée tout au long d’une campagne de grande envergure. Cependant, il est possible (et
souhaitable) de la mettre en oeuvre lors de la phase de préparation de la campagne, en particulier

633 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Guide‘ fume]
I lRég|es‘ K V Réglj
ll

——— " 1 Brews?» Mise a "our
_ ,____> Expert guide J
Erreurs ’ I 77 77

E";"5—> Mise ajour

  
 

   

FIGURE 3 — Une itération du processus d’annotation agile

lors de la mise au point du guide, réalisée en parallele de l’annotation d’une mini—référence (Fort,
2012). Si la mini—référence se doit d’étre représentative du corpus, sa taille va largement dépendre
des contraintes pratiques de la campagne (coﬁt, disponibilité des experts). 11 en va de meme pour
le nombre d’itérations du cycle d’annotation agile.

Pendant la phase de production, durant laquelle les annotateurs travaillent sur l’ensemble du
corpus, cette méthodologie peut sans doute continuer a étre utilisée, mais avec une durée de
cycle beaucoup plus longue. Le repérage d’erreurs par réécriture de graphes est alors un outil
supplémentaire (en complement d’une évaluation réguliere, voir, la encore, (Fort, 2012)) pour le
gestionnaire de la campagne, qui lui permet d’étre alerté au plus tot en cas de probleme dans
l’annotation.

5 Conclusion et perspectives

Nous avons proposé une méthodologie permettant d’assister l’annotation agile lors d’une cam-
pagne d’annotation, a l’aide d’un outil de réécriture de graphes. Si nous avons obtenu des résultats
intéressants lors des expériences présentées ici, il reste a vériﬁer 1’uu'lisabi1ité du systeme dans le
cadre d’une campagne d’annotation réelle, c’est—a—dire de 1’intégrer dans un cycle d’annotation.

Nous comptons donc appliquer cette méthodologie dans les mois qui viennent, pour la création
de la mini—référence et la mise au point du guide, dans le cadre d’une campagne d’annotation en
dépendances syntaxiques profondes du corpus Sequoia.

Pour d’autres types de campagnes d’annotation (par exemple, sémantique ou discursive), la
réécriture de graphes n’est sans doute pas l’outil le plus adapté. Pour autant, une assistance a
l’aide d’outils TAL, méme frustres, pourrait proﬁter a l’annotation agile, dont le principal écueil
est le coﬁt.

634 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
Remerciements

Nous tenons a remercier Florian Besnard, étudiant a 1’F.cole des Mines de Nancy, qui a participé
lors de son stage a la conversion d’une partie du guide en regles de réécriture.

Références

ABEILLE, A., CLEMENT, L. et TOUssENEL, E (2003). Building a treebank for French. In ABEILLE, A.,
éditeur : Treebanks, pages 165 -187. Kluwer, Dordrecht.

ALEX, B., GROVER, C., SHEN, R. et KABADJOV, M. (2010). Agile corpus annotation in practice : An
overview of manual and automatic annotation of CVs. In Proceedings of the Fourth Linguistic
Annotation Workshop (LAW), pages 29-37, Uppsala, Suede. Association for Computational
Linguistics.

CANDITO, M., CRABBE, B. et FALco, M. (2009). Dépendances syntaxiques de surface pour le
francais. Rapport technique, Université Paris 7.

CANDITO, M. et SEDDAH, D. (2012). Le corpus Sequoia : annotation syntaxique et exploitation
pour l’adaptation d’analyseur par pont lexical. In Actes de T raitement Automatique des Langues
Naturelles (TALN), Grenoble, France.

FORT, K. (2012). Les ressources annotées, un enjeu pour l’analyse de contenu : vers une méthodologie
de l’annotation manuelle de corpus. These de doctorat, Université Paris XIII, LIPN, INIST-CNRS.

GUILLAUME, B., BONFANTE, G., MASSON, R, MOREY, M. et PERRIER, G. (2012). Grew : un outil de
réécriture de graphes pour le TAL. In Actes de Conférence annuelle sur le Traitement Automatique
des Langues (TALN), Grenoble, France.

NEDELLEC, C., BEss1EREs, R, Bossy, R., KOTOUJANSKY, A. et MANINE, A.—R (2006). Annotation gui-
delines for machine learning-based named entity recognition in microbiology. In et C. NEDELLEC,
M. H., éditeur : Proceedings of the Data and text mining in integrative biology workshop, pages
40-54, Berlin, Allemagne.

REIDSMA, D. et CARLETTA, J. (2008). Reliability measurement without limits. Computational
Linguistics, 34(3) :319-326.

SAMPSON, G. (2000). The role of taxonomy in language engineering. Philosophical Transactions of
the Royal Society of London. Series A :Mathematical, Physical and Engineering Sciences, 358 (1769):
1339-1355.

SCOTT, D., BARONE, R. et KOELING, R. (2012). Corpus annotation as a scientiﬁc task. In
International Conference on Language Resources and Evaluation, Istanbul, 'Iurquie.

VOORMANN, H. et GUT, U. (2008). Agile corpus creation. Corpus Linguistics and Linguistic Theory,
4(2):235—251.

635 © ATALA

