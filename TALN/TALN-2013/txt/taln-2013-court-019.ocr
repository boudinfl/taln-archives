TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Similarité de second ordre pour 1’exp1oration de bases
textuelles multilingues

Tulechki Nikola1:2 Tanguy Ludovicl
(1) CLLE-ERSS : CNRS et Université de Toulouse 2, 5 allées Antonio Machado, 31058 Toulouse CEDEX 9
(2) Conseil en Facteurs Humains, 4 impasse Montcabrier, 31500 Toulouse
{tanguy,tu1echki}<0univ—t1se2.fr

RESUME
Cet article décrit l’utilisation de la technique de similarité de second ordre pour l’identiﬁcation
de textes semblables au sein d’une base de rapports d’incidents aéronautiques mélangeant les
langues francaise et anglaise. L’objectif du systeme est, pour un document donné, de retrouver
des documents au contenu similaire quelle que soit leur langue. Nous utilisons un corpus bilingue
aligné de rapports d’accidents aéronautiques pour construire des paires de pivots et indexons les
documents avec des vecteurs de similarités, tels que chaque coordonnée correspond au score de
similarité entre un document dans une langue donnée et la partie du pivot de la méme langue.
Nous évaluons les performances du systeme sur un volumineux corpus de rapports d’incidents
aéronautiques pour lesquels nous disposons de traductions. Les résultats sont prometteurs et
valident la technique.

ABSTRACT
Second order similarity for exploring multilingual textual databases

This paper describes the use of second order similarities for identifying similar texts inside a
corpus of aviation incident reports written in both French and English. We use a second bilingual
corpus to construct pairs of reference documents and map each target document to a vector so
each coordinate represents a similarity score between this document and the part of the reference
corpus written in the same language. We evaluate the system using a large corpus of translated
incident reports. The results are promising and validate the approach.

MOTS-CLES : similarité de second ordre, multilingue, ESA.

KEYWORDS: second order similarity, multilingual, ESA.

1 Introduction et contexte applicatif

Dans toute industrie a risque, le retour d’expérience (REX) occupe une place capitale dans les
mécanismes de gestion de la sﬁreté. Des politiques de recueil, d’analyse et de stockage sont mises
en place aﬁn de garder une trace de tout événement qui s’écarte de la norme, de tout incident ou
accident qui survient lors des opérations. Les informations ainsi recueillies servent ensuite de
support aux experts de sﬁreté pour mettre a jour les régles et les procédures d’exploitation en les
adaptant a un contexte en perpétuelle évolution.

L’aviau'on civile est sans doute le secteur dans lequel les politiques de recueil sont les plus avancées
et il n’est pas rare que les bases de REX regroupent plusieurs centaines de milliers de rapports.

651 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Les stratégies d’exploitation actuelles, basées sur la codiﬁcation manuelle de chaque rapport
s’avérent insufﬁsantes, a cause d’un codage souvent incomplet et hétérogéne (Tulechki et Tanguy,
2012). De ce fait, proposer aux experts des outils facilitant l’acces a l’information contenue dans
la partie textuelle des rapports est devenu capitale (Tulechki, 2011). Plus précisément encore,
l’un des moyens privilégiés d’exploitation de ce type de base par des experts consiste a partir
d’un événement particulier et a rechercher des cas similaires aﬁn de faire émerger de nouveaux
risques non encore identiﬁes (et codés).

Cependant, compte tenu du caractére intrinséquement international de l’activité, les informations
dans les bases sont souvent écrites dans des langues différentes, ce qui complique considéra-
blement leur exploitation de maniere outillée. Notre objectif est donc de concevoir un systeme
capable de calculer la similarité textuelle entre deux textes, quelle que soit la langue dans laquelle
ils sont écrits. Aﬁn que le traitement de plusieurs langues soit possible les textes doivent d’abord
étre ramenés a une représentation commune. Traditionnellement ceci implique l’utilisation de
techniques de traduction automatique (TA). Dans notre cas la TA n’est pas envisageable puisque
que les systemes de TA disponibles ne sont pas adaptés aux particularités stylistiques du langage
technique de l’aviation. Pour ces raisons nous nous sommes tournés vers la similarite’ de second
ordre, qui pour une implémentation multilingue ne nécessite pas d’autres ressources qu’un corpus
aligné servant d’intermédiaire (Claveau, 2012).

Dans un premier temps nous présenterons les principes généraux d’approche par similarité de
second ordre monolingue ainsi que son application dans des contextes multilingues. Ensuite nous
détaillerons notre expérience sur un corpus spécialisé multilingue.

2 Similarité textuelle

2.1 Similarité de premier ordre

Calculer la similarité textuelle revient a attribuer un score représentant le degré de ressemblance
entre deux textes en se basant sur leur taux de recouvrement lexical. Aujourd’hui encore le
modéle Vectoriel (Salton et al., 1975) est le plus couramment utilisé. Le score de similarité est
obtenu en calculant le recouvrement (généralement par une mesure de type cosinus) entre deux
Vecteurs dans un espace a n dimensions correspondant aux termes présents dans la collection.
Compte tenu du fait que les documents sont rapprochés grace aux termes qu’il partagent, cette
approche est particuliérement sensible a la Variation lexicale. Deux documents qui traitent du
méme sujet, mais y référent avec des synonymes ne seront pas rapprochés par le calcul et les
techniques existantes bien connues, visant 2‘: en assurer le rapprochement, reposent classiquement
sur des ressources lexicales coﬁteuses a développer et a maintenir dans le cadre d’un domaine
tres spécialisé. Cette similarité est dite de premier ordre dans la suite de cet article.

2.2 Similarité de second ordre

2.2.1 Principe de base

De multiples techniques cherchant a représenter plus ﬁdélement les textes en fonction de leur
contenu et a maitriser les incohérences dues a la variation lexicale ont vu le jour. Une en
particulier, mise au point par Gabrilovich et Markovitch (2007) consiste 2 calculer une similarité
de premier ordre entre chaque document de la collection et un ensemble de n documents

652 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

pivots arbitraires extérieures a cette collection. Les scores forment par la suite un vecteur de n
dimensions qui est utilisé pour représenter le document. La similarité est ensuite calculée de
maniére standard en comparant les vecteurs des documents dans ce nouvel espace (voir ﬁgure 1).

L’implémentation originelle, appelée ESA1 a été évaluée sur un corpus de paires de textes sur
lesquels un jugement de similarité avait été donné par des annotateurs humains. Le systeme
atteint des performances supérieures a la fois a la similarité de premier ordre et aux techniques
de réduction de dimensions comme la LSA/LSI.

    
  
 

Vecieurdu V V V V
document A l 1 , 2 , 3 ' ' ' n
Document , ,

A Slrmlamé Swmllarlté Slmllarlte _ _ _ Slmllarlte

. ﬁt»

Doc pivot 1 Doc pivot 2 Doc pivot 3 Doc pivot n

TV I

sIm(A,B)

DUCWTVSWT . . ., . . ., . . ., . .,

B Slmllarlte Slmllarlte Slmllame _ _ _ Sxmllarlte
vecteur du V1 V2 V3 _ _ _ Vn
documentB , ,

FIGURE 1 — Principe de la similarité de second ordre

On voit bien que le contenu des deux documents n’est pas indexé directement. Cette technique
permet donc de traiter des documents en évitant de se baser sur le partage de termes.

2.2.2 Le choix des pivots

Originellement l’ESA utilise des articles de Wikipédia comme documents pivots. Ses auteurs
insistent sur l’apport en terme de connaissances de leur choix et l’importance du fait que l’espace
ainsi construit est déterminé par rapport aux "concepts naturels" déﬁnis par les rédacteurs
de l’encyclopédie. Le caractére "explicite"2 permet en effet que chacune des dimensions soit
directement interprétable. I1 s’en est suivi qu’une partie considérable de la recherche dans ce
domaine s’est centrée sur les stratégies d’exp1oitation de la catégorisation de Wikipédia afin de
construire des pivots en concaténant des articles en fonction de leur place dans la hiérarchie.

Cependant Claveau (2012) a démontré que la similarité de second ordre peut étre efﬁcace sans
obligatoirement se baser sur une ressource structurée. En utilisant des textes tout-venants comme

1. Explicit Semantic Analysis
2. Les auteurs ont sans doute choisi cette dénomination pour se différencier des “concepts implicites“ formés par les
méthodes de réduction de dimensions.

653 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

pivots, il a évalué la technique sur des taches de RI et de fouille de texte en obtenant a chaque
fois des résultats encourageants.

La question du choix des pivots pour le traitement des textes d’un domaine spécialisé ne s’est
pas encore posée dans la littérature. Néanmoins, il semble évident que compte tenu du fonc—
tionnement de la similarité de second ordre, utiliser des pivots issus du méme domaine est
préférable. Des pivots inadaptés aux documents traités peuvent a la fois engendrer du bruit et
du silence; indexer un rapport d’accident aéronautique en utilisant sa similarité (ou plut6t sa
différence) avec l’article Wikipédia sur Walt Disney ne semble guére distinctif. Pire encore, un
terrne spéciﬁque contenu dans les documents mais absent des pivots sera perdu a jamais du point
de vue du calcul.

2.3 Application inter-langue

L’adaptau'on de la similarité de second ordre a un contexte multilingue est relativement simple.
L’espace dans lequel sont représentés les documents étant indépendant3 de la langue, tout docu-
ment peut y étre représenté. Pour cela il sufﬁt d’uti1iser comme pivots des paires de documents
traduits dans plusieurs langues aﬁn de pouvoir calculer les similarités de premier ordre avec la
partie de la collection écrite dans la méme langue que le document (voir ﬁgure 2).

Vecieur du V V V V
documen1A l 1 , 2 , 3 ' ' ' n

Document . . . . . . . . . .
 X Similarité I I Similarité ‘ Similarité J  Similarité

tr . ‘rd Pivot” Similarité sim(A,B)
Document _ _ _,
B (EN) Slmllame

Ve°‘e“” d” V1 V2 V3 . .. Vn
document B , ,

      

   

Similarité

Similarité J

FIGURE 2 — Similarité de second ordre inter—langue

Sorg et Cimiano (2012) ont appliqué l’ESA a plusieurs langues. Pour cela ils construisent des
ensembles de pivots en exploitant les liens de traduction présents dans Wikipédia. Si le n-eme
pivot correspond au concept Hépital, la n—éme coordonnée des vecteurs des documents en anglais

3. Par comparaison a l’espace des termes pour la similarité de premier ordre.

654 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

correspondra a la similarité entre le document et l’article Hospital de la version anglaise de
l’encyclopédie ainsi que la méme coordonnée d’un document en allemand correspondra a la
similarité entre le document et l’article Krankenhaus de la version allemande. Les documents
sont ainsi représentés dans le méme espace et une similarité peut étre calculée a la fois entre
documents d’une méme langue et de langues différentes.

Aﬁn d’évaluer le systéme les auteurs utilisent un corpus paralléle de documents législatifs traduits
dans plusieurs langues et la tache de recherche de partenaire 4. ﬁtant donné un document dans une
langue donnée, la tache consiste a retrouver ses traductions (partenaires) parmi les documents de
la base. Comme mesure, les auteurs utilisent le rappel au rang k (R@k), qui consiste a chercher
le partenaire parmi les k documents les plus similaires retournés par le systeme. Un R@10 de
1 signiﬁe que pour tout document, sa traduction se trouve dans les 10 premiers documents.
Ce score repose sur l’hypothese qu’un systeme performant doit maximiser la similarité entre
un document et sa traduction. Lors de l’évaluation de leur systeme, Sorg et Cimiano (2012)
atteignent un R@ 10 variant entre 0,27 et 0,51.

Une méthode similaire a été également utilisée pour la clusterisaﬁon de documents multilingues
(Kiran Kumar et al., 2011), toujours en utilisant la Wikipédia comme corpus pivot.

3 Application a un domaine spécialisé

Notre systéme s’inspire des travaux cités précédemment aﬁn d’adapter la technique a un corpus
de rapports d’incidents aéronautiques écrits en francais et en anglais. Nous utilisons deux corpus
distjncts :

Pour les pivots, nous utilisons un corpus de rapports d’accidents du Bureau de la Sécurité des
Transports du Canada 5. Ces documents longs de plusieurs pages existent systématiquement en
anglais et en francais et décrivent de facon exhaustive l’analyse d’un accident aéronautique. Aﬁn
d’obtenir un nombre sufﬁsant de pivots, nous les découpons en paragraphes 6 que nous alignons
entre les deux langues en nous basant sur l’isomorphie de leurs structures HTML. Ce découpage
permet d’obtenir 10032 paires de pivots a paru'r de 390 paires de documents.

A des ﬁns d’évaluation, nous utilisons un second corpus de rapports d’incidents issu de la base
CADORS7 qui contient des rapports volontairement soumis aux autorités de régulation de
l’aviation canadienne. Ces documents d’une centaine de mots en moyenne résument un incident
aéronautique. Ils sont trés semblables aux textes des autorités de controle francaises auxquelles
notre systéme est destiné. Compte tenu de la réglementation canadienne, comme pour le corpus
des pivots, les rapports québécois sont systématiquement traduits et nous pouvons donc procéder
a une évaluation par la tache de recherche de partenaire. Au total le corpus d’évaluation comporte
9217 documents bilingues comme ceux présentés en exemple en table 1.

4. mate retrieval

5. http : //www . bst—tsb . gc . ca/fra/rapports— reports/aviation/index . asp

6. Nous avons choisi ce niveau de grain, aﬁn d’obtenir sufﬁsamment de pivots pour un bon fonctionnement du
systéme.

7. Civil Aviation Daily Occurrence Reporting System. http : //wwwapps .tc . gc . ca/ Saf—Sec—Sur/ 2/
cadors — screaq/

655 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

CRQ590M, a Beech A100 operated by Air Cree-
bec as ﬂight number CRQ590, was on an IFR
MEDEVAC ﬂight from Chibougamau/Chapais
(CYMT) to Montréal/Trudeau (CYUL). At 15352,
the crew was instructed to conduct a missed ap-
proach for Runway 06R due to the presence of C
FFWJ, an Airbus A-320 operated by Air Canada
as ﬂight number ACA407, which was lined up for
departure and which had a mechanical problem.
CRQ590 eventually landed without incident at
1546Z.

CRQ590M, un Beech A100 exploité par Air Cree-
bec sous l’indicatif de vol CRQ590, effectuait un vol
d’évacuation médicale selon les regles de vol aux
instruments (IFR) depuis Chibougamau / Chapais
(CYMT) a destination de Montréal/Trudeau (CYUL).
A 1535Z, l’équipage a regu l’instruction d’interrompre
son approche pour la piste 06 droite en raison de la
présence de C-FFWJ, un Airbus A-320 exploité par
Air Canada sous l’indicatif de vol ACA407 qui était
aligné au départ et qui avait un probléme mécanique.
CRQ590 a ﬁnalement atterri sans encombre a 1546Z.

TABLE 1 — Exemple de rapport d’incident et sa traduction

4 Architecture du systéme

Prétraitements et normalisation

Nous utilisons pour le prétraitement des corpus (documents—pivots et corpus d’évaluation) des
outils génériques disponibles pour le langage Perl. La segmentation est ainsi faite par un simple
tokeniseurs basé sur des expressions réguliéres. Nous appliquons ensuite le raciniseur Snowball 9
et un anti—dictionnaire standard. Vu que les corpus sur lesquels nous travaillons sont souvent de
mauvaise qualité, comportant de nombreux documents écrits entierement en majuscules, nous
normalisons la casse et supprimons les accents pour le francais.

Pondération et calcul de similarité

Aﬁn de prendre en compte l’importance relative des termes dans les documents nous utilisons
un schéma de pondération proposé par Turney et Pantel (2010) : la Positive Pointwise Mutual
Information pour la similarité entre les documents et les pivots. Les vecteurs de second ordre
ne sont pas pondérés : tous les documents—pivots ont un poids identique pour le calcul de la
similarité (basé sur une mesure cosinus).

Elagage

Contrairement aux vecteurs de premier ordre, trés creux par déﬁnition, les vecteurs de second
ordre sont systématiquement pleins. Ceci alourdit considérablement le calcul et pour cette raison
nous appliquons un seuil minimum arbitraire de 0,05 et ramenons tout score inférieur 2 ce seuil
a zéro. Cette opération laisse des vecteurs de second ordre relativement creux avec en moyenne
45 valeurs non-nulles (sur 10000) par document.

5 Evaluation

Aﬁn d’évaluer le systéme, nous avons appliqué la téche de recherche de partenaire au corpus issu
de la base CADORS cité ci—dessus.

8. http : //search . cpa.u . org/"dami/Search—Tokenizer— 1 . 01/lib/Search/Tokenizer . pm
9. http : //search . cpa.u . org/"creamyg/Ling'ua— Stem— Snowba11— 0 . 952/1ib/Ling'ua/Stem/
Snowball .pm

656 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Lors de nos premiers tests, nous avons trouvé que pour certains rapports, le partenaire (i.e. sa
traduction) se trouvait trés loin dans la liste des résultats, dans certains cas a un rang supérieur a
500. Nous avons regardé les rapports en question et nous nous sommes apercus que le corpus
contenait des séries de rapports trés similaires, au point de poser la question des limites de
l’intérét de l’analyse de similarité pour certains textes. En effet, a cause de la nature réglementaire
du signalement d’incidents aéronautiques, certains problémes courants sont systématiquement
rapportés via des textes standardisés selon un schéma commun 1°. 11 apparait clairement que les
seules différences entre les documents de ces séries sont des codes, des nombres et éventuellement
des noms de villes a priori absents des pivots et dont l’impact sur la similarité est nul. Retrouver
la traduction au sein de la série repose par contre uniquement sur ces éléments, ce qui explique
le probléme rencontré. Si notre méthode est inadaptée a ces cas particuliers, ils peuvent étre
traités par des méthodes de surface simples.

Nous avons décidé de ne pas les prendre en considération en les identiﬁant en calculant pour
chaque document la similarité moyenne des 100 premiers rapports similaires. Si cette moyenne
dépassait 0,95, nous considérons que le rapport en question est un texte préformaté et l’excluons
du corpus d’évaluation. Au total 823 paires de documents ont été exclues.

Le corpus ﬁnal d’éva1uation comporte donc 16788 documents monolingues, de facon a ce que
la traduction de chacun soit aussi présente dans la base. Nous avons procédé a la tache de
recherche du partenaire pour la totalité du corpus et calculé le R@k pour les rangs 1, 10 et
100, séparément pour les documents en francais et en anglais en ne prenant en compte que les
documents retournés qui ne sont pas de la méme langue que le document source. Les résultats
sont résumés dans la table 2.

FR EN
R@1 0,43 0,45
R@10 0,71 0,74
R@100 0,90 0,94

TABLE 2 — Résultats de la recherche de partenaire

Comme nous pouvons le voir, les résultats sont encourageants et valident cette approche, au
méme niveau pour les deux langues. Dans plus de 40% des cas, la traduction est bien le document
le plus similaire retourné par le systeme. Dans plus de 70% des cas, la traduction se situe dans
les 10 documents les plus similaires.

6 Conclusion et perspectives

Nous avons présenté une approche permettant de calculer la similarité entre documents de
langues différentes issues d’un domaine spécialise’ que nous avons évaluée sur un grand corpus
de documents réels, semblables aux documents auxquels le systéme est destiné. Cette expérience
permet de valider la méthode et nous encourage a nous intéresser davantage aux particularités
de ce type de calcul.

10. Les deux courts rapports ci-dessous exempliﬁent ce fait :
A :“La station radio d’ae'roport communautaire (CARS) de Waskaganish (CYKQ) n’a pas assure’ les services de me'te'o et de
radio d’aérodrome entre 1300Z et 2100Z.“
B :“La station radio d’ae'roport communautaire (CARS) d’Inukjuak (CYPH) n’a pas assure’ les services de me'te'o et de radio
d’aérodrome entre 1130Z et 2130Z.“

657 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Puisque la méthode est basée sur une similarité classique de premier ordre (entre les documents-
cibles et les pivots), il est logique que le paramétrage de cette derniere inﬂuence les performances.
L’expérience présentée dans cet article utilise une chaine de similarité basique, mais nous
explorerons a 1’avenir1’apport de traitements linguistiques plus sophistiqués en amont.

Le cété explicite de la méthode nous aménera surtout a nous intéresser de pres aux documents
pivots et a analyser plus précisément leur role dans le calcul ﬁnal du score de similarité. Le fait que
nous y avons facilement accés et que les pivots sont interprétables nous permettra de facilement
tracer et comprendre les variations du comportement du systéme avec différents ensembles de
documents pivots. Dans cette logique nous poursuivrons les recherches entamées dans 'I111echki
et Tanguy (2012) visant a identiﬁer les dimensions de similarité entre des documents. Si, comme
c’est le cas dans les données utilisées, les documents—pivots disposent d’un codage spéciﬁque
(méta-données, catégorisation exteme, etc.), nous pourrons l’exploiter a la fois pour identiﬁer ces
dimensions, mais aussi pour restreindre les pivots en fonction de leurs caractéristiques, et ainsi
orienter de facon interactive l’investigation en fonction des facettes exprimées par l’utilisateur.

Remerciements

Nous tenons a remercier Assaf Urieli de CLLE—ERSS d’avoir adapté son calculateur de similarité
aux exigences particulieres de cette expérience.

Références

CLAVEAU, V (2012). Vectorisation, Okapi et calcul de similarité pour le TAL : pour oublier enﬁn
le TF-IDF. In Actes de TAI.N, pages 85-98, Grenoble.

GABRILOVICH, E. et MARKOVITCH, S. (2007). Computing semantic relatedness using Wikipedia-
based explicit semantic analysis. In Proceedings of IJCAI, pages 1606-1611, Hyderabad, India.

KIRAN KUMAR, N., SANTOSH, K. G. S. et VARMA, V (2011). Multilingual document clustering using
wikipedia as external knowledge. In Proceedings of IRFC, pages 108-117.

SALTON, G., WONG, A. et YANG, C.—S. (1975). A vector space model for automatic indexing.
Communications of the ACM, 18(11):613—620.

SORG, P. et CIMIANO, P. (2012). Exploiting wikipedia for cross-lingual and multilingual informa-
tion retrieval. Data & Knowledge Engineering, 74(0):26 - 45.

TULECHKI, N. (2011). Des outils de TAL en support aux experts de sﬁreté industrielle pour
l’exploitation de bases de données de retour d’expérience. In Actes de RECITAL, Montpellier.

TULECHKI, N. et TANGUY, L. (2012). Effacement de dimensions de similarité textuelle pour
l’exploration de collections de rapports d’incidents aéronautiques. In Actes de TALN, Grenoble.

TURNEY, P. D. et PANTEL, P. (2010). From frequency to meaning : Vector space models of semantics.
J. Artiﬁ Intell. Res. (JAIR), 37:141-188.

658 © ATALA

