TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Apprentissage d’une classiﬁcatiqn thématiclluengénérique
e cross-langue a partlr des categorles de a 1k1ped1a

Frangois—Régis Chaumartinl
(1) Proxem, 19 boulevard de Magenta, 75010 Paris
frc@proxem. com

RESUME

La catégorisation de textes nécessite généralement un investissement important en
amont, avec une adaptation de domaine. L’approche que nous proposons ici permet
d’associer ﬁnement a un texte tout-venant écrit dans une langue donnée, un graphe de
catégories de la Wikipédia dans cette langue. L’utilisation de l’index inter-langues de
l’encyclopédie en ligne permet de plus d’obtenir un sous-ensemble de ce graphe dans la
plupart des autres langues.

ABSTRACT

Cross-lingual and generic text categorization

Text categorization usually requires a signiﬁcant investment, which must often be
associated to a ﬁeld adaptation. The approach we propose here allows to ﬁnely associate
a graph of Wikipedia categories to any text written in a given language. Moreover, the
inter-lingual index of the online encyclopedia allows to get a subset of this graph in most
other languages.

MOTS-CLES : catégorisation, apprentissage, recherche d’information, Wikipédia, graphes
KEYWORDS: categorization, machine learning, information retrieval, Wikipedia, graphs

1 Présentation et objectifs

La catégorisationl est le processus qui consiste a associer a un document donné une ou
plusieurs étiquettes prédéﬁnies. L’objectif d’une catégorisation automatique de textes est
d’apprendre a la machine a effectuer cette classiﬁcation en analysant son contenu. La
nature méme des catégories prédéﬁnies varie en fonction des objectifs ; il peut s’agir
d’identiﬁer la langue du texte, les thématiques abordées, mais aussi par exemple la
priorisation souhaitée pour le traitement du document, ou encore les sentiments
exprimés. La difﬁculté de la tache varie selon le type et la longueur du document ; un
tweet, un email, un article de presse, un document scientiﬁque ou un avis de
consommateur ne s’analysent généralement pas de la méme fagon.

Les étapes opérationnelle préalables a l’apprentissage d’une classiﬁcation sont le plus
souvent: i) la constitution du plan de classement, ii) l’annotation manuelle du corpus
d’apprentissage, iii) la déﬁnition de caractéristiques linguistiques utilisées par
l’algorithme d’apprentissage. Ces opérations peuvent étre chronophages; leur résultat
n’est généralement applicable qu’au domaine particulier concerné par les catégories
prédéﬁnies, et aux types de documents représentatifs du corpus d’apprentissage.

1 On parle aussi de classiﬁcation ; dans le milieu da sondages, on emploie plut6t le terme de codiﬁcation.

659 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

L’approche que nous présentons ici concerne la catégorisation thématique ; notre
objectif est d’identiﬁer automatiquement les différents sujets dont parle un textez. Notre
ambition est double. D’une part, savoir traiter un document tout-venant (sous réserve
d’une taille minimale) d’une facon générique, c’est-a-dire sans imposer préalablement
une phase manuelle d’apprentissage spéciﬁque au domaine ou a la langue du document.
D’autre part, étre capable de traduire (au moins certaines) des thématiques du document
dans d’autres langues que celle du texte d’origine ; l’intérét de ce point est d’autoriser
alors une recherche cross-langue des documents associés a une thématique donnée.

2 Etat de 1’art succinct

Si l’application de l’apprentissage automatique a la catégorisation de textes n’est pas
nouvelle, son importance est grandissante. (Sebastiani, 2002) fournit un tableau
comparatif des méthodes et applications possibles. (Dasari, Rao, 2012) complete cet état
de l’art avec des approches plus récentes et mesure les progres accomplis en 10 ans.

Une question se pose a propos des plans de classement, généralement déﬁnis pour un
domaine particulier. Quel jeu d’étiquettes prédéﬁni serait sufﬁsamment couvrant pour
catégoriser d’une facon raisonnablement générique un texte tout venant ? Les catégories
de la Wikipédia sont récemment apparues comme une possibilité de tel plan de
classement universel. (Schonhofen, 2009) propose ainsi de les utiliser pour effectuer une
catégorisation thématique avec un algorithme simple (dont l’implémentation met en
oeuvre un moteur de recherche) qui se contente d’exploiter les titres et les catégories des
articles. Une idée proche est présentée dans (Yun et aL, 2011). Les catégories Wikipédia
servent aussi de référence dans l’ontologie YAGO (Suchanek et aL, 2007).

3 Démarche

3.1 Utiliser les Wikipédia pour effectuer un apprentissage 5 large échelle

Les encyclopédies collaboratives Wikipédia ﬁgurent parmi les sources ayant de bonnes
propriétés pour nous aider a atteindre notre objectif. En mars 2013, elles comptent 41
langues dotées de plus de 100 000 articles, et 70 autres avec au moins 10 000 articles.
Ce volume permet de réaliser des apprentissages dans de nombreuses langues, dont
certaines sont faiblement dotées en ressources lexicales.

Wikipédia propose différentes formes de structuration de l’information :

— Un article est classé dans une ou plusieurs catégories (en bas de chaque page) ;

— Les articles et catégories portant sur le méme sujet, en différentes langues, sont
reliés entre eux par l’intermédiaire d’un index interlingue (afﬁché a gauche) ;

— Les InfoBox présentent des données structurées sur un sujet sous forme de tables
préformatées (encadrés placés en haut a droite ou en ﬁn d’article) ;

— Les articles peuvent étre rattachés a des portails, c’est-a-dire des regroupements
thématiques offrant des points d’entrée dans l’encyclopédie ;

— Chaque article est organisé en sections et sous-sections.

2 Par opposition E1 ce que l’on en dit ; nous ne chercherons pas ici E1 fajre d'a.na1yse d'opinjons, par exemple.

660 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Nous tirons parti notamment des deux premiers points. Les catégories sont organisées
selon un graphe orienté au sein duquel une catégorie est reliée a d’autres, plus générales
ou plus spéciﬁques. Par exemple3, SCIENCE THEORIQUE et INFORMATIQUE sont les deux
catégories meres de INFORMATIQUE THEORIQUE, qui possede 21 sous-catégories
(ALGORITHMIQUE, CALCULABILITE ...). Par ailleurs, 91 articles (Perceptron, Codage...) sont
directement annotés avec (entre autres) la catégorie INFORMATIQUE THEORIQUE.

L’ensemble de ces graphes forme un plan de classement thématique cross-langue a large
échelle. L’idée que présentons ici consiste a effectuer un apprentissage sur le contenu
textuel des articles annotés par ces catégories. Nous allons mettre en oeuvre pour cela des
techniques —classiques et éprouvées— de recherche d’information, en stockant les
résultats de cet apprentissage dans un moteur de recherche. La catégorisation d’un
document revient alors simplement a effectuer une recherche dans l’index créé; plus
précisément, nous utiliserons le texte du document comme requéte, et le moteur de
recherche renverra comme résultat les catégories jugées les plus pertinentes.

3.2 Simpliﬁcation des graphes de catégories de la Wikipédia

L’apprentissage est effectué sur chaque langue séparément. Nous commencons par
charger en base de données la structure4 fournie par le classique ﬁchier XML d’import5,
pour en faciliter la manipulation ultérieure. Notre traitement commence par restructurer
le graphe des catégories. Dans les versions que nous avons utilisées, celui de la
Wikipédia en langue anglaise compte par exemple 438 251 sommets reliés par 949 017
arcs ; celui de la Wikipédia francaise contient 116 158 sommets et 230 217 arcs.

3.2.1 Détection et suppression des cycles

Chaque langue est organisée d’une fagon spéciﬁque, selon un graphe orienté de
catégories qui possede une racines (ou éventuellement plusieurs). La limite pratique des
Wikipédia est la bonne volonté (ou la compétence) des internautes qui éditent les
articles ; parfois, ils introduisent involontairement des cycles7 entre catégories. La phase
d’apprentissage devra explorer récursivement le graphe des racines jusqu’aux feuilles.
Une opération préliminaire consiste donc a détecter puis supprimer ces cycles, de fagon a
travailler sur un graphe orienté acyclique (directed acyclic graph ou DAG en anglais) et
éviter les boucles inﬁnies. Nous appliquons pour cela l’algorithme décrit dans (Tarjan,
1972), qui détecte les zones fortement connexes d’un graphe orienté avec une
exploration en profondeur a partir des racines.

3 Nous noterons la catégories en petites majuscules p1ut6t que sous la forme « Catégorie: Libellé >>.

4 La contenus textuels (balisés en syntaxe Medjawiki) ne sont pas importés pour des rajsons de performance,
majs 1'empan permettant d'y accéder at créé en base de donnés lors de la lecture du ﬁchjer XML.

5 Les ﬁchiers XML compressés (« dumps >>) sont téléchargeables sur http://dumps.wikimedia.org/

5 C'est-E1-dire une catégorie plus générale que toutes la autra. En frangajs, elle est unique et s'appel1e AR'I'ICLE.
Plusieurs racines coexistent pour 1'a.ng1ajs, proposant des organisations djfférentes ; nous avons choisi de partir
de MAIN TOPIC CLASSIFICATIONS majs nous aurions aussi pu retenir FUNDAMENTAL CATEGORIES.

7 En pratique, ces cycles existent dans les djfférentes Wikipédia, majs en nombre relativement fajble.

661 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

La seconde étape consiste a enlever localement un arc jusqu’a supprimer tous les cycles.
Le choix de l’arc a enlever a une dimension arbitraire ; nous privilégions ceux qui relient
les sommets les plus bas dans la hiérarchie.

3.2.2 Suppression des catégories trop ﬁnes

Toutes les catégories ne sont pas pertinentes comme résultat d’un systeme de
classiﬁcation. En effet, beaucoup semblent avoir été créées pour pallier un déﬁcit de
structuration de la Wikipédia : par exemple, NAISSANCE PAR VILLE EN FRANCE compte plus
de 1 000 sous-catégories correspondant a autant de villes ; CHRONOLOGIE PAR CONTINENT
énumere des événements par année avec plus de 500 sous-catégories. Nous commencons
par réduire ce graphe avec différentes heuristiques pour simpliﬁer les manipulations
informatiques ultérieures ; nous supprimons récursivement comme catégories trop ﬁnes :

— Les feuilles du graphe (les noeuds n’ayant pas de catégorie plus spéciﬁque).
— Les catégories servant a annoter trop peu d’articles (10 dans notre expérience).

Lors de ces opérations, les articles directement reliés aux sommets supprimés sont alors
annotés avec leur catégorie mere, de fagon a préserver l’information correspondante. Au
ﬁnal, nous obtenons un DAG plus compact que celui d’origine (Cf. la table 1).

En francais En anglais

_ _ _ _ Nombre de sommets 116 158 438 251

Volumétrie 1n1t1ale
Nombre d’arcs 230 217 949 017
, _ ‘ _ _ _ Nombre de sommets 59 267 229 626

Volumetr1e apres s1mpl1ﬁcat1on

Nombre d’arcs 125 635 535 089

TABLE 1 — Volumétrie du graphe de catégories avant et apres simpliﬁcation.

Des heuristiques supplémentaires pourraient s’appliquer, par exemple a travers
l’utilisation de patrons morphosyntaxiques pour détecter des noms de catégories
particulieres. Une catégorie comme NAISSANCE EN [ANNEE] n’est pas forcément pertinente
dans notre problématique. Nous avons toutefois renoncé a cette approche, qui imposerait
un paramétrage manuel particulier pour chaque langue, ce que nous souhaitons éviter.

3.3 Apprentissage par indexation dans un moteur de recherche

3.3.1 Principe général

Une fois le graphe simpliﬁé, nous pouvons en indexer le contenu dans un moteur de
recherche. L’objectif ici est d’associer a chaque catégorie un sac de mots (ou plus
exactement un vecteur termes-fréquences) représentatif. La classiﬁcation d’un document
revient alors a utiliser ses termes comme criteres de recherche; le moteur renverra
comme résultat les catégories les plus pertinentes, correspondant le mieux au document.

Notre implémentation met en oeuvre le moteur de recherche open source Lucenes. Il
permet d’indexer des textes selon une séquence d’opérations classique en recherche

8 http://lucene.apache.org/
662 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

d’information : segmentation du texte en mots, normalisation de leur casse, suppression
des diacritiques, suppression des mots grammaticaux (stop words), racinisation
(stemming) et comptage des termes; l’un des intéréts de Lucene est de proposer en
standard ces opérations pour une trentaine de langues. Le résultat de ce processus est un
vecteur des termes représentatifs des articles d’une catégorie, associés a leurs fréquences.

Le graphe simpliﬁé des catégories est d’abord triée par ordre topologique inversé.
L’indexation est effectuée avec une exploration récursive remontant des feuilles du DAG
jusqu’a la racine. Le vecteur termes-fréquences d’une catégorie est calculé en fusionnant :

— Celui obtenu par le processus d’indexation décrit plus haut, appliqué au texte des
articles directement annotés par la catégorie.
— Ceux déja calculés sur ses k sous-catégories, pondérés par un facteur 1 / (k + 1).

On donne ainsi une importance prédominante aux termes des articles directement liées a
la catégorie, tout en conservant la contribution due aux catégories plus spéciﬁques.

3.3.2 Amélioration du processus

Notre implémentation utilisant Lucene, les techniques classiques d’optimisation de
moteur de recherche s’appliquent ici. En ce qui concerne la pertinence, une amélioration
du mécanisme consiste a indexer aussi les termes composés; leur utilisation lors de
l’indexation et de la recherche améliore la pertinence des résultats, certes au prix d’une
augmentation du temps de calcul. Nous utilisons des n-grammesg en plus des termes

simples, avec n inférieur ou égal a 3 dans notre expérience1°.

Vus les volumes de texte manipulés, la taille de l’index Lucene peut devenir tres
importante (plusieurs giga-octets pour les langues les mieux dotées); elle s’accro’1‘t
encore quand on indexe des n-grammes en plus des termes simples. Ce point a un impact
direct sur les temps de recherche. De fagon a limiter la taille de l’index et améliorer les
performances, on peut choisir de ne pas indexer les hapax d’une encyclopédie en une
langue donnée; un examen manuel de l’index de la Wikipédia frangaise montre par
ailleurs que ce sont souvent des fautes d’orthographes, ce qui conforte ce choix. On peut
aller plus loin dans cette démarche en enlevant les termes qui n’apparaissent que
quelques fois dans le corpus. Nous avons retenu, dans notre expérience, les termes
apparaissant 3 fois ou plus ; cela peut toutefois diminuer la qualité de l’apprentissage“.

3.3.3 Stockage de l’information de structure du graphe

Chaque enregistrement indexé dans le moteur de recherche correspond a une catégorie
Wikipédia donnée. Il contient son titre ainsi que le vecteur des termes qui lui sont
associés directement (issus des articles de la catégorie) ou indirectement (via les sous-
catégories). L’enregistrement stocke aussi des éléments de structure du graphe :

9 Dans Lucene, la n-grammes sont appelés shingles (« bardeaux >> en frangajs : petites tuiles qui se recouvrent).

1° La terms composés les plus fréquents da.ns Wikipédia sont championnat du monde, jewc olympiques, premier
ministre ou guene mondiale en frangajs (United States, London borough, United Kingdom ou NHL league en anglajs)
11 Par exemple, la banque grecque Emporiki n'apparajssa.it que deux fois dans la Wikipédia frangajse avant

2008. Cela indujsajt de mauvajsa catégorisations sur da texts courts récents parlant de la crise ﬁnanciére.

663 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

— La liste des catégories meres et des sous-catégories au sein d’une langue donnée.
Cette information sera utilisée pour afﬁcher le résultat sous forme graphique et
aussi pour effectuer un ﬁltrage améliorant la pertinence de la catégorisation.

— Les liens de l’index inter-langues, correspondant aux << traductions » de la
catégorie vers les autres Wikipédia. Cette information servira a afﬁcher les
résultats d’une catégorisation d’une fagon cross-langue.

La complétude de l’index inter-langues est aléatoire ; elle varie énormément en fonction
des catégories”. Pour celles jugées importantes aux yeux des wikinautes, des liens sont
fournis vers un grand nombre de langues; en revanche, aucun lien n’existera parfois
pour une catégorie trop ﬁne ou d’intérét secondaire.

3.4 Catégorisation d’un document

3.4.1 Principe

Une fois l’index Lucene constitué, la catégorisation d’un document devient trivialement
simple, et revient a faire une recherche en utilisant le texte du document comme critere.
Plus précisément, le texte est analysé avec le méme processus qui a servi a l’indexation, y
compris l’extraction des termes composés. Le vecteur termes-fréquences obtenu est alors
utilisé par le moteur de recherche pour trouver les documents de l’index (correspondant
aux catégories Wikipédia) les plus proches du texte, avec une pondération TF-IDF13.

3.4.2 Exemple : catégorisation du présent article

Le résultat brut de la recherche est une liste a plat de catégories associées a un score de
pertinence. La ﬁgure 1 illustre le résultat de la catégorisation thématique obtenue a
partir du texte du présent article Nous obtenons: RECHERCHE D'lNFoRMATIoN=0,258;
MOTEUR DE RECHERCHE=0,203 ; MOT-VALIsE=0,198; INTELLIGENCE ARTIFICIELLE=0,186;

INFORMATIQUE THEORIQUE = 0,183 ; TRAITEMENT AUTOMATIQUE DU LANGAGE NATUREL = 0,173.

       
 

Sciences cognitives Sciences de |'inforrnation et des bibliotheques World Wide Web
Mot-valise / Informatique theoriclue Wikipédia Recherche d'information
Intelligence artiﬁcielle Algorithmique Theorie des graphes

Traitement automatique du langage naturel

FIGURE 1 — Catégorisation thématique obtenue sur le texte du présent article.

12 Notons que depujs mars 2013, la Wikipédia en frangajs centralise la liens inter-langues dans Wikidata, une
base de données structurée ljbre. Cela devrajt contribuer E1 élargir et ﬁabi]jser1'indexinter-langues.

13 TF-IDF (term frequency—inverse document frequency) est une méthode de pondération classique. Avec cette
mesure statistique, 1e poids d’un terme augmente proportionnellement E1 son nombre d'occurrenc$ dans le

texte E1 catégoriser. I1 varie également en fonction de la fréquence du terme da.ns1'index da catégories.

664 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Dans les ﬁgures présentées ici, ces scores se traduisent visuellement par une couleur de
fond d’autant plus sombre que la catégorie est pertinente ; pour les catégories reliées par
des arcs, les plus générales s’afﬁchent en haut et les plus spéciﬁques en bas. La structure
locale du graphe (arcs entrants et sortants) est également stockée avec chaque catégorie
(Cf. 3.3.3). Nous utilisons cette information pour reconstituer un graphe a partir de la
liste a plat produite par le moteur de recherche. Un lecteur humain aura ainsi une
visualisation plus riche qu’une simple liste. L’autre intérét est de tenir compte de la
géométrie locale du graphe de catégories pour établir une heuristique de ﬁltrage
supplémentaire. Si un sommet isolé ou de degré 1 présente aussi une pertinence trop
faible, il est supprimé“ ; ce ﬁltrage augmente la précision de la catégorisation.

Enﬁn, les liens de l’index inter-langues permettent de passer sans effort de la ﬁgure 1 (en
frangais) aux ﬁgures 2 (en anglais) et 3 (en allemand). On remarque que dans les deux
cas, on n’obtient qu’un sous-graphe de celui en francais. Les catégories MOT-VALISE et
ALGORITHMIQUE n’ont pas d’équivalent exact en anglais ; de meme, ALGORITHMIQUE
manque en allemand, ainsi que TRAITEMENT AUTOMATIQUE DU LANGAGE NATUREL.

    
 

Cognitive science Library and information science World Wide Web
 °T3lC3l Comp‘-"5? 5  Wikipedia Information retrieval

Artiﬁcial intelligence Graph theory

Natural language processing
FIGURE 2 — Catégorisation thématique obtenue en anglais sur le texte du présent article

Kognitionswissenschaft World Wide Web Bibliothekswesen

./l \_/

Theoretische lnformatik Kofferwort Wikipedia Information Retrieval

/\

Kiinstliche lntelligenz Graphentheorie

      
 

    

FIGURE 3 — Catégorisation thématique obtenue en allemand sur le texte du présent article.
4 Evaluation

Nous avons effectué une mesure préliminaire des résultats de notre algorithme pour
prédire les bonnes catégories sur les articles de la Wikipédia francaise eux-mémes, en

\

utilisant uniquement leur contenu. Nous avons procédé a une validation croisée en

14 Le seuil retenu ici at une pertinence inférieure 31 la moitié de celle de la catégorie la plus pertinente. Da.ns
notre exemple, DEVELOPPEMENT LOGICIEL apparajssajt initialement da.ns 1e graphe résultat, majs avec une
pertinence inférieure au seuil (0,125) et un seul arc (vers ALGORITHMIQUE) ; elle a done été enlevée.

665 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

divisant les articles de l’encyclopédie en 10 échantillons de méme taille. Nous effectuons
un apprentissage sur 9 d’entre eux, suivi d’un test sur le 10é“‘° échantillon ; ce test est
répété 10 fois en changeant a chaque fois l’échantillon de test. Chaque document testé
est explicitement annoté par k catégories << ofﬁcielles ». Le test lui-meme consiste a
prédire 10 catégories, puis a vériﬁer si on retrouve au moins l’une des catégories prédites
dans les catégories ofﬁcielles ; le résultat de chaque test élémentaire vaut donc 0 ou 1.
Avec cette approche, la moyenne sur les 10 échantillons est de 91%. Ce protocole reste
simpliste; nous comptons l’améliorer en nous inspirant de celui utilisé pour le LSHTC
challenge (Large Scale Hierarchical Text Classiﬁcation, http://lshtc.iit.demokritos.gr).

5 Bilan et travaux futurs

Nous avons présenté une approche opérationnelle pour classiﬁer du texte tout-venant
écrit dans l’une des langues pour lesquelles il existe une encyclopédie Wikipédia. Le
composant a été intégré a la plate-forme Antelope (Chaumartin, 2012) et utilisé avec un
succes dans des projets de catégorisation de sites Web et de ﬂux RSS en environnement
multilingues. Notre démarche présente des similitudes avec (Schonhofen, 2009); nos
contributions portent sur (i) l’amélioration de la qualité de l’indexation (processus
d’exploration récursive partant des feuilles et utilisation des n-grammes sur l’intégralité
du texte des articles) ; (ii) L’utilisation de la topologie du graphe résultat pour élaguer les
catégories peu pertinentes ; (iii) l’exploitation de l’index inter-langue pour présenter une
traduction (au moins partielle) du résultat dans les autres langues disposant aussi d’une
Wikipédia. Les résultats sont encourageants mais peuvent encore étre améliorés.

Remerciements

Je remercie les ingénieurs de Proxem pour leur soutien, notamment Fanny Parganin.
Références

CHAUMARTIN, F.-R. (2012). Antelope, une plate-_forme de TAL permettant d’extraire les sens

du texte : t}1éorie et applications de l’ISS. These de doctorat, Université Paris Diderot.

DASARI, D. B., RAO V. G. (2012). Text Categorization and Machine Learning Methods:
Current State of the Art. In GJCST, Vol. 12, N"11.

SCHONHOFEN, P. (2009). Identifying document topics using the Wikipedia category
network. In Web Intelligence and Agent Systems, Vol. 7, N"2, pages 195-207.

SEBASTIANI, F. (2002). Machine Learning in Automated Text Categorization. In ACM
Computing Surveys, Vol. 34, N"1, pages 1-47.

SUCHANEK F., KASNECI G., WEIKUM G. (2007). Yago: a core of semantic knowledge. In
WVVW2007, pp. 697-706.

TARJAN, R. E. (1972). Depth-ﬁrst search and linear graph algorithms. In SIAM Journal on
Computing, Vol. 1, N°2, p. 146-160.

YUN, J., JING, L., YU, J., HUANG, H., ZHANG, Y. (2011). Document Topic Extraction Based
on Wikipedia Category. Actes de Computational Sciences and Optimization (CSO).

666 © ATALA

