<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>SegCV : traitement efficace de CV avec analyse et correction d&#8217;erreurs</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>SegCV : traitement efficace de CV
avec analyse et correction d&#8217;erreurs
</p>
<p>Luis Adri&#225;n Cabrera-Diego1,4 Juan-Manuel Torres-Moreno1,2,3 Marc El-B&#232;ze1,3
(1) LIA, Universit&#233; d&#8217;Avignon et des Pays de Vaucluse, France
</p>
<p>(2) &#201;cole Polytechnique de Montr&#233;al, Canada
(3) SFR Agorantic UAPV, France
</p>
<p>(4) Flejay Group, France
adrian.cabrera@flejay.com ; {juan-manuel.torres, marc.elbeze}@univ-avignon.fr
</p>
<p>R&#201;SUM&#201;
Le march&#233; d&#8217;offres d&#8217;emploi et des candidatures sur Internet a connu, ces derniers temps, une
croissance exponentielle. Ceci implique des volumes d&#8217;information (majoritairement sous la
forme de textes libres) intraitables manuellement. Les CV sont dans des formats tr&#232;s divers :
.pdf, .doc, .dvi, .ps, etc., ce qui peut provoquer des erreurs lors de la conversion en texte plein.
Nous proposons SegCV, un syst&#232;me qui a pour but l&#8217;analyse automatique des CV des candidats.
Dans cet article, nous pr&#233;sentons des algorithmes reposant sur une analyse de surface, afin de
segmenter les CV de mani&#232;re pr&#233;cise. Nous avons &#233;valu&#233; la segmentation automatique selon
des corpus de r&#233;f&#233;rence que nous avons constitu&#233;s. Les exp&#233;riences pr&#233;liminaires r&#233;alis&#233;es sur
une grande collection de CV en fran&#231;ais avec correction du bruit montrent de bons r&#233;sultats en
pr&#233;cision, rappel et F-Score.
</p>
<p>ABSTRACT
SegCV : Eficient parsing of r&#233;sum&#233;s with analysis and correction of errors
</p>
<p>Over the last years, the online market of jobs and candidatures offers has reached an exponential
growth. This has implied great amounts of information (mainly in a text free style) which cannot
be processed manually. The r&#233;sum&#233;s are in several formats : .pdf, .doc, .dvi, .ps, etc., that can
provoque errors or noise during the conversion to plain text. We propose SegCV, a system that
has as goal the automatic parsing of candidates&#8217; r&#233;sum&#233;s. In this article we present the algoritms,
which are based over a surface analysis, to segment the r&#233;sum&#233;s in an accurate way. We evaluated
the automatic segmentation using a reference corpus that we have created. The preliminary
experiments, done over a large collection of r&#233;sum&#233;s in French with noise correction, show good
results in precision, recall and F-score.
</p>
<p>MOTS-CL&#201;S : RI, Ressources humaines, traitement de CV, Mod&#232;le &#224; base de r&#232;gles.
KEYWORDS: Information Retrieval, Human Resources, CV Parsing, Rules Model.
</p>
<p>1 Introduction
</p>
<p>L&#8217;acc&#232;s massif d&#8217;internet par les personnes, les institutions et les entreprises a chang&#233; radicalement
la fa&#231;on dont fonctionne le march&#233; de l&#8217;emploi. De nos jours, des milliers de candidats mettent
en ligne leur Curriculum Vit&#230; (CV), et les entreprises ou les institutions publient des profils de
postes recherch&#233;s. Analyser automatiquement cette quantit&#233; d&#8217;informations est une t&#226;che difficile
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>707 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#224; accomplir. Ceci est d&#251;, d&#8217;un c&#244;t&#233; &#224; la masse grandissante de CV re&#231;us par les d&#233;partements de
ressources humaines, et d&#8217;un autre &#224; l&#8217;&#233;norme diversit&#233; de la pr&#233;sentation des CV. En particulier,
dans certains sections (identit&#233;, formation, exp&#233;rience et comp&#233;tences) et leur organisation.
Si on ne peut pas parler vraiment de documents &#171; non-structur&#233;s &#187;, on peut les qualifier de
&#171; trop librement structur&#233;s &#187;, r&#233;pondant &#224; une structure conceptuelle propre &#224; chaque individu
et difficile &#224; mod&#233;liser. Nous nous situons dans la double perspective d&#8217;emplois acad&#233;miques et
commerciaux. L&#8217;employeur est ici une institution (universit&#233;, grande &#233;cole, centre de recherche)
ou une entreprise, et les candidats pr&#233;sentant des dossiers adapt&#233;s pour correspondre au mieux
aux profils recherch&#233;s. Donc, nous projetons de concevoir un syst&#232;me int&#233;gral d&#8217;analyse des
candidatures acad&#233;miques ou commerciales, dont la premi&#232;re &#233;tape consiste dans le d&#233;coupage
des CV des candidats.
</p>
<p>La probl&#233;matique qui aborde SegCV est plus g&#233;n&#233;rale que celle &#233;tudi&#233;e auparavant [6, 7, 3],
car ces travaux analysent seulement des CV commerciaux. SegCV est compos&#233; des modules
suivants : Extraction d&#8217;information &#224; partir des CV en formats PDF, Word, Open Office, PS, DVI
et RTF ; analyse des CV pour extraire les sections importantes. Cet article pr&#233;sente un syst&#232;me
de d&#233;coupage automatique des CV ainsi qu&#8217;une &#233;tude portant sur la correction d&#8217;erreurs lors
de la transformation en format texte. Nous pr&#233;sentons en section 2 la strat&#233;gie mise en &#339;uvre.
En Section 3, sont d&#233;crits les corpus utilis&#233;s. Nous pr&#233;sentons, en Section 4, la m&#233;thode pour
d&#233;tecter et corriger les erreurs avec deux mod&#232;les bas&#233;s sur des n-grammes. En section 6, sont
d&#233;taill&#233;s les diff&#233;rents r&#233;sultats obtenus avant de conclure.
</p>
<p>2 M&#233;thodologie
</p>
<p>Nous pr&#233;sentons la premi&#232;re &#233;tape d&#8217;un analyseur automatique d&#8217;offres et de demandes d&#8217;em-
ploi : un analyseur des CV bas&#233; sur le contexte. En fonction des sections d&#233;finies comme &#233;tant
importantes par le recruteur, le syst&#232;me extrait l&#8217;information pertinente du CV, puis g&#233;n&#232;re un
fichier avec le contexte et la granularit&#233; voulue. L&#8217;analyseur est essentiellement bas&#233; sur un
nombre restreint de r&#232;gles d&#233;pendantes de chaque langue. Il transforme l&#8217;information des CV
en blocs d&#8217;information selon des mod&#232;les d&#233;finis par l&#8217;utilisateur, faciles &#224; comprendre par les
humains et exploitables par les machines.
</p>
<p>Les CV originaux sont d&#233;clin&#233;s en formats divers : .doc, .odt, .pdf, .ps, .txt, etc. Afin de pouvoir les
traiter convenablement, les CV sont transform&#233;s en texte utf-8. Cependant, cette transformation
n&#8217;est pas libre d&#8217;erreurs, surtout dans les fichiers issus de PDF. Nous consid&#233;rons le bruit comme
la diff&#233;rence entre la forme superficielle d&#8217;une repr&#233;sentation textuelle et le texte pr&#233;vu, correct
ou originel [8]. Si la source est PostScript ou PDF du LATEX, le texte extrait peut comporter un
certain nombre d&#8217;erreurs. Les caract&#232;res accentu&#233;s, la police utilis&#233;e et les petites majuscules sont
des sources d&#8217;erreurs r&#233;currentes et difficiles &#224; mod&#233;liser. Or, les fichiers g&#233;n&#233;r&#233;s par LATEX risquent
d&#8217;&#234;tre tr&#232;s fr&#233;quents dans les CV issus du milieu acad&#233;mique. Cette &#233;tape du pr&#233;-traitement est
souvent n&#233;glig&#233;e alors qu&#8217;elle a un fort impact dans des &#233;tapes ult&#233;rieures. En effet, le d&#233;coupage
des CV (t&#226;che d&#233;j&#224; difficile du fait de la variabilit&#233; &#233;voqu&#233;e) peut &#234;tre un vrai casse-t&#234;te si l&#8217;on
tient compte du bruit introduit par les convertisseurs PDF &#224; texte.
</p>
<p>3 Corpus
</p>
<p>Nous avons constitu&#233; un corpus de 100 CV en fran&#231;ais issus du domaine commercial. Ce corpus
a &#233;t&#233; d&#233;coup&#233; &#224; la main par 2 annotateurs. Les annotateurs ont re&#231;u des consignes strictes quant
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>708 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>au d&#233;coupage des sections, selon un manuel fourni :
&#8211; Identit&#233; (coordonn&#233;es du candidat) ; R&#233;sum&#233; ; Poste demand&#233; (information qui d&#233;crit le poste
demand&#233;) ; Situation actuelle du candidat ; Autres (loisirs, les r&#233;f&#233;rences, etc.).
</p>
<p>&#8211; Formation (formation universitaire) ; formation additionnelle (dipl&#244;mes ou certifications).
&#8211; Exp&#233;rience (exp&#233;rience professionnelle).
&#8211; Comp&#233;tences (comp&#233;tences ou aptitudes personnelles, les langues &#233;trang&#232;res, les outils
ma&#238;tris&#233;s, etc).
</p>
<p>Nous appelons ce corpus &#233;talon CD. Pour les tests de d&#233;coupage, nous avons constitu&#233; le corpus
CN, compos&#233; des m&#234;mes 100 CV, mais sans le d&#233;coupage manuel.
</p>
<p>Pour &#233;tudier le bruit, nous disposons d&#8217;un corpus de 750 CV commerciaux, provenant de fichiers
.doc, .odt et .rtf, pour lesquels la conversion, en th&#233;orie, n&#8217;a g&#233;n&#233;r&#233; aucune erreur 1. Ce corpus
sera nomm&#233; CVcomm. En ce qui concerne les CV acad&#233;miques, la question est plus d&#233;licate :
La plupart de CV sont bruit&#233;s, et les d&#233;-bruiter manuellement serait une t&#226;che p&#233;nible et pas
exempte d&#8217;erreurs. Cependant, nous avons d&#233;tect&#233; 8 CV sans bruit, qui seront utilis&#233;s lors de
tests. Ce corpus sera nomm&#233; CVac.
</p>
<p>4 D&#233;tection et correction du bruit
</p>
<p>La transformation des CV en texte peut g&#233;n&#233;rer plusieurs erreurs : l&#8217;introduction de caract&#232;res
compos&#233;s, de caract&#232;res superpos&#233;s, la s&#233;paration des caract&#232;res ou l&#8217;ajout des espaces entre
caract&#232;res. En g&#233;n&#233;ral, tous les cas, &#224; exception du dernier, peuvent &#234;tre corrig&#233;s en utilisant
des expressions r&#233;guli&#232;res car ces erreurs suivent des patrons r&#233;guliers. Cependant le probl&#232;me
d&#8217;ajout d&#8217;espaces entre les caract&#232;res semble &#234;tre de nature al&#233;atoire. Parfois, ce type d&#8217;erreur est
occasionn&#233; par l&#8217;utilisation de caract&#232;res accentu&#233;s, de majuscules ou par l&#8217;utilisation d&#8217;un format
particulier des documents. Les blancs peuvent &#234;tre pr&#233;sents plusieurs fois dans le m&#234;me mot
ou dans la m&#234;me ligne. Ces espaces plac&#233;s au milieu de mots peuvent emp&#234;cher le d&#233;coupage
correct des sections.
</p>
<p>Pour bien mener nos tests, &#224; partir du corpus CVcomm, nous construisons &#224; tour de r&#244;le 5
sous-corpus qui seront utilis&#233;s comme suit : 4/5 sous-corpus seront employ&#233;s pour le calcul des
n-grammes et 1/5 pour la phase de tests. Il faut dire que la g&#233;n&#233;ration des n-grammes est enrichie
d&#8217;un ensemble T de textes sans bruit : romans, livres scientifiques et discours compos&#233; de 784k
mots. Pour les tests, nous avons bruit&#233; le 1/5 du corpus avec des espaces en blanc introduits
de fa&#231;on al&#233;atoire. Afin d&#8217;injecter chaque espace, nous avons g&#233;n&#233;r&#233; 3 num&#233;ros al&#233;atoires :
le premier fixe la ligne du fichier &#224; bruiter, le deuxi&#232;me le mot et le troisi&#232;me la position &#224;
l&#8217;int&#233;rieur du mot (en &#233;vitant les extr&#234;mes). Le bruit inject&#233; est donc &#224; pourcentage variable 2.
Nous appellerons ces corpus CB(i=0,5,10,15,...,100). Pour les CV acad&#233;miques, nous utiliserons le
corpus CVac comme r&#233;f&#233;rence afin de tester le correcteur. Ainsi nous avons ajout&#233; du bruit &#224;
l&#8217;ensemble CVac suivant la m&#234;me proc&#233;dure qu&#8217;auparavant. Les correcteurs utilisent tous les n-
grammes g&#233;n&#233;r&#233;s avec les CV commerciaux plus les documents de l&#8217;ensemble T afin de debruiter
les CV de CVac.
</p>
<p>La correction d&#8217;erreurs est une t&#226;che g&#233;n&#233;ralement abord&#233;e dans la reconnaissance optique de
caract&#232;res (OCR) ou dans le traitement d&#8217;information informelle, comme les blogs, les forums, les
SMS ou les tchats. Les travaux concernant la correction de bruit [2, 9, 1, 4] traitent la correction
</p>
<p>1. Gr&#226;ce &#224; la codification homog&#232;ne des &#233;diteurs (Word, Libre/OpenOffice)
2. Nous consid&#233;rons un mot comme l&#8217;ensemble de caract&#232;res entre deux espaces
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>709 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>de fautes d&#8217;orthographe et grammaticales, la mauvais ponctuation ou l&#8217;utilisation d&#8217;abr&#233;viations.
Mais le probl&#232;me sp&#233;cifique des blancs a &#233;t&#233; peu trait&#233; &#224; notre connaissance. Pour r&#233;soudre ce
probl&#232;me, nous proposons deux strat&#233;gies &#224; base de n-grammes de caract&#232;res : un correcteur
binaire et un autre probabiliste.
</p>
<p>4.1 Correcteur binaire
</p>
<p>L&#8217;algorithme utilise des n-grammes de caract&#232;res avec n = 4, .., 7. Ces n-grammes ont comme
caract&#233;ristique principale la pr&#233;sence, d&#8217;au moins, un espace entre deux caract&#232;res ([a-zA-Z],
caract&#232;res accentu&#233;s ou l&#8217;apostrophe). Pour chaque ligne avec au moins un espace, on g&#233;n&#232;re
le n-gramme le plus grand possible avec un espace en son centre. Le n-gramme original et ses
voisins &#224; gauche et &#224; droite du centre, sont recherch&#233;s.
</p>
<p>Le n-gramme p&#232;re est consid&#233;r&#233; comme correct (l&#8217;espace central doit &#234;tre conserv&#233;), si lui ou
ses fils, remplissent au moins une des conditions suivantes : i/ le 7-gramme existe ; ii/ deux
6-grammes existent ; iii/ au moins deux 5-grammes existent ; iv/ Deux 4-grammes existent (zone
encadr&#233;e en pontill&#233; de la figure 1). Ces conditions se basent sur l&#8217;id&#233;e qu&#8217;un n-gramme p&#232;re avec
un espace central engendre deux 6-grammes, trois 5-grammes et deux 4-grammes. Si la majorit&#233;
de ses fils existent, il est probable que le n-gramme p&#232;re soit correct. Si le p&#232;re est consid&#233;r&#233;
comme incorrect, il faut analyser la classe &#224; laquelle il appartient. Les cas et les corrections
d&#233;pendent du nombre d&#8217;espaces apr&#232;s ou avant l&#8217;espace central, du nombre de caract&#232;res &#224; droite
et &#224; gauche ou si le n-gramme est au d&#233;but ou &#224; la fin d&#8217;une ligne. Les corrections sont des r&#232;gles
permettant l&#8217;&#233;limination de blancs g&#234;nants. L&#8217;algorithme de correction peut &#234;tre ex&#233;cut&#233; it&#233;ratif
afin de corriger des erreurs non trouv&#233;es lors des corrections pr&#233;c&#233;dentes.
</p>
<p>! !
</p>
<p>! &quot; # $ % &quot; # $ % &amp;
</p>
<p>! &quot; # $ &quot; # $ % # $ % &amp;
</p>
<p># $ %&quot; # $
</p>
<p>! &quot; # $ % &amp;!&quot;#$%&amp;&amp;'(
</p>
<p>)&quot;#$%&amp;&amp;'(
</p>
<p>*&quot;#$%&amp;&amp;'(
</p>
<p>+&quot;#$%&amp;&amp;'(
</p>
<p>! &quot; # $ % &amp; &quot;'
</p>
<p>! &quot; # $ % &amp;' ! &quot; # $ % &amp; &quot;
</p>
<p>! &quot; # $ %' ! &quot; # $ % &amp;
</p>
<p>' ! &quot; # ( $ # ( $ % &amp; &quot;
</p>
<p>,&quot;#$%&amp;&amp;'(
</p>
<p>-&quot;#$%&amp;&amp;'(
</p>
<p>FIGURE 1: Exemple de n-grammes pour les correcteurs.
</p>
<p>4.2 Correcteur probabiliste
</p>
<p>Afin d&#8217;obtenir des performances plus robustes et de meilleurs r&#233;sultats, nous avons d&#233;velopp&#233;
un correcteur probabiliste. Le principe &#233;tant proche de celui binaire, sauf que le parcours
des branches sera conditionn&#233; par la probabilit&#233; des n-grammes. L&#8217;algorithme construit le n-
gramme le plus grand possible (n = 4, ..., 9) ayant un espace central entre deux caract&#232;res.
Nous &#233;num&#233;rons toutes les combinaisons de n-grammes en &#233;liminant ou en maintenant les
espaces qu&#8217;ils contenant. Des caract&#232;res &#224; droite peuvent &#234;tre ajout&#233;s pour maintenir la taille et
le contexte du n-gramme le plus grand possible. Puis on calcule les probabilit&#233;s conditionnelles
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>710 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>de chaque combinaison en utilisant l&#8217;estimation du maximum de vraisemblance :
</p>
<p>P
&#65535;
ci |ni&#8722;1&#65535; = C &#65535;ni&#8722;1ci&#65535;C &#65535;ni&#8722;1&#65535; = C
</p>
<p>&#65535;
ni
&#65535;
</p>
<p>C
&#65535;
ni&#8722;1
</p>
<p>&#65535; (1)
o&#249; ci est le dernier caract&#232;re du n-gramme de taille i, C
</p>
<p>&#65535;
ni
&#65535;
et C
</p>
<p>&#65535;
ni&#8722;1
</p>
<p>&#65535;
sont leurs fr&#233;quences.
</p>
<p>Si la probabilit&#233; de toutes les combinaisons du n-gramme sont nulles, la taille du n-gramme
est diminu&#233;e en 1 caract&#232;re (figure 1) et le processus it&#232;re &#224; nouveau. Autrement on consid&#232;re
comme une correction acceptable la combinaison ayant la probabilit&#233; conditionnelle la plus
grande.
</p>
<p>5 D&#233;coupage en sections
</p>
<p>La t&#226;che principale de SegCV consiste &#224; rep&#233;rer, d&#233;couper et regrouper les sections pertinentes
des CV. &#192; cette fin, on peut &#234;tre tent&#233; d&#8217;utiliser des m&#233;thodes d&#8217;apprentissage automatique, car
on sait qu&#8217;elles donnent de tr&#232;s bons r&#233;sultats sur les t&#226;ches de TALN. Mais l&#8217;apprentissage
automatique n&#233;cessite une grande quantit&#233; de documents pr&#233;alablement &#233;tiquet&#233;s. Or, nous
ne disposons pas d&#8217;un grand corpus annot&#233; manuellement. En cons&#233;quence, nous avons deux
possibilit&#233;s pour faire face &#224; ce probl&#232;me. La premi&#232;re consiste &#224; faire un d&#233;coupage &#224; de tailles
fixes (1/3, 2/3, etc.), comme propos&#233; par [5], mais cette approche nous semble trop grossi&#232;re.
L&#8217;autre possibilit&#233; consiste &#224; &#233;tablir des r&#232;gles de d&#233;coupage. Notre objectif &#233;tant de d&#233;couper les
CV de la mani&#232;re la plus fine possible, nous avons d&#233;cid&#233; d&#8217;utiliser des r&#232;gles.
</p>
<p>&#192; cette fin, nous avons suivi deux approches. La premi&#232;re est bas&#233;e sur la structure du CV : les
titres, les sous-titres ou les d&#233;buts des lignes avec un symbole d&#233;limitant une section. 94 expres-
sions r&#233;guli&#232;res composent ces r&#232;gles. La deuxi&#232;me approche essaie d&#8217;am&#233;liorer le d&#233;coupage au
moyen de mots-cl&#233;s qui seront recherch&#233;s &#224; l&#8217;int&#233;rieur des sections. Le d&#233;coupage fait appel &#224; un
pr&#233;traitement (&#233;limination ou normalisation de symboles et la normalisation d&#8217;espaces), puis,
les r&#232;gles de structure sont appliqu&#233;es. Apr&#232;s ce premier d&#233;coupage, nous v&#233;rifions la taille des
sections trouv&#233;es. Si elle est anormalment grande (ou petite) par rapport &#224; la taille du CV nous
faisons appel aux mots-cl&#233;s pour d&#233;clancher une proc&#233;dure de d&#233;placement de l&#8217;information. Par
exemple, si un fragment de texte dans la section &#171; Comp&#233;tences &#187; contient les mots c&#233;libataire
ou situation de famille ce fragment sera d&#233;plac&#233; &#224; la section &#171; Identit&#233; &#187;.
</p>
<p>6 R&#233;sultats
</p>
<p>Nous avons effectu&#233; trois exp&#233;riences pour &#233;valuer le d&#233;coupage automatique et la correction du
bruit. Nous avons d&#233;cid&#233; d&#8217;utiliser des mesures de similarit&#233; et non pas des mesures bas&#233;es sur les
fronti&#232;res du d&#233;coupage car l&#8217;information dans les sections peut &#234;tre &#233;parpill&#233;e. Puisque les CV
sont des fichiers trop librement structur&#233;s, les limites exactes des sections sont difficiles &#224; rep&#233;rer.
Si l&#8217;on ajoute du bruit, ces fronti&#232;res sont souvent perdues. Essayer de trouver les fronti&#232;res
exactes est alors un exercice tr&#232;s d&#233;licat et impr&#233;cis. Nous avons d&#233;cid&#233; donc de mesurer la
pertinence du d&#233;coupage par le contenu des sections, plut&#244;t que par les fronti&#232;res. A ce fin, nous
avons utilis&#233; deux mesures de similarit&#233; entre le d&#233;coupage manuel et celui automatique : la
similarit&#233; cosinus et une mesure de divergence de Kullback-Leiber modifi&#233;e (issue du domaine du
r&#233;sum&#233; automatique). Une section sera consid&#233;r&#233;e comme correctement d&#233;coup&#233;e si sa similarit&#233;
d&#233;passe un certain seuil. Le seuil peut &#234;tre strict (similarit&#233;=1) ou relax&#233; (0,95 &lt; similarit&#233;
&lt; 0,5). Ensuite nous avons calcul&#233; la pr&#233;cision, le rappel et le F-score.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>711 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Pour &#233;valuer la correction du bruit, nous avons compar&#233; le nombre de mots corrects dans le
fichier corrig&#233; par rapport au nombre de mots dans le fichier d&#8217;origine. Formellement, la pr&#233;cision
et le rappel ont &#233;t&#233; d&#233;finis de fa&#231;on classique comme suit :
</p>
<p>Pr&#233;cision=
CC
TC
</p>
<p>Rappel=
CC
TO
</p>
<p>(2)
</p>
<p>o&#249;, CC est le nombre de mots corrects dans le fichier corrig&#233;, TC le nombre de mots dans le fichier
corrig&#233; et TO le nombre de mots dans le fichier d&#8217;origine.
</p>
<p>D&#233;coupage automatique. La premi&#232;re exp&#233;rience a consist&#233; &#224; d&#233;couper automatiquement les
fichiers du corpus CN. La figure 2 montre le F-score pour les deux mesures de similarit&#233;.
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>&quot;#$$ $#%&amp; $#%$ $#'&amp; $#'$ $#(&amp; $#($ $#)&amp; $#)$ $#&amp;&amp; $#&amp;$
$#$
</p>
<p>$#&quot;
</p>
<p>$#*
</p>
<p>$#+
</p>
<p>$#,
</p>
<p>$#&amp;
</p>
<p>$#)
</p>
<p>$#(
</p>
<p>$#'
</p>
<p>$#%
</p>
<p>&quot;#$
</p>
<p>!
</p>
<p>!
</p>
<p>!&quot;
#$
</p>
<p>%&amp;
'
</p>
<p>(')*+,-',&amp;'+./.0*%1
</p>
<p>!-./012/
!34
</p>
<p>FIGURE 2: D&#233;coupage de CV : F-score
</p>
<p>Le syst&#232;me ne d&#233;coupe pas les sections avec une grande pr&#233;cision. Les raisons de ce probl&#232;me sont
vari&#233;es. D&#8217;abord, les annotateurs ont &#233;vit&#233; les informations inutiles (num&#233;ros de page, en-t&#234;tes
ou les pieds de page), ce qui le syst&#232;me ne fait pas encore. Ensuite, la perte de la structure du CV
(comme les tables ou les colonnes) produit une m&#233;lange erron&#233;e de l&#8217;information. Et finalement,
les r&#232;gles de mots-cl&#233;s peuvent d&#233;placer incorrectement l&#8217;information d&#8217;une section.
</p>
<p>Correction du bruit. Nous avons simul&#233; le bruit par ajout al&#233;atoire de blancs au milieu des mots.
La quantit&#233; d&#8217;espaces a &#233;t&#233; d&#233;termin&#233;e par la taille du fichier d&#8217;origine et par un pourcentage
variable (0%,5%,10%...100%). Les correcteurs binaire et probabiliste ont &#233;t&#233; appliqu&#233;s it&#233;ratif
trois fois. Au del&#224; de la troisi&#232;me application, les r&#233;sultats n&#8217;ont gu&#232;re chang&#233;. Pour l&#8217;&#233;valuation
des corpus bruit&#233;s CBi , nous nous sommes servis des corpus de r&#233;f&#233;rence. La figure 3 montre
le F-score pour cette exp&#233;rience mesur&#233; sur des CV commerciaux &#224; gauche et acad&#233;miques &#224;
droite. Les r&#233;sultats montrent que le correcteur binaire fonctionne assez mal, m&#234;me pour des
quantit&#233;s minimales de bruit. A 50% de bruit, le correcteur probabiliste obtient un F-score
de 0,82 (CV commerciaux) et de 0,75 (CV acad&#233;miques). Pour un taux de bruit de 100% le
correcteur probabiliste obtient un F-score de 0,80 (commerciaux) et de 0,71 (acad&#233;miques). Il
faut dire que la quantit&#233; de bruit dans les cas r&#233;els n&#8217;est pas si &#233;lev&#233;e, mais nous voulions tester
nos correcteurs dans les cas extr&#234;mes.
</p>
<p>D&#233;coupage automatique plus correction de bruit La derni&#232;re exp&#233;rience a consist&#233; &#224; seg-
menter automatiquement le corpus CD. Mais cette fois, nous y avons ajout&#233; du bruit de mani&#232;re
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>712 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>&quot; #&quot; $&quot; %&quot; &amp;&quot; '&quot; (&quot; )&quot; *&quot; +&quot; #&quot;&quot;
&quot;,&quot;
</p>
<p>&quot;,#
</p>
<p>&quot;,$
</p>
<p>&quot;,%
</p>
<p>&quot;,&amp;
</p>
<p>&quot;,'
</p>
<p>&quot;,(
</p>
<p>&quot;,)
</p>
<p>&quot;,*
</p>
<p>&quot;,+
</p>
<p>#,&quot;
!
</p>
<p>!&quot;
#$
</p>
<p>%&amp;
'
</p>
<p>(&amp;)*+,-./
</p>
<p>!-./010232456
!72812.6
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>&quot; #&quot; $&quot; %&quot; &amp;&quot; '&quot; (&quot; )&quot; *&quot; +&quot; #&quot;&quot;
&quot;,&quot;
</p>
<p>&quot;,#
</p>
<p>&quot;,$
</p>
<p>&quot;,%
</p>
<p>&quot;,&amp;
</p>
<p>&quot;,'
</p>
<p>&quot;,(
</p>
<p>&quot;,)
</p>
<p>&quot;,*
</p>
<p>&quot;,+
</p>
<p>#,&quot;
</p>
<p>!
</p>
<p>!
</p>
<p>!&quot;
#$
</p>
<p>%&amp;
'
</p>
<p>(&amp;)*+,-./
</p>
<p>!-./010232456
!72812.6
</p>
<p>FIGURE 3: Correction de l&#8217;injection de bruit : &#224; gauche CV commerciaux, &#224; droite CV acad&#233;miques
</p>
<p>al&#233;atoire (de la m&#234;me fa&#231;on que pour le CB), en utilisant le correcteur probabiliste, appliqu&#233; 3
fois, pour le diminuer. Nous avons &#233;valu&#233; la qualit&#233; du d&#233;coupage avec la mesure de cosinus.
La figure 4 montre la surface de F-score en fonction du pourcentage du bruit et du seuil de
relaxation. Les r&#233;sultats obtenus indiquent que l&#8217;utilisation du correcteur impacte la qualit&#233;
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !
</p>
<p>&quot;#$%
&quot;#&amp;'
</p>
<p>&quot;#()&quot;#*+
&quot;#+*
</p>
<p>&quot;#+%
&quot;#)(
</p>
<p>&quot;#)'
</p>
<p>&quot;#'&amp;
</p>
<p>&quot;#')
</p>
<p>&quot;#',&quot;#%$
</p>
<p>&quot;#&quot;,&quot;
</p>
<p>&quot; &amp;&quot; *&quot; )&quot; %&quot; $&quot;&quot;
$#&quot;
</p>
<p>&quot;#,
</p>
<p>&quot;#%
</p>
<p>&quot;#'
</p>
<p>&quot;#)
</p>
<p>&quot;#+
!
</p>
<p>!
</p>
<p>!&quot;
#$
</p>
<p>%&amp;'
&quot;&amp;
</p>
<p>(&quot;
%)
</p>
<p>*)
+$,
</p>
<p>-
</p>
<p>.(#$+&amp;/01
</p>
<p>FIGURE 4: D&#233;coupage automatique avec correction de bruit : F-score
</p>
<p>de d&#233;coupage. Pour un pourcentage de z&#233;ro bruit ajout&#233; et un seuil de relaxation &#233;gal &#224; 1,00,
c&#8217;est-&#224;-dire une similarit&#233; exacte, le d&#233;coupage automatique avec correction probabiliste obtient
un F-score=0,13, contre un F-score=0,37 du d&#233;coupage sans correctif. Nonobstant, pour un
niveau de bruit nul et un seuil de relaxation &#233;gal &#224; 0,50, le F-score pour le premier est de 0,84 et
de 0,79 sans correctif. Pour un niveau de bruit &#233;gal &#224; 50% et un seuil de relaxation de 50%, le
d&#233;coupage automatique avec correction obtient un F-score de 0,796.
</p>
<p>7 Conclusions et perspectives
</p>
<p>L&#8217;analyse automatique de CV est une t&#226;che extr&#234;mement difficile. Ceci s&#8217;explique par plusieurs
raisons, dont la principale est la structure des CV : malgr&#233; une structure conventionnelle,
l&#8217;information pr&#233;sente dans les CV est en format libre. En outre, ils sont produits en plusieurs
formats &#233;lectroniques. Leur transformation peut occasionner des erreurs ou perte d&#8217;information.
Le vocabulaire utilis&#233; peut varier &#233;norm&#233;ment au niveau des CV ou des profils. Dans ce travail,
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>713 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>nous avons pr&#233;sent&#233; la premi&#232;re &#233;tape d&#8217;un syst&#232;me d&#8217;analyse automatique des CV. Nous avons
pr&#233;sent&#233; un module pour d&#233;couper des CV en fran&#231;ais et un module pour corriger les erreurs
g&#233;n&#233;r&#233;es &#224; cause de la transformation du fichier d&#8217;origine. Les exp&#233;riences r&#233;alis&#233;es montrent que
le d&#233;coupage automatique doit &#234;tre am&#233;lior&#233; pour se rapprocher plus du d&#233;coupage manuel. Par
contre, la correction de bruit a montr&#233; de tr&#232;s bons r&#233;sultats. Nous avons v&#233;rifi&#233; que la m&#233;thode
probabiliste corrective donne les meilleurs r&#233;sultats. Cependant, il faut &#233;viter la correction de
fichiers non bruit&#233;s, car, en effet, il semble que la correction de faux positifs g&#233;n&#232;re une diminution
de la qualit&#233; du d&#233;coupage. &#192; l&#8217;avenir, nous voulons augmenter la qualit&#233; de nos modules et les
appliquer dans de corpus acad&#233;miques de taille plus cons&#233;quente. Pour le d&#233;coupage automatique,
nous pensons ajouter un module de nettoyage afin d&#8217;&#233;liminer les num&#233;ros de pages, les en-t&#234;tes
et les pieds de page. De la m&#234;me fa&#231;on, il sera int&#233;ressant d&#8217;effectuer des exp&#233;riences avec des
CV dans des langues autres que le fran&#231;ais.
</p>
<p>Remerciements
</p>
<p>Ce travail a &#233;t&#233; financ&#233; par la convention ANRT-CIFRE n&#9702; 2012/0293 entre Flejay et l&#8217;UAPV.
</p>
<p>R&#233;f&#233;rences
</p>
<p>[1] Sumeet Agarwal, Shantanu Godbole, Diwakar Punjani, and Shourya Roy. How much noise
is too much : A study in automatic text classification. In Data Mining, 2007. ICDM 2007.
Seventh IEEE International Conference on, pages 3&#8211;12. IEEE, 2007.
</p>
<p>[2] Alexander Clark. Pre-processing very noisy text. In Proc. of Workshop on Shallow Processing
of Large Corpora, pages 12&#8211;22, 2003.
</p>
<p>[3] J&#233;r&#233;my Clech and Djamel A. Zighed. Data mining et analyse des cv : une exp&#233;rience et des
perspectives. In Extraction et la Gestion des Connaissances, EGC&#8217;03, pages 189&#8211;200, 2003.
</p>
<p>[4] Lipika Dey and SK Mirajul Haque. Opinion mining from noisy text data. International
Journal on Document Analysis and Recognition (IJDAR), 12(3) :205&#8211;226, 2009.
</p>
<p>[5] R&#233;my Kessler, Nicolas B&#233;chet, Mathieu Roche, Marc El-B&#232;ze, and Juan-Manuel Torres-Moreno.
Automatic profiling system for ranking candidates answers in human resources. In OTM &#8217;08
Monterrey, Mexico, pages 625&#8211;634, 2008.
</p>
<p>[6] R&#233;my Kessler, Juan-Manuel Torres-Moreno, and Marc El-B&#232;ze. E-Gen : Automatic Job Offer
Processing system for Human Ressources. In MICAI, pages 985&#8211;995, 2007.
</p>
<p>[7] R&#233;my Kessler, Juan-Manuel Torres-Moreno, and Marc El-B&#232;ze. E-Gen : Profilage automatique
de candidatures. In TALN&#8217;08 Avignon, 2008.
</p>
<p>[8] Craig Knoblock, Daniel Lopresti, Shourya Roy, and L.Venkata Subramaniam. Special issue
on noisy text analytics. IJDAR, 10(3-4) :127&#8211;128, 2007.
</p>
<p>[9] Beno&#238;t Sagot, Pierre Boullier, et al. Sxpipe 2 : architecture pour le traitement pr&#233;-syntaxique
de corpus bruts. Traitement Automatique des Langues, 49(2) :155&#8211;188, 2008.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>714 c&#65535; ATALA</p>

</div></div>
</body></html>