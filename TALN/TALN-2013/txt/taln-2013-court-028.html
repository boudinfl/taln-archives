<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Un corpus d&#8217;erreurs de traduction</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Un corpus d&#8217;erreurs de traduction
</p>
<p>Guillaume Wisniewski1,2 Anil Kumar Singh2 Natalia Segal3 Fran&#231;ois
Yvon1,2
</p>
<p>(1) Universit&#233; Paris Sud 91 403 ORSAY CEDEX
(2) LIMSI&#8211;CNRS 91403 ORSAY CEDEX
</p>
<p>(3) Reverso&#8211;Softissimo, 5 rue Soyer, 92 500 NEUILLY
</p>
<p>{wisniews,anil,yvon}@limsi.fr,nsegal@softissimo.com
</p>
<p>R&#201;SUM&#201;
Avec le d&#233;veloppement de la post-&#233;dition, de plus en plus de corpus contenant des corrections de
traductions sont disponibles. Ce travail pr&#233;sente un corpus de corrections d&#8217;erreurs de traduction
collect&#233; dans le cadre du projet ANR/TRACE et illustre les diff&#233;rents types d&#8217;analyses auxquels
il peut servir. Nous nous int&#233;resserons notamment &#224; la d&#233;tection des erreurs fr&#233;quentes et &#224;
l&#8217;analyse de la variabilit&#233; des post-&#233;ditions.
</p>
<p>ABSTRACT
A corpus of post-edited translations
</p>
<p>More and more datasets of post-edited translations are being collected. These corpora have many
applications, such as failure analysis of SMT systems and the development of quality estimation
systems for SMT. This work presents a large corpus of post-edited translations that has been
gathered during the ANR/TRACE project. Applications to the detection of frequent errors and to
the analysis of the inter-rater agreement of hTER are also reported.
</p>
<p>MOTS-CL&#201;S : Traduction automatique,Analyse d&#8217;erreur,Post-&#233;diition.
KEYWORDS: Machine Translation, Failure Analysis,Post-edition.
</p>
<p>1 Introduction
</p>
<p>La post-&#233;dition consiste &#224; corriger les sorties d&#8217;un syst&#232;me de traduction automatique (TA) afin
de produire une traduction de qualit&#233;. Cette pratique se d&#233;veloppe de plus en plus, aussi bien
dans le cadre de traduction professionnelle (Garcia, 2011), que pour l&#8217;&#233;valuation des syst&#232;mes
de TA : quantifier le nombre d&#8217;&#233;ditions n&#233;cessaires pour la post-&#233;dition, comme le fait le score
hTER (Snover et al., 2006), fournit une indication pertinente de la qualit&#233; d&#8217;un syst&#232;me de TA.
</p>
<p>Le d&#233;veloppement de la post-&#233;dition suscite le d&#233;veloppent et la diffusion de corpus contenant
des corrections de traductions (Potet et al., 2012; Callison-Burch et al., 2012). Le travail pr&#233;sent&#233;
dans cet article s&#8217;inscrit dans cette lign&#233;e et d&#233;crit la constitution et l&#8217;exploitation d&#8217;un nouveau
corpus de corrections de traductions collect&#233; dans le cadre du projet ANR-TRACE 1. Le recueil de
ce corpus permet de r&#233;pondre &#224; un des principaux objectifs de TRACE, &#224; savoir le d&#233;veloppement
de mesures de confiance pour la TA (Zhuang et al., 2012) et la d&#233;tection de zones difficiles &#224;
</p>
<p>1. anr-trace.limsi.fr
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>723 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>traduire. D&#8217;autres usages sont &#233;galement envisageables : il peut, par exemple, &#234;tre utilis&#233; pour
identifier les limites des syst&#232;mes de traduction, ou encore pour &#233;tudier la coh&#233;rence des scores
hTER et, de mani&#232;re plus qualitative, la variabilit&#233; des post-&#233;ditions.
</p>
<p>C&#8217;est sur ces derniers points que porte le travail pr&#233;sent&#233; dans cet article : apr&#232;s avoir d&#233;taill&#233; les
caract&#233;ristiques du corpus et la mani&#232;re dont les donn&#233;es ont &#233;t&#233; collect&#233;es (Section 2), nous
discutons &#224; la Section 3 de deux mani&#232;res de mettre en &#233;vidence certaines limites des syst&#232;mes
de TA. Nous pr&#233;sentons finalement, &#224; la Section 4, une premi&#232;re analyse de la variabilit&#233; des
post-&#233;ditions.
</p>
<p>2 Description du corpus
</p>
<p>Le corpus TRACE de corrections de traductions comprend 6693 phrases (soit 109689 mots)
pour la direction fran&#231;ais-anglais ; et 5929 phrases (soit 120378 mots) pour la direction anglais-
fran&#231;ais. Ces phrases ont &#233;t&#233; traduites par deux syst&#232;mes de TA : un syst&#232;me commercial &#224; base de
r&#232;gles, SYSRULE, et un syst&#232;me statistique, NCode (Crego et al., 2011; Le et al., 2012), d&#233;sign&#233; par
SYSSTAT dans la suite du texte. Pour chaque direction de traduction, un traducteur professionnel
confirm&#233; 2 a ensuite corrig&#233; une des deux traductions automatiques (choisie al&#233;atoirement) pour
produire la r&#233;f&#233;rence post-&#233;dit&#233;e. Conform&#233;ment &#224; l&#8217;usage, les traducteurs traduisaient vers leur
langue maternelle. Le corpus TRACE contient, en outre, pour chaque direction de traduction,
1000 phrases qui ont &#233;t&#233; corrig&#233;es par deux traducteurs diff&#233;rents. Ces corpus sont librement
t&#233;l&#233;chargeables sur le site du projet TRACE. 3
</p>
<p>Ces donn&#233;es proviennent, pour moiti&#233;, de demandes de traduction d&#8217;utilisateurs &#171; grand public &#187;
collect&#233;es sur le portail de traduction en ligne de Softissimo (3 434 phrases en fran&#231;ais et 2 541
en anglais) ; l&#8217;autre moiti&#233; est issue d&#8217;extrait d&#8217;un site journalistique en ligne (2 268 phrases
en fran&#231;ais), de diff&#233;rents corpus utilis&#233;s dans les compagnes d&#8217;&#233;valuation de traduction WMT
(Callison-Burch et al., 2012) (991 phrases en fran&#231;ais et 864 en anglais) et IWLST (Cettolo
et al., 2012) (1 524 phrases en anglais) ainsi que d&#8217;une campagne d&#8217;&#233;valuation de modules
de d&#233;sambigu&#239;sation s&#233;mantique (Lefever et Hoste, 2010) (1 000 phrases en anglais). Les
exemples de ce dernier sous-corpus sont accompagn&#233;s d&#8217;informations compl&#233;mentaires, telles
que des traductions de r&#233;f&#233;rence ou des annotations s&#233;mantiques, qui ont &#233;t&#233; collect&#233;es par les
organisateurs de ces diff&#233;rentes campagnes d&#8217;&#233;valuation.
</p>
<p>Des consignes de correction pr&#233;cises (diffus&#233;es avec le corpus) ont &#233;t&#233; fournies aux traducteurs
afin d&#8217;assurer que celles-ci soient minimales : l&#8217;objectif est d&#8217;obtenir des traductions jug&#233;es
correctes (aussi bien au niveau du sens que de la langue) tout en restant le plus proche possible
de la traduction automatique. Afin de garantir leur qualit&#233;, des &#233;chantillons des corrections ont
&#233;t&#233; valid&#233;es par un expert et, au besoin, des modifications ont &#233;t&#233; demand&#233;es aux traducteurs
pour assurer le respect des consignes. Par ailleurs, les traductions corrig&#233;es ont &#233;t&#233; utilis&#233;es
pour &#233;valuer automatiquement la qualit&#233; des syst&#232;mes de TA. Comme le montre le Tableau 1,
les principales m&#233;triques ont des valeurs bien plus &#233;lev&#233;es que celles g&#233;n&#233;ralement observ&#233;es,
montrant clairement que les r&#233;f&#233;rences produites sont effectivement plus proches des sorties des
syst&#232;mes que les r&#233;f&#233;rences utilis&#233;es dans les campagnes d&#8217;&#233;valuation. Ainsi, lorsque SYSSTAT est
&#233;valu&#233; par rapport aux r&#233;f&#233;rences fournies pour la campagne d&#8217;&#233;valuation WMT 2012, son score
</p>
<p>2. Au total, 10 traducteurs diff&#233;rents (5 pour chaque direction de traduction) ont &#233;t&#233; sollicit&#233;s
3. anr-trace.limsi.fr
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>724 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>SYSSTAT SYSRULE
</p>
<p>BLEU&#8593; 57,0 47,6
hTER&#8595; 29,1 36,8
M&#233;t&#233;or&#8593; 40,6 33,8
</p>
<p>TABLE 1 &#8211; &#201;valuation des syst&#232;mes de TA quand les hypoth&#232;ses post-&#233;dit&#233;es sont prises comme
r&#233;f&#233;rences. Les scores suivis de &#8593; (resp. &#8595;) sont d&#8217;autant meilleurs qu&#8217;ils sont grands (resp. petits).
</p>
<p>TER est de 56,3 (contre 36,8 ici). Notons &#233;galement que, comme cela a d&#233;j&#224; observ&#233; par ailleurs,
les m&#233;triques automatiques d&#233;favorisent fortement le syst&#232;me &#224; base de r&#232;gles.
</p>
<p>3 Analyse des limites des syst&#232;mes de TA
</p>
<p>Nous montrons dans cette section comment la comparaison des hypoth&#232;ses de traduction avec
leur post-&#233;dition permet d&#8217;identifier certaines limites des syst&#232;mes de TA. Pour des raisons de
place, seuls les r&#233;sultats obtenus pour les traductions de l&#8217;anglais vers le fran&#231;ais sont pr&#233;sent&#233;s.
</p>
<p>3.1 Erreurs fr&#233;quentes
</p>
<p>Le calcul de la distance d&#8217;&#233;dition entre les hypoth&#232;ses de traduction et leur post-&#233;dition permet
de d&#233;terminer automatiquement les corrections &#224; effectuer pour rendre &#171; acceptables &#187; les
traductions automatiques. L&#8217;&#233;tude des &#233;ditions les plus fr&#233;quentes permet de caract&#233;riser certaines
limites des syst&#232;mes de TA actuels.
</p>
<p>Une premi&#232;re observation porte sur le type des &#233;ditions fr&#233;quentes : il s&#8217;agit essentiellement
de substitutions (Tableau 2), m&#234;me si le syst&#232;me &#224; base de r&#232;gles a tendance &#224; produire des
traductions trop longues. Une part non n&#233;gligeable des substitutions (pr&#232;s de 9 %) correspond &#224;
la modification de la terminaison d&#8217;un mot (par exemple, &#171; penserai &#187; est corrig&#233; en &#171; penserais &#187;,
&#171; sp&#233;ciales &#187; en &#171; sp&#233;cial &#187;, ...). Il est toutefois difficile d&#8217;&#233;valuer si ces modifications sont des
corrections isol&#233;es (par exemple, pour corriger une erreur d&#8217;accord) ou si bien elles d&#233;coulent
d&#8217;autres corrections (accord d&#8217;un adjectif suite &#224; la substitution du mot avec lequel il s&#8217;accorde).
</p>
<p>Une &#233;tude statistique des &#233;ditions montre que la plupart des modifications (pr&#232;s de 70 %) sont
uniques, ce qui rend difficile l&#8217;identification de motifs d&#8217;erreurs . Les erreurs les plus fr&#233;quentes
portent presqu&#8217;exclusivement sur des mots outils (Table 3) et, comme pr&#233;c&#233;demment, il est
difficile de savoir si ces r&#233;visions sont dues &#224; des erreurs de la TA, ou bien d&#233;coulent d&#8217;autres
corrections. Le filtrage des mots outils permet de faire appara&#238;tre certains motifs d&#8217;erreurs
r&#233;currents. Ainsi, sur les 5 929 traductions du corpus, la traduction de &#171; order &#187; par &#171; ordre &#187; a
&#233;t&#233; corrig&#233;e 23 fois en &#171; commande &#187; et &#171; maison &#187; 10 fois en &#171; chez ... &#187;. Une centaine de motifs
de ce type ont &#233;t&#233; extraits, m&#234;me si tous ne sont pas aussi facilement interpr&#233;tables.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>725 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>op&#233;ration SYSSTAT SYSRULE
</p>
<p>d&#233;placement 2861 3473
substitution 10065 10991
suppression 3572 7371
insertion 2502 2263
</p>
<p>TABLE 2 &#8211; Nombre d&#8217;op&#233;rations n&#233;cessaires
pour corriger les sorties des deux syst&#232;mes
de TA
</p>
<p>Substitution Insertion Suppression
</p>
<p>148 les&#8594; des 380 de 799 de
93 des&#8594; les 233 la 335 &#224;
60 la&#8594; le 204 le 329 la
57 du&#8594; le 204 a 278 le
55 des&#8594; de 184 &#224; 277 que
53 du&#8594; de 141 dans 256 les
51 de&#8594; des 131 que 242 en
46 de&#8594; pour 99 en 215 et
43 cela&#8594; il 97 un 212 des
42 une&#8594; un 96 des 167 pour
TABLE 3 &#8211; Corrections les plus fr&#233;quentes
</p>
<p>3.2 Diff&#233;rences entre les traductions automatiques et leur post-&#233;dition
</p>
<p>Une autre analyse, inspir&#233;e des travaux en estimation de confiance pour la traduction (Kulesza
et Shieber, 2004), permet d&#8217;avoir une vision plus globale des diff&#233;rences entre hypoth&#232;ses de
traduction et traductions post-&#233;dit&#233;es. Cette analyse repose sur l&#8217;apprentissage d&#8217;un classifieur
capable de distinguer ces deux types de traductions et l&#8217;&#233;tude des caract&#233;ristiques utiles pour
faire cette distinction. Le m&#234;me principe peut &#234;tre utilis&#233; pour caract&#233;riser les diff&#233;rences entre
les r&#233;f&#233;rences obtenues en post-&#233;ditant des hypoth&#232;ses de traduction et les r&#233;f&#233;rences &#171; libres &#187;
utilis&#233;es dans les campagnes d&#8217;&#233;valuation de la traduction.
</p>
<p>Dans les exp&#233;riences de cette section, chaque traduction est repr&#233;sent&#233;e par un ensemble
de 336 caract&#233;ristiques utilis&#233;es dans un syst&#232;me d&#8217;estimation de confiance pour la TA (Wisniewski
et al., 2013). Ces caract&#233;ristiques se r&#233;partissent en quatre grandes cat&#233;gories :
&#8211; des mesures de la qualit&#233; de l&#8217; &#171; association &#187; entre la source et l&#8217;hypoth&#232;se de traduction, telles
des caract&#233;ristiques d&#233;riv&#233;es des mod&#232;les d&#8217;alignement ;
</p>
<p>&#8211; des mesures de la fluidit&#233; et de la grammaticalit&#233; de l&#8217;hypoth&#232;se de traduction ainsi que de la
phrase source, telles des caract&#233;ristiques d&#233;riv&#233;es des mod&#232;les de langue ;
</p>
<p>&#8211; des caract&#233;ristiques de surfaces telles le nombre de mots hors vocabulaire, de signes de
ponctuation, ... ;
</p>
<p>&#8211; des caract&#233;ristiques syntaxiques simples comme le nombre de noms, de mots outils, ...
Une liste compl&#232;te des caract&#233;ristiques utilis&#233;es est donn&#233;e dans (Wisniewski et al., 2013).
</p>
<p>Pour mener cette analyse, nous avons utilis&#233; comme classifieur une for&#234;t al&#233;atoire (Breiman,
2001), une m&#233;thode d&#8217;apprentissage ensembliste qui repose sur la combinaison des pr&#233;dictions de
plusieurs arbres de d&#233;cision. Les for&#234;ts al&#233;atoires ont montr&#233; leur efficacit&#233; dans de nombreuses
t&#226;ches ; elles sont connues pour &#234;tre particuli&#232;rement robustes au sur-apprentissage et pour
permettre la mod&#233;lisation d&#8217;interactions complexes entre les caract&#233;ristiques. En plus de la
construction d&#8217;un classifieur, l&#8217;algorithme d&#8217;apprentissage permet d&#8217;estimer l&#8217;importance de chaque
caract&#233;ristique (Breiman, 2001) qui quantifie directement son pouvoir discriminant : plus cette
importance est &#233;lev&#233;e, plus la caract&#233;ristique est utile &#224; la pr&#233;diction de l&#8217;&#233;tiquette.
</p>
<p>Nous avons utilis&#233;, dans nos exp&#233;riences, l&#8217;impl&#233;mentation des for&#234;ts al&#233;atoires fournies par
la biblioth&#232;que scikit-learn (Pedregosa et al., 2011). Les param&#232;tres de la for&#234;t al&#233;atoire
sont appris sur 2/3 des donn&#233;es ; le dernier tiers des donn&#233;es &#233;tant utilis&#233; pour &#233;valuer les
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>726 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>performances du classifieur. L&#8217;ensemble des hyper-param&#232;tres sont choisis par validation crois&#233;e.
</p>
<p>La premi&#232;re t&#226;che consid&#233;r&#233;e a pour objectif de distinguer les traductions produites par un
syst&#232;me de TA de leur post-&#233;dition : elle n&#233;cessite donc de distinguer automatiquement une
bonne traduction d&#8217;une mauvaise. C&#8217;est une t&#226;che difficile, ces deux traductions &#233;tant par
construction proches l&#8217;une de l&#8217;autre. Il n&#8217;est donc pas surprenant que la pr&#233;cision du classifieur
ne soit que de 63 % en apprentissage et de 59 % en test. Les performances de la seconde
t&#226;che, visant &#224; distinguer les r&#233;f&#233;rences obtenues par post-&#233;dition des r&#233;f&#233;rences &#171; libres &#187; sont
sensiblement meilleures : la pr&#233;cision en apprentissage est de 71 % et de 67 % en test.
</p>
<p>Les 8 caract&#233;ristiques les plus discriminantes et leur importance sont repr&#233;sent&#233;es Figure 1. Pour
les deux t&#226;ches, seules quelques caract&#233;ristiques sont discriminantes et celles-ci sont presque
uniquement d&#233;riv&#233;es des scores de mod&#232;les de langue. Les mod&#232;les de langue neuronaux (Le
et al., 2011) (caract&#233;ristiques comportant SOUL dans leur nom), appliqu&#233;s aussi bien &#224; la source
qu&#8217;&#224; la traduction, jouent un r&#244;le pr&#233;dominant, surtout pour la distinction entre les hypoth&#232;ses
de traduction et leur post-&#233;dition. Ces caract&#233;ristiques sont compl&#233;t&#233;es par des mod&#232;les de
langue &#171; classiques &#187; appris aussi bien sur les &#233;tiquettes morpho-syntaxiques (POSLMLOGPROB
correspond &#224; la log-probabilit&#233; d&#8217;une s&#233;quences d&#8217;&#233;tiquettes morpho-syntaxiques) que sur les
mots (BIGRAMSFREQQUARTILE1 d&#233;crit le pourcentage de bi-grams dont la fr&#233;quence est dans le
premier quartile). Dans tous les cas, les valeurs des caract&#233;ristiques sont plus faibles pour les
traductions automatiques que pour les hypoth&#232;ses post-&#233;dit&#233;es qui ont elles-m&#234;mes des valeur
plus faibles que celles observ&#233;es dans les r&#233;f&#233;rences libres. Cette observation indique soit que
l&#8217;espace de recherche des syst&#232;mes de TA n&#8217;est pas assez riche puisque le syst&#232;me de TA n&#8217;est pas
capable de g&#233;n&#233;rer des hypoth&#232;ses suffisamment &#171; fluides &#187;, soit le mod&#232;le de langue n&#8217;a pas un
poids suffisant dans la fonction de score qui permet au syst&#232;me de TA d&#8217;&#233;valuer la qualit&#233; des
hypoth&#232;ses. Des exp&#233;riences suppl&#233;mentaires sont toutefois n&#233;cessaires pour d&#233;terminer laquelle
de ces deux hypoth&#232;ses est correcte.
</p>
<p>Parmi les autres caract&#233;ristiques importantes, on peut noter la pr&#233;sence de descripteurs de surface
simples d&#233;crivant les longueurs des phrases (SENLENGTH), le nombre de signes de ponctuation
(NUMPUNC) ou la longueur moyenne des tokens (AVGTOKENLENGTH). Finalement, la caract&#233;ristique
la plus importante pour distinguer les r&#233;f&#233;rences post-&#233;dit&#233;es des r&#233;f&#233;rences libres est fond&#233;e sur
la probabilit&#233; d&#8217;alignement de la traduction avec la source, telle qu&#8217;estim&#233;e par un mod&#232;le IBM 1,
et quantifie le nombre moyen de mots dont la probabilit&#233; d&#8217;alignement est plus grande que 0,02.
</p>
<p>4 &#201;valuation de la variabilit&#233; des post-&#233;ditions
</p>
<p>Une autre application du corpus TRACE est l&#8217;&#233;tude de l&#8217;accord inter-annotateur de la post-&#233;dition,
puisque, pour chaque direction de traduction, 1000 traductions ont &#233;t&#233; corrig&#233;es deux fois
ind&#233;pendamment. &#192; notre connaissance, c&#8217;est la premi&#232;re fois que deux annotateurs diff&#233;rents
corrigent les m&#234;mes phrases, permettant une comparaison des post-&#233;ditions et une estimation de
l&#8217;accord inter-annoteur du score hTER. Pour des raisons de place, nous d&#233;crirons uniquement les
r&#233;sultats obtenus sur le corpus de traductions de l&#8217;anglais vers le fran&#231;ais. Les r&#233;sultats pour la
direction fran&#231;ais vers anglais sont similaires.
</p>
<p>De mani&#232;re quantitative, il est possible de mesurer la similarit&#233; entre les post-&#233;ditions effectu&#233;es
par les diff&#233;rents correcteurs en mesurant la corr&#233;lation entre les scores hTER obtenus lorsque
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>727 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>0 0,1 0,2 0,3 0,4 0,5
</p>
<p>tgtAvgTokenLength
</p>
<p>nTgtBigramsFreqQuartile1
</p>
<p>nSrcSoul
</p>
<p>tgtBigramsFreqQuartile1
</p>
<p>rNumPunc
</p>
<p>rSoul
</p>
<p>rPOSLMLogprob
</p>
<p>nTgtSoul
</p>
<p>Importance de la caract&#233;ristique
</p>
<p>C
ar
</p>
<p>ac
t&#233;
</p>
<p>ri
st
</p>
<p>iq
ue
</p>
<p>Distinction hypoth&#232;ses/post-&#233;dition
</p>
<p>0 0,02 0,04 0,06 0,08 0,1 0,12
</p>
<p>nTgtNumCaps
</p>
<p>rSenLength
</p>
<p>rNumPunc
</p>
<p>nSrcSoul
</p>
<p>rSoul
</p>
<p>rPOSLMLogprob
</p>
<p>rAvgTokenLength
</p>
<p>t2sAvgNumTrans02
</p>
<p>Importance de la caract&#233;ristique
</p>
<p>Distinction r&#233;f&#233;rence/post-&#233;dition
</p>
<p>FIGURE 1 &#8211; Importance des caract&#233;ristiques les plus discriminantes pour les deux t&#226;ches consid&#233;-
r&#233;es. Les caract&#233;ristiques dont le nom commence par un N sont normalis&#233;es par la longueur de la
phrase ; celles dont le nom commence par un R sont constitu&#233;es par le rapport entre les valeurs
de la caract&#233;ristique calcul&#233;e sur la phrase source et sur la traduction.
</p>
<p>ces corrections sont utilis&#233;es comme r&#233;f&#233;rence. Cette corr&#233;lation est faible : le coefficient de
Pearson entre les deux notes n&#8217;est que de 0,642 et le &#964; de Kendall de 0,476. L&#8217;interpr&#233;tation est
que si les traductions &#233;taient ordonn&#233;es suivant leur score hTER, deux traductions quelconques
ne seraient dans le m&#234;me ordre pour les deux r&#233;f&#233;rences qu&#8217;une fois sur deux. De mani&#232;re
globale, les post-&#233;ditions produites ne sont identiques que dans 12 % des cas 4. La distance
d&#8217;&#233;dition normalis&#233;e moyenne entre les deux post-&#233;ditions est de 24 % : il faut donc, pour passer
d&#8217;une post-&#233;dition &#224; l&#8217;autre, changer en moyenne un mot sur quatre. Bien qu&#8217;elles ne soient
pas directement comparables, puisque dans l&#8217;un des cas le score (h)TER n&#8217;est pas calcul&#233; par
rapport &#224; une r&#233;f&#233;rence &#171; adapt&#233;e &#187;, cette valeur est &#224; peine plus petite que celle observ&#233;e lors de
l&#8217;&#233;valuation des sorties de SYSSTAT. Ce r&#233;sultat illustre les limites de l&#8217;&#233;valuation de la TA par des
score (h)TER. Les op&#233;rations les plus fr&#233;quentes dans cette transformation sont les substitutions
de mots (57 % des modifications) suivi des suppressions et des insertions de mots (16 % dans les
deux cas) ; les d&#233;placements de mots n&#8217;interviennent que dans 11 % des cas.
</p>
<p>Plus qualitativement, le Tableau 4 reprend des exemples des corrections les plus diff&#233;rentes ainsi
que des phrases sources et des traductions automatiques. Ces exemples illustrent la vari&#233;t&#233; des
diff&#233;rences entre les post-&#233;ditions qui peuvent &#234;tre dues &#224; :
&#8211; une sensibilit&#233; diff&#233;rente aux traductions litt&#233;rales : dans de nombreux cas, un correcteur
accepte une traduction parfaitement compr&#233;hensible et juste d&#8217;un point de vue grammatical,
m&#234;me si elle n&#8217;aurait jamais &#233;t&#233; &#171; produite &#187; par un locuteur natif, alors que le second pr&#233;f&#232;re
la reformuler (4e exemple) ;
</p>
<p>&#8211; une reformulation non n&#233;cessaire de la traduction automatique (le second correcteur qui
corrige &#171; cette r&#233;glementation &#187; en &#171; le pr&#233;sent r&#232;glement &#187; dans le 1er exemple)
</p>
<p>&#8211; une utilisation de paraphrases ou de synonymes sans raisons apparentes (&#171; ultramodernes &#187;
</p>
<p>4. La comparaison entre les deux corrections ne tient compte ni de la ponctuation, ni de la casse.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>728 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1. source Each year, the Member States shall send the Commission a report on the evaluation of the
execution and effectiveness of this regulation.
</p>
<p>trad. autom. Chaque ann&#233;e, les &#201;tats membres transmettent &#224; la Commission un rapport sur l&#8217;&#233;valuation
de l&#8217;ex&#233;cution et l&#8217;efficacit&#233; de cette r&#233;glementation.
</p>
<p>correction no 1 Chaque ann&#233;e, les &#201;tats membres transmettent &#224; la Commission un rapport sur l&#8217;&#233;valuation
de l&#8217;ex&#233;cution et l&#8217;efficacit&#233; de cette r&#233;glementation.
</p>
<p>correction no 2 Chaque ann&#233;e, les &#201;tats membres communiquent &#224; la Commission un rapport d&#8217;&#233;valuation
concernant l&#8217;ex&#233;cution et l&#8217;efficacit&#233; du pr&#233;sent r&#232;glement.
</p>
<p>2. source I&#8217;m thinking this must be an ancient print date, right.
trad. autom. Je retiens ce doit &#234;tre une date imprim&#233;e antique.
correction no 1 Je pense qu&#8217;il s&#8217;agit une ancienne &#233;dition, c&#8217;est &#233;vident.
correction no 2 Je pense que &#231;a doit &#234;tre une ancienne date d&#8217;impression, n&#8217;est-ce pas.
</p>
<p>3. source So let&#8217;s take a tour of this state-of-the-art clean coal facility.
trad. autom. Donc prenons un tour de cet &#233;tat de l&#8217;art nettoient la facilit&#233; de charbon.
correction no 1 Alors allons voir ces installations ultramodernes de charbon propre.
correction no 2 Donc faisons une visite de cette installation de charbon propre &#224; la pointe de la technolo-
</p>
<p>gie.
</p>
<p>4. source Dear Valued Customer, please follow the steps below to have a troubleshooting.
trad. autom. Cher valoris&#233;es &#224; la client&#232;le, veuillez suivre les &#233;tapes ci-dessous pour avoir un d&#233;pannage.
correction no 1 Cher client estim&#233;, veuillez suivre les &#233;tapes ci-dessous pour avoir un d&#233;pannage.
correction no 2 Tr&#232;s cher client, veuillez suivre les &#233;tapes ci-dessous pour &#234;tre d&#233;pann&#233;.
</p>
<p>TABLE 4 &#8211; Exemple de diff&#233;rences de post-&#233;ditions.
</p>
<p>versus &#171; &#224; la pointe de la technologie &#187; dans le 3e exemple) ;
&#8211; une ambigu&#239;t&#233; li&#233;e au manque de contexte en source (&#171; cette installation &#187; versus &#171; ces
</p>
<p>installations &#187; dans le 3e exemple).
Remarquons que les corrections sont diff&#233;rentes aussi bien quand la traduction automatique est
plut&#244;t bonne (1er exemple) que quand elle est compl&#232;tement fausse (2e et 3e exemples).
</p>
<p>Ces observations mettent en &#233;vidence les limites inh&#233;rentes &#224; l&#8217;&#233;valuation des syst&#232;mes de TA
par un score comme hTER : dans la mesure o&#249; la post-&#233;dition semble aussi subjective que la
traduction elle-m&#234;me, les scores hTER seront aussi variables et difficiles &#224; interpr&#233;ter que les
autres m&#233;triques automatique utilis&#233;es pour &#233;valuer la TA.
</p>
<p>5 Conclusion
</p>
<p>Nous avons pr&#233;sent&#233;, dans ce travail, un grand corpus de corrections de traductions et illustr&#233;
diff&#233;rents types d&#8217;analyse que celui-ci rend possible. Bien qu&#8217;ils ne soient que pr&#233;liminaires, les
r&#233;sultats pr&#233;sent&#233;s sont d&#233;j&#224; riches en enseignements : ils montrent notamment les limites de la
m&#233;trique hTER et illustrent une mani&#232;re d&#8217;identifier les erreurs fr&#233;quentes en traduction. D&#8217;autres
exploitations sont possibles, notamment en exploitant les annotations compl&#233;mentaires qui sont
disponibles pour diverses sous-parties du corpus TRACE. Nos travaux futurs ont pour objectif
d&#8217;approfondir ces observations et d&#8217;arriver &#224; les int&#233;grer dans les syst&#232;mes de TA afin d&#8217;am&#233;liorer
la qualit&#233; des hypoth&#232;ses produites. Une autre piste de recherche consiste &#224; comparer les erreurs
faites par les syst&#232;mes de TA aux erreurs faites par les humains en utilisant, par exemple, des
corpus contenant des corrections de traduction (Abekawa et al., 2010).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>729 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Remerciements
</p>
<p>Ce travail a &#233;t&#233; partiellement financ&#233; par l&#8217;Agence Nationale de la Recherche au travers du projet
ANR/CONTINT-2010/TRACE.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ABEKAWA, T., UTIYAMA, M., SUMITA, E. et KAGEURA, K. (2010). Community-based construction of
draft and final translation corpus through a translation hosting site minna no hon&#8217;yaku (mnh).
In Proc. of LREC. ELRA.
BREIMAN, L. (2001). Random forests. Mach. Learn., 45(1):5&#8211;32.
CALLISON-BURCH, C., KOEHN, P., MONZ, C., POST, M., SORICUT, R. et SPECIA, L. (2012). Findings of
the 2012 workshop on statistical machine translation. In Proc. of WMT, pages 10&#8211;51, Montr&#233;al,
Canada. ACL.
CETTOLO, M., GIRARDI, C. et FEDERICO, M. (2012). Wit3 : Web inventory of transcribed and
translated talks. In Proc. of EAMT, pages 261&#8211;268, Trento, Italy.
CREGO, J. M., YVON, F. et NO, J. B. M. (2011). N-code : an open-source Bilingual N-gram SMT
Toolkit. Prague Bulletin of Mathematical Linguistics, 96:49&#8211;58.
GARCIA, I. (2011). Translating by post-editing : is it the way forward ? Machine Translation,
25:217&#8211;237.
KULESZA, A. et SHIEBER, S. M. (2004). A learning approach to improving sentence-level mt
evaluation. In Proc. of TMI.
LE, H.-S., LAVERGNE, T., ALLAUZEN, A., APIDIANAKI, M., GONG, L., MAX, A., SOKOLOV, A., WISNIEWSKI,
G. et YVON, F. (2012). LIMSI @ WMT12. In Proc. of WMT, pages 330&#8211;337, Montr&#233;al, Canada.
ACL.
LE, H. S., OPARIN, I., ALLAUZEN, A., GAUVAIN, J.-L. et YVON, F. (2011). Structured Output Layer
Neural Network Language Model. In Proceedings of IEEE International Conference on Acoustic,
Speech and Signal Processing, pages 5524&#8211;5527, Prague, Czech Republic.
LEFEVER, E. et HOSTE, V. (2010). Semeval-2010 task 3 : Cross-lingual word sense disambiguation.
In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 15&#8211;20, Uppsala,
Sweden. ACL.
PEDREGOSA, F., VAROQUAUX, G., GRAMFORT, A., MICHEL, V., THIRION, B., GRISEL, O., BLONDEL, M.,
PRETTENHOFER, P., WEISS, R., DUBOURG, V., VANDERPLAS, J., PASSOS, A., COURNAPEAU, D., BRUCHER,
M., PERROT, M. et DUCHESNAY, E. (2011). Scikit-learn : Machine Learning in Python . JMLR,
12:2825&#8211;2830.
POTET, M., ESPERAN&#199;A-RODIER, E., BESACIER, L. et BLANCHON, H. (2012). Collection of a large
database of French-English SMT output corrections. In Proc. of LREC, Istanbul, Turkey. ELRA.
SNOVER, M., DORR, B., SCHWARTZ, R., MICCIULLA, L. et MAKHOUL, J. (2006). A study of translation
edit rate with targeted human annotation. In Proc. of AMTA, pages 223&#8211;231.
WISNIEWSKI, G., SINGH, A. K. et YVON, F. (2013). Quality estimation for machine translation :
Some lessons learned. Machine Translation, page accept&#233; pour publication.
ZHUANG, Y., WISNIEWSKI, G. et YVON, F. (2012). Non-linear models for confidence estimation. In
Proc. of WMT, pages 157&#8211;162, Montr&#233;al, Canada. ACL.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>730 c&#65535; ATALA</p>

</div></div>
</body></html>