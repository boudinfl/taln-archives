<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Construction et exploitation d&#8217;un corpus fran&#231;ais pour l&#8217;analyse de sentiment</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction et exploitation d&#8217;un corpus fran&#231;ais pour
l&#8217;analyse de sentiment
</p>
<p>Marc Vincent1 Gr&#233;goire Winterstein2
(1) UMR S-775, Universit&#233; Paris Descartes
</p>
<p>(2) LLF, UMR 7110, Universit&#233; Sorbonne Nouvelle
marc.r.vincent@gmail.com, gregoire.winterstein@linguist.jussieu.fr
</p>
<p>R&#201;SUM&#201;
Ce travail pr&#233;sente un corpus en fran&#231;ais d&#233;di&#233; &#224; l&#8217;analyse de sentiment. Nous y d&#233;crivons la
construction et l&#8217;organisation du corpus. Nous pr&#233;sentons ensuite les r&#233;sultats de l&#8217;application de
techniques d&#8217;apprentissage automatique pour la t&#226;che de classification d&#8217;opinion (positive ou
n&#233;gative) v&#233;hicul&#233;e par un texte. Deux techniques sont utilis&#233;es : la r&#233;gression logistique et la
classification bas&#233;e sur des Support Vector Machines (SVM). Nous mentionnons &#233;galement l&#8217;int&#233;r&#234;t
d&#8217;appliquer une s&#233;lection de variables avant la classification (par r&#233;gularisation par elastic net).
</p>
<p>ABSTRACT
Building and exploiting a French corpus for sentiment analysis
</p>
<p>This work introduces a French corpus for sentiment analysis. We describe the construction
and organization of the corpus. We then apply machine learning techniques to automatically
predict whether a text is positive or negative (the opinion classification task). Two techniques are
used : logistic regression and classification based on Support Vector Machines (SVM). Finally, we
briefly evaluate the merits of applying feature selection algorithms to our models (via elastic net
regularization).
</p>
<p>MOTS-CL&#201;S : Analyse de sentiments, Corpus, Classification, Apprentissage automatique, S&#233;lec-
tion de variable.
</p>
<p>KEYWORDS: Sentiment Analysis, Corpus, Opinion Mining, Classification, Machine Learning,
Variable Selection.
</p>
<p>1 Introduction
</p>
<p>Ce travail pr&#233;sente la construction et l&#8217;exploitation d&#8217;un corpus fran&#231;ais destin&#233; &#224; l&#8217;analyse de
sentiment (sentiment analysis ou opinion mining). L&#8217;analyse de sentiment recouvre l&#8217;ensemble
des t&#226;ches d&#233;di&#233;es &#224; la reconnaissance des opinions exprim&#233;es au sein d&#8217;un texte et conna&#238;t de
nombreuses applications (pour un panorama voir Pang et Lee (2008)).
</p>
<p>Les recherches sur l&#8217;analyse de sentiments (ou de subjectivit&#233;) sont en majorit&#233; centr&#233;es sur
l&#8217;anglais, bien que le sujet ait d&#233;j&#224; fait l&#8217;objet de plusieurs recherches ayant abouti entre autres
&#224; l&#8217;&#233;tablissement de corpus (cf. notamment Grouin et al. (2007); Vernier (2011)). Nous avons
cependant jug&#233; utile de construire un nouveau corpus constitu&#233; de critiques issues du web. La
motivation, la construction et la structure du corpus sont d&#233;crites en section 2.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>764 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Parmi les t&#226;ches relevant de l&#8217;analyse de sentiment nous nous sommes focalis&#233;s sur la classification
d&#8217;opinion, c&#8217;est-&#224;-dire sur la t&#226;che qui consiste &#224; classer un texte dans une cat&#233;gorie d&#8217;opinion
(typiquement positif ou n&#233;gatif). Nous rapportons les r&#233;sultats obtenus pour cette t&#226;che en ayant
eu recours aux Support Vector Machines (SVM). Nous rapportons &#233;galement les r&#233;sultats obtenus
en op&#233;rant au pr&#233;alable une s&#233;lection des variables par r&#233;gularisation par elastic net. Notre
m&#233;thodologie est d&#233;crite des sections 3.1 &#224; 3.4 et nos r&#233;sultats en section 3.5.
</p>
<p>2 Construction et constitution du corpus
</p>
<p>Les ressources n&#233;cessaires &#224; l&#8217;analyse de sentiment doivent fournir en parall&#232;le d&#8217;un contenu
textuel une forme d&#8217;&#233;valuation du sentiment associ&#233; au texte. Avec le d&#233;veloppement des contenus
g&#233;n&#233;r&#233;s par les utilisateurs sur le web, ce type de ressource peut aujourd&#8217;hui facilement s&#8217;obtenir
sur des sites web permettant aux internautes de partager leur opinion sur divers sujets. Du point
de vue qualitatif et m&#233;thodologique, un corpus regroupant ce genre de textes se doit d&#8217;&#234;tre
le plus g&#233;n&#233;ral possible afin que les mod&#232;les issus de techniques d&#8217;apprentissage soient aussi
g&#233;n&#233;raux que possible. Cela signifie notamment que chacune des critiques r&#233;cup&#233;r&#233;es doit traiter
d&#8217;un produit diff&#233;rent. Les descriptions des corpus existants (p.ex. celui utilis&#233; dans la campagne
DEFT&#8217;07 ou celui utilis&#233; par Ghorbel et Jacot (2011)) ne font pas &#233;tat de la vari&#233;t&#233; d&#8217;&#233;l&#233;ments
&#233;valu&#233;s dans le corpus, et il nous a donc paru pertinent de construire un nouveau corpus en
tenant compte de cette dimension.
</p>
<p>2.1 Construction du corpus
</p>
<p>La construction de notre corpus s&#8217;appuie sur la collecte de commentaires d&#8217;internautes recueillis
sur diff&#233;rentes plate-formes web en fran&#231;ais et permettant aux utilisateurs d&#8217;exprimer leur
opinion par le biais d&#8217;une note chiffr&#233;e. La totalit&#233; des informations a &#233;t&#233; obtenue de mani&#232;re
automatique et non-supervis&#233;e en cr&#233;ant des parseurs adapt&#233;s aux sites concern&#233;s. Le corpus
obtenu est disponible sur demande aupr&#232;s des auteurs.
</p>
<p>Afin de varier les th&#232;mes abord&#233;s dans les critiques constituant le corpus, nous avons consid&#233;r&#233;
trois domaines diff&#233;rents : des critiques de films tir&#233;es du site allocine.fr, des avis sur des
romans de poche extraits du site amazon.fr et des commentaires relatifs &#224; des &#233;tablissements
h&#244;teliers tir&#233;s du site tripadvisor.fr. Sur chacun de ces sites, les utilisateurs sont invit&#233;s
&#224; r&#233;diger une opinion et &#224; exprimer leur avis par une note situ&#233;e entre 1 et 5 (typiquement
repr&#233;sent&#233;e &#224; l&#8217;&#233;cran par un nombre d&#8217;&#233;toiles). Le nombre de commentaires par type de produit
est r&#233;sum&#233; dans le tableau ci-dessous :
</p>
<p>Type de produit Provenance N. critiques / note
H&#244;tels tripadvisor.fr 1000
Films allocine.fr 1000
</p>
<p>Romans amazon.fr 800
</p>
<p>TABLE 1 &#8211; Constitution du corpus (nombre total de textes : 14000)
</p>
<p>La diversit&#233; de provenance des critiques est une premi&#232;re &#233;tape pour s&#8217;assurer que les mod&#232;les
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>765 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>produits par les algorithmes d&#8217;apprentissage ne se montreront pas trop li&#233;s au idiosyncrasies du
corpus. Outre la diversit&#233; de provenance, nous nous sommes &#233;galement assur&#233;s que :
&#8211; Le nombre de produits distincts repr&#233;sent&#233;s dans chaque plage de notation soit maximal.
</p>
<p>Dans le cas des romans et des films, ce nombre est &#233;gal au nombre de critiques, c&#8217;est-&#224;-dire
qu&#8217;un produit donn&#233; fait l&#8217;objet d&#8217;au plus une critique pour chacune des 5 notes. Dans le cas
des &#233;tablissements h&#244;teliers cette ventilation ne s&#8217;est pas montr&#233;e possible, nous avons donc
cherch&#233; &#224; limiter le nombre de r&#233;p&#233;titions. Au final, aucun produit ne se trouve mentionn&#233;
plus de 5 fois par plage de note dans le corpus.
</p>
<p>&#8211; Les auteurs de critiques soient aussi diff&#233;rents que possible au sein des critiques d&#8217;une m&#234;me
plage de notation. S&#8217;il n&#8217;a pas &#233;t&#233; possible de s&#8217;assurer que chacune des critiques ait un auteur
distinct des autres, le nombre de critiques sign&#233;es d&#8217;un m&#234;me auteur au sein d&#8217;une m&#234;me plage
de notation est de 12. 1
</p>
<p>Ces deux pr&#233;cautions permettent d&#8217;&#233;viter que des mod&#232;les produits par des algorithmes d&#8217;appren-
tissage perdent en g&#233;n&#233;ralit&#233; en &#233;tant trop d&#233;pendant des sp&#233;cificit&#233;s propres &#224; certains items ou
auteurs fr&#233;quemment r&#233;p&#233;t&#233;s.
</p>
<p>Les possibilit&#233;s de notation offertes par les plates-formes marchandes vont aujourd&#8217;hui au-del&#224;
de l&#8217;appariement d&#8217;une note &#224; un texte. C&#8217;est pourquoi, outre la note attribu&#233;e et le contenu du
commentaire utilisateur, nous avons cherch&#233; &#224; conserver la totalit&#233; des informations disponibles
et pertinentes pour diff&#233;rentes t&#226;ches d&#8217;analyse de sentiment. Chacune des critiques utilisateurs
est alors accompagn&#233;e des informations suivantes (le corpus est organis&#233; dans un format XML) : 2
&#8211; Identifiant de la critique.
&#8211; Identifiant du produit (sous forme d&#8217;entier).
&#8211; Descriptif du produit (type de produit et titre de film, nom de l&#8217;h&#244;tel ou titre de roman).
&#8211; Note associ&#233;e &#224; la critique (fournie par l&#8217;auteur de la critique).
&#8211; Identifiant (anonymis&#233;) de l&#8217;auteur de la critique
&#8211; Contenu de la critique
Dans les parties relatives &#224; tripadvisor et amazon on trouve de plus pour chaque critique
individuelle :
&#8211; Le r&#233;sum&#233; de la critique (en une phrase) fourni par l&#8217;utilisateur.
&#8211; Une mesure &#8220;d&#8217;utilit&#233;&#8221; de la critique, indiqu&#233;e par le nombre d&#8217;utilisateurs ayant jug&#233; la critique
</p>
<p>utile.
Enfin, dans la partie des critiques issues de tripadvisor, on inclut &#233;galement des informations
de notation sur des crit&#232;res sp&#233;cifiques. Par exemple certains utilisateurs notent la propret&#233; des
chambres ou le rapport qualit&#233;/prix de l&#8217;h&#244;tel (toujours sur une note de 1 &#224; 5).
</p>
<p>Au final, la longueur totale du corpus, en nombre de termes diff&#233;rents reconnus par segmentation
automatique (en utilisant le tokenizer de MElt, cf. infra) est de 1 402867 tokens. La longueur
moyenne d&#8217;une critique est de 100 tokens, les critiques d&#8217;&#233;tablissements h&#244;teliers se montrant
globablement plus longues (123 tokens en moyenne) que celles de films (90 tokens) ou de
romans (83 tokens).
</p>
<p>1. La plage de notation en question est celle correspondant &#224; une note de 2 sur 5 pour les critiques de films. Cette
plage de notation s&#8217;av&#232;re s&#233;v&#232;rement sous-repr&#233;sent&#233;e de mani&#232;re g&#233;n&#233;rale sur le site allocine.fr. En excluant cette
plage sp&#233;cifique, le nombre maximal de r&#233;p&#233;titions par auteur dans le corpus est de 5.
</p>
<p>2. Les informations r&#233;cup&#233;r&#233;es n&#8217;ont pas fait l&#8217;objet de validation subs&#233;quente, notamment sur l&#8217;ad&#233;quation des notes
indiqu&#233;es par les utilisateurs avec le contenu de leur critique. Cependant, nous avons effectu&#233; une extraction al&#233;atoire
de 150 critiques not&#233;es 1 ou 5 que nous avons manuellement annot&#233;es en &#8220;positif&#8221; et &#8220;n&#233;gatif&#8221;. Sur les 150, une seule
erreur a &#233;t&#233; relev&#233;e, montrant que les donn&#233;es utilis&#233;es ult&#233;rieurement dans la t&#226;che de classification sont fiables.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>766 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3 Classification d&#8217;opinion par apprentissage automatique
</p>
<p>En guise d&#8217;illustration de l&#8217;emploi du corpus construit, nous nous focalisons sur la t&#226;che de
classification automatique d&#8217;opinion. Cette t&#226;che est une des premi&#232;res qui ait &#233;t&#233; abord&#233;e dans
le domaine de l&#8217;opinion mining (Pang et al., 2002) et il nous est apparu pertinent de fournir un
&#233;talon relatif au corpus que nous utilisons. Il est important de noter que cette t&#226;che ne fait pas
appel &#224; la totalit&#233; des informations offertes par le corpus : d&#8217;autres t&#226;ches potentiellement plus
complexes peuvent par exemple faire usage des indicateurs d&#8217;utilit&#233; associ&#233;s aux critiques. Un de
nos buts est avant tout de fournir des mesures de bases associ&#233;es au corpus. Comme mentionn&#233;
pr&#233;c&#233;demment, des t&#226;ches similaires ont d&#233;j&#224; &#233;t&#233; entreprises, mais sur des corpus dont le
caract&#232;re g&#233;n&#233;ral n&#8217;est pas assur&#233;. Outre de fournir ces mesures, nous voulons &#233;galement mesurer
l&#8217;int&#233;r&#234;t d&#8217;appliquer des techniques de r&#233;duction de variable avant les phases d&#8217;apprentissage
automatique.
</p>
<p>Pour aborder la t&#226;che de classification automatique nous avons utilis&#233; deux types d&#8217;approches :
une classification bas&#233;e sur des SVM, et une autre bas&#233;e sur la r&#233;gression logistique &#224; l&#8217;issue de
la s&#233;lection de variable. Pour chacune de ces t&#226;ches, les critiques ont &#233;t&#233; au pr&#233;alable segment&#233;e,
&#233;tiquet&#233;e et lemmatis&#233;e. Du fait du marquage morphologique relativement riche du fran&#231;ais
cette &#233;tape est apparue n&#233;cessaire pour optimiser les performances des mod&#232;les produits. Pour
cette &#233;tape nous nous sommes bas&#233;s sur l&#8217;&#233;tiqueteur et lemmatiseur MElt (Denis et Sagot, 2012)
dont les performances pour le fran&#231;ais sont l&#8217;&#233;tat de l&#8217;art et qui emploie un module de gestion de
&#8220;crappy text&#8221; qui permet de corriger un certain nombre des irr&#233;gularit&#233;s typiquement trouv&#233;es
dans les contenus r&#233;cup&#233;r&#233;s sur le web.
</p>
<p>3.1 Traits
</p>
<p>Pang et al. (2002) ont observ&#233; que pour la t&#226;che de classification d&#8217;opinion, la fa&#231;on la plus
efficace de d&#233;crire un texte &#233;tait sous forme de &#8220;sac de mots&#8221;, c&#8217;est-&#224;-dire d&#8217;un vecteur &#224; valeurs
bool&#233;ennes, indiquant la pr&#233;sence et l&#8217;absence d&#8217;un &#233;l&#233;ment lexical. Cette m&#233;thode s&#8217;av&#232;re plus
efficace que d&#8217;encoder le nombre d&#8217;occurrences de chaque unigramme et meilleure que d&#8217;utiliser
une description en termes de combinaisons d&#8217;unigrammes et de bigrammes.
</p>
<p>Nous avons suivi ici leurs recommandations pour encoder nos donn&#233;es. Suite au processus de
lemmatisation pr&#233;c&#233;demment mentionn&#233;, nous avons retenu uniquement les lemmes qui avaient
&#233;t&#233; reconnus par MElt et nous avons encod&#233; chacune des critiques sous forme d&#8217;un vecteur
encodant l&#8217;absence ou la pr&#233;sence d&#8217;un lemme (rep&#233;r&#233; par une combinaison de forme et de partie
du discours, p.ex. andalou/ADJ). Nous avons sciemment omis de consid&#233;rer les &#233;l&#233;ments non
reconnus et ceux cat&#233;goris&#233;s comme noms propres : la prise en compte de ces &#233;l&#233;ments aurait fait
baisser la g&#233;n&#233;ralit&#233; des mod&#232;les produits et nettement augment&#233; la taille de l&#8217;espace des traits
(sur le corpus entier on d&#233;nombre 12300 traits ainsi retenus contre 26 765 si tous les lemmes
avaient &#233;t&#233; pris en compte).
</p>
<p>La prise en compte de la pr&#233;sence d&#8217;une n&#233;gation est traditionnellement consid&#233;r&#233;e comme un
indicateur pertinent pour la classification d&#8217;opinion. Usuellement, cette prise en compte se fait
sous la forme d&#8217;un d&#233;doublement des lemmes pris en compte : si un lemme se trouve sous la
port&#233;e d&#8217;une n&#233;gation dans la phrase, il sera encod&#233; sous la forme d&#8217;un trait NEG-LEMME. Afin
de mesurer l&#8217;impact de cette prise en compte, nous n&#8217;avons pas inclus la n&#233;gation dans nos
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>767 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>exp&#233;riences de base, et en &#233;valuons s&#233;parement l&#8217;int&#233;r&#234;t. L&#8217;algorithme de d&#233;tection de la pr&#233;sence
de n&#233;gation est basique et en partie inspir&#233; de celui de Das et Chen (2001). Afin d&#8217;&#233;tiqueter un
lemme n&#233;gativement nous avons :
&#8211; utilis&#233; un chunk parser minimal (impl&#233;ment&#233; en nltk) pour identifier des structures n&#233;gatives
(p.ex. des verbes accompagn&#233;s d&#8217;un marqueur de n&#233;gation),
</p>
<p>&#8211; &#233;tiquet&#233; tout &#233;l&#233;ment situ&#233; &#224; droite de la fronti&#232;re gauche de ces constituants comme n&#233;gatif.
On pourrait raffiner cette approche en utilisant un analyseur syntaxique en d&#233;pendances ou bien
en utilisant un lexique de polarit&#233; (sur le mod&#232;le de Wilson et al. (2005)), mais nous r&#233;servons
ces manipulations &#224; une recherche future.
</p>
<p>3.2 La t&#226;che de classification d&#8217;opinion
</p>
<p>Pour la premi&#232;re exploitation du corpus, nous avons choisi une t&#226;che simple de classification
d&#8217;opinion dans la lign&#233;e de celle entreprise par Pang et al. (2002). Le but de la t&#226;che est donc de
classer des documents (les critiques de produits) selon la polarit&#233; de l&#8217;opinion qui y est exprim&#233;e :
positive ou n&#233;gative. Pour les besoins de cette t&#226;che, nous n&#8217;avons consid&#233;r&#233; que deux types
de critiques : celles ayant re&#231;u une note de 1 que nous avons consid&#233;r&#233;es comme n&#233;gatives, et
celles ayant re&#231;u une note de 5 que nous avons consid&#233;r&#233;es comme positives. Nous n&#8217;avons pas
chercher &#224; classer individuellement les phrases qui composent chacun des documents selon leur
polarit&#233;, bien que ce type de traitement permette g&#233;n&#233;ralement d&#8217;obtenir de meilleurs r&#233;sultats
(Pang et Lee, 2008).
</p>
<p>Comme d&#233;j&#224; mentionn&#233; nous avons utilis&#233; deux techniques d&#8217;apprentissage automatique : une
classification bas&#233;e sur la r&#233;gression logistique (en utilisant le package R glmnet) et une classifica-
tion bas&#233;e sur les Support Vector Machines (SVM). Pour cette derni&#232;re approche nous avons utilis&#233;
le programme SVMlight (Joachims, 1999). Le choix de ces m&#233;thodes est motiv&#233; par l&#8217;efficacit&#233;
reconnue des m&#233;thodes SVM d&#8217;une part, et la simplicit&#233; de la r&#233;gression logistique d&#8217;autre part.
</p>
<p>3.3 S&#233;lection de mod&#232;les et &#233;valuation
</p>
<p>Afin de reporter des estimateurs de performances non biais&#233;s et r&#233;alistes des classifieurs test&#233;s,
nous avons eu recours &#224; une proc&#233;dure de validation crois&#233;e imbriqu&#233;e. Suivant le principe de
la validation crois&#233;e, l&#8217;ensemble des N exemples est divis&#233; al&#233;atoirement en k partitions de test
de m&#234;me taille (N/k) et de m&#234;me stratification (comportant le m&#234;me nombre d&#8217;exemples de
chaque classe et de chaque source). Chaque partition de test sert &#224; l&#8217;&#233;valuation d&#8217;un classifieur
construit &#224; partir du reste des exemples du corpus (de taille N &#8722; N/k) qui forme la partition
d&#8217;apprentissage.
</p>
<p>Comme nous utilisons des algorithmes d&#8217;apprentissage param&#233;tr&#233;s (SVM et elastic net) nous
devons au pr&#233;alable avoir d&#233;termin&#233; les valeurs de ces param&#232;tres par une validation crois&#233;e
interne qui, &#224; partir de chacune de k partitions d&#8217;apprentissage, cr&#233;e m partitions de test et
d&#8217;apprentissage. Les param&#232;tres s&#233;lectionn&#233;s parmi ceux test&#233;s sont ceux qui auront permis
d&#8217;obtenir la meilleure moyenne d&#8217;une mesure de performance (d&#233;viance pour l&#8217;elastic net, F-score
pour les SVM) mesur&#233;e pour chaque partition de test de la validation crois&#233;e interne. Pour nos
exp&#233;riences nous avons choisi k = 10 et m= 5. En pr&#233;alable &#224; ces exp&#233;riences nous avons filtr&#233;
les variables pr&#233;sentes dans moins de 10 exemples dans le corpus afin de faciliter l&#8217;apprentissage
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>768 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>et l&#8217;interpr&#233;tation des mod&#232;les produits (aboutissant &#224; 2829 variables sans NEG-LEMME, 3257
avec).
</p>
<p>3.4 S&#233;lection de variable
</p>
<p>Les techniques de s&#233;lection de variables visent &#224; r&#233;duire le nombre de traits utilis&#233;s dans les
mod&#232;les produits par les techniques d&#8217;apprentissage automatique. La s&#233;lection de variable
poursuit trois objectifs reli&#233;s entre eux (Guyon et Elisseeff, 2003) :
&#8211; L&#8217;am&#233;lioration de la performance des mod&#232;les pr&#233;dicteurs.
&#8211; La mise au point de pr&#233;dicteurs plus rapides et consommant moins de ressources.
&#8211; Une meilleure compr&#233;hension des processus &#224; l&#8217;&#339;uvre dans la g&#233;n&#233;ration des donn&#233;es.
Il existe plusieurs m&#233;thodes de s&#233;lection de variable. Pour nos exp&#233;riences nous avons utilis&#233;
la r&#233;gularisation par elastic net sur un mod&#232;le de r&#233;gression logistique (Zou et Hastie, 2005) (&#224;
l&#8217;aide de la bibilioth&#232;que glmnet) pour deux raisons. D&#8217;une part, &#224; l&#8217;instar d&#8217;autres techniques
lomme le LASSO, l&#8217;elastic net produit des mod&#232;les creux en &#233;liminant les variables non essentielles
&#224; la pr&#233;diction, cependant l&#8217;elastic net inclut dans le mod&#232;le l&#8217;ensemble des variables pr&#233;dictives
m&#234;me lorsque celle-ci sont corr&#233;l&#233;es entre elles (alors que le LASSO tend &#224; n&#8217;en s&#233;lectionner
qu&#8217;une). D&#8217;autre part, l&#8217;elastic net a &#224; plusieurs reprises obtenu de meilleures performances de
pr&#233;diction que le LASSO (cf. Zou et Hastie (2005) sur des donn&#233;es issues de la biologie).
</p>
<p>Comme d&#8217;autre m&#233;thodes apparent&#233;es la r&#233;gression logistique p&#233;nalis&#233;e cr&#233;e un pr&#233;dicteur bas&#233;
sur un mod&#232;le lin&#233;aire en assignant des poids &#946;i &#224; chaque variable d&#8217;entr&#233;e (1, . . . , i, . . . , p).
Pratiquement, pour une p&#233;nalsiation elastic net le vecteur &#946; est trouv&#233; en r&#233;solvant le probl&#232;me
d&#8217;optimisation :
</p>
<p>&#946;&#770; = ar gmin
&#946;
</p>
<p>l(&#946;) +&#955;
&#65535;
1&#8722;&#945;
2
</p>
<p>||&#946; ||22 +&#945;||&#946; ||1
&#65535;
</p>
<p>o&#249; l(&#946;) est une fonction de perte &#224; minimiser et les termes suivant correspondent aux normes
1 et 2 du vecteur de coefficient &#946; par lesquelles est p&#233;nalis&#233; le probl&#232;me de minimisation. Le
coefficient &#955; d&#233;termine l&#8217;importance de la p&#233;nalisation qui contraint les coefficients &#946;i a &#224;ller
vers z&#233;ro. Le param&#232;tre &#945; d&#233;termine l&#8217;importance relative des deux normes dans la p&#233;nalisation,
quand &#945; = 1 seule la p&#233;nalisation en norme 1 est utilis&#233;e (ce qui revient au LASSO), quand &#945; = 0
seule la p&#233;nalisation en norme 2 est utilis&#233;e (ce qui revient &#224; la r&#233;gression ridge, sans s&#233;lection
de variable).
</p>
<p>3.5 R&#233;sultats
</p>
<p>Six types de mod&#232;les ont &#233;t&#233; consid&#233;r&#233;s, ceux incluant une s&#233;lection de variables (SVM et
r&#233;gression logistique) et ceux sans (SVM uniquement), avec ou sans inclusion des attributs
qualifiant la n&#233;gation. L&#8217;interpr&#233;tation de la s&#233;lection de variable a &#233;t&#233; faite &#224; partir de mod&#232;les
&#233;tabli sur l&#8217;ensemble du corpus en utilisant les param&#232;tres &#233;tablis au cours de l&#8217;&#233;valuation. Les
r&#233;sultats obtenus pour chacune des approches sont r&#233;sum&#233;s dans la table 2.
</p>
<p>Un des r&#233;sultats les plus frappants est l&#8217;absence d&#8217;impact de la d&#233;tection des environnement
n&#233;gatifs. Ce r&#233;sultat est &#233;tonnant &#233;tant donn&#233; que la n&#233;gation est pr&#233;sente dans 18,5% des
critiques n&#233;gatives contre 10,9% des critiques positives et qu&#8217;elle appara&#238;t donc comme un
param&#232;tre pr&#233;dicteur potentiellement pertinent. Par ailleurs, bien que la s&#233;lection de variables
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>769 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>N. variables Pr&#233;cision Rappel F-value
</p>
<p>SVM 2829 88.18% 89.54% 88.84
</p>
<p>SVM + n&#233;g. 3257 86.66 % 87.54% 86.77
R&#233;g. logistique + s&#233;l. elastic net 1219 88.78% 91.61% 90.16
R&#233;g. logistique + s&#233;l. elastic net + n&#233;g. 1028.7 87.77% 85.29% 86.49
SVM + s&#233;l. elastic net 1219 88.22% 90.32% 89.25
SVM + s&#233;l. elastic net + n&#233;g. 1028.7 86.92% 84.50% 85.66
</p>
<p>TABLE 2 &#8211; Classification d&#8217;opinion : r&#233;sultats
</p>
<p>n&#8217;offre pas un r&#233;el gain de performance elle a l&#8217;avantage de r&#233;duire consid&#233;rablement l&#8217;espace de
variable, et donc de permettre une meilleure interpr&#233;tation des mod&#232;les fournis.
</p>
<p>Les r&#233;sultats obtenus ne sont pas directement comparables &#224; ceux rapport&#233;s dans la campagne
DEFT&#8217;07 car nous n&#8217;avons ici pas consid&#233;r&#233; la cat&#233;gorie &#8220;neutre&#8221; utilis&#233;e dans cette campagne.
L&#8217;int&#233;gration de cette cat&#233;gorie ferait baisser les performances relev&#233;es ici. On peut toutefois
noter que nos performances se montrent sup&#233;rieures &#224; celles relev&#233;es par Pang et al. (2002)
sur une t&#226;che &#233;quivalente. Une explication &#224; cette sup&#233;riorit&#233; tient certainement d&#8217;une part &#224; la
g&#233;n&#233;ralit&#233; des mod&#232;les produits lors de l&#8217;apprentissage et &#224; l&#8217;effet du pr&#233;-traitement des textes.
</p>
<p>4 Conclusions
</p>
<p>Le travail pr&#233;sent&#233; ici a pour vocation de servir de base &#224; l&#8217;exploration pouss&#233;e du domaine
de l&#8217;analyse de sentiment en fran&#231;ais. Nous avons fourni des mesures de base pour une t&#226;che
de classification simple et montr&#233; l&#8217;int&#233;r&#234;t d&#8217;appliquer des techniques de s&#233;lection de variable
avant de proc&#233;der &#224; un apprentissage automatique. Dans le futur, nous comptons nous appuyer
sur ces premi&#232;res exp&#233;riences pour essayer d&#8217;am&#233;liorer les performances des mod&#232;les produits.
&#192; cet effet, nous pr&#233;voyons d&#8217;analyser plus en d&#233;tail le cas de la n&#233;gation et de son absence
d&#8217;effet pour la classification par SVM. Plus g&#233;n&#233;ralement, un de nos objectifs est de mesurer
l&#8217;int&#233;r&#234;t d&#8217;ajouter de l&#8217;information s&#233;mantique dans les traits retenus, notamment en exploitant le
caract&#232;re rh&#233;torique de certains &#233;l&#233;ments linguistiques. Pour cela nous nous basons notamment
sur les th&#233;ories argumentatives du discours (Anscombre et Ducrot, 1983; Winterstein, 2010).
</p>
<p>Une autre direction de recherche concerne l&#8217;interpr&#233;tation des mod&#232;les produits. Si les mod&#232;les
issus de l&#8217;utilisation de SVM sont g&#233;n&#233;ralement trop complexes pour &#234;tre interpr&#233;t&#233;s, le processus
de s&#233;lection de variable s&#8217;offre mieux &#224; l&#8217;interpr&#233;tation puisqu&#8217;il met en avant les traits les plus
pertinents pour la classification. Ainsi la s&#233;lection de variables pr&#233;sent&#233;e ici permet de confirmer
l&#8217;importance de certaines cat&#233;gories dans l&#8217;analyse d&#8217;opinion : les substantifs se retrouvent
significativement sous-repr&#233;sent&#233;s dans les critiques n&#233;gatives (45% des traits s&#233;lectionn&#233;s contre
54,1% avant s&#233;lection) au profit des adjectifs, verbes et adverbes (50,1% apr&#232;s s&#233;lection contre
44,6% avant). Par ailleurs, la s&#233;lection des connecteurs confirme les pr&#233;dictions de certaines
approches : la conjonctionmais s&#8217;av&#232;re &#234;tre un bon pr&#233;dicteur de critique n&#233;gative, alors que et est
un pr&#233;dicteur positif. En termes de strat&#233;gie argumentative (Winterstein, 2010), ces observations
valident l&#8217;hypoth&#232;se qu&#8217;une critique positive va avoir tendance &#224; pr&#233;senter plusieurs arguments
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>770 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>positifs ind&#233;pendants (reli&#233;s par et) alors qu&#8217;un seul argument n&#233;gatif, m&#234;me contre-balanc&#233;
par un positif (avec le connecteur mais), suffira &#224; produire une critique n&#233;gative. Une autre
approche dans cette perspective consiste &#224; utiliser des techniques de bootstrapping qui permettent
&#233;galement d&#8217;&#233;valuer l&#8217;importance des diff&#233;rents traits utilis&#233;s dans les processus d&#8217;apprentissage.
Ces recherches sont actuellement en cours.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ANSCOMBRE, J.-C. et DUCROT, O. (1983). L&#8217;argumentation dans la langue. Pierre Mardaga, Li&#232;ge,
Bruxelles.
</p>
<p>DAS, S. et CHEN, M. (2001). Yahoo ! for amazon : Extracting market sentiment from stock
message boards. In Proceedings of the 8th Asia Pacific Finance Association Annual Conference
(APFA 2001).
</p>
<p>DENIS, P. et SAGOT, B. (2012). Coupling an annotated corpus and a lexicon for state-of-the-art
pos tagging. Language Resources and Evaluation, 46:721&#8211;746.
</p>
<p>GHORBEL, H. et JACOT, D. (2011). Further experiments in sentiment analysis of french movie
reviews. In MUGELLINI, E., SZCZEPANIAK, P. S., PETTENATI, M. C. et SOKHN, M., &#233;diteurs : Advances
in Intelligent and Soft Computing, volume 86, pages 19&#8211;28. Springer, Berlin.
</p>
<p>GROUIN, C. et AL. (2007). Pr&#233;sentation de l&#8217;&#233;dition 2007 du d&#233;fi fouille de textes (DEFT&#8217;07). In
Actes de l&#8217;atelier de cl&#244;ture du 3&#232;me D&#233;fi Fouille de Textes (DEFT&#8217;07), pages 1&#8211;8, Grenoble, France.
</p>
<p>GUYON, I. et ELISSEEFF, A. (2003). An introduction to variable and feature selection. Journal of
Machine Learning Research, 3:1157&#8211;1182.
</p>
<p>JOACHIMS, T. (1999). Making large-scale svm learning practical. In SCH&#214;LKOPF, B., BURGES, C.
J. C. B. et SMOLA, A. J., &#233;diteurs : Advances in Kernel Methods - Support Vector Learning, pages
41&#8211;56. MIT Press.
</p>
<p>PANG, B. et LEE, L. (2008). Opinion mining and sentiment analysis. Foundations and Trends in
Information Retrieval, 2(1&#8211;2):1&#8211;135.
</p>
<p>PANG, B., LEE, L. et VAITHYANATHAN, S. (2002). Thumbs up ? sentiment classification using
machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 79&#8211;86. Association for Computational Linguistics.
</p>
<p>VERNIER, M. (2011). Analyse &#224; granularit&#233; fine de la subjectivit&#233;. Th&#232;se de doctorat, Universit&#233;
de Nantes.
</p>
<p>WILSON, T., WIEBE, J. et HOFFMANN, P. (2005). Recognizing contextual polarity in phrase-level
sentiment analysis. In Proceedings of the Human Language Technology Conference and the
Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 347&#8211;354.
WINTERSTEIN, G. (2010). La dimension probabiliste des marqueurs de discours. Nouvelles perspec-
tives sur l&#8217;argumentation dans la langue. Th&#232;se de doctorat, Universit&#233; Paris Diderot.
</p>
<p>ZOU, H. et HASTIE, T. (2005). Regularization and variable selection via the elastic net. Journal
of the Royal Statistical Society, Series B:301&#8211;320.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>771 c&#65535; ATALA</p>

</div></div>
</body></html>