TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Construction et exploitation d’un corpus francais pour
l’analyse de sentiment

Marc Vincentl Grégoire Wintersteinz
(1) UMR S-775, Université Paris Descartes
(2) LLE UMR 7110, Université Sorbonne Nouvelle
marc . r . vincent@gmai1 . com, gregoire . winterstein@1inguist . jussieu . fr

RESUME
Ce travail présente un corpus en frangais dédié a l’analyse de sentiment. Nous y décrivons la
construction et l’organisation du corpus. Nous présentons ensuite les résultats de l’application de
techniques d’apprentissage automatique pour la téiche de classiﬁcation d’opinion (positive ou
négative) Véhiculée par un texte. Deux techniques sont utilisées : la régression logistique et la
classiﬁcation basée sur des Support Vector Machines (SVM). Nous mentionnons également l’intérét
d’appliquer une sélection de variables avant la classiﬁcation (par régularisation par elastic net).

ABSTRACT
Building and exploiting a French corpus for sentiment analysis

This work introduces a French corpus for sentiment analysis. We describe the construction
and organization of the corpus. We then apply machine learning techniques to automatically
predict whether a text is positive or negative (the opinion classiﬁcation task). Two techniques are
used : logistic regression and classiﬁcation based on Support Vector Machines (SVM). Finally, we
brieﬂy evaluate the merits of applying feature selection algorithms to our models (via elastic net
regularization).

MOTS-CLEZS 2 Analyse de sentiments, Corpus, Classiﬁcation, Apprentissage automatique, Sélec—
tion de variable.

KEYWORDS: Sentiment Analysis, Corpus, Opinion Mining, Classiﬁcation, Machine Learning,
Variable Selection.

1 Introduction

Ce travail présente la construction et l’exploitation d’un corpus francais destiné a l’analyse de
sentiment (sentiment analysis ou opinion mining). L’analyse de sentiment recouvre l’ensemble
des taches dédiées a la reconnaissance des opinions exprimées au sein d’un texte et connait de
nombreuses applications (pour un panorama voir Pang et Lee (2008)).

Les recherches sur l’analyse de sentiments (ou de subjectivité) sont en majorité centrées sur
l’anglais, bien que le sujet ait déja fait l’objet de plusieurs recherches ayant abouti entre autres
a l’établissement de corpus (cf. notamment Grouin et al. (2007); Vernier (2011)). Nous avons
cependant jugé utile de construire un nouveau corpus constitué de critiques issues du web. La
motivation, la construction et la structure du corpus sont décrites en section 2.

764 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Parrni les taches relevant de l’analyse de sentiment nous nous sommes focalisés sur la classiﬁcation
d’opinion, c’est—a—dire sur la tache qui consiste a classer un texte dans une catégorie d’opinion
(typiquement positif ou négatif). Nous rapportons les résultats obtenus pour cette tache en ayant
eu recours aux Support Vector Machines (SVM). Nous rapportons également les résultats obtenus
en opérant au préalable une sélection des variables par régularisation par elastic net. Notre
méthodologie est décrite des sections 3.1 a 3.4 et nos résultats en section 3.5.

2 Construction et constitution du corpus

Les ressources nécessaires a l’analyse de sentiment doivent fournir en paralléle d’un contenu
textuel une forme d’évaluan'on du sentiment associé au texte. Avec le développement des contenus
générés par les utilisateurs sur le web, ce type de ressource peut aujourd’hui facilement s’obtenir
sur des sites web permettant aux internautes de partager leur opinion sur divers sujets. Du point
de vue qualitatif et méthodologique, un corpus regroupant ce genre de textes se doit d’étre
le plus général possible aﬁn que les modéles issus de techniques d’apprentissage soient aussi
généraux que possible. Cela signiﬁe notamment que chacune des critiques récupérées doit traiter
d’un produit différent. Les descriptions des corpus existants (p.ex.ce1ui utilisé dans la campagne
DEFT’07 ou celui utilisé par Ghorbel et Jacot (2011)) ne font pas état de la variété d’éléments
évalués dans le corpus, et il nous a donc paru pertinent de construire un nouveau corpus en
tenant compte de cette dimension.

2.1 Construction du corpus

La construction de notre corpus s’appuie sur la collecte de commentaires d’intemautes recueillis
sur différentes plate-formes web en francais et permettant aux utilisateurs d’exprimer leur
opinion par le biais d’une note chiffrée. La totalité des informations a été obtenue de maniére
automatique et non—supervisée en créant des parseurs adaptés aux sites concernés. Le corpus
obtenu est disponible sur demande auprés des auteurs.

Aﬁn de varier les themes abordés dans les critiques constituant le corpus, nous avons considéré
trois domaines différents : des critiques de ﬁlms tirées du site allocine . fr, des avis sur des
romans de poche extraits du site amazon. fr et des commentaires relatifs a des établissements
hételiers tirés du site tripadvisor.fr. Sur chacun de ces sites, les utilisateurs sont invités
a rédiger une opinion et a exprimer leur avis par une note située entre 1 et 5 (typiquement
représentée a l’écran par un nombre d’étoiles). Le nombre de commentaires par type de produit
est résumé dans le tableau ci—dessous :

Type de produit Provenance N. critiques / note
Hétels tripadvisor . fr 1000
Films allocine . fr 1000
Romans amazon. fr 800

TABLE 1 — Constitution du corpus (nombre total de textes : 14000)

La diversité de provenance des critiques est une premiere étape pour s’assurer que les modeles
765 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

produits par les algorithmes d’apprentissage ne se montreront pas trop liés au idiosyncrasies du

corpus. Outre la diversité de provenance, nous nous sommes également assurés que :

— Le nombre de produits distincts représentés dans chaque plage de notation soit maximal.
Dans le cas des romans et des ﬁlms, ce nombre est égal au nombre de critiques, c’est—a—dire
qu’un produit donné fait l’objet d’au plus une critique pour chacune des 5 notes. Dans le cas
des établissements hoteliers cette ventilation ne s’est pas montrée possible, nous avons donc
cherché a limiter le nombre de répétitions. Au ﬁnal, aucun produit ne se trouve mentionné
plus de 5 fois par plage de note dans le corpus.

— Les auteurs de critiques soient aussi différents que possible au sein des critiques d’une meme
plage de notation. S’il n’a pas été possible de s’assurer que chacune des critiques ait un auteur
distinct des autres, le nombre de critiques signées d’un méme auteur au sein d’une méme plage
de notation est de 12.1

Ces deux précautions permettent d’éviter que des modeles produits par des algorithmes d’appren—

tissage perdent en généralité en étant trop dépendant des spéciﬁcités propres a certains items ou

auteurs fréquemment répétés.

Les possibilités de notation offertes par les p1ates—formes marchandes vont aujourd’hui au—dela
de l’appariement d’une note a un texte. C’est pourquoi, outre la note attribuée et le contenu du
commentaire utilisateur, nous avons cherché a conserver la totalité des informations disponibles
et pertinentes pour différentes taches d’analyse de sentiment. Chacune des critiques utilisateurs
est alors accompagnée des informations suivantes (le corpus est organisé dans un format XML) :2
— Identiﬁant de la critique.

Identiﬁant du produit (sous forme d’entier).

Descriptif du produit (type de produit et titre de ﬁlm, nom de 1’h6te1 ou titre de roman).
Note associée a la critique (fournie par l’auteur de la critique).

Identiﬁant (anonymisé) de l’auteur de la critique

Contenu de la critique

Dans les parties relatives 51 tripadvisor et amazon on trouve de plus pour chaque critique
individuelle :

— Le résumé de la critique (en une phrase) fourni par 1’uti1isateur.

— Une mesure “d’utilité” de la critique, indiquée par le nombre d’utilisateurs ayant jugé la critique

utile.

Enﬁn, dans la partie des critiques issues de tripadvisor, on inclut également des informations
de notation sur des criteres spéciﬁques. Par exemple certains utilisateurs notent la propreté des
chambres ou le rapport qua1ité/ prix de 1’h6te1 (toujours sur une note de 1 a 5).

Au ﬁnal, la longueur totale du corpus, en nombre de termes différents reconnus par segmentation
automatique (en utilisant le tokenizer de MElt, cf. infra) est de 1 402 867 tokens. La longueur
moyenne d’une critique est de 100 tokens, les critiques d’établissements hoteliers se montrant
globablement plus longues (123 tokens en moyenne) que celles de ﬁlms (90 tokens) ou de
romans (83 tokens).

1. La plage de notation en question est celle correspondant a une note de 2 sur 5 pour les critiques de ﬁlms. Cette
plage de notation s’avere séverement sous-représentée de maniere générale sur le site allocine . fr. En excluant cette
plage spéciﬁque, le nombre maximal de répétitions par auteur dans le corpus est de 5.

2. Les informations récupérées n’ont pas fait l’objet de validation subséquente, notamment sur l’adéquation des notes
indiquées par les utilisateurs avec le contenu de leur critique. Cependant, nous avons effectué une extraction aléatoire
de 150 critiques notées 1 ou 5 que nous avons manuellement annotées en “positif” et “négatif”. Sur les 150, une seule
erreur a été relevée, montrant que les données utilisées ultéiieurement dans la téche de classiﬁcation sont ﬁables.

766 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
3 Classiﬁcation d’opinion par apprentissage automatique

En guise d’illustration de l’emploi du corpus construit, nous nous focalisons sur la tache de
classiﬁcation automatique d’opinion. Cette tache est une des premieres qui ait été abordée dans
le domaine de l’opinion mining (Pang et al., 2002) et il nous est apparu pertinent de fournir un
étalon relatif au corpus que nous utilisons. Il est important de noter que cette tache ne fait pas
appel a la totalité des informations offertes par le corpus : d’autres taches potentiellement plus
complexes peuvent par exemple faire usage des indicateurs d’utilité associés aux critiques. Un de
nos buts est avant tout de fournir des mesures de bases associées au corpus. Comme mentionné
précédemment, des taches similaires ont déja été entreprises, mais sur des corpus dont le
caractére général n’est pas assuré. Outre de fournir ces mesures, nous voulons également mesurer
l’intérét d’appliquer des techniques de réduction de variable avant les phases d’apprentissage
automatique.

Pour aborder la tache de classiﬁcation automatique nous avons utilise’ deux types d’approches :
une classiﬁcation basée sur des SVM, et une autre basée sur la régression logistique a l’issue de
la sélection de variable. Pour chacune de ces taches, les critiques ont été au préalable segmentée,
étiquetée et lemmatisée. Du fait du marquage morphologique relativement riche du francais
cette étape est apparue nécessaire pour optimiser les performances des modeles produits. Pour
cette étape nous nous sommes basés sur l’étiqueteur et lemmatiseur MElt (Denis et Sagot, 2012)
dont les performances pour le francais sont l’état de l’art et qui emploie un module de gestion de
“crappy text” qui permet de corriger un certain nombre des irrégularités typiquement trouvées
dans les contenus récupérés sur le web.

3. 1 Traits

Pang et al. (2002) ont observé que pour la tache de classiﬁcation d’opinion, la facon la plus
efﬁcace de décrire un texte était sous forme de “sac de mots”, c’est—a—dire d’un vecteur a valeurs
booléennes, indiquant la présence et l’absence d’un élément lexical. Cette méthode s’avere plus
efﬁcace que d’encoder le nombre d’occurrences de chaque unigramme et meilleure que d’uﬁliser
une description en termes de combinaisons d’unigrammes et de bigrammes.

Nous avons suivi ici leurs recommandations pour encoder nos données. Suite au processus de
lemmaﬁsation précédemment mentionné, nous avons retenu uniquement les lemmes qui avaient
été reconnus par MElt et nous avons encodé chacune des critiques sous forme d’un vecteur
encodant l’absence ou la présence d’un lemme (repéré par une combinaison de forme et de partie
du discours, p.ex. a.ndalou/ ADJ ). Nous avons sciemment omis de considérer les éléments non
reconnus et ceux catégorisés comme noms propres : la prise en compte de ces éléments aurait fait
baisser la généralité des modeles produits et nettement augmenté la taille de l’espace des traits
(sur le corpus entier on dénombre 12 300 traits ainsi retenus contre 26 765 si tous les lemmes
avaient été pris en compte).

La prise en compte de la présence d’une négation est tradiﬁonnellement considérée comme un
indicateur pertinent pour la classiﬁcation d’opinion. Usuellement, cette prise en compte se fait
sous la forme d’un dédoublement des lemmes pris en compte : si un lemme se trouve sous la
portée d’une négation dans la phrase, il sera encodé sous la forme d’un trait NEG—LEMME. Aﬁn
de mesurer l’impact de cette prise en compte, nous n’avons pas inclus la négation dans nos

767 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

expériences de base, et en évaluons séparement l’intérét. L’algorithme de détecﬁon de la présence
de ne’gation est basique et en partie inspire’ de celui de Das et Chen (2001). Aﬁn d’étiqueter un
lemme négativement nous avons :

— utilisé un chunk parser minimal (implémenté en nltk) pour identiﬁer des structures négaﬁves

(p.ex. des verbes accompagnés d’un marqueur de négation),

— étiqueté tout élément situé a droite de la frontiere gauche de ces constituants comme négatif.
On pourrait rafﬁner cette approche en utilisant un analyseur syntaxique en dépendances ou bien
en utilisant un lexique de polarité (sur le modele de Wilson et al. (2005)), mais nous réservons
ces manipulations a une recherche future.

3.2 La tache de classiﬁcation d’opinion

Pour la premiere exploitation du corpus, nous avons choisi une tache simple de classiﬁcation
d’opinion dans la lignée de celle entreprise par Pang et al. (2002). Le but de la tache est donc de
classer des documents (les critiques de produits) selon la polarité de l’opinion qui y est exprimée :
positive ou négative. Pour les besoins de cette tache, nous n’avons considéré que deux types
de critiques : celles ayant recu une note de 1 que nous avons considérées comme négatives, et
celles ayant recu une note de 5 que nous avons considérées comme positives. Nous n’avons pas
chercher a classer individuellement les phrases qui composent chacun des documents selon leur
polarité, bien que ce type de traitement permette généralement d’obtenir de meilleurs résultats
(Pang et Lee, 2008).

Comme déja mentionné nous avons utilisé deux techniques d’apprentissage automatique : une
classiﬁcaﬁon basée sur la régression logistique (en utilisant le package R glmnet) et une classiﬁca-
ﬁon basée sur les Support Vector Machines (SV1\/I). Pour cette derniere approche nous avons utilisé
le programme SVM“3h‘ (Joachims, 1999). Le choix de ces méthodes est motivé par l’efﬁcacité
reconnue des méthodes SVM d’une part, et la simplicité de la régression logistique d’autre part.

3.3 Sélection de modéles et évaluation

Aﬁn de reporter des estimateurs de performances non biaisés et réalistes des classiﬁeurs testés,
nous avons eu recours a une procédure de Validation croisée imbriquée. Suivant le principe de
la validation croisée, l’ensemble des N exemples est divisé aléatoirement en k partitions de test
de méme taille (N / k) et de méme stratiﬁcation (comportant le méme nombre d’exemples de
chaque classe et de chaque source). Chaque partition de test sert a l’évaluation d’un classiﬁeur
construit a partir du reste des exemples du corpus (de taille N — N / k) qui forme la partition
d’apprentissage.

Comme nous utilisons des algorithmes d’apprentissage paramétrés (SVM et elastic net) nous
devons au préalable avoir déterminé les valeurs de ces paramétres par une validation croisée
interne qui, a partir de chacune de k partitions d’apprentissage, crée m partitions de test et
d’apprentissage. Les paramétres sélectionnés parmi ceux testés sont ceux qui auront permis
d’obtenir la meilleure moyenne d’une mesure de performance (déviance pour l’elasu'c net, F—score
pour les SVM) mesurée pour chaque partition de test de la validation croisée interne. Pour nos
expériences nous avons choisi k = 10 et m = 5. En préalable a ces expériences nous avons ﬁltré
les variables présentes dans moins de 10 exemples dans le corpus aﬁn de faciliter l’apprenu'ssage

768 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

et l’interprétation des modeles produits (aboutissant a 2829 variables sans NEG—LEMME, 3257
avec).

3.4 Sélection de variable

Les techniques de sélection de variables visent a réduire le nombre de traits utilisés dans les
modeles produits par les techniques d’apprentissage automatique. La sélection de variable
poursuit trois objectifs reliés entre eux (Guyon et Elisseeff, 2003) :

— L’améliorau'on de la performance des modéles prédicteurs.

— La mise au point de prédicteurs plus rapides et consommant moins de ressources.

— Une meilleure compréhension des processus a l’oeuvre dans la génération des données.

Il existe plusieurs méthodes de sélection de variable. Pour nos expériences nous avons utilisé
la régularisation par elastic net sur un modele de régression logistique (Zou et Hastie, 2005) (a
l’aide de la bibiliothéque glmnet) pour deux raisons. D’une part, a l’instar d’autres techniques
lomme le LASSO, l’elastic net produit des modéles creux en éliminant les variables non essentielles
a la prédiction, cependant 1’elastic net inclut dans le modéle l’ensemble des variables prédictives
méme lorsque celle—ci sont corrélées entre elles (alors que le LASSO tend a n’en sélectionner
qu’une). D’autre part, l’elastic net a a plusieurs reprises obtenu de meilleures performances de
prédiction que le LASSO (cf. Zou et Hastie (2005) sur des données issues de la biologie).

Comme d’autre méthodes apparentées la régression logistique pénalisée crée un prédicteur basé
sur un modele linéaire en assignant des poids [ii a chaque variable d’entrée (1, . . ., i, . . ., p).
Pratiquement, pour une pénalsiation elastic net le vecteur [3 est trouvé en résolvant le probléme
d’optimisation :

/3 =argﬂmin z<m+A (1;°‘IImI§+aIImI1)

ou l([3) est une fonction de perte a minimiser et les termes suivant correspondent aux normes
1 et 2 du vecteur de coefficient [3 par lesquelles est pénalisé le probleme de minimisation. Le
coefficient A détermine l’importance de la pénalisation qui contraint les coefﬁcients [ii a aller
vers zéro. Le paramétre a détermine l’importance relative des deux normes dans la pénalisation,
quand a = 1 seule la pénalisation en norme 1 est utilisée (ce qui revient au LASSO), quand a = 0
seule la pénalisation en norme 2 est utilisée (ce qui revient a la régression ridge, sans sélection
de variable).

3.5 Résultats

Six types de modeles ont été considérés, ceux incluant une sélection de variables (SVM et
régression logistique) et ceux sans (SVM uniquement), avec ou sans inclusion des attributs
qualiﬁant la négation. L’interprétation de la sélection de variable a été faite a partir de modéles
établi sur l’ensemble du corpus en utilisant les paramétres établis au cours de l’éValuation. Les
résultats obtenus pour chacune des approches sont résumés dans la table 2.

Un des résultats les plus frappants est l’absence d’impact de la détection des environnement
négatifs. Ce résultat est étonnant étant donné que la négation est présente dans 18,5% des
critiques négatives contre 10,9% des critiques positives et qu’elle apparait donc comme un
paramétre prédicteur potentiellement pertinent. Par ailleurs, bien que la sélection de Variables

769 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

N. variables Précision Rappel F—value

SVM 2829 88.18% 89.54% 88.84
SVM + nég. 3257 86.66 % 87.54% 86.77
Rég. logisﬁque + sél. elastic net 1219 88.78% 91.61% 90.16
Rég. logisﬁque + sél. elastic net + nég. 1028.7 87.77% 85.29% 86.49
SVM + sél. elastic net 1219 88.22% 90.32% 89.25
SVM + sél. elastic net + nég. 1028.7 86.92% 84.50% 85.66

TABLE 2 — Classiﬁcation d’opinion : résultats

n’offre pas un réel gain de performance elle a l’avantage de réduire considérablement l’espace de
variable, et donc de permettre une meilleure interprétation des modeles fournis.

Les résultats obtenus ne sont pas directement comparables a ceux rapportés dans la campagne
DEFT’07 car nous n’avons ici pas considéré la catégorie “neutre” utilisée dans cette campagne.
L’intégration de cette catégorie ferait baisser les performances relevées ici. On peut toutefois
noter que nos performances se montrent supérieures a celles relevées par Pang et al. (2002)
sur une tache équivalente. Une explication a cette supériorité tient certainement d’une part a la
généralité des modeles produits lors de l’apprentissage et a l’effet du pré—traitement des textes.

4 Conclusions

Le travail présenté ici a pour vocation de servir de base a l’exploration poussée du domaine
de l’analyse de sentiment en frangais. Nous avons fourni des mesures de base pour une tache
de classiﬁcation simple et montré l’intérét d’appliquer des techniques de sélection de variable
avant de procéder a un apprentissage automatique. Dans le futur, nous comptons nous appuyer
sur ces premieres expe’riences pour essayer d’améliorer les performances des modeles produits.
A cet effet, nous prévoyons d’analyser plus en détail le cas de la négation et de son absence
d’effet pour la classiﬁcation par SVM. Plus généralement, un de nos objectifs est de mesurer
l’intérét d’ajouter de l’information sémantique dans les traits retenus, notamment en exploitant le
caractere rhétorique de certains éléments linguistiques. Pour cela nous nous basons notamment
sur les théories argumentatives du discours (Anscombre et Ducrot, 1983; Winterstein, 2010).

Une autre direction de recherche concerne l’interprétation des modéles produits. Si les modeles
issus de l’uu'lisation de SVM sont généralement trop complexes pour étre interprétés, le processus
de sélection de variable s’offre mieux a l’interprétation puisqu’il met en avant les traits les plus
perﬁnents pour la classiﬁcation. Ainsi la sélecﬁon de variables présentée ici permet de conﬁrmer
l’importance de certaines catégories dans l’analyse d’opinion : les substantifs se retrouvent
signiﬁcaﬁvement sous—représentés dans les critiques négaﬁves (45% des traits sélectionnés contre
54,1% avant sélection) au proﬁt des adjectifs, verbes et adverbes (50,1% apres sélection contre
44,6% avant). Par ailleurs, la sélection des connecteurs conﬁrme les prédictions de certaines
approches : la conjoncﬁon mais s’avere étre un bon prédicteur de critique négaﬁve, alors que et est
un prédicteur positif. En termes de stratégie argumentative (Winterstein, 2010), ces observations
valident l’hypothese qu’une critique positive va avoir tendance a presenter plusieurs arguments

770 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

positifs indépendants (reliés par et) alors qu’un seul argument négatif, méme contre-balancé
par un positif (avec le connecteur mais), sufﬁra a produire une critique négative. Une autre
approche dans cette perspective consiste a utiliser des techniques de bootstrapping qui permettent
également d’éva1uerl’importance des différents traits utilisés dans les processus d’apprenu'ssage.
Ces recherches sont actuellement en cours.

Références

ANSCOMBRE, J.-C. et DUCROT, O. (1983). Ifargumentation dans la langue. Pierre Mardaga, Liege,
Bruxelles.

DAS, S. et CHEN, M. (2001). Yahoo! for amazon : Extracting market sentiment from stock
message boards. In Proceedings of the 8th Asia Pacific Finance Association Annual Conference
(APFA 2001).

DEN1s, R et SAGOT, B. (2012). Coupling an annotated corpus and a lexicon for state—of—the—art
pos tagging. Language Resources and Evaluation, 46:721-746.

GHORBEL, H. et JACOT, D. (2011). Further experiments in sentiment analysis of french movie
reviews. In MUGELLINI, E., SZCZEPANIAK, R S., PETTENATI, M. C. et SOKHN, M., éditeurs :Advances
in Intelligent and Soft Computing, volume 86, pages 19-28. Springer, Berlin.

GROUIN, C. et AL. (2007). Présentation de l’édition 2007 du déﬁ fouille de textes (DEFT’07). In
Actes de l’atelier de cléture du 3éme De’ﬁ Fouille de Textes (DEFT’07), pages 1-8, Grenoble, France.

GUYON, I. et ELISSEEFF, A. (2003). An introduction to variable and feature selection. Journal of
Machine Learning Research, 321157-1182.

JoAcHIMs, T. (1999). Making large—scale svm learning practical. In ScHoLKo1>E, B., BURGES, C.
J. C. B. et SMOLA, A. J., éditeurs : Advances in Kernel Methods - Support Vector Learning, pages
41-56. MIT Press.

PANG, B. et LEE, L. (2008). Opinion mining and sentiment analysis. Foundations and Trends in
Information Retrieval, 2(1—2):1—135.

PANG, B., LEE, L. et VAITHYANATHAN, S. (2002). Thumbs up? sentiment classiﬁcation using
machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 79-86. Association for Computational Linguistics.

VERNIER, M. (2011). Analyse c‘1 granularite’ ﬁne de la subjectivite’. These de doctorat, Université
de Nantes.

WILSON, 'I‘., WIEBE, J . et HOFFMANN, P (2005). Recognizing contextual polarity in phrase—leve1
sentiment analysis. In Proceedings of the Human Language Technology Conference and the
Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 347-354.

WINTERSTEIN, G. (2010). La dimension probabiliste des marqueurs de discours. Nouvelles perspec-
tives sur l’argumentation dans la langue. These de doctorat, Université Paris Diderot.

ZOU, H. et HASTIE, T. (2005). Regularization and variable selection via the elastic net. Journal
of the Royal Statistical Society, Series B:301—320.

771 © ATALA

