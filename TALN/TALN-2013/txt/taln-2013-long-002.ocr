TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Apprentissage symbolique et statistique pour le chunking:
comparaison et combinaisons

Isabelle Tellier, Yoann Dupont
Laboratoire Lattice, 1 rue Maurice Arnoux, 92320 Montrouge
isabelle.tellier@univ-paIis3.fr, yoa.dupont©gmail.com

RESUME
Nous décrivons dans cet article l’utilisation d’a1gorithmes d’inférence grammaticale pour la tache
de chunking, pour ensuite les comparer et les combiner avec des CRF (Conditional Random
Fields), a l’efﬁcacité éprouvée pour cette tache. Notre corpus est extrait du French TreeBank.
Nous proposons et évaluons deux manieres différentes de combiner modele symbolique et modele
statistique appris par un CRF et montrons qu’ils bénéﬁcient dans les deux cas l’un de l’autre.

ABSTRACT
Symbolic and statistical learning for chunking : comparison and combinations

We describe in this paper how to use grammatical inference algorithms for chunking, then
compare and combine them to CRFs (Conditional Random Fields) which are known efficient for
this task Our corpus is extracted from the FrenchTreebank. We propose and evaluate two ways
of combining a symbolic model and a statistical model learnt by a CRF; and show that in both
cases they beneﬁt from one another.

MOTS-CLES : apprentissage automatique, chunking, CRE inférence grammaticale, k—RI, French
TreeBank.

KEYWORDS: machine learning, chunking, CRE grammatical inference, k-RI, French TreeBank.

1 Introduction

L’apprenu'ssage automatique supervisé, surtout lorsqu’une grande quantité de données annotées
est disponible, a largement prouvé son efﬁcacité pour les taches de fouille de textes classiques
comme la classiﬁcation ou l’annotau'on. Les bases théoriques des techniques d’apprenu'ssage les
plus perforrnantes relévent en général des statistiques (Naive Bayes), de l’opu'misau'on (SVM) ou
des deux (HMM, CRF). L’inconvénient principal des modeles produits par ces méthodes est qu’ils
sont difficilement lisibles par un humain.

Il existe pourtant aussi d’autres branches de l’apprentissage automatique, qualiﬁées de symbolique,
qui ont la particularité d’offrir une sortie généralement plus lisible par un étre humain. Les plus
illustres membres de cette famille sont les arbres de décision, la Programmation Logique Inductive
(PLI) ou l’Inférence Grammaticale (IG par la suite) (de la Higuera, 2010). C’est cette derniere qui
nous intéresse ici. On peut la déﬁnir comme l’étude des techniques perrnettant d’apprendre une
grammaire forrnelle ou tout autre modele capable de représenter un langage (comme un automate,
une expression réguliere, etc...) a partir d’exemples de séquences (éventuellement enrichies)

19 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

appartenant (ou non) a ce langage. Ce domaine, qui a son origine dans 1’inforInau'que théorique
et la théorie des langages formels, est souvent méconnu. Les algorithmes d’IG sont en effet
réputés ne pas tres bien se comporter sur des données réelles : ils sont souvent algorithmiquement
complexes, sensibles aux erreurs et peu adaptés aux langages fondés sur de grands alphabets (ce
qui est le cas quand l’a1phabet est l’ensemb1e des mots d’une langue naturelle).

Dans cet article, nous voulons donner leur chance a des algorithmes classiques d’IG pour les
comparer aux méthodes d’apprentissage automatique statistique état de l’art, en l’occurrence
les CRF (Lafferty et al., 2001). La tache considérée est le chunking (Abney, 1991) du francais,
qui peut en effet trés bien étre réalisée a l’aide d’automates construits manuellement (Antoine
et al., 2008; Blanc et al., 2010). A notre connaissance, essayer d’apprendre automatiquement ces
automates au lieu de les écrire a la main n’a encore pas jamais été testé, pour quelque langue que
ce soit. Par ailleurs, le chunking peut également étre vu comme une tache d’annotau'on (objet de
la Shared Task CoNLL’2000) et de ce fait abordé via des méthodes d’apprentissage statistique. Ce
contexte nous semblait par conséquent idéal pour comparer les deux approches.

Cette comparaison n’est cependant pas notre seul but. Notre intuition est que les deux tech-
niques sont complémentaires car elles se concentrent sur des propriétés distinctes des données
d’apprentissage. Nous proposons donc également dans cet article deux manieres différentes de
les combiner, en fonction du but visé. La premiere maniere est orientée vers l’efﬁcacité : elle vise
a enrichir un modele CRF a l’aide d’informations extraites des automates. La seconde privilégie
la lisibilité : elle propose d’analyser1es automates appris par 1G a l’aide de poids calculés par un
CRE poids qui seront tous interprétables relativement a cet automate.

L’article suit le plan suivant. Dans la premiere section, nous introduisons la tache de chunking et
décrivons les données utilisées pour nos expériences. La deuxieme section est dédiée a l’inférence
grammaticale. Apres un bref état de l’art, nous détaillons la famille des algorithmes k—RI (Angluin,
1982) et donnons les meilleurs résultats expérimentaux qu’ils permettent d’atteindre pour le
chunking. Dans la section qui suit, nous appliquons les CRF a la méme tache. Comme on pouvait
s’y attendre, les CRF donnent de bien meilleurs résultats que ceux obtenus par IG. Dans la
derniere section, nous décrivons et évaluons deux manieres de combiner automates et CRE Les
résultats obtenus pour chacune de ces combinaisons sont prometteurs et suggérent des pistes
originales pour associer modeles symboliques et apprentissage statistique.

2 Chunking: la téiche et les données

Nous décrivons ici la tache de chunking par annotation et nous présentons les données
d’apprentissage que nous avons utilisées pour nos expériences. Ces derniéres reprennent et
prolongent celles présentées dans (Tellier et al., 2012). Notre but étant de construire un chunker
pour le francais, nous sommes partis du French Tree Bank (Abeillé et al., 2003).

2. 1 La tache

La tache de chunking, également appelée analyse syntaxique de surface, a pour but d’identiﬁer les
groupes syntaxiques élémentaires des phrases. Les chunks sont en effet des se'quences contigiies et
non—re’cursives d’unite's lexicales lie'es c‘z une unique téte forte (Abney, 1991). Chacun est caractérisé

20 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

par le type (ou étiquette Part—Of—Speech (POS)) de sa téte. 11 y a ainsi autant de types de chunks
que de types de tétes fortes possibles.

La tache de chunking a fait l’objet de de la compétition CoNLL’20001, dont le corpus
d’apprentissage était constitué d’environ 9 000 phrases issues du Penn Treebank, associées
a deux niveaux d’annotion : un niveau POS donné par l’étiqueteur Brill et un de chunking. Les
vainqueurs avaient utilisé des SVM et des “Weighted Probability Distribution Voting”. Ce meme
corpus a aussi servi plus tard a montrer l’efﬁcacité des CRF (Sha and Pereira, 2003).

2.2 Les données

9)

Le French TreeBank (FTB) est un recueil de phrases extraites d’articles du journal “Le Monde
publiés entre 1989 et 1993 (Abeillé et al., 2003). Les phrases ont été tokenisées (en conservant
certaines unités mu1ti—mots), lemmatisées, étiquetées et analysées syntaxiquement. I1 existe
plusieurs variantes du FTB, celle que nous avons utilisée contenait environ 8 600 arbres XML
enrichis de fonctions syntaxiques (parfois nécessaires pour identiﬁer certains chunks). Pour le
POS, nous avons repris les 30 étiquettes morpho-syntaxiques déﬁnies dans (Crabbé and Candito,
2008), assurant ainsi la continuité avec nos précédents travaux (Constant et al., 2011).

Nous considérons 7 types de chunks distincts : AP (Adjectival Phrase), AdP (Adverbial Phrase),
CONJ (Conjonctions), NP (Noun Phrase), PP (Prepositional Phrase), VP (verbal Phrase) et
UNKONWN (coquilles ou certains mots étrangers, eux—mémes étiquetés UNKNOWN). Les marques
de ponctuations, sauf exceptions (certains guillemets par exemple) sont hors chunks (étiquette
O comme Out). Nous avons décidé de modiﬁer certains choix que nous avions faits dans
(Tellier et al., 2012). Par exemple, le chunk CONJ contient seulement la conjonction. Le PB en
revanche, integre toujours le chunk introduit par la préposition. Et, a l’inverse de (Paroubek
et al., 2006), les adjectifs épithétes appartiennent toujours au chunk NP contenant le nom qu’ils
qualiﬁent, qu’ils soient situe’s avant ou apres lui. Les chunks AP sont donc assez rares car ils ne
correspondent qu’aux adjectifs séparés d’un groupe nominal, comme les attributs du sujet ou de
l’objet (les fonctions syntaxiques disponibles dans les arbres XML sont nécessaires pour identiﬁer
ces derniers). La phrase suivante illustre notre notion de parenthésage en chunksz :

(la/DET dépréciation/NC)NP (par_rapport_au/P dollar/NC)“, (a/V été/VPP limitée/VPP)VP
(£1/P 2,5/DET %/NC)“,

Nous avons extrait du FTB deux corpus distincts, chacun représentant un chunking différent :

0 un corpus ou tous les chunks sont extraits et étiquetés selon le modéle BIO (Begin/ In/ Out).
Les proportions de chaque type de chunk trouvées dans le corpus sont les suivantes : PP : 33,86%,
AdP : 7,23%, VP : 17,11%, AP : 2,21%, NP : 32,95%, CONJ : 6,61%, UNKNOWN : 0,03%.

0 un corpus o1‘1 seuls les NP sont étiquetés, tout autre groupe étant alors considéré 0. Ce
corpus n’est pas un sous—ensemb1e du précédent : par exemple, de nombreux PP incluent un NP
qui ne devient visible que dans ce deuxieme corpus. L’exemple précédent devient ainsi :
(la/DET dépréciation/ NC) Np par_rapport_au/ P (dol1ar/ NC) Np a/V été/VPP limitée/VPP a/ P
(2,5/DET %/NC)Np

1http://wwwcnts.ua.be/conl12000/chunking
zguide complet disponible sur : http : //www . lattice . cnrs . fr/sites/itellier/guide .htm1

21 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
3 L’inférence grammaticale

L’inférence grammaticale (IG) est un domaine de recherche tres riche apparu dans les années 60
dont il n’est, par conséquent, pas aisé de faire un résumé. Nous nous placons ici dans le cadre
de l’IG d’automates par exemples positifs seuls. Aprés un bref état de l’art, nous décrivons les
algorithmes k-RI (Angluin, 1982) utilisés dans nos expériences et les résultats obtenus avec eux.

3.1 Bref état de l’art

L’IG étudie les différentes maniéres d’apprendre automatiquement un dispositif symbolique
capable de représenter un langage (comme une grammaire formelle, un automate, etc...) a partir
d’un ensemble de séquences (parfois enrichies) regroupées selon leur (non-)appartenance a ce
langage (de la Higuera, 2010). Lorsque seules des séquences appartenant au langage cible sont
disponibles, le probleme est appelé IG par présentation positive. Nous nous situons dans ce cadre
car les séquences 2 notre disposition ne comportent aucun contre—exemple. L’IG est, dans ce cas,
notoirement plus difﬁcile car, sans contre-exemple, on risque la surgénéralisation. Par exemple, si
un programme d’IG fait l’hypothese, lors de sa phase d’apprentissage, que le langage a apprendre
est le langage universel (Z}*, ou Z} est l’alphabet du langage), aucun exemple positif n’est en
mesure de le contredire, alors meme qu’il a peut—étre surgénéralisé.

La premiere chose que l’IG se doit de fournir est une déﬁnition précise de ce qu’ “apprendre
une langue par exemples positifs” signiﬁe pour un programme. Le critére d’apprenabilité est
théorique et formel et non pas empirique. Faisons le paralléle avec l’acquisition du langage
chez les enfants. Un enfant n’est pas “programmé” pour une langue précise, il est capable
d’acquérir n’importe laquelle parlée dans son environnement. De méme, un programme d’IG par
présentation positive doit étre en mesure d’apprendre une classe de langages formels, c’est—a—dire
d’identiﬁer n’importe lequel de ses membres a l’aide d’exemples de séquences (phrases) lui
appartenant. Les principaux criteres possibles qui caractérisent la notion d”’apprenabilité d’une
classe de langages” en IG (aussi appelés modeles d’apprentissage) sont “l’identiﬁcation a la limite”
(Gold, 1967) et “1’apprentissage PAC” (Valiant, 1984), que nous ne pouvons détailler ici.

Malheureusement, méme pour la classe des langages réguliers, la plus simple dans la hiérarchie
de Chomsky, ces critéres sont impossibles a satisfaire : il n’existe aucun algorithme capable
d’apprendre par présentation positive la classe complete des langages réguliers dans ces modeles
(Gold, 1967; Keams and Vazirani, 1994). Les recherches se sont donc orientées vers des classes
plus petites, ou transverses a la hiérarchie de Chomsky, et apprenables, caractérisées notamment
dans (Angluin, 1980). Les classes de langages k—réversibles (Angluin, 1982) entrent dans ce
cadre, elles constituent le point de départ de nos expériences. Depuis, bien d’autres classes
apprenables par présentation positive ont été décrites et étudiées (Garcia and Vidal, 1990; Denis
et al., 2002; Kanazawa, 1998; Koshiba et al., 2000; Yokomori, 2003). Des avancées récentes
dans le domaine concement aussi l’apprenabilité de dispositifs intégrant des probabilités, comme
les automates probabilistes et leurs liens avec les HHM (Thollard et al., 2000; Dupont et al.,
2005). Parallelement, des compétitions 3 ont permis de tester l’efﬁcacité des algorithmes proposés
lorsqu’i1s sont confrontés a des données réelles.

3les plus récents étant Stamina (http : //stamina . chefbe . net) et Zulu (http : //1abh— curien .
univ— st— etienne . fr/zulu)

22 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
3.2 L’algorithme k-RI

Dans cette section, nous décrivons les algorithmes d’IG par présentation positive utilisés dans
nos expériences. Ils sont destinés a apprendre un automate pour un type spéciﬁque de chunk, a
partir uniquement des différentes séquences de POS aparaissant dans ce type de chunks dans
les données d’apprentissage. Les algorithmes d’IG par exemples positifs semblent adaptés a ce
probleme en raison du vocabulaire restreint mis en jeu (au maximum les 30 étiquettes POS) et
de la relativement faible variabilité des séquences de POS pouvant décrire un méme chunk.

L’algorithme k—Reversib1e Inference (k-RI) (Angluin, 1982) a la propriété d’identiﬁer a la limite
tout langage k—réversib1e, pour tout k E N fixé. Les langages k—réversib1es sont réguliers, ils sont
donc représentables par des automates ﬁnis. Un automate ﬁni déﬁnit un langage k—réversible
s’i1 est déterministe et si son miroir 4 est déterministe avec anticipation k. Pour k = 0, les
langages 0—réversibles peuvent étre représentés par un automate déterministe dont 1e miroir1’est
également, l’algorithme correspondant étant appelé Zéro Réversible (ZR). Si kl < k2, la classe
des langages k1—réversib1es est strictement incluse dans celle des langages k2—réversibles.

Soit un ensemble de séquences positives S, la premiere étape de k—RI est de construire P'I‘A(S),
le Preﬁx Tree Acceptor de S. PTA(S) est le plus petit (en nombre d’états) AFD (Automate Fini
Déterministe) en forme d’arbre reconnaissant exactement le langage S. La racine de PTA(S)
est son état initial. L’espace de recherche de tout algorithme d’IG partant de S est un trelli
dont la borne inférieure est PTA(S) et la borne supérieure l’automate universel construit sur
l’alphabet observé dans S (Dupont et al., 1994). La plupart des algorithmes d’IG suivent le
meme schéma : ils partent de P'I‘A(S) pour ensuite généraliser le langage déﬁni par fusions
d’états, la connaissance de k permettant d’éviter la surgénéralisation. k—RI, détaillé ci—dessous,
fonctionne selon ce principe. La fusion qu’il emploie est appelée déterministe car elle se propage
récursivement a travers l’automate pour préserver son déterminisme.

Algorithme k-RI
Entrée :S : un ensemble de séquences (positives), k : un entier naturel ;
Sortie : A : un automate k-réversible ;
début
A := PTA(S);
tant que non (A k—réversib1e) faire
// soient N1 et N2 deux noeuds empéchant la k—re’versibilite’ de A.
Fusion_Déterministe(A, N1, N2);
fin tant que;
renvoyer A;
ﬁn k—RI;

Dans la ﬁgure 1, nous illustrons le comportement de ZR (k-RI pour k = 0) sur les séquences de
POS suivantes : S = {DE T NC, DE T ADJ NC}. Sur cet exemple tres simple, nous voyons que
ZR généralise PTA(S) pour obtenir un automate reconnaissant 1e langage déﬁni par l’expression
réguliere : DE T ADJ * NC. Cette généralisation est sensée d’un point de vue linguistique. Mais
si on ajoute aux exemples précédents la simple séquence NC, alors ZR mene a un automate
reconnaissant le langage {DE T|ADJ }*N C, ce qui est une généralisation plus discutable.

4l’automate miroir est obtenu en transformant les états initiaux de l’automate de départ en états ﬁnaux, ses états

ﬁnaux en initiaux, et en retournant le sens de ses transitions

23 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

. . NC . .,_
—"D1‘*]’C DET  No
my

étape 1 : PTA(S) étape 1 : miroir de PTA(S)

ADJ
ADJ

® BET
emoﬁ No a No
étape 2 : les états ﬁnaux de PTA(S) sont fusionnés étape 3 : ql et qz sont fusionnés
(sinon le miroir n’est pas déterministe) (sinon le miroir n’est pas déterministe)

Figure 1: Démonstration pas—a—pas de ZR

3.3 Résultats des expériences d’IG sur le chunking NP

Nous avons appliqué k—RI pour différentes valeurs de k (k = 0, k = 1, k = 2) sur les séquences
d’étiquettes POS correspondant a un méme chunk. Les annotations BIO sont obtenues en utilisant
les automates appris comme des expressions réguliéres selon un parcours séquentiel de la phrase.
Nous avons cherché a reconaitre soit les séquences les plus longues ("Longest Match", LM) soit
les séquences les plus courtes ("Shortest Match", SM). L’étiquetage en NP seuls est la tache pour
laquelle l’IG est la plus appropriée. Il est aussi évidemment possible d’apprendre un automate
distinct pour chaque type de chunk. Mais l’application de plusieurs automates distincts sur une
nouvelle donnée pose des problémes de recouvrements de frontiéres. Nous n’ut1'liserons donc ces
automates que dans le cadre d’une combinaison avec un modele statistique, en section 5.

k—RI est connu pour étre trés sensible aux données d’entrée : une seule séquence incorrecte peut
mener a de multiples fusions d’états, et done a une surgénéralisation. C’est le cas pour notre jeu
de données issues du FI‘B, d’o1‘1 les cas aberrants et les erreurs d’étiquetage ne sont pas absents.
Quelques mauvais exemples étaient cependant faciles a détecter : par exemple, des séquences
d’étiquettes POS ne contenant aucune téte nominale possible peuvent étre retirées sans risque.
Nous avons envisagé diverses autres facons de nettoyer les données. Un nettoyage retirant toutes
les séquences apparaissant moins d’une certaine proportion ﬁxée s’est révélé le plus efﬁcace.
Cette stratégie entraine néanmoins la suppression de séquences utiles, en raison de la faible
proportion de certaines tétes (clitiques notamment).

Nos expériences ont été réalisées selon un protocole de validation croisée partitionant les données
en cinq (4/5 pour l’apprentissage d’un automate, 1/5 pour le test). L’égalité requise sur les
chunks est stricte, c’est—a—dire que pour étre égaux, ils doivent partager exactement les méme
frontiéres. Les précision, rappel et F—mesure des chunks NP sont calculés sans prendre en compte
les étiquettes 0. Le tableau 1 contient diverses F1—mesures obtenues par inférence grammaticale
sur les chunks NP seuls, en appliquant sur les données de test une stratégie de correspondance LM.
Les versions dites nettoyées ont été obtenues en supprimant toute séquence de POS apparaissant
strictement moins de 0.01%. Les valeurs entre parentheses sont les nombres moyens d’états des

24 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

xp PTA pur PTA net. 0-RI net. (1) 1-RI net. (19) 2-RI net. (68.6)
F-mes. 51.92 88.05 26.95 72.74 88.25

Table 1: Résultats de l’IG pour le chunking NP

5 automates calculés pendant la phase d’apprentissage. Les versions PTA, dont les performances
ne sont pas négligeables, peuvent étre vues comme un apprentissage “par coeur”, puisqu’ils n’ont
donné lieu a aucune généralisation. Les automates de taille 1 correspondent a ceux reconnaissant
le langage universel des étiquettes POS présentes au moins une fois dans un chunk NP. Il faut
atteindre k = 2 pour obtenir un automate meilleur que le PTA sur des données nettoyées.

4 Apprentissage statistique pour 1’annotation

Dans cette section, nous nous concentrons sur la meilleure approche statistique actuelle pour
une téiche d’annotation : les Conditional Random Fields (CRF), qui se comportent trés bien
sur notre probléme (Tellier et al., 2012). Nous rappelons aussi comment un HMM peut étre
“transformé” en un CRE parce que cette transformation sera une source d’inspiration pour une
des combinaisons présentées par la suite.

4.1 Conditional Random Fields et HMMs

Les CRE introduits par (Lafferty et al., 2001) sont de la famille des modeles graphiques. Lorsque
que le graphe exprimant les dépendances entre étiquettes est linéaire (ce qui est généralement le
cas pour étiqueter des séquences), la distribution de probabilité d’une séquence d’annotations y
connaissant une séquence observable x est déﬁnie par :

p(y|x) = % 1T[eXP(glkfk(t:}':s.}'t—1:x))

Ou Z (x) est un facteur de normalisation dépendant de x et les K features (ou fonctions
caractéristiques) fk des fonctions fournies par l’utilisateur. Une feature fk est vériﬁée (i.e.
fk(t, _y,,_y,_1,x) = 1) si, a la position courante t, une conﬁguration entre x, y, et _y,_1 est
observée (elle vaut 0 sinon). A chaque feature fk est associé un poids lk. Ces poids constituent
les paramétres du modele devant étre estimés au cours de l’apprentissage. Pour définir un grand
nombre de features, les programmes implémentant les CRF permettent d’avoir recours a des
patrons (ou templates) qui seront instanciés en autant de features qu’il y a de positions sur les
données d’entrainement ou ils peuvent s’appliquer. L’implémentation la plus efﬁcace a l’heure
actuelle des CRF linéaires est fournie par Wapiu'5, qui utilise des pénalisations pour sélectionner
les features les plus pertinentes (Lavergne et al., 2010). C’est le logiciel que nous avons utilisé.

Les CRF se sont montrés efﬁcaces sur de nombreuses taches d’annotation, notamment l’éu'quetage
POS (Lafferty et al., 2001), la reconnaissance d’entités nommées (McCallum and Li, 2003), le
chunking (Sha and Pereira, 2003) et méme le parsing complet (Finkel et al., 2008; Tsuruoka

5http : //wapiti . limsi . fr/
25 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

A chunking Complet NP seuls
ﬂute Ugflggm F[‘_"2“"1‘]" micro 97.53 N/A
POS Bigiam [ 2"1] macro 90.49 N/A
_ " F1-mesure N/A 96.43

Table 2: Le patron de template et les résultats obtenus avec les CRF seuls pour chaque tache

et al., 2009). Leur principal inconvénient est qu’ils apparaissent comme des “boites noires”. Un
modele issu d’un apprentissage par CRF est simplement une liste de features pondérées pouvant
avoir plusieurs millions d’éléments, ce qui le rend difﬁcile a interpréter.

Les HMM, qui étaient parmi les meilleures méthodes d’annotation statistique avant que les CRF
n’apparaissent, présentent quant a eux l’avantage d’étre plus interprétables. Cependant, tout
HMM peut étre “transformé” en un CRF déﬁnissant la méme distribution de probabilité (Sutton
and McCallum, 2006; Tellier and Tommasi, 2011). Pour ce faire, pour un HMM donné, nous
devons déﬁnir deux familles de features :

0 les features de la forme f (yr, xr) associant une seule étiquette yr avec une seule entIe’e de
meme position xr : elles valent 1 quand l’états yr du HMM émet xr ;

0 les features de la forme f (yr_1, yr) qui associent deux états yr_1 et yr du HMM ; elles valent
1 quand la transition entre ces deux états est utilisée.

Si 9 est une probabilité d’émission ou de transition du HMM, alors on choisit A = log(6) comme
poids pour la feature correspondant dans le CRE Le calcul de p(y|x) s’écrira alors exactement de
la méme facon dans les deux cas. Un HMM peut ainsi étre vu comme un cas particulier de CRF.
Mais les CRF sont plus généraux car ils permettent d’avoir recours a d’autres features que celles
utilisées dans la transformation. Cette correspondance nous a inspirés pour exploiter les CRF
afin de diagnostiquer les automates appris par IG. Cette idée sera étudiée dans la section 5. Mais
auparavant, nous présentons les résultats obtenus avec les CRF seuls sur nos données.

4.2 Résultats des expériences

Les tableaux 2 montrent les patrons de features utilisés ainsi que les résultats obtenus avec
les CRF seuls sur les deux taches de chunking. Pour ces expériences, comme en section 3.3,
nous avons suivi un protocole de validation croisée a 5 plis et un critére d’égalité stricte des
chunks. Pour la tache de chunking complet, nous avons calculé les micro et macro—average,
qui correspondent aux moyennes des F1—mesures des différents types de chunks, pondérées
(micro) ou pas (macro) par leur proportion. Comme attendu, les CRF seuls sont trés performants.
Remarquons toutefois qu’ils exploitent dans leurs features a la fois des mots et des étiquettes
POS présents dans les données, alors que les algorithmes d’IG n’ont acces qu’aux seuls POS.

On peut comparer ces résultats avec ceux obtenus lors de la campagne PASSAGE (Paroubek
et al., 2006), méme si les notions de chunks adoptées de part et d’autre different (dans PASSAGE,
les adjectifs épithétes situés aprés un nom ne font pas partie du chunk nomimal, par exemple)
et si les corpus ne sont pas les mémes. Les meilleurs participants de la campagne PASSAGE
atteignaient une micro—average de 92,7, ce qui situe tout de méme la performance de nos CRE

26 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

mot POS auto. NP auto. VP auto. PP  label correct | auto. NP NP-label correct
la DET B O O B-NP B B
dépréciation NC I O O I-NP I I
par_rapport_au P O O B B-PP O 0
dollar NC B O I I-1’? B B
a V O B O B-VP O O
été VPP O I O I-VP O O
limitée VPP O I O I-VP O O
51 P O O B B-PP O 0
2,5 DET B O I I-1’? B B
% NC I O I I-1’? I I

Table 3: Données enrichies par des sorties d’automates spéciﬁques pour chaque chunk

5 Combinaisons

Dans les sections précédentes, nous avons appliqué a la tache de chunking une approche soit
purement symbolique soit purement statistique. Dans cette section, nous allons combiner les
deux approches, cette combinaison pouvant s’envisager selon deux axes distincts :

0 Soit le but est la seule performance, auquel cas il faut privilégier l’apprentissage statistique.
Cependant, les automates obtenus par IG offrent une vision globale (et non locale, comme c’est
le cas dans les features) des relations entre les étiquettes POS d’un méme chunk qui pourrait
s’avérer uu'le dans un CRE Nous pouvons donc chercher a intégrer les résultats de l’apprentissage
symbolique en tant que ressource externe de l’apprentissage statistique.

0 Soit nos ﬁns sont plus en rapport avec la lisibilité, auquel cas nous favoriserons les automates
produits par IG. Or, comme évoqué en 4.1, il est tout a fait possible de simuler la structure d’un
HMM (et, similairement, d’un automate) avec les features d’un CRE On pourrait donc évaluer la
qualité des états et des transitions d’un automate en fonction des poids associés aux features qui
les représentent dans un CRE offrant ainsi par la meme occasion un moyen de l’améliorer.

5.]. Les automates en tant que ressource externe

Nous nous attaquons ici aux deux types de chunking. Le premier mode de combinaison envisagé
consiste a enrichir les données du CRF avec des attributs provenant de la ressource externe, a
la fagon de (Constant and Tellier, 2012). Dans le cas du chunking complet, nous appliquons
l’IG a chaque type de chunk distinct, produisant ainsi autant d’automates qu’il y a de types de
chunks selon un protocole de validation croisée a 5 plis (les PTA dans ces expériences sont donc
uniquement extraits des corpus d’apprentissage). Chacun des automates de chunk fournit un
étiquetage BIO indépendant, comme dans le tableau 3 (les automates sont ici supposés fournir
un étiquetage parfait). 11 y a done dans nos données autant d’attributs nouveaux que de chunks.

Les tableaux de gauche dans les tables 4 donnent les patrons aboutissant aux meilleurs résultats
(micro resp. macro—average resp. F—mesure) pour le chunking complet ou le chunking NP.
La ligne "Automate" prend en compte la sortie de chaque automate indépendamment alors
que "POS+Automates" représente la concaténation des colonnes POS et des sorties de tous les
automates. Les résultats correspondants sont donnés dans les tableaux de droite. Ils montrent
que les attributs provenant des automates perrnettent d’améliorer signiﬁcativement les résultats
des CRE C’est particulierement vrai pour la macro-average, qui donne un poids équivalent a la

27 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

F1—mesure de chaque type de chunk. Les informations issues des automates améliorent donc
surtout les performances de reconnaissance des chunks rares. Dans l’expérience permettant
d’obtenir la meilleure macro, les trois améliorations les plus signiﬁcatives en terme de F—mesure
sont : UNKNOWN (de 41.67 a 61.22), AP (de 96.78 a 97.44) et AdP (de 98.72 a 98.92).

Feature Type Fenetre Emesure put 1_RI LM
Mot Unigram [-2..1] .
. micro 97.66
Automate Bigram [-2. . 1] macro 92 22
POS Bigram [-2..1] '
Feature Type Fenétre
Mot Unigram [—2..1] F—mesure pur 1—RI SM
Automate Unigram [-1..1] micro 97. 62
POS Bigram [—2..1] macro 93.52
POS+Automates Bigram [-1 ..1]
Feature Type Fenétre
Mot Unigram [-2..1] put 2_RI LM
POS Blgram [_2"1] F—measure 96 75
Automate Bigram [- 1 . . 1] '
POS+Automate Bigram [—1..1]

Table 4: Patrons et meilleure micro—average (resp. macro—average) pour le chunking complet,
idem pour la F—mesure du chunking NP seul

5.2 Diagnostiquer un automate £1 l’aide d’un CRF

Nous voulons ici obtenir des informations sur l’automate produit par IG a l’aide des CRE en
faisant un apprentissage n’utilisant que des features interprétables relativement a lui. Les poids
associés par le CRF a ces features fourniront un diagnostic ﬁn de l’automate. Cette idée se
rapproche de (Roark and Saraclar, 2004), ou un CRF était appris selon la structure d’un automate
pondéré pour le “corriger” grace a l’estimation des poids. Elle en differe toutefois car nous
ne cherchons pas a obtenir un automate pondéré mais a trouver d’éventuelles modiﬁcations
a effectuer sur l’automate selon le diagnostic fourni par le CRE tout en préservant sa nature
purement symbolique. Pour illustrer cette approche, nous nous concentrons sur la tache de
chunking NP seul car elle ne nécessite la prise en compte que d’un seul automate. I1 peut étre plus
facile pour comprendre la suite de se représenter les automates ﬁnis déterministes (AFD) “a la
Unitex” (http://www-igm.univ-mlv.fr/ unitex/). Ainsi, le résultat de l’algorithme ZR sur la ﬁgure
1 (l’automate ﬁnal, en bas a droite) est identique a celui de la ﬁgure 2. Cette représentation a
l’avantage de montrer les étiquettes POS et les transitions entre deux étiquettes POS comme deux
objets différents. Pour construire un CRF a partir d’un tel automate, nous considérons surtout les
sorties en termes d’étiquetage BIO que cet automate produit (partie droite de la Table 3).

Nous inspirant de la relation entre les HMM et les CRF évoquée en section 4.1, nous déﬁnissons
des patrons de features qui peuvent s’interpréter relativement a l’automate :

28 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

F F " P ‘E!

Figure 2: Automate représenté “a la Unitex”

0 Un patron unigramme qui observe une étiquette POS et l’étiquette BIO prédite par l’automate
a la méme position, conjointement avec le label BIO correct. L’étiquette POS correspond a un
(ou plusieurs) état(s) de l’automate. Si les étiquettes BIO coincident pour un POS donné, cela
signiﬁe que l’automate a en quelque sorte raison d’étre dans cet état en analysant la donnée.

0 Un patron bigramme qui observe un couple d’étiquettes POS successives et le couple
d’étiquettes BIO prédites par l’automate correspondant, associé au couple de labels BIO correct.
Le couple de POS représente une (ou plusieurs) transiu'on(s) de l’automate. Si les deux couples
d’étiquettes BIO coincident, cela signiﬁe que la transition est correctement utilisée.

Il est a noter que les mots eux—mémes ne sont pas pris en compte dans ces patrons, aﬁn de
préserver l’interprétation des features relativement a l’automate, d’ou les mots sont absents.

La Table 5 est une matrice de confusion qui met en relation les étiquettes BIO prédites par un
automate (EP) et les étiquettes BIO correctes (EC), pour une étiquette POS donnée (ici, l’étiquette
DET d’un automate appris). On peut construire autant de tables que d’étiquettes POS présentes
dans un chunk NP, chaque case de chaque table correspondant a une feature unigramme. Les
cases de la Table 5 sont remplies par les poids appris par le CRF pour les features en question, les
couleurs montrent comment elles s’interprétent relativement a l’automate de départ. Comme
espéré, les poids sur la diagonale, qui signalent un étiquetage correct, sont plus grands que
ceux en dehors, qui désignent une erreur d’étiquetage. Les features bigrammes sont un peu plus
compliquées mais il est également possible d’en tirer des matrices de confusion interprétables.

les deux sorties sont identiques.
début prématuré de chunk.

I =

I =

‘ : début de chunk manqué.
I =

I =

continuation intempestive de chunk.
arrét prématuré de chunk.

 

Table 5: Une matrice de confusion colorée pour l’étiquette DET (2—RI, tableau 1)

De maniere générale, le poids associé a une feature d’un CRF représente son pouvoir discriminant.
Ces poids sont donc bien plus pertinents que de simples comptes d’occurences sur le nombre de
fois qu’une feature a été satisfaite ou pas dans les données d’apprentissage. Les poids sur les
diagonales peuvent ainsi étre vus comme évaluant la qualité des états / transitions de l’automate,
alors que les poids dans les autres cases correspondent aux gains obtenus en prenant une décision
d’étiquetage non préconisée par l’automate. L’ensemble des matrices de confusion offre donc une
mesure extrémement ﬁne et précise de la qualité de l’automate.

Le tableau 6 rappelle le meilleur résultat obtenu par IG “pure” sur le chunking NP de la section
3.3 et donne les résultats des CRF construits comme précédemment sur le meilleur automate

29 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Expérience baseline (IG seule) 0—RI 1-RI 2—RI
chunk 88.25 93.00 93.07 93.08

Table 6: Résultats du chunking NP avec les CRF construits sur les automates

produit par k—RI pour chaque valeur de k. Comme on pouvait s’y attendre, les CRF construits
sur les automates NP sont meilleurs que les automates NP seuls, mais moins bons qu’un CRF
exploitant plus d’attributs et de features. Les résultats des matrices de confusion doivent encore
étre examinés en détail. Nous espérons en tirer un diagnostic précis pour analyser 011 et pourquoi
les automates prennent de bonnes ou de mauvaises décisions, et les modiﬁer en conséquence. Les
améliorations observées dans la Table 6 laissent en effet supposer qu’a de nombreuses occasions
1e CRF a eu raison de prendre une décision différente de celle préconisée par l’automate.

Conclusion et perspectives

Dans cet article, nous avons a li ué deux méthodes d’a rentissa e automati ue sur le méme
PP (1 PP 8 <1
jeu de données et avons proposé deux facons différentes de les combiner.

Pour ce qui est de l’apprentissage symbolique seul, il est possible que d’autres algorithmes d’IG
par présentation positive pourraient donner de meilleurs résultats que les n6tres, comme ceux de
(Garcia and Vidal, 1990; Denis et al., 2002). Le choix d’une grande valeur de k dans certains cas
peut étre important, mais il s’accompagne d’une plus grande complexité de calculs5.

Mais la partie la plus originale de notre travail concerne les combinaisons automates/CRF.
Notons que ces combinaisons peuvent tout autant s’app1iquer a des automates écrits a la main,
généralement plus pertinents d’un point de vue linguistique que ceux obtenus par IG. Nous nous
sommes concentrés ici sur des automates appris automatiquement pour montrer que, méme sans
ressource ni expertise linguistique, il est possible de combiner modeles symboliques et statistiques.
L’intuition derriere ce travail est que ces deux types de modeles sont complémentaires, et qu’ils
peuvent chacun bénéﬁcier de l’autre. Les CRF sont basés sur un grand nombre de conﬁgurations
locales pondérées. Il est théoriquement possible d’uti1iser dans un CRF des features portant sur
l’intégralité de la séquence x mais dans la pratique, cela est rarement fait. L’IG au contraire
s’app1ique a un ensemble de séquences globales qu’elle est capable de généraliser. Il a déja été
observé que les CRF gagnent a recourir a des features exprimant des propriétés plus générales
que de simples conﬁgurations locales (Pu et al., 2010). Notre pari était que 1’IG pouvait fournir
ce type de généralisation, via le premier mode de combinaison. Les résultats obtenus vont dans
ce sens. Il est aussi intéressant de constater que les modéles symboliques permettent d’améliorer
1e traitement des cas rares, mal pris en compte par les modeles statistiques.

Les CRF construits sur des automates restent encore a étudier, notamment pour interpréter et
exploiter au mieux les matrices de confusion qu’ils produisent. Certaines cases de ces matrices
sont vides car Wapiti élimine les features non pertinentes de l’ensemble de départ selon un critere
de pénalité. I1 devrait étre possible, a l’aide de ces informations, de modiﬁer l’automate sur
lequel se base le CRF en supprimant ou ajoutant des états ou des transitions pour se conformer
au diagnostic fourni par une table. Une IG dirigée par des CRF reste encore a déﬁnir ! Un autre

61a complexité algorithmique de k-RI est |ZI|k|Q|k+3 o1‘1 |Q| est le nombre d’états du PTA
30 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

déﬁ serait l’étude du lien entre les automates associés aux poids calculés par CRF que nous
définissons et les plus classiques HMM ou automates probabilistes pour lesquels des algorithmes
d’apprentissage existent déja (Thollard et al., 2000).

6 Références

Abeillé, A., Clément, L., and Toussenel, E (2003). Building a treebank for french. In Abeillé, A.,
editor, Treebanks. Kluwer, Dordrecht.

Abney, S. (1991). Parsing by chunks. In Berwick, R., Abney, R., and Tenny, C., editors,
Principle-based Parsing. Kluwer Academic Publisher.

Angluin, D. (1980). Inductive inference of formal languages from positive data. Information
and Control, 45 (2):1 17-135.

Angluin, D. (1982). Inference of reversible languages. Journal of the ACM, 29(3):741—765.

Antoine, J.-Y., Mokrane, A., and Friburger, N. (2008). Automatic rich annotation of large corpus
of conversational transcribed speech: the chunking task of the epac project. In Proceedings of
LREC’2008.

Blanc, 0., Constant, M., Dister, A., and Watrin, R (2010). Partial parsing of spontaneous spoken
french. In Proceedings of LREC’201 0.

Constant, M. and Tellier, I. (2012). Evaluating the impact of external lexical resources unto a
crf—based multiword segmenter and part—of—speech tagger. In Proceedings of LREC 2012.

Constant, M., Tellier, I., Duchier, D., Dupont, Y., Sigogne, A., and Billot, S. (2011). Intégrer
des connaissances linguistiques dans un CRF : application a l’apprentissage d’un segmenteur—
étiqueteur du francais. In Actes de TALN’1 1.

Crabbé, B. and Candito, M. H. (2008). Expériences d’analyse syntaxique statistique du francais.
In Actes de TALN’08.

de la Higuera, C. (2010). Grammatical Inference: Learning Automata and Grammars. CU Press.

Denis, F., Lemay, A., and Terlutte, A. (2002). Some language classes identiﬁable in the limit
from positive data. In ICGI 2002, number 2484 in LNAI, pages 63-76. Springer Verlag.

Dupont, P, Denis, E, and Esposito, Y. (2005). Links between probabilistic automata and hidden
markov models: probability distributions, learning models and induction algorithms. Pattern
Recognition, 38(9):1349—1371.

Dupont, P., Miclet, L., and Vidal, E. (1994). What is the search space of the regular inference. In
ICGI’94 — LNCS, volume 862 - Grammatical Inference and Applications, pages 25-37, Heidelberg.

Finkel, J . R., Kleeman, A., and Manning, C. D. (2008). Efficient, feature—based, conditional
random ﬁeld parsing. In Proceedings of ACI.’2008, pages 959-967.

31 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Garcia, P. and Vidal, E. (1990). Inference of k—testable languages in the strict sense and
application to syntactic pattern recognition. IEEE TPAMI, 12(9):920-925.

Gold, E. (1967). Language identiﬁcation in the limit. Information and Control, 10:447-474.
Kanazawa, M. (1998). Learnable Classes of Categorial Grammars. FoLLI. CLSI Publications.

Kearns, M. J. and Vazirani, U. V (1994). An Introduction to Computational Learning Theory. MIT
Press.

Koshiba, 'I‘., Makinen, E., and Takada, Y. (2000). Inferring pure context-free languages from
positive data. Acta Cybernetica, 14(3):469—477.

Lafferty, J ., McCallum, A., and Pereira, E (2001). Conditional random ﬁelds: Probabilistic
models for segmenting and labeling sequence data. In Proceedings of ICML 2001, pages 282-289.

Lavergne, 'I‘., Cappé, 0., and Yvon, E (2010). Practical very large scale CRFs. In Proceedings of
ACI.’2010, pages 504-513. Association for Computational Linguistics.

McCallum, A. and Li, W. (2003). Early results for named entity recognition with conditional
random ﬁelds. In Proceedings of CoNLI.’2003.

Paroubek, P, Robba, I., Vilnat, A., and C., A. (2006). Data annotations and measures in easy,
the evaluation campain for parsers of french. In Proceedings of LREC’2006, pages 315-320.

Pu, X., Mac, Q., Wu, G., and Yuan, C. (2010). Chinese named entity recognition with the
improved smoothed conditional random ﬁelds. Research in Computing Science, 46:90—103.

Roark, B. and Saraclar, M. (2004). Discriminative language modeling with conditional random
ﬁelds and the perceptron algorithm. In Proceedings of ACI.’2004, pages 47-54.

Sha, E and Pereira, E (2003). Shallow parsing with conditional random ﬁelds. In Proceedings of
HL'T—NAACL 2003, pages 213 — 220.

Sutton, C. and McCallum, A. (2006). Introduction to Statistical Relational Learning, chapter An
Introduction to Conditional Random Fields for Relational Learning. MIT Press.

Tellier, I., Duchier, D., Eshkol, I., Gourmet, A., and Martinet, M. (2012). Apprentissage
automatique d’un chunker pour le francais. In Actes de TALN’12, papier court (poster).

Tellier, I. and Tommasi, M. (2011). Champs Markoviens Conditionnels pour l’extraction
d’information. In Modeles probabilistes pour l’accés a l’information textuelle. Hermes.

Thollard, E, Dupont, P, and de la Higuera, C. (2000). Probabilistic DFA inference using
Kullback-Leibler divergence and minimality. In Proc. of ICMI.’2000, pages 975-982.

Tsuruoka, Y., Tsujii, J ., and Ananiadou, S. (2009). Fast full parsing by linear—chain conditional
random ﬁelds. In Proceedings of EACL 2009, pages 790-798.

Valiant, L. G. (1984). A theory of the leamable. Communications of the ACM, 27(11):1134-1142.

Yokomori, T. (2003). Polynomial-time identiﬁcation of very simple grammars from positive data.
Theoretical Computer Science, 1.

32 © ATALA

