<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>S&#233;lection non supervis&#233;e de relations s&#233;mantiques pour am&#233;liorer un th&#233;saurus distributionnel</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>S&#233;lection non supervis&#233;e de relations s&#233;mantiques pour
am&#233;liorer un th&#233;saurus distributionnel
</p>
<p>Olivier Ferret
CEA, LIST, Laboratoire Vision et Ing&#233;nierie des Contenus,
</p>
<p>Gif-sur-Yvette, F-91191 France.
</p>
<p>olivier.ferret@cea.fr
</p>
<p>R&#201;SUM&#201;
Les travaux se focalisant sur la construction de th&#233;saurus distributionnels ont montr&#233; que les
relations s&#233;mantiques qu&#8217;ils rec&#232;lent sont principalement fiables pour les mots de forte fr&#233;quence.
Dans cet article, nous proposons une m&#233;thode pour r&#233;&#233;quilibrer de tels th&#233;saurus en faveur des
mots de fr&#233;quence faible sur la base d&#8217;un m&#233;canisme d&#8217;amor&#231;age : un ensemble d&#8217;exemples et de
contre-exemples de mots s&#233;mantiquement similaires sont s&#233;lectionn&#233;s de fa&#231;on non supervis&#233;e et
utilis&#233;s pour entra&#238;ner un classifieur supervis&#233;. Celui-ci est ensuite appliqu&#233; pour r&#233;ordonner les
voisins s&#233;mantiques du th&#233;saurus utilis&#233; pour s&#233;lectionner les exemples et contre-exemples. Nous
montrons comment les relations entre les constituants de noms compos&#233;s similaires peuvent
&#234;tre utilis&#233;es pour r&#233;aliser une telle s&#233;lection et comment conjuguer ce crit&#232;re &#224; un crit&#232;re d&#233;j&#224;
exp&#233;riment&#233; sur la sym&#233;trie des relations s&#233;mantiques. Nous &#233;valuons l&#8217;int&#233;r&#234;t de cette proc&#233;dure
sur un large ensemble de noms en anglais couvrant un vaste spectre de fr&#233;quence.
</p>
<p>ABSTRACT
Unsupervised selection of semantic relations for improving a distributional thesaurus
</p>
<p>Work about distributional thesauri has shown that the relations in these thesauri are mainly
reliable for high frequency words. In this article, we propose a method for improving such a
thesaurus through its re-balancing in favor of low frequency words. This method is based on a
bootstrapping mechanism : a set of positive and negative examples of semantically similar words
are selected in an unsupervised way and used for training a supervised classifier. This classifier is
then applied for reranking the semantic neighbors of the thesaurus used for example selection.
We show how the relations between the mono-terms of similar nominal compounds can be used
for performing this selection and how to associate this criterion with an already tested criterion
based on the symmetry of semantic relations. We evaluate the interest of the global procedure
for a large set of English nouns with various frequencies.
</p>
<p>MOTS-CL&#201;S : S&#233;mantique lexicale, similarit&#233; s&#233;mantique, th&#233;saurus distributionnels.
KEYWORDS: Lexical semantics, semantic similarity, distributional thesauri.
</p>
<p>1 Introduction
</p>
<p>Le travail pr&#233;sent&#233; dans cet article s&#8217;inscrit dans le contexte de la construction automatique
de th&#233;saurus &#224; partir de corpus. Dans le prolongement de (Grefenstette, 1994) ou (Curran
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>48 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>et Moens, 2002), une mani&#232;re largement r&#233;pandue d&#8217;aborder ce probl&#232;me est d&#8217;utiliser une
mesure de similarit&#233; s&#233;mantique pour extraire les voisins s&#233;mantiques de chacune des entr&#233;es
pressenties du th&#233;saurus. Trois principales approches peuvent &#234;tre distingu&#233;es pour construire
une telle mesure. La premi&#232;re repose sur des ressources construites manuellement abritant
des relations s&#233;mantiques clairement identifi&#233;es, g&#233;n&#233;ralement de nature paradigmatique. Les
travaux exploitant des r&#233;seaux lexicaux de type WordNet pour &#233;laborer des mesures de similarit&#233;
s&#233;mantique, tels que (Budanitsky et Hirst, 2006) ou (Pedersen et al., 2004), entrent pleinement
dans cette cat&#233;gorie. Ces mesures s&#8217;appuient typiquement sur la structure hi&#233;rarchique de ces
r&#233;seaux, fond&#233;e sur des relations d&#8217;hyperonymie. La deuxi&#232;me approche pour construire une
telle mesure fait appel &#224; une source de connaissances concernant les mots moins structur&#233;e
que la pr&#233;c&#233;dente : les descriptions textuelles de leur sens. Les gloses de WordNet ont ainsi &#233;t&#233;
utilis&#233;es pour mettre en &#339;uvre des mesures de type Lesk dans (Banerjee et Pedersen, 2003)
et plus r&#233;cemment, des mesures ont &#233;t&#233; d&#233;finies &#224; partir de Wikip&#233;dia ou des d&#233;finitions des
Wiktionaries (Gabrilovich, 2007). La derni&#232;re option pour la construction d&#8217;une mesure de
similarit&#233; s&#233;mantique prend appui sur un corpus en g&#233;n&#233;ralisant l&#8217;hypoth&#232;se distributionnelle :
chaque mot est caract&#233;ris&#233; par l&#8217;ensemble des contextes dans lesquels il appara&#238;t pour un corpus
donn&#233; et la similarit&#233; s&#233;mantique de deux mots est &#233;valu&#233;e sur la base de la proportion de
contextes que ces deux mots partagent. Cette perspective, initialement adopt&#233;e par (Grefenstette,
1994) et (Lin, 1998), a fait l&#8217;objet d&#8217;&#233;tudes approfondies, notamment dans (Curran et Moens,
2002), (Weeds, 2003) ou (Heylen et al., 2008).
</p>
<p>Le probl&#232;me de l&#8217;am&#233;lioration des r&#233;sultats d&#8217;une impl&#233;mentation &#171; classique &#187; de l&#8217;approche
distributionnelle telle qu&#8217;elle est r&#233;alis&#233;e dans (Curran et Moens, 2002) a d&#233;j&#224; fait l&#8217;objet d&#8217;un
certain nombre de travaux. Une partie d&#8217;entre eux se sont focalis&#233;s sur la pond&#233;ration des &#233;l&#233;-
ments constituant les contextes distributionnels, &#224; l&#8217;instar de (Broda et al., 2009), qui transforme
les poids au sein de des contextes en rangs, ou de (Zhitomirsky-Geffet et Dagan, 2009), repris et
&#233;tendu par (Yamamoto et Asakura, 2010), qui propose une m&#233;thode fond&#233;e sur l&#8217;amor&#231;age pour
modifier les poids des &#233;l&#233;ments des contextes en s&#8217;appuyant sur les voisins s&#233;mantiques trouv&#233;s
au moyen d&#8217;une mesure de similarit&#233; distributionnelle initiale. Des approches plus radicalement
diff&#233;rentes ont &#233;galement vu le jour. L&#8217;utilisation de m&#233;thodes de r&#233;duction de dimensions, comme
l&#8217;Analyse S&#233;mantique Latente dans (Pad&#243; et Lapata, 2007), les mod&#232;les de type multi-prototype
(Reisinger et Mooney, 2010) ou la red&#233;finition de l&#8217;approche distributionnelle dans un cadre
bay&#233;sien dans (Kazama et al., 2010) se rangent dans cette seconde cat&#233;gorie.
</p>
<p>Le travail que nous pr&#233;sentons dans cet article s&#8217;appuie comme (Zhitomirsky-Geffet et Dagan,
2009) sur un m&#233;canisme d&#8217;amor&#231;age mais adopte une perspective diff&#233;rente, initi&#233;e dans (Ferret,
2012) : au lieu d&#8217;utiliser les &#171; meilleurs &#187; voisins s&#233;mantiques pour adapter directement les
poids des &#233;l&#233;ments constituant les contextes distributionnels des mots, l&#8217;id&#233;e est de s&#233;lectionner
de fa&#231;on non supervis&#233;e un ensemble restreint de mots jug&#233;s s&#233;mantiquement similaires pour
entra&#238;ner, &#224; l&#8217;instar de (Hagiwara, 2008), un classifieur statistique supervis&#233; capable de mod&#233;liser
la notion de similarit&#233; s&#233;mantique. La s&#233;lection de cet ensemble d&#8217;apprentissage est r&#233;alis&#233;e
plus pr&#233;cis&#233;ment en associant deux crit&#232;res faibles fond&#233;s sur la similarit&#233; distributionnelle des
mots : le premier, d&#233;j&#224; exp&#233;riment&#233; dans (Ferret, 2012), exploite la sym&#233;trie de la relation de
similarit&#233; s&#233;mantique ; le second, nouvellement introduit ici, fait l&#8217;hypoth&#232;se que les constituants
de mots compos&#233;s s&#233;mantiquement similaires sont eux-m&#234;mes susceptibles d&#8217;entretenir des
liens de similarit&#233; s&#233;mantique. Nous montrons que le classifieur ainsi construit est utilisable
pour r&#233;ordonner les voisins s&#233;mantiques trouv&#233;s par la mesure de similarit&#233; initiale et corriger
certaines de ses insuffisances du point de vue de la construction d&#8217;un th&#233;saurus distributionnel.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>49 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>2 Construction d&#8217;un th&#233;saurus distributionnel initial
</p>
<p>L&#8217;utilisation de l&#8217;amor&#231;age implique dans notre cas de construire un th&#233;saurus initial dont la
qualit&#233;, au moins pour un sous-ensemble de celui-ci, soit suffisamment &#233;lev&#233;e pour servir de
marchepied &#224; une am&#233;lioration plus globale. Compte tenu du mode de construction de ce type de
th&#233;saurus, cet objectif prend la forme de la d&#233;finition d&#8217;une mesure de similarit&#233; distributionnelle
obtenant des performances, telles qu&#8217;elles peuvent &#234;tre &#233;valu&#233;es au travers de tests de type
TOEFL (Landauer et Dumais, 1997) par exemple, compatibles avec cette exigence. (Ferret, 2010)
s&#8217;est attach&#233; &#224; la s&#233;lection d&#8217;une telle mesure. Nous reprenons ici les conclusions de ce travail.
</p>
<p>2.1 D&#233;finition d&#8217;une mesure de similarit&#233; distributionnelle
</p>
<p>Bien que notre langue cible soit l&#8217;anglais, nous avons choisi de limiter le niveau des traitements
linguistiques appliqu&#233;s au corpus source de nos donn&#233;es distributionnelles &#224; l&#8217;&#233;tiquetage morpho-
syntaxique et &#224; la lemmatisation, de mani&#232;re &#224; faciliter la transposition du travail &#224; des langues
moins dot&#233;es. Cette approche appara&#238;t &#224; cet &#233;gard comme un compromis raisonnable entre
l&#8217;approche de (Freitag et al., 2005), dans laquelle aucune normalisation n&#8217;est faite, et l&#8217;approche
plus largement r&#233;pandue consistant &#224; utiliser un analyseur syntaxique, &#224; l&#8217;instar de (Curran
et Moens, 2002). Plus pr&#233;cis&#233;ment, nous nous sommes appuy&#233;s sur l&#8217;outil TreeTagger (Schmid,
1994) pour assurer le pr&#233;traitement du corpus AQUAINT-2 qui est &#224; la base de ce travail. Ce
corpus comprenant environ 380 millions de mots est compos&#233; d&#8217;articles de journaux.
</p>
<p>Les param&#232;tres d&#8217;extraction des donn&#233;es distributionnelles et les caract&#233;ristiques de la mesure de
similarit&#233; sont quant &#224; eux issus de la s&#233;lection op&#233;r&#233;e dans (Ferret, 2010) :
</p>
<p>&#8211; contextes distributionnels constitu&#233;s de cooccurrents graphiques : noms, verbes et adjectifs
collect&#233;s gr&#226;ce &#224; une fen&#234;tre de taille fixe centr&#233;e sur chaque occurrence du mot cible ;
</p>
<p>&#8211; taille de la fen&#234;tre = 3 (un mot &#224; droite et un mot &#224; gauche du mot cible), c&#8217;est-&#224;-dire des
cooccurrents de tr&#232;s courte port&#233;e ;
</p>
<p>&#8211; filtrage minimal des contextes : suppression des seuls cooccurrents de fr&#233;quence &#233;gale &#224; 1 ;
&#8211; fonction de pond&#233;ration des cooccurrents dans les contextes = Information mutuelle entre le
</p>
<p>mot cible et son cooccurrent ;
&#8211; mesure de similarit&#233; entre contextes, pour &#233;valuer la similarit&#233; s&#233;mantique de deux mots =
</p>
<p>mesure Cosinus.
</p>
<p>Un filtre fr&#233;quentiel est en outre appliqu&#233; &#224; la fois aux mots cibles et &#224; leurs cooccurrents puisque
seuls les mots de fr&#233;quence sup&#233;rieure &#224; 10 sont consid&#233;r&#233;s.
</p>
<p>2.2 Construction et &#233;valuation du th&#233;saurus initial
</p>
<p>La construction de notre th&#233;saurus distributionnel initial &#224; partir de la mesure de similarit&#233;
d&#233;finie ci-dessus a &#233;t&#233; r&#233;alis&#233;e comme dans (Lin, 1998) ou (Curran et Moens, 2002) en extrayant
les plus proches voisins s&#233;mantiques de chacune de ses entr&#233;es. Plus pr&#233;cis&#233;ment, cette mesure a
&#233;t&#233; calcul&#233;e entre chaque entr&#233;e et l&#8217;ensemble de ses voisins possibles. Ces voisins ont ensuite
&#233;t&#233; ordonn&#233;s selon l&#8217;ordre d&#233;croissant des valeurs de cette mesure et les N premiers voisins
(N = 100) ont &#233;t&#233; conserv&#233;s en tant que voisins s&#233;mantiques de l&#8217;entr&#233;e. Les entr&#233;es du th&#233;saurus
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>50 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>de m&#234;me que leurs voisins possibles &#233;taient constitu&#233;s des noms du corpus AQUAINT-2 de
fr&#233;quence sup&#233;rieure &#224; 10. &#192; titre illustratif, nous donnons les premiers voisins de deux entr&#233;es
de ce th&#233;saurus, aid et procurator, avec leur poids :
</p>
<p>aid assistance [0,41] relief [0,34] funding [0,29] grant [0,27] fund [0,26] donation [0,26] . . .
procurator justiceship [0,31] amadou [0,27] commmission [0,26] pamphleteer [0,22] . . .
</p>
<p>Le tableau 1 montre quant lui les r&#233;sultats de l&#8217;&#233;valuation du th&#233;saurus distributionnel obtenu,
r&#233;alis&#233;e en comparant les voisins s&#233;mantiques extraits &#224; deux ressources de r&#233;f&#233;rence compl&#233;men-
taires : les synonymes de WordNet [W], dans sa version 3.0, qui permettent de caract&#233;riser une
similarit&#233; fond&#233;e sur des relations paradigmatiques et le th&#233;saurus Moby [M], qui regroupe des
mots li&#233;s par des relations plus diverses. Comme l&#8217;illustre la 4e&#768;me colonne du tableau, ces deux
ressources sont aussi tr&#232;s diff&#233;rentes en termes de richesse. Le but &#233;tant d&#8217;&#233;valuer la capacit&#233;
&#224; extraire des voisins s&#233;mantiques, elles sont filtr&#233;es pour en exclure les entr&#233;es et les voisins
non pr&#233;sents dans le vocabulaire du corpus AQUAINT-2 (cf. la diff&#233;rence entre le nombre de
mots de la 1e&#768;re colonne et le nombre de mots effectivement &#233;valu&#233;s de la 3e&#768;me colonne). Une
fusion de ces deux ressources a &#233;galement &#233;t&#233; faite [WM]. La fr&#233;quence des mots &#233;tant une don-
n&#233;e importante des approches distributionnelles, les r&#233;sultats globaux sont diff&#233;renci&#233;s suivant
deux tranches fr&#233;quentielles de m&#234;me effectif (7 335 mots chacune) : hautes pour les mots de
fr&#233;quence &gt; &#224; la fr&#233;quence m&#233;diane (249) et basses pour les autres. Ces r&#233;sultats se d&#233;clinent
sous la forme de diff&#233;rentes mesures, &#224; commencer &#224; la 5e&#768;me colonne par le taux de rappel par
rapport aux ressources consid&#233;r&#233;es pour les 100 premiers voisins de chaque mot. Ces voisins
</p>
<p>fr&#233;q. r&#233;f. #mots
&#233;val.
</p>
<p>#syn.
/mot
</p>
<p>rappel R-
pr&#233;c.
</p>
<p>MAP P@1 P@5 P@10 P@100
</p>
<p>W 10 473 2,9 24,6 8,2 9,8 11,7 5,1 3,4 0,7
toutes M 9 216 50,0 9,5 6,7 3,2 24,1 16,4 13,0 4,8
14 670 WM 12 243 38,7 9,8 7,7 5,6 22,5 14,1 10,8 3,8
</p>
<p>W 5889 3,3 29,4 11,8 13,5 17,4 7,5 4,9 1,0
hautes M 5751 60,5 11,2 9,4 4,6 35,9 24,2 18,9 6,8
7 335 VM 6754 52,6 11,4 11,1 7,4 36,4 22,8 17,5 6,0
</p>
<p>W 4584 2,3 16,0 3,7 5,1 4,2 2,0 1,4 0,4
basses M 3465 32,5 4,4 2,3 0,9 4,4 3,4 3,1 1,4
7 335 WM 5489 21,6 5,1 3,6 3,4 5,5 3,3 2,7 1,1
</p>
<p>TABLE 1 &#8211; &#201;valuation de l&#8217;extraction des voisins s&#233;mantiques (mesures donn&#233;es en pourcentage)
</p>
<p>&#233;tant ordonn&#233;s, il est en outre possible de r&#233;utiliser les m&#233;triques d&#8217;&#233;valuation classiquement
adopt&#233;es en recherche d&#8217;information en faisant jouer aux mots cibles le r&#244;le de requ&#234;tes et
aux voisins celui des documents. Les derni&#232;res colonnes du tableau 1 rendent compte de ces
mesures : la R-pr&#233;cision (R-pr&#233;c.) est la pr&#233;cision obtenue en se limitant aux R premiers voisins,
R &#233;tant le nombre de synonymes dans la ressource de r&#233;f&#233;rence pour l&#8217;entr&#233;e consid&#233;r&#233;e ; la MAP
(Mean Average Precision) est la moyenne des pr&#233;cisions pour chacun des rangs auxquels un
synonyme de r&#233;f&#233;rence a &#233;t&#233; identifi&#233; ; enfin, sont donn&#233;es les pr&#233;cisions pour diff&#233;rents seuils de
nombre de voisins s&#233;mantiques examin&#233;s (pr&#233;cision apr&#232;s examen des 1, 5, 10 et 100 premiers
voisins). Les r&#233;sultats du tableau 1 suscitent trois principales observations. En premier lieu, il faut
constater que les r&#233;sultats sont globalement faibles. Cette faiblesse touche &#224; la fois la proportion
des synonymes et mots li&#233;s trouv&#233;s et leur rang parmi les voisins s&#233;mantiques. Bien que les
comparaisons avec d&#8217;autres travaux soient rendues difficiles par la diversit&#233; des conditions de
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>51 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>construction et d&#8217;&#233;valuation des th&#233;saurus, il est n&#233;anmoins possible d&#8217;affirmer que cette faiblesse
ne nous est pas sp&#233;cifique. (Muller et Langlais, 2011) ont ainsi &#233;valu&#233; le th&#233;saurus construit
dans (Lin, 1998) avec les m&#234;mes mesures et les m&#234;mes r&#233;f&#233;rences que les n&#244;tres et trouvent
des r&#233;sultats assez comparables en tenant compte du fait que le corpus de (Lin, 1998) &#233;tait
beaucoup plus gros que le n&#244;tre, 3 milliards de mots, et que les donn&#233;es distributionnelles &#233;taient
extraites sur la base de cooccurrences syntaxiques. &#192; titre indicatif, l&#8217;utilisation de WordNet
comme r&#233;f&#233;rence pour des fr&#233;quences &gt; 5 000 donnent ainsi les valeurs suivantes pour les
donn&#233;es de Lin : P@1 = 16,5 ; P@5 = 5,0 ; P@10 = 3,5 ; MAP = 9,2 ; R-pr&#233;c. = 16,7. Par rapport
aux fr&#233;quences hautes du tableau 1, configuration la plus directement comparable, on constate
qu&#8217;en dehors de la R-pr&#233;cision, plus &#233;lev&#233;e dans le cas des donn&#233;es de Lin, les autres mesures
donnent des valeurs proches de celles rapport&#233;es dans (Muller et Langlais, 2011).
</p>
<p>Le deuxi&#232;me point que laisse appara&#238;tre ce tableau est la forte d&#233;pendance des r&#233;sultats vis-&#224;-vis
de la fr&#233;quence des entr&#233;es du th&#233;saurus. Les meilleurs r&#233;sultats sont ainsi obtenus par les mots
de la tranche de fr&#233;quences sup&#233;rieure tandis que les mesures d&#8217;&#233;valuation diminuent de fa&#231;on
tr&#232;s significative pour la tranche fr&#233;quentielle la plus basse. Le dernier constat a trait &#224; l&#8217;impact de
la r&#233;f&#233;rence utilis&#233;e pour l&#8217;&#233;valuation du th&#233;saurus. WordNet est ainsi caract&#233;ris&#233; par un nombre
restreint de synonymes pour chaque nom tandis que le th&#233;saurus Moby contient pour chaque
entr&#233;e un large ensemble de synonymes et de mots li&#233;s. La cons&#233;quence de cette diff&#233;rence
s&#8217;observe clairement au niveau des pr&#233;cisions &#224; diff&#233;rents rangs dans le tableau 1 : les valeurs
sont nettement sup&#233;rieures pour Moby par rapport &#224; WordNet alors que la mesure de similarit&#233;
sous-jacente est la m&#234;me. Seule la richesse de la r&#233;f&#233;rence varie. Ce ph&#233;nom&#232;ne est &#233;galement
illustr&#233; dans (Ferret, 2010) au travers de la comparaison avec (Curran et Moens, 2002).
</p>
<p>3 Am&#233;lioration d&#8217;un th&#233;saurus distributionnel
</p>
<p>3.1 Principes
</p>
<p>L&#8217;&#233;valuation de notre th&#233;saurus distributionnel initial montre que les voisins s&#233;mantiques obtenus
sont significativement meilleurs pour certaines entr&#233;es que pour d&#8217;autres. Une telle configuration
est a priori favorable &#224; un m&#233;canisme de type amor&#231;age dans la mesure o&#249; il est envisageable de
s&#8217;appuyer sur les r&#233;sultats des &#171; bonnes &#187; entr&#233;es pour obtenir une am&#233;lioration plus globale.
(Zhitomirsky-Geffet et Dagan, 2009) a d&#233;j&#224; fait appel &#224; l&#8217;amor&#231;age dans un contexte proche
du n&#244;tre, l&#8217;acquisition de relations d&#8217;implication textuelle entre mots. Cependant, des exp&#233;ri-
mentations rapport&#233;es dans (Ferret, 2010) ont montr&#233; que la transposition de cette approche
&#224; notre probl&#232;me n&#8217;&#233;tait pas concluante. Ainsi, au lieu d&#8217;utiliser les r&#233;sultats d&#8217;une mesure de
similarit&#233; initiale pour modifier directement les poids des &#233;l&#233;ments constitutifs des contextes
distributionnels, nous avons adopt&#233; une approche plus indirecte, fond&#233; sur (Hagiwara, 2008).
</p>
<p>(Hagiwara, 2008) a en effet montr&#233; qu&#8217;il est possible d&#8217;entra&#238;ner et d&#8217;appliquer avec un bon
niveau de performance un classifieur statistique, en l&#8217;occurrence de type Machine &#224; Vecteurs
de Support (SVM), pour d&#233;cider si deux mots sont ou ne sont pas synonymes, au sens large
du terme. Par ailleurs, ce travail montre &#233;galement que la valeur de la fonction de d&#233;cision
caract&#233;risant les SVM, dont on n&#8217;utilise que le signe dans le cas d&#8217;une classification binaire, peut
jouer, pour l&#8217;ordonnancement des voisins s&#233;mantiques, le m&#234;me r&#244;le que la valeur d&#8217;une mesure
de similarit&#233; telle que celle d&#233;finie &#224; la section 2.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>52 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#192; la diff&#233;rence de (Hagiwara, 2008), nous ne disposons pas d&#8217;un ensemble d&#8217;exemples et de
contre-exemples &#233;tiquet&#233;s manuellement pour r&#233;aliser l&#8217;entra&#238;nement d&#8217;un tel classifieur. En
revanche, les voisins s&#233;mantiques obtenus en appliquant la mesure de similarit&#233; de la section 2
peuvent &#234;tre exploit&#233;s pour construire un tel ensemble. Cette mesure n&#8217;offre pas de crit&#232;re
&#233;vident pour discriminer les mots s&#233;mantiquement li&#233;s1. Cependant, elle peut &#234;tre utilis&#233;e
plus indirectement pour s&#233;lectionner un ensemble d&#8217;exemples et de contre-exemples de fa&#231;on
non supervis&#233;e en minimisant le nombre d&#8217;erreurs. Ces erreurs correspondent &#224; des exemples
consid&#233;r&#233;s comme positifs mais en r&#233;alit&#233; n&#233;gatifs et d&#8217;exemples consid&#233;r&#233;s comme n&#233;gatifs
mais en fait positifs. Dans cette optique, nous proposons d&#8217;entra&#238;ner un classifieur SVM gr&#226;ce
&#224; ces ensembles et de l&#8217;appliquer ensuite pour r&#233;ordonner les voisins s&#233;mantiques obtenus
pr&#233;c&#233;demment. L&#8217;ensemble de la d&#233;marche peut &#234;tre r&#233;sum&#233;e par la proc&#233;dure suivante :
</p>
<p>&#8211; d&#233;finition d&#8217;une mesure de similarit&#233; distributionnelle ;
&#8211; application de cette mesure pour la construction d&#8217;un th&#233;saurus distributionnel par le biais de
</p>
<p>l&#8217;extraction de voisins s&#233;mantiques ;
&#8211; s&#233;lection non supervis&#233;e d&#8217;un ensemble d&#8217;exemples et de contre-exemples de mots s&#233;mantique-
</p>
<p>ment similaires gr&#226;ce aux r&#233;sultats de l&#8217;application de la mesure de similarit&#233; ;
&#8211; entra&#238;nement d&#8217;un classifieur statistique &#224; partir de l&#8217;ensemble d&#8217;exemples constitu&#233; ;
&#8211; application du classifieur entra&#238;n&#233; au r&#233;ordonnancement des voisins du th&#233;saurus initial.
</p>
<p>Le point cl&#233; de l&#8217;am&#233;lioration des r&#233;sultats par ce moyen est de s&#233;lectionner de fa&#231;on non
supervis&#233;e un nombre suffisant d&#8217;exemples et de contre-exemples en minimisant les erreurs
propres &#224; une telle s&#233;lection. Dans la section 4, nous proposons d&#8217;associer deux m&#233;thodes faibles,
&#224; la fois au sens de la productivit&#233; et de la validit&#233; des r&#233;sultats, pour accomplir cette t&#226;che.
</p>
<p>3.2 Repr&#233;sentation des exemples
</p>
<p>Avant de pr&#233;senter plus en d&#233;tail ce processus de s&#233;lection, il convient de pr&#233;ciser la nature des
exemples et des contre-exemples. Nous reprenons de ce point de vue la conception d&#233;velopp&#233;e
dans (Hagiwara, 2008) : un exemple est constitu&#233; d&#8217;un couple de mots consid&#233;r&#233;s comme
synonymes ou plus g&#233;n&#233;ralement s&#233;mantiquement li&#233;s ; un contre-exemple est form&#233; d&#8217;un couple
de mots entre lesquels un tel lien s&#233;mantique n&#8217;existe pas. La repr&#233;sentation de ces couples
pour un classifieur de type SVM s&#8217;effectue en associant leurs repr&#233;sentations distributionnelles.
Cette association s&#8217;effectue pour chaque couple (M1, M2) en sommant le poids des cooccurrents
communs aux mots M1 et M2. Les cooccurrents de Mx non pr&#233;sents dans My se voient attribuer
un poids nul. Chaque exemple ou contre-exemple a donc la m&#234;me forme que la repr&#233;sentation
distributionnelle d&#8217;un mot, c&#8217;est-&#224;-dire un vecteur de mots pond&#233;r&#233;s.
</p>
<p>4 S&#233;lection des exemples et des contre-exemples
</p>
<p>Du point de vue de la s&#233;lection des exemples et des contre-exemples de mots s&#233;mantiquement
li&#233;s, le tableau 1 offre une image claire : trouver des exemples est beaucoup plus probl&#233;matique
que trouver des contre-exemples dans la mesure o&#249; le nombre de mots s&#233;mantiquement li&#233;s &#224;
</p>
<p>1Fixer pour ce faire un seuil sur les valeurs de similarit&#233; produit de mauvais r&#233;sultats du fait de la variabilit&#233; de ces
valeurs d&#8217;une entr&#233;e &#224; l&#8217;autre. Ce constat a motiv&#233; notre choix d&#8217;utiliser un SVM en classification plut&#244;t qu&#8217;en r&#233;gression.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>53 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>une entr&#233;e du th&#233;saurus diminue tr&#232;s fortement d&#232;s que l&#8217;on consid&#232;re ses voisins de rang un
peu &#233;lev&#233;. Dans les exp&#233;rimentations de la section 5, nous avons ainsi construits nos contre-
exemples &#224; partir de nos exemples en cr&#233;ant pour chaque exemple (A,B) deux contre-exemples
de la forme : (A, voisin de rang 10 de A) et (B, voisin de rang 10 de B). Le choix d&#8217;un rang
sup&#233;rieur garantirait un nombre plus faible de faux contre-exemples (i.e. couples de synonymes)
et donc a priori, de meilleurs r&#233;sultats. En pratique, l&#8217;utilisation de voisins du mot cible de
rang assez faible conduit &#224; une performance sup&#233;rieure, sans doute parce que ceux-ci sont plus
utiles en termes de discrimination, &#233;tant plus proches de la zone de transition entre exemples
et contre-exemples. Nous avons par ailleurs constat&#233; exp&#233;rimentalement que le rapport entre
contre-exemples et exemples dans (Hagiwara, 2008), &#233;gal 6,5 et donc fortement d&#233;s&#233;quilibr&#233; en
faveur des contre-exemples, n&#8217;&#233;tait pas n&#233;cessaire dans notre situation et pouvait se ramener &#224; 2.
</p>
<p>Pour la s&#233;lection des exemples, le tableau 1 impose un double constat : trouver un voisin
s&#233;mantiquement proche est d&#8217;autant plus probable que la fr&#233;quence de l&#8217;entr&#233;e du th&#233;saurus
consid&#233;r&#233;e est &#233;lev&#233;e et que le rang du voisin est faible. La forme extr&#234;me de cette logique
conduirait &#224; retenir comme exemples tous les couples de mots (entr&#233;e de haute fr&#233;quence, voisin de
rang 1), ce qui donne un large nombre d&#8217;exemples &#8211; 7 335 &#8211; mais un taux d&#8217;erreur (i.e. nombre de
couples de mots non li&#233;s s&#233;mantiquement) &#233;galement &#233;lev&#233; &#8211; 63,6% dans le cas le plus favorable
(r&#233;f&#233;rence WM). Nous avons donc propos&#233; une approche plus s&#233;lective pour choisir nos exemples
parmi les entr&#233;es fr&#233;quentes du th&#233;saurus afin d&#8217;aboutir &#224; une solution plus &#233;quilibr&#233;e entre le
nombre d&#8217;exemples et leur taux d&#8217;erreur. Cette approche associe deux m&#233;thodes de s&#233;lection non
supervis&#233;es produisant chacune un nombre limit&#233; d&#8217;exemples mais avec un meilleur taux d&#8217;erreur.
Nous pr&#233;sentons ces m&#233;thodes dans les deux sections suivantes en d&#233;taillant plus sp&#233;cifiquement
celle fond&#233;e sur les mots compos&#233;s, nouvelle proposition de cet article.
</p>
<p>4.1 S&#233;lection fond&#233;e sur les relations de sym&#233;trie dans le th&#233;saurus
</p>
<p>Notre premi&#232;re m&#233;thode de s&#233;lection d&#8217;exemples de mots s&#233;mantiquement similaires a &#233;t&#233;
introduite dans (Ferret, 2012). Elle est fond&#233;e sur l&#8217;hypoth&#232;se que les relations de similarit&#233;
s&#233;mantique sont sym&#233;triques, ce qui est strictement vrai dans le cas des synonymes de WordNet
mais l&#8217;est moins pour les mots li&#233;s de Moby. En accord avec cette hypoth&#232;se, nous avons consid&#233;r&#233;
que si une entr&#233;e A du th&#233;saurus initial a pour voisin un mot B, ce voisin a d&#8217;autant plus de
chances d&#8217;&#234;tre s&#233;mantiquement similaire &#224; A que A est lui-m&#234;me un voisin de B en tant qu&#8217;entr&#233;e
du th&#233;saurus. Plus pr&#233;cis&#233;ment, les r&#233;sultats du tableau 1 nous ont conduit &#224; limiter l&#8217;application
de ce principe aux voisins de rang 1 et aux entr&#233;es de haute fr&#233;quence, dont les voisins sont
eux-m&#234;mes g&#233;n&#233;ralement des noms de haute fr&#233;quence. Nous avons donc appliqu&#233; ce principe
aux 7 335 entr&#233;es dites de haute fr&#233;quence du th&#233;saurus, obtenant des cas de sym&#233;trie entre
entr&#233;e et voisin de rang 1 pour 1 592 entr&#233;es. 796 exemples de mots s&#233;mantiquement similaires
ont finalement &#233;t&#233; produits puisque les couples (A,B) et (B,A) repr&#233;sentent un m&#234;me exemple.
</p>
<p>4.2 S&#233;lection fond&#233;e sur les mots compos&#233;s
</p>
<p>4.2.1 Construction d&#8217;un th&#233;saurus distributionnel de noms compos&#233;s
</p>
<p>La seconde m&#233;thode que nous proposons pour la s&#233;lection de couples de mots s&#233;mantiquement
similaires repose sur l&#8217;hypoth&#232;se que les mono-termes de deux mots compos&#233;s s&#233;mantiquement
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>54 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>similaires occupant dans ces deux termes le m&#234;me r&#244;le syntaxique sont eux-m&#234;mes susceptibles
d&#8217;&#234;tre s&#233;mantiquement similaires. Par exemple, les noms compos&#233;s movie_director et film_director
&#233;tant trouv&#233;s similaires et les t&#234;tes syntaxiques de ces deux compos&#233;s &#233;tant identiques, il est
vraisemblable que la similarit&#233; s&#233;mantique observ&#233;e entre film et movie dans le th&#233;saurus initial
soit v&#233;ritable. Le point de d&#233;part de cette hypoth&#232;se &#233;tant la similarit&#233; s&#233;mantique des mots
compos&#233;s, nous avons commenc&#233; par construire un th&#233;saurus distributionnel de noms compos&#233;s
pour l&#8217;anglais, &#224; l&#8217;image du th&#233;saurus de la section 2 pour les noms simples. Cette construction a
&#233;t&#233; r&#233;alis&#233;e &#224; partir du m&#234;me corpus et avec les m&#234;mes param&#232;tres que pour les mono-termes, &#224;
l&#8217;exception bien entendu de l&#8217;ajout d&#8217;une &#233;tape dans le pr&#233;traitement linguistique des documents
du corpus pour l&#8217;identification des noms compos&#233;s. Cette identification a &#233;t&#233; r&#233;alis&#233;e en deux
&#233;tapes : un ensemble de noms compos&#233;s ont d&#8217;abord &#233;t&#233; extraits du corpus AQUAINT-2 sur la
base d&#8217;un nombre limit&#233; de patrons morpho-syntaxiques ; les plus fr&#233;quents de ces compos&#233;s ont
ensuite &#233;t&#233; utilis&#233;s comme r&#233;f&#233;rence dans un processus d&#8217;indexation contr&#244;l&#233;e.
</p>
<p>La premi&#232;re &#233;tape a &#233;t&#233; mise en &#339;uvre gr&#226;ce &#224; l&#8217;outil mwetoolkit (Ramisch et al., 2010), qui
permet d&#8217;extraire efficacement des mots compos&#233;s d&#8217;un corpus &#224; partir du r&#233;sultat d&#8217;un &#233;tiqueteur
morpho-syntaxique, le TreeTagger dans notre cas, en s&#8217;appuyant sur un ensemble de patrons
morpho-syntaxiques. Nous nous sommes limit&#233;s aux trois patrons de noms compos&#233;s suivants :
&lt;nom&gt;&lt;nom&gt;,&lt;adjectif&gt;&lt;nom&gt;,&lt;nom&gt;&lt;pr&#233;position&gt;&lt;nom&gt;. Un ensemble de 3 246 401
noms compos&#233;s ont ainsi &#233;t&#233; extraits du corpus AQUAINT-2 parmi lesquels seuls les 30 121 termes
de fr&#233;quence sup&#233;rieure &#224; 100 ont &#233;t&#233; retenus, pour des raisons &#224; la fois de fiabilit&#233; et de limitation
du vocabulaire pour la construction du th&#233;saurus. L&#8217;identification de ces termes de r&#233;f&#233;rence
dans les textes a ensuite &#233;t&#233; r&#233;alis&#233;e en appliquant la strat&#233;gie de l&#8217;appariement maximal &#224; la
sortie lemmatis&#233;e du TreeTagger. Finalement, des contextes distributionnels constitu&#233;s &#224; la fois
de mots simples et de termes complexes ont &#233;t&#233; construits suivant les principes de la section 2 et
des voisins ont &#233;t&#233; trouv&#233;s pour 29 174 noms compos&#233;s.
</p>
<p>r&#233;f. #mots
&#233;val.
</p>
<p>#syn.
/mot
</p>
<p>rappel R-pr&#233;c. MAP P@1 P@5 P@10 P@100
</p>
<p>W 608 1,2 82,0 41,5 50,0 43,4 14,3 8,0 1,0
M 241 2,3 38,0 9,0 12,2 11,2 6,5 4,2 0,9
WM 813 1,6 63,5 32,7 39,5 34,9 12,3 7,1 1,0
</p>
<p>TABLE 2 &#8211; &#201;valuation du th&#233;saurus distributionnel pour les noms compos&#233;s
</p>
<p>Le tableau 2 donne les r&#233;sultats de l&#8217;&#233;valuation des voisins s&#233;mantiques trouv&#233;s en prenant
comme pr&#233;c&#233;demment en tant que r&#233;f&#233;rence WordNet, le th&#233;saurus Moby et la fusion des deux.
Le premier constat pouvant &#234;tre fait est la proportion tr&#232;s faible, par rapport aux mono-termes,
d&#8217;entr&#233;es ayant pu &#234;tre &#233;valu&#233;es : seulement 2,8% des entr&#233;es, &#224; comparer &#224; 83,5% des entr&#233;es
pour les mono-termes. De ce fait, les r&#233;sultats de cette &#233;valuation doivent &#234;tre consid&#233;r&#233;s avec
prudence, m&#234;me si le nombre d&#8217;entr&#233;es &#233;valu&#233;es est globalement plus &#233;lev&#233; que le nombre
d&#8217;entr&#233;es consid&#233;r&#233;es dans les &#233;valuations standards : 70 pour (Curran et Moens, 2002) ou 353
pour (Gabrilovich, 2007). Cette prudence est particuli&#232;rement de mise pour les mots li&#233;s de
Moby : les r&#233;sultats, &#224; l&#8217;exception du rappel, sont tr&#232;s significativement inf&#233;rieurs &#224; ceux obtenus
avec les mono-termes mais le nombre d&#8217;entr&#233;es &#233;valu&#233;es &#8211; 241 &#8211; est aussi faible. &#192; l&#8217;inverse,
les performances obtenues pour les synonymes de WordNet sont tr&#232;s nettement sup&#233;rieures sur
tous les plans &#224; celles caract&#233;risant les mono-termes, ces r&#233;sultats &#233;tant obtenus pour un nombre
d&#8217;entr&#233;es &#8211; 608 &#8211; nettement sup&#233;rieur. Cette diff&#233;rence ne s&#8217;expliquant pas par un biais concernant
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>55 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>la fr&#233;quence des entr&#233;es &#233;valu&#233;es vis-&#224;-vis respectivement de WordNet et de Moby, il semble donc
que le comportement des noms compos&#233;s soit, du point de vue des similarit&#233;s distributionnelles,
l&#8217;inverse de celui des noms simples, favorisant les relations s&#233;mantiques paradigmatiques par
rapport aux relations syntagmatiques. La plus faible ambigu&#239;t&#233; s&#233;mantique des noms compos&#233;s
serait une explication possible de ce ph&#233;nom&#232;ne qui demanderait n&#233;anmoins une &#233;tude plus
approfondie avec une base d&#8217;&#233;valuation plus large.
</p>
<p>4.2.2 S&#233;lection d&#8217;exemples &#224; partir de noms compos&#233;s
</p>
<p>La s&#233;lection d&#8217;exemples de mots simples s&#233;mantiquement similaires &#224; partir de noms compos&#233;s
s&#8217;appuie sur la structure syntaxique de ces noms compos&#233;s. Compte tenu des patrons utilis&#233;s
pour l&#8217;extraction des termes, cette structure prend la forme de l&#8217;un des trois grands sch&#233;mas
suivants :&lt;nom&gt;expansion &lt;nom&gt;t e&#770;te,&lt;adjectif&gt;expansion &lt;nom&gt;t e&#770;te,&lt;nom&gt;t e&#770;te &lt;pr&#233;position&gt;
&lt;nom&gt;expansion.
</p>
<p>Chaque nom compos&#233; Ci a ainsi &#233;t&#233; repr&#233;sent&#233; sous la forme d&#8217;un couple de noms (Ti , Ei), dans
lequel Ti repr&#233;sente la t&#234;te syntaxique de Ci et Di , son expansion, au sens des grammaires
de d&#233;pendance. Conform&#233;ment au principe sous-tendant notre m&#233;thode s&#233;lection, si un nom
compos&#233; (T2, E2) est un voisin s&#233;mantique d&#8217;un nom compos&#233; (T1, E1) (au plus, son cie&#768;me voisin),
il est probable que T1 et T2 ou E1 et E2 soient s&#233;mantiquement similaires2. Comme le montre le
tableau 2, notre th&#233;saurus distributionnel de noms compos&#233;s est cependant loin d&#8217;&#234;tre parfait.
Pour limiter les erreurs, nous avons ajout&#233; des contraintes sur l&#8217;appariement des constituants des
noms compos&#233;s similaires en nous appuyant sur la similarit&#233; distributionnelle de ces constituants.
Au final, nous s&#233;lectionnons des exemples de noms simples s&#233;mantiquement similaires (couples
de noms suivant&#8594;) en appliquant les trois r&#232;gles suivantes, dans lesquelles E1 = E2 signifie que
E1 et E2 sont identiques et T1 &#8801; T2 signifie que T2 est au plus le nie&#768;me voisin de T1 dans notre
th&#233;saurus de noms simples :
</p>
<p>(1) T1 &#8801; T2 et E1 = E2&#8594; (T1, T2)
(crash, accident) issu de car_crash et car_accident ; (boat, vessel) de fishing_vessel et fishing_boat
</p>
<p>(2) E1 &#8801; E2 et T1 = T2&#8594; (E1, E2)
(ocean, sea) de ocean_floor et sea_floor ; (jail, prison) de prison_cell et jail_cell
</p>
<p>(3) E1 &#8801; E2 et T1 &#8801; T2&#8594; (T1, T2), (E1, E2)
(increase, rise) et (salary, pay) de salary_increase et pay_rise
</p>
<p>5 Exp&#233;rimentations et &#233;valuation
</p>
<p>5.1 S&#233;lection des exemples de mots s&#233;mantiquement similaires
</p>
<p>Le tableau 3 fait une synth&#232;se des r&#233;sultats de nos deux m&#233;thodes de s&#233;lection de mots s&#233;manti-
quement similaires en donnant le pourcentage des couples s&#233;lectionn&#233;s trouv&#233;s dans chacune
de nos ressources (W, M et WM) ainsi que la taille de chaque ensemble d&#8217;exemples. Dans le cas
de la seconde m&#233;thode, ces mesures sont &#233;galement d&#233;clin&#233;es au niveau de chacune des trois
</p>
<p>2Notons que nous ne nous int&#233;ressons pas ici &#224; la similarit&#233; entre E1 et E2 lorsque ce sont des adjectifs.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>56 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>r&#232;gles de s&#233;lection. Les chiffres donn&#233;s entre crochets repr&#233;sentent quant &#224; eux les pourcentages
d&#8217;erreurs parmi les exemples de mots non similaires. Ces r&#233;sultats ont &#233;t&#233; obtenus en fixant
exp&#233;rimentalement la taille du voisinage consid&#233;r&#233; pour les entr&#233;es &#224; 3 pour les noms compos&#233;s
(c) et &#224; 1 pour les noms simples (n). En outre, ces trois r&#232;gles de s&#233;lection ont &#233;t&#233; appliqu&#233;es
avec l&#8217;ensemble des entr&#233;es du th&#233;saurus des noms compos&#233;s et les entr&#233;es du th&#233;saurus des
noms simples dites de haute fr&#233;quence. Les valeurs des param&#232;tres c et n ne r&#233;sultent pas d&#8217;une
optimisation sophistiqu&#233;e mais r&#233;pondent plut&#244;t une logique induite des &#233;valuations r&#233;alis&#233;es :
pour les mono-termes, seul le premier voisin est retenu du fait de la faiblesse des r&#233;sultats alors
que pour les multi-termes, le voisinage peut &#234;tre l&#233;g&#232;rement &#233;largi du fait d&#8217;une meilleure fiabilit&#233;
des voisins. Il est &#224; noter par ailleurs que l&#8217;association de deux ensembles d&#8217;exemples s&#233;lectionn&#233;s
par des m&#233;thodes diff&#233;rentes rend les r&#233;sultats plus stables vis-&#224;-vis des valeurs de c et n.
</p>
<p>m&#233;thode W M WM # exemples
sym&#233;trie 36,6 [2,0] 55,5 [14,4] 59,7 [12,4] 796
r&#232;gle (1) 19,3 56,1 56,9 921
r&#232;gle (2) 16,2 42,4 44,7 308
r&#232;gle (3) 13,5 45,9 46,2 40
r&#232;gles (1,2) 17,8 [2,5] 52,2 [16,8] 53,0 [16,1] 1 115
r&#232;gles (1,2,3) 17,6 51,7 52,4 1 131
sym&#233;trie + r&#232;gles (1,2) 23,5 [2,3] 52,5 [16,3] 54,3 [15,0] 1 710
sym&#233;trie + r&#232;gles (1,2,3) 23,3 52,1 53,9 1 725
</p>
<p>TABLE 3 &#8211; R&#233;sultats de la s&#233;lection des exemples
</p>
<p>L&#8217;&#233;valuation de la seconde m&#233;thode de s&#233;lection montre d&#8217;abord que la r&#232;gle (3), qui est a priori
la moins fiable des trois, ne produit effectivement qu&#8217;un petit nombre d&#8217;exemples tendant &#224;
d&#233;grader les r&#233;sultats. De ce fait, seule la combinaison des r&#232;gles (1) et (2) a &#233;t&#233; utilis&#233;e dans ce
qui suit. Cette &#233;valuation montre en outre que les t&#234;tes de deux noms compos&#233;s s&#233;mantiquement
li&#233;s ont davantage tendance &#224; &#234;tre elles-m&#234;mes similaires si leurs expansions sont similaires
que n&#8217;ont tendance &#224; &#234;tre similaires des expansions de deux noms compos&#233;s dont les t&#234;tes sont
similaires. Ce r&#233;sultat n&#8217;&#233;tait pas &#233;vident a priori dans la mesure o&#249; l&#8217;on s&#8217;attend &#224; ce que la t&#234;te
d&#8217;un compos&#233; soit davantage repr&#233;sentatif de son sens que son expansion. Plus globalement, le
tableau 3 laisse appara&#238;tre que la premi&#232;re m&#233;thode de s&#233;lection est sup&#233;rieure &#224; la seconde mais
que leur association produit un compromis int&#233;ressant entre le nombre d&#8217;exemples, 1 710, et son
taux d&#8217;erreur, 45,7% avec WM comme r&#233;f&#233;rence. Cette compl&#233;mentarit&#233; est &#233;galement illustr&#233;e
par le faible nombre d&#8217;exemples &#8211; 201 &#8211; qu&#8217;elles partagent.
</p>
<p>5.2 Mise en &#339;uvre du r&#233;ordonnancement des voisins
</p>
<p>La mise en &#339;uvre effective de notre approche de r&#233;ordonnancement des voisins s&#233;mantiques
n&#233;cessite de fixer un certain nombre de param&#232;tres li&#233;s aux SVM. De m&#234;me que (Hagiwara,
2008), nous avons adopt&#233; un noyau RBF et une strat&#233;gie de type grid search pour l&#8217;optimisation
du param&#232;tre &#947; fixant la largeur de la fonction gaussienne du noyau RBF et du param&#232;tre C
d&#8217;ajustement entre la taille de la marge et le taux d&#8217;erreur. Cette optimisation a &#233;t&#233; r&#233;alis&#233;e pour
chaque ensemble d&#8217;apprentissage consid&#233;r&#233; en se fondant sur la mesure de pr&#233;cision calcul&#233;e
dans le cadre d&#8217;une validation crois&#233;e divisant ces ensembles en 5 parties. Chaque mod&#232;le SVM
correspondant a &#233;t&#233; construit en utilisant l&#8217;outil LIBSVM puis appliqu&#233; &#224; la totalit&#233; des 14 670
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>57 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>noms cibles de notre &#233;valuation initiale. Plus pr&#233;cis&#233;ment, pour chaque nom cible NC , une
repr&#233;sentation d&#8217;exemple a &#233;t&#233; construite pour chaque couple (NC , voisin de NC) et a &#233;t&#233;
soumise au mod&#232;le SVM consid&#233;r&#233; en mode classification. L&#8217;ensemble de ces voisins ont ensuite
&#233;t&#233; r&#233;ordonn&#233;s suivant la valeur de la fonction de d&#233;cision ainsi calcul&#233;e pour chaque voisin.
</p>
<p>5.3 &#201;valuation
</p>
<p>Le tableau 4 donne les r&#233;sultats globaux du r&#233;ordonnancement r&#233;alis&#233; sur la base des exemples
s&#233;lectionn&#233;s par chacune des deux m&#233;thodes pr&#233;sent&#233;es tandis que les r&#233;sultats d&#233;taill&#233;s du
tableau 5 correspondent au r&#233;ordonnancement fond&#233; sur l&#8217;association des deux m&#233;thodes de
s&#233;lection. Chacun des ces trois th&#233;saurus a &#233;t&#233; &#233;valu&#233; selon les m&#234;mes principes qu&#8217;&#224; la section 2.2.
La valeur de chaque mesure se voit associer sa diff&#233;rence avec la valeur correspondante pour
le th&#233;saurus initial dans le tableau 1. Enfin, comme l&#8217;&#233;valuation s&#8217;applique au r&#233;sultat d&#8217;un
r&#233;ordonnancement, les mesures de rappel et de pr&#233;cision au rang le plus lointain ne changent
pas et ne sont pas rappel&#233;es.
</p>
<p>m&#233;thode r&#233;f. R-pr&#233;c. MAP P@1 P@5 P@10
W 7,8 (-0,4) 9,4 (-0,4) 11,2 (-0,5) &#8225; 5,0 (-0,1) &#8225; 3,3 (-0,1) &#8225;
</p>
<p>sym&#233;trie M 7,1 (0,4) 3,4 (0,2) 27,3 (3,2) 17,6 (1,2) 13,7 (0,7)
WM 8,0 (0,3) 5,7 (0,1) 24,6 (2,1) 14,9 (0,8) 11,4 (0,6)
W 7,2 (-1,0) 8,8 (-1,0) 10,4 (-1,3) 4,6 (-0,5) 3,1 (-0,3)
</p>
<p>compos&#233;s M 7,1 (0,4) 3,3 (0,1) 26,8 (2,7) 17,4 (1,0) 13,5 (0,5)
WM 7,8 (0,1) 5,5 (-0,1) 24,0 (1,5) 14,6 (0,5) 11,2 (0,4)
</p>
<p>TABLE 4 &#8211; R&#233;ordonnancement des voisins s&#233;mantiques de toutes les entr&#233;es du th&#233;saurus initial
pour chaque m&#233;thode de s&#233;lection d&#8217;exemples
</p>
<p>La tendance g&#233;n&#233;rale est claire : le processus de r&#233;ordonnancement conduit &#224; une am&#233;lioration
significative des r&#233;sultats &#224; l&#8217;&#233;chelle globale (tableau 4 et lignes tous du tableau 5) pour les
r&#233;f&#233;rences M et WM3. Parall&#232;lement, une diminution des r&#233;sultats est observ&#233;e pour la r&#233;f&#233;rence
W, diminution statistiquement non significative pour le tableau 5. En d&#8217;autres termes, par rapport
au th&#233;saurus initial, la proc&#233;dure de r&#233;ordonnancement tend &#224; favoriser les mots similaires
au d&#233;triment des synonymes. Cette tendance n&#8217;est pas surprenante compte tenu du principe
de ce r&#233;ordonnancement : les premiers sont en effet mieux repr&#233;sent&#233;s que les seconds dans
les exemples s&#233;lectionn&#233;s du fait m&#234;me de leur meilleure repr&#233;sentation au niveau global. Les
mod&#232;les SVM appris ne font en l&#8217;occurrence qu&#8217;amplifier un &#233;tat de fait d&#233;j&#224; pr&#233;sent initialement.
Ce biais est particuli&#232;rement fort pour la m&#233;thode de s&#233;lection fond&#233;e sur les noms compos&#233;s,
comme l&#8217;illustre le tableau 4. Cependant, les r&#233;sultats du tableau 5 montrent clairement l&#8217;int&#233;r&#234;t
de l&#8217;association des deux m&#233;thodes de s&#233;lection, la m&#233;thode de s&#233;lection fond&#233;e sur la sym&#233;trie
des relations venant r&#233;&#233;quilibrer ce biais au b&#233;n&#233;fice des r&#233;sultats globaux. Par ailleurs, en
associant la partie du th&#233;saurus initial correspondant aux fr&#233;quences hautes et la partie du
th&#233;saurus apr&#232;s r&#233;ordonnancement correspondant aux fr&#233;quences basses (cf. ligne hybride du
tableau 5), on obtient un th&#233;saurus hybride dont les r&#233;sultats sont sup&#233;rieurs &#224; ceux du th&#233;saurus
initial pour toutes les conditions.
</p>
<p>3La significativit&#233; statistique des diff&#233;rences a &#233;t&#233; &#233;valu&#233;e gr&#226;ce &#224; un test de Wilcoxon avec un seuil de 0,05, les
&#233;chantillons &#233;tant appari&#233;s. Seules les diff&#233;rences suivies du signe &#8225; sont consid&#233;r&#233;es comme non significatives.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>58 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>fr&#233;q. r&#233;f. R-pr&#233;c. MAP P@1 P@5 P@10
W 7,9 (-0,3) &#8225; 9,5 (-0,3) &#8225; 11,5 (-0,2) &#8225; 5,1 (0,0) &#8225; 3,4 (0,0) &#8225;
</p>
<p>toutes M 7,2 (0,5) 3,5 (0,3) 27,9 (3,8) 18,1 (1,7) 14,1 (1,1)
WM 8,0 (0,3) 5,8 (0,2) 25,3 (2,8) 15,3 (1,2) 11,7 (0,9)
W 9,9 (-1,9) 11,7 (-1,8) 15,1 (-2,3) 6,8 (-0,7) 4,5 (-0,4)
</p>
<p>hautes M 9,4 (0,0) 4,5 (-0,1) &#8225; 37,5 (1,6) 24,3 (0,1) &#8225; 19,0 (0,1) &#8225;
WM 10,5 (-0,6) &#8225; 6,8 (-0,6) 36,7 (0,3) &#8225; 22,5 (-0,3) &#8225; 17,4 (-0,1) &#8225;
W 5,4 (1,7) 6,8 (1,7) 6,9 (2,7) 3,0 (1,0) 2,0 (0,6)
</p>
<p>basses M 3,5 (1,2) 1,7 (0,8) 12,0 (7,6) 7,8 (4,4) 5,9 (2,8)
WM 5,0 (1,4) 4,6 (1,2) 11,3 (5,8) 6,5 (3,2) 4,7 (2,0)
W 9,0 (0,8) 10,6 (0,8) &#8225; 12,8 (1,1) 5,6 (0,5) 3,6 (0,2)
</p>
<p>toutes M 7,2 (0,5) 3,5 (0,3) &#8225; 26,9 (2,8) 18,1 (1,7) 14,1 (1,1)
(hybride) WM 8,3 (0,6) 6,1 (0,5) &#8225; 25,1 (2,6) 15,5 (1,4) 11,8 (1,0)
</p>
<p>TABLE 5 &#8211; R&#233;ordonnancement du th&#233;saurus initial avec les deux m&#233;thodes de s&#233;lection d&#8217;exemples
</p>
<p>L&#8217;analyse des r&#233;sultats du tableau 5 en termes de fr&#233;quence des mots met en &#233;vidence une seconde
grande tendance : l&#8217;am&#233;lioration produite par le r&#233;ordonnancement est d&#8217;autant plus sensible que
la fr&#233;quence de l&#8217;entr&#233;e du th&#233;saurus est faible. Ainsi, pour les noms de faible fr&#233;quence, cette
am&#233;lioration s&#8217;observe quelle que soit la r&#233;f&#233;rence tandis que pour les noms de forte fr&#233;quence,
la variation est n&#233;gative pour certaines r&#233;f&#233;rences et mesures et positive pour d&#8217;autres. Ce constat
montre que le r&#233;ordonnancement tend ainsi &#224; r&#233;&#233;quilibrer le th&#233;saurus initial, tr&#232;s fortement
biais&#233; vers les fortes fr&#233;quences. Enfin, l&#8217;&#233;valuation de ces trois th&#233;saurus confirment les r&#233;sultats
du tableau 3 &#224; propos de chaque ensemble d&#8217;exemples s&#233;lectionn&#233;s : le th&#233;saurus construit &#224;
partir des exemples de la premi&#232;re m&#233;thode de s&#233;lection est meilleur que celui construit &#224; partir
des exemples de la seconde m&#233;thode de s&#233;lection et les deux sont nettement d&#233;pass&#233;s par le
th&#233;saurus construit &#224; partir de la fusion des deux ensembles d&#8217;exemples.
</p>
<p>WordNet respect, admiration, regard
</p>
<p>Moby
</p>
<p>admiration, appreciation, acceptance, dignity, regard, respect, account,
adherence, consideration, estimate, estimation, fame, greatness, homage,
honor, prestige, prominence, reverence, veneration + 74 mots li&#233;s sup-
pl&#233;mentaires
</p>
<p>initial
cordiality, gratitude, admiration, comradeship, back-scratching, per-
plexity, respect, ruination, appreciation, neighbourliness, trust, empathy,
suffragette, goodwill . . .
</p>
<p>apr&#232;s r&#233;ordonnan-
cement
</p>
<p>respect, admiration, trust, recognition, gratitude, confidence, affec-
tion, understanding, solidarity, dignity, appreciation, regard, sympathy,
acceptance . . .
</p>
<p>TABLE 6 &#8211; Impact du r&#233;ordonnancement pour l&#8217;entr&#233;e esteem
</p>
<p>Enfin, le tableau 6 illustre pour une entr&#233;e sp&#233;cifique du th&#233;saurus initial, en l&#8217;occurrence le mot
esteem, l&#8217;impact du r&#233;ordonnancement fond&#233; sur les deux m&#233;thodes de s&#233;lection d&#8217;exemples.
Ce tableau donne d&#8217;abord pour cette entr&#233;e ses synonymes dans WordNet et les premiers mots
qui lui sont li&#233;s dans Moby. Il fait ensuite appara&#238;tre que dans notre th&#233;saurus initial, les deux
premiers voisins de cette entr&#233;e apparaissant dans une de nos deux ressources de r&#233;f&#233;rence
sont les mots admiration, au rang 3, et le mot respect, au rang 7. Le r&#233;ordonnancement am&#233;liore
significativement la situation puisque ces deux mots deviennent les deux premiers voisins tandis
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>59 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>que le 3e&#768;me synonyme donn&#233; par WordNet passe du rang 22 au rang 12. Par ailleurs, le nombre
de voisins pr&#233;sents parmi les 14 premiers mots li&#233;s de Moby passe de 3 &#224; 6.
</p>
<p>6 Conclusion et perspectives
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; une m&#233;thode fond&#233;e sur l&#8217;amor&#231;age pour am&#233;liorer un
th&#233;saurus distributionnel. Plus pr&#233;cis&#233;ment, cette m&#233;thode se fonde sur le r&#233;ordonnancement des
voisins s&#233;mantiques de ce th&#233;saurus par le biais d&#8217;un classifieur SVM. Ce classifieur est entra&#238;n&#233; &#224;
partir d&#8217;un ensemble d&#8217;exemples et de contre-exemples s&#233;lectionn&#233;s de fa&#231;on non supervis&#233;e en
combinant deux crit&#232;res faibles fond&#233;s sur la similarit&#233; distributionnelle. L&#8217;un exploite la sym&#233;trie
des relations s&#233;mantiques tandis que l&#8217;autre s&#8217;appuie sur l&#8217;appariement des constituants de noms
compos&#233;s similaires. Les am&#233;liorations apport&#233;es par cette m&#233;thode sont plus particuli&#232;rement
notables pour les noms de fr&#233;quence faible ou interm&#233;diaire et pour des mots similaires plut&#244;t
que pour de stricts synonymes.
</p>
<p>Nous envisageons plusieurs pistes d&#8217;extension de ce travail. Tout d&#8217;abord, nous souhaitons
appliquer, tout en conservant une s&#233;lection d&#8217;exemples non supervis&#233;e, des techniques de s&#233;lection
de caract&#233;ristiques afin de mettre en &#233;vidence les traits les plus int&#233;ressants du point de vue de
la similarit&#233; s&#233;mantique, en particulier pour am&#233;liorer les th&#233;saurus distributionnels produits
en construisant des mod&#232;les plus g&#233;n&#233;raux de cette similarit&#233;. L&#8217;&#233;largissement des crit&#232;res de
s&#233;lection non supervis&#233;e d&#8217;exemples est une deuxi&#232;me extension assez directe du travail pr&#233;sent&#233;.
Alors que les techniques de s&#233;lection exp&#233;riment&#233;es reposent toutes deux sur des th&#233;saurus
distributionnels, des crit&#232;res s&#8217;attachant aux occurrences des mots et &#224; leur environnement plut&#244;t
qu&#8217;&#224; une repr&#233;sentation distributionnelle sont &#233;galement envisageables, comme l&#8217;utilisation de
patrons linguistiques classiques d&#8217;extraction de synonymes par exemple. Sur un autre plan,
l&#8217;&#233;valuation men&#233;e, fond&#233;e sur la comparaison avec des ressources de r&#233;f&#233;rence, pourrait &#234;tre
compl&#233;t&#233;e avec profit par une &#233;valuation in vivo permettant de juger de l&#8217;impact des am&#233;liorations
du th&#233;saurus distributionnel sur une t&#226;che auquel il contribue. Parmi les nombreuses t&#226;ches
possibles, nous serions particuli&#232;rement int&#233;ress&#233;s par celle de segmentation th&#233;matique, dans
le prolongement de (Adam et Morlane-Hond&#232;re, 2009). Enfin, nous planifions d&#8217;appliquer la
m&#233;thode d&#233;crite au fran&#231;ais en nous appuyant sur des th&#233;saurus distributionnels comme freDist
(Anguiano et Denis, 2011).
</p>
<p>R&#233;f&#233;rences
</p>
<p>ADAM, C. et MORLANE-HOND&#200;RE, F. (2009). D&#233;tection de la coh&#233;sion lexicale par voisinage
distributionnel : application &#224; la segmentation th&#233;matique. In RECITAL&#8217;09, Senlis, France.
</p>
<p>ANGUIANO, E. H. et DENIS, P. (2011). FreDist : Automatic construction of distributional thesauri
for French. In TALN 2011, session articles courts, Montpellier, France.
</p>
<p>BANERJEE, S. B. et PEDERSEN, T. (2003). Extended gloss overlaps as a measure of semantic
relatedness. In Eighteenth International Conference on Artificial Intelligence (IJCAI-03), Mexico.
</p>
<p>BRODA, B., PIASECKI, M. et SZPAKOWICZ, S. (2009). Rank-Based Transformation in Measuring
Semantic Relatedness. In 22nd Canadian Conference on Artificial Intelligence, pages 187&#8211;190.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>60 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>BUDANITSKY, A. et HIRST, G. (2006). Evaluating wordnet-based measures of lexical semantic
relatedness. Computational Linguistics, 32(1):13&#8211;47.
CURRAN, J. et MOENS, M. (2002). Improvements in automatic thesaurus extraction. In Workshop
of the ACL Special Interest Group on the Lexicon (SIGLEX), pages 59&#8211;66, Philadelphia, USA.
FERRET, O. (2010). Similarit&#233; s&#233;mantique et extraction de synonymes &#224; partir de corpus. In
TALN 2010.
FERRET, O. (2012). Combining bootstrapping and feature selection for improving a distributional
thesaurus. In 20th European Conference on Artificial Intelligence (ECAI 2012), pages 336&#8211;341.
FREITAG, D., BLUME, M., BYRNES, J., CHOW, E., KAPADIA, S., ROHWER, R. et WANG, Z. (2005). New
experiments in distributional representations of synonymy. In CoNLL 2005, pages 25&#8211;32.
GABRILOVICH, Evgeniyand Markovitch, S. (2007). Computing semantic relatedness using
wikipedia-based explicit semantic analysis. In IJCAI 2007, pages 6&#8211;12.
GREFENSTETTE, G. (1994). Explorations in automatic thesaurus discovery. Kluwer Academic
Publishers.
HAGIWARA, M. (2008). A supervised learning approach to automatic synonym identification
based on distributional features. In ACL-08, student session, Columbus, Ohio.
HEYLEN, K., PEIRSMANY, Y., GEERAERTS, D. et SPEELMAN, D. (2008). Modelling Word Similarity : An
Evaluation of Automatic Synonymy Extraction Algorithms. In LREC 2008, Marrakech, Morocco.
KAZAMA, J., DE SAEGER, S., KURODA, K., MURATA, M. et TORISAWA, K. (2010). A bayesian method
for robust estimation of distributional similarities. In ACL 2010, pages 247&#8211;256.
LANDAUER, T. K. et DUMAIS, S. T. (1997). A solution to Plato&#8217;s problem : the latent semantic
analysis theory of acquisition, induction, and representation of knowledge. Psychological review,
104(2):211&#8211;240.
LIN, D. (1998). Automatic retrieval and clustering of similar words. In ACL-COLING&#8217;98, pages
768&#8211;774.
MULLER, P. et LANGLAIS, P. (2011). Comparaison d&#8217;une approche miroir et d&#8217;une approche
distributionnelle pour l&#8217;extraction de mots s&#233;mantiquement reli&#233;s. In TALN 2011.
PAD&#211;, S. et LAPATA, M. (2007). Dependency-based construction of semantic space models.
Computational Linguistics, 33(2):161&#8211;199.
PEDERSEN, T., PATWARDHAN, S. et MICHELIZZI, J. (2004). Wordnet : :similarity - measuring the
relatedness of concepts. In HLT-NAACL 2004, demonstration papers, pages 38&#8211;41.
RAMISCH, C., VILLAVICENCIO, A. et BOITET, C. (2010). mwetoolkit : a Framework for Multiword
Expression Identification. In LREC&#8217;10, Valetta, Malta.
REISINGER, J. et MOONEY, R. J. (2010). Multi-prototype vector-space models of word meaning.
In HLT-NAACL 2010, pages 109&#8211;117.
SCHMID, H. (1994). Probabilistic part-of-speech tagging using decision trees. In International
Conference on New Methods in Language Processing.
WEEDS, J. (2003). Measures and Applications of Lexical Distributional Similarity. Th&#232;se de
doctorat, Department of Informatics, University of Sussex.
YAMAMOTO, K. et ASAKURA, T. (2010). Even unassociated features can improve lexical distribu-
tional similarity. In Second Workshop on NLP Challenges in the Information Explosion Era (NLPIX
2010), pages 32&#8211;39, Beijing, China.
ZHITOMIRSKY-GEFFET, M. et DAGAN, I. (2009). Bootstrapping Distributional Feature Vector Quality.
Computational Linguistics, 35(3):435&#8211;461.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>61 c&#65535; ATALA</p>

</div></div>
</body></html>