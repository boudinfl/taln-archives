<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Approches statistiques discriminantes pour l&#8217;interpr&#233;tation s&#233;mantique multilingue de la parole</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Approches statistiques discriminantes pour l&#8217;interpr&#233;tation
s&#233;mantique multilingue de la parole
</p>
<p>Bassam Jabaian1, Fabrice Lef&#232;vre1, Laurent Besacier2
(1) LIA, Universit&#233; d&#8217;Avignon et des Pays de Vaucluse, Avignon, France
</p>
<p>(2) LIG, Universit&#233; Joseph Fourrier, Grenoble, France
</p>
<p>R&#201;SUM&#201;
</p>
<p>Les approches statistiques sont maintenant tr&#232;s r&#233;pandues dans les diff&#233;rentes appli-
cations du traitement automatique de la langue et le choix d&#8217;une approche particuli&#232;re
d&#233;pend g&#233;n&#233;ralement de la t&#226;che vis&#233;e. Dans le cadre de l&#8217;interpr&#233;tation s&#233;mantique
multilingue, cet article pr&#233;sente une comparaison entre les m&#233;thodes utilis&#233;es pour la
traduction automatique et celles utilis&#233;es pour la compr&#233;hension de la parole. Cette
comparaison permet de proposer une approche unifi&#233;e afin de r&#233;aliser un d&#233;codage conjoint
qui &#224; la fois traduit une phrase et lui attribue ses &#233;tiquettes s&#233;mantiques. Ce d&#233;codage est
obtenu par une approche &#224; base de transducteurs &#224; &#233;tats finis qui permet de composer un
graphe de traduction avec un graphe de compr&#233;hension. Cette repr&#233;sentation peut &#234;tre
g&#233;n&#233;ralis&#233;e pour permettre des transmissions d&#8217;informations riches entre les composants
d&#8217;un syst&#232;me d&#8217;interaction vocale homme-machine.
</p>
<p>ABSTRACT
Discriminative statistical approaches for multilingual speech understanding
</p>
<p>Statistical approaches are now widespread in the various applications of natural language
processing and the elicitation of an approach usually depends on the targeted task. This
paper presents a comparison between the methods used for machine translation and speech
understanding. This comparison allows to propose a unified approach to perform a joint
decoding which translates a sentence and assign semantic tags to the translation at the same
time. This decoding is achieved through a finite-state transducer approach which allows
to compose a translation graph with an understanding graph. This representation can be
generalized to allow the rich transmission of information between the components of a
human-machine vocal interface.
</p>
<p>MOTS-CL&#201;S : compr&#233;hension multilingue, syst&#232;me de dialogue, CRF, graphes d&#8217;hypoth&#232;ses.
KEYWORDS: multilingual understanding, dialogue system, CRF, hypothesis graphs.
</p>
<p>1 Introduction
</p>
<p>Aujourd&#8217;hui, les approches statistiques sont tr&#232;s utilis&#233;es pour toutes les applications du
traitement automatique de la langue (reconnaissance de la parole, traduction automatique,
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>90 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>analyse syntaxique, &#233;tiquetage s&#233;mantique...). La performance d&#8217;une approche particuli&#232;re
d&#233;pend &#233;norm&#233;ment de la t&#226;che &#224; laquelle elle est appliqu&#233;e. Et, selon les t&#226;ches, les approches
permettant les meilleures performances ne sont pas toujours les m&#234;mes.
</p>
<p>Par exemple, pour une t&#226;che de compr&#233;hension de la parole (Spoken Language Understanding,
SLU), assimilable &#224; un &#233;tiquetage s&#233;quentiel en concepts, les champs al&#233;atoires conditionnels
(Conditional Random Fields, CRF) (Lafferty et al., 2001) utilis&#233;s dans leur version cha&#238;ne
lin&#233;aire sont les plus performants (Hahn et al., 2010). Alors que pour la traduction automa-
tique, ce sont les mod&#232;les de traduction log-lin&#233;aires &#224; base de segments sous-phrastiques
(Log-linear Phrase-Based Statistical Machine Translation, LLPB-SMT) (Koehn et al., 2003), qui
sont le plus souvent utilis&#233;s.
</p>
<p>Cependant, malgr&#233; les diff&#233;rences entre les approches statistiques, celles-ci pr&#233;sentent des
points communs et les fronti&#232;res entre les unes et les autres ont tendance &#224; s&#8217;estomper. On
voit, par exemple, des travaux autour de l&#8217;utilisation d&#8217;approches discriminantes de type CRF
pour la traduction automatique (Och et Ney, 2002; Liang et al., 2006; Lavergne et al., 2011),
tandis que les approches de traduction &#224; base de segments, sont aussi utilis&#233;es dans d&#8217;autres
t&#226;ches du traitement automatique de la langue, comme la conversion graph&#232;me-phon&#232;mes
(Rama et al., 2009) ou le d&#233;codage de Part-Of-Speech (Gasc&#243; i Mora et S&#225;nchez Peir&#243;, 2007).
</p>
<p>Dans cet article nous comparons les approches CRF-SLU et LLPB-SMT pour les t&#226;ches de
compr&#233;hension et de traduction. Pour cela nous proposons d&#8217;utiliser et d&#8217;optimiser une
approche LLPB-SMT pour la compr&#233;hension de la parole, et par ailleurs d&#8217;int&#233;grer des mod&#232;les
&#224; base de CRF &#224; un module de traduction automatique. Cette &#233;tude nous permet de mettre en
avant les sp&#233;cificit&#233;s de chaque t&#226;che et d&#8217;&#233;valuer les performances des approches respectives
sur ces t&#226;ches.
</p>
<p>D&#8217;autre part, nous avons montr&#233; dans un travail pr&#233;c&#233;dent (Jabaian et al., 2010, 2011) que
l&#8217;utilisation de la traduction automatique constitue une solution efficace pour la portabilit&#233;
multilingue d&#8217;un module de compr&#233;hension d&#8217;une langue vers une autre. Cette portabilit&#233;
peut &#234;tre obtenue en cascadant un module de traduction avec un module de compr&#233;hension
(pour traduire les entr&#233;es d&#8217;un utilisateur vers une langue pour laquelle nous disposons d&#8217;un
syst&#232;me de compr&#233;hension).
</p>
<p>Dans certains cas, la meilleure hypoth&#232;se de traduction n&#8217;est pas l&#8217;hypoth&#232;se pour laquelle le
syst&#232;me de compr&#233;hension g&#233;n&#232;re la meilleure hypoth&#232;se (souvent pour des raisons li&#233;es &#224;
l&#8217;ordre des mots). Et donc la s&#233;lection pr&#233;alable de la meilleure traduction n&#8217;optimise pas
forc&#233;ment le syst&#232;me lorsqu&#8217;on se place selon un sc&#233;nario de compr&#233;hension multilingue.
</p>
<p>Nous nous basons sur la comparaison r&#233;alis&#233;e entre les deux t&#226;ches afin de pouvoir proposer un
mod&#232;le qui pourra g&#233;rer la traduction et la compr&#233;hension d&#8217;une mani&#232;re similaire permettant
un d&#233;codage conjoint entre les modules. Ce d&#233;codage conjoint permettra de s&#233;lectionner
des traductions en tenant compte des hypoth&#232;ses d&#8217;&#233;tiquetage s&#233;mantique. Dans cet esprit,
nous ne cherchons plus la meilleure traduction possible mais la traduction qui sera &#233;tiquet&#233;e
s&#233;mantiquement de la meilleure mani&#232;re possible.
</p>
<p>Nos exp&#233;riences sont bas&#233;es sur le corpus de dialogue fran&#231;ais MEDIA sur lequel nous appre-
nons un syst&#232;me de compr&#233;hension du fran&#231;ais. Dans le but de pouvoir utiliser ce syst&#232;me
pour &#233;tiqueter des entr&#233;es en italien, nous apprenons un syst&#232;me de traduction de l&#8217;italien
vers fran&#231;ais, qui sera utilis&#233; ensuite lors des tests pour traduire les entr&#233;es italiennes vers le
fran&#231;ais afin de les fournir en entr&#233;e du syst&#232;me de compr&#233;hension.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>91 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Cet article est organis&#233; de la mani&#232;re suivante : la section 2 pr&#233;sente l&#8217;utilisation d&#8217;une
approche de traduction automatique pour la compr&#233;hension de la parole. La section 3 d&#233;crit
l&#8217;utilisation des CRF pour la traduction automatique. Notre proposition pour un d&#233;codage
conjoint entre la compr&#233;hension et la traduction est pr&#233;sent&#233;e dans la section 4. Enfin la
section 5 pr&#233;sente l&#8217;&#233;tude exp&#233;rimentale et les r&#233;sultats.
</p>
<p>2 M&#233;thode de traduction pour la compr&#233;hension
</p>
<p>Le probl&#232;me de la compr&#233;hension d&#8217;un &#233;nonc&#233; utilisateur peut &#234;tre vu comme un probl&#232;me
de traduction de la s&#233;quence de mots qui forme cet &#233;nonc&#233; (langue source) vers une s&#233;quence
de concepts (langue cible). (Macherey et al., 2001, 2009) ont montr&#233; que les approches de
la traduction automatique statistique peuvent &#234;tre utilis&#233;es avec un certain succ&#232;s pour une
t&#226;che de compr&#233;hension de la parole. Cette approche part du principe que les s&#233;quences de
concepts sont les traductions des s&#233;quences de mots initiales.
</p>
<p>Malgr&#233; l&#8217;apparente similitude entre les t&#226;ches de compr&#233;hension et de traduction, la compr&#233;-
hension a ses sp&#233;cificit&#233;s qui doivent &#234;tre prises en consid&#233;ration afin de pouvoir am&#233;liorer
les performances obtenues par une approche de traduction comme LLPB-SMT.
</p>
<p>Les diff&#233;rences entre une t&#226;che de traduction classique (d&#8217;une langue naturelle vers une
autre) et l&#8217;utilisation de la traduction pour la compr&#233;hension (traduction d&#8217;une langue vers
des &#233;tiquettes s&#233;mantiques) peuvent &#234;tre r&#233;sum&#233;es comme suit :
&#8211; la s&#233;mantique d&#8217;une phrase respecte l&#8217;ordre dans lequel les mots sont &#233;mis contrairement &#224;
une t&#226;che de traduction o&#249; les mots traduits peuvent avoir un ordre diff&#233;rent de l&#8217;ordre
des mots de la phrase source selon le couple de langues consid&#233;r&#233;es ;
</p>
<p>&#8211; dans une t&#226;che de traduction, un mot source peut n&#8217;&#234;tre align&#233; &#224; aucun mot cible (fertilit&#233;
= 0), alors que pour la compr&#233;hension chaque mot doit &#234;tre align&#233; &#224; un concept, sachant
que les mots qui ne contribuent pas au sens de la phrase sont &#233;tiquet&#233;s par un concept
sp&#233;cifique ;
</p>
<p>&#8211; enfin, les mesures d&#8217;&#233;valuation sont diff&#233;rentes entre les deux t&#226;ches (BLEU (Papineni et al.,
2002) pour la traduction vs. CER pour la compr&#233;hension) et donc les outils utilis&#233;s pour
l&#8217;optimisation des syst&#232;mes de traduction doivent &#234;tre adapt&#233;s pour optimiser le score CER.
</p>
<p>En suivant l&#8217;hypoth&#232;se que la s&#233;mantique d&#8217;une phrase respecte l&#8217;ordre dans lequel les mots
sont &#233;mis, nous proposons d&#8217;imposer une contrainte de monotonie pendant la traduction
(d&#233;codage monotone), qui oblige le d&#233;codeur &#224; respecter, en fonction de l&#8217;ordre des mots
initiaux, l&#8217;ordre des concepts g&#233;n&#233;r&#233;s.
</p>
<p>Une difficult&#233; majeure du processus de traduction automatique est l&#8217;alignement d&#8217;un mot de
la langue source avec le mot correspondant dans le langue cible. Vu que les corpus utilis&#233;s
pour apprendre des syst&#232;mes de traduction sont des corpus align&#233;s au niveau des phrases, une
&#233;tape d&#8217;alignement automatique est n&#233;cessaire pour obtenir l&#8217;alignement en mots. Cependant,
la plupart des corpus de compr&#233;hension sont &#233;tiquet&#233;s (align&#233;s) au niveau des segments
conceptuels et donc l&#8217;utilisation de ces informations d&#8217;alignement peut &#234;tre avantageuse pour
aider le processus d&#8217;alignement.
</p>
<p>Pour cela nous proposons d&#8217;utiliser les corpus en format BIO (Begin Inside Outside) (Ramshaw
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>92 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>et Marcus, 1995). Ce format garanti que chaque mot de la phrase source est align&#233; &#224; son
concept correspondant et donc aucun alignement automatique suppl&#233;mentaire n&#8217;est requis.
De cette fa&#231;on, l&#8217;extraction de la table de segments est obtenue &#224; partir d&#8217;un corpus avec un
alignement parfait (non bruit&#233;).
</p>
<p>Vu que nous cherchons &#224; &#233;valuer les hypoth&#232;ses g&#233;n&#233;r&#233;es par cette approche du point de vue
de la compr&#233;hension (la mesure d&#8217;&#233;valuation du syst&#232;me de compr&#233;hension &#233;tant le CER
et non pas le score BLEU) nous proposons de modifier l&#8217;algorithme MERT (Och, 2003) afin
d&#8217;optimiser le CER directement.
</p>
<p>3 M&#233;thode de compr&#233;hension pour la traduction
</p>
<p>Dans cette approche, le probl&#232;me de la traduction d&#8217;une phrase est consid&#233;r&#233; comme un
probl&#232;me d&#8217;&#233;tiquetage de la s&#233;quence de mots source, avec comme &#233;tiquettes possibles les
mots de la langue cible. L&#8217;apprentissage d&#8217;un &#233;tiqueteur fond&#233; sur une approche CRF pour une
t&#226;che de traduction n&#233;cessite un corpus annot&#233; (traduit) au niveau des mots. L&#8217;application
des mod&#232;les IBM (Brown et al., 1993) permet d&#8217;obtenir automatiquement des alignements
en mots &#224; partir d&#8217;un corpus bilingue align&#233; au niveau des phrases.
</p>
<p>Comme pour la compr&#233;hension, o&#249; plusieurs mots peuvent &#234;tre associ&#233;s &#224; un seul concept,
plusieurs mots source peuvent &#234;tre align&#233;s avec un seul mot cible. Pour g&#233;rer cela, la propo-
sition la plus simple est d&#8217;appliquer la m&#234;me m&#233;thode utilis&#233;e pour la compr&#233;hension : le
passage au format BIO. Ainsi la s&#233;quence fran&#231;aise &#8220;je voudrais&#8221; qui est align&#233;e au mot italien
&#8220;vorrei&#8221; sera repr&#233;sent&#233;e comme : &lt;je, B_vorrei&gt; &lt;voudrais, I_vorrei&gt;.
</p>
<p>La difficult&#233; principale pour apprendre des mod&#232;les CRF pour la traduction est li&#233;e au nombre
&#233;lev&#233; d&#8217;&#233;tiquettes (correspondant &#224; la taille du vocabulaire de la langue cible). (Riedmiller et
Braun, 1993) ont propos&#233; d&#8217;utiliser l&#8217;algorithme RPROP pour l&#8217;optimisation des param&#232;tres de
mod&#232;les lorsqu&#8217;il s&#8217;agit d&#8217;un mod&#232;le avec un nombre important de param&#232;tres. Cet algorithme
r&#233;duit le besoin en m&#233;moire par rapport &#224; d&#8217;autres algorithmes d&#8217;optimisation (Turian et al.,
2006).
</p>
<p>Un autre d&#233;faut important de l&#8217;utilisation des CRF pour la traduction est qu&#8217;ils ne prennent
pas en compte le r&#233;ordonnancement des mots et que le mod&#232;le de langage cible limit&#233; par la
complexit&#233; algorithmique lors du d&#233;codage. Afin d&#8217;obtenir un syst&#232;me de traduction efficace
&#224; base de CRF, (Lavergne et al., 2011) ont propos&#233; un mod&#232;le fond&#233; sur des transducteurs &#224;
&#233;tats finis qui composent les diff&#233;rents &#233;tapes du processus de traduction. Nous l&#8217;appellerons
CRFPB-SMT car il int&#233;gre aussi un m&#233;canisme pour la mod&#233;lisation d&#8217;une table de traduction
par segments sous-phrastiques (appel&#233;s tuples dans ce contexte).
</p>
<p>Le d&#233;codeur propos&#233; pour ce mod&#232;le est une composition de transducteurs &#224; &#233;tats finis
pond&#233;r&#233;s (Weighted Finite State Transducer, WFST) qui met en ouvre les fonctionnalit&#233;s
standards des WFST, disponibles dans des biblioth&#232;ques logicielles comme OpenFST (Allauzen
et al., 2007). Essentiellement, le d&#233;codeur de traduction est une composition de transducteurs
qui repr&#233;sentent les &#233;tapes suivantes : le r&#233;ordonnancement et la segmentation de la phrase
source selon les tuples de mots, l&#8217;application dumod&#232;le de traduction (mise en correspondance
des parties source et cible des tuples) avec une valuation des hypoth&#232;ses &#224; base de CRF et,
enfin, la composition avec un mod&#232;le de langage dans la langue cible. (Kumar et Byrne, 2003)
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>93 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>a propos&#233; une architecture assez similaire qui utilise un mod&#232;le ATTM (Alignment Template
Translation Models) au lieu des CRF comme mod&#232;le de traduction.
</p>
<p>Cette architecture permet de voir la traduction d&#8217;une phrase comme une composition (&#9702;) de
transducteurs dans l&#8217;ordre suivant :
</p>
<p>&#955;t raduct ion = &#955;S &#9702;&#955;R &#9702;&#955;T &#9702;&#955;F &#9702;&#955;L
sachant que &#955;S est l&#8217;accepteur de la phrase source, &#955;R repr&#233;sente un mod&#232;le de r&#233;ordonnan-
cement, &#955;T est un dictionnaire de tuples, qui associe des s&#233;quences de la langue source avec
leurs traductions possibles en se basant sur l&#8217;inventaire des tuples lors de l&#8217;apprentissage, &#955;F
est une fonction d&#8217;extraction de motifs (feature matcher), qui permet d&#8217;attribuer des scores de
probabilit&#233; aux tuples en les comparant aux motifs des fonctions caract&#233;ristiques du mod&#232;le
CRF et &#955;L est un mod&#232;le de langage de la langue cible.
</p>
<p>4 D&#233;codage conjoint pour la traduction et la compr&#233;hen-
sion, application &#224; la compr&#233;hension multilingue
</p>
<p>Notre &#233;tude des relations entre les diff&#233;rentes approches est r&#233;alis&#233;e avec l&#8217;objectif de pouvoir
les combiner du mieux possible pour la portabilit&#233; multilingue d&#8217;un syst&#232;me de compr&#233;hension.
</p>
<p>Dans des travaux pr&#233;c&#233;dents (Jabaian et al., 2010), nous avons montr&#233; que la meilleure
m&#233;thode pour porter un syst&#232;me de compr&#233;hension existant vers une nouvelle langue est
aussi la plus simple : traduire les &#233;nonc&#233;s utilisateurs de la nouvelle langue vers la langue du
syst&#232;me existant et ensuite faire &#233;tiqueter les &#233;nonc&#233;s (traduits) par ce syst&#232;me.
</p>
<p>Notre proposition est bas&#233;e sur une cascade d&#8217;un syst&#232;me de traduction (LLPB-SMT) et d&#8217;un
syst&#232;me de compr&#233;hension (CRF-SLU). La meilleure hypoth&#232;se g&#233;n&#233;r&#233;e par le syst&#232;me de
traduction constitue l&#8217;entr&#233;e du syst&#232;me de compr&#233;hension. Cependant, d&#8217;autres hypoth&#232;ses
de traductions peuvent diff&#233;rer (m&#234;me sensiblement, par exemple dans l&#8217;ordre des mots) et
ces variantes peuvent &#234;tre mieux interpr&#233;t&#233;es par l&#8217;&#233;tiqueteur s&#233;mantique. Donc la s&#233;lection
a priori de la meilleure traduction n&#8217;optimise pas forc&#233;ment le comportement du syst&#232;me
global.
</p>
<p>Pour faire face &#224; ce probl&#232;me nous proposons d&#8217;effectuer un d&#233;codage conjoint entre la
traduction et la compr&#233;hension. Ce d&#233;codage conjoint aura l&#8217;avantage de pouvoir optimiser
la s&#233;lection de la traduction en prenant compte des &#233;tiquettes qui peuvent &#234;tre attribu&#233;es aux
diff&#233;rentes traductions possibles.
</p>
<p>La proposition d&#8217;utiliser l&#8217;approche CRFPB-SMT utilisant des transducteurs pour la traduction
de graphes d&#8217;hypoth&#232;ses peut &#234;tre appliqu&#233;e la compr&#233;hension. Donc un syst&#232;me de compr&#233;-
hension &#955;comprehension peut &#234;tre obtenu de la m&#234;me mani&#232;re que propos&#233; dans la section 3.
Cette repr&#233;sentation nous permet alors d&#8217;obtenir un graphe de compr&#233;hension similaire &#224;
celui obtenu pour la traduction. Vu que le vocabulaire des sorties du graphe de traduction
est le m&#234;me que celui de l&#8217;entr&#233;e du graphe de compr&#233;hension, ces deux graphes peuvent
&#234;tre compos&#233;s facilement en utilisant la fonction de composition pour donner un graphe
permettant le d&#233;codage conjoint :
</p>
<p>&#955;con joint = &#955;t raduct ion &#9702;&#955;comprehension
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>94 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Cette composition prend une phrase de la langue cible en entr&#233;e et attribue une s&#233;quence de
concept &#224; cette phrase en passant par un &#233;tiqueteur disponible dans la langue source. Elle
nous permet d&#8217;obtenir un d&#233;codage conjoint entre la traduction et la compr&#233;hension dans
la mesure o&#249; les probabilit&#233;s des deux mod&#232;les sont prises en compte. Un tel d&#233;codage ne
cherche pas &#224; optimiser la traduction en soi, mais &#224; optimiser le choix d&#8217;une traduction qui
donnera une meilleure compr&#233;hension automatique.
</p>
<p>Le transducteur &#955;con joint peut &#234;tre g&#233;n&#233;ralis&#233; pour permettre de composer un graphe de
reconnaissance de la parole avec un graphe de compr&#233;hension dans le cadre d&#8217;un syst&#232;me de
dialogue. Dans un tel cas des proc&#233;dures d&#8217;&#233;lagage devront &#234;tre prises en compte afin d&#8217;assurer
que les op&#233;rations de composition puissent &#234;tre r&#233;alis&#233;es selon les contraintes classiques
(temps de calcul et espace m&#233;moire machine disponible).
</p>
<p>4.1 Travaux connexes
</p>
<p>Ce probl&#232;me rejoint, dans son esprit, le probl&#232;me classique de la cascade des composants
d&#8217;un syst&#232;me d&#8217;interaction vocal homme-machine. Dans une architecture standard, le syst&#232;me
de reconnaissance de la parole transmet sa meilleure hypoth&#232;se de transcription au syst&#232;me
de compr&#233;hension. Vu que cette hypoth&#232;se est bruit&#233;e, elle n&#8217;est pas forc&#233;ment l&#8217;hypoth&#232;se
que le syst&#232;me de compr&#233;hension pourra &#233;tiqueter le mieux.
</p>
<p>Plusieurs travaux ont propos&#233; un d&#233;codage conjoint entre la reconnaissance et la compr&#233;-
hension de la parole pour prendre en compte les n-meilleures hypoth&#232;ses de reconnaissance
lors de l&#8217;&#233;tiquetage s&#233;mantique. Ces premiers travaux (T&#252;r et al., 2002; Servan et al., 2006;
Hakkani-T&#252;r et al., 2006) ont propos&#233; d&#8217;utiliser un r&#233;seau de confusion entre les diff&#233;rentes
sorties de reconnaissance pour obtenir un graphe d&#8217;hypoth&#232;ses. Le syst&#232;me de compr&#233;hension
dans ces propositions a &#233;t&#233; repr&#233;sent&#233; par un WFST, dont les poids sont obtenus pas maximum
de vraisemblance sur les donn&#233;es d&#8217;apprentissage. Et le d&#233;codage conjoint est obtenu par la
composition du graphe de reconnaissance avec le graphe de compr&#233;hension.
</p>
<p>Les r&#233;sultats positifs obtenus par ces propositions ont encourag&#233; d&#8217;autres travaux dans la
m&#234;me ligne. Vu que les mod&#232;les les plus performants dans la litt&#233;rature sont les CRF, (Anoop
Deoras et Hakkani-Tur, 2012) a propos&#233; d&#8217;utiliser des mod&#232;les CRF au lieu des WFST pour
l&#8217;&#233;tape de compr&#233;hension.
</p>
<p>Dans la lign&#233;e de ces travaux, notre proposition cherche &#224; obtenir un d&#233;codage conjoint
pour la traduction et la compr&#233;hension. Les deux syst&#232;mes &#233;tant de natures diff&#233;rentes, leur
combinaison et leur optimisation conjointe sont rendues d&#233;licates, d&#8217;o&#249; l&#8217;int&#233;r&#234;t d&#8217;uniformiser
les syst&#232;mes pour les deux t&#226;ches.
</p>
<p>5 Exp&#233;riences et r&#233;sultats
</p>
<p>Toutes nos exp&#233;riences utilisent le corpus de dialogue fran&#231;ais MEDIA. Le corpus MEDIA d&#233;crit
dans (Bonneau-Maynard et al., 2005) couvre un domaine li&#233; aux r&#233;servations d&#8217;h&#244;tel et
aux informations touristiques. Ce corpus est annot&#233; avec 99 &#233;tiquettes qui repr&#233;sentent la
s&#233;mantique du domaine.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>95 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Le corpus est constitu&#233; de 1257 dialogues regroup&#233;s en 3 parties : un ensemble d&#8217;apprentissage
(environ 13k phrases), un ensemble de d&#233;veloppement (environ 1,3k phrases) et un ensemble
d&#8217;&#233;valuation (environ 3,5k phrases). Un sous-ensemble de donn&#233;es d&#8217;apprentissage (environ
5,6k phrases), de m&#234;me que les ensembles de tests et de d&#233;veloppement sont manuellement
traduits en italien.
</p>
<p>Un syst&#232;me de type LLPB-SMT est utilis&#233; pour apprendre un syst&#232;me de compr&#233;hension du
fran&#231;ais sur le corpus MEDIA, et le sous-ensemble traduit de ce corpus est utilis&#233; comme corpus
parall&#232;le pour apprendre un mod&#232;le de traduction &#224; base de CRF. Ensuite l&#8217;approche CRFPB-
SMT &#224; base de transducteurs est &#233;valu&#233;e s&#233;par&#233;ment pour la traduction et la compr&#233;hension
avant d&#8217;&#234;tre utilis&#233;e dans le cadre d&#8217;un d&#233;codage conjoint traduction/compr&#233;hension.
</p>
<p>Le taux d&#8217;erreur en concepts (Concept Error Rate, CER) est le crit&#232;re d&#8217;&#233;valuation retenu pour
&#233;valuer la t&#226;che de compr&#233;hension. Le CER est l&#8217;&#233;quivalent du taux d&#8217;erreur en mots (WER),
et peut &#234;tre d&#233;fini comme le rapport de la somme des concepts omis, ins&#233;r&#233;s et substitu&#233;s sur
le nombre de concepts dans la r&#233;f&#233;rence. D&#8217;autre part le score BLEU (Papineni et al., 2002)
qui se base sur des comptes de n-grammes communs entre hypoth&#232;se et r&#233;f&#233;rence est retenu
pour &#233;valuer la t&#226;che de traduction.
</p>
<p>5.1 Evaluation des syst&#232;mes de traduction &#224; base de segments pour une
t&#226;che de compr&#233;hension
</p>
<p>La bo&#238;te &#224; outils MOSES (Koehn et al., 2007) a &#233;t&#233; utilis&#233;e pour apprendre un mod&#232;le LLPB-
SMT pour la compr&#233;hension du fran&#231;ais. Nos premi&#232;res tentatives ont clairement montr&#233; des
performances inf&#233;rieures &#224; celles d&#8217;un mod&#232;le CRF-SLU de r&#233;f&#233;rence (CER 23,2% apr&#232;s r&#233;glage
des param&#232;tres avec MERT pour le LLPB-SMT &#224; comparer aux 12,9% pour CRF-SLU 1.).
</p>
<p>Les am&#233;liorations progressives du mod&#232;le propos&#233;es dans la section 2 sont &#233;valu&#233;es dans
le tableau 1. L&#8217;utilisation de la contrainte de monotonie durant le d&#233;codage permet une
r&#233;duction de 0,5% absolu. Convertir les donn&#233;es selon le formalisme BIO avant la phase
d&#8217;apprentissage r&#233;duit le CER de fa&#231;on significative de 2,4%. Enfin, optimiser le score CER &#224;
la place du score BLEU r&#233;duit le CER de 0,4% suppl&#233;mentaire. Enfin, l&#8217;ajout d&#8217;une liste de
villes &#224; l&#8217;ensemble d&#8217;apprentissage avant r&#233;apprentissage du mod&#232;le LLPB-SMT r&#233;pond au
probl&#232;me du traitement des mots hors-vocabulaire et permet une r&#233;duction finale de 0,8%.
</p>
<p>Les r&#233;sultats montrent qu&#8217;en d&#233;pit de r&#233;glages fins de l&#8217;approche LLPB-SMT, les approches &#224;
base de CRF obtiennent toujours les meilleures performances pour une t&#226;che de compr&#233;hen-
sion (CER de 12,9% pour CRF-SLU vs. 18,3% pour LLPB-SMT).
</p>
<p>Une analyse rapide du type d&#8217;erreur montre que les m&#233;thodes utilisant des CRF ont un haut
niveau de suppressions comparativement aux autres types d&#8217;erreurs, tandis que la m&#233;thode
LLPB-SMT pr&#233;sente un meilleur compromis entre les erreurs de suppression et d&#8217;insertion,
et ce bien qu&#8217;elle aboutisse &#224; un CER plus &#233;lev&#233;. Un nombre important d&#8217;erreurs caus&#233;es
par le mod&#232;le LLPB-SMT pour la compr&#233;hension est d&#251; &#224; une mauvaise segmentation (le
plus souvent une sur-segmentation) des phrases. Cette caract&#233;ristique des mod&#232;les LLPB-
SMT m&#232;ne &#224; une distribution &#233;quilibr&#233;e d&#8217;erreurs entre les omissions, les insertions et les
substitutions, alors que pour CRF-SLU un grand nombre d&#8217;erreurs venait des omissions.
</p>
<p>1. Se r&#233;f&#233;rer &#224; (Jabaian et al., 2011) pour plus de d&#233;tails sur le mod&#232;le CRF-SLU
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>96 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;le Sub Om Ins CER
Initial 5,4 4,1 14,6 24,1
</p>
<p>+MERT (BLEU) 5,6 8,4 9,2 23,2
+D&#233;codage monotone 6,2 7,8 8,7 22,7
</p>
<p>+Format BIO 5,7 9,3 5,3 20,3
MERT (CER) 5,3 9,2 4,6 19,1
</p>
<p>Traitement de mots HV 5,8 7,4 5,1 18,3
</p>
<p>TABLE 1: Les am&#233;liorations it&#233;ratives du mod&#232;le LLPB-SMT pour la compr&#233;hension du
fran&#231;ais (CER%).
</p>
<p>5.2 Evaluation des &#233;tiqueteurs s&#233;mantiques pour une t&#226;che de traduc-
tion automatique
</p>
<p>Afin de pouvoir &#233;valuer notre proposition d&#8217;utiliser une approche CRF-SLU pour la traduction
nous utilisons la partie traduite manuellement (du fran&#231;ais vers l&#8217;italien) du corpus MEDIA
comme corpus parall&#232;le pour apprendre le mod&#232;le de traduction. L&#8217;outil GIZA++ (disponible
avec MOSES) a &#233;t&#233; utilis&#233; pour apprendre automatiquement un alignement mot &#224; mot entre
les corpus des deux langues et l&#8217;outil Wapiti (Lavergne et al., 2010) a &#233;t&#233; utilis&#233; pour apprendre
les param&#232;tres des mod&#232;les CRF.
</p>
<p>Dans un premier temps, nous cherchons &#224; apprendre unmod&#232;le CRF-SLU pour la traduction, en
utilisant l&#8217;algorithme RPROP comme propos&#233; dans la section 3. Des fonctions caract&#233;ristiques
de type 4-grammes sym&#233;triques sur les observations et bi-grammes sur les &#233;tiquettes sont
utilis&#233;es pour apprendre ce mod&#232;le. Les performances obtenues sont pr&#233;sent&#233;es dans le
tableau 2. Les r&#233;sultats montrent que la performance du mod&#232;le CRF-SLU (BLEU de 42,5)
est significativement moins bonne que la performance obtenue par la m&#233;thode LLPB-SMT
classique utilisant MOSES avec des param&#232;tres de base (47,2) 2.
</p>
<p>Afin d&#8217;avoir une comparaison juste entre les deux m&#233;thodes, nous cherchons &#224; &#233;valuer l&#8217;ap-
proche LLPB-SMT dans les m&#234;mes conditions que l&#8217;approche CRF-SLU. La m&#233;thode LLPB-SMT
utilise un mod&#232;le de r&#233;ordonnancement alors que CRF-SLU, d&#233;di&#233; &#224; l&#8217;&#233;tiquetage s&#233;quentiel,
ne comprend pas un tel mod&#232;le. Pour cela nous rajoutons une contrainte de monotonie dans
le d&#233;codage pour l&#8217;approche LLPB-SMT emp&#234;chant tout r&#233;ordonnancement. Il est aussi impor-
tant de mentionner que l&#8217;approche LLPB-SMT utilise un mod&#232;le de langage pour s&#233;lectionner
la meilleure traduction. Les performances du mod&#232;le LLPB-SMT de r&#233;f&#233;rence sont obtenues
en utilisant un mod&#232;le de langage tri-grammes (utilis&#233; g&#233;n&#233;ralement dans les syst&#232;mes de
traduction). Cependant la complexit&#233; algorithmique de l&#8217;approche CRF-SLU ne permet pas
d&#8217;utiliser un tel mod&#232;le de langage sur les &#233;tiquettes.
</p>
<p>Afin d&#8217;&#233;valuer les approches CRF-SLU et LLPB-SMT dans les m&#234;mes conditions, et vu qu&#8217;on ne
peut pas augmenter la taille des fonctions caract&#233;ristiques du mod&#232;le CRF, nous proposons
de d&#233;grader l&#8217;approche LLPB-SMT et de r&#233;&#233;valuer sa performance en utilisant un mod&#232;le de
langage de type bi-grammes.
</p>
<p>Par ailleurs, en observant les sorties du mod&#232;le CRF-SLU, nous remarquons que les mots
</p>
<p>2. Se r&#233;f&#233;rer &#224; (Jabaian et al., 2011) pour plus de d&#233;tails sur le mod&#232;le LLPB-SMT.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>97 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CRF-SLU LLPB-SMT
r&#233;f&#233;rence 42,5 47,2
</p>
<p>d&#233;codage monotone 42,5 46,3
bi-grammes 42,5 46,0
</p>
<p>traitement de mots HV 43,5 46,0
</p>
<p>TABLE 2: Comparaison entre les mod&#232;les LLPB-SMT et CRF-SLU pour la traduction de l&#8217;italien
vers le fran&#231;ais (BLEU %).
</p>
<p>inconnus (hors-vocabulaire) dans le test ont &#233;t&#233; traduits par d&#8217;autres mots du corpus cible
selon le contexte g&#233;n&#233;ral de la phrase, contrairement &#224; l&#8217;approche LLPB-SMT qui a tendance &#224;
projeter les mots hors-vocabulaire tels qu&#8217;ils sont dans la phrase traduite. Ces mots, &#233;tant dans
la plupart des cas des noms de ville ou de lieux, leur traduction ne change pas d&#8217;une langue
&#224; l&#8217;autre, et donc leur projection dans la sortie traduite est avantageuse pour les mod&#232;les
LLPB-SMT. Pour cela nous proposons un pr&#233;-traitement des mots inconnus dans la phrase
source permettant de les r&#233;cup&#233;rer en sortie dans l&#8217;approche CRF-SLU.
</p>
<p>Les r&#233;sultats pr&#233;sent&#233;s dans le tableau 2 montrent que le d&#233;codage monotone d&#233;grade la
performance du mod&#232;le LLPB-SMT de 0,91% absolu. L&#8217;utilisation d&#8217;un mod&#232;le de langage bi-
grammes augmente la perte de 0,3% suppl&#233;mentaire. Le traitement des mots hors-vocabulaire
permet au mod&#232;le CRF-SLU de r&#233;cup&#233;rer 1,0% de score BLEU par rapport au mod&#232;le CRF-
SLU de r&#233;f&#233;rence. On remarque que malgr&#233; la d&#233;gradation du mod&#232;le LLPB-SMT et les
am&#233;liorations du mod&#232;le CRF-SLU, la performance de ce dernier reste inf&#233;rieure &#224; celle du
mod&#232;le LLPB-SMT (43,5% pour les CRF vs. 46,0% pour LLPB-SMT).
</p>
<p>5.3 Evaluation des syst&#232;mes &#224; base de transducteurs CRFPB-SMT pour
la traduction et la compr&#233;hension
</p>
<p>Un mod&#232;le de traduction CRFPB-SMT &#224; base de transducteurs valu&#233;s par des CRF pour la
traduction a &#233;t&#233; construit comme d&#233;crit dans la section 3. Ce mod&#232;le a &#233;t&#233; construit &#224; partir
de l&#8217;outil n-code (Crego et al., 2011), impl&#233;ment&#233; pour apprendre des mod&#232;les de traduction
&#224; base de n-grammes (Mari&#241;o et al., 2006).
</p>
<p>Cet outil utilise la biblioth&#232;que OpenFst (Allauzen et al., 2007) pour construire un graphe de
traduction qui est la composition de plusieurs transducteurs. La diff&#233;rence entre le mod&#232;le
impl&#233;ment&#233; par cet outil et le mod&#232;le qu&#8217;on cherche &#224; d&#233;veloper r&#233;side dans les poids du
mod&#232;le de traduction. Nous adaptons donc cet outil pour interroger les param&#232;tres d&#8217;un
mod&#232;le CRF afin d&#8217;estimer les probabilit&#233;s de traduction et ensuite nous appliquons une
normalisation des scores de probabilit&#233; obtenus par ce mod&#232;le sur les diff&#233;rents chemins du
graphe (comme cela a &#233;t&#233; propos&#233; dans (Lavergne et al., 2011)).
</p>
<p>Dans n-code le mod&#232;le de r&#233;ordonnancement, propos&#233; par (Crego et Mari&#241;o, 2006), est fond&#233;
sur une approche &#224; base de r&#232;gles apprises automatiquement sur les donn&#233;es d&#8217;entrainement.
Cette approche n&#233;cessite un &#233;tiquetage grammatical des phrases source et un alignement au
niveau des mots entre les phrases source et les phrases cible pour apprendre le mod&#232;le &#955;R.
Nous avons utiliser les outils TreeTagger (Schmid, 1994) pour obtenir l&#8217;&#233;tiquetage grammatical
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>98 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;le Langue BLEU
LLPB-SMT
</p>
<p>IT &#8211;&gt; FR
47,2
</p>
<p>CRF-SLU 43,5
CRFPB-SMT 44,1
</p>
<p>TABLE 3: Comparaison entre les diff&#233;rentes approches (LLPB-SMT, CRF-SLU, CRFPB-SMT)
pour la traduction de l&#8217;italien vers le fran&#231;ais.
</p>
<p>et GIZA++ pour l&#8217;alignement en mots. Le mod&#232;le de langage utilis&#233; dans nos exp&#233;riences est
un mod&#232;le tri-grammes appris sur la partie cible de notre corpus d&#8217;apprentissage &#224; l&#8217;aide de
l&#8217;outil SRILM (Stolcke, 2002).
</p>
<p>Le tableau 3 pr&#233;sente une comparaison entre trois mod&#232;les : le mod&#232;le CRFPB-SMT, le
mod&#232;le LLPB-SMT (de r&#233;f&#233;rence) et le mod&#232;le CRF-SLU de base (pr&#233;sent&#233; dans la section
pr&#233;c&#233;dente). Les r&#233;sultats pr&#233;sent&#233;s dans ce tableau montrent que l&#8217;approche CRFPB-SMT &#224;
base de transducteurs donne des performances inf&#233;rieures mais comparables &#224; celles obtenues
par l&#8217;approche LLPB-SMT.
</p>
<p>Malgr&#233; une d&#233;gradation de 3,1 points absolu, ces performances restent assez &#233;lev&#233;es en
valeur pour une t&#226;che de traduction (malgr&#233; un ensemble d&#8217;apprentissage de taille r&#233;duite),
ce qui s&#8217;explique dans notre contexte par le vocabulaire limit&#233; du domaine. Cette diff&#233;rence
de performance est comparable &#224; celle observ&#233;e par le LIMSI (Lavergne et al., 2010) (en ne
consid&#233;rant que l&#8217;utilisation des param&#232;tres de base).
</p>
<p>D&#8217;autre part les r&#233;sultats montrent que l&#8217;utilisation de graphes d&#8217;hypoth&#232;ses dans CRFPB-SMT
est doublement avantageuse par rapport &#224; l&#8217;utilisation d&#8217;une approche CRF simple ; en plus
du fait qu&#8217;elle permette de traiter des graphes en entr&#233;es, cette approche permet d&#8217;embl&#233;e
d&#8217;augmenter la performance du syst&#232;me d&#8217;environ 1 point absolu.
</p>
<p>Le m&#233;canisme utilis&#233; pour obtenir des graphe de traduction peut &#234;tre utilis&#233; d&#8217;une mani&#232;re
similaire pour la compr&#233;hension. Dans un premier temps, le graphe d&#8217;hypoth&#232;se de concepts
est obtenu en composant tous les mod&#232;les &#955;S &#9702;&#955;R &#9702;&#955;T &#9702;&#955;F &#9702;&#955;L comme cela a &#233;t&#233; propos&#233;
pour la traduction. Cette approche donne un CER de 15,3%, bien moins bon que l&#8217;approche
CRF-SLU de base (12,9%).
</p>
<p>Afin de prendre les sp&#233;cificit&#233;s de la compr&#233;hension (qui ne comprend pas de mod&#232;le de
r&#233;ordonnancement, ni de mod&#232;le de langage cible final), nous proposons d&#8217;obtenir le graphe
de sorties en combinant uniquement les mod&#232;les &#955;S &#9702;&#955;F . Cela nous a permis d&#8217;augmenter la
performance de cette approche de 2,2% absolu (15,3% vs 13,1%) permettant de retrouver
quasiment les m&#234;mes performances qu&#8217;avec CRF-SLU (13,1% vs 12.9%). Une comparaison
entre les performances des diff&#233;rentes versions est donn&#233;e dans le tableau 4. Par la suite,
CRFPB-SMT simplifi&#233; est utilis&#233; pour toutes les exp&#233;riences de compr&#233;hension.
</p>
<p>5.4 D&#233;codage conjoint dans un sc&#233;nario de compr&#233;hension multilingue
</p>
<p>Un d&#233;codage conjoint pour la traduction et la compr&#233;hension a &#233;t&#233; appliqu&#233; comme nous
l&#8217;avons propos&#233; dans la section 4. Ce d&#233;codage consiste &#224; transmettre le graphe de traduction
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>99 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Mod&#232;le Sub Del Ins CER
CRF-SLU 3,1 8,1 1,8 12,9
</p>
<p>CRFPB-SMT (complet) (&#955;S &#9702;&#955;R &#9702;&#955;T &#9702;&#955;F &#9702;&#955;L ) 4,2 8,8 2,3 15,3
CRFPB-SMT (simplifi&#233;) (&#955;S &#9702;&#955;T &#9702;&#955;F) 3,5 7,6 2,0 13,1
</p>
<p>TABLE 4: Evaluation des approches bas&#233;es sur les CRF pour la compr&#233;hension du fran&#231;ais.
</p>
<p>en entr&#233;e du module de compr&#233;hension (incluant les scores pond&#233;r&#233;s relatifs &#224; la traduction)
et ensuite r&#233;cup&#233;rer en sortie un graphe de compr&#233;hension qui int&#232;gre les scores de traduction
et de compr&#233;hension. Ce d&#233;codage permettra d&#8217;&#233;tiqueter des phrases en italien en combinant
un syst&#232;me de traduction italien vers fran&#231;ais et un syst&#232;me de compr&#233;hension du fran&#231;ais
</p>
<p>Pour cela nous avons adapt&#233; l&#8217;accepteur du mod&#232;le de compr&#233;hension du fran&#231;ais (donn&#233;
dans la derni&#232;re ligne du tableau 4 d&#233;crit dans 5.3) pour prendre des graphes en entr&#233;e (au
lieu d&#8217;une hypoth&#232;se unique). Ce transducteur g&#233;n&#232;re un graphe valu&#233; de compr&#233;hension qui
prend en compte les scores de traduction.
</p>
<p>Au moment du d&#233;codage les deux scores (traduction et compr&#233;hension) sont pris en consi-
d&#233;ration. Dans un premier temps nous proposons que le score final pour chaque chemin du
graphe soit l&#8217;addition simple du score de traduction et du score de compr&#233;hension sur ce
chemin 3. Le meilleur chemin est ensuite s&#233;lectionn&#233; parmi l&#8217;ensemble des chemins possibles
dans le graphe. Ce chemin repr&#233;sente donc un d&#233;codage conjoint entre la traduction et la
compr&#233;hension (marginalisation de la variabilit&#233; al&#233;atoire li&#233;e &#224; la traduction interm&#233;diaire).
</p>
<p>Afin de pouvoir se positionner par rapport &#224; l&#8217;&#233;tat de l&#8217;art, nous proposons de r&#233;aliser le
d&#233;codage conjoint selon deux modes : le syst&#232;me de traduction utilis&#233; est un mod&#232;le LLPB-
SMT (en utilisant la bo&#238;te &#224; outils MOSES) dans le premier et un CRFPB-SMT (comme d&#233;crit
dans 5.3) dans le second. Dans les deux cas les performances du d&#233;codage conjoint sont
compar&#233;es avec ou sans prise en compte du graphe d&#8217;hypoth&#232;ses complet. Dans un premier
cas, le meilleur chemin (1-best) du graphe de traduction est fourni en entr&#233;e du syst&#232;me de
compr&#233;hension. Dans un second cas, l&#8217;oracle du graphe de traduction est donn&#233; en entr&#233;e
au module de compr&#233;hension. Les scores oracle repr&#233;sentent une &#233;valuation fond&#233;e sur le
chemin du graphe qui se rapproche le plus de la r&#233;f&#233;rence de la traduction. Il est alors possible
de mesurer l&#8217;impact de la qualit&#233; de la traduction sur les performances de compr&#233;hension.
</p>
<p>Le r&#233;sultat de cette comparaison est donn&#233; dans la tableau 5. Nous avons aussi calcul&#233; les
scores oracle (pour la traduction et la compr&#233;hension) sur les sorties des diff&#233;rents couplages
de modules, et nous avons calcul&#233; le score BLEU sur la traduction s&#233;lectionn&#233;e par le d&#233;codage
conjoint (derni&#232;re colonne du tableau 5).
</p>
<p>La premi&#232;re ligne de ce tableau constitue la combinaison de r&#233;f&#233;rence (sans l&#8217;utilisation de
graphe) dans laquelle la sortie de MOSES est donn&#233;e en entr&#233;e d&#8217;un mod&#232;le CRF. Les r&#233;sultats
montrent que le graphe de traduction permet d&#8217;am&#233;liorer la performance du syst&#232;me par
rapport au syst&#232;me de 1-meilleure traduction (CER 19,7% vs. 19,9% pour LLPB-SMT et
21,3 vs. 21,7 pour CRF). L&#8217;utilisation d&#8217;un graphe de traduction donne aussi des meilleurs
performances par rapport &#224; la combinaison avec son oracle (CER 19,7% vs. 19,8% pour
</p>
<p>3. Une exp&#233;rience pr&#233;liminaire pour mesurer l&#8217;impact de la pond&#233;ration des scores est pr&#233;sent&#233;e dans (Jabaian,
2012).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>100 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Traduction Compr&#233;hension (CRF)
Mod&#232;le Sortie BLEU/Oracle Entr&#233;e CER/Oracle BLEU
</p>
<p>LLPB-SMT
</p>
<p>1-best 47,2/47,2 1-best 19,9/19,9 47,2
graphe 46,9/47,9 1-best(graphe) 19,9/19,4 46,9
graphe 46,9/47,9 oracle(graphe) 19,8/19,3 47,9
graphe 46,9/47,9 graphe 19,7/19,1 46,3
</p>
<p>CRFPB-SMT
graphe 44,1/44,9 1-best(graphe) 21,7/21,1 44,1
graphe 44,1/44,9 oracle(graphe) 21,6/21,1 44,9
graphe 44,1/44,9 graphe 21,3/20,6 43,9
</p>
<p>TABLE 5: Evaluation des diff&#233;rents configurations de compr&#233;hension multilingue
fran&#231;cais-italien, variant selon le type d&#8217;information transmise entre les 2 &#233;tapes (1-best,
</p>
<p>oracle ou graphe).
</p>
<p>LLPB-SMT et 21,3 vs. 21,6 pour CRF). La diff&#233;rence entre la performance obtenue par le
d&#233;codage conjoint en utilisant un mod&#232;le LLPB-SMT pour la traduction et celle obtenue en
utilisant un mod&#232;le CRF (CER 19,7,8% vs. 21,3%) peut &#234;tre expliqu&#233;e par la diff&#233;rence entre
la performance de ces deux mod&#232;les (BLEU 46,9% vs 44,1%).
</p>
<p>Il est important de mentionner que seuls les couplages prenant des graphes en entr&#233;e de la
compr&#233;hension permettent de s&#233;lectionner la traduction en fonction de l&#8217;&#233;tiquetage qui lui
sera appliqu&#233;. Dans les autres cas la s&#233;lection de la traduction se fait ind&#233;pendamment. On
remarque que le score BLEU de la traduction s&#233;lectionn&#233;e par le d&#233;codage conjoint est moins
bon que celui par la meilleure traduction (46,3 vs. 47,2 pour LLPB-SMT et 43,9 vs. 44,1 pour
CRF) malgr&#233; le fait que le premier est plus performant en CER. Cela montre l&#8217;int&#233;r&#234;t de la
m&#233;thode conjointe &#224; base de graphes qui permet de s&#233;lectionner la traduction qui pourra
&#234;tre &#233;tiquet&#233;e de la meilleure fa&#231;on possible.
</p>
<p>Les scores oracle montrent que la meilleure hypoth&#232;se s&#233;lectionn&#233;e lors du d&#233;codage n&#8217;est
pas forc&#233;ment la plus proche de la r&#233;f&#233;rence parmi les hypoth&#232;ses du graphe. Cependant, ce
r&#233;sultat est encourageant du fait que la performance du syst&#232;me peut &#234;tre encore am&#233;lior&#233;e
en ajustant les poids des mod&#232;les vu que des meilleures hypoth&#232;ses se trouvent dans le graphe.
Un d&#233;codage optimal permettra d&#8217;am&#233;liorer le CER de 0,6% absolu pour un d&#233;codage en
composant avec un graphe LLPB-SMT pour la traduction (19,7% vs 19,1%) et de 0,7% absolu
pour un d&#233;codage en composant avec un graphe CRF pour la traduction (21,3% vs 20,6%).
</p>
<p>6 Conclusion
</p>
<p>Dans cet article nous avons &#233;valu&#233; et compar&#233; des approches statistique &#224; la fois pour la
compr&#233;hension de la parole et pour la traduction automatique. Nous avons observ&#233; que
l&#8217;approche discriminante CRF reste la meilleure approche pour la compr&#233;hension de la parole,
malgr&#233; toutes les adaptations de l&#8217;approche LLPB-SMT pour la t&#226;che. Une approche de type
CRF pour la traduction a plusieurs limites et les performances de cette approche peuvent &#234;tre
am&#233;lior&#233;es par un mod&#232;le &#224; base de transducteurs permettant l&#8217;int&#233;gration de traitements
adapt&#233;s (r&#233;ordonnancement, segmentation, mod&#232;le de langage cible).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>101 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Nous avons alors pu proposer et &#233;valuer une approche de d&#233;codage conjoint entre la traduction
et la compr&#233;hension dans le contexte d&#8217;un syst&#232;me de compr&#233;hension de la parole multilingue.
Nous avons montr&#233; qu&#8217;avec un tel d&#233;codage nous pouvons obtenir de bonnes performances
tout en proposant un syst&#232;me homog&#232;ne sur les deux t&#226;ches sous-jacentes.
</p>
<p>Dans le contexte d&#8217;un syst&#232;me de dialogue homme-machine complet un d&#233;codage conjoint
entre la reconnaissance de la parole et la traduction pourra &#234;tre ajout&#233;. Dans ce cas un graphe
de reconnaissance devra &#234;tre compos&#233; avec un graphe de traduction. Cette composition
permettra au syst&#232;me de reconnaissance de transmettre des informations plus riches au
syst&#232;me de compr&#233;hension et le syst&#232;me de compr&#233;hension transmettra &#224; son tour des
informations riches au gestionnaire de dialogue ce qui influencera positivement la performance
globale du syst&#232;me.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ALLAUZEN, C., RILEY, M., SCHALKWYK, J., SKUT, W. et MOHRI, M. (2007). OpenFst : A general
and efficient weighted finite-state transducer library. In CIAA.
</p>
<p>ANOOP DEORAS, G. T. et HAKKANI-TUR, D. (2012). Joint decoding for speech recognition
and semantic tagging. In INTERSPEECH.
</p>
<p>BONNEAU-MAYNARD, H., ROSSET, S., AYACHE, C., KUHN, A. et MOSTEFA, D. (2005). Semantic
annotation of the french media dialog corpus. In EUROSPEECH.
</p>
<p>BROWN, P. F., PIETRA, S. D., PIETRA, V. J. D. et MERCER, R. L. (1993). The mathematics of
statistical machine translation : Parameter estimation. Computational Linguistics, 19(2):263&#8211;
311.
</p>
<p>CREGO, J. M. et MARI&#209;O, J. B. (2006). Improving statistical mt by coupling reordering and
decoding. Machine Translation, 20(3):199&#8211;215.
</p>
<p>CREGO, J. M., YVON, F. et MARI&#209;O, J. B. (2011). Ncode : an open source bilingual n-gram
smt toolkit. The Prague Bulletin of Mathematical Linguistics, 96:49&#8211;58.
</p>
<p>GASC&#211; I MORA, G. et S&#193;NCHEZ PEIR&#211;, J. (2007). Part-of-speech tagging based on machine
translation techniques. Pattern Recognition and Image Analysis, pages 257&#8211;264.
</p>
<p>HAHN, S., DINARELLI, M., RAYMOND, C., LEF&#200;VRE, F., LEHNEN, P., DE MORI, R., MOSCHITTI,
A., NEY, H. et RICCARDI, G. (2010). Comparing stochastic approaches to spoken language
understanding in multiple languages. IEEE Transactions in Audio, Speech and Language
Processing, 19(6):1569&#8211;1583.
</p>
<p>HAKKANI-T&#220;R, D. Z., B., F., RICCARDI, G. et T&#220;R, G. (2006). Beyond asr 1-best : Using word
confusion networks in spoken language understanding. Computer Speech and Language,
pages 495&#8211;514.
</p>
<p>JABAIAN, B. (2012). Syst&#232;mes de compr&#233;hension et de traduction de la parole : vers une
approche unifi&#233;e dans le cadre de la portabilit&#233; multilingue des syst&#232;mes de dialogue. Th&#232;se de
doctorat, CERI - Universit&#233; d&#8217;Avignon, Avignon.
</p>
<p>JABAIAN, B., BESACIER, L. et LEF&#200;VRE, F. (2010). Investigating multiple approaches for slu
portability to a new language. In INTERSPEECH.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>102 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>JABAIAN, B., BESACIER, L. et LEF&#200;VRE, F. (2011). Comparaison et combinaison d&#8217;approches
pour la portabilit&#233; vers une nouvelle langue d&#8217;un syst&#232;me de compr&#233;hension de l&#8217;oral. In
TALN.
KOEHN, P., HOANG, H., BIRCH, A., CALLISON-BURCH, C., FEDERICO, M., BERTOLDI, N., COWAN,
B., SHEN, W., MORAN, C., ZENS, R. et al. (2007). Moses : Open source toolkit for statistical
machine translation. In ACL.
KOEHN, P., OCH, F. et MARCU, D. (2003). Statistical phrase-based translation. In HLT-NAACL.
KUMAR, S. et BYRNE, W. (2003). A weighted finite state transducer implementation of the
alignment template model for statistical machine translation. In HLT-NAACL.
LAFFERTY, J., MCCALLUM, A. et PEREIRA, F. (2001). Conditional random fields : Probabilistic
models for segmenting and labeling sequence data. In ICML.
LAVERGNE, T., CAPP&#201;, O. et YVON, F. (2010). Practical very large scale CRFs. In ACL.
LAVERGNE, T., CREGO, J. M., ALLAUZEN, A. et YVON, F. (2011). From n-gram-based to crf-based
translation models. In WSMT.
LIANG, P., TASKAR, B. et KLEIN, D. (2006). Alignment by agreement. In HLT-NAACL.
MACHEREY, K., BENDER, O. et NEY, H. (2009). Application of statistical machine translation
approaches to spoken language understanding. In IEEE ICASSP.
MACHEREY, K., OCH, F. J. et NEY, H. (2001). Natural language understanding using statistical
machine translation. In INTERSPEECH.
MARI&#209;O, J. B., BANCHS, R. E., CREGO, J. M., de GISPERT, A., LAMBERT, P., FONOLLOSA, J.
A. R. et COSTA-JUSS&#192;, M. R. (2006). N-gram-based machine translation. Computational
Linguistic, 32(4):527&#8211;549.
OCH, F. (2003). Minimum error rate training in statistical machine translation. In ACL.
OCH, F. J. et NEY, H. (2002). Discriminative training and maximum entropy models for
statistical machine translation. In ACL.
PAPINENI, K., ROUKOS, S., WARD, T. et ZHU, W. (2002). Bleu : a method for automatic
evaluation of machine translation. In ACL.
RAMA, T., SINGH, A. et KOLACHINA, S. (2009). Modeling letter-to-phoneme conversion as a
phrase based statistical machine translation problem with minimum error rate training. In
HLT-NAACL.
RAMSHAW, L. et MARCUS, M. (1995). Text chunking using transformation-based learning.
In The Workshop on Very Large Corpora.
RIEDMILLER, M. et BRAUN, H. (1993). A direct adaptive method for faster backpropagation
learning : The RPROP algorithm. In ICNN.
SCHMID, H. (1994). Probabilistic part-of-speech tagging using decision trees. In NMLP.
SERVAN, C., RAYMOND, C., B., F. et NOCERA, P. (2006). Conceptual decoding from word
lattices : application to the spoken dialogue corpus MEDIA. In INTERSPEECH.
STOLCKE, A. (2002). Srilm-an extensible language modeling toolkit. In ICASSP.
T&#220;R, G., WRIGHT, J. H., GORIN, A. L., RICCARDI, G. et HAKKANI-T&#220;R, D. Z. (2002). Improving
spoken language understanding using word confusion networks. In INTERSPEECH.
TURIAN, J. P., WELLINGTON, B. et MELAMED, I. D. (2006). Scalable discriminative learning
for natural language parsing and translation. In NIPS.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>103 c&#65535; ATALA</p>

</div></div>
</body></html>