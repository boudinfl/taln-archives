TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Approches statistiques discriminantes pour l’interprétation
sémantique multilingue de la parole

Bassam J abaian-1, Fabrice Lefévre-1, Laurent Besacierz
(1) LIA, Université d’Avignon et des Pays de Vaucluse, Avignon, France
{bassam . jabaian , fabrice . lefevre}-@univ—avignon . fr
(2) LIG, Université Joseph Fourrier, Grenoble, France laurent .besacier©imag . fr

RESUME

Les approches statistiques sont maintenant trés répandues dans les différentes appli-
cations du traitement automatique de la langue et le choix d’une approche particuliére
dépend généralement de la tache visée. Dans le cadre de l’interprétation sémantique
multilingue, cet article présente une comparaison entre les méthodes utilisées pour la
traduction automatique et celles utilisées pour la compréhension de la parole. Cette
comparaison permet de proposer une approche uniﬁée aﬁn de réaliser un décodage conjoint
qui a la fois traduit une phrase et lui attribue ses étiquettes sémantiques. Ce décodage est
obtenu par une approche a base de transducteurs a états ﬁnis qui permet de composer un
graphe de traduction avec un graphe de compréhension. Cette représentation peut étre
généralisée pour permettre des transmissions d’informations riches entre les composants
d’un systéme d’interaction vocale homme-machine.

ABSTRACT
Discriminative statistical approaches for multilingual speech understanding

Statistical approaches are now widespread in the various applications of natural language
processing and the elicitation of an approach usually depends on the targeted task. This
paper presents a comparison between the methods used for machine translation and speech
understanding. This comparison allows to propose a uniﬁed approach to perform a joint
decoding which translates a sentence and assign semantic tags to the translation at the same
time. This decoding is achieved through a ﬁnite—state transducer approach which allows
to compose a translation graph with an understanding graph. This representation can be
generalized to allow the rich transmission of information between the components of a
human-machine vocal interface.

MOTS-CLES : compréhension multilingue, systéme de dialogue, CRF, graphes d’hypothéses.
KEYWORDS: multilingual understanding, dialogue system, CRE hypothesis graphs.

1 Introduction

Aujourd’hui, les approches statistiques sont trés utilisées pour toutes les applications du
traitement automatique de la langue (reconnaissance de la parole, traduction automatique,

90 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

analyse syntaxique, étiquetage sémantique...). La performance d’une approche particuliere
dépend énormément de la tache a laquelle elle est appliquée. Et, selon les taches, les approches
permettant les meilleures performances ne sont pas toujours les mémes.

Par exemple, pour une tache de compréhension de la parole (Spoken Language Understanding,
SLU), assimilable a un étiquetage séquentiel en concepts, les champs aléatoires conditionnels
(Conditional Random Fields, CRF) (Lafferty et al., 2001) utilisés dans leur version chaine
linéaire sont les plus performants (Hahn et al., 2010). Alors que pour la traduction automa-
tique, ce sont les modeles de traduction log—linéaires a base de segments sous—phrastiques
(Log—linear Phrase—Based Statistical Machine Translation, LLPB—SMT) (Koehn et al., 2003), qui
sont le plus souvent utilisés.

Cependant, malgré les différences entre les approches statistiques, celles-ci présentent des
points communs et les frontieres entre les unes et les autres ont tendance a s’estomper. On
voit, par exemple, des travaux autour de l’utilisation d’approches discriminantes de type CRF
pour la traduction automatique (Och et Ney, 2002; Liang et al., 2006; Lavergne et al., 2011),
tandis que les approches de traduction a base de segments, sont aussi utilisées dans d’autres
taches du traitement automatique de la langue, comme la conversion grapheme-phonemes
(Rama et al., 2009) ou le décodage de Part—Of—Speech (Gascé i Mora et Sanchez Peiré, 2007).

Dans cet article nous comparons les approches CRF—SLU et LLPB—SMT pour les taches de
compréhension et de traduction. Pour cela nous proposons d’utiliser et d’optimiser une
approche LLPB—SMT pour la compréhension de la parole, et par ailleurs d’intégrer des modéles
a base de CRF a un module de traduction automatique. Cette étude nous permet de mettre en
avant les spéciﬁcités de chaque tache et d’évaluer les performances des approches respectives
sur ces taches.

D’autre part, nous avons montré dans un travail précédent (Jabaian et al., 2010, 2011) que
l’utilisation de la traduction automatique constitue une solution efﬁcace pour la portabilité
multilingue d’un module de compréhension d’une langue vers une autre. Cette portabilité
peut étre obtenue en cascadant un module de traduction avec un module de compréhension
(pour traduire les entrées d’un utilisateur vers une langue pour laquelle nous disposons d’un
systéme de compréhension).

Dans certains cas, la meilleure hypothése de traduction n’est pas l’hypothese pour laquelle le
systéme de compréhension génere la meilleure hypothese (souvent pour des raisons liées a
l’ordre des mots). Et donc la sélection préalable de la meilleure traduction n’optimise pas
forcément le systéme lorsqu’on se place selon un scénario de compréhension multilingue.

Nous nous basons sur la comparaison réalisée entre les deux taches aﬁn de pouvoir proposer un
modéle qui pourra gérer la traduction et la compréhension d’une maniere similaire permettant
un décodage conjoint entre les modules. Ce décodage conjoint permettra de sélectionner
des traductions en tenant compte des hypotheses d’étiquetage sémantique. Dans cet esprit,
nous ne cherchons plus la meilleure traduction possible mais la traduction qui sera étiquetée
sémantiquement de la meilleure maniére possible.

Nos expériences sont basées sur le corpus de dialogue frangais MEDIA sur lequel nous appre-
nons un systeme de compréhension du francais. Dans le but de pouvoir utiliser ce systeme
pour étiqueter des entrées en italien, nous apprenons un systeme de traduction de l’italien
vers francais, qui sera utilisé ensuite lors des tests pour traduire les entrées italiennes vers le
francais aﬁn de les fournir en entrée du systéme de compréhension.

91 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Cet article est organisé de la maniere suivante : la section 2 présente l’utilisation d’une
approche de traduction automatique pour la compréhension de la parole. La section 3 décrit
l’utilisation des CRF pour la traduction automatique. Notre proposition pour un décodage
conjoint entre la compréhension et la traduction est présentée dans la section 4. Enﬁn la
section 5 présente l’étude expérimentale et les résultats.

2 Méthode de traduction pour la compréhension

Le probléme de la compréhension d’un énoncé utilisateur peut étre vu comme un probléme
de traduction de la séquence de mots qui forme cet énoncé (langue source) vers une séquence
de concepts (langue cible). (Macherey et al., 2001, 2009) ont montré que les approches de
la traduction automatique statistique peuvent étre utilisées avec un certain succés pour une
tache de compréhension de la parole. Cette approche part du principe que les séquences de
concepts sont les traductions des séquences de mots initiales.

Malgré l’apparente similitude entre les téiches de compréhension et de traduction, la compré-
hension a ses spéciﬁcités qui doivent étre prises en considération aﬁn de pouvoir améliorer
les performances obtenues par une approche de traduction comme LLPB-SMT.

Les différences entre une tache de traduction classique (d’une langue naturelle vers une
autre) et l’utilisation de la traduction pour la compréhension (traduction d’une langue vers
des étiquettes sémantiques) peuvent étre résumées comme suit :

— la sémantique d’une phrase respecte l’ordre dans lequel les mots sont émis contrairement a
une tache de traduction ou les mots traduits peuvent avoir un ordre différent de l’ordre
des mots de la phrase source selon le couple de langues considérées;

— dans une tache de traduction, un mot source peut n’étre aligné a aucun mot cible (fertilité
= 0), alors que pour la compréhension chaque mot doit étre aligné a un concept, sachant
que les mots qui ne contribuent pas au sens de la phrase sont étiquetés par un concept
spéciﬁque NULL;

— enﬁn, les mesures d’évaluation sont différentes entre les deux taches (BLEU (Papineni et al.,
2002) pour la traduction vs. CER pour la compréhension) et donc les outils utilisés pour
l’optimisation des systémes de traduction doivent étre adaptés pour optimiser le score CER.

En suivant l’hypothése que la sémantique d’une phrase respecte l’ordre dans lequel les mots
sont émis, nous proposons d’imposer une contrainte de monotonie pendant la traduction
(décodage monotone), qui oblige le décodeur a respecter, en fonction de l’ordre des mots
initiaux, l’ordre des concepts générés.

Une difﬁculté majeure du processus de traduction automatique est l’alignement d’un mot de
la langue source avec le mot correspondant dans le langue cible. Vu que les corpus utilisés
pour apprendre des systémes de traduction sont des corpus alignés au niveau des phrases, une
étape d’alignement automatique est nécessaire pour obtenir l’alignement en mots. Cependant,
la plupart des corpus de compréhension sont étiquetés (alignés) au niveau des segments
conceptuels et donc l’utilisation de ces informations d’alignement peut étre avantageuse pour
aider le processus d’alignement.

Pour cela nous proposons d’utiliser les corpus en format BIO (Begin Inside Outside) (Ramshaw
92 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

et Marcus, 1995). Ce format garanti que chaque mot de la phrase source est aligné a son
concept correspondant et donc aucun alignement automatique supplémentaire n’est requis.
De cette facon, 1’eXtraction de la table de segments est obtenue a partir d’un corpus avec un
alignement parfait (non bruité).

Vu que nous cherchons a évaluer les hypotheses générées par cette approche du point de vue
de la compréhension (la mesure d’éva1uation du systeme de compréhension étant 1e CER
et non pas le score BLEU) nous proposons de modiﬁer 1’a1gorithme MERT (Och, 2003) aﬁn
d’optimiser 1e CER directement.

3 Méthode de compréhension pour la traduction

Dans cette approche, 1e probleme de la traduction d’une phrase est considéré comme un
probleme d’étiquetage de la séquence de mots source, avec comme étiquettes possibles les
mots de la langue cible. L’apprentissage d’un étiqueteur fondé sur une approche CRF pour une
tache de traduction nécessite un corpus annoté (traduit) au niveau des mots. L’app1ication
des modeles IBM (Brown et al., 1993) permet d’obtenir automatiquement des alignements
en mots a partir d’un corpus bilingue aligné au niveau des phrases.

Comme pour la compréhension, ou plusieurs mots peuvent étre associés a un seul concept,
plusieurs mots source peuvent étre alignés avec un seul mot cible. Pour gérer cela, la propo-
sition la plus simple est d’app1iquer la méme méthode utilisée pour la compréhension : 1e
passage au format BIO. Ainsi la séquence francaise “je voudrais” qui est alignée au mot italien
“vorrei” sera représentée comme : <je, B_vorrei> <voudrais, I_vorrei>.

La difﬁculté principale pour apprendre des modéles CRF pour la traduction est liée au nombre
élevé d’étiquettes (correspondant a la taille du vocabulaire de la langue cible). (Riedmiller et
Braun, 1993) ont proposé d’uti1iser1’a1gorithme RPROP pour 1’optimisation des paramétres de
modéles 1orsqu’i1 s’agit d’un modéle avec un nombre important de paramétres. Cet algorithme
réduit 1e besoin en mémoire par rapport a d’autres algorithmes d’optimisation (Turian et al.,
2006).

Un autre défaut important de 1’uti1isation des CRF pour la traduction est qu’i1s ne prennent
pas en compte 1e réordonnancement des mots et que le modéle de langage cible limité par la
complexité algorithmique lors du décodage. Aﬁn d’obtenir un systéme de traduction efﬁcace
a base de CRE (Lavergne et al., 2011) cm proposé un modéle fondé sur des transducteurs a
états ﬁnis qui composent les différents étapes du processus de traduction. Nous 1’appe11erons
CRFPB—SMT car il intégre aussi un mécanisme pour la modélisation d’une table de traduction
par segments sous-phrastiques (appelés tuples dans ce contexte).

Le décodeur proposé pour ce modele est une composition de transducteurs a états ﬁnis
pondérés (Weighted Finite State Transducer, WFST) qui met en ouvre les fonctionnalités
standards des WFST, disponibles dans des bibliothéques logicielles comme OpenFST (Allauzen
et al., 2007). Essentiellement, 1e décodeur de traduction est une composition de transducteurs
qui représentent les étapes suivantes : 1e réordonnancement et la segmentation de la phrase
source selon les tuples de mots, 1’app1ication du modéle de traduction (mise en correspondance
des parties source et cible des tuples) avec une valuation des hypotheses a base de CRF et,
enﬁn, la composition avec un modéle de langage dans la langue cible. (Kumar et Byrne, 2003)

93 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

a proposé une architecture assez similaire qui utilise un modele ATTM (Alignment Template
Translation Models) au lieu des CRF comme modéle de traduction.

Cette architecture permet de voir la traduction d’une phrase comme une composition (0) de
transducteurs dans l’ordre suivant :

Atraduction = AS O AR ° AT ° AF ° AL

sachant que A5 est l’accepteur de la phrase source, AR représente un modéle de réordonnan-
cement, AT est un dictionnaire de tuples, qui associe des séquences de la langue source avec
leurs traductions possibles en se basant sur l’inventaire des tuples lors de l’apprentissage, AF
est une fonction d’extraction de motifs (feature matcher), qui permet d’attribuer des scores de
probabilité aux tuples en les comparant aux motifs des fonctions caractéristiques du modéle
CRF et AL est un modéle de langage de la langue cible.

4 Décodage conjoint pour la traduction et la compréhen-
sion, application a la compréhension multilingue

Notre étude des relations entre les différentes approches est réalisée avec l’objectif de pouvoir
les combiner du mieux possible pour la portabilité multilingue d’un systeme de compréhension.

Dans des travaux précédents (Jabaian et al., 2010), nous avons montré que la meilleure
méthode pour porter un systeme de compréhension existant vers une nouvelle langue est
aussi la plus simple : traduire les énoncés utilisateurs de la nouvelle langue vers la langue du
systéme existant et ensuite faire étiqueter les énoncés (traduits) par ce systéme.

Notre proposition est basée sur une cascade d’un systeme de traduction (LLPB—SMT) et d’un
systeme de compréhension (CRF—SLU). La meilleure hypothese générée par le systeme de
traduction constitue l’entrée du systéme de compréhension. Cependant, d’autres hypotheses
de traductions peuvent différer (méme sensiblement, par exemple dans l’ordre des mots) et
ces variantes peuvent étre mieux interprétées par l’étiqueteur sémantique. Donc la sélection
a priori de la meilleure traduction n’optimise pas forcément le comportement du systeme
global.

Pour faire face a ce probleme nous proposons d’effectuer un décodage conjoint entre la
traduction et la compréhension. Ce décodage conjoint aura l’avantage de pouvoir optimiser
la sélection de la traduction en prenant compte des étiquettes qui peuvent étre attribuées aux
différentes traductions possibles.

La proposition d’utiliser l’approche CRFPB—SMT utilisant des transducteurs pour la traduction
de graphes d’hypotheses peut étre appliquée la compréhension. Donc un systeme de compré-
hension Acomprehmion peut étre obtenu de la méme maniere que proposé dans la section 3.
Cette représentation nous permet alors d’obtenir un graphe de compréhension similaire a
celui obtenu pour la traduction. Vu que le vocabulaire des sorties du graphe de traduction
est le méme que celui de l’entrée du graphe de compréhension, ces deux graphes peuvent
étre composés facilement en utilisant la fonction de composition pour donner un graphe
permettant le décodage conjoint :

Aconjoint = Atraduction ° Acomprehension
94 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Cette composition prend une phrase de la langue cible en entrée et attribue une séquence de
concept a cette phrase en passant par un étiqueteur disponible dans la langue source. Elle
nous permet d’obtenir un décodage conjoint entre la traduction et la compréhension dans
la mesure ou les probabilités des deux modeles sont prises en compte. Un tel décodage ne
cherche pas a optimiser la traduction en soi, mais a optimiser le choix d’une traduction qui
donnera une meilleure compréhension automatique.

Le transducteur Aconjoint peut étre généralisé pour permettre de composer un graphe de
reconnaissance de la parole avec un graphe de compréhension dans le cadre d’un systéme de
dialogue. Dans un tel cas des procédures d’élagage devront étre prises en compte aﬁn d’assurer
que les opérations de composition puissent étre réalisées selon les contraintes classiques
(temps de calcul et espace mémoire machine disponible).

4. 1 T.ravaux connexes

Ce probleme rejoint, dans son esprit, le probleme classique de la cascade des composants
d’un systéme d’interaction vocal homme—machine. Dans une architecture standard, le systéme
de reconnaissance de la parole transmet sa meilleure hypothése de transcription au systéme
de compréhension. Vu que cette hypothese est bruitée, elle n’est pas forcément l’hypothese
que le systéme de compréhension pourra étiqueter le mieux.

Plusieurs travaux ont proposé un décodage conjoint entre la reconnaissance et la compré-
hension de la parole pour prendre en compte les n—meilleures hypotheses de reconnaissance
lors de l’étiquetage sémantique. Ces premiers travaux CI‘1'ir et al., 2002; Servan et al., 2006;
Hakkani—T1'ir et al., 2006) ont proposé d’utiliser un réseau de confusion entre les différentes
sorties de reconnaissance pour obtenir un graphe d’hypothéses. Le systéme de compréhension
dans ces propositions a été représenté par un WFST, dont les poids sont obtenus pas maximum
de vraisemblance sur les données d’apprentissage. Et le décodage conjoint est obtenu par la
composition du graphe de reconnaissance avec le graphe de compréhension.

Les résultats positifs obtenus par ces propositions ont encouragé d’autres travaux dans la
méme ligne. Vu que les modeles les plus performants dans la littérature sont les CRE (Anoop
Deoras et Hakkani-Tur, 2012) a proposé d’utiliser des modeles CRF au lieu des WFST pour
l’étape de compréhension.

Dans la lignée de ces travaux, notre proposition cherche a obtenir un décodage conjoint
pour la traduction et la compréhension. Les deux systémes étant de natures différentes, leur
combinaison et leur optimisation conjointe sont rendues délicates, d’o1‘1 l’intérét d’uniformiser
les systémes pour les deux taches.

5 Expériences et résultats

Toutes nos expériences utilisent le corpus de dialogue francais MEDIA. Le corpus MEDIA décrit
dans (Bonneau—Maynard et al., 2005) couvre un domaine lié aux réservations d’h6tel et
aux informations touristiques. Ce corpus est annoté avec 99 étiquettes qui représentent la
sémantique du domaine.

95 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Le corpus est constitué de 1257 dialogues regroupés en 3 parties : un ensemble d’apprentissage
(environ 13k phrases), un ensemble de développement (environ 1,3k phrases) et un ensemble
d’évaluation (environ 3,5k phrases). Un sous—ensemble de données d’apprentissage (environ
5,6k phrases), de méme que les ensembles de tests et de développement sont manuellement
traduits en italien.

Un systéme de type LLPB-SMT est utilisé pour apprendre un systéme de compréhension du
francais sur le corpus MEDIA, et le sous—ensemble traduit de ce corpus est utilisé comme corpus
parallele pour apprendre un modele de traduction a base de CRF. Ensuite l’approche CRFPB—
SMT a base de transducteurs est évaluée séparément pour la traduction et la compréhension
avant d’étre utilisée dans le cadre d’un décodage conjoint traduction/compréhension.

Le taux d’erreur en concepts (Concept Error Rate, CER) est le critere d’évaluation retenu pour
évaluer la tache de compréhension. Le CER est l’équivalent du taux d’erreur en mots (WER),
et peut étre déﬁni comme le rapport de la somme des concepts omis, insérés et substitués sur
le nombre de concepts dans la référence. D’autre part le score BLEU (Papineni et al., 2002)
qui se base sur des comptes de n—grammes communs entre hypothese et référence est retenu
pour évaluer la tache de traduction.

5.1 Evaluation des systémes de traduction a base de segments pour une
téiche de compréhension

La boite a outils MOSES (Koehn et al., 2007) a été utilisée pour apprendre un modéle LLPB-
SMT pour la compréhension du francais. Nos premieres tentatives ont clairement montré des
performances inférieures a celles d’un modele CRF-SLU de référence (CER 23,2% apres réglage
des paramétres avec MERT pour le LLPB-SMT a comparer aux 12,9% pour CRF-SLU 1.).

Les améliorations progressives du modéle proposées dans la section 2 sont évaluées dans
le tableau 1. L’utilisation de la contrainte de monotonie durant le décodage permet une
réduction de 0,5% absolu. Convertir les données selon le forrnalisme BIO avant la phase
d’apprentissage réduit le CER de facon signiﬁcative de 2,4%. Enﬁn, optimiser le score CER a
la place du score BLEU réduit le GER de O,4% supplémentaire. Enﬁn, l’ajout d’une liste de
villes a l’ensemble d’apprentissage avant réapprentissage du modéle LLPB-SMT répond au
probléme du traitement des mots hors—vocabulaire et permet une réduction ﬁnale de 0,8%.

Les résultats montrent qu’en dépit de réglages ﬁns de l’approche LLPB-SMT, les approches a
base de CRF obtiennent toujours les meilleures performances pour une tache de compréhen-
sion (CER de 12,9% pour CRF-SLU vs. 18,3% pour LLPB-SMT).

Une analyse rapide du type d’erreur montre que les méthodes utilisant des CRF ont un haut
niveau de suppressions comparativement aux autres types d’erreurs, tandis que la méthode
LLPB-SMT présente un meilleur compromis entre les erreurs de suppression et d’insertion,
et ce bien qu’elle aboutisse a un GER plus élevé. Un nombre important d’erreurs causées
par le modéle LLPB-SMT pour la compréhension est dﬁ a une mauvaise segmentation (le
plus souvent une sur—segmentation) des phrases. Cette caractéristique des modéles LLPB-
SMT méne a une distribution équilibrée d’erreurs entre les omissions, les insertions et les
substitutions, alors que pour CRF-SLU un grand nombre d’erreurs venait des omissions.

1. Se référer 5 (Jabaian et al., 2011) pour plus de détails sur le modéle CRF-SLU
96 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Modele Sub Om Ins CER

Initial 5,4 4,1 14,6 24,1

+MERT (BLEU) 5,6 8,4 9,2 23,2
+Décodage monotone 6,2 7,8 8,7 22,7
+Format BIO 5,7 9,3 5,3 20,3
MERT (CER) 5,3 9,2 4,6 19,1
Traitement de mots HV 5,8 7,4 5,1 18,3

TABLE 1: Les améliorations itératives du modéle LLPB-SMT pour la compréhension du
francais (CER%).

5.2 Evaluation des étiqueteurs sémantiques pour une tache de traduc-
tion automatique

Aﬁn de pouvoir évaluer notre proposition d’utiliser une approche CRF—SLU pour la traduction
nous utilisons la partie traduite manuellement (du francais vers l’italien) du corpus MEDIA
comme corpus paralléle pour apprendre le modéle de traduction. L’outil GIZA++ (disponible
avec MOSES) a été utilisé pour apprendre automatiquement un alignement mot a mot entre
les corpus des deux langues et l’outil Wapiti (Lavergne et al., 2010) a été utilisé pour apprendre
les paramétres des modéles CRE

Dans un premier temps, nous cherchons a apprendre un modéle CRF—SLU pour la traduction, en
utilisant l’algorithme RPROP comme proposé dans la section 3. Des fonctions caractéristiques
de type 4—grammes syrnétriques sur les observations et bi—grammes sur les étiquettes sont
utilisées pour apprendre ce modele. Les performances obtenues sont présentées dans le
tableau 2. Les résultats montrent que la performance du modéle CRF—SLU (BLEU de 42,5)
est signiﬁcativement moins bonne que la performance obtenue par la méthode LLPB-SMT
classique utilisant MOSES avec des paramétres de base (47,2) 2.

Aﬁn d’avoir une comparaison juste entre les deux méthodes, nous cherchons a évaluer l’ap-
proche LLPB-SMT dans les mémes conditions que l’approche CRF—SLU. La méthode LLPB-SMT
utilise un modéle de réordonnancement alors que CRF—SLU, dédié 2‘1l’étiquetage séquentiel,
ne comprend pas un tel modele. Pour cela nous rajoutons une contrainte de monotonie dans
le décodage pour l’approche LLPB-SMT empéchant tout réordonnancement. Il est aussi impor-
tant de mentionner que l’approche LLPB-SMT utilise un modéle de langage pour sélectionner
la meilleure traduction. Les performances du modéle LLPB-SMT de référence sont obtenues
en utilisant un modéle de langage tri-grammes (utilisé généralement dans les systémes de
traduction). Cependant la complex1'té algorithmique de l’approche CRF—SLU ne permet pas
d’utiliser un tel modéle de langage sur les étiquettes.

Aﬁn d’évaluer les approches CRF—SLU et LLPB-SMT dans les mémes conditions, et vu qu’on ne
peut pas augmenter la taille des fonctions caractéristiques du modéle CRE nous proposons
de dégrader l’approche LLPB-SMT et de réévaluer sa performance en utilisant un modéle de
langage de type bi-grammes.

Par ailleurs, en observant les sorties du modéle CRF—SLU, nous remarquons que les mots

2. Se référer 5 (Jabaian et al., 2011) pour plus de détails sur le modéle LLPB-SM'I'.
97 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

CRF-SLU LLPB-SMT
référence 42,5 47,2
décodage monotone 42,5 46,3
bi-grammes 42,5 46,0
traitement de mots HV 43,5 46,0

TABLE 2: Comparaison entre les modeles LLPB-SMT et CRF-SLU pour la traduction de l’italien
vers le francais (BLEU %).

inconnus (hors—vocabulaire) dans le test ont été traduits par d’autres mots du corpus cible
selon le contexte général de la phrase, contrairement a l’approche LLPB-SMT qui a tendance a
projeter les mots hors—vocabulaire tels qu’ils sont dans la phrase traduite. Ces mots, étant dans
la plupart des cas des noms de ville ou de lieux, leur traduction ne change pas d’une langue
a l’autre, et donc leur projection dans la sortie traduite est avantageuse pour les modéles
LLPB-SMT. Pour cela nous proposons un pré—traitement des mots inconnus dans la phrase
source permettant de les récupérer en sortie dans l’approche CRF-SLU.

Les résultats présentés dans le tableau 2 montrent que le décodage monotone dégrade la
performance du modele LLPB-SMT de 0,91% absolu. L’utilisation d’un modele de langage bi-
grammes augmente la perte de 0,3% supplémentaire. Le traitement des mots hors—vocabulaire
permet au modéle CRF-SLU de récupérer 1,0% de score BLEU par rapport au modéle CRF-
SLU de référence. On remarque que malgré la dégradation du modéle LLPB-SMT et les
améliorations du modéle CRF-SLU, la performance de ce demier reste inférieure a celle du
modéle LLPB-SMT (43,5% pour les CRF vs. 46,0% pour LLPB-SMT).

5.3 Evaluation des systémes a base de transducteurs CRFPB-SMT pour
la traduction et la compréhension

Un modéle de traduction CRFPB-SMT a base de transducteurs valués par des CRF pour la
traduction a été construit comme décrit dans la section 3. Ce modéle a été construit a partir
de l’outil n—code (Crego et al., 2011), implémenté pour apprendre des modeles de traduction
a base de n-grammes (Mariﬁo et al., 2006).

Cet outil utilise la bibliotheque OpenFst (Allauzen et al., 2007) pour construire un graphe de
traduction qui est la composition de plusieurs transducteurs. La différence entre le modéle
implémenté par cet outil et le modéle qu’on cherche a déveloper réside dans les poids du
modéle de traduction. Nous adaptons donc cet outil pour interroger les paramétres d’un
modéle CRF aﬁn d’estimer les probabilités de traduction et ensuite nous appliquons une
normalisation des scores de probabilité obtenus par ce modéle sur les différents chemins du
graphe (comme cela a été proposé dans (Lavergne et al., 2011)).

Dans n—code le modele de réordonnancement, proposé par (Crego et Mariﬁo, 2006), est fondé
sur une approche a base de regles apprises automatiquement sur les données d’entrainement.
Cette approche nécessite un étiquetage grammatical des phrases source et un alignement au
niveau des mots entre les phrases source et les phrases cible pour apprendre le modéle AR.
Nous avons utiliser les outils TreeTagger (Schmid, 1994) pour obtenir l’étiquetage grammatical

98 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Modéle Langue BLEU
LLPB-SMT 47,2
CRF-SLU IT —> FR 43,5
CRFPB-SMT 44, 1

TABLE 3: Comparaison entre les différentes approches (LLPB-SMT, CRF-SLU, CRFPB-SMT)
pour la traduction de l’italien vers le francais.

et GIZA++ pour l’alignement en mots. Le modele de langage utilisé dans nos expériences est
un modéle tri-grammes appris sur la partie cible de notre corpus d’apprentissage a l’aide de
l’outil SRILM (Stolcke, 2002).

Le tableau 3 présente une comparaison entre trois modéles : le modéle CRFPB-SMT, le
modéle LLPB-SMT (de référence) et le modéle CRF-SLU de base (présenté dans la section
précédente). Les résultats présentés dans ce tableau montrent que l’approche CRFPB-SMT a
base de transducteurs donne des performances inférieures mais comparables a celles obtenues
par l’approche LLPB-SM'I‘.

Malgré une dégradation de 3,1 points absolu, ces performances restent assez élevées en
valeur pour une tache de traduction (malgré un ensemble d’apprentissage de taille réduite),
ce qui s’explique dans notre contexte par le vocabulaire limité du domaine. Cette différence
de performance est comparable a celle observée par le LIMSI (Lavergne et al., 2010) (en ne
considérant que l’utilisation des paramétres de base).

D’autre part les résultats montrent que l’utilisation de graphes d’hypotheses dans CRFPB-SMT
est doublement avantageuse par rapport a l’utilisation d’une approche CRF simple; en plus
du fait qu’elle permette de traiter des graphes en entrées, cette approche perrnet d’emblée
d’augmenter la performance du systéme d’environ 1 point absolu.

Le mécanisme utilisé pour obtenir des graphe de traduction peut étre utilisé d’une maniére
similaire pour la compréhension. Dans un premier temps, le graphe d’hypothese de concepts
est obtenu en composant tous les modéles A5 0 AR 0 AT 0 AF 0 AL comme cela a été proposé
pour la traduction. Cette approche donne un CER de 15,3%, bien moins bon que l’approche
CRF-SLU de base (12,9%).

Aﬁn de prendre les spéciﬁcités de la compréhension (qui ne comprend pas de modéle de
réordonnancement, ni de modele de langage cible ﬁnal), nous proposons d’obtenir le graphe
de sorties en combinant uniquement les modeles A5 0 AF. Cela nous a permis d’augmenter la
performance de cette approche de 2,2% absolu (15,3% vs 13,1%) perrnettant de retrouver
quasiment les mémes performances qu’avec CRF-SLU (13,1% vs 12.9%). Une comparaison
entre les performances des différentes versions est donnée dans le tableau 4. Par la suite,
CRFPB-SMT simpliﬁé est utilisé pour toutes les expériences de compréhension.

5.4 Décodage conjoint dans un scénario de compréhension multilingue
Un décodage conjoint pour la traduction et la compréhension a été appliqué comme nous

l’avons proposé dans la section 4. Ce décodage consiste a transmettre le graphe de traduction
99 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Modele Sub Del Ins CER

CRF-SLU 3,1 8,1 1,8 12,9

CRFPB-SMT (complet) (A5 0 AR 0 AT 0 AF 0 AL ) 4,2 8,8 2,3 15,3
CRFPB-SMT (simpliﬁé) (A5 0 AT 0 AF) 3,5 7,6 2,0 13,1

TABLE 4: Evaluation des approches basées sur les CRF pour la compréhension du francais.

en entrée du module de compréhension (incluant les scores pondérés relatifs a la traduction)
et ensuite récupérer en sortie un graphe de compréhension qui intégre les scores de traduction
et de compréhension. Ce décodage permettra d’étiqueter des phrases en italien en combinant
un systéme de traduction italien vers francais et un systéme de compréhension du francais

Pour cela nous avons adapté l’accepteur du modéle de compréhension du francais (donné
dans la derniére ligne du tableau 4 décrit dans 5.3) pour prendre des graphes en entrée (au
lieu d’une hypothése unique). Ce transducteur génére un graphe valué de compréhension qui
prend en compte les scores de traduction.

Au moment du décodage les deux scores (traduction et compréhension) sont pris en consi-
dération. Dans un premier temps nous proposons que le score ﬁnal pour chaque chemin du
graphe soit l’addition simple du score de traduction et du score de compréhension sur ce
chemin3. Le meilleur chemin est ensuite sélectionné parmi l’ensemble des chemins possibles
dans le graphe. Ce chemin représente donc un décodage conjoint entre la traduction et la
compréhension (marginalisation de la variabilité aléatoire liée a la traduction intermédiaire).

Aﬁn de pouvoir se positionner par rapport a l’état de l’art, nous proposons de réaliser le
décodage conjoint selon deux modes : le systéme de traduction utilisé est un modéle LLPB-
SMT (en utilisant la boite a outils MOSES) dans le premier et un CRFPB-SMT (comme décrit
dans 5.3) dans le second. Dans les deux cas les performances du décodage conjoint sont
comparées avec ou sans prise en compte du graphe d’hypothéses complet. Dans un premier
cas, le meilleur chemin (1-best) du graphe de traduction est fourni en entrée du systéme de
compréhension. Dans un second cas, l’oracle du graphe de traduction est donné en entrée
au module de compréhension. Les scores oracle représentent une évaluation fondée sur le
chemin du graphe qui se rapproche le plus de la référence de la traduction. Il est alors possible
de mesurer l’impact de la qualité de la traduction sur les performances de compréhension.

Le résultat de cette comparaison est donné dans la tableau 5. Nous avons aussi calculé les
scores oracle (pour la traduction et la compréhension) sur les sorties des différents couplages
de modules, et nous avons calculé le score BLEU sur la traduction sélectionnée par le décodage
conjoint (derniére colonne du tableau 5).

La premiere ligne de ce tableau constitue la combinaison de référence (sans l’utilisation de
graphe) dans laquelle la sortie de MOSES est donnée en entrée d’un modéle CRE Les résultats
montrent que le graphe de traduction perrnet d’améliorer la performance du systéme par
rapport au systéme de 1—meilleure traduction (CER 19,7% vs. 19,9% pour LLPB—SMT et
21,3 vs. 21,7 pour CRF). L’utilisation d’un graphe de traduction donne aussi des meilleurs
performances par rapport a la combinaison avec son oracle (CER 19,7% vs. 19,8% pour

3. Une expérience préliminaire pour mesurer l’impact de la pondération des scores est présentée dans (Jabaian,
2012).

100 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Traduction Compréhension (CRF)
Modéle Sortie BLEU / Oracle Entrée CER/ Oracle BLEU
1-best 47,2/47,2 1-best 19,9/ 19,9 47,2

graphe 46,9/47,9 1-best(graphe) 19,9 / 19,4 46,9
graphe 46,9/47,9 oracle (graphe) 19,8 / 19,3 47,9
graphe 46,9/47,9 graphe 19, 7/ 19, 1 46,3
graphe 44,1 /44,9 1-best(graphe) 21,7/ 21,1 44,1
CRFPB-SMT graphe 44,1/44,9 oracle (graphe) 21,6 / 21,1 44,9
graphe 44, 1 /44,9 graphe 2 1,3 / 20, 6 43,9

LLPB-SMT

TABLE 5: Evaluation des différents conﬁgurations de compréhension multilingue
franccais—italien, variant selon le type d’information transmise entre les 2 étapes (1-best,
oracle ou graphe).

LLPB-SMT et 21,3 vs. 21,6 pour CRF). La différence entre la performance obtenue par le
décodage conjoint en utilisant un modéle LLPB-SMT pour la traduction et celle obtenue en
utilisant un modéle CRF (CER 19,7,8% vs. 21,3%) peut étre expliquée par la différence entre
la performance de ces deux modeles (BLEU 46,9% vs 44,1%).

11 est important de mentionner que seuls les couplages prenant des graphes en entrée de la
compréhension permettent de sélectionner la traduction en fonction de l’étiquetage qui lui
sera appliqué. Dans les autres cas la sélection de la traduction se fait indépendamment. On
remarque que le score BLEU de la traduction sélectionnée par le décodage conjoint est moins
bon que celui par la meilleure traduction (46,3 vs. 47,2 pour LLPB-SMT et 43,9 vs. 44,1 pour
CRF) malgré le fait que le premier est plus performant en GER. Cela montre l’intérét de la
méthode conjointe a base de graphes qui permet de sélectionner la traduction qui pourra
étre étiquetée de la meilleure facon possible.

Les scores oracle montrent que la meilleure hypothése sélectionnée lors du décodage n’est
pas forcément la plus proche de la référence parmi les hypotheses du graphe. Cependant, ce
résultat est encourageant du fait que la performance du systeme peut étre encore améliorée
en ajustant les poids des modéles vu que des meilleures hypotheses se trouvent dans le graphe.
Un décodage optimal permettra d’améliorer le CER de 0,6% absolu pour un décodage en
composant avec un graphe LLPB-SMT pour la traduction (19,7% vs 19,1%) et de 0,7% absolu
pour un décodage en composant avec un graphe CRF pour la traduction (21,3% vs 20,6%).

6 Conclusion

Dans cet article nous avons évalué et comparé des approches statistique a la fois pour la
compréhension de la parole et pour la traduction automatique. Nous avons observé que
l’approche discriminante CRF reste la meilleure approche pour la compréhension de la parole,
malgré toutes les adaptations de l’approche LLPB-SMT pour la tache. Une approche de type
CRF pour la traduction a plusieurs limites et les performances de cette approche peuvent étre
améliorées par un modéle a base de transducteurs permettant l’intégration de traitements
adaptés (réordonnancement, segmentation, modele de langage cible).

101 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Nous avons alors pu proposer et évaluer une approche de décodage conjoint entre la traduction
et la compréhension dans le contexte d’un systeme de compréhension de la parole multilingue.
Nous avons montré qu’avec un tel décodage nous pouvons obtenir de bonnes performances
tout en proposant un systeme homogene sur les deux taches sous-jacentes.

Dans le contexte d’un systéme de dialogue homme-machine complet un décodage conjoint
entre la reconnaissance de la parole et la traduction pourra étre ajouté. Dans ce cas un graphe
de reconnaissance devra étre composé avec un graphe de traduction. Cette composition
permettra au systéme de reconnaissance de transmettre des informations plus riches au
systéme de compréhension et le systéme de compréhension transmettra a son tour des
informations riches au gestionnaire de dialogue ce qui inﬂuencera positivement la performance
globale du systeme.

Références

ALLAUZEN, C., RILEY, M., SCHALKWYK, J., SKUT, W. et MOHRI, M. (2007). OpenFst : A general
and efﬁcient weighted ﬁnite—state transducer library. In CIAA.

ANOOP DEORAS, G. T. et HAKKANI-TUR, D. (2012). Joint decoding for speech recognition
and semantic tagging. In INTERSPEECH.

BONNEAU-MAYNARD, H., ROSSET, S., AYACHE, C., KUHN, A. et MOSTEFA, D. (2005). Semantic
annotation of the french media dialog corpus. In EUROSPEECH.

BROWN, P. E, PIETRA, S. D., PIETRA, V J . D. et MERCER, R. L. (1993). The mathematics of
statistical machine translation : Parameter estimation. Computational Linguistics, 19(2):263—
311.

CREGO, J. M. et MARINO, J . B. (2006). Improving statistical mt by coupling reordering and
decoding. Machine Translation, 20(3):199—215.

CREGO, J . M., YVON, F. et MARINO, J . B. (2011). Ncode : an open source bilingual n-gram
smt toolkit. 'Ihe Prague Bulletin of Mathematical Linguistics, 96:49-58.

GAsco I MORA, G. et SANCHEZ PEIRC), J. (2007). Part-of-speech tagging based on machine
translation techniques. Pattern Recognition and Image Analysis, pages 257-264.

HAHN, S., DINARELLI, M., RAYMOND, C., LEFEVRE, E, LEHNEN, P, DE MORI, R., MOSCHITTI,
A., NEY, H. et RICCARDI, G. (2010). Comparing stochastic approaches to spoken language
understanding in multiple languages. IEEE Transactions in Audio, Speech and Language
Processing, 19(6):1569—1583.

HAKKAN1-TUR, D. Z., B., F., RICCARDI, G. et TUR, G. (2006). Beyond asr 1-best : Using word
confusion networks in spoken language understanding. Computer Speech and Language,
pages 495-514.

JABAIAN, B. (2012). Systémes de compréhension et de traduction de la parole : vers une
approche unifiée dans le cadre de la portabilite’ multilingue des systémes de dialogue. These de
doctorat, CERI — Université d’Avignon, Avignon.

JABAIAN, B., BESACIER, L. et LEFEVRE, F. (2010). Investigating multiple approaches for slu
portability to a new language. In INTERSPEECH.

102 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

JABAIAN, B., BESACIER, L. et LEFEVRE, E (2011). Comparaison et combinaison d’approches
pour la portabilité vers une nouvelle langue d’un systéme de compréhension de l’oral. In
TALN.

KOEHN, P., HOANG, H., BIRCH, A., CALLISON-BURCH, C., FEDERICO, M., BERTOLDI, N., CowAN,
B., SHEN, W., MORAN, C., ZENS, R. et al. (2007). Moses : Open source toolkit for statistical
machine translation. In ACL.

KOEHN, P., OCH, E et MARCU, D. (2003). Statistical phrase—based translation. In HL'I"—NAACL.

KUMAR, S. et BYRNE, W. (2003). A weighted ﬁnite state transducer implementation of the
alignment template model for statistical machine translation. In HLT-NAACL.

LAFFERTY, J ., MCCALLUM, A. et PEREIRA, F. (2001). Conditional random ﬁelds : Probabilistic
models for segmenting and labeling sequence data. In ICML.

LAVERGNE, T., CAPPE, O. et YVoN, E (2010). Practical very large scale CRFs. In ACL.

LAVERGNE, T., CREGO, J. M., ALLAUZEN, A. et YVON, F. (201 1). From n-gram-based to crf-based
translation models. In WSMT.

LIANG, P., TASKAR, B. et KLEIN, D. (2006). Alignment by agreement. In HLT-NAACL.

MACHEREY, K., BENDER, O. et NEY, H. (2009). Application of statistical machine translation
approaches to spoken language understanding. In IEEE ICASSP.

MACHEREY, K., OCH, E J . et NEY, H. (2001). Natural language understanding using statistical
machine translation. In INTERSPEECH.

MARINO, J. B., BANCHS, R. E., CREGO, J. M., de GISPERT, A., LAMBERT, P., FoNoLLosA, J.
A. R. et CosTA—JUssA, M. R. (2006). N—gram—based machine translation. Computational
Linguistic, 32(4):527—549.

OCH, E (2003). Minimum error rate training in statistical machine translation. In ACL.

OCH, E J. et NEY, H. (2002). Discriminative training and maximum entropy models for
statistical machine translation. In ACL.

PAPINENI, K., RoUKos, S., WARD, T. et ZHU, W. (2002). Bleu : a method for automatic
evaluation of machine translation. In ACL.

RAMA, T., SINGH, A. et KOLACHINA, S. (2009). Modeling letter-to-phoneme conversion as a
phrase based statistical machine translation problem with minimum error rate training. In
HLT-NAACL.

RAMSHAW, L. et MARCUS, M. (1995). Text chunking using transformation-based learning.
In The Workshop on Very Large Corpora.

RIEDMILLER, M. et BRAUN, H. (1993). A direct adaptive method for faster backpropagation
learning : The RPROP algorithm. In ICNN.

SCHMID, H. (1994). Probabilistic part-of-speech tagging using decision trees. In NMLP.

SERVAN, C., RAYMOND, C., B., F. et NOCERA, P. (2006). Conceptual decoding from word
lattices : application to the spoken dialogue corpus MEDIA. In INT ERSPEECH .

STOLCKE, A. (2002). Srilm—an extensible language modeling toolkit. In ICASSP.

TUR, G., WRIGHT, J. H., GORIN, A. L., RICCARDI, G. et HAKKANI-TUR, D. Z. (2002). Improving
spoken language understanding using word confusion networks. In INT ERSPEECH .

TURIAN, J . P., WELLINGTON, B. et MELAMED, I. D. (2006). Scalable discriminative learning
for natural language parsing and translation. In NIPS.

103 © ATALA

