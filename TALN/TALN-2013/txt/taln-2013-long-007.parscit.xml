<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C ALLAUZEN</author>
<author>M RILEY</author>
<author>J SCHALKWYK</author>
<author>W et MOHRI SKUT</author>
<author>M</author>
</authors>
<title>OpenFst : A general and efficient weighted finite-state transducer library.</title>
<date>2007</date>
<booktitle>In CIAA.</booktitle>
<marker>ALLAUZEN, RILEY, SCHALKWYK, SKUT, M, 2007</marker>
<rawString>ALLAUZEN, C., RILEY, M., SCHALKWYK, J., SKUT, W. et MOHRI, M. (2007). OpenFst : A general and efficient weighted finite-state transducer library. In CIAA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ANOOP DEORAS</author>
<author>G T et HAKKANI-TUR</author>
<author>D</author>
</authors>
<title>Joint decoding for speech recognition and semantic tagging.</title>
<date>2012</date>
<booktitle>In INTERSPEECH.</booktitle>
<marker>DEORAS, HAKKANI-TUR, D, 2012</marker>
<rawString>ANOOP DEORAS, G. T. et HAKKANI-TUR, D. (2012). Joint decoding for speech recognition and semantic tagging. In INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H BONNEAU-MAYNARD</author>
<author>S ROSSET</author>
<author>C AYACHE</author>
<author>A et MOSTEFA KUHN</author>
<author>D</author>
</authors>
<title>Semantic annotation of the french media dialog corpus.</title>
<date>2005</date>
<booktitle>In EUROSPEECH.</booktitle>
<marker>BONNEAU-MAYNARD, ROSSET, AYACHE, KUHN, D, 2005</marker>
<rawString>BONNEAU-MAYNARD, H., ROSSET, S., AYACHE, C., KUHN, A. et MOSTEFA, D. (2005). Semantic annotation of the french media dialog corpus. In EUROSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F BROWN</author>
<author>S D PIETRA</author>
<author>V J D et MERCER PIETRA</author>
<author>R L</author>
</authors>
<title>The mathematics of statistical machine translation : Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>311</pages>
<marker>BROWN, PIETRA, PIETRA, L, 1993</marker>
<rawString>BROWN, P. F., PIETRA, S. D., PIETRA, V. J. D. et MERCER, R. L. (1993). The mathematics of statistical machine translation : Parameter estimation. Computational Linguistics, 19(2):263– 311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M et MARIÑO CREGO</author>
<author>J B</author>
</authors>
<title>Improving statistical mt by coupling reordering and decoding.</title>
<date>2006</date>
<journal>Machine Translation,</journal>
<volume>20</volume>
<issue>3</issue>
<marker>CREGO, B, 2006</marker>
<rawString>CREGO, J. M. et MARIÑO, J. B. (2006). Improving statistical mt by coupling reordering and decoding. Machine Translation, 20(3):199–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M CREGO</author>
<author>F et MARIÑO YVON</author>
<author>J B</author>
</authors>
<title>Ncode : an open source bilingual n-gram smt toolkit.</title>
<date>2011</date>
<booktitle>The Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>96--49</pages>
<marker>CREGO, YVON, B, 2011</marker>
<rawString>CREGO, J. M., YVON, F. et MARIÑO, J. B. (2011). Ncode : an open source bilingual n-gram smt toolkit. The Prague Bulletin of Mathematical Linguistics, 96:49–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GASCÓ I MORA</author>
<author>G et SÁNCHEZ PEIRÓ</author>
<author>J</author>
</authors>
<title>Part-of-speech tagging based on machine translation techniques. Pattern Recognition and Image Analysis,</title>
<date>2007</date>
<pages>257--264</pages>
<marker>MORA, PEIRÓ, J, 2007</marker>
<rawString>GASCÓ I MORA, G. et SÁNCHEZ PEIRÓ, J. (2007). Part-of-speech tagging based on machine translation techniques. Pattern Recognition and Image Analysis, pages 257–264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S HAHN</author>
<author>M DINARELLI</author>
<author>C RAYMOND</author>
<author>F LEFÈVRE</author>
<author>P LEHNEN</author>
<author>R DE MORI</author>
<author>A MOSCHITTI</author>
<author>H et RICCARDI NEY</author>
<author>G</author>
</authors>
<title>Comparing stochastic approaches to spoken language understanding in multiple languages.</title>
<date>2010</date>
<journal>IEEE Transactions in Audio, Speech and Language Processing,</journal>
<volume>19</volume>
<issue>6</issue>
<marker>HAHN, DINARELLI, RAYMOND, LEFÈVRE, LEHNEN, DE MORI, MOSCHITTI, NEY, G, 2010</marker>
<rawString>HAHN, S., DINARELLI, M., RAYMOND, C., LEFÈVRE, F., LEHNEN, P., DE MORI, R., MOSCHITTI, A., NEY, H. et RICCARDI, G. (2010). Comparing stochastic approaches to spoken language understanding in multiple languages. IEEE Transactions in Audio, Speech and Language Processing, 19(6):1569–1583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Z HAKKANI-TÜR</author>
<author>F B</author>
<author>G et TÜR RICCARDI</author>
<author>G</author>
</authors>
<title>Beyond asr 1-best : Using word confusion networks in spoken language understanding. Computer Speech and Language,</title>
<date>2006</date>
<pages>495--514</pages>
<marker>HAKKANI-TÜR, B, RICCARDI, G, 2006</marker>
<rawString>HAKKANI-TÜR, D. Z., B., F., RICCARDI, G. et TÜR, G. (2006). Beyond asr 1-best : Using word confusion networks in spoken language understanding. Computer Speech and Language, pages 495–514.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B JABAIAN</author>
</authors>
<title>Systèmes de compréhension et de traduction de la parole : vers une approche unifiée dans le cadre de la portabilité multilingue des systèmes de dialogue. Thèse de doctorat, CERI - Université d’Avignon,</title>
<date>2012</date>
<location>Avignon.</location>
<marker>JABAIAN, 2012</marker>
<rawString>JABAIAN, B. (2012). Systèmes de compréhension et de traduction de la parole : vers une approche unifiée dans le cadre de la portabilité multilingue des systèmes de dialogue. Thèse de doctorat, CERI - Université d’Avignon, Avignon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B JABAIAN</author>
<author>L et LEFÈVRE BESACIER</author>
<author>F</author>
</authors>
<title>Investigating multiple approaches for slu portability to a new language. In INTERSPEECH.</title>
<date>2010</date>
<marker>JABAIAN, BESACIER, F, 2010</marker>
<rawString>JABAIAN, B., BESACIER, L. et LEFÈVRE, F. (2010). Investigating multiple approaches for slu portability to a new language. In INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>c ATALA TALN-RÉCITAL</author>
</authors>
<title>Comparaison et combinaison d’approches pour la portabilité vers une nouvelle langue d’un système de compréhension de l’oral.</title>
<date>2013</date>
<booktitle>In TALN.</booktitle>
<pages>17--21</pages>
<contexts>
<context position="2468" citStr="TALN-RÉCITAL 2013" startWordPosition="336" endWordPosition="337">pproach which allows to compose a translation graph with an understanding graph. This representation can be generalized to allow the rich transmission of information between the components of a human-machine vocal interface. MOTS-CLÉS : compréhension multilingue, système de dialogue, CRF, graphes d’hypothèses. KEYWORDS: multilingual understanding, dialogue system, CRF, hypothesis graphs. 1 Introduction Aujourd’hui, les approches statistiques sont très utilisées pour toutes les applications du traitement automatique de la langue (reconnaissance de la parole, traduction automatique, 90 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne analyse syntaxique, étiquetage sémantique...). La performance d’une approche particulière dépend énormément de la tâche à laquelle elle est appliquée. Et, selon les tâches, les approches permettant les meilleures performances ne sont pas toujours les mêmes. Par exemple, pour une tâche de compréhension de la parole (Spoken Language Understanding, SLU), assimilable à un étiquetage séquentiel en concepts, les champs aléatoires conditionnels (Conditional Random Fields, CRF) (Lafferty et al., 2001) utilisés dans leur version chaîne linéaire sont les plus performant</context>
<context position="6274" citStr="TALN-RÉCITAL 2013" startWordPosition="901" endWordPosition="902">prit, nous ne cherchons plus la meilleure traduction possible mais la traduction qui sera étiquetée sémantiquement de la meilleure manière possible. Nos expériences sont basées sur le corpus de dialogue français MEDIA sur lequel nous apprenons un système de compréhension du français. Dans le but de pouvoir utiliser ce système pour étiqueter des entrées en italien, nous apprenons un système de traduction de l’italien vers français, qui sera utilisé ensuite lors des tests pour traduire les entrées italiennes vers le français afin de les fournir en entrée du système de compréhension. 91 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Cet article est organisé de la manière suivante : la section 2 présente l’utilisation d’une approche de traduction automatique pour la compréhension de la parole. La section 3 décrit l’utilisation des CRF pour la traduction automatique. Notre proposition pour un décodage conjoint entre la compréhension et la traduction est présentée dans la section 4. Enfin la section 5 présente l’étude expérimentale et les résultats. 2 Méthode de traduction pour la compréhension Le problème de la compréhension d’un énoncé utilisateur peut être vu comme un problème de traducti</context>
<context position="9619" citStr="TALN-RÉCITAL 2013" startWordPosition="1417" endWordPosition="1418"> de la langue source avec le mot correspondant dans le langue cible. Vu que les corpus utilisés pour apprendre des systèmes de traduction sont des corpus alignés au niveau des phrases, une étape d’alignement automatique est nécessaire pour obtenir l’alignement en mots. Cependant, la plupart des corpus de compréhension sont étiquetés (alignés) au niveau des segments conceptuels et donc l’utilisation de ces informations d’alignement peut être avantageuse pour aider le processus d’alignement. Pour cela nous proposons d’utiliser les corpus en format BIO (Begin Inside Outside) (Ramshaw 92 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne et Marcus, 1995). Ce format garanti que chaque mot de la phrase source est aligné à son concept correspondant et donc aucun alignement automatique supplémentaire n’est requis. De cette façon, l’extraction de la table de segments est obtenue à partir d’un corpus avec un alignement parfait (non bruité). Vu que nous cherchons à évaluer les hypothèses générées par cette approche du point de vue de la compréhension (la mesure d’évaluation du système de compréhension étant le CER et non pas le score BLEU) nous proposons de modifier l’algorithme MERT (Och, 2003) afin</context>
<context position="13102" citStr="TALN-RÉCITAL 2013" startWordPosition="1954" endWordPosition="1955">t en ouvre les fonctionnalités standards des WFST, disponibles dans des bibliothèques logicielles comme OpenFST (Allauzen et al., 2007). Essentiellement, le décodeur de traduction est une composition de transducteurs qui représentent les étapes suivantes : le réordonnancement et la segmentation de la phrase source selon les tuples de mots, l’application dumodèle de traduction (mise en correspondance des parties source et cible des tuples) avec une valuation des hypothèses à base de CRF et, enfin, la composition avec un modèle de langage dans la langue cible. (Kumar et Byrne, 2003) 93 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne a proposé une architecture assez similaire qui utilise un modèle ATTM (Alignment Template Translation Models) au lieu des CRF comme modèle de traduction. Cette architecture permet de voir la traduction d’une phrase comme une composition (◦) de transducteurs dans l’ordre suivant : λt raduct ion = λS ◦λR ◦λT ◦λF ◦λL sachant que λS est l’accepteur de la phrase source, λR représente un modèle de réordonnancement, λT est un dictionnaire de tuples, qui associe des séquences de la langue source avec leurs traductions possibles en se basant sur l’inventaire des tuples</context>
<context position="16205" citStr="TALN-RÉCITAL 2013" startWordPosition="2422" endWordPosition="2423">es peut être appliquée la compréhension. Donc un système de compré- hension λcomprehension peut être obtenu de la même manière que proposé dans la section 3. Cette représentation nous permet alors d’obtenir un graphe de compréhension similaire à celui obtenu pour la traduction. Vu que le vocabulaire des sorties du graphe de traduction est le même que celui de l’entrée du graphe de compréhension, ces deux graphes peuvent être composés facilement en utilisant la fonction de composition pour donner un graphe permettant le décodage conjoint : λcon joint = λt raduct ion ◦λcomprehension 94 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Cette composition prend une phrase de la langue cible en entrée et attribue une séquence de concept à cette phrase en passant par un étiqueteur disponible dans la langue source. Elle nous permet d’obtenir un décodage conjoint entre la traduction et la compréhension dans la mesure où les probabilités des deux modèles sont prises en compte. Un tel décodage ne cherche pas à optimiser la traduction en soi, mais à optimiser le choix d’une traduction qui donnera une meilleure compréhension automatique. Le transducteur λcon joint peut être généralisé pour permettre d</context>
<context position="19279" citStr="TALN-RÉCITAL 2013" startWordPosition="2886" endWordPosition="2887">ion cherche à obtenir un décodage conjoint pour la traduction et la compréhension. Les deux systèmes étant de natures différentes, leur combinaison et leur optimisation conjointe sont rendues délicates, d’où l’intérêt d’uniformiser les systèmes pour les deux tâches. 5 Expériences et résultats Toutes nos expériences utilisent le corpus de dialogue français MEDIA. Le corpus MEDIA décrit dans (Bonneau-Maynard et al., 2005) couvre un domaine lié aux réservations d’hôtel et aux informations touristiques. Ce corpus est annoté avec 99 étiquettes qui représentent la sémantique du domaine. 95 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Le corpus est constitué de 1257 dialogues regroupés en 3 parties : un ensemble d’apprentissage (environ 13k phrases), un ensemble de développement (environ 1,3k phrases) et un ensemble d’évaluation (environ 3,5k phrases). Un sous-ensemble de données d’apprentissage (environ 5,6k phrases), de même que les ensembles de tests et de développement sont manuellement traduits en italien. Un système de type LLPB-SMT est utilisé pour apprendre un système de compréhension du français sur le corpus MEDIA, et le sous-ensemble traduit de ce corpus est utilisé comme corpus </context>
<context position="22761" citStr="TALN-RÉCITAL 2013" startWordPosition="3430" endWordPosition="3431">n meilleur compromis entre les erreurs de suppression et d’insertion, et ce bien qu’elle aboutisse à un CER plus élevé. Un nombre important d’erreurs causées par le modèle LLPB-SMT pour la compréhension est dû à une mauvaise segmentation (le plus souvent une sur-segmentation) des phrases. Cette caractéristique des modèles LLPBSMT mène à une distribution équilibrée d’erreurs entre les omissions, les insertions et les substitutions, alors que pour CRF-SLU un grand nombre d’erreurs venait des omissions. 1. Se référer à (Jabaian et al., 2011) pour plus de détails sur le modèle CRF-SLU 96 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Modèle Sub Om Ins CER Initial 5,4 4,1 14,6 24,1 +MERT (BLEU) 5,6 8,4 9,2 23,2 +Décodage monotone 6,2 7,8 8,7 22,7 +Format BIO 5,7 9,3 5,3 20,3 MERT (CER) 5,3 9,2 4,6 19,1 Traitement de mots HV 5,8 7,4 5,1 18,3 TABLE 1: Les améliorations itératives du modèle LLPB-SMT pour la compréhension du français (CER%). 5.2 Evaluation des étiqueteurs sémantiques pour une tâche de traduction automatique Afin de pouvoir évaluer notre proposition d’utiliser une approche CRF-SLU pour la traduction nous utilisons la partie traduite manuellement (du français vers l’italien) du c</context>
<context position="25624" citStr="TALN-RÉCITAL 2013" startWordPosition="3868" endWordPosition="3869">a complexité algorithmique de l’approche CRF-SLU ne permet pas d’utiliser un tel modèle de langage sur les étiquettes. Afin d’évaluer les approches CRF-SLU et LLPB-SMT dans les mêmes conditions, et vu qu’on ne peut pas augmenter la taille des fonctions caractéristiques du modèle CRF, nous proposons de dégrader l’approche LLPB-SMT et de réévaluer sa performance en utilisant un modèle de langage de type bi-grammes. Par ailleurs, en observant les sorties du modèle CRF-SLU, nous remarquons que les mots 2. Se référer à (Jabaian et al., 2011) pour plus de détails sur le modèle LLPB-SMT. 97 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne CRF-SLU LLPB-SMT référence 42,5 47,2 décodage monotone 42,5 46,3 bi-grammes 42,5 46,0 traitement de mots HV 43,5 46,0 TABLE 2: Comparaison entre les modèles LLPB-SMT et CRF-SLU pour la traduction de l’italien vers le français (BLEU %). inconnus (hors-vocabulaire) dans le test ont été traduits par d’autres mots du corpus cible selon le contexte général de la phrase, contrairement à l’approche LLPB-SMT qui a tendance à projeter les mots hors-vocabulaire tels qu’ils sont dans la phrase traduite. Ces mots, étant dans la plupart des cas des noms de ville ou de lieu</context>
<context position="28606" citStr="TALN-RÉCITAL 2013" startWordPosition="4339" endWordPosition="4340">de probabilité obtenus par ce modèle sur les différents chemins du graphe (comme cela a été proposé dans (Lavergne et al., 2011)). Dans n-code le modèle de réordonnancement, proposé par (Crego et Mariño, 2006), est fondé sur une approche à base de règles apprises automatiquement sur les données d’entrainement. Cette approche nécessite un étiquetage grammatical des phrases source et un alignement au niveau des mots entre les phrases source et les phrases cible pour apprendre le modèle λR. Nous avons utiliser les outils TreeTagger (Schmid, 1994) pour obtenir l’étiquetage grammatical 98 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Modèle Langue BLEU LLPB-SMT 47,2 CRF-SLU IT –&gt; FR 43,5 CRFPB-SMT 44,1 TABLE 3: Comparaison entre les différentes approches (LLPB-SMT, CRF-SLU, CRFPB-SMT) pour la traduction de l’italien vers le français. et GIZA++ pour l’alignement en mots. Le modèle de langage utilisé dans nos expériences est un modèle tri-grammes appris sur la partie cible de notre corpus d’apprentissage à l’aide de l’outil SRILM (Stolcke, 2002). Le tableau 3 présente une comparaison entre trois modèles : le modèle CRFPB-SMT, le modèle LLPB-SMT (de référence) et le modèle CRF-SLU de base (pr</context>
<context position="31455" citStr="TALN-RÉCITAL 2013" startWordPosition="4774" endWordPosition="4775"> performance de cette approche de 2,2% absolu (15,3% vs 13,1%) permettant de retrouver quasiment les mêmes performances qu’avec CRF-SLU (13,1% vs 12.9%). Une comparaison entre les performances des différentes versions est donnée dans le tableau 4. Par la suite, CRFPB-SMT simplifié est utilisé pour toutes les expériences de compréhension. 5.4 Décodage conjoint dans un scénario de compréhension multilingue Un décodage conjoint pour la traduction et la compréhension a été appliqué comme nous l’avons proposé dans la section 4. Ce décodage consiste à transmettre le graphe de traduction 99 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Modèle Sub Del Ins CER CRF-SLU 3,1 8,1 1,8 12,9 CRFPB-SMT (complet) (λS ◦λR ◦λT ◦λF ◦λL ) 4,2 8,8 2,3 15,3 CRFPB-SMT (simplifié) (λS ◦λT ◦λF) 3,5 7,6 2,0 13,1 TABLE 4: Evaluation des approches basées sur les CRF pour la compréhension du français. en entrée du module de compréhension (incluant les scores pondérés relatifs à la traduction) et ensuite récupérer en sortie un graphe de compréhension qui intègre les scores de traduction et de compréhension. Ce décodage permettra d’étiqueter des phrases en italien en combinant un système de traduction italien vers fr</context>
</contexts>
<marker>TALN-RÉCITAL, 2013</marker>
<rawString>102 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne JABAIAN, B., BESACIER, L. et LEFÈVRE, F. (2011). Comparaison et combinaison d’approches pour la portabilité vers une nouvelle langue d’un système de compréhension de l’oral. In TALN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P KOEHN</author>
<author>H HOANG</author>
<author>A BIRCH</author>
<author>C CALLISON-BURCH</author>
<author>M FEDERICO</author>
<author>N BERTOLDI</author>
<author>B COWAN</author>
<author>W SHEN</author>
<author>C MORAN</author>
<author>R ZENS</author>
</authors>
<title>Moses : Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<marker>KOEHN, HOANG, BIRCH, CALLISON-BURCH, FEDERICO, BERTOLDI, COWAN, SHEN, MORAN, ZENS, 2007</marker>
<rawString>KOEHN, P., HOANG, H., BIRCH, A., CALLISON-BURCH, C., FEDERICO, M., BERTOLDI, N., COWAN, B., SHEN, W., MORAN, C., ZENS, R. et al. (2007). Moses : Open source toolkit for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P KOEHN</author>
<author>F et MARCU OCH</author>
<author>D</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In HLT-NAACL.</booktitle>
<marker>KOEHN, OCH, D, 2003</marker>
<rawString>KOEHN, P., OCH, F. et MARCU, D. (2003). Statistical phrase-based translation. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S et BYRNE KUMAR</author>
<author>W</author>
</authors>
<title>A weighted finite state transducer implementation of the alignment template model for statistical machine translation.</title>
<date>2003</date>
<booktitle>In HLT-NAACL.</booktitle>
<marker>KUMAR, W, 2003</marker>
<rawString>KUMAR, S. et BYRNE, W. (2003). A weighted finite state transducer implementation of the alignment template model for statistical machine translation. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J LAFFERTY</author>
<author>A et PEREIRA MCCALLUM</author>
<author>F</author>
</authors>
<title>Conditional random fields : Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In ICML.</booktitle>
<marker>LAFFERTY, MCCALLUM, F, 2001</marker>
<rawString>LAFFERTY, J., MCCALLUM, A. et PEREIRA, F. (2001). Conditional random fields : Probabilistic models for segmenting and labeling sequence data. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T LAVERGNE</author>
<author>O et YVON CAPPÉ</author>
<author>F</author>
</authors>
<title>Practical very large scale CRFs.</title>
<date>2010</date>
<booktitle>In ACL.</booktitle>
<marker>LAVERGNE, CAPPÉ, F, 2010</marker>
<rawString>LAVERGNE, T., CAPPÉ, O. et YVON, F. (2010). Practical very large scale CRFs. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T LAVERGNE</author>
<author>J M CREGO</author>
<author>A et YVON ALLAUZEN</author>
<author>F</author>
</authors>
<title>From n-gram-based to crf-based translation models.</title>
<date>2011</date>
<booktitle>In WSMT.</booktitle>
<marker>LAVERGNE, CREGO, ALLAUZEN, F, 2011</marker>
<rawString>LAVERGNE, T., CREGO, J. M., ALLAUZEN, A. et YVON, F. (2011). From n-gram-based to crf-based translation models. In WSMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P LIANG</author>
<author>B et KLEIN TASKAR</author>
<author>D</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In HLT-NAACL.</booktitle>
<marker>LIANG, TASKAR, D, 2006</marker>
<rawString>LIANG, P., TASKAR, B. et KLEIN, D. (2006). Alignment by agreement. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K MACHEREY</author>
<author>O et NEY BENDER</author>
<author>H</author>
</authors>
<title>Application of statistical machine translation approaches to spoken language understanding.</title>
<date>2009</date>
<booktitle>In IEEE ICASSP.</booktitle>
<marker>MACHEREY, BENDER, H, 2009</marker>
<rawString>MACHEREY, K., BENDER, O. et NEY, H. (2009). Application of statistical machine translation approaches to spoken language understanding. In IEEE ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K MACHEREY</author>
<author>F J et NEY OCH</author>
<author>H</author>
</authors>
<title>Natural language understanding using statistical machine translation.</title>
<date>2001</date>
<booktitle>In INTERSPEECH.</booktitle>
<marker>MACHEREY, OCH, H, 2001</marker>
<rawString>MACHEREY, K., OCH, F. J. et NEY, H. (2001). Natural language understanding using statistical machine translation. In INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B MARIÑO</author>
<author>R E BANCHS</author>
<author>J M CREGO</author>
<author>A de GISPERT</author>
<author>P LAMBERT</author>
<author>J A R et COSTA-JUSSÀ FONOLLOSA</author>
<author>M R</author>
</authors>
<title>N-gram-based machine translation.</title>
<date>2006</date>
<journal>Computational Linguistic,</journal>
<volume>32</volume>
<issue>4</issue>
<marker>MARIÑO, BANCHS, CREGO, de GISPERT, LAMBERT, FONOLLOSA, R, 2006</marker>
<rawString>MARIÑO, J. B., BANCHS, R. E., CREGO, J. M., de GISPERT, A., LAMBERT, P., FONOLLOSA, J. A. R. et COSTA-JUSSÀ, M. R. (2006). N-gram-based machine translation. Computational Linguistic, 32(4):527–549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F OCH</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In ACL.</booktitle>
<marker>OCH, 2003</marker>
<rawString>OCH, F. (2003). Minimum error rate training in statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J et NEY OCH</author>
<author>H</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<marker>OCH, H, 2002</marker>
<rawString>OCH, F. J. et NEY, H. (2002). Discriminative training and maximum entropy models for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K PAPINENI</author>
<author>S ROUKOS</author>
<author>T et ZHU WARD</author>
<author>W</author>
</authors>
<title>Bleu : a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<marker>PAPINENI, ROUKOS, WARD, W, 2002</marker>
<rawString>PAPINENI, K., ROUKOS, S., WARD, T. et ZHU, W. (2002). Bleu : a method for automatic evaluation of machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T RAMA</author>
<author>A et KOLACHINA SINGH</author>
<author>S</author>
</authors>
<title>Modeling letter-to-phoneme conversion as a phrase based statistical machine translation problem with minimum error rate training.</title>
<date>2009</date>
<booktitle>In HLT-NAACL.</booktitle>
<marker>RAMA, SINGH, S, 2009</marker>
<rawString>RAMA, T., SINGH, A. et KOLACHINA, S. (2009). Modeling letter-to-phoneme conversion as a phrase based statistical machine translation problem with minimum error rate training. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L et MARCUS RAMSHAW</author>
<author>M</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>In The Workshop on Very Large Corpora.</booktitle>
<marker>RAMSHAW, M, 1995</marker>
<rawString>RAMSHAW, L. et MARCUS, M. (1995). Text chunking using transformation-based learning. In The Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M et BRAUN RIEDMILLER</author>
<author>H</author>
</authors>
<title>A direct adaptive method for faster backpropagation learning : The RPROP algorithm.</title>
<date>1993</date>
<booktitle>In ICNN.</booktitle>
<marker>RIEDMILLER, H, 1993</marker>
<rawString>RIEDMILLER, M. et BRAUN, H. (1993). A direct adaptive method for faster backpropagation learning : The RPROP algorithm. In ICNN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H SCHMID</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In NMLP.</booktitle>
<marker>SCHMID, 1994</marker>
<rawString>SCHMID, H. (1994). Probabilistic part-of-speech tagging using decision trees. In NMLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C SERVAN</author>
<author>C RAYMOND</author>
<author>F et NOCERA B</author>
<author>P</author>
</authors>
<title>Conceptual decoding from word lattices : application to the spoken dialogue corpus MEDIA.</title>
<date>2006</date>
<booktitle>In INTERSPEECH.</booktitle>
<marker>SERVAN, RAYMOND, B, P, 2006</marker>
<rawString>SERVAN, C., RAYMOND, C., B., F. et NOCERA, P. (2006). Conceptual decoding from word lattices : application to the spoken dialogue corpus MEDIA. In INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A STOLCKE</author>
</authors>
<title>Srilm-an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In ICASSP.</booktitle>
<marker>STOLCKE, 2002</marker>
<rawString>STOLCKE, A. (2002). Srilm-an extensible language modeling toolkit. In ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G TÜR</author>
<author>J H WRIGHT</author>
<author>A L GORIN</author>
<author>G et HAKKANI-TÜR RICCARDI</author>
<author>D Z</author>
</authors>
<title>Improving spoken language understanding using word confusion networks.</title>
<date>2002</date>
<booktitle>In INTERSPEECH.</booktitle>
<marker>TÜR, WRIGHT, GORIN, RICCARDI, Z, 2002</marker>
<rawString>TÜR, G., WRIGHT, J. H., GORIN, A. L., RICCARDI, G. et HAKKANI-TÜR, D. Z. (2002). Improving spoken language understanding using word confusion networks. In INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P TURIAN</author>
<author>B et MELAMED WELLINGTON</author>
<author>I D</author>
</authors>
<title>Scalable discriminative learning for natural language parsing and translation.</title>
<date>2006</date>
<booktitle>In NIPS. 103 c ATALA</booktitle>
<marker>TURIAN, WELLINGTON, D, 2006</marker>
<rawString>TURIAN, J. P., WELLINGTON, B. et MELAMED, I. D. (2006). Scalable discriminative learning for natural language parsing and translation. In NIPS. 103 c ATALA</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>