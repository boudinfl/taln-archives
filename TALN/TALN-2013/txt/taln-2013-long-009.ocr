TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Apprentissage d’une hiérarchie de modéles a paires
spécialisés pour la résolution de la coréférence

Emmanuel Lassallel Pascal Denis2
(1) Alpage : INRIA - Université Paris Diderot, Sorbonne Paris Cité
(2) Magnet : INRIA Nord Lille Europe - Université de Lille LIFL
emmanuel . lassalle@ens—lyon . org, pascal . denis@inria . fr

RESUME
Nous proposons une nouvelle méthode pour améliorer signiﬁcativement la performance des
modéles a paires de mentions pour la résolution de la coréférence. Etant donné un ensemble
d’indicateurs, notre méthode apprend a séparer au mieux des types de paires de mentions en
classes d’équivalence, chacune de celles—ci donnant lieu a un modéle de classiﬁcation spéciﬁque.
La procédure algorithmique proposée trouve le meilleur espace de traits (créé a partir de
combinaisons de traits élémentaires et d’indicateurs) pour discriminer les paires de mentions
coréférentielles. Bien que notre approche explore un trés vaste ensemble d’espaces de trait,
elle reste efﬁcace en exploitant la structure des hiérarchies construites a partir des indicateurs.
Nos expériences sur les données anglaises de la CoNLL—2012 Shared Task indiquent que notre
méthode donne des gains de performance par rapport au modéle initial utilisant seulement
les traits élémentaires, et ce, quelque soit la méthode de formation des chaines ou la métrique
d’évaluation choisie. Notre meilleur systeme obtient une moyenne de 67.2 en F1-mesure MUC, B3
et CEAF ce qui, malgré sa simplicité, le situe parmi les meilleurs systémes testés sur ces données.

ABSTRACT
Learning a hierarchy of specialized pairwise models for coreference resolution

This paper proposes a new method for signiﬁcantly improving the performance of pairwise
coreference models. Given a set of indicators, our method learns how to best separate types of
mention pairs into equivalence classes for which we construct distinct classiﬁcation models. In
effect, our approach ﬁnds the best feature space (derived from a base feature set and indicator set)
for discriminating coreferential mention pairs. Although our approach explores a very large space
of possible features spaces, it remains tractable by exploiting the structure of the hierarchies built
from the indicators. Our experiments on the CoNLL-2012 shared task English datasets indicate
that our method is robust to different clustering strategies and evaluation metrics, showing large
and consistent improvements over a single pairwise model using the same base features. Our
best system obtains 67.2 of average F1 over MUC, B3, and CEAF which, despite its simplicity,
places it among the best performing systems on these datasets.

MOTS-CLES : résolution de la coréférence, apprentissage automatique.

KEYWORDS: coreference resolution, machine learning.

118 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
1 Introduction

La résolution de la coréférence consiste a partitionner une séquence de syntagmes nominaux (ou
mentions) apparaissant dans un texte en un ensemble d’entités qui partagent chacune le méme
référent. Une approche désormais classique pour résoudre cette tache consiste a la diviser en deux
étapes : d’abord, on définit un modéle pour traiter les relations de coréférence indépendamment
les unes des autres, en général via un classiﬁeur binaire détectant les mentions coréférentielles.
Ensuite, les liens détectés sont regroupés en clusters par un décodeur pour former une sortie
cohérente. Typiquement, cette étape est réalisée par des méthodes heuristiques gloutonnes
(McCarthy et Lehnert, 1995; Soon et al., 2001; Ng et Cardie, 2002; Bengston et Roth, 2008), bien
qu’il existe des approches plus sophistiquées telles que les méthodes de graph cutting (Nicolae et
Nicolae, 2006; Cai et Strube, 2010) ou l’ILP (Integer Linear Programming) (Klenner, 2007; Denis
et Baldridge, 2009). Malgré sa simplicité apparente, cette approche en deux étapes demeure
compétitive méme lorsqu’on la compare a des modéles plus complexes utilisant des mesures de
perte globale (Bengston et Roth, 2008).

Avec ce type d’architecture, la performance du systéme complet dépend fortement de la qualité
du classiﬁeur local de paires. 1 Par conséquent, beaucoup de travaux de recherche ont consisté
a essayer d’améliorer la performance de ce classiﬁeur. Nombre d’entre eux se concentrent
sur l’extraction de traits, typiquement en essayant d’enrichir le classiﬁeur avec davantage de
connaissances linguistiques et/ou de connaissances du monde (Ng et Cardie, 2002; Kehler et al.,
2004; Ponzetto et Strube, 2006; Bengston et Roth, 2008; Versley et al., 2008; Uryupina et al.,
2011). D’autres travaux cherchent a utiliser des modeles locaux distincts pour différents types de
mentions, en particulier pour différents types de mentions anaphoriques en se basant sur leur
catégories grammaticales (telles que pronoms, noms propres, descriptions définies). On entraine
par exemple un modele pour les pronoms, un autre pour les SN déﬁnis, etc (Morton, 2000; Ng,
2005; Denis et Baldridge, 2008) 2. L’utilisation de modeles spécialisés trouve une justiﬁcation
importante en psycho-linguistique, dans des travaux théoriques sur la saillance ou l’accessibi1ité
(Ariel, 1988). Du point de vue de 1’apprentissage statistique, ces seconds travaux se rapprochent
de ceux sur l’extraction de traits dans la mesure on les deux approches reviennent a poser le
probléme de la classiﬁcation de paires dans un espace de plus grande dimension.

Dans ce travail, nous soutenons que les paires de mentions ne devraient pas étre traitées
par un seul classiﬁeur, mais au contraire par des modeles spéciﬁques. En somme, nous nous
intéressons a apprendre comment construire et sélectionner de tel modéles. Notre argumentation
se fonde sur des considérations statistiques plut6t que purement linguistiques (l’approche est
donc complémentaire aux études théoriques). La question que nous posons est, étant donné
un ensemble d’indicateurs (tels que les types grammaticaux, la distance entre deux mentions
ou le type d’entité nommée), comment séparer les paires de mentions aﬁn de discriminer au
mieux les paires coréférentielles par rapport a celles qui ne le sont pas. Ainsi, nous cherchons a
apprendre les “meilleurs” espaces de représentation pour nos différents modeles : c’est—a—dire des
espaces ni trop grossiers (c.-a-d. peu aptes a bien séparer les données), ni trop spéciﬁques (c.-a-d.
pouvant souffrir du manque de données ou de bruit). Nous verrons que cette démarche est aussi
équivalente a construire un seul trés grand espace de traits pour représenter toutes les données.

1. Il n’y a toutefois aucune garantie théorique pour que l’amélioration de la classiﬁcation locale ait toujours un impact
positif sur la performance globale lorsque les deux modules sont optimisés séparément.

2. Parfois, des échantillonnages différents sont choisis lors de la phase d’apprentissage des modéles locaux distincts
(Ng et Cardie, 2002; Uryupina, 2004).

119 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Notre approche généralise les approches précédentes de plusieurs manieres. D’une part, la
déﬁnition des différents modeles n’est plus restreinte au simple typage grammatical (notre modele
permet d’utiliser n’importe quel type d’indicateurs) ni au seul typage de la mention anaphorique
(nos modeles peuvent aussi étre associés au typage de l’antécédent ou bien au types des deux
éléments de la paire). D’autre part, nous proposons une méthode originale pour apprendre les
meilleurs ensembles de modeles que l’on peut construire a partir d’un ensemble d’indicateurs
donnés et des données d’apprentissage. Ces modeles sont organisés dans une hiérarchie o1‘1
chaque feuille correspond a un ensemble de paires de mentions disjoint des autres et sur lequel
un classiﬁeur est entrainé. Nos différents modeles sont entrainés en utilisant 1’a1gorithme Online
Passive-Aggressive, ou PA (Crammer et al., 2006), qui est une version a large marge du perceptron.
Notre méthode peut étre qualiﬁée d’exacte dans le sens ou elle explore completement l’espace des
hiérarchies déﬁnissables a partir d’un ensemble d’indicateurs donné (on en dénombre au moins
22" pour n indicateurs), tout en maitrisant la complexité algorithmique par une technique de
programmation dynamique qui exploite la structure particuliere des hiérarchies. Cette approche
obtient de tres bonnes performances, et dépasse largement le modele de départ qui utilise
seulement les traits élémentaires. Comme le montreront diverses expériences sur les données
anglaises de la CoNLL—2012 Shared Task, des améliorations importantes sont observables sur
différentes métriques d’évaluation; par ailleurs, celles—ci ne dépendent pas de la méthode de
clustering choisie pour le décodeur.

La suite de cet article est organisée comme suit : dans la section 2, nous discutons les hypotheses
statistiques sur lesquelles repose le modele standard a paires de mentions, et nous déﬁnissons un
modele alternatif qui utilise une simple séparation des paires de mentions en fonction de leur
type grammatical. Ensuite, dans la section 3, nous généralisons ce modele en introduisant les
hiérarchies d’indicateurs en expliquant comment apprendre le meilleur modele possible a partir
de celles—ci. La section 4 donne une breve description du systeme complet et la section 5 donne
les résultats d’évaluation des différents modeles sur les données anglaises de CoNLL—2012.

2 Modélisation des paires

En principe, les modeles a paires emploient un seul classiﬁeur local pour décider si deux mentions
sont coréférentes ou non. Lorsque l’on utilise des techniques d’apprentissage automatique, cela
entraine quelques hypotheses sur le comportement statistique des paires de mentions.

2. 1 Hypotheses statistiques

Pour commencer, adoptons un point de Vue probabiliste pour décrire le prototype du modele a
paires. Etant donné un document, le nombre de mentions est ﬁxé et chaque paire de mentions
suit une certaine distribution (que l’on observe en partie en projetant les paires dans un espace de
traits). L’idée fondamentale du modele a paires est de considérer que les paires de mentions sont
indépendantes les unes des autres (du coup, la propriété de transitivité n’est pas nécessairement
vériﬁée en sortie, c’est pourquoi il faut un décodeur la transformer en partition cohérente).

Utiliser un seul classiﬁeur pour traiter toutes les paires de mentions revient a supposer qu’e1les
sont identiquement distribuées. Nous pensons que les paires ne sont pas identiquement dis-

120 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

tribuées, mais qu’il faut au contraire séparer différents “types” de paires et créer des modeles
spéciﬁques pour ces types.

Séparer différents types de paires et les traiter avec des modeles spéciﬁques peut amener a
des modeles globaux plus précis. Certains systémes de résolution traitent déja différents types
d’anaphores séparément, ce qui revient a supposer que par exemple, les paires qui contiennent
un pronom se comportent différemment des autres (Morton, 2000; Ng, 2005; Denis et Baldridge,
2008). Nous pourrions essayer de capturer ces différents comportements avec un ensemble
trés riche de traits, mais en réalité nous ne disposons que d’un nombre assez restreint de traits
élémentaires (Voir la section 4) et créer de nouveaux traits en les combinant doit étre fait avec
prudence pour éviter d’introduire du bruit dans le modele. Au lieu de cela, nous montrerons
qu’une séparation habile des instances apporte de bonnes améliorations au modéle a paires.

2.2 Espaces de traits
2.2.1 Définitions

Commencons par donner une vision plus formelle de la modélisation. Chaque paire de mentions
mi et mi est représentée par une variable aléatoire :

0-’ '—’ (xij(°-’):.}'ij(°-’))

ou Q dénote classiquement l’aléatoire, 3!," est l’espace des objets "paires de mentions" qui n’est
pas directement observable et y,-j(a.>) E ‘III = {+1, -1} sont les étiquettes indiquant si mi et mj
sont coréférentes ou non. Pour alléger un peu ces notations, nous n’écrirons pas toujours l’indice
i j. Maintenant nous déﬁnissons une fonction :

¢g:.9l7 —> e?

X H ¢.9r(X)

qui projette les paires dans un espace de traits 9' a travers lequel elles sont observées. Pour nous,
.9’ est simplement un espace vectoriel sur JR (dans notre cas, la plupart des traits sont booléens;
ils sont projetés sur JR avec les valeurs 0 et 1). Pour des raisons de cohérence technique, nous
supposons que (1531 (x(a.>)) et <15 g~2(X(Cl))) conservent les mémes valeurs lorsqu’on les projette sur
l’espace de traits 9'1 n 9'2 : cela signiﬁe simplement que les traits communs a deux espaces ont
toujours les mémes valeurs.

De ce point de vue formel, la tache de résolution de la coréférence consiste a ﬁxer un es-
pace de traits 9', observer des échantillons étiquetés {(¢g~(X), y)t}teT,a,-"Set et, étant donné de
nouvelles variables partiellement observées {(¢§~ (x))t}tETestSet, tenter de retrouver la valeur
correspondante de y.

2.2.2 Un autre point de vue sur les hypothéses statistiques

Nous avons écrit plus haut que les paires de mentions n’apparaissent pas identiquement distri-
buées puisque, par exemple, les pronoms ne se comportent pas de la méme facon que les noms.

121 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Nous pouvons maintenant formuler cela de facon plus rigoureuse : puisque nous ne pouvons
pas observer directement l’espace des objets 3%,”, nous en ignorons la complexité. En particulier,
lorsque nous utilisons une projection vers un espace de traits trop petit, le classiﬁeur ne parvient
pas a capturer la distribution correctement : les données semblent trop bruitées.

Maintenant en remarquant que les anaphores pronominales ne se comportent pas de la méme
maniere que les autres anaphores, nous distinguons deux types de paires, c’est—a—dire que nous
voyons la distribution des paires dans 3!," comme un mélange de deux distributions. De ce fait,
nous pourrons peut-étre séparer les paires positives et négatives plus facilement si nous projetons
chaque type de paires dans un espace de traits spéciﬁque. Appelons ces espaces de traits $1
et $2. Nous pouvons ou bien déﬁnir deux classiﬁeurs indépendants sur $1 et $2 pour traiter
chaque type de paires ou déﬁnir un seul modéle sur un espace plus grand $ = $1 63 $2. Si le
modéle est linéaire, et ca sera notre cas, il se trouve que cela est équivalent.

En conséquence, nous pouvons de fait supposer que les variables P1 1. sont identiquement distri-
buées. Et le nouveau probleme a résoudre est de trouver une projection (1531 qui représente au
mieux la distribution des données (qui les rend facilement séparables).

D’un point de vue théorique, plus la dimension de l’espace des traits est grande (par exemple
la somme directe de tous les espaces de traits dont nous disposons), plus nous avons de détails
sur la distribution des paires de mentions et plus nous pouvons espérer séparer les positifs des
négatifs avec précision. En pratique, nous sommes confrontés au probléme de rareté des données :
il n’y a pas assez de données pour entrainer correctement un modele linéaire sur un tel espace.
Au ﬁnal, nous cherchons un espace de traits qui se situe entre les deux extrémes que constituent
un espace trop grand (données rares) ou trop petit (données bruitées). L’objectif principal de ce
travail est de déﬁnir une méthode générale pour choisir l’espace $ le plus adéquat parmi un trés
grand nombre de possibilités et lorsque nous ne savons pas a priori lequel peut étre le meilleur.

2.2.3 Modéles linéaires et espaces indépendants

Dans ce travail, nous essayons de séparer linéairement les instances positives des négatives dans
$ : le modéle apprend un vecteur parametre w qui déﬁnit un hyperplan coupant l’espace en
deux parties. La classe prédite pour la paire x avec vecteur de traits <15 31 (x) est donnée par :

Cg(x) == 5ign(WT - ¢gv(x))

La propriété de linéarité rend équivalentes les séparations des instances de deux types t1 et t2,
dans deux modéles indépendants avec pour espace de traits respectif $1 et $2 et pour paramétres
W1 et W2, et un modéle simple sur $1 63 $2. Pour voir pourquoi, déﬁnissons la projection :

¢ (X): (qSg1(x)T 0  sixestde type t1
g1$g2 ( 0 ¢g~2(X)T ) sixest de type t2

1
1 w
et le vecteur parametre w = ( W2 ) 6 $1 63 $2. Nous avons alors :

C971 (x) si x est de type t1
Cg~2(X) si x est de type t2
122 © ATALA

C3?1e.9?2(x) = {

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

I1 faut maintenant s’assurer que cette propriété est vériﬁée lors de 1’apprentissage du paramétre
w. Dans ce travail nous avons utilisé 1’a1gorithme en ligne Passive—Aggressive pour la classiﬁcation
binaire (Crammer et al., 2006). Ce modele est une extension du perceptron, dont l’obectif a
chaque itération est, d’une part de minimiser les changements apportés au modele existant
(d’o1‘1 la caractéristique “passive”) et, d’autre part, de faire en sorte que 1’exemp1e courant
soit correctement classiﬁé avec une large marge (d’o1‘1 la caractéristique “aggressive”). Plus
précisément, la mise a jour du vecteur de poids a chaque itération prend la forme suivante :

W:+1= argmm;||w~w1||2 tq zcw; (xtsytn = o
wE$

ou l(w; (x,,_yt)) = min(0, 1 — _yt(w - ¢g~(Xt))), de sorte que lorsque $ = $1 63 $2, le minimum

. ‘N1. 1 . . ‘N1. \ 1'
s1 x est de type t1 est w,+1 = W§ et s1 x est de type t2 1s w,+1 = W2 ou wt +1
I t+1
correspond aux mises a jour dans l’espace $,- indépendamment du reste. Ce résultat peut étre

facilement étendu au cas de n espaces de traits. Par conséquent, avec une séparation déterministe
des données, un modele sur un grand espace peut étre appris en le décomposant en modeles
indépendants sur des espaces plus petits.

2.3 Un exemple : la séparation par gramtype

Pour motiver notre approche, nous commencons par introduire une séparation relativement
simple des paires de mentions qui s’appuie sur les 9 modeles obtenus en considérant toutes
les combinaisons possibles des types grammaticaux {nominal, name, pronoun} pour les deux
mentions de la paire (une séparation ﬁne similaire peut étre trouvée dans (Chen et al., 2011)).

Cela revient a utiliser 9 espaces de traits différents $1, . . .,$9 pour capturer la distribution
globale des paires. Avec des classiﬁeur linéaires, nous obtenons un seul modéle sur l’espace de
traits $ = $1 63 - - - 63 $9. Nous appellerons cela le modéle gramtype.

Comme nous le verrons dans la section 5, ces modéles séparés obtiennent des performances qui
dépassent signiﬁcativement celles d’un unique modéle qui utilise les mémes traits élémentaires.
Mais nous voudrions déﬁnir une méthode qui adapte l’espace de traits aux données en choisissant
e1le—méme la séparation des paires la plus appropriée.

3 Hiérarchisation des espaces de traits

Dans cette section, nous présentons notre méthode pour trouver automatiquement une séparation
optimale des paires de mentions. On gardera a l’esprit que séparer les paires dans différents
modéles est la méme chose que construire un grand espace de traits dans lequel le paramétre w
peut étre appris par parties dans des sous—espaces indépendants.

3.1 Indicateurs sur les paires

Pour déﬁnir des espaces de traits supplémentaires, nous utilisons des indicateurs, qui sont des
fonctions déterministes sur les paires de mentions avec un nombre restreint de valeurs possibles.

123 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Les indicateurs sont uﬁlisés pour classer les paires dans des catégories prédéﬁnies et en bijecﬁon
avec un ensemble d’espaces de traits élémentaires indépendants. Nous pouvons réutiliser les
traits du systeme comme indicateurs, par exemple, le type grammatical ou celui des entités
nommées. Nous pouvons également uﬁliser des foncﬁons qui ne sont pas des traits, par exemple
la position approximaﬁve d’une des deux mentions dans le texte.

Le petit nombre de valeurs possibles pour un indicateur est requis pour des raisons pratiques : si
une catégories de paires est trop ﬁne, 1’espace de traits associé souffrira de la rareté des données.
Les indicateurs utilisant des distances doivent donc les approximer par des histogrammes assez
grossiers. Dans nos expériences, le nombre de valeurs possibles ne dépassera jamais une douzaine
(ce qui sera amplement sufﬁsant pour générer assez de combinatoire). Une facon de réduire la
taille de l’ensemble des valeurs d’un indicateur est de le binariser, de la meme facon que l’on
binarise un arbre (il y a plusieurs binarisations possibles). Cette opération produit une hiérarchie
d’indicateurs imbriqués, qui est exactement la structure que nous exploitons dans la suite.

3.2 Des hiérarchies pour séparer les paires

Nous déﬁnissons les hiérarchies comme des combinaisons d’indicateurs créant des catégories
de plus en plus ﬁnes de paires de mentions : étant donnée une suite d’indicateurs, une paire
de mentions est classée en appliquant les indicateurs successivement, chaque fois en rafﬁnant
une catégorie en sous-catégories, de la méme maniere que dans un arbre de décision (chaque
noeud ayant le meme nombre d’enfants que le nombre de valeurs prises par son indicateur).
Nous autorisons la classiﬁcation a s’arréter avant d’appliquer le dernier indicateur, mais le
comportement doit étre le méme pour toutes les instances. Ainsi une hiérarchie est en principe
un sous-arbre de l’arbre de décision complet qui contient des copies d’un meme indicateur a
chaque niveau.

Si toutes les feuilles de l’arbre de décision ont la méme profondeur, cela correspond 2 prendre le
produit cartésien des valeurs de tous les indicateurs pour indexer les catégories. Dans ce cas, nous
parlerons de hiérarchies-produit. Le modéle gramtype peut étre vu comme une hiérarchie—produit
a deux niveaux (ﬁgure 1).

 
   
      
 
    

gramtype

droite
nom

   
    
 
       

 
 

ronom
53 mm propre
gramtype CUWWUH gramtype
gauche gauche
gramtype
gauche
pronom hum ntnm pronom “Gm num
V prop” commun pmpre

commur.
pront:-m mm “OW
ct:-mr-"nun pmpre

FIGURE 1 — Le modele gramtype vu comme une hiérarchie—produit.

Les hiérarchies-produit seront le point de départ de notre méthode pour trouver un espace de
124 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

traits qui représente bien les données. Maintenant, pour choisir une suite d’indicateurs appropriés,
il faut faire appel aux intuitions linguistiques et aux travaux théoriques sur le sujet. Le systéme
trouvera lui-méme la meilleure facon d’utiliser ces indicateurs 1orsqu’i1 optimisera la hiérarchie.
La suite d’indicateurs est donc un paramétre du modéle.

3.3 Lien entre les hiérarchies et les espaces de traits

Comme nous l’avons fait pour le modéle gramtype, nous associons un espace de traits .9’, a
chacune des feuilles de la hiérarchie. De la méme maniére, la somme 9' = EB, 91 déﬁnit un
grand espace de traits, et le paramétre correspondant w d’un modéle linéaire peut étre appris en
apprenant les Wi dans les 9',-.

Etant donnée une séquence d’indicateurs, le nombre de hiérarchies différentes que nous pouvons
déﬁnir est égal au nombre de sous-arbres entiers (chaque noeud a tous ses enfants possibles
ou aucun) de l’arbre complet de décision (chaque noeud interne ayant tous ses enfants). Le cas
minimal est celui d’indicateurs booléens. Le nombre d’arbre binaires entiers de taille au plus n
peut étre calculé par la récurrence suivante : T(1) = 1 et T(n+ 1) = 1 + T(n)2. Donc T(n) Z 22" :
méme avec des petites Valeurs de n, le nombre de hiérarchies différentes (ou de grand espaces
de traits) déﬁnissables par une séquence d’indicateurs est gigantesque (p.ex. T(10) N 3.8.1090).

Parmi toutes les possibilités pour un grand espace de traits, beaucoup ne sont pas appropriés
parce qu’avec eux les données sont trop rares ou trop bruitées dans certains sous—espaces. Nous
avons besoin d’une méthode générale pour trouver le meilleur espace sans avoir a énumérer et
tester chacun d’eux.

3.4 Optimisation des hiérarchies

Considérons que la séquence d’indicateurs est ﬁxée, soit n sa longueur. Pour trouver le meilleur
espace de traits parmi un trés grand nombre de possibilités, nous avons besoin d’un critére de
sélection applicable sans trop de calculs supplémentaires. Pour cela, nous n’évaluons l’espace
de traits que localement sur les paires, c’est—a—dire sans appliquer un décodeur a la sortie. Nous
employons trois mesures sur les résultats de la classiﬁcation des paires : la précision, le rappel et
le F1—score. Sélectionner le meilleur espace pour une de ces mesures peut étre réalisé en utilisant
des techniques de programmation dynamique. Dans nos expériences, nous cherchons a optimiser
le F1—score.

Entrainement de la hiérarchie : Partant de la hiérarchie—produit, nous associons un classiﬁeur
et son propre espace de traits a chacun des noeuds de l’arbre 3. Les classiﬁeurs sont alors entrainés
comme suit : pour chaque instance, il existe un unique chemin de la racine vers une feuille de
l’arbre complet. Chaque classiﬁeur situé sur ce chemin est mis a jour avec cette instance. Le
nombre d’itérations pour le Passive—Aggressive est ﬁxé (nous n’avons pas cherché a optimiser ce
paramétre).

Calcul des scores : Apres la phase d’apprentissage, nous testons tous les classiﬁeurs sur un autre

3. Dans les expériences, les classiﬁeurs utilisent une copie d’un méme espace de traits, mais pas les mémes données,
ce qui correspond a croiser les traits avec les catégories de l’arbre de décision.

125 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

ensemble de paires de développement4. Une fois encore, un classiﬁeur est testé sur une instance
seulement s’il est situé sur le chemin de la racine vers une feuille associé a l’instance. Nous
obtenons des nombres TP/FP/FN5 sur les classiﬁcations des paires, qui sufﬁsent pour calculer
le F1—score. Comme pour l’apprentissage, les données sur lesquelles un classiﬁeur a un noeud
donné est évalué sont les mémes que la réunion de toutes les données utilisées pour évaluer les
classiﬁeurs correspondant aux enfant de ce noeud. C’est ainsi que nous sommes en mesure de
comparer les scores obtenus au niveau d’un noeud a la "réunion des scores" obtenus au niveau de
ses enfants.

Découpage de la hiérarchie : Pour le moment, nous avons un arbre complet avec un classiﬁeur
a chaque noeud. Nous utilisons une technique de programmation dynamique pour calculer la
meilleure hiérarchie en coupant cet arbre et en ne gardant que les classiﬁeurs situés au niveau
des feuilles. L’algorithme assemble les meilleurs modeles locaux (ou espaces de traits) pour créer
des modeles plus grands. 11 part des feuilles pour remonterjusqu’a la racine et coupe le sous—arbre
qui commence a un noeud a chaque fois qu’il ne fournit pas de meilleur score que le score du
noeud seul, ou au contraire il propage le score du sous—arbre lorsqu’i1 y a une amélioration. Les
détails sont donnés dans l’algorithme 1.

list <— list of nodes given by breadth—ﬁrst search for node in reversed list do
if node.children 75 0 then
if sum—score(node.children) > node.score then
node.TP/FP/FN <— sum—num (node.children)

1

2

3

4

5 else

6 node.children <— 0
7 end
8 end

9 end

ALGORITHME 1 — Découpage de la hiérarchie

Discutons brievement la validité et la complexité de l’algorithme. Chaque noeud n’est vu que deux
fois donc la complexité est linéaire en le nombre de noeuds qui est au moins 0'(2"). Toutefois,
seulement les noeuds qui ont rencontré au moins une instance d’apprentissage sont utiles et il y
en a 0‘(n x k) (ou k est la taille de l’ensemble d’apprentissage). Donc nous pouvons optimiser
l’algorithme pour tourner en temps 6’(n X k) (qui est également le temps d’entrainement de la
hiérarchie). En parcourant a l’envers la liste obtenue par le parcours en largeur de la hiérarchie,
nous sommes assurés que chaque noeud sera traité apres ses enfants donc que le modele optimal
sera construit de proche en proche jusqu’a la racine. (node.children) est l’ensemble des enfants de
node, et (node.score) est son score. sum—num fournit les TP/FP/FN en sommant simplement les
nombres correspondants des enfants et sum—score calcule le score basé sur ces nouveaux nombres
TP/FP/FN. La (ligne 6) coupe les enfants d’un noeud quand ils ne sont pas utilisés pour déﬁnir le
meilleur score. L’algorithme propage alors les meilleurs scores depuis les feuilles vers la racine,
ce qui donne au ﬁnal un seul score qui correspond a celui de la meilleure hiérarchie. Seulement
les feuilles utilisées pour calculer le meilleur score sont gardées et elles déﬁnissent la meilleure
hiérarchie.

Relation entre le découpage et l’espace de traits global : Nous pouvons voir l’opération de

4. Les données d’apprentissages sont coupées en deux parties, pour l’apprentissage et pour tester la hiérarchie.
5. “True positives“, “false positives“ et “false negatives“.

126 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

découpage comme le remplacement d’un groupe de sous—espaces par un seul sous—espace dans
la somme (voir ﬁgure 2). Découper la hiérarchie—produit revient done a réduire l’espace de
traits global (l’espace somme) de maniére optimale. Nous voyons ici le lien entre la meilleure
hiérarchie et l’espace de traits qui perrnet de séparer au mieux les paires.

13.1 I}, I5  I: an

\ ,
X‘ découpage de la ,'
~ hterarchte ,1

\ .

\ .

-Fn—1 fn -7'-n+1

FIGURE 2 — Découper la hiérarchie réduit l’espace de traits

4 Description du systeme

Notre systéme se compose du modéle a paires séparées obtenu en découpant la hiérarchie (c’est
donc un PA sur l’espace de traits somme) et un décodeur glouton pour créer des clusters a partir
de sa sortie. Il est paramétré par le choix de la séquence initiale d’indicateurs.

Les traits élémentaires Nous avons utilise’ un ensemble de traits classiques qui sont détaillés
dans (Bengston et Roth, 2008) et (Rahman et Ng, 2011). Nous ne listons ici que les groupes de
traits : types et sous—types grammaticaux des mentions, méme chaine/sous-chaine de caractéres,
apposition, copule, distance (en nombre de mentions /phrases/ mots), égalité en genre/nombre,
synonymie/hyperonymie et caractére animé (en utilisant WordNet), nom de famille (a partir de
liste), types d’entité nommée, traits syntaxiques (gold parse tree) et détection d’anaphoricité.

Indicateurs Comme indicateurs nous avons utilisé : types et sous—types grammaticaux pour les
mentions gauche (antécédent) et droite (anaphore) selon l’ordre du texte, types d’entités nom-
mées, un booléen indiquant si les mentions se trouvent dans la méme phrase et un histogramme
tres grossier de la distance en nombre de phrase. Nous avons systématiquement commencé les
séquences (de différentes longueurs) par les types grammaticaux droit et gauche, en ajoutant
ensuite d’autres indicateurs. Le paramétre a été optimisé par catégorie de document en utilisant
les données de développement, aprés avoir décodé la sortie du modéle a paires.

Décodeurs Nous avons testé trois stratégies gloutonnes classiques pour sélectionner les liens
et former les clusters a partir des décisions du classiﬁeur : Closest—First (fusionne les mentions
avec la mention coréférente a gauche la plus proche, si elle existe) (Soon et al., 2001), Best—ﬁrst
(fusionne les mentions avec la mention a gauche qui obtient le meilleur score positif) (Ng et
Cardie, 2002; Bengston et Roth, 2008), et Aggressive—Merge (fermeture transitive sur les paires
positives) (McCarthy et Lehnert, 1995). Chacun de ces décodeurs Va typiquement de paire
avec un échantillonnage particulier lors de l’apprentissage (méme si ce n’est pas obligatoire).

127 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Par exemple, Closest—First est combiné avec un échantillonnage o1‘1 sont utilisées seulement les
instances dans lesquelles la mention de gauche apparait entre le l’anaphore et l’antécédent le
plus proche (Soon et al., 2001).

5 Expériences

5. 1 Données

Nous avons évalué le systéme sur la partie anglaise du corpus fourni dans la CoNLL—2012 Shared
Task (Pradhan et al., 2012). Le corpus contient 7 catégories de documents (plus de 2k documents,
1.3M de mots). Nous avons utilisé les données d’entrainement/ déve1oppement/ test ofﬁcielles.

5.2 Paramétres

Les hiérarchies ont été entrainées par validation croisée (10—fold) sur les données d’entrainement
(découper les hiérarchies se fait aprés avoir cumulé les scores obtenus par la validation croisée) et
les paramétres ont été optimisés par catégorie de documents sur les données de développement :
la séquence d’indicateurs obtenant le meilleur score moyen (entre MUC, B3 et CEAF) apres
décodage a été sélectionné comme paramétre optimal pour la catégorie. Dans les résultats, nous
appellerons best hierarchy la hiérarchie obtenue. Nous avons ﬁxé le nombre d’itérations du
Passive—Aggressive pour tous les modéles.

Nos baselines sont le modele initial avec les traits élémentaires (single model) et le modele
gramtype (section 2) associés a chacun des décodeurs gloutons, et également les versions ou l’on
utilise ces décodeurs avec un échantillonnage particulier.

Dans nos expériences, nous ne prenons en compte que les mentions gold (pas de singletons ni
de non—référentie1s). Cela n’est pas tout a fait réaliste, mais notre but est de comparer les divers
modéles a paires locaux plutot que de mettre en place un systéme complet de résolution. De plus,
nous voulons éviter d’avoir a considérer trop de paramétres dans nos expériences.

5.3 Métriques d’évaluation

Nous utilisons les trois métriques les plus communes, a savoir :

— MUC (Vilain et al., 1995) calcule pour chaque vrai cluster-entité le nombre de clusters systéme
nécessaires pour le recouvrir. La précision est cette quantité divisée par la taille du vrai cluster
moins un. Le rappel est obtenu en inversant les clusters vrai et prédits. Le F1 est la moyenne
harmonique du rappel et de la précision.

— B3 (Bagga et Baldwin, 1998) calcule les scores de rappel et de précision pour chaque mention,
a partir de l’intersection entre le cluster systeme et le vrai cluster pour cette mention. La
précision est le rapport des tailles de l’intersection et du cluster systéme, alors que le rappel est
le rapport des tailles de l’intersection et du vrai cluster. Les rappel et précision globaux et le F1
sont obtenus en prenant la moyenne sur les scores des mentions.

128 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

— CEAF (Luo, 2005) : scores obtenus en calculant la meilleure bijection entre la vraie partition
et la partition systeme, ce qui est équivalent a trouver l’alignement optimal dans le graphe
bipartite formé par ces partitions. Nous utilisons la fonction de similarité (154 de (Luo, 2005).

Ces métriques ont été récemment utilisées dans les Shared Task CoNLL-201 1 et 2012. Par ailleurs,
ces campagnes utilisent une moyenne non pondérée sur les F1 scores donnés par ces trois
métriques. Comme cela est fait normalement, nous utilisons le mode micro—averaging (moyennes
sur le nombre de mention) lorsque nous donnons nos scores sur1’ensemble des données.

5.4 Résultats

Les résultats obtenus par le systéme sont repris dans les tableaux 1, 2 et 3. Les échantillonnages
originaux associés aux décodeurs Closest—First et Best—First sont désignés par Soon et NgCardie.
single model correspond a un modele simple entrainé sans échantillonnage spéciﬁque. Malgré
l’utilisation de décodeurs gloutons, nous pouvons observer sur la sortie un effet positif tres
signiﬁcatif sur la séparation des paires dans les modéles locaux. L’uti1isation de modéles distincts
plutot qu’un seul modele a un effet positif sur le score moyen, avec un incrément de 6.4 a 15.5
en fonction du décodeur. Il est intéressant de constater qu’indépendamment du décodeur utilisé,
le modéle gramtype surpasse toujours le single model, et est 1ui—méme dépassé par le modéle best
hierarchy. Nous avons observé des variations dans le paramétre optimal des hiérarchies, toutefois
un parametre fréquemment bien classé était : gramtype droite —> gramtype gauche —> méme
phrase —> type d’entité nommée droite.

MUC B‘ CEAF
P R F1 P R F1 P R F1 Mean
Soon 79.49 93.72 86.02 26.23 89.43 40.56 49.74 19.92 28.44 51.67

single model 78.95 75.15 77.0 51.88 68.42 59.01 37.79 43.89 40.61 58.87
gramtype 80.5 71.12 75.52 66.39 61.04 63.6 43.11 59.93 50.15 63.09
best hierarchy 83.23 73.72 78.19 73.5 67.09 70.15 47.3 60.89 53.24 67.19

TABLE 1 — Scores sur CoNLL-2012 avec mentions gold, décodeur Closest-First.

En regardant les trois différentes métriques, nous constatons que globalement, la séparation des
paires améliore B3 et CEAF (mais pas toujours MUC, a cause du trés gros rappel du single model)
apres le décodage de la sortie : gramtype donne un meilleur score que le modele simple, et best
hierarchy donne les plus hauts B3, CEAF et scores moyens.

La meilleure combinaison de classiﬁeur—décodeur réalise un score de 67.19, ce qui la placerait au
niveau des meilleurs systémes qui ont pris part a la CoNLL—2012 Shared Task sur la conﬁguration
gold mentions (moyenne a 66.41, le premier isolé a 77, les meilleurs suivants a 68-69).

MUC B‘ CEAF

P R F1 P R F1 P R F1 Mean
NgCardie 81.02 93.82 86.95 23.33 93.92 37.37 40.31 18.97 25.8 50.04
single model 79.22 73.75 76.39 40.93 75.48 53.08 30.52 37.59 33.69 54.39
gramtype 77.21 65.89 71.1 49.77 67.19 57.18 32.08 47.83 38.41 55.56
best hierarchy 78.11 69.82 73.73 53.62 70.86 61.05 35.04 46.67 40.03 58.27

TABLE 2 — Score sur CoNLL-2012 avec mentions gold, décodeur Best—First.

129 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

MUC B‘ CEAF

P R F1 P R F1 P R F1 Mean
single model 83.15 88.65 85.81 35.67 88.18 50.79 36.3 28.27 31.78 56.13
gramtype 83.12 84.27 83.69 44.73 81.58 57.78 45.02 42.94 43.95 61.81
best hierarchy 83.26 85.2 84.22 45.65 82.48 58.77 46.28 43.13 44.65 62.55

TABLE 3 - Scores sur CoNLL—2012 avec mentions gold, décodeur Aggressive—Merge.

6 Conclusion et perspectives

Dans cet article, nous avons décrit une méthode pour construire un espace de traits séparant les
paires, en exploitant la linéarité et en combinant des indicateurs pour séparer les instances. Nous
avons mis en oeuvre une technique de programmation dynamique pour calculer efﬁcacement
l’espace de traits fournissant la meilleure classiﬁcation des paires parmi un trés grand nombre
de possibilités. Nous avons appliqué cette méthode pour optimiser le modéle a paires dans un
systéme de résolution de la coréférence. En testant différents décodeurs gloutons, nous avons
montré que cela apporte un gain signiﬁcatif au systeme.

Pour ce travail, nous n’aVons considéré que des stratégies heuristiques standards pour créer les
clusters telles que Closest-First et Best—First. Donc une extension naturelle de ce travail serait de
combiner notre méthode pour apprendre des modeles a paires avec des stratégies de décodage
plus sophistiquées (comme Mincut ou Integer Linear Programming). Nous pourrons alors évaluer
l’impact des hiérarchies dans des conditions plus réalistes.

Notre approche est adaptable dans le sens o1‘1 elle peut s’appliquer avec des indicateurs trés variés.
Dans le futur, nous appliquerons les hiérarchies sur des espaces de traits plus ﬁns pour pouvoir
obtenir des optimisations plus précises. Par ailleurs, étant donné que la méthode générale
de découpage des hiérarchies n’est pas spéciﬁque a la modélisation des paires, mais peut
étre appliquer a d’autres probléme ayant des aspects booléens, nous projetons d’employer
les hiérarchies pour traiter d’autres taches TAL (p.ex. de’tection d’anaphoricité, classiﬁcation de
relations de discours ou de relations temporelles).

La sélection d’espaces avec les hiérarchies, si les indicateurs sont tous des traits du modéle,
s’apparente aux méthodes de noyaux polynomiaux. I1 serait intéressant de les comparer. Par
ailleurs, nous pourrons développer cette méthode en utilisant des critéres statistiques pour choisir
les indicateurs et construire des hiérarchies de départ plus complexes que les hiérarchies—produits,
a la maniere des arbres de décision. Le paramétrage du systeme sera alors facilité.

Références

ARIEL, M. (1988). Referring and accessibility. Journal of Linguistics, pages 65-87.

BAGGA, A. et BALDWIN, B. (1998). Algorithms for scoring coreference chains. In Proceedings of
LREC 1998, pages 563-566.

BENGSTON, E. et ROTH, D. (2008). Understanding the value of features for coreference resolution.
In Proceedings of EMNLP 2008, pages 294-303, Honolulu, Hawaii.

CA1, J. et STRUBE, M. (2010). End—to—end coreference resolution via hypergraph partitioning. In
COLING, pages 143-151.

130 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

CHEN, B., SU, J., PAN, S. J. et TAN, C. L. (2011). A uniﬁed event coreference resolution by
integrating multiple resolvers. In Proceedings of 5th IJCNLP, pages 102-110. Asian Federation of
Natural Language Processing.

CRAMMER, K., DEKEL, 0., KESHET, J., SHALEV-SHWARTZ, S. et SINGER, Y. (2006). Online passive-
aggressive algorithms. Journal of Machine Learning Research, 72551-585.

DENIs, P. et BALDRIDGE, J. (2008). Specialized models and ranking for coreference resolution. In
Proceedings of EMNLP 2008, pages 660-669, Honolulu, Hawaii.

DENIs, P et BALDRIDGE, J. (2009). Global joint models for coreference resolution and named
entity classiﬁcation. Procesamiento del Lenguaje Natural, 43.

KEHLER, A., APPELT, D., TAYLOR, L. et SIMMA, A. (2004). The (non)utility of predicate—argument
frequencies for pronoun interpretation. In Proceedings ofHL'11NAACL 2004.

KLENNER, M. (2007). Enforcing coherence on coreference sets. In Proceedings of RANLP 2007.

LUo, X. (2005). On coreference resolution performance metrics. In Proceedings of HLT-
NAACL 2005, pages 25-32.

MCCARTHY, J. F. et LEHNERT, W. G. (1995). Using decision trees for coreference resolution. In
IJCAI, pages 1050-1055.

MORTON, T. (2000). Coreference for NLP applications. In Proceedings of ACL 2000, Hong Kong.
NG, V (2005). Supervised ranking for pronoun resolution : Some recent improvements. In
Proceedings of AAA] 2005.

NG, V et CARDIE, C. (2002). Improving machine learning approaches to coreference resolution.
In Proceedings of ACL 2002, pages 104-111.

NICOLAE, C. et NICOLAE, G. (2006). Bestcut : A graph algorithm for coreference resolution. In
EMNLP, pages 275-283.

PONZETTO, S. et STRUBE, M. (2006). Exploiting semantic role labeling, WordNet and Wikipedia
for coreference resolution. In Proceedings of the HLT 2006, pages 192-199, New York City, N.Y.

PRADHAN, S., MOSCHITTI, A., XUE, N., URYUPINA, O. et ZHANG, Y. (2012). Conll-2012 shared task :
Modeling multilingual unrestricted coreference in ontonotes. In Joint Conference on EMNLP and
CoNLL — Shared Task, pages 1-40, Jeju Island, Korea. Association for Computational Linguistics.

RAHMAN, A. et NG, V (2011). Narrowing the modeling gap : a cluster-ranking approach to
coreference resolution. J. Artif Int. Res., 40(1):469—521.

So0N, W. M., NG, H. T. et LIM, D. (2001). A machine learning approach to coreference resolution
of noun phrases. Computational Linguistics, 27(4):521-544.

URYUPINA, O. (2004). Linguistically motivated sample selection for coreference resolution. In
Proceedings of DAARC 2004, Furnas.

URYUPINA, 0., POEs10, M., GIULIANO, C. et TYMOSHENKO, K. (2011). Disambiguation and ﬁltering
methods in using web knowledge for coreference resolution. In FLAIRS Conference.

VERSLEY, Y., MOSCHITTI, A., PoEs1o, M. et YANG, X. (2008). Coreference systems based on kernels
methods. In COLING, pages 961-968.

VILAIN, M., BURGER, J., ABERDEEN, J., CONNOLLY, D. et HIRSCHMAN, L. (1995). A model-theoretic
coreference scoring scheme. In Proceedings fo the 6th Message Understanding Conference (MUC—6),
pages 45-52, San Mateo, CA. Morgan Kaufmann.

131 © ATALA

