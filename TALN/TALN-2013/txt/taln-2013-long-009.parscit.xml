<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M ARIEL</author>
</authors>
<title>Referring and accessibility.</title>
<date>1988</date>
<journal>Journal of Linguistics,</journal>
<booktitle>In Proceedings of LREC</booktitle>
<pages>65--87</pages>
<marker>ARIEL, 1988</marker>
<rawString>ARIEL, M. (1988). Referring and accessibility. Journal of Linguistics, pages 65–87. BAGGA, A. et BALDWIN, B. (1998). Algorithms for scoring coreference chains. In Proceedings of LREC 1998, pages 563–566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E et ROTH BENGSTON</author>
<author>D</author>
</authors>
<title>Understanding the value of features for coreference resolution.</title>
<date>2008</date>
<marker>BENGSTON, D, 2008</marker>
<rawString>BENGSTON, E. et ROTH, D. (2008). Understanding the value of features for coreference resolution.</rawString>
</citation>
<citation valid="true">
<date>2008</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>294--303</pages>
<location>Honolulu, Hawaii.</location>
<marker>2008</marker>
<rawString>In Proceedings of EMNLP 2008, pages 294–303, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J et STRUBE CAI</author>
<author>M</author>
</authors>
<title>End-to-end coreference resolution via hypergraph partitioning.</title>
<date>2010</date>
<booktitle>In COLING,</booktitle>
<pages>143--151</pages>
<marker>CAI, M, 2010</marker>
<rawString>CAI, J. et STRUBE, M. (2010). End-to-end coreference resolution via hypergraph partitioning. In COLING, pages 143–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>c ATALA TALN-RÉCITAL</author>
</authors>
<title>A unified event coreference resolution by integrating multiple resolvers.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of 5th IJCNLP,</booktitle>
<pages>17--21</pages>
<contexts>
<context position="2855" citStr="TALN-RÉCITAL 2013" startWordPosition="413" endWordPosition="414">e of the hierarchies built from the indicators. Our experiments on the CoNLL-2012 shared task English datasets indicate that our method is robust to different clustering strategies and evaluation metrics, showing large and consistent improvements over a single pairwise model using the same base features. Our best system obtains 67.2 of average F1 over MUC, B3, and CEAF which, despite its simplicity, places it among the best performing systems on these datasets. MOTS-CLÉS : résolution de la coréférence, apprentissage automatique. KEYWORDS: coreference resolution, machine learning. 118 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 1 Introduction La résolution de la coréférence consiste à partitionner une séquence de syntagmes nominaux (ou mentions) apparaissant dans un texte en un ensemble d’entités qui partagent chacune le même référent. Une approche désormais classique pour résoudre cette tâche consiste à la diviser en deux étapes : d’abord, on définit un modèle pour traiter les relations de coréférence indépendamment les unes des autres, en général via un classifieur binaire détectant les mentions coréférentielles. Ensuite, les liens détectés sont regroupés en clusters par un décodeu</context>
<context position="7037" citStr="TALN-RÉCITAL 2013" startWordPosition="1036" endWordPosition="1037">i trop spécifiques (c.-à-d. pouvant souffrir du manque de données ou de bruit). Nous verrons que cette démarche est aussi équivalente à construire un seul très grand espace de traits pour représenter toutes les données. 1. Il n’y a toutefois aucune garantie théorique pour que l’amélioration de la classification locale ait toujours un impact positif sur la performance globale lorsque les deux modules sont optimisés séparément. 2. Parfois, des échantillonnages différents sont choisis lors de la phase d’apprentissage des modèles locaux distincts (Ng et Cardie, 2002; Uryupina, 2004). 119 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Notre approche généralise les approches précédentes de plusieurs manières. D’une part, la définition des différents modèles n’est plus restreinte au simple typage grammatical (notre modèle permet d’utiliser n’importe quel type d’indicateurs) ni au seul typage de la mention anaphorique (nos modèles peuvent aussi être associés au typage de l’antécédent ou bien au types des deux éléments de la paire). D’autre part, nous proposons une méthode originale pour apprendre les meilleurs ensembles de modèles que l’on peut construire à partir d’un ensemble d’indicateurs d</context>
<context position="10606" citStr="TALN-RÉCITAL 2013" startWordPosition="1566" endWordPosition="1567">tions suit une certaine distribution (que l’on observe en partie en projetant les paires dans un espace de traits). L’idée fondamentale du modèle à paires est de considérer que les paires de mentions sont indépendantes les unes des autres (du coup, la propriété de transitivité n’est pas nécessairement vérifiée en sortie, c’est pourquoi il faut un décodeur la transformer en partition cohérente). Utiliser un seul classifieur pour traiter toutes les paires de mentions revient à supposer qu’elles sont identiquement distribuées. Nous pensons que les paires ne sont pas identiquement dis120 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne tribuées, mais qu’il faut au contraire séparer différents “types” de paires et créer des modèles spécifiques pour ces types. Séparer différents types de paires et les traiter avec des modèles spécifiques peut amener à des modèles globaux plus précis. Certains systèmes de résolution traitent déjà différents types d’anaphores séparément, ce qui revient à supposer que par exemple, les paires qui contiennent un pronom se comportent différemment des autres (Morton, 2000; Ng, 2005; Denis et Baldridge, 2008). Nous pourrions essayer de capturer ces différents comporte</context>
<context position="13291" citStr="TALN-RÉCITAL 2013" startWordPosition="2015" endWordPosition="2016">s ont toujours les mêmes valeurs. De ce point de vue formel, la tâche de résolution de la coréférence consiste à fixer un espace de traits  , observer des échantillons étiquetés {(φ (x), y)t}t∈TrainSet et, étant donné de nouvelles variables partiellement observées {(φ (x))t}t∈TestSet , tenter de retrouver la valeur correspondante de y . 2.2.2 Un autre point de vue sur les hypothèses statistiques Nous avons écrit plus haut que les paires de mentions n’apparaissent pas identiquement distribuées puisque, par exemple, les pronoms ne se comportent pas de la même façon que les noms. 121 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Nous pouvons maintenant formuler cela de façon plus rigoureuse : puisque nous ne pouvons pas observer directement l’espace des objets  , nous en ignorons la complexité. En particulier, lorsque nous utilisons une projection vers un espace de traits trop petit, le classifieur ne parvient pas à capturer la distribution correctement : les données semblent trop bruitées. Maintenant en remarquant que les anaphores pronominales ne se comportent pas de la même manière que les autres anaphores, nous distinguons deux types de paires, c’est-à-dire que nous voyons la dis</context>
<context position="16458" citStr="TALN-RÉCITAL 2013" startWordPosition="2569" endWordPosition="2570"> avec vecteur de traits φ (x) est donnée par : C (x) := si gn(wT ·φ (x)) La propriété de linéarité rend équivalentes les séparations des instances de deux types t1 et t2, dans deux modèles indépendants avec pour espace de traits respectif1 et2 et pour paramètres w1 et w2, et un modèle simple sur1 ⊕2. Pour voir pourquoi, définissons la projection : φ x) :=  φ (x)T T0 si x est de type t1 11⊕ (2   0 φ (x)T T si x est de type t 2 2 w1 et le vecteur paramètre w= w2 ∈1 ⊕2. Nous avons alors : C de type t C x) =  (x) si x est 1 1 1⊕ (2 C (x) si x est de type t2 2 122 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Il faut maintenant s’assurer que cette propriété est vérifiée lors de l’apprentissage du paramètre w. Dans ce travail nous avons utilisé l’algorithme en ligne Passive-Aggressive pour la classification binaire (Crammer et al., 2006). Ce modèle est une extension du perceptron, dont l’obectif à chaque itération est, d’une part de minimiser les changements apportés au modèle existant (d’où la caractéristique “passive”) et, d’autre part, de faire en sorte que l’exemple courant soit correctement classifié avec une large marge (d’où la caractéristique “aggressive”). </context>
<context position="19380" citStr="TALN-RÉCITAL 2013" startWordPosition="3042" endWordPosition="3043">ces de traits Dans cette section, nous présentons notre méthode pour trouver automatiquement une séparation optimale des paires de mentions. On gardera à l’esprit que séparer les paires dans différents modèles est la même chose que construire un grand espace de traits dans lequel le paramètre w peut être appris par parties dans des sous-espaces indépendants. 3.1 Indicateurs sur les paires Pour définir des espaces de traits supplémentaires, nous utilisons des indicateurs, qui sont des fonctions déterministes sur les paires de mentions avec un nombre restreint de valeurs possibles. 123 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Les indicateurs sont utilisés pour classer les paires dans des catégories prédéfinies et en bijection avec un ensemble d’espaces de traits élémentaires indépendants. Nous pouvons réutiliser les traits du système comme indicateurs, par exemple, le type grammatical ou celui des entités nommées. Nous pouvons également utiliser des fonctions qui ne sont pas des traits, par exemple la position approximative d’une des deux mentions dans le texte. Le petit nombre de valeurs possibles pour un indicateur est requis pour des raisons pratiques : si une catégories de pair</context>
<context position="21946" citStr="TALN-RÉCITAL 2013" startWordPosition="3436" endWordPosition="3437">e un sous-arbre de l’arbre de décision complet qui contient des copies d’un même indicateur à chaque niveau. Si toutes les feuilles de l’arbre de décision ont la même profondeur, cela correspond à prendre le produit cartésien des valeurs de tous les indicateurs pour indexer les catégories. Dans ce cas, nous parlerons de hiérarchies-produit. Le modèle gramtype peut être vu comme une hiérarchie-produit à deux niveaux (figure 1). FIGURE 1 – Le modèle gramtype vu comme une hiérarchie-produit. Les hiérarchies-produit seront le point de départ de notre méthode pour trouver un espace de 124 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne traits qui représente bien les données. Maintenant, pour choisir une suite d’indicateurs appropriés, il faut faire appel aux intuitions linguistiques et aux travaux théoriques sur le sujet. Le système trouvera lui-même la meilleure façon d’utiliser ces indicateurs lorsqu’il optimisera la hiérarchie. La suite d’indicateurs est donc un paramètre du modèle. 3.3 Lien entre les hiérarchies et les espaces de traits Comme nous l’avons fait pour le modèle gramtype, nous associons un espace de traits i à chacune des feuilles de la hiérarchie. De la même manière, la so</context>
<context position="25227" citStr="TALN-RÉCITAL 2013" startWordPosition="3961" endWordPosition="3962">pour chaque instance, il existe un unique chemin de la racine vers une feuille de l’arbre complet. Chaque classifieur situé sur ce chemin est mis à jour avec cette instance. Le nombre d’itérations pour le Passive-Aggressive est fixé (nous n’avons pas cherché à optimiser ce paramètre). Calcul des scores : Après la phase d’apprentissage, nous testons tous les classifieurs sur un autre 3. Dans les expériences, les classifieurs utilisent une copie d’un même espace de traits, mais pas les mêmes données, ce qui correspond à croiser les traits avec les catégories de l’arbre de décision. 125 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne ensemble de paires de développement 4. Une fois encore, un classifieur est testé sur une instance seulement s’il est situé sur le chemin de la racine vers une feuille associé à l’instance. Nous obtenons des nombres TP/FP/FN 5 sur les classifications des paires, qui suffisent pour calculer le F1-score. Comme pour l’apprentissage, les données sur lesquelles un classifieur à un nœud donné est évalué sont les mêmes que la réunion de toutes les données utilisées pour évaluer les classifieurs correspondant aux enfant de ce nœud. C’est ainsi que nous sommes en mesure</context>
<context position="28591" citStr="TALN-RÉCITAL 2013" startWordPosition="4510" endWordPosition="4511">éfinir le meilleur score. L’algorithme propage alors les meilleurs scores depuis les feuilles vers la racine, ce qui donne au final un seul score qui correspond à celui de la meilleure hiérarchie. Seulement les feuilles utilisées pour calculer le meilleur score sont gardées et elles définissent la meilleure hiérarchie. Relation entre le découpage et l’espace de traits global : Nous pouvons voir l’opération de 4. Les données d’apprentissages sont coupées en deux parties, pour l’apprentissage et pour tester la hiérarchie. 5. &amp;quot;True positives&amp;quot;, &amp;quot;false positives&amp;quot; et &amp;quot;false negatives&amp;quot;. 126 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne découpage comme le remplacement d’un groupe de sous-espaces par un seul sous-espace dans la somme (voir figure 2). Découper la hiérarchie-produit revient donc à réduire l’espace de traits global (l’espace somme) de manière optimale. Nous voyons ici le lien entre la meilleure hiérarchie et l’espace de traits qui permet de séparer au mieux les paires. FIGURE 2 – Découper la hiérarchie réduit l’espace de traits 4 Description du système Notre système se compose du modèle à paires séparées obtenu en découpant la hiérarchie (c’est donc un PA sur l’espace de traits s</context>
<context position="31240" citStr="TALN-RÉCITAL 2013" startWordPosition="4910" endWordPosition="4911">r les liens et former les clusters à partir des décisions du classifieur : Closest-First (fusionne les mentions avec la mention coréférente à gauche la plus proche, si elle existe) (Soon et al., 2001), Best-first (fusionne les mentions avec la mention à gauche qui obtient le meilleur score positif) (Ng et Cardie, 2002; Bengston et Roth, 2008), et Aggressive-Merge (fermeture transitive sur les paires positives) (McCarthy et Lehnert, 1995). Chacun de ces décodeurs va typiquement de paire avec un échantillonnage particulier lors de l’apprentissage (même si ce n’est pas obligatoire). 127 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne Par exemple, Closest-First est combiné avec un échantillonnage où sont utilisées seulement les instances dans lesquelles la mention de gauche apparaît entre le l’anaphore et l’antécédent le plus proche (Soon et al., 2001). 5 Expériences 5.1 Données Nous avons évalué le système sur la partie anglaise du corpus fourni dans la CoNLL-2012 Shared Task (Pradhan et al., 2012). Le corpus contient 7 catégories de documents (plus de 2k documents, 1.3M de mots). Nous avons utilisé les données d’entraînement/développement/test officielles. 5.2 Paramètres Les hiérarchies o</context>
</contexts>
<marker>TALN-RÉCITAL, 2013</marker>
<rawString>130 c ATALA TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne CHEN, B., SU, J., PAN, S. J. et TAN, C. L. (2011). A unified event coreference resolution by integrating multiple resolvers. In Proceedings of 5th IJCNLP, pages 102–110. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K CRAMMER</author>
<author>O DEKEL</author>
<author>J KESHET</author>
<author>S et SINGER SHALEV-SHWARTZ</author>
<author>Y</author>
</authors>
<title>Online passiveaggressive algorithms.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>7--551</pages>
<marker>CRAMMER, DEKEL, KESHET, SHALEV-SHWARTZ, Y, 2006</marker>
<rawString>CRAMMER, K., DEKEL, O., KESHET, J., SHALEV-SHWARTZ, S. et SINGER, Y. (2006). Online passiveaggressive algorithms. Journal of Machine Learning Research, 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P et BALDRIDGE DENIS</author>
<author>J</author>
</authors>
<title>Specialized models and ranking for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP 2008,</booktitle>
<pages>660--669</pages>
<location>Honolulu, Hawaii.</location>
<marker>DENIS, J, 2008</marker>
<rawString>DENIS, P. et BALDRIDGE, J. (2008). Specialized models and ranking for coreference resolution. In Proceedings of EMNLP 2008, pages 660–669, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P et BALDRIDGE DENIS</author>
<author>J</author>
</authors>
<title>Global joint models for coreference resolution and named entity classification.</title>
<date>2009</date>
<booktitle>Procesamiento del Lenguaje Natural,</booktitle>
<pages>43</pages>
<marker>DENIS, J, 2009</marker>
<rawString>DENIS, P. et BALDRIDGE, J. (2009). Global joint models for coreference resolution and named entity classification. Procesamiento del Lenguaje Natural, 43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A KEHLER</author>
<author>D APPELT</author>
<author>L et SIMMA TAYLOR</author>
<author>A</author>
</authors>
<title>The (non)utility of predicate-argument frequencies for pronoun interpretation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<marker>KEHLER, APPELT, TAYLOR, A, 2004</marker>
<rawString>KEHLER, A., APPELT, D., TAYLOR, L. et SIMMA, A. (2004). The (non)utility of predicate-argument frequencies for pronoun interpretation. In Proceedings of HLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M KLENNER</author>
</authors>
<title>Enforcing coherence on coreference sets.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP</booktitle>
<marker>KLENNER, 2007</marker>
<rawString>KLENNER, M. (2007). Enforcing coherence on coreference sets. In Proceedings of RANLP 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X LUO</author>
</authors>
<title>On coreference resolution performance metrics.</title>
<date>2005</date>
<booktitle>In Proceedings of HLTNAACL</booktitle>
<pages>25--32</pages>
<marker>LUO, 2005</marker>
<rawString>LUO, X. (2005). On coreference resolution performance metrics. In Proceedings of HLTNAACL 2005, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F et LEHNERT MCCARTHY</author>
<author>W G</author>
</authors>
<title>Using decision trees for coreference resolution. In</title>
<date>1995</date>
<booktitle>IJCAI,</booktitle>
<pages>1050--1055</pages>
<marker>MCCARTHY, G, 1995</marker>
<rawString>MCCARTHY, J. F. et LEHNERT, W. G. (1995). Using decision trees for coreference resolution. In IJCAI, pages 1050–1055.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T MORTON</author>
</authors>
<title>Coreference for NLP applications.</title>
<date>2000</date>
<booktitle>In Proceedings of ACL</booktitle>
<location>Hong Kong.</location>
<marker>MORTON, 2000</marker>
<rawString>MORTON, T. (2000). Coreference for NLP applications. In Proceedings of ACL 2000, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V NG</author>
</authors>
<title>Supervised ranking for pronoun resolution : Some recent improvements.</title>
<date>2005</date>
<booktitle>In Proceedings of AAAI</booktitle>
<marker>NG, 2005</marker>
<rawString>NG, V. (2005). Supervised ranking for pronoun resolution : Some recent improvements. In Proceedings of AAAI 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V et CARDIE NG</author>
<author>C</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<marker>NG, C, 2002</marker>
<rawString>NG, V. et CARDIE, C. (2002). Improving machine learning approaches to coreference resolution.</rawString>
</citation>
<citation valid="true">
<date>2002</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>104--111</pages>
<marker>2002</marker>
<rawString>In Proceedings of ACL 2002, pages 104–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C et NICOLAE NICOLAE</author>
<author>G</author>
</authors>
<title>Bestcut : A graph algorithm for coreference resolution. In</title>
<date>2006</date>
<booktitle>EMNLP,</booktitle>
<pages>275--283</pages>
<marker>NICOLAE, G, 2006</marker>
<rawString>NICOLAE, C. et NICOLAE, G. (2006). Bestcut : A graph algorithm for coreference resolution. In EMNLP, pages 275–283.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S et STRUBE PONZETTO</author>
<author>M</author>
</authors>
<title>Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of the HLT</booktitle>
<pages>192--199</pages>
<institution>Jeju Island, Korea. Association for Computational Linguistics.</institution>
<location>New York City, N.Y.</location>
<marker>PONZETTO, M, 2006</marker>
<rawString>PONZETTO, S. et STRUBE, M. (2006). Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution. In Proceedings of the HLT 2006, pages 192–199, New York City, N.Y. PRADHAN, S., MOSCHITTI, A., XUE, N., URYUPINA, O. et ZHANG, Y. (2012). Conll-2012 shared task : Modeling multilingual unrestricted coreference in ontonotes. In Joint Conference on EMNLP and CoNLL - Shared Task, pages 1–40, Jeju Island, Korea. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A et NG RAHMAN</author>
<author>V</author>
</authors>
<title>Narrowing the modeling gap : a cluster-ranking approach to coreference resolution.</title>
<date>2011</date>
<journal>J. Artif. Int. Res.,</journal>
<volume>40</volume>
<issue>1</issue>
<marker>RAHMAN, V, 2011</marker>
<rawString>RAHMAN, A. et NG, V. (2011). Narrowing the modeling gap : a cluster-ranking approach to coreference resolution. J. Artif. Int. Res., 40(1):469–521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W M SOON</author>
<author>H T et LIM NG</author>
<author>D</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<marker>SOON, NG, D, 2001</marker>
<rawString>SOON, W. M., NG, H. T. et LIM, D. (2001). A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O URYUPINA</author>
</authors>
<title>Linguistically motivated sample selection for coreference resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of DAARC 2004,</booktitle>
<location>Furnas.</location>
<marker>URYUPINA, 2004</marker>
<rawString>URYUPINA, O. (2004). Linguistically motivated sample selection for coreference resolution. In Proceedings of DAARC 2004, Furnas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O URYUPINA</author>
<author>M POESIO</author>
<author>C et TYMOSHENKO GIULIANO</author>
<author>K</author>
</authors>
<title>Disambiguation and filtering methods in using web knowledge for coreference resolution.</title>
<date>2011</date>
<booktitle>In FLAIRS Conference.</booktitle>
<marker>URYUPINA, POESIO, GIULIANO, K, 2011</marker>
<rawString>URYUPINA, O., POESIO, M., GIULIANO, C. et TYMOSHENKO, K. (2011). Disambiguation and filtering methods in using web knowledge for coreference resolution. In FLAIRS Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y VERSLEY</author>
<author>A MOSCHITTI</author>
<author>M et YANG POESIO</author>
<author>X</author>
</authors>
<title>Coreference systems based on kernels methods.</title>
<date>2008</date>
<booktitle>In COLING,</booktitle>
<pages>961--968</pages>
<marker>VERSLEY, MOSCHITTI, POESIO, X, 2008</marker>
<rawString>VERSLEY, Y., MOSCHITTI, A., POESIO, M. et YANG, X. (2008). Coreference systems based on kernels methods. In COLING, pages 961–968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M VILAIN</author>
<author>J BURGER</author>
<author>J ABERDEEN</author>
<author>D et HIRSCHMAN CONNOLLY</author>
<author>L</author>
</authors>
<title>A model-theoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proceedings fo the 6th Message Understanding Conference (MUC-6),</booktitle>
<pages>45--52</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>San Mateo, CA.</location>
<note>131 c ATALA</note>
<marker>VILAIN, BURGER, ABERDEEN, CONNOLLY, L, 1995</marker>
<rawString>VILAIN, M., BURGER, J., ABERDEEN, J., CONNOLLY, D. et HIRSCHMAN, L. (1995). A model-theoretic coreference scoring scheme. In Proceedings fo the 6th Message Understanding Conference (MUC-6), pages 45–52, San Mateo, CA. Morgan Kaufmann. 131 c ATALA</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>