<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Construction d&#8217;un large corpus &#233;crit libre annot&#233; morpho-syntaxiquement en fran&#231;ais</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Construction d&#8217;un large corpus &#233;crit libre annot&#233;
morpho-syntaxiquement en fran&#231;ais
</p>
<p>Nicolas Hernandez Florian Boudin
Universit&#233; de Nantes
</p>
<p>nicolas.hernandez@univ-nantes.fr, florian.boudin@univ-nantes.fr
</p>
<p>R&#201;SUM&#201;
Cet article &#233;tudie la possibilit&#233; de cr&#233;er un nouveau corpus &#233;crit en fran&#231;ais annot&#233; morpho-
syntaxiquement &#224; partir d&#8217;un corpus annot&#233; existant. Nos objectifs sont de se lib&#233;rer de la licence
d&#8217;exploitation contraignante du corpus d&#8217;origine et d&#8217;obtenir une modernisation perp&#233;tuelle des
textes. Nous montrons qu&#8217;un corpus pr&#233;-annot&#233; automatiquement peut permettre d&#8217;entra&#238;ner un
&#233;tiqueteur produisant des performances &#233;tat-de-l&#8217;art, si ce corpus est suffisamment grand.
</p>
<p>ABSTRACT
Construction of a Free Large Part-of-Speech Annotated Corpus in French
</p>
<p>This paper studies the possibility of creating a new part-of-speech annotated corpus in French
from an existing one. The objectives are to propose an exit from the restrictive licence of the
source corpus and to obtain a perpetual modernisation of texts. Results show that it is possible
to train a state-of-the-art POS-tagger from an automatically tagged corpus if this one is large
enough.
</p>
<p>MOTS-CL&#201;S : corpus arbor&#233;, construction de corpus, &#233;tiquetage morpho-syntaxique.
KEYWORDS: French treebank, Building a corpus, Part-of-Speech Tagging.
</p>
<p>1 Introduction
</p>
<p>L&#8217;entra&#238;nement et le test de syst&#232;mes statistiques de Traitement Automatique des Langues (TAL)
requi&#232;rent la disponibilit&#233; de larges corpus annot&#233;s (Hajic&#780;ov&#225; et al., 2010). Force est de constater
que la communaut&#233; scientifique est pauvre en corpus &#233;crits en fran&#231;ais librement accessibles,
annot&#233;s en quantit&#233; et en qualit&#233; suffisantes avec des analyses linguistiques structurelles (seg-
mentation des textes en titres, paragraphes, phrases et mots), morpho-syntaxiques (parties du
discours, lemme, genre, nombre, temps...) et syntaxiques (en constituants et en d&#233;pendances)
qui constituent les pr&#233;-traitements de la plupart des applications du TAL. Nous reprenons ainsi &#224;
notre compte des propos &#233;nonc&#233;s pr&#232;s de dix ans plus t&#244;t dans (Salmon-Alt et al., 2004). Dans
cet article nous nous int&#233;ressons &#224; l&#8217;entra&#238;nement d&#8217;&#233;tiqueteurs morpho-syntaxiques pour traiter
des &#233;crits en fran&#231;ais ainsi qu&#8217;&#224; la construction des corpus annot&#233;s associ&#233;s.
</p>
<p>Parmi les corpus &#233;crits annot&#233;s et en fran&#231;ais que nous recensons, nous comptons PAROLE 1 et
MULTEXT JOC 2 (V&#233;ronis et Khouri, 1995), le French Treebank (P7T) (Abeill&#233; et al., 2003), la base
</p>
<p>1. http://catalog.elra.info/product_info.php?products_id=565
2. http://catalog.elra.info/product_info.php?products_id=534
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>160 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FREEBANK (Salmon-Alt et al., 2004) et le r&#233;cent corpus Sequoia 3 (Candito et Seddah, 2012).
Except&#233; la FREEBANK, ces corpus sont toujours accessibles aujourd&#8217;hui via un guichet sur le Web.
La FREEBANK, dont la motivation &#233;tait le recueil collaboratif, la construction et le partage de
corpus libres annot&#233;s en fran&#231;ais a malheureusement disparu dans les limbes du Web 4 du fait de
la difficult&#233; d&#8217;acquisition de textes libres et du co&#251;t de r&#233;alisation d&#8217;une telle entreprise.
</p>
<p>Le P7T 5 est probablement le corpus annot&#233; le plus utilis&#233; et le plus r&#233;f&#233;renc&#233;, et ce essentiellement
pour trois raisons : il est libre d&#8217;usage pour des activit&#233;s de recherche, il b&#233;n&#233;ficie d&#8217;une analyse
multi-niveaux (de la structure textuelle &#224; la structure syntaxique en passant par des annotations en
morphologie) et il compte pr&#232;s du double de mots annot&#233;s que tous les autres corpus disponibles
r&#233;unis. En pratique ce corpus se compose d&#8217;articles journalistiques issus du journal Le Monde
&#233;crits dans les ann&#233;es 90, soit plus de 500 000 mots annot&#233;s. Ainsi (Candito et al., 2010a) utilisent
la structure en constituants du P7T pour construire une structure en d&#233;pendances et permettre
l&#8217;entra&#238;nement d&#8217;analyseurs syntaxiques statistiques en d&#233;pendance du fran&#231;ais (Candito et al.,
2010b). (Sagot et al., 2012) l&#8217;enrichissent avec des annotations r&#233;f&#233;rentielles en entit&#233;s nomm&#233;es.
Tandis que (Danlos et al., 2012) projettent de l&#8217;utiliser comme base d&#8217;annotations discursives.
</p>
<p>Il y a n&#233;anmoins quelques probl&#232;mes associ&#233;s &#224; l&#8217;utilisation du corpus P7T dans une optique de
d&#233;veloppement de syst&#232;mes statistiques de TAL.
</p>
<p>1. Le premier probl&#232;me concerne la faible ad&#233;quation du mod&#232;le th&#233;orique linguistique avec
la t&#226;che d&#8217;entra&#238;nement &#224; laquelle on le destine. (Schluter et van Genabith, 2007; Crabb&#233;
et Candito, 2008) montrent qu&#8217;en remaniant certaines annotations syntaxiques et le jeu
d&#8217;&#233;tiquettes, il est possible d&#8217;am&#233;liorer les performances des syst&#232;mes entra&#238;n&#233;s avec ce
corpus. Un autre aspect du probl&#232;me porte sur la notion de mots compos&#233;s d&#233;finie par les
auteurs. Celle-ci est tr&#232;s large et a pour cons&#233;quence de rendre difficilement reproductible
la segmentation du P7T par un syst&#232;me automatique non entra&#238;n&#233; sur cette ressource.
Cette cons&#233;quence conduit &#224; s&#8217;interroger sur la pertinence d&#8217;utiliser des mod&#233;lisations
construites sur ce corpus pour traiter d&#8217;autres corpus. (Candito et Seddah, 2012), par
exemple, d&#233;cident de restreindre cette d&#233;finition et d&#8217;aborder le traitement des formes les
plus ouvertes (compos&#233;s nominaux et verbaux) qu&#8217;au niveau syntaxique. En comparaison,
le Penn Treebank 6, qui constitue la r&#233;f&#233;rence pour l&#8217;anglais-am&#233;ricain (Marcus et al., 1993;
Gabbard et al., 2006), favorise un d&#233;coupage en mots simples 7 en privil&#233;giant la rupture
pour les mots joints. Il est n&#233;anmoins important de rappeler que le P7T a initialement &#233;t&#233;
cr&#233;&#233; avec une motivation diff&#233;rente de la n&#244;tre aujourd&#8217;hui &#224; savoir la construction de
ressources lexicales de type dictionnaire 8.
</p>
<p>2. Le second probl&#232;me est plus technique et concerne la relative inad&#233;quation du sch&#233;ma
XML de repr&#233;sentation des annotations pour des t&#226;ches automatiques ainsi que le manque
de consistance de la structure d&#8217;annotation. La repr&#233;sentation des amalgames en deux
&#233;l&#233;ments XML distincts qui se retrouvent distribu&#233;s dans diff&#233;rentes configurations selon
qu&#8217;ils se produisent en partie dans un mot compos&#233; est une situation difficile &#224; traiter
automatiquement car elle oblige &#224; &#233;num&#233;rer tous les cas possibles. Certains &#233;l&#233;ments n&#8217;ont
pas syst&#233;matiquement tous leurs attributs, d&#8217;autres ont des noms d&#8217;attribut erron&#233;s. . . Ces
</p>
<p>3. https://www.rocq.inria.fr/alpage-wiki/tiki-index.php?page=CorpusSequoia
4. http://web.archive.org/web/20081215041844/http://freebank.loria.fr/
5. http://www.llf.cnrs.fr/Gens/Abeille/French-Treebank-fr.php
6. http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC99T42
7. http://www.cis.upenn.edu/~treebank/tokenization.html
8. http://www.llf.cnrs.fr/Gens/Abeille/guide-morpho-synt.02.pdf
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>161 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>inconsistances sont relev&#233;es dans de nombreux travaux (Arun et Keller, 2005; Schluter et
van Genabith, 2007; Green et al., 2011; Candito et Seddah, 2012; Boudin et Hernandez,
2012) qui militent en faveur d&#8217;une am&#233;lioration voire d&#8217;une r&#233;organisation de la structure
du P7T avant de pouvoir l&#8217;utiliser dans toute &#233;tude s&#233;rieuse.
</p>
<p>3. G&#233;n&#233;ralement les m&#234;mes auteurs ont aussi observ&#233;s des inconsistances au niveau d&#8217;anno-
tations. Certains, comme (Schluter et van Genabith, 2007; Boudin et Hernandez, 2012),
mettent en oeuvre des techniques automatiques pour d&#233;tecter et corriger des erreurs d&#8217;&#233;ti-
quetage morpho-syntaxique. Le nombre d&#8217;erreurs de ce type est souvent minime ramen&#233;
au nombre de mots annot&#233;s. Sur les 628 767 tokens mots consid&#233;r&#233;s dans (Boudin et
Hernandez, 2012) par exemple, seulement 169 ont &#233;t&#233; consid&#233;r&#233;s comme ayant une erreur
d&#8217;&#233;tiquette. Le corpus &#233;tant construit semi-automatiquement (d&#8217;abord analys&#233; automati-
quement puis valid&#233; manuellement), ce type de probl&#232;me illustre le fait que la validation
humaine ne garantie pas l&#8217;absence d&#8217;erreurs sur un large corpus.
</p>
<p>4. Le quatri&#232;me probl&#232;me que nous relevons r&#233;sulte d&#8217;un parti pris que nous prenons 9.
Nous estimons en effet que sa licence d&#8217;exploitation n&#8217;est pas adapt&#233;e pour favoriser son
utilisation dans le monde de la recherche. Bien que la licence permette des utilisations
avec des outils propri&#233;taires et &#224; des fins commerciales moyennant finance, elle n&#8217;autorise
pas la modification et la diffusion libre des modifications du corpus. Cela a pour principale
cons&#233;quence de ralentir voire de d&#233;courager les contributions ext&#233;rieures et l&#8217;am&#233;lioration
de la ressource (par exemple pour corriger les probl&#232;mes pr&#233;c&#233;demment cit&#233;s).
</p>
<p>5. Les donn&#233;es annot&#233;es sont des textes mono-genres vieux de pr&#232;s de vingt ans encod&#233;s en
ISO-8859-1. On peut se poser la question de la robustesse et de la pr&#233;cision des syst&#232;mes
entra&#238;n&#233;s sur ceux-ci pour traiter des textes plus r&#233;cents (qui pr&#233;sentent de nouveaux
ph&#233;nom&#232;nes linguistiques et des caract&#232;res encod&#233;s en UTF-8, qui est le standard de facto
aujourd&#8217;hui pour encoder des textes en fran&#231;ais) et/ou de genre diff&#233;rent.
</p>
<p>6. M&#234;me s&#8217;il constitue le plus gros corpus annot&#233; disponible pour le fran&#231;ais, on peut s&#8217;inter-
roger sur la repr&#233;sentativit&#233; d&#8217;un corpus d&#8217;un demi-million de mots pour la construction de
syst&#232;mes automatiques. A titre de comparaison, le Penn Treebank compte en corpus &#233;crits
pr&#232;s de 2,4 millions de mots annot&#233;s morphologiquement et syntaxiquement et couvrent le
domaine journalistique (Wall Street Journal) et l&#8217;anglais g&#233;n&#233;ral (Brown).
</p>
<p>Comparativement, PAROLE et MULTEXT JOC ont aussi des licences restrictives, le Sequoia offre
quant &#224; lui le plus de libert&#233;s 10 aux utilisateurs. Aucun des corpus n&#8217;est de taille comparable &#224;
celle du P7T. Ils comptent respectivement 250 000, 200 000 et 72 311 mots annot&#233;s morpho-
syntaxiquement. Except&#233; en partie pour le Sequoia, les textes datent des ann&#233;es 80 et 90.
</p>
<p>Dans cet article, nous r&#233;-ouvrons la question de la construction de corpus annot&#233;s libres en
fran&#231;ais. Une conjoncture &#224; la fois soci&#233;tale, politique, technique et scientifique nous y conduit.
En effet nous b&#233;n&#233;ficions aujourd&#8217;hui d&#8217;au moins deux sources de contenu libres et multilingues,
en croissance perp&#233;tuelle et comptant d&#233;j&#224; plusieurs millions de mots, &#224; savoir les projets de
</p>
<p>9. Nous nous situons dans une d&#233;marche de recherche scientifique &#171;ouverte&#187; (Nielsen, 2011).
10. LGPL-LR (Lesser General Public License For Linguistic Resources). Les auteurs ne pr&#233;cisent pas l&#8217;objet d&#233;sign&#233;
</p>
<p>par la licence. Celle-ci doit se restreindre aux annotations produites et ne peut comprendre les textes. Le corpus est
compos&#233; de textes de quatre origines. On note que le journal Est R&#233;publicain diffus&#233; par le CNRTL est sous licence
CC-BY-NC-SA 2.0 FR qui par sa clause de non-diffusion commerciale s&#8217;oppose &#224; la LGPL-LR. La licence de wikipedia
(CC-BY-SA 3.0) ne semble pas contredire cette licence. La licence de Europarl et de EMEA manque de pr&#233;cision sur les
droits d&#8217;usage mais autorise la reproduction.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>162 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>la Wikimedia Foundation 11 (Wikipedia, Wikinews. . .) et les actes du Parlement Europ&#233;en 12
</p>
<p>(Europarl) tels que remani&#233;s par (Koehn, 2005). Nous nous int&#233;resserons ici aux &#233;crits en fran&#231;ais
de Wikinews et de Europarl. La version en fran&#231;ais de Janvier 2013 de Wikinews compte plus
de 28 000 articles d&#8217;actualit&#233; (soit plus de 2,5 millions de mots sur pr&#232;s de 90 000 phrases) et
couvre une p&#233;riode s&#8217;&#233;talant de Janvier 2005 &#224; nos jours. La section en fran&#231;ais de la version 7
(mai 2012) du corpus Europarl compte, quant &#224; elle, plus de 61,5 millions de mots (plus de 2
millions de phrases) et couvre une p&#233;riode s&#8217;&#233;talant de 1996 &#224; 2011. Les textes du premier sont
disponibles sous licence 13 Creative Commons Attribution 2.5 (CC-BY 2.5) (les versions ant&#233;rieures
&#224; Septembre 2005 sont dans le domaine public) qui permet &#224; l&#8217;utilisateur d&#8217;utiliser, de modifier
et de diffuser la ressource et ses modifications comme il le souhaite moyennant l&#8217;obligation d&#8217;en
citer l&#8217;auteur. Les textes du second sont libres de reproduction 14.
</p>
<p>Dans les sections suivantes, nous nous interrogeons sur la possibilit&#233; d&#8217;exploiter des donn&#233;es
pr&#233;-annot&#233;es automatiquement pour construire un syst&#232;me ayant des performances similaires
&#224; des syst&#232;mes entra&#238;n&#233;s sur des donn&#233;es valid&#233;es manuellement. Nous proposons notamment
d&#8217;observer comment la taille des donn&#233;es pr&#233;-annot&#233;es automatiquement peut jouer un r&#244;le dans
la performance d&#8217;un &#233;tiqueteur morpho-syntaxique entra&#238;n&#233; sur celles-ci.
</p>
<p>2 Cadre exp&#233;rimental
</p>
<p>Dans cette section, nous pr&#233;sentons les donn&#233;es, le jeu d&#8217;&#233;tiquettes et l&#8217;&#233;tiqueteur que nous
utilisons (section 2.1). Nous pr&#233;sentons aussi les pr&#233;-traitements op&#233;r&#233;s sur les donn&#233;es pour les
exploiter (sections 2.2 et 2.3) ainsi que le protocole d&#8217;&#233;valuation de nos exp&#233;riences (section 2.4).
</p>
<p>2.1 Donn&#233;es, jeu d&#8217;&#233;tiquettes et &#233;tiqueteur
</p>
<p>Pour nos exp&#233;rimentations nous utilisons tour &#224; tour le corpus P7T comme donn&#233;es d&#8217;entra&#238;ne-
ment et de test. Le corpus Sequoia est aussi utilis&#233; selon les exp&#233;riences.
</p>
<p>Nous utilisons les parties en fran&#231;ais du Wikinews et d&#8217;Europarl comme donn&#233;es non &#233;tiquet&#233;es.
Nous filtrons les phrases courtes (i.e. inf&#233;rieures &#224; 5 tokens) de chaque document et nettoyons
la syntaxe wiki de Wikinews. L&#8217;ensemble de donn&#233;es ainsi g&#233;n&#233;r&#233; poss&#232;de plusieurs avantages.
Tout d&#8217;abord, Wikinews est du m&#234;me genre que le P7T (journalistique). La diff&#233;rence de genre
avec Europarl permet de discuter de la portabilit&#233; de l&#8217;approche &#224; des genres diff&#233;rents. Ensuite
ces corpus poss&#232;dent une taille bien sup&#233;rieure au P7T ; environ quatre fois sup&#233;rieure pour
Wikinews et soixante fois pour Europarl. Enfin la licence associ&#233;e &#224; ces ressources permettent de
les distribuer librement accompagn&#233;es des annotations que nous g&#233;n&#233;rons.
</p>
<p>Le jeu de cat&#233;gories morpho-syntaxiques que nous utilisons est celui mis ou point par (Crabb&#233;
et Candito, 2008), contenant 28 cat&#233;gories qui combinent diff&#233;rentes valeurs de traits morpho-
syntaxiques du P7T. Outre le fait que ce jeu soit plus complet que les cat&#233;gories du P7T, qui
</p>
<p>11. http://wikimediafoundation.org
12. http://www.statmt.org/europarl/
13. http://dumps.wikimedia.org/legal.html
14. &#171;Except where otherwise indicated, reproduction is authorised, provided that the source is acknowledged.&#187;
</p>
<p>http://www.europarl.europa.eu/guide/publisher/default_en.htm
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>163 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>elles sont au nombre de 13, les auteurs montrent que les performances d&#8217;un &#233;tiqueteur entra&#238;n&#233;
sur de telles annotations sont meilleures. Par ailleurs, son utilisation facilite l&#8217;acc&#232;s &#224; d&#8217;autres
ressources tels que les analyseurs syntaxiques statistiques en d&#233;pendance du fran&#231;ais qui ont
d&#233;j&#224; &#233;t&#233; d&#233;velopp&#233;s &#224; partir de ce jeu d&#8217;&#233;tiquettes 15 (MaltParser, MSTParser, Berkeley Parser)
(Candito et al., 2010b). Par la suite nous ferons r&#233;f&#233;rence &#224; ce jeu d&#8217;&#233;tiquette par le nom P7T+.
Par abus ce nom d&#233;signera aussi le corpus P7T avec des &#233;tiquettes converties en P7T+.
</p>
<p>En ce qui concerne l&#8217;&#233;tiqueteur morpho-syntaxique que nous avons utilis&#233; pour nos exp&#233;riences,
il s&#8217;agit de la version 3.1.3 du Stanford POS Tagger (Toutanova et al., 2003). Ce syst&#232;me utilise un
mod&#232;le par maximum d&#8217;entropie, et peut atteindre des performances au niveau de l&#8217;&#233;tat-de-l&#8217;art
en fran&#231;ais (Boudin et Hernandez, 2012). Nous utilisons un ensemble standard 16 de traits
bidirectionnels sur les mots et les &#233;tiquettes.
</p>
<p>2.2 Segmentation en mots
</p>
<p>Le P7T fournit des analyses linguistiques qui reposent sur une segmentation en mots simples et
en mots compos&#233;s. Les mots composant les compos&#233;s (nous appelons &#171;mots composants&#187; les mots
qui composent les mots compos&#233;s) sont signal&#233;s mais seulement un sous-ensemble b&#233;n&#233;ficie d&#8217;une
cat&#233;gorie grammaticale et aucun d&#8217;eux ne b&#233;n&#233;ficie des autres traits (sous-cat&#233;gorie, flexions
morphologiques et lemme). Except&#233; le lemme, ces traits sont requis pour la conversion en P7T+.
</p>
<p>La notion de compos&#233; dans le P7T est tr&#232;s large (cf. note 8). La composition se justifie par des
crit&#232;res aussi bien graphiques que morphologiques, syntaxiques et s&#233;mantiques. La segmentation
en unit&#233;s lexicales n&#8217;est pas un probl&#232;me trivial. De nombreuses marques de ponctuation (apos-
trophe, virgule, tiret, point et espace) sont ambigu&#235;s, et suivant la situation, jouent le r&#244;le de
joint ou de s&#233;parateur. Cela conduit la majorit&#233; des syst&#232;mes de segmentation (Beno&#238;t et Boullier,
2008; Nasr et al., 2010; Constant et al., 2011) &#224; exploiter, en compl&#233;ment de r&#232;gles g&#233;n&#233;rales,
des listes de formes finies ou r&#233;guli&#232;res &#224; consid&#233;rer comme unit&#233;s lexicales. La segmentation en
compos&#233;s du P7T r&#233;sulte d&#8217;un processus d&#8217;annotation &#224; la fois manuel et &#224; base de lexiques non
pr&#233;cis&#233;ment r&#233;f&#233;renc&#233;s. Outre la difficult&#233; &#224; reproduire automatiquement cette segmentation,
il n&#8217;y a pas d&#8217;enjeu &#224; chercher &#224; le faire car celle-ci est avant tout ad hoc &#224; une p&#233;riode et un
genre de textes. Motiv&#233;s par la volont&#233; d&#8217;entra&#238;ner des analyseurs robustes afin de pouvoir traiter
des textes pour lesquels des dictionnaires de mots compos&#233;s ne seraient pas disponibles, nous
avons souhait&#233; nous abstraire au maximum de la notion de compos&#233; du P7T. Nous n&#8217;avons ainsi
consid&#233;r&#233; comme unit&#233;s lexicales que les compos&#233;s consistant en des unit&#233;s graphiques exemptes
d&#8217;espace ou ceux consistant en des formes num&#233;rales r&#233;guli&#232;res (e.g. &#171;20 000&#187;, &#171;50,12&#187;, &#171;deux
cent vingt-et-un&#187;), lesquelles peuvent admettre des espaces. Certains mots composants sont
donc amen&#233;s &#224; &#234;tre consid&#233;r&#233;s comme unit&#233;s lexicales. Il en d&#233;coule le besoin de d&#233;terminer
les traits morpho-syntaxiques manquants de ceux-ci afin de pouvoir leur affecter une &#233;tiquette
P7T+ (cf. section 2.3). Le P7T compte 6 791 lemmes distincts de mots compos&#233;s qui ne sont pas
des unit&#233;s graphiques (i.e. ne contenant pas d&#8217;espace) soient 26 648 occurrences. 1 892 de ces
lemmes de mots compos&#233;s ont au moins un de leur composant sans &#233;tiquette grammaticale. Cela
repr&#233;sente 7 795 occurrences. 1 106 n&#8217;ont aucune &#233;tiquette &#224; leurs composants.
</p>
<p>Pour les donn&#233;es autres que le P7T, nous utilisons dans nos exp&#233;riences le segmenteur KEA 17.
</p>
<p>15. http://alpage.inria.fr/statgram/frdep/fr_stat_dep_parsing.html
16. Nous avons utilis&#233; la macro generic,naacl2003unknowns d&#233;crite dans (Toutanova et al., 2003).
17. https://github.com/boudinfl/kea
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>164 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>2.3 R&#233;vision et extension du P7T
</p>
<p>Afin de faciliter le traitement automatique ult&#233;rieur du P7T, nous r&#233;alisons des op&#233;rations de
r&#233;vision et d&#8217;extension de la forme et du contenu. Nous envisageons &#224; terme la construction de
mod&#233;lisations de toutes les informations disponibles dans le P7T pour des syst&#232;mes pr&#233;dictifs
statistiques. Nous avons jug&#233; compliqu&#233;es les situations o&#249; l&#8217;extraction de certaines informations
n&#233;cessite des travaux d&#8217;analyse d&#233;di&#233;es (que cela soit des analyses de valeurs d&#8217;attributs ou des
manipulations de la mod&#233;lisation objet des documents (DOM) pour obtenir diff&#233;rents fragments
d&#8217;une m&#234;me information).
</p>
<p>Concernant les op&#233;rations visant la validation 18, l&#8217;homog&#233;n&#233;isation et la simplification de la
structure XML des documents (second type de probl&#232;mes recens&#233; &#224; la section 1), nous avons par
exemple fusionn&#233; les &#233;l&#233;ments XML composant les amalgames 19 en un seul &#233;l&#233;ment de mani&#232;re
similaire &#224; (Candito et Seddah, 2012) (19 489 fusions). Nous avons explicit&#233; les caract&#233;ristiques
morphologiques de chaque mot par des attributs propres (genre, nombre, temps, personne. . .).
Nous avons fait diverses corrections pour valider les documents comme l&#8217;ajout d&#8217;attributs man-
quant (e.g. 3166 attribut compound ajout&#233;s) et le renommage d&#8217;attribut (e.g. 3 726 attributs cat
corrig&#233;s en catint).
</p>
<p>Concernant les op&#233;rations de modification de contenu, la segmentation en tokens mots originale
et le contenu textuel du P7T ont &#233;t&#233; &#233;pargn&#233;s. De m&#234;me, les corrections d&#8217;erreurs triviales
d&#8217;&#233;tiquetage ont &#233;t&#233; consid&#233;r&#233;es &#224; la marge pour cette &#233;tude. Les op&#233;rations se sont concen-
tr&#233;es d&#8217;une part sur la d&#233;termination des traits morpho-syntaxiques (cat&#233;gorie grammaticale,
sous-cat&#233;gorie, flexion morphologique et lemme) des mots composant les mots compos&#233;s, et
d&#8217;autre part sur l&#8217;attribution &#224; chaque mot de l&#8217;&#233;tiquette grammaticale du jeux d&#8217;&#233;tiquettes du
P7T+ correspondant &#224; ses attributs. Ces deux types d&#8217;op&#233;rations, dont le d&#233;tail est pr&#233;sent&#233;
respectivement dans les deux paragraphes suivants, visent &#224; traiter le premier type de probl&#232;mes
recens&#233; &#224; la section 1 ; en particulier la d&#233;termination des traits morpho-syntaxiques est une
&#233;tape n&#233;cessaire &#224; l&#8217;affectation d&#8217;une &#233;tiquette P7T+ aux mots composants (cf. section 2.2).
</p>
<p>Le processus de d&#233;termination des traits manquants pour les mots composants repose sur
l&#8217;observation des s&#233;quences de traits associ&#233;es aux occurrences des compos&#233;s, aux s&#233;quences
de mots simples correspondant aux composants des compos&#233;s, ainsi que sur l&#8217;observation des
traits associ&#233;s individuellement &#224; chaque mot du corpus. Notre approche tente d&#8217;abord une
r&#233;solution avec des statistiques globales et s&#8217;appuie ensuite sur des traits locaux au compos&#233;
en cas d&#8217;ambigu&#239;t&#233; au niveau global. Sur les 1 892 lemmes de compos&#233;s incomplets que nous
observons, nous proposons une solution &#224; 1 736 (3 009 occurrences).
</p>
<p>Le processus d&#8217;attribution &#224; chaque mot d&#8217;une &#233;tiquette du P7T+ exploite les traits cat&#233;gorie,
sous-cat&#233;gorie et flexion morphologique des mots. Pour ce faire, nous nous sommes appuy&#233;s sur
la table de conversion &#233;nonc&#233;e par (Crabb&#233; et Candito, 2008) ainsi que sur la documentation
de l&#8217;&#233;tiqueteur morpho-syntaxique MELT (Denis et Sagot, 2010) pour compl&#233;ter quelques r&#232;gles
manquantes 20. 31 r&#232;gles r&#233;alisent la conversion. Sur les 679 584 mots (simples, compos&#233;s et
composants) que compte le P7T, la proc&#233;dure attribue une &#233;tiquette P7T+ &#224; 664 240 mots ;
</p>
<p>18. Seulement 27 des 44 fichiers composant la section tagged (&#233;tiquet&#233; grammaticalement) de la version de Janvier
2012 sont valides (c&#8217;est-&#224;-dire v&#233;rifient la sp&#233;cification d&#233;finie par le sch&#233;ma NG fourni par les auteurs.)
19. Les amalgames sont des unit&#233;s lexicales d&#233;crite par une unit&#233; graphique mais compos&#233;s deux cat&#233;gories grammati-
</p>
<p>cales (e.g. &quot;du&quot; pour &quot;de+le&quot;, &quot;auxquel&quot; pour &quot;&#224;+lequel&quot;).
20. Un mot de cat&#233;gorie &quot;Nom&quot; et de sous-cat&#233;gorie &quot;cardinal&quot; (million, huit, 2001...) est converti en nom commun.
</p>
<p>L&#8217;&#233;tiquette &quot;pr&#233;fix&quot; ne change pas, comme celle des amalgames apr&#232;s fusion de ses sous-&#233;l&#233;ments.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>165 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>15 344 sont donc ind&#233;finis. Nos r&#232;gles de conversion, test&#233;es sur les annotations P7T du corpus
Sequoia, produisent les m&#234;mes 21 annotations P7T+ que le corpus met aussi &#224; disposition.
</p>
<p>En pratique les diff&#233;rentes op&#233;rations ont &#233;t&#233; mises en oeuvre via des r&#232;gles 22 plus ou moins
g&#233;n&#233;rales exprim&#233;es sur le DOM des documents. Les op&#233;rations de comptage requises par
certaines strat&#233;gies ont &#233;t&#233; r&#233;alis&#233;s sur tout le corpus et non seulement sur chaque document.
</p>
<p>2.4 Protocole d&#8217;&#233;valuation
</p>
<p>Notre objectif est d&#8217;&#233;valuer les performances d&#8217;un &#233;tiqueteur morpho-syntaxique construit sur des
donn&#233;es pr&#233;-annot&#233;es automatiquement par rapport &#224; un &#233;tiqueteur construit sur des donn&#233;es
valid&#233;es manuellement. Notre m&#233;thodologie est pr&#233;sent&#233;e &#224; la figure 1. La premi&#232;re &#233;tape
consiste &#224; produire l&#8217;ensemble de donn&#233;es d&#8217;entra&#238;nement. Pour cela, nous utilisons le Stanford
POS tagger avec un mod&#232;le entra&#238;n&#233; sur le P7T+ pour annoter un large corpus de donn&#233;es
non-&#233;tiquet&#233;es. Cet ensemble de donn&#233;es est not&#233; CORPUSpos apr&#232;s qu&#8217;il ait &#233;t&#233; &#233;tiquet&#233; morpho-
syntaxiquement. Nous l&#8217;utilisons alors dans une deuxi&#232;me &#233;tape pour entra&#238;ner un nouveau
mod&#232;le. La performance du mod&#232;le cr&#233;&#233; &#224; partir de CORPUSpos est ensuite &#233;valu&#233;e sur le P7T+.
</p>
<p>P7T+
</p>
<p>CORPUSPOS
</p>
<p>Mod&#232;le 1
</p>
<p>Mod&#232;le 2
</p>
<p>Test &#201;tiquetagemorpho-syntaxique
</p>
<p>Apprentissage
</p>
<p>Apprentissage
</p>
<p>FIGURE 1 &#8211; Apprentissage d&#8217;un mod&#232;le &#224; partir de donn&#233;es automatiquement annot&#233;es.
</p>
<p>Afin d&#8217;&#233;tudier l&#8217;impact de la taille du corpus d&#8217;entra&#238;nement sur la performance de l&#8217;&#233;tiquetage
morpho-syntaxique, nous avons entra&#238;n&#233; diff&#233;rents mod&#232;les en utilisant des portions de CORPUSpos
repr&#233;sentant un facteur x du nombre de phrases de P7T+. Ici, nous utilisonsWikinews et Europarl
en fran&#231;ais comme CORPUS. Pour Wikinews, nous avons test&#233; les facteurs allant de 1 &#224; 4 fois le
nombre de phrases de P7T+ (4 &#233;tant la limite que nous pouvions atteindre avec le nombre de
phrases contenu dans Wikinews). Pour Europarl, nous avons explor&#233; jusqu&#8217;au facteur 16.
</p>
<p>Trois mesures d&#8217;&#233;valuation sont consid&#233;r&#233;es comme pertinentes pour nos exp&#233;riences : la pr&#233;cision
sur les tokens, la pr&#233;cision sur les phrases (nombre de phrases dans lesquelles tous les tokens ont
&#233;t&#233; correctement &#233;tiquet&#233;s par rapport au nombre de phrases total) et la pr&#233;cision sur les mots
inconnus (calcul&#233;e &#224; partir des tokens n&#8217;apparaissant pas dans l&#8217;ensemble d&#8217;entra&#238;nement).
</p>
<p>21. 108 mots obtiennent une &#233;tiquette diff&#233;rente de celle attribu&#233;e par les auteurs du Sequoia, &#224; savoir une &#233;tiquette
d&#233;signant une valeur ind&#233;finie. En y regardant d&#8217;un peu plus pr&#232;s nous avons constat&#233; que cela concernait en fait 22 formes
distinctes et que ces formes &#233;taient ambigu&#235;s et pouvaient correspondre &#224; des noms communs ou bien &#224; des adverbes
n&#233;gatifs (e.g. 34 &#171;personnes ?&#187;, 37 &#171;points ?&#187;). En creusant davantage, nous avons constat&#233; un probl&#232;me d&#8217;annotation. Ces
mots &#233;taient annot&#233;s en tant que nom (cat&#233;gorie &#171;N&#187;) mais poss&#233;daient une sous-cat&#233;gorie &#171;NEG&#187; propre aux adverbes.
La description incompl&#232;te de certains traits semblent &#234;tre aussi la raison de l&#8217;attribution d&#8217;une &#233;tiquette ind&#233;finie. C&#8217;est
le cas de verbes (&#171;aboutisse, &#171;agrandisse&#187;, &#171;remplisse&#187;) dont le mode n&#8217;est pas pr&#233;cis&#233;. Indirectement notre syst&#232;me a
permis ainsi de d&#233;tecter des erreurs d&#8217;inconsistances dans le Sequoia.
22. L&#8217;outil de r&#233;vision et d&#8217;extension est librement disponible sur https://sites.google.com/site/
</p>
<p>nicolashernandez/resources
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>166 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3 Exp&#233;riences
</p>
<p>Cette section pr&#233;sente les exp&#233;riences que nous avons men&#233;es. Nous rapportons d&#8217;abord la perfor-
mance d&#8217;un &#233;tiqueteur &#233;tat-de-l&#8217;art construit sur des donn&#233;es manuellement valid&#233;es (section 3.1).
Puis nous rapportons les performances observ&#233;es pour diff&#233;rentes tailles de donn&#233;es d&#8217;entra&#238;ne-
ment annot&#233;es automatiquement et ce pour des corpus d&#8217;entra&#238;nement de deux genres diff&#233;rents
(sections 3.2 et 3.2). Enfin nous rapportons les performances de ces &#233;tiqueteurs construits sur des
donn&#233;es non valid&#233;es sur un corpus sans aucun lien de filiation connu (section 3.3). Le mod&#232;le
et les traits d&#8217;entra&#238;nement de ces &#233;tiqueteurs sont pr&#233;sent&#233;s &#224; la section 2.1.
</p>
<p>3.1 Performance d&#8217;un &#233;tiqueteur &#233;tat-de-l&#8217;art
</p>
<p>La premi&#232;re exp&#233;rience que nous avons men&#233;e porte sur l&#8217;&#233;valuation du Stanford POS Tagger sur
l&#8217;ensemble de donn&#233;es P7T+. Il s&#8217;agit de conna&#238;tre la performance maximale que peut obtenir le
syst&#232;me lorsqu&#8217;il est entra&#238;n&#233; sur des donn&#233;es qui ont &#233;t&#233; manuellement valid&#233;es. Les r&#233;sultats
que nous pr&#233;sentons ici ont &#233;t&#233; obtenus en validation crois&#233;e en 10 strates. L&#8217;&#233;cart type (&#963;) des
scores calcul&#233;s sur les diff&#233;rentes strates est &#233;galement report&#233;. Les r&#233;sultats sont pr&#233;sent&#233;s dans
la table 1. Le Stanford POS Tagger obtient une pr&#233;cision moyenne de 96,93% sur les tokens et de
50,03% sur les phrases. Ces r&#233;sultats sont conformes &#224; l&#8217;&#233;tat-de-l&#8217;art des m&#233;thodes n&#8217;utilisant
pas de ressources externes (Crabb&#233; et Candito, 2008). Il faut cependant noter que les scores
pr&#233;sent&#233;s ne sont pas directement comparables aux approches pr&#233;c&#233;dentes qui n&#8217;utilisaient pas
une m&#233;thodologie d&#8217;&#233;valuation en validation crois&#233;e.
</p>
<p>Pr&#233;cision Min. - Max. &#201;cart type
</p>
<p>Tokens 96,93 96,55 - 97,28 0,219
Phrases 50,03 47,08 - 52,41 1,888
</p>
<p>Mots inconnus 85,44 82,04 - 87,67 1,661
</p>
<p>TABLE 1 &#8211; Scores de pr&#233;cision sur les tokens, phrases et mots inconnus du Stanford POS tagger
calcul&#233;s &#224; partir du P7T+ en validation crois&#233;e en 10 strates. Le minimum, le maximum et l&#8217;&#233;cart
type des scores calcul&#233;s sur les 10 strates sont &#233;galement report&#233;s.
</p>
<p>3.2 Entra&#238;nement &#224; partir de donn&#233;es automatiquement annot&#233;es
</p>
<p>Dans une seconde s&#233;rie d&#8217;exp&#233;riences, nous &#233;valuons la performance d&#8217;une m&#233;thode d&#8217;&#233;tiquetage
morpho-syntaxique entra&#238;n&#233;e &#224; partir de donn&#233;es automatiquement annot&#233;es. Les r&#233;sultats sont
pr&#233;sent&#233;s dans la table 2. Le mod&#232;le entra&#238;n&#233; sur la totalit&#233; de Wikinewspos obtient les meilleurs
scores avec une pr&#233;cision moyenne de 96,97% sur les tokens et de 49,74% sur les phrases. Il s&#8217;agit
d&#8217;un niveau de performance statistiquement comparable 23 &#224; celui obtenu avec le mod&#232;le entra&#238;n&#233;
sur le P7T+ (d&#233;crit &#224; la section 3.1). Ce r&#233;sultat montre qu&#8217;il est possible, compte tenu de la
taille des donn&#233;es manuellement annot&#233;es disponibles en fran&#231;ais &#224; ce jour, de cr&#233;er un mod&#232;le
d&#8217;&#233;tiquetage morpho-syntaxique tout aussi performant &#224; partir de donn&#233;es automatiquement
annot&#233;es.
23. &#961; &gt; 0,1 avec un t-test de Student.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>167 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Entra&#238;nement Pr&#233;c. tokens Pr&#233;c. phrases Pr&#233;c. inconnus
</p>
<p>Wikinewspos (1:1 P7T+) 96,46 44,42 80,81
Wikinewspos (2:1 P7T+) 96,77 47,35 80,08
Wikinewspos (3:1 P7T+) 96,88 48,52 79,20
Wikinewspos (4:1 P7T+) 96,97&#8224; 49,57&#8224; 78,20
</p>
<p>TABLE 2 &#8211; Scores de pr&#233;cision sur les tokens, phrases et mots inconnus du Stanford POS tagger
entra&#238;n&#233; &#224; partir de Wikinews (annot&#233; automatiquement) et &#233;valu&#233; sur le P7T+. Le ratio entre la
taille de l&#8217;ensemble d&#8217;entra&#238;nement et la taille du P7T+ est indiqu&#233; entre parenth&#232;ses. Les scores
indiqu&#233;s par le caract&#232;re &#8224; n&#8217;ont pas de diff&#233;rence statistiquement significative par rapport aux
scores obtenus par le mod&#232;le entra&#238;n&#233; sur le P7T+ (&#961; &gt; 0,1 avec un t-test de Student).
</p>
<p>Il est int&#233;ressant de voir que la pr&#233;cision sur les tokens et les phrases est en constante aug-
mentation par rapport &#224; la taille du corpus d&#8217;entra&#238;nement et ce, malgr&#233; un nombre d&#8217;erreurs
d&#8217;&#233;tiquetage automatique obligatoirement &#224; la hausse. La pr&#233;cision moyenne sur les mots incon-
nus est quant &#224; elle en diminution. N&#233;anmoins, le nombre total d&#8217;erreurs commises sur les mots
inconnus est en nette diminution (7128 mots inconnus mal &#233;tiquet&#233;s avec le mod&#232;le entra&#238;n&#233;
&#224; partir d&#8217;un facteur 1 du P7T+ contre 5168 avec le mod&#232;le entra&#238;n&#233; sur 100% Wikinewspos).
On peut &#233;galement constater qu&#8217;il faut une quantit&#233; bien plus importante de donn&#233;es automati-
quement annot&#233;es que de donn&#233;es manuellement annot&#233;es, ici quatre fois plus, pour obtenir le
m&#234;me niveau de performance.
</p>
<p>Entra&#238;nement Pr&#233;c. tokens Pr&#233;c. phrases Pr&#233;c. inconnus
</p>
<p>Europarlpos (1:1 P7T+) 95,85 40,22 79,45
Europarlpos (4:1 P7T+) 96,53 45,51 77,46
Europarlpos (8:1 P7T+) 96,74 47,38 76,68
</p>
<p>Europarlpos (16:1 P7T+) 96,93&#8224; 49,22&#8225; 75,81
</p>
<p>Sequoia 93,99 28,42 83,49
</p>
<p>TABLE 3 &#8211; Scores de pr&#233;cision sur les tokens, phrases et mots inconnus du Stanford POS tagger
entra&#238;n&#233; &#224; partir de Europarl (annot&#233; automatiquement) et Sequoia (valid&#233; manuellement) et
&#233;valu&#233; sur le P7T+. Le ratio entre la taille de l&#8217;ensemble d&#8217;entra&#238;nement et la taille du FTB+
est indiqu&#233; entre parenth&#232;ses. Les scores indiqu&#233;s par le caract&#232;re &#8224; (&#961; &gt; 0,1 avec un t-test
de Student) et &#8225; (&#961; &gt; 0,05 avec un t-test de Student) n&#8217;ont pas de diff&#233;rence statistiquement
significative par rapport aux scores obtenus par le mod&#232;le entra&#238;n&#233; sur le P7T+.
</p>
<p>La table 3 rapporte les r&#233;sultats que nous obtenons avec le corpus Europarlpos. De par la diff&#233;rence
de genre, il &#233;tait attendu que les scores obtenus avec ce corpus soient moins &#233;lev&#233;s que ceux
obtenus avec Wikinewspos. On note que, en comparaison avec Wikinewspos, il faut davantage de
donn&#233;es de Europarlpos pour obtenir un niveau de performance acceptable. Plus exactement, il
semble falloir quatre fois plus de donn&#233;es pour obtenir les m&#234;mes performances. Ainsi avec 16
fois plus de donn&#233;es que le P7T+, on arrive &#224; une performance significative similaire &#224; un syst&#232;me
&#233;tat-de-l&#8217;art entra&#238;n&#233; sur celui-ci. Malgr&#233; des scores de pr&#233;cisions moins &#233;lev&#233;s, on observe les
m&#234;mes tendances de progression quels que soient les scores. Bien que la pr&#233;cision sur les mots
inconnus diminue, le nombre de mots inconnus mal &#233;tiquet&#233;s est &#233;galement &#224; la baisse.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>168 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Dans la m&#234;me table, nous pr&#233;sentons &#224; titre de comparaison les r&#233;sultats obtenus par un mod&#232;le
entra&#238;n&#233; sur Sequoia, seul corpus librement disponible &#224; ce jour. Les scores de pr&#233;cision de ce
mod&#232;le &#233;valu&#233; sur le P7T+ sont bien en dessous de ceux obtenus par les mod&#232;les entra&#238;n&#233;s
sur Wikinewspos et Europarlpos, avec une pr&#233;cision de 93,99% sur les tokens et de seulement
28,42% sur les phrases. Ces r&#233;sultats confirment qu&#8217;un ensemble de donn&#233;es automatiquement
annot&#233;es repr&#233;sente une alternative pertinente pour l&#8217;entra&#238;nement de mod&#232;les d&#8217;&#233;tiquetage
morpho-syntaxique.
</p>
<p>3.3 Performance sur un corpus sans lien de filiation
</p>
<p>La troisi&#232;me et derni&#232;re exp&#233;rience que nous avons men&#233;e consiste &#224; &#233;valuer la performance des
mod&#232;les entra&#238;n&#233;s &#224; partir de Wikinewspos et du P7T+ sur un corpus autre que le French TreeBank.
Pour cela nous avons choisi le corpus Sequoia. Ce dernier est compos&#233; de phrases provenant de
quatre origines : Europarl fran&#231;ais, le journal l&#8217;Est R&#233;publicain, Wikipedia Fr et des documents
de l&#8217;Agence Europ&#233;enne du M&#233;dicament (EMEA). Les r&#233;sultats sont pr&#233;sent&#233;s dans la table 4.
</p>
<p>D&#8217;une mani&#232;re g&#233;n&#233;rale, les scores de pr&#233;cisions sont plus faibles que ceux observ&#233;s sur le
P7T+. La taille tr&#232;s restreinte de Sequoia (3204 phrases) ne permet cependant pas d&#8217;&#233;tablir des
conclusions. Les meilleurs scores sont obtenus sur les phrases provenant de l&#8217;Est R&#233;publicain
et les moins bons sur celles provenant de documents de l&#8217;EMEA (domaine m&#233;dical). Il s&#8217;agit
d&#8217;un comportement normal puisque les mod&#232;les ont &#233;t&#233; construits &#224; partir de phrases issues de
documents journalistiques. Encore une fois, les r&#233;sultats du mod&#232;le entra&#238;n&#233; sur Wikinewspos sont
tr&#232;s proches de ceux obtenus par le mod&#232;le entra&#238;n&#233; sur le P7T+.
</p>
<p>Entra&#238;nement Europarl Est R&#233;p. Wikipedia EMEA Tout
</p>
<p>FTB+ 94,00 95,10 94,86 92,06 93,85
Wikinewspos 93,55 94,56 94,61 91,09 93,30
</p>
<p>TABLE 4 &#8211; Scores de pr&#233;cision sur les tokens du Stanford POS tagger entra&#238;n&#233; &#224; partir deWikinewspos
et du FTB+ et &#233;valu&#233; sur le Sequoia. Les scores de pr&#233;cision en fonction de l&#8217;origine des phrases
sont &#233;galement report&#233;s.
</p>
<p>4 Travaux connexes relatifs &#224; la construction de corpus
</p>
<p>La proc&#233;dure d&#8217;annotation morpho-syntaxique de corpus repose en g&#233;n&#233;ral sur une proc&#233;dure en
deux &#233;tapes 24 : d&#8217;abord une assignation automatique des &#233;tiquettes par un &#233;tiqueteur existant
(&#233;tape aussi appel&#233;e &#171;pr&#233;-annotation&#187;) et ensuite une r&#233;vision de celles-ci par des annotateurs
humains (Hajic&#780;ov&#225; et al., 2010). On retrouve cette mani&#232;re de pr&#233;c&#233;der dans la construction
des corpus Penn Treebank (Marcus et al., 1993), PAROLE, MULTEXT JOC (V&#233;ronis et Khouri,
1995), French Treebank (Abeill&#233; et al., 2003), FREEBANK (Salmon-Alt et al., 2004), TCOF-POS
(un corpus libre de fran&#231;ais parl&#233;) (Benzitoun et al., 2012) et Sequoia (Candito et Seddah, 2012).
</p>
<p>24. Le processus de construction d&#8217;un corpus annot&#233; est plus complexe et comprend notamment les &#233;tapes suivantes :
s&#233;lection et constitution de la base de textes &#224; annoter, d&#233;finition du sch&#233;ma d&#8217;annotation, mise en place du protocole de
validation par les experts, entra&#238;nement et mesure du taux d&#8217;accord entre ceux-ci.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>169 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Cette phase de post-&#233;dition, connue comme &#233;tant toujours n&#233;cessaire, constitue une entreprise
co&#251;teuse en temps et p&#233;cuniairement. (Fort et Sagot, 2010) montrent n&#233;anmoins qu&#8217;il suffit d&#8217;un
petit corpus d&#8217;entra&#238;nement pour construire un syst&#232;me produisant une pr&#233;-annotation de qualit&#233;
suffisante pour permettre une annotation par correction plus rapide qu&#8217;une annotation manuelle.
Dans ce travail, nous ne nous situons pas dans une perspective d&#8217;un post-traitement correctif
manuel.
</p>
<p>Diff&#233;rentes techniques ont &#233;t&#233; propos&#233;es pour rendre plus fiable l&#8217;assignation automatique
d&#8217;&#233;tiquettes ainsi que pour faciliter le travail des annotateurs en d&#233;tectant (voire en corrigeant)
les erreurs d&#8217;annotation. En ce qui concerne l&#8217;assignation automatique, (Clark et al., 2003)
utilisent deux &#233;tiqueteurs morpho-syntaxiques pour annoter de nouvelles donn&#233;es et &#233;tendre
leur corpus d&#8217;entra&#238;nement avec une s&#233;lection de celles-ci. Leur id&#233;e consiste &#224; s&#233;lectionner
les phrases qui maximisent l&#8217;accord d&#8217;annotation entre les &#233;tiqueteurs et d&#8217;ajouter celles-ci aux
donn&#233;es d&#8217;entra&#238;nement, puis de recommencer la proc&#233;dure. Les auteurs constatent que le co-
entra&#238;nement permet d&#8217;am&#233;liorer la performance des syst&#232;mes entra&#238;n&#233;s &#224; partir d&#8217;une quantit&#233;
de donn&#233;es manuellement annot&#233;e tr&#232;s faible. Cette approche trouve son utilit&#233; lorsque l&#8217;on
dispose de peu de quantit&#233; de donn&#233;es annot&#233;s pour entra&#238;ner un syst&#232;me.
</p>
<p>L&#8217;id&#233;e de combiner plusieurs &#233;tiqueteurs se retrouve dans d&#8217;autres travaux. (Loftsson et al., 2010),
par exemple, entra&#238;nent cinq &#233;tiqueteurs sur un m&#234;me corpus (le corpus Icelandic Frequency
Dictionary (IFD)), et utilisent leur combinaison pour annoter un second corpus. La combinaison 25
</p>
<p>se fait par vote &#224; la majorit&#233; et par degr&#233; de confiance dans les &#233;tiqueteurs en cas d&#8217;&#233;galit&#233;. Le
r&#233;sultat de cette combinaison est ensuite sujet &#224; la d&#233;tection d&#8217;erreurs en utilisant la d&#233;tection
d&#8217;incoh&#233;rences entre un &#233;tiquetage en constituants fourni par un outil tiers et l&#8217;&#233;tiquetage morpho-
syntaxique des mots contenus dans les constituants (Loftsson, 2009). La correction effective
des erreurs est ensuite r&#233;alis&#233;e manuellement. Les auteurs montrent que la combinaison des
&#233;tiqueteurs permet d&#8217;augmenter la pr&#233;cision de l&#8217;&#233;tiquetage comparativement aux performances
individuelles de chacun des &#233;tiqueteurs. La raison invoqu&#233;e pour expliquer le ph&#233;nom&#232;ne est que
les diff&#233;rents &#233;tiqueteurs produisent diff&#233;rentes erreurs et que cette diff&#233;rence peut souvent &#234;tre
exploit&#233;e pour conduire &#224; de meilleurs r&#233;sultats.
</p>
<p>Sur le fran&#231;ais, le travail qui se rapproche le plus de ces efforts est celui de (Dejean et al., 2010)
pour qui le d&#233;veloppement d&#8217;un corpus annot&#233; morpho-syntaxiquement reste avant tout un
moyen d&#8217;atteindre leur objectif : construire un &#233;tiqueteur morpho-syntaxique libre du fran&#231;ais.
Les auteurs observent (apr&#232;s alignement des jeux d&#8217;&#233;tiquettes) les divergences d&#8217;annotations des
&#233;tiqueteurs de (Brill, 1994) (BRILL) et de (Schmid, 1994) (TREETAGGER). Ces observations les
conduisent &#224; &#233;mettre des r&#232;gles correctives sur le r&#233;sultat de la combinaison de ces &#233;tiqueteurs,
qu&#8217;ils utilisent pour entra&#238;ner un &#233;tiqueteur &#233;tat-de-l&#8217;art. Leurs exp&#233;rimentations sont r&#233;alis&#233;es
sur un corpus de pr&#232;s de 500 000 mots construit &#224; partir d&#8217;extraits de Wikip&#233;dia, Wikiversity
et Wikinews. L&#8217;&#233;tiqueteur est entra&#238;n&#233; sur une partie du corpus et ses r&#233;sultats sont compar&#233;s
sur une autre partie par rapport aux sorties produites par l&#8217;&#233;tiqueteur BRILL. Le fait que la mise
au point des &#233;tiqueteurs BRILL et TREETAGGER n&#8217;aient pas &#233;t&#233; r&#233;alis&#233;e sur un m&#234;me corpus ainsi
que l&#8217;absence de corpus de r&#233;f&#233;rence pour &#233;valuer les &#233;tiquetages produits, rendent difficile
l&#8217;interpr&#233;tation de ces r&#233;sultats.
</p>
<p>Afin d&#8217;assister la t&#226;che de correction de corpus annot&#233;s, (Dickinson et Meurers, 2003) proposent,
dans le cadre du projet DECCA 26, de s&#8217;appuyer sur l&#8217;observation des variations d&#8217;annotations
</p>
<p>25. http://combitagger.sourceforge.net
26. http://decca.osu.edu
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>170 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>associ&#233;es &#224; un m&#234;me n-gramme de mots pour trouver des erreurs d&#8217;&#233;tiquetage. L&#8217;hypoth&#232;se qu&#8217;ils
font est qu&#8217;un mot ambigu peut avoir diff&#233;rentes &#233;tiquettes dans diff&#233;rents contextes mais plus
ses contextes d&#8217;occurrences sont similaires, plus rare devrait &#234;tre la variation d&#8217;&#233;tiquetage ; et
par cons&#233;quent plus grande devrait &#234;tre la probabilit&#233; qu&#8217;il s&#8217;agisse d&#8217;une erreur. Appliqu&#233; sur le
corpus du Wall Street Journal (WSJ), il observe que 97,6% des variations ramen&#233;es pour des
n-grammes de taille sup&#233;rieure &#224; 6 constituent des erreurs effectives.
</p>
<p>Poursuivant le m&#234;me objectif, (Loftsson, 2009) s&#8217;appuie sur cette technique ainsi que sur deux
autres : le vote de plusieurs &#233;tiqueteurs automatiques et la coh&#233;rence de l&#8217;&#233;tiquetage morpho-
syntaxique des mots en regard d&#8217;une analyse en constituants des phrases. Il observe que ces
techniques permettent individuellement de d&#233;tecter des erreurs et qu&#8217;elles agissent en compl&#233;-
mentarit&#233; ; ce qui lui permet de corriger manuellement 0,23% (1 334 tokens mots) du corpus
IFD. Nous notons que les deux premi&#232;res techniques ne sont pas d&#233;pendantes de la langue mais
que la derni&#232;re repose sur l&#8217;&#233;criture de r&#232;gles ad&#8217;hoc issues de l&#8217;observation des donn&#233;es.
</p>
<p>(Boudin et Hernandez, 2012) appliquent sur le P7T des techniques de d&#233;tection d&#8217;erreurs
fond&#233;es sur les travaux de (Dickinson et Meurers, 2003) ainsi que des heuristiques pour assigner
automatiquement des &#233;tiquettes morpho-syntaxiques aux mots composants. Ils montrent que ces
corrections am&#233;liorent les performances de syst&#232;mes d&#8217;&#233;tiquetage &#233;tat-de-l&#8217;art.
</p>
<p>5 Conclusion et perspectives
</p>
<p>Dans cet article nous montrons qu&#8217;&#224; partir d&#8217;une certaine quantit&#233; de donn&#233;es pr&#233;-annot&#233;es
automatiquement il est possible d&#8217;entra&#238;ner des &#233;tiqueteurs morpho-syntaxiques qui produisent
des r&#233;sultats &#233;quivalents &#224; des syst&#232;mes entra&#238;n&#233;s sur des donn&#233;es valid&#233;es manuellement. La
cons&#233;quence directe de ce r&#233;sultat d&#233;coule de la nature des donn&#233;es utilis&#233;es pour ces exp&#233;riences
(&#224; savoir Wikinews et Europarl) : il est possible de construire un corpus libre annot&#233; morpho-
syntaxiquement offrant une modernisation perp&#233;tuelle des textes et qui puisse servir de base pour
entra&#238;ner des &#233;tiqueteurs morpho-syntaxiques statistiques produisant des analyses &#233;tat-de-l&#8217;art.
</p>
<p>Les perspectives &#224; ce travail sont triples : d&#8217;abord confirmer la qualit&#233; de l&#8217;&#233;tiquetage automatique
des annotations morpho-syntaxiques du corpus ainsi construit, ensuite &#233;tendre les annotations
du corpus &#224; d&#8217;autres niveaux d&#8217;analyse, et enfin diffuser librement la ressource par un moyen qui
permette un enrichissement collaboratif. Concernant l&#8217;am&#233;lioration de la qualit&#233; d&#8217;&#233;tiquetage,
(Schluter et van Genabith, 2007; Loftsson et al., 2010; Boudin et Hernandez, 2012) ont montr&#233;
des pistes pour la d&#233;tection et la correction d&#8217;erreurs par des proc&#233;dures automatiques en utilisant
la d&#233;tection de variations d&#8217;&#233;tiquetage ou la combinaison de multiples &#233;tiqueteurs. Concernant
l&#8217;extension du corpus &#224; d&#8217;autres niveaux d&#8217;analyses, (Candito et Seddah, 2012) utilisent pour le
projet Sequoia diff&#233;rentes techniques pour pr&#233;-annoter automatiquement le niveau syntaxique
avec des analyses en constituants et en d&#233;pendances. Les solutions mises en oeuvre dans le
projet DECCA (cf. note 26) permettent d&#8217;envisager la d&#233;tection d&#8217;erreurs &#224; ces niveaux. L&#8217;une des
difficult&#233;s sera de voir s&#8217;il est possible d&#8217;automatiser certaines corrections comme dans (Boudin et
Hernandez, 2012) ainsi que de voir si la taille des donn&#233;es annot&#233;es a une incidence sur la qualit&#233;
des syst&#232;mes entra&#238;n&#233;s. L&#8217;enjeu de la mise au point de telles techniques est &#233;norme puisqu&#8217;il s&#8217;agit
de pouvoir offrir &#224; la communaut&#233; un large corpus annot&#233; croissant continuellement sous une
licence d&#8217;exploitation offrant &#224; l&#8217;utilisateur le droit de copier, modifier et utiliser la ressource pour
la finalit&#233; qu&#8217;il souhaite.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>171 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;f&#233;rences
</p>
<p>ABEILL&#201;, A., CL&#201;MENT, L. et TOUSSENEL, F. (2003). Building and using Parsed Corpora, chapitre
Building a treebank for French. Language and Speech series, Kluwer, Dordrecht.
ARUN, A. et KELLER, F. (2005). Lexicalization in crosslinguistic probabilistic parsing : The case
of French. In Proceedings of the 43rd Annual Meeting of the Association for Computational
Linguistics (ACL&#8217;05), pages 306&#8211;313, Ann Arbor, Michigan.
BENO&#206;T, S. et BOULLIER, P. (2008). Sxpipe 2 : architecture pour le traitement pr&#233;-syntaxique de
corpus bruts. Traitement Automatique des Langues, 49(2):155&#8211;188.
BENZITOUN, C., FORT, K. et SAGOT, B. (2012). TCOF-POS : un corpus libre de fran&#231;ais parl&#233;
annot&#233; en morphosyntaxe. In Actes de la conf&#233;rence conjointe JEP-TALN-RECITAL, pages 99&#8211;
112, Grenoble, France. Quaero.
BOUDIN, F. et HERNANDEZ, N. (2012). D&#233;tection et correction automatique d&#8217;erreurs d&#8217;an-
notation morpho-syntaxique du french treebank. In Proceedings of the Joint Conference
JEP-TALN-RECITAL 2012, volume 2 : TALN, pages 281&#8211;291, Grenoble, France. ATALA/AFCP.
BRILL, E. (1994). Some advances in rule-based part of speech tagging. In Proceedings of the
Twelfth National Conference on Artificial Intelligence (AAAI), pages 722&#8211;727.
CANDITO, M. et SEDDAH, D. (2012). Le corpus Sequoia : annotation syn-
taxique et exploitation pour l&#8217;adaptation d&#8217;analyseur par pont lexical. In
19e conf&#233;rence sur le Traitement Automatique des Langues Naturelles, Grenoble, France.
CANDITO, M.-H., CRABB&#201;, B. et DENIS, P. (2010a). Statistical french dependency parsing : Treebank
conversion and first results. In Proceedings of LREC, Valletta, Malta.
CANDITO, M.-H., NIVRE, J., DENIS, P. et ANGUIANO, E. H. (2010b). Benchmarking of statistical
dependency parsers for french. In COLING&#8217;2010 (poster session), Beijing, China.
CLARK, S., CURRAN, J. et OSBORNE, M. (2003). Bootstrapping pos-taggers using unlabelled data.
In DAELEMANS, W. et OSBORNE, M., &#233;diteurs : Proceedings of the Seventh Conference on Natural
Language Learning at HLT-NAACL 2003, pages 49&#8211;55.
CONSTANT, M., TELLIER, I., DUCHIER, D., DUPONT, Y., SIGOGNE, A. et BILLOT, S. (2011). Int&#233;grer
des connaissances linguistiques dans un CRF : application &#224; l&#8217;apprentissage d&#8217;un segmenteur-
&#233;tiqueteur du fran&#231;ais. In Actes de la 18e conf&#233;rence sur le Traitement Automatique des
Langues Naturelles (TALN&#8217;2011), Montpellier, France.
CRABB&#201;, B. et CANDITO, M. (2008). Exp&#233;riences d&#8217;analyse syntaxique statistique du fran&#231;ais. In
Actes de la 15&#232;me conf&#233;rence sur le Traitement Automatique des Langues Naturelles (TALN),
Avignon, France.
DANLOS, L., ANTOLINOS-BASSO, D., BRAUD, C. et ROZE, C. (2012). Vers le FDTB : French Discourse
Tree Bank. In Actes de la 19e conf&#233;rence sur le Traitement Automatique des Langues Naturelles
(TALN), pages 471&#8211;478, Grenoble, France.
DEJEAN, C., FORTUN, M., MASSOT, C., POTTIER, V., POULARD, F. et VERNIER, M. (2010). Un
&#233;tiqueteur de r&#244;les grammaticaux libre pour le fran&#231;ais int&#233;gr&#233; &#224; Apache UIMA. In
Actes de la 17e Conf&#233;rence sur le Traitement Automatique des Langues Naturelles, Montr&#233;al,
Canada.
DENIS, P. et SAGOT, B. (2010). Exploitation d&#8217;une ressource lexicale pour la construction d&#8217;un
&#233;tiqueteur morpho-syntaxique &#233;tat-de-l&#8217;art du fran&#231;ais. In Actes de la 17e conf&#233;rence sur le
Traitement Automatique des Langues Naturelles (TALN&#8217;2010), Montr&#233;al, Canada.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>172 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>DICKINSON, M. et MEURERS, W. D. (2003). Detecting errors in part-of-speech annotation.
In Proceedings of the 10th Conference of the European Chapter of the Association for
Computational Linguistics (EACL-03), pages 107&#8211;114, Budapest, Hungary.
</p>
<p>FORT, K. et SAGOT, B. (2010). Influence of pre-annotation on pos-tagged corpus development.
In Proceedings of the Fourth Linguistic Annotation Workshop, pages 56&#8211;63, Uppsala, Sweden.
Association for Computational Linguistics.
</p>
<p>GABBARD, R., MARCUS, M. et KULICK, S. (2006). Fully parsing the penn treebank. In Proceedings
of the main conference on Human Language Technology Conference of the North American
Chapter of the Association of Computational Linguistics, HLT-NAACL &#8217;06, pages 184&#8211;191,
Stroudsburg, PA, USA. Association for Computational Linguistics.
</p>
<p>GREEN, S., de MARNEFFE, M.-C., BAUER, J. et MANNING, C. D. (2011). Multiword expression
identification with tree substitution grammars : A parsing tour de force with french. In EMNLP.
</p>
<p>HAJIC&#780;OV&#193;, E., ABEILL&#201;, A., HAJIC&#780;, J., MIROVSK&#221;, J. et URE&#352;OV&#193;, Z. (2010). Handbook of Natural
Language Processing, chapitre Treebank Annotation. Chapman &amp; Hall/CRC.
KOEHN, P. (2005). Europarl : A parallel corpus for statistical machine translation. In MT Summit.
</p>
<p>LOFTSSON, H. (2009). Correcting a POS-tagged corpus using three complementary methods. In
Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages
523&#8211;531, Athens, Greece. Association for Computational Linguistics.
</p>
<p>LOFTSSON, H., YNGVASON, J. H., HELGAD&#211;TTIR, S. et R&#214;GNVALDSSON, E. (2010). Developing a
pos-tagged corpus using existing tools. In Proceedings of LREC.
</p>
<p>MARCUS, M. P., MARCINKIEWICZ, M. A. et SANTORINI, B. (1993). Building a large annotated corpus
of english : the penn treebank. Computational Linguistics, 19(2):313&#8211;330.
</p>
<p>NASR, A., B&#201;CHET, F. et REY, J.-F. (2010). Macaon : Une cha&#238;ne linguistique pour le traite-
ment de graphes de mots. In Traitement Automatique des Langues Naturelles - session de
d&#233;monstrations, Montr&#233;al.
</p>
<p>NIELSEN, M. (2011). Reinventing Discovery : The New Era of Networked Science. Princeton,
N.J. Princeton University Press.
</p>
<p>SAGOT, B., RICHARD, M. et STERN, R. (2012). Annotation r&#233;f&#233;rentielle du Corpus Arbor&#233; de
Paris 7 en entit&#233;s nomm&#233;es. In Actes de la 19e conf&#233;rence sur le Traitement Automatique des
Langues Naturelles (TALN), pages 535&#8211;542, Grenoble, France.
</p>
<p>SALMON-ALT, S., BICK, E., ROMARY, L. et PIERREL, J.-M. (2004). La FReeBank : vers une base libre
de corpus annot&#233;s. In Traitement Automatique des Langues Naturelles - TALN&#8217;04, F&#232;s, Maroc.
</p>
<p>SCHLUTER, N. et van GENABITH, J. (2007). Preparing, restructuring, and augmenting a french
treebank : lexicalised parsers or coherent treebanks ? In Proceedings of the 10th Conference of
the Pacific Association for Computational Linguistics (PACLING), Melbourne, Australia.
</p>
<p>SCHMID, H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings of
the Conference on New Methods in Language Processing, Manchester, UK.
</p>
<p>TOUTANOVA, K., KLEIN, D., MANNING, C. et SINGER, Y. (2003). Feature-rich part-of-speech tagging
with a cyclic dependency network. In Proceedings of the 3rd Conference of the North American
Chapter of the ACL (NAACL 2003), pages 173&#8211;180. Association for Computational Linguistics.
</p>
<p>V&#201;RONIS, J. et KHOURI, L. (1995). Etiquetage grammatical multilingue : le projet multext.
Traitement Automatique des Langues, 36(1/2):233&#8211;248.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>173 c&#65535; ATALA</p>

</div></div>
</body></html>