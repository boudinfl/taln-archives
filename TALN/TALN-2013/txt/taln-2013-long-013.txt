TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Vers un treebank du frangais parlé

Anne Abeillé1:2 Benoit Crabbé1’3
(1) LLE CNRS-Université Paris Diderot, 75013 Paris, PRES Sorbonne Paris Cité, IUF
(2) Alpage, INRIA, Université Paris Diderot, 75013 Paris, PRES Sorbonne Paris Cité
abei11e<0u.niv—paris—diderot.fr, bcrabbe@u.niv—paris—diderot.fr

RESUME
Nous présentons les premiers résultats d’un corpus arboré pour le francais parlé. 11 a été réalisé
dans le cadre du projet ANR Etape (resp. G. Gravier) en 2011 et 2012. Contrairement a d’autres
langues comme l’anglais (voir le Switchboard treebank de (Meteer, 1995)), i1 n’existe pas de
grand corpus oral du francais annoté et validé pour les constituants et les fonctions syntaxiques.
Nous souhaitons construire une ressource comparable, qui serait une extension naturelle du
Corpus arboré de Paris 7 (FTB : (Abeillé et al., 2003))) basé sur des textes du journal Le Monde.
Nous serons ainsi en mesure de comparer, avec des annotations comparables, l’écrit et l’oral. Les
premiers résultats, qui consistent a réutiliser l’analyseur de (Petrov et al., 2006) entrainé sur
l’écrit, avec une phase de correction manuelle, sont encourageants.

ABSTRACT
Towards a treebank of spoken French

We present the ﬁrst results of an attempt to build a spoken treebank for French. It has been
conducted as part of the ANR project Etape (resp. G. Gravier). Contrary to other languages such
as English (see the Switchboard treebank (Meteer, 1995)), there is no sizable spoken corpus for
French annotated for syntactic constituents and grammatical functions. Our project is to build
such a resource which will be a natural extension of the Paris 7 treebank (FTB : (Abeillé et al.,
2003))) for written French, in order to be able to compare with similar annotations written and
spoken French. We have reused and adapted the parser (Petrov et al., 2006) which has been
trained on the written treebank, with manual correction and validation. The ﬁrst results are
promising.

MOTS-CLES : Corpus arboré, francais parlé, corpus oral, analyse syntaxique automatique.

KEYWORDS: Treebank, spoken French, spoken corpus, parsing.

1 Introduction

Nous présentons les premiers résultats d’un corpus arboré pour le francais parlé. 11 a été réalisé
dans le cadre du projet ANR Etape (resp. G. Gravier) entre 2010 et 2012. Les corpus arborés
(Treebank) pour les autres langues ont une partie écrite et une partie orale : Penn Treebank
(Switchboard (Meteer, 1995)), Verbmobil pour l’allemand, Prague Dependency Treebank pour le
tchéque (Mikulova, 2008). A notre connaissance, il n’existe pas de grand corpus oral du francais

174 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

annoté et validé pour les constituants et les fonctions syntaxiques. Les corpus oraux annotés
existants pour le francais suivent des schémas spéciﬁques : annotation en micro et macro syntaxe
pour le corpus Rhapsodie (cite Deulofeu 2011), annotation en dépendances de (Cerisara et al.,
2010), annotation en chunks du corpus Otim (Blache et al., 2010) Nous souhaitons construire
une ressource qui soit une extension naturelle du Corpus arboré de Paris 7 (FTB (Abeillé et al.,
2003)) basé sur des textes du journal Le Monde. Nous serons ainsi en mesure de comparer, avec
des annotations comparables, l’écrit et l’oral. Nous procédons en trois temps : une phase de
prétraitement avec ponctuation et balisage des dysﬂuences, une phase d’analyse automatique,
une phase de correction manuelle. Pour la seconde phase, nous avons adapté le parseur de
(Petrov et al., 2006) entraine’ sur le FTB; pour la troisieme phase, nous avons adapté et enrichi
les consignes du Corpus arboré de Paris 7 (Abeille et al., 2013).

2 De 1’écrit a l’oral

Contrairement a d’autres langues comme l’anglais (Switchboard (Meteer, 1995)) i1 n’existe pas de
grand corpus oral du francais annoté et validé pour les constituants et les fonctions syntaxiques.
Nous souhaitons construire une ressource comparable, qui serait une extension naturelle du
Corpus arboré de Paris 7 (FTB (Abeillé et al., 2003)) basé sur des textes du journal Le Monde. Une
extension 2‘: l’oral devrait permettre a terme de mener des études comparatives sur des données
comparables de la syntaxe du francais écrit et du francais oral.

Le corpus écrit est annoté lexicalement (lemme, catégories et sous—catégories lexicales, morpho-
logie ﬂexionnelle, mots composés), en constituants et en fonctions et a été validé manuellement.
Il est distribué depuis 2001 et est accompagné d’un guide d’annotation (135pp). Le jeu d’éti—
quettes morphologiques est relativement riche (218 catégories) alors qu’on compte 12 étiquettes
de syntagmes et 8 étiquettes de fonctions. Les choix généraux d’annotation reposent sur un
schéma surfaciste d’annotation de constituants majeurs qui se veut compatible avec plusieurs
théories syntaxiques. Contrairement au Penn Treebank (Marcus et al., 1993) le corpus francais
ne comporte pas de catégories vides ni de constituants discontinus.

Contrairement a d’autres initiatives d’annotation pour le francais (Deulofeu et al., 2010), et
suivant en cela les initiatives pour d’autres langues (Meteer, 1995; Mikulova, 2008) la représen-
tation de données orales proposée ici repose sur 1’hypothese que la syntaxe de la phrase orale
ne nécessite pas un réaménagement en profondeur du schéma d’annotation de l’écrit, méme si
des aménagements légers sont nécessaires. Ce choix a pour conséquence de rendre disponible
1’outillage déja existant (analyseurs, outils d’édition de treebank) pour faciliter et accélérer le
travail d’annotation.

Plusieurs versions du French Treebank sont actuellement utilisées (Schluter et van Genabith,
2007; Blache et Rauzy, 2012). Nous nous appuyons sur la représentation simpliﬁée décrite
notamment par (Crabbé et Candito, 2008) qui permet l’analyse automatique avec les algorithmes
d’analyse en constituants a l’état de l’art. En particulier nous nous appuyons sur un jeu de catégo-
ries lexicales réduit (28 catégories) et une liste de mots composés réduite aux mots composés
grammaticaux. Cette version réduite a l’avantage de se convertir de maniere déterministe vers
une représentation en dépendances syntaxiques projectives (Candito et al., 2009) qui est de
plus en plus utilisée. Annoter en constituants permet donc de bénéﬁcier des deux types de
représentations.

175 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

— Approche par utilisation exclusive des données orales (0) Dans ce troisieme scénario, on
suppose qu’on dispose d’un fragment de données déja annotées pour le domaine cible. Le
modele d’ana1yse est entrainé uniquement sur ce fragment de données orales et n’uti1ise pas
les données écrites.

— Approche par utilisation combinée des données écrites et des données orales (0/E) :
Dans ce dernier scénario, le modele est appris sur l’intégralité des données écrites et sur un
fragment des données orales.

Comparaison des différentes méthodes Dans ce qui suit nous évaluons chacune de ces mé-

thodes en fonction de la quantité de données orales utilisées pour entrainer le modele. Dans

le cas des méthodes (E) et (T/ D), le fragment de données orales de référence disponible n’est
pas utilisé pour l’entrainement. Les méthodes (E) (T/ D) et (E/O) utilisent systématiquement

l’intégra1ité des données écrites pour 1’entrainement. Les fragments de données orales utjlisés a

l’entrainement du modéle par les méthodes (O) et (E/O) sont issus de données de référence déja

validées par les annotateurs.

L’analyseur utilisé est l’analyseur de Berkeley (Petrov et al., 2006) tel que distribué a ce jour. Cet
algorithme faiblement lexicalisé est connu pour étre relativement robuste au changement de
domaine. L’ensemble des tests réalisés repose sur la Comparaison des prédictions de cet analyseur
sur un corpus de test comportant 528 phrases. Le calcul du F—Score est réalisé avec le logiciel
evalb (paramétrage standard, phrase de moins de 40 mots).

Nous avons évalué la correction de chacune des quatre méthodes en fonction de la taille du
fragment de données orales utilisées a l’entrainement. Les résultats sont résumés dans la table 3
(Précision,Rappe1, F—score, Tagging accurracy) 3. Les lignes représentent chacune des quatre
méthodes d’analyse. Les colonnes représentent la taille des données orales (en nombre de
phrases) utilisées par l’analyseur lors de l’entrainement. Les chiffres indiquent le F—score de
1’analyseur sur le jeu de test de 528 phrases.

Méthode 530 1060 1590
P R F Tag P R F Tag P R F Tag
Ecrit (E) 62.2 66.4 64.3 61.7 62.2 66.4 64.3 61.7 62.2 66.4 64.3 61.7
Ecrit (T/D) 72.8 79.6 76.0 62.4 72.8 79.6 76.0 62.4 72.8 79.6 76.0 62.4
Oral (O) 64.8 64.8 64.8 66.4 68.9 69.2 69.0 70.7 70.6 71.3 71.0 72.3
Oral+Ecrit (O/E) 63.6 66.1 64.9 62.0 63.6 67.0 65.3 64.8 67.4 70.9 69.11 67.0

TABLE 3 — Evaluation des méthodes d’adaptation

Vu que les deux premieres lignes représentent des protocoles qui ignorent totalement les don-
nées orales a l’entrainement, le score d’évaluation est constant. En premiere observation, on
constate que la méthode de transformation/détransformation des données est celle qui donne les
meilleurs résultats. L’explication la plus Vraisemblable pour expliquer ce meilleur résultat tient
probablement a (1) les données a prédire correspondent structurellement aux données apprises
et (2) une partie de la solution est simplement déja donnée : les dysﬂuences sont en effet copiées
de l’entrée vers la sortie sans possibilité de se tromper dans leurs prédictions.

On constate également que le modéle mixte (O/E) fonctionne comparativement moins bien qu’un
modele entrainé uniquement sur les données orales (0). La raison est certainement a chercher
dans le fait que les proportions de données orales et écrites de ce modéle sont inégales : 21268

3. Notons toutefois que les performances de l’analyseur varient d’un type de corpus a l’autre : ainsi on obtient un
F—score de 69.5 sur les données CORAL-ROM et de 61.8 sur les données France Inter avec le modéle (E).

184 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

phrases pour 1’écrit contre k * 530 phrases pour l’oral (1 5 k 5 3). Autrement dit, ce modele reste
fondamentalement semblable a un modéle de l’écrit.

Exploration du comportement des modéles mixtes (0/ E) De maniere a vériﬁer plus en détail
si un modele de type (0 / E) permet d’obtenir un modele satisfaisant en assurant une pondération
plus appropriée des deux groupes de données (oral,écrit) nous avons procédé a une seconde
expérience par rééchantillonage contr6lé des données. Dans cette seconde expérience nous
avons testé dans quelle mesure un la méthode de type (0 / E) se comporte en fonction de deux
parametres : (1) la proportion de données écrites dans le corpus d’entrainement et (2) la taille
des données d’entrainement.

Le protocole de quantiﬁcation des résultats est identique au cas précédent, nous utilisons systé—
matjquement le méme corpus de test. Ce qui change c’est la création du corpus d’entrainement.
Ainsi pour chaque mesure réalisée, on a créé un corpus d’entrainement par échantillonage avec
remise dans les données (angl. bootstrapping with replacement). Les groupes de données source
(dans lesquelles on tire) sont un échantillon écrit E constitué des 21268 phrases du French
treebank écrit, et d’un échantillon O constitué de 1530 phrases annotées pour l’oral. Notons
k la proportion de texte écrit souhaitée dans le corpus généré. Chaque phrase c,- du corpus
bootstrappé C = cl . . .c,, est tirée avec une probabilité k dans le groupe E et (1 — k) dans le
groupe 0. Le tirage dans un groupe (E ou O) est fait de maniere uniforme et avec remplacement
(on peut tirer plusieurs fois le méme exemple). C’est ce corpus généré aléatoirement C qui
sert comme données d’apprentissage du modéle d’analyse syntaxique. Il est donc possible que
certaines phrases de E ou de O ne soient pas représentées dans C échantillonné et que certaines
phrase de E ou de 0 y soient représentées plusieurs fois.

Notons que le processus de bootstrapping nous permet de créer des corpus de tailles queclonques.
Ainsi nous avons croisé chaque valeur retenue pour k (0,0.25,0.5,0.75) avec une taille de corpus
n variant de 1000 a 7000 phrases. Les résultats d’anlyse sur les 528 phrases de test sont reportées
dans le tableau 4. Les résultats montrent globalement qu’une pondération plus appropriée des

Données d’entrainement 1000 2000 3000 4000 5000 6000 7000

Mix(Oral,Ecrit,k = 0) 65.57 68.09 69.15 68.2 69.1 67.4 68.0
Mix(Oral,Ecrit,k = 0.25) 68.2 69.6 71.0 72.1 70.9 71.9 72.1
Mix(Oral,Ecrit,k = 0.5) 67.8 69.6 71.0 72.0 69.1 67.4 67.9
Mix(Oral,Ecrit,k = 0.75) 65.7 69.9 70.7 71.2 71.7 72.0 72.4

TABLE 4 — Evaluation par bootstrapping

deux groupes de données permet d’amé1iorer subtantiellement les performances de l’analyseur.
Ainsi on atteint un F—Score de 72.4 pour un corpus d’entrainement de 7000 phrases comportant
75% de données écrites a comparer avec 69.1 obtenu par le mélange na'1‘f de la premiere
expérience. Toutefois, l’observation la plus étonnante reste la comparaison avec la méthode
artisanale (T / D) F—score= 76% qui reste trés nettement meilleure que la méthodes de mélange
(O/E) méme en contrélant les proportions pour cette derniére. Pour conﬁrmer la pertinence
de notre méthode artisanale, il faudrait également la comparer a des méthodes d’adaptation
de domaine plus élaborées que le bootstrapping, comme par exemple des méthodes d’active
learning qui visent a pondérer d’avantage les exemples clés pour l’apprenu'ssage ou encore a des
méthodes d’apprentissage semi—supervisées. I1 serait intéressant également de reformuler notre
méthode artisanale sous forme d’analyse syntaxique de graphes acycliques orientés (DAG) ou
les dysﬂuences sont données en entrée a l’analyseur comme segments préparenthésés. I1 faut
toutefois noter que cette approche n’est pas parfaitement équivalente a la méthode (T/D) dans

185 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

la mesure ou les segments préparenthésés seraient étiquetés par des symboles de dysﬂuences
qui sont absents de la grammaire de l’écrit. I1 faut toutefois rappeler que la méthode (T/D)
s’app1ique a un scénario d’annotation dans lequel les disﬂuences sont déja annotées. Les bonnes
performances de cette méthode semblent en effet provenir du fait qu’une partie du parenthésage
a prédire est donné. Dans un scénario d’analyse syntaxique de l’oral — a partir d’une source brute —
déployer cette méthode demanderait en particulier de réaliser un tagger en disﬂuences pour
l’oral dont les résultats sont supposés parfaits. Or l’étiquetage automatique de disﬂuences comme
les répétitions ou les révisions ne représente apparemment pas un probleme trivial.

7 Conclusion

Nous avons validé sur deux heures de transcription de débats radiophoniques et de dialoque
informel, une méthode d’analyse syntaxique du francais parlé, en constituants et en fonctions,
inspiré de ce qui se fait pour d’autres langues, et qui est une extension naturelle du FTB
pour le francais journalistique. Nous avons enrichi le guide d’annotation du FTB, adapté et
réentrainé l’analyseur de (Crabbé et Candito, 2008) et adapté une plate—forme d’annotation pour
la validation manuelle. Les premiers résultats sont encourageants, a la fois en ce qui concerne
les performances du parseur et les temps de correction. Les corpus radiophoniques annotés
(une heure trente de temps de parole, environ 27 000 mots) seront distribués dans le cadre du
consortium du projet Etape. Les annotations du dialogue c—ora1-rom (Cresti et al., 2004) sont
disponibles et le corpus distribué par Elra. La suite du travail consistera a annoter des corpus
oraux librement accessibles comme le corpus CID (Bertrand et al., 2008) ou CFPP (Branca—Rosoff
et al., 2012).

Remerciements

Les auteurs tiennent a remercier les annotateurs qui ont contribué a corriger les annotations :
Vanessa Combet, Floriane Guida, Antoine Lacambre et Mathilde Marié. Ceux—ci ont été ﬁnancés
par le projet ANR ETAPE (resp. G. gravier). Ce projet a aussi bénéﬁcié du ﬁnancement du PEPS
Syfrap (reps. C. Gardent) (CNRS INSHS INSII). Nous remercions Elisabeth Delais—Roussarie
qui a corrigé certaines transcriptions, Mathilde Dargnat avec qui nous avons établi la liste des
marqueurs de discours, Djamé Seddah pour l’aide au déploiement des outils de correction
ainsi que Claire Gardent et Christophe Cerisara pour les discussions permettant de comparer
annotations en constituants et annotations en dépendances.

Références

ABEILLE, A., COMBET, V et CRABBE, B. (2013). Conventions pour annotation syntaxique du
francais parlé. Rapport technique, Université Paris 7.

ABEILLE, A. et BARRIER, N. (2004). Enriching a french treebank. In Proceedings of LREC.

ABEILLE, A., CLEMENT, L. et TOUSSENEL, E (2003). Building a treebank for french. In ABEILLE, A.,
éditeur : Treebanks. Kluwer, Dordrecht.

186 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

BARRAs, C., GEOFFROIS, E., WU, Z. et LIBERMAN, M. (1998). Transcriber : a free tool for
segmenting, labeling and transcribing speech. In First International Conference on Language
Resources and Evaluation (LREC).

BERTRAND, R., BLACHE, R, ESPESSER, R., FERRE, G., MEUNIER, C., PR1EG0—VALvERDE, B. et RAUZY, S.
(2008). Le cid - corpus of interactional data - annotation et exploitation multimodale de parole
conversationnelle. TAL, 49(3).

BLACHE, R, BERTRAND, R., GUARDIOLA, M., GUENOT, M.—L., C.MEUNIER, NESTERENKO, I., PALLAUD,
B., PREVOT, L., PR1EGo—VALvERDE, B. et RAUZY, S. (2010). The OTIM formal annotation model : a
preliminary step before annotation scheme. In Proceedings LREC.

BLACHE, P. et RAUZY, S. (2012). Enrichissement du ftb : un treebank hybride consti-
tuants/propriétés. In Actes TALN, Grenoble.

BLANCHE-BENVENISTE, C. (1997). Approches de la langues parle'e en francais. Ophrys, Paris.
BRANCA-ROSOFF, S., FLEURY, S., LEFEUVRE, E et P1REs, M. (2012). Discours sur la ville. corpus de
francais parlé parisien des années 2000. Rapport technique, Université Paris 3.

CANDITO, M., CRABBE, B., DENIs, P. et GUERIN, F. (2009). Analyse syntaxique du francais : des
constituants aux dépendances. In TALN.

CER1sARA, C., GARDENT, C. et ANDERSON, C. (2010). Building and exploiting a dependency
treebank for french radio broadcast. In Proc. TLT9, Tartu, Estonia.

CRAEEE, B. et CANDITO, M. (2008). Expériences d’analyse syntaxique du francais. In TALN.
CREsTI, E., do NASCIMENTO, E B., MoRENo—SANDovAL, A., VERoNIs, J., MARTIN, R et CHOUKRI, K.
(2004). The c—oral—rom corpus. a multilingual resource of spontaneous speech for romance
languages. In LREC.

DEULOFEU, J., DUFORT, L., GERDES, K., KAHANE, S. et PIETRANDREA, P (2010). Depends on what
the french say : Spoken corpus annotation with and beyond syntactic function. In Linguistic
Annotation Workshop (LAW IV).

GRAVIER, G., ADDA, G., PAULssoN, N., CARRE, M., GIRAUDEL, A. et GALIBERT, O. (2012). The etape
corpus for the evaluation of speech—based tv content processing in the french language. In Proc
LREC.

HOEKSTRA, A., MOORTGAT, M., SCHUURMAN, I. et van der WOUDEN, A. (2000). Syntactic annotation
for the spoken dutch corpus project (cgn). In Computational Linguistics in the Netherlands (CLIN).
LEVY, R. et ANDREW, G. (2006). Tregex and tsurgeon : tools for querying and manipulating tree
data structures. In Proc. LREC.

MARCUS, M. P., SANTORINI, B. et MARCINKIEWICZ, M. A. (1993). Building a large annotated corpus
of english : The penn treebank. Computational Linguistics, 19(2):313—330.

METEER, M. (1995). Dysﬂuency annotation stylebook for the switchboard corpus. Rapport
technique, Upenn.

MIKULOVA, M. (2008). Rekonstrukce standardizovaného textu z mluvené feci V praisksém
zavislostnim korpusu mluvené cestiny. manual pro anotatory. Rapport technique 38, UFAL.
PETROV, S., BARRETT, L., THIBAUX, R. et KLEIN, D. (2006). Learning accurate, compact, and
interpretable tree annotation. In Proceedings of the 21st International Conference on Computatio-
nal Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages
433-440, Sydney, Australia. Association for Computational Linguistics.

SCHLUTER, N. et van GENABITH, J. (2007). Preparing, restructuring and augmenting a french
treebank : lexicalized parsers or coherent treebanks ? In Proceedings Pacling 2007, Melbourne.

187 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
3 Les données orales

Les données orales que nous uu'1isons sont des données du corpus ESTER 3 issues du projet ETAPE
(Gravier et al., 2012) dédié a l’évaluation de systemes de reconnaissance automatique de la
parole. Les données sont constituées d’extraits de débats de télévision et de radio francaises.

Les données annotées ici constituent un sous—ensemble de ce corpus constitué des émissions
radiophoniques de France Inter de l’année 2010 : cinq émissions de un temps de pauchon et une
émission du Masque et la plume, ce qui représente pres d’une heure trente de temps de parole.
Dans le premier cas il s’agit d’interviews non préparées donnant la parole a des inconnus. Dans
le second, il s’agit d’un débat public tres animé avec au moins dix journalistes sur le plateau,
plus des commentaires de spectateurs. Nous avons également un extrait du corpus francais
de CORAL-ROM (Cresti et al., 2004). L’extrait annoté est Eallumage (Poitiers 2001). CORAL-ROM
présente un type de conversation informel et spontané entre deux amies : qui représente 14
minutes de parole. Les données de référence ESTER 3 sont transcrites orthographiquement,
ponctuées et enrichies avec un balisage des difﬂuences, selon le format transcriber (Barras
et al., 1998). De maniere a uniformiser nos données de travail, nous avons également refor-
maté les données CORAL-ROM dans ce méme format. Au vu de 1’ extrait donné en Figure 1, on
constate que les données de départ sont déja structurées, en particulier on observe que l’on a un
balisage pour la musique <Event desc="musique" ty'pe="noise" extent="begin"/>
et les bruits parasites, un balisage pour les disﬂuences comme pour les marqueurs de dis-
cours <Event desc="dm" type=" lexical" . . . /> mais aussi les répétitions, les révisions
<Event desc="rev" type="lexica1" . . . > et les hésitations ainsi qu’une segmentation
en tours de parole. On distingue trois types de caractéristiques des données orales qui touchent a
la segmentation, la présence de chevauchements et a la présence de disﬂuences.

Segmentation Nous partons ici d’une transcription enrichie, c’est—a—dire avec des ponctuations
fortes, mais avec peu de ponctuations faibles, et pas de mots composés. On voit sur l’exemple
qu’un tour de parole ESTER peut comporter plusieurs phrases ou aucune. On a également observé
que certaines phrases recouvrent plusieurs tours de parole. On note ﬁnalement que la ponctuation
renseignée dans les transcriptions de départ n’a pas un statut clair : les annotateurs la renseignent
plut6t pour indiquer des pauses dans le ﬂux de parole que comme marque syntaxique. C’est
pourquoi nous avons revu la segmentation manuellement avant 1’analyse automatique.

Les chevauchements On trouve en particulier dans les transcriptions du Masque et la plume
un nombre non négligeable de chevauchements. Ceux—ci sont annotés dans le format ESTER en
suivant un schéma comme illustré en Figure 1 : ou la balise XML <0verlap> encode la portée
d’un chevauchement. L’attribut type indique le locuteur qui domine l’échange par la valeur
primary et celui que l’on entend moins est renseigné par la valeur backchalmel.

Les disﬂuences Outre les questions de segmentation et de chevauchements, les disﬂuences sont

typiques de l’oral. La transcription ESTER les renseigne sous forme de balises XML, on recense

ainsi quatre types de disﬂuences :

— Hésitations : euh

— Répétitions qui concernent la répétition a l’identique : qui a retardé un peu <nos> nos commen-
taires, qui avait e’te’ sérieusement amoche’ <au> au masque et la Plume, a été bluﬁe’ par le jeu
<de> de Morgan Freeman. . . )

— Révisions qui concernent des révisions de forme : <le>la grandiloquence, beaucoup <de>
d’auditeurs, autre chose <qu’un> qu’une guerre

176 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

<Turn speaker=“spk2“ startTime=“428.447“ endTime=“430.539“>
<Sync time=“428.447“/>
<Event desc=“rev“ type=“1exica1“ extent=“begin“/>
s1
<Event desc=“rev“ type=“1exica1“ extent=“end“/>
i1 y avait pas une route

<Sync time=“429.187“/>

<0ver1ap type=“primary“ extent=“begin“/>
qui desservait ce terrain

<Event desc=“dm“ type=“1exica1“ extent=“begin“/>
quoi

<Event desc=“dm“ type=“1exica1“ extent=“end“/>
7

<0ver1ap type=“primary“ extent=“end“/>
<0ver1ap type=“backchanne1“ extent=“begin“ speaker=“spk3“ subtype=“out—fie1d“/>
non i1 y avait pas une route .
<0ver1ap type=“backchanne1“ extent=“end“/>
</Turn>

FIGURE 1 — Extrait d’un ﬁchier Le Mas ue et la lume au format Transcriber
‘l P

— Marqueurs de discours qui sont des mots ou des locutions qui ont une Valeur illocutoire sans
avoir de fonction syntaxique dans l’énoncé comme par exemple ah, breﬁ mais bon voilc‘t, non
non non, na na na. ..

L’annotation des marqueurs de discours n’étant pas toujours cohérente, nous l’avons reprise,

avec une liste de 115 marqueurs (simples ou composés). En particulier les connecteurs, les

conjonctions de coordination en début de phrase, ou les pronoms disloqués, ne sont pas traités
comme des marqueurs de discours. De facon générale, nous traitons les balises de difﬂuences
comme des étiquettes de syntagmes, qui peuvent avoir une structure interne.

4 Le schéma d’annotation

Nous indiquons dans cette section les lignes directrices et les conventions adoptées pour l’annota—
tion en syntaxe des données de l’oral. Le schéma d’annotation est dérivé du schéma d’annotation
pour le treebank écrit (Abeillé et al., 2003).

On supprime les informations ayant trait au bruit et a la musique considérées comme extra-
linguistiques. Par contre on préserve les balises de synchronisation avec la piste sonore, notées
<Sync> dans ESTER 3 (Figure 1) encodées par des sous—arbres de racine Sync attachés avec les
mémes conventions que les disﬂuences. Nous présentons plus en détails dans la suite de cette
section les choix quant a la segmentation et a la gestion des dysﬂuences.

4.1 Linéarisation et segmentation des données orales

Comme pour l’écrit, une des premieres décisions a prendre lorsqu’on annote un corpus en syntaxe
porte sur la segmentation en mots. Contrairement au corpus écrit, la segmentation pour le corpus
oral minimise le nombre de mots composés. Nous nous sommes pour cela appuyés sur les travaux

177 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

antérieurs de (Crabbé et Candito, 2008) en ne retenant qu’un nombre minimal de mots composés,
en particulier des mots composés grammaticaux comme des conjonctions de subordination, de
coordinations, des déterminants, prépositions ...et quelques mots composés propres a l’oral
n’est-ce pas, s’il vous plait, tant pis. . . qui ont un impact sur la syntaxe et l’analyse de la phrase.
La liste exacte des mots composés est déﬁnie et documentée dans (Abeille et al., 2013).

Nous nous appuyons également sur une segmentation en phrases, meme si le choix de tel ou
tel découpage ne Va pas de soi. Plusieurs notions sont possibles : une notion phonétique ou la
phrase est délimitée par la durée des pauses, ce qui est le cas de la transcription ESTER 3, une
notion dialogique ou la phrase correspond a un tour de parole, une notion discursive ou la phrase
correspond a un acte de langage, et une notion syntaxique ou la phrase correspond a une plus
grande unité syntaxique complete (avec enchassement possible). Ici nous avons considéré qu’un
tour de parole non constitué uniquement de bruit ou de musique correspond au moins a une
phrase, méme fragmentaire. Un tour de parole peut lui-méme étre découpé en plusieurs phrases
racines. Nous nous appuyons pour cela sur des criteres syntaxiques, discursifs et prosodiques. Une
séquence autonome associée a un acte de langage forme une phrase racine. En revanche, nous ne
considérons pas qu’une phrase recouvre des tours de paroles différents, c’est-a-dire qu’une méme
phrase commencée par un locuteur soit terminée par un autre locuteur 1. En cas d’interruption et
pour repérer les syntagmes inachevés nous utilisons plutot une annotation d’inachevement (-INA)
comme étiquette supplémentaire sur les noeuds racine des syntagmes jugés inachevés.

Ces criteres étant donnés, voyons comment sont traités les cas de chevauchements. Les structures
a chevauchements ESTER 3 suivent un schéma tel qu’illustré en ﬁgure 2 a gauche (ou le balisage
XML est simpliﬁé). Pour gérer les cas de chevauchement dans l’annotation syntaxique, le principe
a été de fusionner les parties en backchalmel associées a un locuteur X au tour de parole
suivant (resp. précédent selon les cas) de ce locuteur X dans les données transcrites, ce qui
permet d’éViter de découper artiﬁciellement une phrase complete énoncée par ce locuteur X.
Par contre, pour préserver l’information, nous avons également introduit des marques dans
les arbres sous forme de noeuds feuilles pour indiquer la portée du chevauchement suivant le
schéma donné en ﬁgure 2. Chacun des quatre noeuds feuilles ainsi introduit dans les arbres est

<Turn speaker= "Y" >

w[y,1] . . . w[y,b-1]
<Uver1ap> SENT SENT
w[y,b+1]  w[y,e-1] 
</Uver1ap>
w[y,e+1] . . . w[y,n]
<Backcha.n.ne1 speaker="X"> y WW"‘W%b*1°"E”“”B’idWyab+1“‘W%’< “W“‘W%€'1°"e'1“”E“'W%€+1“‘WYv"
w[x, 1] . . . w[x,e-1]
</Backcha.n.ne1>
</Turn>
<Turn speaker = "X"> SENT  SENT
w[x,e+1] . . . w[x,n]
</Turn>
BackchannelBridw,(’2...wX’k wxl ...wx’e_1BackchannelEridwX’e+1 ...w,(,,,

FIGURE 2 — Encodage des chevauchements dans les arbres

1. Les annotations ESTER 3 comportent parfois plusieurs tours de paroles consécutifs pour un méme locuteur. Nous
avons refusionné ces séquences de maniére a éviter qu’une phrase prononcée par un méme locuteur ne soit artiﬁciellement
découpée.

178 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

de plus annoté par un identiﬁant unique (noté id dans le schéma) permettant d’identiﬁer a quel
chevauchement ce noeud fait re’fe’rence. Ce qui permet de ge’rer des chevauchements multiples
dans un meme document et dans un meme tour de parole. Notons que coder le chevauchement
sous forme d’un noeud non terminal dans les arbres ne serait pas sufﬁsamment général, car cela
empéche de coder des chevauchements qui portent sur plusieurs phrases ou des chevauchements
qui présentent des structures a croisementz

4.2 La gestion des disﬂuences

Les disﬂuences sont annotées dans les données ETAPE

par des balises XML qui groupent une séquence de SENT
mots comme étant disﬂuente. Schématiquement pour une
phrase w1...w,,, une disﬂuence a la forme suivante : D

w1...w,,_1(D)w,, ...we_1(/D)we...w,,.O1‘1 D représente un
code XML pour hésitation, révision, répétition ou marqueur
de discours. Les disﬂuences sont intra—phrasu'ques, peuvent
avoir une structure interne (dans le cas de répétions ou de
révisions par exemple) mais ne présentent pas de schémas
de croisement non projectifs. Nous les représentons comme des noeuds syntagmatiques dans les
arbres, comme illustré en Figure 3.

w1...w,,_1 w,,...we_1 we...wn

FIGURE 3 — Disﬂuences

L’attachement des disﬂuences dans les arbres de constituants n’étant pas naturellement détermi—
niste, nous choisissons d’attacher les répétitions au premier syntagme qui contient le matériel
répété, et les révisions au premier syntagme qui contient le matériel révisé. En cas d’hésitation
sur le noeud auquel attacher la disﬂuence, on tranche pour l’attachement au noeud le plus haut
dans l’arbre.

4.3 Les catégories utilisées

Catégories syntagmatiques AdP AP, COORD, NP, PP, VN, VPinf, VPpart
Sint (parenthétique ou incise), Srel (relative), Ssub (subordonnée), SENT (racine)
Catégories lexicales ADJ, ADJINT (adjectif interrogatif), ADV, ADVINT (adverbe interrogatif),
ADVEX (adverbe exclamatif), (V (indicatif qui inclut conditionnel), VINF (inﬁnitif)
VIMP (impératif), VPP (part passé), VPR (part présent), VS (subjonctif)
NC (nom commun), NPP (nom propre), CC (conj coord), CS (conj sub)
CLS (clitique sujet), CLO (clitique objet ou complément), CLR (clitique réﬂéchi)
P (preposition), P+D (au, du, des), P+PRO (auquel, duquel, desquels) PRO
PROINT (pronom interrogatif), PROREL (pronom relatif)
DET, DETINT (déterminant interrogatif), DETEX (déterminant exclamatif),
ET (mot étranger), I (interjection), UK (mots inachevés/ non reconnus)
HES, REP, REV,'DM
Symboles Fonctionnels SUJ,OBJ,A-OBJ,DE-OBJ,P-OBJ,MOD,ATS,ATO,DIS,VOC
Marque d’inachévement INA

TABLE 1 — Jeu d’étiquettes utilisé dans le treebank oral

Le schéma d’annotation est un format en constituants et en fonctions dont les arbres sont anno-
tées par un jeu d’étiquette utilisé par (Crabbé et Candito, 2008) et qui simpliﬁe le jeu d’étiquette

2. Formellement, les balises de chevauchement n’encodent pas nécessairement des structures d’arbres projectifs.

179 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

du treebank écrit quant aux jeux de symboles préterminaux (étiquettes morphosyntaxiques). On
ajoute a ce jeu d’étiquettes les symboles non terminaux HEs, REV, REP, DM qui encodent respecti-
vement les disﬂuences (hésitation, révision, répétition, marqueur de discours), et des symboles
supplémentaires SYNC, OVERLAPB, OVERLAPE,BACKCHANNELB,BACKCHANNELE qui encodent dans
les arbres les annotations de synchronisation son et de chevauchement extraites du format des
annotations ETAPE.

De plus, certains noeuds comportent des annotations structurées par plus d’un attribut. Ainsi en
plus de la catégorie syntaxique, on renseigne pour les noeuds arguments du verbe, c’est—a—dire
les noeuds fréres du noeud VN et les clitiques arguments leur fonction syntaxique prise parmi le
jeu décrit par (Abeillé et Barrier, 2004) auquel on ajoute deux nouvelles fonctions de vocatif et
de disloquées (notées Voc, DIS). Un troisieme attribut booléen (noté INA) peut étre renseigné sur
un noeud non terminal pour indiquer qu’il encode un syntagme inachevé.

4.4 Quelques observations

Statistiques descriptives Suivant ce schéma d’annotation nous avons annoté 2118 phrases des
corpus ESTER 3 et CORAL-ROM. En détaillant les différents sous—corpus, le treebank annoté se
résume par la table suivante :

Le masque et la plume Un temps de Pauchon CORAL-ROM(L’allumage) Total

Occurrences 15260 1 1 932 5050 32242
Phrases 795 882 441 21 18
Lg. moy. phrases 19.1 13.5 11.5 15.2

TABLE 2 — Statistiques descriptives

Observations qualitatives On observe un certain nombre de particularités déja mentionnées
pour 1’oral (Blanche—Benveniste, 1997). On observe une abondance de discours rapporté et
d’incises (incise notée Sint :MOD en 1), un nombre important de syntagmes inachevés et
d’énoncés fragmentaires. Un nombre important de phrases commencent par un marqueur discursif
(2) ou une conjonction de coordination ( phrase annotée comme COORD en 4) :

(1) (VN ils faisaient) (NP :OBJ (REV des :Det) (Sint :MOD je sais pas moi) des :Det trucs) (c-oral-rom)

(2) (DM bon-A alors-ADV) (VN raconte-moi) (NP :OBJ ton week-end) ) (c-oral-rom)

On observe aussi de nombreuses juxtapositions (comme en (3) ou on duplique la fonction P{[‘S) et
on peut parfois hésiter entre une annotation comme disﬂuence (révision ou répétition) ou comme
juxtaposition. A partir du moment on les disﬂuences ont la méme structure inteme que les autres
syntagmes, comme la répétition en (4) qui inclut deux syntagmes, un utilisateur qui serait en
désaccord peut choisir d’ignorer certaines balises de disﬂuences. Les répétitions intensives (5)
ne sont pas notées comme des disﬂuences. De méme les mots annotés comme marqueurs de
discours ont leur étiquette habituelle (par exemple A, V ou ADV) dominée par la balise DM,
comme en (2), qui peut aussi étre ignorée en cas de besoin :

(3) C’est (NP :ATS un grand couteau), (NP :ATS une sorte de hachoir) (un temps de pauchon)
(4) (COORD mais (REP (VN il y a) (NP :OBJ mélée)), (VN il y a ) (NP :OBJ mélée) (masque et la plume)
(5) Ils sont (AP :ATS tres-ADV tres-ADV laids-A) (masque et la plume)

180 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

SENT
Sync HES COORD PONCT
I {rm I
655.949 I CC REP VN NP—OEJ I-ES COORD .
I /\ /K I I Jm
Euh Mais VN NPOBJ CLS-SUJ CLO V N|C i C|C Sint
CLS-SUJ CLO V N:C  3|’ 3|: Inélée euh et NP-SUJ PP-MOD Sync V|N AP-.|ATS
{K ZR I
i] 3|’ 1 mélée DET NC PP P HES NP 662.004 V ADJ
I I /\ I I /\ I I
les opposants 1|’ N|P comme i N1|>P Ni’? sont solides
A NPP euh Pierre Murat

Lnvictus

FIGURE 4 — Exemple d’arbre du Masque et la plume (apres correction)

SENT
DM NP-MOD I-DES PONCT VN PP-P_OBJ PONCT
ADJ ADV PONCT I DET NC I ,| CLS-SUJ V VPP P NP
.,.',,. .1; I ,.I,,. I wee]!-end I. I J1 1'enI1'ée 1L1 P110

moi

FIGURE 5 — Exemple d’arbre de CORAL-ROM (apres correction)

5 Procédé d’annotation

Dans cette section nous décrivons plus précisément la méthode d’annotation qui a été déployée.
Ce11e—ci se divise en trois étapes séquentielles.

Segmentation et linéarisation des données Lors de cette premiere étape, nous avons segmenté
semi—automatiquement les données en phrases en nous appuyant sur la ponctuation donnée
par les données au format ESTER 3. La segmentation en phrases a été systématiquement validée
manuellement. Lors de cette étape 1e travail d’annotation a consisté tout d’abord a corriger la
ponctuation EsTER 3. Celle-ci ayant été réalisée principalement sur critéres phonétiques, elle a
été corrigée pour reﬂéter davantage une ponctuation grammaticale.

Lors de cette étape nous avons parfois rélinéarisé les données. En effet 1’annotation EsTER 3
n’impose pas de contrainte stricte quant a 1’ordre de la transcription lorsque plusieurs locuteurs
parlent simultanément. Nous avons identiﬁé quelques cas de structures syntaxiques bien forrnées
qui étaient interrompues par le tour de parole d’un autre locuteur. Pour ces quelques cas,
nous nous sommes permis de réordonner1’annotation pour restituer une cohérence quant a la
structuration du texte en phrases.

Finalement, nous avons normalisé la segmentation en mots. La segmentation en mots a été
réalisée de maniére a minimiser la quantité de mots composés en nous basant sur la liste établie
par (Crabbé et Candito, 2008). Sont retenus en priorité comme mots composés les mots composés
grammaticaux (notoirement les déterminants, conjonctions de subordination et de coordination).
La liste de (Crabbé et Candito, 2008) a été mise a jour et est documentée dans (Abeille et al.,
2013).

181 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

L’annotation syntaxique automatique la méthode d’analyse syntaxique repose sur l’hypothése
que la structure des phrases a l’oral n’est pas fondamentalement différente de celles de l’écrit.
C’est plutot la distribution de probabilité de la grammaire qui varie. Les données étant segmentées,
l’étape d’analyse syntaxique couvre les taches traditionnelles d’étiquetage morphosyntaxique,
de parsing et d’étiquetage fonctionnel. Nous n’avons pas utilisé explicitement d’étiqueteur
morphosyntaxique dans la mesure ou l’analyseur syntaxique utilisé (Petrov et al., 2006) est un
modele conjoint qui réalise déja le tagging.

Plus spéciﬁquement, la méthode d’analyse utilisée tire parti des annotations en disﬂuences
données par ESTER 3. L’analyse en constituants proprement dite est précédée d’un prétraitement
qui supprime de l’entrée les disﬂuences, les marques de chevauchement et les balises de synchro-
nisation avec la bande son. Celles—ci sont réintégrées dans les analyses en post—traitement. Les
arbres de dysﬂuences sont créés de maniere heuristique : la racine est la catégorie donnée par
ESTER 3, celle—ci domine systématiquement les noeud préterminaux (tags) étiquetés par un 2-CRF
linéaire (modéle appris sur le treebank écrit).

Les arbres sont ﬁnalement annotés en fonctions par un 2-CRF linéaire appris sur les données
écrites suivant la description donnée dans (Candito et al., 2009) : seuls les noeuds arguments du
verbe recoivent une étiquette fonctionnelle : il s’agit des noeuds en position frére des noeuds VN
et des noeuds clitiques (en position fréres du noeud V).

La correction manuelle L’étape de correction manuelle a consisté a corriger les annotations en
constjtuant et en fonctions. Notons que nous avons travaillé avec des représentations type Penn
Treebank ce qui a permis de réutiliser les interfaces graphique WordFreak destinée a l’édition
d’arbres en constituants et Tregex (Levy et Andrew, 2006) pour la visualisation et la recherche
de motifs, ce qui facilite considérablement le travail d’annotation. Cette partie du processus a
consisté en une premiere étape d’annotation suivie d’une étape de discussion/ adjudication entre
annotateurs.

Concemant les disﬂuences, la correction concerne leur structure inteme pour les révisions ou les
répétitions comme en (6) cu leur rattachement. En (7) on a une phrase en discours rapporté
(complément du verbe faire) réduite a un marqueur discursif. :

(6) moi, (REP (NP :SUJ ca-PRO) (VN-INA me-CLO) ) ca me dit rien, moi (c-oral-rom)

(7) Il me fait : (Sint :OBJ (DM ben si )).

Pour les catégories lexicales, on observe le meme type de corrections que pour l’écrit, concernant
le mauvaise étiquetage de mots grammaticaux fréquents et ambigus comme pour de (préposition
au lieu de déterminant) ou que (conjonction de subordination au lieu de pronom relatif). Les
autres erreurs concernent les mots non appris sur l’écrit comme les interjections, ou plus rares
comme les interrogatifs et les impératifs. Les formes verbales syncrétiques, fréquentes avec les
verbes du premier groupe au présent, sont ainsi systématiquement étiquetées indicatif alors
qu’il faut les corriger en impératif voire subjonctif. Pour les constituants aussi, on observe le
meme type de corrections que pour l’écrit concernant les mauvais rattachements de syntagmes
prépositionnels ou de relative. Les autres corrections concernent l’ajout de l’ étiquette INA quand
le syntagme inachevé est mal formé et le rattachement des disﬂuences (REP, REV). Pour les
fonctions, les corrections spéciﬁques concernent l’ajout des fonctions vocatif (8) et disloqué (9),
et la réduplication des fonctions pour les juxtapositions (10). Une partie des corrections est la
méme que pour l’écrit concernant les sujets inversés ou la distinction entre complément et ajout

182 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
pour les syntagmes prépositionnels.
(8) (DM Allez-V) (NP-Voc Catherine) (NP encore un tour) ! (1e masque et la plume)
(9) (NP :DIS moi-PRO), (NP :DIS ce qui me frappe), (VN c’-CLS-SUJ est) (NP-ATS la ﬁn). (1e masque et la plume)

(10) (NP-SUJ des chanteurs) ,(NP-SUJ des musiciens) (VN sont passés) dans ce théétre (un temps de pauchon)

On compte 8 a 10 heures pour 100 phrases environ (en double correction). Au total, pour la
correction des transcriptions et la segmentation (avant parsing) et la correction des analyses
(aprés parsing), nous avons employé 4 annotateurs pour un total de 12 hommes-mois : 3 étudiants
de Paris 7 en linguistique (M2) ou en linguistique informatique (M1), et une ancienne étudiante,
spécialiste du FI‘B (Vanessa Combet).

6 Evaluation

Cette section propose une évaluation et une mise en perspective de la méthode de préannotation
syntaxique (étape 2 du processus d’annotation), qui est l’étape clé du processus. La question que
l’on se pose lorsqu’on veut annoter un corpus hors domaine consiste a déterminer la meilleure
maniere d’amorcer la préannotation des données de maniere a faciliter la tache des annotateurs
sachant qu’on dipose d’un modele d’analyse pour le domaine source.

En terrnes d’analyse syntaxique, l’annotation d’un corpus oral tombe dans la classe des problemes
d’adaptation de domaine. Celui—ci comporte deux aspects. Premiérement il s’agit d’adapter la
structure : en effet nous avons vu que le schéma d’annotation de l’oral introduit de nouvelles
structures et de nouvelles catégories liées aux disﬂuences. En second lieu il faut adapter la distri-
bution de probabilité de la grammaire. Il s’agit du probléme classique d’adapter la distribution de
probabilité d’un modéle probabiliste entrainé sur un échantillon de données biaisé (un corpus
écrit) a un échantillon possédant des propriétés différentes (corpus oral).

De maniére a apporter une premiere idée de la correction de méthodes d’adaptation simples,
nous comparons ici quatre méthodes qui tirent parti des données a la fois écrites et orales pour
faciliter le processus de préannotation :

— Utilisation des données écrites uniquement (E) : Cette méthode de base consiste a analyser
les données orales en utilisant uniquement un modéle d’analyse appris sur l’intégralité des
données écrites (21268 phrases). Utiliser cette méthode de base ne permet pas d’envisager
analyser correctement les structures propres a l’oral (dysﬂuences). Il s’agira essentiellement de
notre baseline.

— Approche par transformation/détransformation des données (T/D) : Cette méthode

consiste a prétraiter les données orales en supprimant les disﬂuences (balisées dans les données
ESTER 3) de l’entrée donnée a l’analyseur syntaxique. Ce dernier, entrainé sur l’ensemble des
données écrites (21268 phrases), doit alors prédire pour l’oral des structures qui ressemblent a
celles de l’écrit. Une étape de post traitement réinsere ﬁnalement dans les arbres d’analyse les
dysﬂuences supprimées en prétraitement.
Chaque disﬂuence de k mots ainsi réinsérée est un arbre dont la racine est la catégorie de la
dysﬂuence (donnée par ESTER 3). La racine domine immédiatement une séquence de k—tags
étiquetées par un 2CRF linéaire appris sur le treebank écrit, chacun de ces k—tags domine le
mot correpondant.

183 © ATALA

