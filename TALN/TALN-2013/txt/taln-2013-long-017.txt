TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Chunks et activation : un modéle de facilitation du traitement
linguistique

Philippe Blache
Aix-Marseille Université, CNRS, LPL
5 Avenue Pasteur, 13100 Aix-en-Provence
b1ache@1p1—aix . fr

RESUME
Nous proposons dans cet article d’intégrer la notion de chunk au sein d’une architecture globale
de traitement de la phrase. Les chunks jouent un r6le important dans les théories cognitives
comme ACT—R (Anderson et al., 2004) : il s’agit d’unités de traitement globales auxquelles
il est possible d’accéder directement via des buffers en mémoire a court on long terme. Ces
chunks sont construits par une fonction d’activation (processus cognitif pouvant étre quantiﬁé)
s’appuyant sur l’évaluation de leur relation au contexte. Nous proposons une interprétation de
cette théorie appliquée a l’analyse syntaxique. Un mécanisme de construction des chunks est
proposé. Nous développons pour cela une fonction d’activation tirant parti de la représentation
de l’information linguistique sous forme de contraintes. Cette fonction permet de montrer en
quoi les chunks sont faciles a construire et comment leur existence facilite le traitement de la
phrase. Plusieurs exemples sont proposés, illustrant cette hypothese de facilitation.

ABSTRACT
Chunks and the notion of activation : a facilitation model for sentence processing

We propose in this paper to integrate the notion of chunk within a global architecture for
sentence processing. Chunks play an important role in cognitive theories such as ACT—R cite
Anderson04 : they constitute global processing units which can be accessed directly via short or
long term memory buffers. Chunks are built on the basis of an activation function evaluating
their relationship to the context. We propose an interpretation of this theory applied to parsing.
A construction mechanism is proposed, based on an adapted version of the activation function
which takes advantage of the representation of linguistic information in terms of constraints.
This feature allows to show how chunks are easy to build and how they can facilitate treatment.
Several examples are given, illustrating this hypothesis of facilitation.

MOTS-CLES : Chunks, ACT—R, activation, mémoire, parsing, traitement de la phrase, experimen-
tation.

KEYWORDS: Chunks, ACT—R, activation, memory, parsing, sentence processing, experimentation.

229 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
1 Introduction

L’interprétation d’un énoncé, a commencer par son traitement syntaxique, peut étre plus ou
moins facile pour un sujet humain. Plusieurs travaux proposent des éléments d’explication de
cette variabilité. Au niveau syntaxique, des travaux proposent par exemple des explications en
termes de distance pour une relation a établir entre deux éléments, une grande distance étant
plus complexe a traiter qu’une plus faible (Gibson, 1998) ; (Grodner et Gibson, 2005). D’autres
travaux portent sur l’identiﬁcation d’un niveau d’acu'vation des items en s’appuyant notamment
sur des relations avec le reste de la structure en cours de construction (Lewis et Vasishth, 2005).
Dans tous les cas, ces modeles de difﬁculté abordent la question d’un point de vue global, en
tentant d’identiﬁer les parametres pouvant complexiﬁer le traitement. Nous proposons dans cet
article d’aborder un point de vue complémentaire en tentant d’identiﬁer des facteurs qui au
contraire peuvent permettre de faciliter le traitement.

En se situant dans l’hypothese d’un traitement incrémental du langage, dans laquelle les mots
sont intégrés au fur et a mesure de leur décodage dans une structure en cours de construction, des
travaux antérieurs ont montré la possibilité de mesurer la quantité d’information linguistique 1
disponible au moment de l’intégration d’un mot. Dans les cas ou le niveau d’information est
élevé, le traitement (la compréhension) s’en trouve facilité. En revanche, un déﬁcit d’information
entraine une complexiﬁcation du traitement. En termes computationnels, la quantité d’informa-
tion disponible permet de contr6ler l’espace de recherche requis pour l’interprétation d’un énoncé.
Une construction associée a une faible quantité d’information est trés ambigué et donc difﬁcile 2
traiter car le nombre d’interprétations possibles (donc l’espace de recherche) est tres grand. En
revanche, une construction pour laquelle une grande quantité d’information (éventuellement
redondante) est disponible sera peu ou pas ambigué, son espace de recherche plus restreint et son
traitement (son interprétation) devient plus facile. Dans certains cas, il n’y a aucune ambiguité, le
traitement est alors purement déterministe. La quantité d’information est dans ce cas un facteur
de simpliﬁcation du traitement et non pas de complexiﬁcation.

D’une facon générale, la quantité (ou densité) d’information disponible est variable selon les
parties de l’énoncé ou de la phrase. L’hypothese que nous formulons est que les zones comportant
une densité d’information importante sont traitées plus facilement que les autres. Dans certains
cas, ces zones de haute densité peuvent étre traitées d’un bloc. Nous nous intéressons dans cet
article a cette idée que le processus d’intégration syntaxique pourrait se faire au niveau de ces
zones plut6t qu’au niveau des mots. Une présence plus importante de zones de haute densité
d’information dans un énoncé ou une phrase faciliterait ainsi son traitement. Cette idée s’appuie
sur le principe Maximize On—Line Processing (noté MoP) proposé dans (Hawkins, 2003) :

The human parser prefers to maximize the set of properties that are assignable to each item X as X is
parsed. [...] The maximization diﬁerence between competing orders and structures will be a function
of the number of properties that are misassigned or unassigned to X in a structure S, compared with
the number in an alternative.

Ce principe comporte plusieurs éléments. Il integre tout d’abord l’idée selon laquelle, dans
un processus incrémental, l’intégration d’un mot repose sur la vériﬁcation d’un ensemble de
propriétés. Il indique également que deux constructions peuvent se distinguer par le nombre
de propriétés qu’elles vériﬁent. La notion de densité d’information recoupe donc ce principe de

1. On entend ici par information linguistique toute propriété morpho-syntaxique ou syntaxique caractérisant la
structure en cours de construction.

230 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Le jotL1"nal:Lste qui cmtiqua

Det all Frail V
net { N / Le jlaurnalvlste qui critigua
D“ ”‘” N N '0 D t N P R V
Det a II E H’

(a) Activation du N (b) Construction du chunk [Det , N]

FIGURE 5 — Activation et construction de chunk

Le journalists qui critiqua Ee sénateur admit sun erreur.
Dem N ProR «-V [Jet N V Det N

ProR[suj] 4 V
ProR[suj]  ‘V
ProR[suj] «» N V-
ProR[suj] :,» V

FIGURE 6 — Activation et construction de chunk, suite

Ce processus appliqué a la suite des catégories de la phrase permet de construire la suite de
chunks illustrée par la ﬁgure 7.

4.2 Les chunks, mécanisme de facilitation

L’hypothése que nous défendons repose tout d’abord sur l’idée que les chunks sont construits
directement, sur la base de mécanismes tirant parti a la fois de critéres de fréquence et de
densité de relation. Les mécanismes conduisant a la construction de chunks ne sont donc pas
les mécanismes classiques de l’analyse syntaxique : le probléme posé consiste a mesurer les
relations unissant deux catégories adjacentes alors que l’analyse syntaxique consiste a intégrer
une catégorie a une structure syntaxique globale. I1 s’agit donc de mécanismes de bas niveau,
effectués tres rapidement.

Une fois construits, ces chunks sont stockés en mémoire et accessibles directement, comme
indiqué dans la théorie ACT-R. Notre hypothese consiste done a dire que les chunks facilitent le
traitement. Leur accés se faisant en bloc, il revient du point de vue cognitif a un accés lexical. De
plus, leur intégration se fait également de facon globale. Par conséquent, la présence de chunks
dans un énoncé ou une phrase en facilitera le traitement par rapport a d’autres situation on
1’intégration devra se faire mot par mot. Autrement dit, une phrase contenant un grand nombre
de chunks sera plus facile a traiter qu’une phrase qui en contiendra moins.

Illustrons cette hypothese en revenant sur le cas des phrases relatives. Les travaux en psycholin—
guistique (Gibson, 2000), conﬁrmés par plusieurs études expérimentales (Fedorenko et al., 2006),
(Demberg et Keller, 2009) ont montré que les relatives objet sont plus difﬁciles a traiter que les

Le jam’-rml.-isle qui. criltiqua le sévmteur adnr-I31. sun 8!"!"Eli|"
Det N PIOF. V Prok V V Det N

FIGURE 7 — Construction des chunks pour la phrase complete
239 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Le jaumnliste que le sénateur critique azim-it son e'r-'r'e1u‘.
Der. N Proll Det N V V Det N

ProR[obj] 4 NP
ProR[o‘bj] «I.» S//VP ? a‘???
ProR[u~bj] 2» S

La Journalists que la sérmteur‘ criti qua. admit sun erreur
Der. N ProR Proll V V V D91: N

FIGURE 8 — Cas de la relative objet

relatives sujet. Ce phénoméne se retrouve au niveau de la construction des chunks. Nous avons vu
en effet dans l’exemple de la ﬁgure 7 que la relative sujet conduisait a la construction d’un chunk
entre le pronom relatif et le verbe. La phrase correspondante contient ainsi 4 chunks au total.
La ﬁgure 6 illustre ce phénomene par 1’impossibi1ité de construire un chunk contenant le relatif.
Celui—ci active bien un certain nombre de catégories, mais aucune d’entre elle ne correspond
directement a la catégorie adjacente. Au total, la phrase contenant la relative objet ne contient
que 3 chunks. Cet exemple ne prétend bien entendu pas ériger le role des chunks en théorie de la
difﬁculté syntaxique comme proposé par (Gibson, 2000). Elle illustre cependant des différences
de fonctionnement pouvant accompagner ou compléter ces modeles.

5 Conclusion

Nous avons présenté dans cet article une approche proposant de donner une place centrale a
la notion de chunk dans le processus de traitement de la phrase par des sujets humains. Nous
utilisons pour cela l’architecture de traitement des processus cognitifs élaborée dans le cadre de
la théorie ACT—R. Cette approche précise le role joué par les chunks en mémoire. Elle introduit
de plus une notion d’activation permettant d’expliquer la rapidité de traitement de ces objets.
Appliquée a la question de l’analyse syntaxique (ou du traitement de la phrase si l’on se situe
dans une perspective psycholinguistique), cette théorie offre un cadre permettant de décrire la
construction et le role joué par ces chunks.

En tirant parti d’une description des inforrnations syntaxiques basée sur les contraintes (dans le
cadre des Grammaires de Propriétés), nous avons proposé une évaluation de la notion d’activation
servant de base a la construction des chunks. Il s’agit d’un mécanisme de bas niveau, n’ayant
pas recours a l’analyse syntaxique a proprement parler et qui permet la construction d’unités de
niveau supra—lexical facilitant le processus car accessibles directement en mémoire. L’utilisation de
telles unités correspond a des observations expérimentales, notamment de mouvement oculaire,
montrant que les chunks correspondent a des unités de traitement pertinentes.

Il reste a évaluer la validité de l’hypothese de facilitation des chunks de facon expérimentale. Il
s’agira notamment de vériﬁer que la construction des chunks est un processus de bas niveau et que
leur accés correspond a un acces lexical en complétant les observations de mouvement oculaire
par des expériences a l’aide de potentiels évoqués et de localisation de source. L’étape suivante
consistera a vériﬁer la facilitation induite par les chunks en termes de temps de traitement.

240 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
Remerciements

Ce travail réalisé dans le cadre du Labex BLRI (http ://www.blri.fr) portant la référence ANR-11-
LABX—0036 a bénéﬁcié d’une aide de l’Etat gérée par l’ANR au titre du projet Investissements
d’Avenir A*MIDEX portant la référence ANR-1 1-IDEX-0001-02.

Références

ABEILLE, A., CLEMENT, L. et TOUSSENEL, E (2003). Building a treebank for french. In ABEILLE, A.,
éditeur : Treebanks, Kluwer, Dordrecht.

ABNEY, S. (1991). Parsing by chunks. In Principle—Based Parsing. Kluwer Academic Publishers,
pages 257-278.

ANDERSON, J. R., BOTHELL, D., BYRNE, M. D., DOUGLASS, S., LEBIERE, C. et QIN, Y. (2004). An
integrated theory of the mind. Psychological Review, 111(4):1036—1060.

BIRD, S., KLEIN, E. et LOPER, E. (2009). Natural Language Processing with Python. O’Reilly Media.

BLACHE, P (2001). Les Grammaires de Propriétés : Des contraintes pour le traitement automatique
des langues naturelles. Hermes.

BLACHE, P (2012). Estimating constraint weights from treebanks. In Proceedings of CSLP.

BLACHE, P et RAUZY, S. (2011). Predicting linguistic difﬁculty by means of a morpho—syntactic
probabilistic model. In Proceedings of PACLIC 201 1, december 201 1, Singapour.

DEMBERG, V et KELLER, E (2008). Data from eye—tracking corpora as evidence for theories of
syntactic processing complexity. In Cognition, volume 109, Issue 2, pages 193-210.

DEMBERG, V et KELLER, E (2009). A computational model of prediction in human parsing :
Unifying locality and surprisal effects. In Proceedings of the 31st Annual Conference of the
Cognitive Science Society, pages 1888- 1893.

DUCHIER, D., PROST, J.-P et DAO, 'I‘.-B.-H. (2009). A model—theoretic framework for grammatica-
lity judgements. In Conference on Formal Grammar (FG’09).

FEDORENKO, E., GIBSON, E. et ROHDE, D. (2006). The nature of working memory capacity in
sentence comprehension : Evidence against domain—speciﬁc working memory resources. Journal
of Memory and Language, 54(4):541—553.

GIBSON, E. (1998). Linguistic complexity: locality of syntactic dependencies. Cognition, 68:1-76.

GIBSON, E. (2000). The dependency locality theory : A distance—based theory of linguistic
complexity. In Image. A. Marantz, Y. Miyashita, W. O’Neil (Edts).

GRODNER, D. J. et GIBSON, E. A. E (2005). Consequences of the serial nature of linguistic input
for sentenial complexity. Cognitive Science, 29:261-291.

HALE, J. (2001). A probabilistic earley parser as a psycholinguistic model. In Proceeding of
2nd Conference of the North American Chapter of the Association for Computational Linguistics,
Pittsburgh, PA.

HAWKINS, J. (2003). Efficiency and complexity in grammars : Three general principles. In
MOORE, J. et POLINSKY, M., éditeurs : The Nature of Explanation in Linguistic Theory, pages
95-126. CSLI Publications.

241 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
LEWIS, R. L. et VASISHTH, S. (2005). An activation—based model of sentence processing as skilled
memory retrieval. Cognitive Science, 29:375-419.

RAUZY, S. et BLACHE, P. (2012). Robustness and processing difﬁculty models. a pilot study
for eye—tracking data on the french treebank. In Proceedings of the 1st Eye-T racking and NLP
workshop.

REITTER, D., KELLER, F. et MOORE, J. D. (2011). A computational cognitive model of syntactic
priming. Cognitive Science, 35(4):587—637.

242 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

maximisation : un mot sera plus ou moins facilement intégré a la structure selon que le nombre
de propriétés qui lui sont associées est important ou pas.

Notre hypothese est que ces unités, déﬁnies par maximisation, correspondent en termes de
traitement a des chunks tels que décrits dans les théories cognitives de type ACT—R (Adaptive
Character of T hought—Rational (Anderson et al., 2004)) et peuvent a ce titre étre stockés en
mémoire a court terme et bénéﬁcier d’un accés direct.

2 Chunks et activation

La notion de chunk est bien connue en TAL, et généralement déﬁnie comme une suite de
catégories non récursive, formée d’une téte, a laquelle peuvent étre adjoints mots fonctionnels et
modiﬁeurs adjacents (Abney, 1991) ; (Bird et al., 2009). Nous nous intéressons dans cet article a
la facon dont ces chunks peuvent étre construits, dans le cadre d’un processus incrémental, par
un parseur humain.

2.1 Les chunks dans les théories cognitives

Le traitement du langage, comme celui des activités cognitives de haut niveau, repose sur la
capacité d’identiﬁer des unités de traitement pouvant étre de taille et de nature variable. Cette
idée est plus particuliérement développée par la théorie ACT—R et son adaptation au langage
(Lewis et Vasishth, 2005), (Reitter et al., 2011) dans laquelle les mécanismes de traitement
s’organisent autour de buffers (jouant comme en informatique le r6le de mémoire tampon)
pouvant mémoriser des chunks. Un chunk est dans cette approche décrit comme un ensemble de
propriétés caractérisant une catégorie (ou une unité de plus haut niveau), pouvant par exemple
contenir une structure syntaxique partielle (Lewis et Vasishth, 2005). Les chunks sont représentés
en ACT—R par des structures de traits et peuvent représenter des objets atomiques ou complexes,
offrant la possibilité pour un chunk de faire référence a un autre chunk et exprimer ainsi des
relations. La déﬁnition d’un chunk est donc trés générale et permet de référencer des structures
incomplétes ou sous—spéciﬁées.

La théorie ACT—R s’intéresse d’une part aux processus de base et d’autre part aux structures de
mémoire sur lesquelles ils s’appuient. Elle distingue notamment entre mémoire procédurale et
déclarative, cette derniére permettant de stocker a la fois des informations lexicales (a long terme)
mais également les structures nouvelles (a court terme). La me’moire de’c1arative repose sur un
petit nombre de buffers, chacun contenant un chunk. L’élément important de cette organisation
réside dans le fait que ces chunks forment une unité et sont utilisables (ou accessibles) directement
en mémoire. Cette accessibilité est soumise a un niveau d’activation dépendant de plusieurs
paramétres : degré de latence depuis le demier acces, poids des éléments associés au chunk et qui
peuvent l’activer (les sources), mais également force des relations associant les sources au chunk
considéré. Il est ainsi possible de proposer une formule permettant de quantiﬁer l’activation d’un
chunki :

A,- = 13,. +21/I/,.s,., (1)
1'

231 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

N _ T T ‘ f T T O f . ' f 7‘
‘g - r E 5 I ‘ 5 II E T 1 E E
g (D — : 1 ' ; I I : - E 1 ' 1
.1 «o ~ +' I I I I I + I I I +
" N — I I I . - I l . -
C, _ ‘ . 1 L J_ L 4 I ' L 4 l I
I I I I I I I I I I I I I I I
Adj Adv AdvNeg Aux Cllll Corusub Det lnterj Noun Pct Prelt Prep Pro Verb
morpho synta cii I: category

FIGURE 1 — Nombre de ﬁxations par catégorie

Dans cette formule, B représente l’activation de base (fréquence et historique de l’accés au
chunk), W correspond aux poids des termes en relation avec le chunk et S la force des relations
reliant ces termes au chunk. Il est donc possible de caractériser un chunk en fonction de son
niveau d’activation. Le point important qui nous intéresse ici réside dans le fait que cette
activation est en partie dépendante des relations avec le contexte. En d’autres termes, la force des
relations permettra d’activer de facon plus ou moins importante un chunk (et donc la catégorie
correspondante). Or, l’activation d’un chunk contréle a la fois sa probabilité et la vitesse de son
acces : un chunk fortement activé sera ainsi accessible tres rapidement.

On remarquera que cette approche est compatible avec le principe MoP de Hawkins (cf. section
précédente) : les relations activant un chunk peuvent étre vues comme des propriétés dont on
recherche la maximisation.

Dans le cadre du traitement du langage et plus particuliérement de l’analyse syntaxique, notre
hypothése est que les chunks facilitent l’analyse d’un énoncé. Plus précisément, les énoncés
comportant des chunks hautement activés sont traités plus facilement que les autres.

2.2 Une observation expérimentale des chunks dans le traitement de la
phrase

Dans le cadre d’une expérience récente, consistant a acquérir des données de mouvement oculaire
de sujets lisant le French Treebank (Rauzy et Blache, 2012), nous avons observé un phénomene
intéressant en relation avec les chunks. Le nombre de ﬁxations du regard par mot différe en
effet fortement en fonction de la taille du mot, mais également de sa catégorie. La ﬁgure 1
représente le nombre moyen de ﬁxations par catégorie. On observe ainsi que les catégories a
contenu lexical (N, r; Adj, Adv) ont un nombre de ﬁxations du regard nettement plus élevé que
les mots grammaticaux (Det, Prep, Clit, etc.).

Ce phénomene peut étre mis en relation avec l’étude de l’évolution de l’indice de surprise (Hale,
2001) dans une phrase. Cet indice reﬂéte une probabilité d’intégration de chaque mot dans la
structures syntaxique en cours de construction (calculé comme une fonction de la différence de
probabilité entre les structures précédant et celle intégrant le mot courant). Plusieurs expériences
ont montré qu’il était un bon prédicteur du temps de lecture, pouvant donc étre utilisé comme

232 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

mnrphus vntacl i: imrpriil

 

\z, . is Q o 1 \-2. K c. o\ <. 1, _¢ :7 la . ‘>\ -x. E 1. o e,
on '3 $\ .95? és ) <9 \ =- gt 35k 0 12.?“ kc ‘$0 a, oi»
b?

’b
\ \ \) \
<9 D 9'“ be» '15 L, 5 o 9‘ ‘° 0°
902' 99° \ 5»; da ’ 2.“? I3’; ‘E’ ,_a‘7’$\ <&‘\
0°-1 61$ ‘#2? , \>
‘is \‘

FIGURE 2 — Evolution de l’indice de surprise dans une phrase

mesure de diﬁiculté (voir (Demberg et Keller, 2008) pour l’anglais et (Rauzy et Blache, 2012)
pour le francais). Un indice de surprise peut donc étre associé a chaque mot de la phrase. La ﬁgure
2 illustre l’évolution de la valeur de cet indice (calculé selon la méthode décrite dans (Blache
et Rauzy, 2011)) sur une phrase. On remarque la aussi un phénoméne intéressant, soulignant
la succession d’indices élevés et faibles en fonction de la catégorie : les mots grammaticaux
correspondent systématiquement a un indice de surprise plus élevé que les mots lexicaux auxquels
ils sont associés.

Ces deux observations sont convergentes : la ﬁxation du regard en lecture englobe en un seul
mouvement le token lexicalisé et les mots grammaticaux qui lui sont associés, ce qui peut étre
prédit au niveau de l’évolution de l’indice de surprise. Elles confortent donc l’hypothése d’un
traitement non pas au niveau du mot, mais directement par chunk, chaque fois que c’est possible.

2.3 Hypothése

La théorie ACT—R appliquée au langage fait l’hypothese que le traitement linguistique d’intégration
repose sur des chunks. Ceux—ci sont des structures partielles, pouvant étre a la fois stockées dans
la mémoire a long terme, mais également construites en temps réel, en mémoire a court terme.
Ces chunks reposent sur une notion d’activau'on, elle-méme correspondant au principe Maximize
Online Processing : l’intégration d’un mot a une structure (par exemple l’association de deux
catégories pour construire un chunk) repose sur la vériﬁcation d’un maximum de propriétés.
La force des relations unissant un objet avec des éléments qui le précédent permet d’activer
fortement cet objet.

Nous émettons l’hypothése que les chunks facilitent le traitement linguistique. Nous nous ap-
puyons pour cela sur trois aspects :

1. Les chunks sont construits en mémoire sur la base du processus d’activation, qui ne
correspond pas a une véritable analyse syntaxique. Leur construction peut reposer sur des
mécanismes de bas niveau (comme la fréquence de cooccurrence) ou sur l’accumulation de
propriétés ou relations entre deux catégories. Lorsqu’une catégorie est fortement activée
par une ou plusieurs catégories précédentes, elle formera un chunk avec elles. Dans la
plupart des cas, ces chunks sont formés d’une suite [mot grammatical + mot lexical].

233 © ATALA

TALN-RBCITAL 2013, 17-21 Iuin, Les Sables d’Olonne

2. Les chunks sont stockés en mémoire déclarative et accessibles directement. Certains chunks
peuvent étre tres fréquents voire correspondre a des suites plus ou moins ﬁgées (par
exemple dans des collocations). Dans ce cas, ils sont stockés en mémoire along terme. Les
chunks construits dynamiquement sur la base d’une activation sont quant a eux disponibles
dans des buffers de traitement a court terme.

3. La présence de chunks dans une phrase facilite son traitement : ils sont accessible d’un bloc
et ne nécessitent pas d’analyse. Une phrase contenant des chunks sera plus facile a traiter
qu’une autre n’en contenant pas.

La question qui se pose est celle de la notion d’activation, son évaluation et sa mise en oeuvre
dans le processus de construction des chunks. Nous proposons pour cela d’uti1iser la description
des propriétés syntaxiques sous la forme de contraintes. Maximiser les propriétés (et donc activer
une catégorie) correspond ainsi a la maximisation de l’ensemble des contraintes a satisfaire.
Nous utilisons pour cela la représentation proposée dans le cadre des Grammaires de Propriétés
(Blache, 2001).

3 Propriétés et activation

Nous présentons dans cette section les principales caractéristiques de l’approche des Grammaires
de Propriétés (Blache, 2001) utilisées pour déﬁnir la notion d’activation. Elle repose sur la
représentation des informations syntaxiques sous la forme d’un ensemble de propriétés pouvant
étre décrites, suivant la proposition de (Duchier et al., 2009), comme des relations caractérisant
un syntagme (ici noté A) et mettant en relation des constituants (notés B, C ou S) :

Obligation A : AB au moins un B

Unicité A : B! au plus un B

Linéarité A: B —< C B précéde C

Implication A : B => C si EIB, alors EIC

Exclusion A: B §E> C pas de B et C simultanément
Constituance A: S? les descendants E S
Dépendance A: B w> C B dépend de C

Une Grammaire de Propriétés associe a chaque syntagme un ensemble de contraintes. Le tableau
suivant illustre la grammaire du syntagme adjectival (noté SA) (extraite du French Treebank, cf.
(Abeillé et al., 2003)). Soulignons au passage la compacité de la représentation : 22 contraintes
sont utilisées pour décrire les constructions possibles du SA 2.

Constituance AP : {AdP A, VPinf, PP Ssub, AP NP}?
AP : A < {VPinf, Ssub, PP NP AP}

Lin AP : AdP < {A, Ssub, PP}

AP : AP < {A, AdP}

AP : PP -< {Ssub}

Dépendance AP : {AdP VPinf, PP Ssub, NP} w> A

Unicité AP : {A, VPinf, Ssub} !
Obligation AP : A A
Exclusion AP : VPinf §E> {PP Ssub}

2. Le jeu d’étiquettes utilisé est celui du FTB, notantAP pour syntagme adjectival, AdP pour syntagme adverbial, etc.
234 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

mm

     
    
    
  
  
  
 

Dct

L.

N

md.u.=u'ic

Ncmsu

en

Vmps-smuip-»

Adj
capable

Nam 5--

[res

Ds3msp---

FIGURE 3 — Graphe des propriétés satisfaites pour “L’indu.strie est trés capable.”

Une analyse dans le cadre de GP consiste, pour une suite de catégories donnée, a évaluer
l’ensemble des propriétés correspondantes. Une propriété correspondant a une relation entre une
ou plusieurs catégories, le résultat de l’analyse est donc un graphe comme représenté dans la
ﬁgure suivante illustrant l’analyse de la phrase “L’industrie est trés capable.”, extraite du FTB. Ce
graphe indique les propriétés satisfaites entre les différentes catégories composant la structure
syntaxique. Par exemple, la contrainte de linéarité entre le déterminant et le nom est représentée
par un arc reliant les deux noeuds correspondants) :

Construire une analyse syntaxique dans ce type d’approche consiste donc a chaque étape a par-
courir le systemes de contraintes en évaluant celles qui correspondent aux catégories concernées.
Dans une perspective incrémentale, il est donc possible a chaque étape de connaitre les relations
qui concernent le mot ou la catégorie a analyser. Cette caractéristique constituera la base de la
déﬁnition de la notion d’actiVation utilisée ici.

Par ailleurs, il est possible de distinguer deux constructions en fonction du nombre de relations
permettant de les caractériser. Dans l’exemple précédent, le SA est formé d’un adjectif accompagné
d’un modiﬁeur adverbial. L’exemple suivant illustre une construction légérement différente d’un
SA, correspondant a la phrase “Eindustrie est capable d’investi1:” dans laquelle une inﬁnitive
est complément de l’adjectif. Dans ce cas, conformément a la grammaire du SA décrite plus
haut, un plus grand nombre de contraintes sera Vériﬁée, la densité du graphe est donc plus
importante. Le nombre de propriétés vériﬁées joue un role important en offrant la possibilité
de quantiﬁer l’information syntaxique. Dans la perspective du principe MOP, la maximisation
reposera précisément sur cette capacité.

Un des avantages de cette approche réside dans sa souplesse : il est toujours possible d’éValuer
les relations existant entre deux catégories, sans qu’il ne soit nécessaire de construire de structure
syntaxique. Cette caractéristique répond au besoin d’éValuation de la notion d’actiVation d’une
catégorie : celle-ci sera dépendante du nombre et de la force des relations existant entre un mot
et les catégories qui la précedent. Nous disposons ainsi d’un cadre théorique d’implantation des
notions proposées par ACT-R appliquée au langage.
235 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

mm

an

Vmps-smiilp-»

PP, Ssub

 

V

invcstir

Vmn-»---

Prep

dl
Spd

 

N cms--

FIGURE 4 ~ Graphe des propriétés satisfaites pour “L’indu.strie est capable d’investir.”

4 Activation et création de chunks

Nous proposons de déﬁnir la notion d’activation sur la base des caractérisations syntaxiques
construites £1 l’aide des contraintes présentées dans la section précédente. Nous avons vu qu’il
était possible en Grammaire de Propriétés d’éValuer, pour tout sous-ensemble de categories, les
contraintes qui leur sont attachées. Il s’agit pour cela d’identiﬁer les contraintes pertinentes, £1
savoir celles qui permettent de mettre en relation les categories concernées. Le principe est
simple et consiste é parcourir la grammaire (l’ensemble des contraintes) et sélectionner celles qui
concernent les catégories. En reprenant l’exemple de la grammaire du syntagme adjectival décrite
plus haut, le sous-ensemble de catégories {AdB A} permettra d’identiﬁer comme pertinentes les
contraintes suivantes :

:{AdP,A}?
:AdP—<A
:AdP-~>A
:A!
:AA

%%%%%

En généralisant ce mécanisme, il également possible d’identiﬁer les contraintes qui sont potentiel-
lement pertinentes : soit une contrainte AQZB reliant deux categories A et B, la connaissance de A
permet de dire que AWZB pourra devenir pertinente, é la condition que B soit réalisé. Dans le cas
de la grammaire du SA, la réalisation de la catégorie AdP permet d’identiﬁer comme contrainte
potentiellement pertinente l’ensemble suivant :

AP:{AdP}?
AP:AdP—<A
AP
AP

: AP —< AdP
: AdP -~> A
236 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Nous proposons d’utiliser cette caractéristique pour décrire et évaluer la notion d’activation. Dans
la perspective d’un traitement incrémental de la langue, le principe consiste a associer a chaque
catégorie les contraintes potentiellement pertinentes qui peuvent lui étre associées. Remarquons
que du point de vue du traitement automatique, cette information n’a pas besoin d’étre calculée
online, mais peut étre compilée. L’ensemble des contraintes ainsi identiﬁées permet de déﬁnir les
catégories activées : il s’agit de toutes les catégories appartenant a cet ensemble et pouvant étre
réalisées apres la catégorie en question. Cette demiere information est obtenue en vériﬁant les
contraintes de linéarité. Dans l’exemple précédent, seule la catégorie A se retrouve activée par
AdP (la catégorie AP ne pouvant suivre AdP comme stipulé par la contrainte AP : AP -< AdP).

4.1 Calcul du degré d’activation

Le niveau d’activation d’une catégorie dans un contexte donné dépend de sa densité ou, en
d’autres termes, du nombre de contraintes dont elle est la cible (et dont la source la précéde)
et de leur poids. Il s’agit donc exactement de la notion d’activation telle que décrite dans la
théorie ACT—R. Nous proposons d’évaluer cette activation en tirant parti de la représentation par
contraintes. Pour chaque catégorie c de la grammaire, nous établissons une liste de transition
formée par toutes les catégories présentes dans au moins une contrainte contenant c et respectant
les contrainte de linéarité (i.e. pouvant suivre c). L’activation est alors évaluée comme suit :

— Soit la catégorie courante c,-. Notons Trans(c,-) l’ensemble des catégories faisant partie de la
liste de transition de cl-. Notons PP(c,-) l’ensemble des propriétés potentiellement pertinentes
déclenchées par la catégorie cl-. Notons N le nombre de ces propriétés (N =| PP(c,-) |).

— Notons PPcJ_(c,-) le sous ensemble de PP(c,-) formé des propriétés contenant une catégorie cj,
avec n son cardinal. Chacune des propriétés de PP est associée dans la grammaire a un poids.
Notons 2 WC? la somme des poids de ces propriétés.

— Pour toute catégorie de transition de c,- tq cj E Trans(c,-), son degré d’activation est donné par
la formule suivante :

A(cj) = % * Z wfj (2)

Le premier terme de l’activation correspond a une évaluation de la densité du réseau de
contraintes en rapportant le nombre de contraintes n qui permet d’activer la catégorie étu—
diée par rapport au nombre total de contraintes potentiellement pertinentes pour la catégorie
source. Le second terme correspond quant a lui a la force des relations qui unissent la catégorie
courante (ou catégorie activante) a la catégorie activée.

Concrétement, en cours d’analyse, cette mesure permettra d’identiﬁer le type de catégorie activée
par la catégorie courante ainsi que le niveau de son activation. Lorsque qu’une catégorie est
activée et réalisée, elle formera un chunk avec la catégorie qui l’active. Ce chunk pourra avoir
un niveau d’activation plus ou moins élevé, identiﬁé par cette fonction d’activation. Notons que
cette déﬁnition de l’activation permet également de rendre compte des relations lexicales du
type collocationnelles. La sélection lexicale entre les termes sera dans ce cas représentée par une
contrainte d’implication avec un poids élevée. Il sera ainsi possible de former un chunk doté d’un
niveau d’activation fort.

L’exemple qui suit illustre l’utilisation de la fonction d’activation pour la construction d’un chunk
a l’intérieur du SN entre les catégories Det et N en nous appuyant sur la grammaire extraite

237 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

du French T reebank. Les contraintes dont la catégorie Det est source sont répertoriées dans le
tableau suivant, comportant également l’indication de leurs poids (calculé en suivant la méthode
proposée dans (Blache, 2012)).

Linéarité
Det 4 N 12,18569885
Det ~> N 7 Det < Np 0,718659942
Det < AdP 0,178675795
Pro Det 4 Det < AP 0,135447163

Clit ﬁe) Det 0,003417994 Det 4 VPpart 0,077399536
Det -< VPinf 0,03891139

 

Det 99 Det -< Ssub 0,025216138
Det -< Srel 0,021433718
Det =;, N 2, 10191 1 Det -< PP 0,016570605
Det < NP 0,016030259

L’ensemble de transition de Det extrait de ces contraintes est le suivant :

Trans(Det) = {N, Np,AdP, AP, VPpart, VPinf, Ssub, Srel, PP, NP} (3)

L’évaluau'on du degre’ d’activation des catégories de l’ensemble de transition est récapitulée dans
le tableau suivant :

Catégorie activée Contraintes Densité Poids Activation

N 3 0,2 21,7273 0409 4,345460818
Np 1 0,066666667 0,71 865 9942 0,047910663
AdP 1 0,066666667 0,178675795 0,01191172
AP 1 0,066666667 0,135447163 0,009029811
VPpart 1 0,066666667 0,077399536 0,0051 59969
VPinf 1 0,066666667 0,03891139 0,002594093
Ssub 1 0,066666667 0,025216138 0,001681076
Srel 1 0,066666667 0,021433718 0,001428915
PP 1 0,066666667 0,016570605 0,001104707
NP 1 0,066666667 0,016030259 0,001068684

Cet ensemble de résultats indique, comme attendu, une forte activation de la catégorie N
provenant d’une part du nombre de propriétés potentielles qui l’activent et d’autre part de leur
importance (i.e. un poids élevé). Cette forte activation conduit 31 la constitution d’un chunk [Det ,
N] qui sera stocké dans un buffer de la mémoire déclarative. Ce processus d’identiﬁcation de
chunk repose donc sur des mécanismes de bas niveau, effectués en temps réel ce qui se manifeste
concrétement par un traitement global notamment au niveau du mouvement oculaire dans le cas
de la lecture. L’exemple de la ﬁgure 5 illustre ce mécanisme. La réalisation de la catégorie Det
permet d’identiﬁer trois propriétés activant le N conduisant a la création du chunk.

L’exemple de la ﬁgure 6 décrit le méme mécanisme, appliqué ici a la constitution d’un chunk
formé, dans le cas d’une relative sujet, par le pronom relatif et le verbe qui suit. Les catégories
activées les plus importantes (celles correspondant a des contraintes de plus fort poids) sont V et
N, représentées dans le cadre associé au pronom relatif. La catégorie V dispose cependant d’un
niveau d’activation trés supérieur au N. Le V étant réalisé immédiatement aprés l’activation, ceci
conduit a la construction du chunk [ProR, V].

238 © ATALA

