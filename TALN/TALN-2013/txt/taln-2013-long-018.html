<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Extraction de lexiques bilingues &#224; partir de corpus comparables par combinaison de repr&#233;sentations contextuelles</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Extraction de lexiques bilingues &#224; partir de corpus
comparables par combinaison de repr&#233;sentations
</p>
<p>contextuelles
</p>
<p>Amir HAZEM Emmanuel MORIN
LINA - UMR CNRS 6241, 2 rue de la houssini&#232;re, BP 92208, 44322 Nantes Cedex 03
</p>
<p>R&#201;SUM&#201;
La caract&#233;risation du contexte des mots constitue le c&#339;ur de la plupart des m&#233;thodes d&#8217;extraction
de lexiques bilingues &#224; partir de corpus comparables. Dans cet article, nous revisitons dans un
premier temps les deux principales strat&#233;gies de repr&#233;sentation contextuelle, &#224; savoir celle par
fen&#234;tre ou sac de mots et celle par relations de d&#233;pendances syntaxiques. Dans un second temps,
nous proposons deux nouvelles approches qui exploitent ces deux repr&#233;sentations de mani&#232;re
conjointe. Nos exp&#233;riences montrent une am&#233;lioration significative des r&#233;sultats sur deux corpus
de langue de sp&#233;cialit&#233;.
</p>
<p>ABSTRACT
Bilingual Lexicon Extraction from Comparable Corpora by Combining Contextual Repre-
sentations
</p>
<p>Word&#8217;s context characterisation constitute the heart of most methods of bilingual lexicon
extraction from comparable corpora. In this article, we first revisit the two main strategies of
context representation, that is : the window-based and the syntactic based context representation.
Secondly, we propose two new methods that exploit jointly these different representations . Our
experiments show a significant improvement of the results obtained on two different domain
specific comparable corpora.
</p>
<p>MOTS-CL&#201;S : Multilingualisme, corpus comparables, lexique bilingue, vecteurs de contexte,
d&#233;pendances syntaxiques.
</p>
<p>KEYWORDS: Multilingualism, comparable corpora, bilingual lexicon, context vectors, syntactic
dependencies.
</p>
<p>1 Introduction
</p>
<p>Les lexiques bilingues sont une ressource importante pour diff&#233;rentes applications relevant du
traitement automatique des langues comme en traduction assist&#233;e par ordinateur ou en recherche
d&#8217;information inter-langue. Bien que les travaux s&#8217;appuyant sur des corpus parall&#232;les 1 aient
montr&#233; de tr&#232;s bons r&#233;sultats, ce type de corpus reste difficile &#224; collecter (Fung et Yee, 1998) et
</p>
<p>1. Un corpus parall&#232;le est un ensemble de textes accompagn&#233;s de leurs traductions dans une ou plusieurs langues
(Bowker et Pearson, 2002).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>243 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>plus particuli&#232;rement quand il s&#8217;agit de traiter des corpus sp&#233;cialis&#233;s ou des couples de langues
rares ou moins usit&#233;es (Morin et al., 2004). L&#8217;exploitation des corpus comparables 2 a marqu&#233; un
tournant dans la t&#226;che d&#8217;extraction de lexiques bilingues, et suscite un int&#233;r&#234;t constant depuis
le milieu des ann&#233;es 1990 gr&#226;ce &#224; l&#8217;abondance et la disponibilit&#233; de tels corpus (Rapp, 1995;
Fung, 1995; Rapp, 1999; D&#233;jean et al., 2002; Gaussier et al., 2004; Morin et al., 2004; Laroche
et Langlais, 2010). L&#8217;essor du Web ayant sensiblement facilit&#233; la collecte de grandes quantit&#233;s
de donn&#233;es multilingues, les corpus comparables se sont naturellement impos&#233;s comme une
alternative aux corpus parall&#232;les. Ils ont donn&#233; lieu &#224; plusieurs travaux dont le d&#233;nominateur
commun est l&#8217;hypoth&#232;se selon laquelle les mots qui sont en correspondance de traduction,
ont de grandes chances d&#8217;appara&#238;tre dans les m&#234;mes contextes (Rapp, 1999). Cette hypoth&#232;se
d&#233;coule directement de la proposition souvent cit&#233;e de Firth (1957) : &#171; On reconna&#238;t un mot &#224; ses
fr&#233;quentations &#187; 3.
</p>
<p>Rapp (1995) et Fung (1995) ont &#233;t&#233; les premiers &#224; introduire les corpus comparables. Ils se sont
appuy&#233;s sur l&#8217;id&#233;e de caract&#233;risation du contexte des mots, contrairement aux travaux s&#8217;appuyant
sur les corpus parall&#232;les, qui eux se basaient sur des informations positionnelles. En 1998, Fung
(1998) a introduit la m&#233;thode directe, reprise dans de nombreux travaux, notamment ceux de
(Rapp, 1999). Dans cette m&#233;thode, la traduction d&#8217;un mot comporte plusieurs &#233;tapes. Le mot est
tout d&#8217;abord caract&#233;ris&#233; par un vecteur repr&#233;sentatif de son contexte. Puis, ce vecteur est traduit
dans la langue cible &#224; l&#8217;aide d&#8217;un dictionnaire aussi appel&#233; lexique de transfert ou lexique pivot.
Enfin, il reste &#224; comparer ce vecteur avec tous les vecteurs de contexte des mots de la langue
cible, et en extraire les n plus proches comme traductions candidates. Par la suite, une partie
des travaux a port&#233; sur l&#8217;adaptation et l&#8217;am&#233;lioration de cette m&#233;thode &#224; diff&#233;rents types de
corpus (corpus de langue g&#233;n&#233;rale ou de sp&#233;cialit&#233;), et &#224; diff&#233;rentes langues et diff&#233;rents types
de termes (termes simples, termes complexes, collocations, etc.) (D&#233;jean et Gaussier, 2002),
(Morin et Daille, 2004). De nouvelles m&#233;thodes ont &#233;galement &#233;t&#233; propos&#233;es telles que l&#8217;approche
par similarit&#233; interlangue (D&#233;jean et Gaussier, 2002), l&#8217;utilisation de l&#8217;Analyse en Composantes
Canoniques (CCA) (Haghighi et al., 2008). R&#233;cemment, Li et Gaussier (2010) et Li et al. (2011) se
sont int&#233;ress&#233;s &#224; l&#8217;aspect inverse qui consiste &#224; am&#233;liorer la comparabilit&#233; des corpus comparables
afin d&#8217;augmenter l&#8217;efficacit&#233; des m&#233;thodes d&#8217;extraction de lexiques bilingues.
</p>
<p>La plupart des travaux utilisant les corpus comparables ont comme d&#233;nominateur commun
le contexte, qui repr&#233;sente le c&#339;ur de l&#8217;extraction lexicale bilingue. La question principale &#224;
se poser est alors la suivante : &#233;tant donn&#233; un mot quelconque, comment choisir les mots
qui caract&#233;risent au mieux son contexte ? Selon l&#8217;&#233;tat de l&#8217;art, le contexte d&#8217;un mot donn&#233; est
habituellement repr&#233;sent&#233; par les mots faisant partie de son environnement, c&#8217;est-&#224;-dire, les
mots qui l&#8217;entourent. Ces mots sont extraits, soit &#224; l&#8217;aide d&#8217;une fen&#234;tre contextuelle (Rapp, 1999;
D&#233;jean et Gaussier, 2002), soit &#224; l&#8217;aide des relations de d&#233;pendances syntaxiques (Gamallo,
2007). L&#8217;un des probl&#232;mes sous-jacent au contexte extrait &#224; l&#8217;aide des fen&#234;tres contextuelles est
le choix de la taille des fen&#234;tres. Celle-ci est habituellement fix&#233;e empiriquement, et bien que
diff&#233;rentes &#233;tudes aient montr&#233; une tendance &#224; choisir des fen&#234;tres de petite taille quand il s&#8217;agit
de caract&#233;riser des mots fr&#233;quents, et des fen&#234;tres de grande taille quand il s&#8217;agit de caract&#233;riser
des mots peu fr&#233;quents (Prochasson et Morin, 2009), cela reste impr&#233;cis car il n&#8217;y a toujours pas
de m&#233;thode dite optimale pour le choix de la taille de la fen&#234;tre contextuelle. Quant aux relations
de d&#233;pendances syntaxiques, leur efficacit&#233; est tr&#232;s sensible &#224; la taille des corpus, et bien que cette
</p>
<p>2. Un corpus comparable est une collection de documents multilingues produits g&#233;n&#233;ralement &#224; la m&#234;me p&#233;riode et
traitant des m&#234;mes sujets.
</p>
<p>3. &#171; You shall know a word by the company it keeps &#187;
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>244 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>repr&#233;sentation soit plus int&#233;ressante d&#8217;un point de vue s&#233;mantique, elle atteint ses limites lorsqu&#8217;il
s&#8217;agit de traiter des corpus de petite taille. Une proposition, qui vient naturellement &#224; l&#8217;esprit
consiste &#224; utiliser conjointement ces deux repr&#233;sentations afin de tirer profit de leurs avantages
respectifs. Une premi&#232;re approche exploitant les deux repr&#233;sentations propos&#233;e par Andrade et al.
(2011) combine quatre mod&#232;les statistiques et compare les d&#233;pendances lexicales pour identifier
les traductions candidates. Dans cet article, nous proposons une autre mani&#232;re de combiner les
deux pr&#233;c&#233;dentes repr&#233;sentations contextuelles, partant de l&#8217;intuition que cette combinaison
permettrait un lissage du contexte en prenant en compte deux informations compl&#233;mentaires
qui sont : (i) l&#8217;information globale v&#233;hicul&#233;e par la repr&#233;sentation par fen&#234;tre contextuelle et (ii)
une information s&#233;mantique plus fine apport&#233;e par les relations de d&#233;pendances syntaxiques.
L&#8217;objectif &#233;tant d&#8217;am&#233;liorer la repr&#233;sentation contextuelle et les performances de l&#8217;extraction de
lexiques bilingues &#224; partir de corpus comparables.
</p>
<p>Dans la suite de cet article, nous pr&#233;sentons en section 2 les deux principales strat&#233;gies de
repr&#233;sentations contextuelles. La section 3 d&#233;crit ensuite nos deux approches de combinaison
de contextes. La section 4 se concentre sur l&#8217;&#233;valuation des m&#233;thodes mises en &#339;uvre. Nous
terminons enfin par une discussion en section 5 et une conclusion en section 6.
</p>
<p>2 Construction de contextes
</p>
<p>2.1 Cooccurrences graphiques
</p>
<p>Le contexte par sac de mots consiste simplement &#224; collecter des mots entourant un mot donn&#233;,
sans r&#232;gles pr&#233;cises hormis le choix du nombre de mots &#224; sa gauche et &#224; sa droite, appel&#233; aussi
fen&#234;tre contextuelle. Soit la phrase suivante : &#171;(...) Pour les cas trait&#233;s pour danger ost&#233;oporotique
les densitom&#233;tries osseuses comparatives ont montr&#233; une am&#233;lioration sous THS (...)&#187;.
</p>
<p>Pour le terme ost&#233;oporotique, si nous choisissons une fen&#234;tre contextuelle de taille 5, c&#8217;est-&#224;-dire
deux mots &#224; gauche et deux mots &#224; droite de celui-ci. Le contexte de ost&#233;oporotique sera :
trait&#233;s, danger, densitom&#233;tries et osseuses. Ce processus est r&#233;p&#233;t&#233; autant de fois que le terme
ost&#233;oporotique appara&#238;t dans un corpus donn&#233;. Cette technique de repr&#233;sentation du contexte a
montr&#233; son efficacit&#233; surtout lorsqu&#8217;il s&#8217;agit de mots tr&#232;s fr&#233;quents. Intuitivement, nous pouvons
nous dire que tous les mots entourant un mot donn&#233; n&#8217;ont pas la m&#234;me importance et qu&#8217;il serait
parfois utile de ne pas tous les consid&#233;rer de la m&#234;me mani&#232;re. Cependant, toute la difficult&#233;
r&#233;side dans la prise de d&#233;cision concernant tel ou tel mot. Brosseau-Villeneuve et al. (2010)
proposent une m&#233;thode de pond&#233;ration des mots du contexte selon leur position pour la t&#226;che de
d&#233;sambigu&#239;sation du sens des mots. Une autre m&#233;thode pour pallier cette difficult&#233; consiste en
l&#8217;utilisation des relations de d&#233;pendances syntaxiques entre les mots que nous pr&#233;sentons dans la
section suivante.
</p>
<p>2.2 Cooccurrences syntaxiques
</p>
<p>Afin de mieux repr&#233;senter le contexte d&#8217;un mot, plusieurs travaux se sont int&#233;ress&#233;s aux relations
de d&#233;pendances syntaxiques (Gamallo, 2008a; Garera et al., 2009). L&#8217;id&#233;e n&#8217;est plus de repr&#233;senter
le contexte seulement par les mots avoisinants mais de rajouter une information suppl&#233;mentaire
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>245 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>qui sp&#233;cifie le type de relation syntaxique entre les mots. Une relation de d&#233;pendance est
une relation binaire asym&#233;trique entre un mot appel&#233; t&#234;te ou parent (Head or parent) et un
modificateur ou d&#233;pendant (modifier or dependant). Les relations de d&#233;pendances forment un
arbre qui inter-connecte tous les mots d&#8217;une phrase. Un mot dans une phrase peut avoir plusieurs
modificateurs mais chaque mot ne peut modifier qu&#8217;au plus un seul mot (Lin, 1998). La racine
de l&#8217;arbre de d&#233;pendance aussi appel&#233;e Head, ne modifie aucun mot de la phrase. Une liste
de tuples est utilis&#233;e pour repr&#233;senter un arbre de d&#233;pendances : ([word], [category], [head],
[relationship]) avec :
&#8211; word : est le mot repr&#233;sent&#233; dans le n&#339;ud de l&#8217;arbre ;
&#8211; category : constitue la cat&#233;gorie lexicale du mot (word) ;
&#8211; head : sp&#233;cifie quel mot est modifi&#233; par word ;
&#8211; relationship : est une &#233;tiquette attribu&#233;e &#224; la relation de d&#233;pendance (subj pour subject, spec
</p>
<p>pour specifier, etc.).
</p>
<p>En outre, le signe &#171; &lt; &#187; signifie pr&#233;c&#233;dent et &#171; &gt; &#187; signifie successeur.
Pour la phrase suivante : &#171; I have a brown dog &#187;, l&#8217;arbre de d&#233;pendance serait celui donn&#233; en
table 1 :
</p>
<p>Modificateur Cat&#233;gorie Head Type
I Noun &lt; have subj
have Verb - -
a Det &lt; dog spec
brown Adj &lt; dog adjn
dog Noun &gt; have comp
</p>
<p>TABLE 1 &#8211; Exemple de relations de d&#233;pendances syntaxiques
</p>
<p>Pour plus de d&#233;tails concernant les d&#233;pendances syntaxiques et plus particuli&#232;rement pour les
t&#226;ches de d&#233;sambiguisation de mots et de r&#233;solution des d&#233;pendances, se rapporter &#224; Gamallo
(2008b). Dans Gamallo (2007), trois notions &#233;l&#233;mentaires de d&#233;notation sont abord&#233;es :
&#8211; Les mots lexicaux ;
&#8211; Les d&#233;pendances syntaxiques (sujet, relation d&#8217;objet direct, relation pr&#233;positionnelle entre
</p>
<p>deux noms, relation pr&#233;positionnelle entre un verbe et un nom, etc.) ;
&#8211; Les mod&#232;les lexico-syntaxiques qui consiste &#224; combiner les mots et leurs cat&#233;gories syntaxiques
</p>
<p>en terme de d&#233;pendance ( Noun+ subj + Verb).
</p>
<p>Les mots lexicaux repr&#233;sentent des ensembles de propri&#233;t&#233;s {Noun, Verb, Adj, Adv ... } alors
que les d&#233;pendances et les mod&#232;les lexico-syntaxiques sont d&#233;finis comme des op&#233;rations sur
ces ensembles. Une d&#233;pendance est une relation binaire qui prend en entr&#233;e deux ensembles
de propri&#233;t&#233;s et donne en sortie un ensemble plus restreint qui est l&#8217;intersection des ensembles
donn&#233;es en entr&#233;e. Nous retrouvons sept types de relations de d&#233;pendances (Gamallo, 2007)
r&#233;sum&#233;s dans la table 2.
</p>
<p>Par exemple, pour le mot recurrence, il existe une relation Lmod avec l&#8217;adjectif local. Ainsi dans le
processus de construction du contexte de recurrence, nous comptabiliserons le nombre de fois
o&#249; l&#8217;adjectif local appara&#238;t &#224; gauche de recurrence dans le corpus. Nous ferons de m&#234;me pour les
autres relations de d&#233;pendances syntaxiques.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>246 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Relation type Exemple
Lmod modificateur gauche si relation Adj - Noun local - recurrence
Rmod modificateur droite si relation Noun - Adj number - insufficient
modN modificateur de Nom si relation Noun - Noun breast - cancer
Lobj objet &#224; gauche si relation Noun - Verb study - demonstrate
Robj objet &#224; droite si relation Verb - Noun have - effect
PRP si relation pr&#233;positionnelle Noun-PRP-Noun malignancy - in - woman
iobj si relation objet indirecte Verb-PRP-Noun occur - in - portion
</p>
<p>TABLE 2 &#8211; Liste des relations de d&#233;pendances syntaxiques
</p>
<p>2.3 Synth&#232;se
</p>
<p>Nous venons de voir deux mani&#232;res de repr&#233;senter le contexte, &#224; savoir une repr&#233;sentation
graphique (par sac de mots) et une repr&#233;sentation syntaxique (par relations de d&#233;pendances
syntaxiques). L&#8217;int&#233;r&#234;t de passer d&#8217;une coloration graphique &#224; une coloration syntaxique des
mots peut &#234;tre vu selon deux aspects. Le premier consiste &#224; se dire que l&#8217;information v&#233;hicul&#233;e
par une coloration graphique n&#8217;est principalement qu&#8217;une information quantitative tr&#232;s variable
et fortement d&#233;pendante des corpus utilis&#233;s. D&#8217;o&#249; l&#8217;id&#233;e d&#8217;abandonner ce type de coloration
pour passer &#224; une coloration syntaxique porteuse d&#8217;informations qualitatives et id&#233;alement
ind&#233;pendante de la taille des corpus. Le deuxi&#232;me aspect serait de dire que malgr&#233; tout, la
coloration graphique a un int&#233;r&#234;t et qu&#8217;au lieu de s&#8217;en &#233;carter il vaudrait peut &#234;tre mieux la
combiner avec la coloration syntaxique afin de tirer le meilleur des deux. C&#8217;est notre hypoth&#232;se
de compl&#233;mentarit&#233; entre les informations qualitatives et quantitatives des mots.
</p>
<p>3 Combinaison de contextes
</p>
<p>Nous nous positionnons ici dans le cadre de l&#8217;am&#233;lioration de la m&#233;thode directe d&#233;crite dans
plusieurs travaux dont Fung (1998) et Rapp (1999). Notre d&#233;marche vise &#224; montrer que l&#8217;ex-
ploitation des deux principales repr&#233;sentations contextuelles a un int&#233;r&#234;t particulier pour la
t&#226;che de constitution de lexiques bilingues. Nous proposons donc deux mani&#232;res de combiner
les contextes (graphique et syntaxique) que nous appellerons : la combinaison a posteriori des
contextes et la combinaison a priori des contextes.
</p>
<p>Une premi&#232;re mani&#232;re de combiner les deux repr&#233;sentations contextuelles est une combinaison a
posteriori, c&#8217;est-&#224;-dire la combinaison des scores renvoy&#233;s par la m&#233;thode directe selon les deux
repr&#233;sentations. La seconde mani&#232;re consiste en une combinaison a priori qui utilise les deux
informations contextuelles a priori dans un m&#234;me vecteur pour ensuite appliquer la m&#233;thode
directe une seule fois sur l&#8217;ensemble du corpus.
</p>
<p>3.1 Combinaison a posteriori des contextes
</p>
<p>Dans le domaine de la recherche d&#8217;information, la combinaison de plusieurs listes renvoy&#233;es
par diff&#233;rents moteurs de recherche est souvent utilis&#233;e pour am&#233;liorer les performances d&#8217;un
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>247 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>syst&#232;me de questions/r&#233;ponses (Aslam et Montague, 2001). Nous partons du principe que chaque
repr&#233;sentation du contexte correspond &#224; une m&#233;thode bien d&#233;finie. Nous nous retrouvons donc
dans le cas d&#8217;une combinaison de deux m&#233;thodes bien distinctes. La premi&#232;re est la m&#233;thode
directe bas&#233;e sur une repr&#233;sentation graphique et la seconde est la m&#233;thode directe bas&#233;e sur
une repr&#233;sentation syntaxique. Une mani&#232;re classique de fusionner les deux m&#233;thodes est de
prendre, comme entr&#233;e, la sortie de chacune des m&#233;thodes cit&#233;es. Dans notre cas, pour chaque
mot &#224; traduire, nous prenons comme entr&#233;e une liste de scores retourn&#233;e par chacune des deux
m&#233;thodes, puis nous fusionnons les deux listes par une simple combinaison arithm&#233;tique des
scores. Ceci nous donne une nouvelle liste de mots ordonn&#233;s (sachant que les scores fusionn&#233;s
sont compatibles &#224; partir du moment o&#249; nous utilisons la m&#234;me mesure de similarit&#233; pour les
deux m&#233;thodes). En utilisant les scores comme crit&#232;re de fusion, nous calculons le score de
similarit&#233; d&#8217;un candidat &#224; la traduction, en sommant les scores qui sont renvoy&#233;s par chacune
des deux m&#233;thodes comme suit :
</p>
<p>Scomb(w) = S f en(w) + Srel(w) (1)
</p>
<p>o&#249; Scomb(w) est le score final du mot w, S f en(w) est le score retourn&#233; par la m&#233;thode directe
bas&#233;e sur une repr&#233;sentation graphique et Srel(w) est le score retourn&#233; par la m&#233;thode directe
bas&#233;e sur une repr&#233;sentation syntaxique.
</p>
<p>Cette &#233;quation peut aussi s&#8217;&#233;crire comme suit :
</p>
<p>Scomb(w) = (&#955;)&#215; S f en(w) + (1&#8722;&#955;)&#215; Srel(w) (2)
</p>
<p>avec &#955; comme indice de confiance donn&#233; &#224; chaque m&#233;thode (&#955; &#8712; [0,1]). Dans notre cas, &#955; = 0,5,
notre but n&#8217;&#233;tant pas de trouver la valeur optimale de &#955; pour obtenir les meilleurs r&#233;sultats.
Diff&#233;rentes exp&#233;riences ont &#233;t&#233; men&#233;es qui indiquent que les meilleurs r&#233;sultats sont globalement
ceux montr&#233;s dans la section 4 avec un lambda &#8712; [0,5,0,6]. Par ailleurs, d&#8217;autres m&#233;thodes
de combinaisons de scores ont &#233;t&#233; test&#233;es comme la combinaison harmonique des rangs et des
scores (Morin, 2009), mais la m&#233;thode que nous avons choisi (combinaison arithm&#233;tique des
scores) est celle qui donne les meilleures performances.
</p>
<p>3.2 Combinaison a priori des contextes
</p>
<p>Le vecteur de contexte a pour but d&#8217;enregistrer un ensemble d&#8217;information sur le contexte d&#8217;un
mot w donn&#233;. Dans le cas de la repr&#233;sentation graphique, ces informations sont les mots qui
cooccurrent avec le mot w. Dans le cas d&#8217;une repr&#233;sentation syntaxique, ce sont les mots en
relation avec w qui sont s&#233;lectionn&#233;s pour faire partie de son vecteur de contexte. Dans un cadre
plus g&#233;n&#233;rique, nous pourrions imaginer plusieurs autres sources d&#8217;informations &#224; exploiter.
Cependant si chaque nouvelle information engendre un nouveau vecteur de contexte, nous
pourrions vite &#234;tre d&#233;pass&#233;s par le nombre de sources &#224; fusionner. Pour rem&#233;dier &#224; cela, une
autre mani&#232;re serait de repr&#233;senter dans un seul vecteur de contexte toutes les informations
concernant le mot w. C&#8217;est la position adopt&#233;e avec la combinaison a priori des contextes.
</p>
<p>Dans cette technique de combinaison, nous consid&#233;rons le vecteur de contexte d&#8217;un mot comme
un descripteur qui contient plusieurs informations pour chaque entr&#233;e du vecteur. Dans notre cas,
nous avons deux types d&#8217;information : (i) une information de cooccurrence globale fournie par la
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>248 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Repr&#233;sentation graphique Repr&#233;sentation syntaxique Combinaison
regional13 regionalLmod2 regional13, regionalLmod2
local5 localLmod1 local5, localLmod1
oest rogen1 - oest rogen1
rate32 ratemodN29 ,ratePRPV3 rate32, ratemodN29 ,ratePRPV3
</p>
<p>TABLE 3 &#8211; Exemple de la repr&#233;sentation du contexte du mot recurrence et du nombre de ses cooc-
currences, en fonction des repr&#233;sentations graphique et syntaxique ainsi que de leur combinaison
</p>
<p>repr&#233;sentation graphique et (ii) une information plus sp&#233;cifique fournie par la repr&#233;sentation
syntaxique. Si nous prenons par exemple le mot regional (repr&#233;sent&#233; dans la table 3), nous
pouvons voir qu&#8217;il appara&#238;t 13 fois avec le mot recurrence selon la repr&#233;sentation graphique et
2 fois comme modificateur gauche (Lmod) selon la repr&#233;sentation syntaxique. La combinaison
prend en compte les deux informations, en consid&#233;rant que le mot regional appara&#238;t 13 fois avec
recurrence, dont 2 fois en tant que modificateur gauche. Une information importante &#224; souligner
est que la m&#233;thode directe se basant sur les relations de d&#233;pendances syntaxiques consid&#232;re
ratemodN29 et ratePRPV3 par exemple, comme &#233;tant deux mots distincts. L&#8217;un des avantages de la
combinaison a priori est que si l&#8217;une des m&#233;thodes manque une information (un mot), comme
nous pouvons le constater avec le mot oestrogen par exemple, la fusion permet de pallier ce
manque (gr&#226;ce ici &#224; la repr&#233;sentation graphique). Nous consid&#233;rons les deux repr&#233;sentations
contextuelles comme &#233;tant compl&#233;mentaires. Le but de la combinaison a priori est de pr&#233;server le
classement et renforcer les scores des entr&#233;es des vecteurs de contexte afin de lisser les contextes
et corriger certaines erreurs qui peuvent appara&#238;tre.
</p>
<p>Nous illustrons dans les tables 4, 5 et 6 les 10 premi&#232;res entr&#233;es du vecteur de contexte du mot
recurrence extrait du corpus du cancer du sein, en fonction de trois mesures d&#8217;association, &#224;
savoir : le taux de vraisemblance (Log), le Odds-Ratio (Odds) et l&#8217;information mutuelle (Im).
La notation (+/-) indique l&#8217;apport positif ou n&#233;gatif de la combinaison a priori. L&#8217;indice &#8217;+&#8217;
indique qu&#8217;un mot class&#233; dans les 10 premi&#232;res entr&#233;es du vecteur de contexte de la m&#233;thode par
fen&#234;tre ou par relation de d&#233;pendance, conserve son classement dans les 10 premi&#232;res entr&#233;es
apr&#232;s combinaison. Le signe &#8217;-&#8217; en revanche, indique l&#8217;apparition d&#8217;un mot non class&#233; dans les 10
premi&#232;res entr&#233;es du vecteur de contexte.
</p>
<p>w=5 RelDep Combinaison +/-
local 818,98 localLmod 618,17 localLmod 936,05 +
rate 119,71 riskPRPN 96,02 local 791,15 +
distant 72,62 ratemodN 68,34 riskPRPN 153,14 +
risk 61,00 tumormodN 62,82 rate 113,96 +
salvage 39,15 ratePRPN 40,18 ratemodN 110,28 +
year 39,08 t imePRPN 32,85 tumormodN 104,71 +
time 31,84 diseasemodN 28,76 distant 70,23 +
tumor 31,04 isolatedLmod 24,29 ratePRPN 64,69 +
isolate 30,15 distantLmod 24,28 risk 54,89 +
inoperable 28,16 patientPRPN 23,64 t imePRPN 53,13 +
</p>
<p>TABLE 4 &#8211; Illustration des 10 premi&#232;res entr&#233;es du vecteur de contexte du mot recurrence en
fonction du taux de vraisemblance (Log) pour les repr&#233;sentations graphique (w = 5) et syntaxique
(RelDep) ainsi que par la combinaison a priori
</p>
<p>La table 4 montre que la combinaison a priori a un apport positif car, elle engendre un vecteur
de contexte qui respecte le classement des m&#233;thodes w = 5 et RelDep et ceci, gr&#226;ce &#224; la mesure
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>249 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>d&#8217;association du taux de vraisemblance.
</p>
<p>w=5 RelDep Combinaison +/-
isolated 5,10 f reedomPRPN 7,83 f reedomPRPN 8,12 +
geographic 4,62 heatRob j 6,72 f atPRPN 7,02 +
adjudication 4,44 operableRmod 6,72 disappointingRmod 7,02 +
conspicuous 4,44 f atPRPN 6,72 operableRmod 7,02 +
reconcile 4,44 disappointingRmod 6,72 threatPRPN 7,02 +
liberate 4,44 threatPRPN 6,72 heatRob j 7,02 +
evade 4,44 localLmod 5,89 localLmod 6,02 +
inoperable 4,38 f earPRPN 5,63 f earPRPN 5,93 +
quarter 4,29 suspicionPRPN 5,63 suspicionPRPN 5,93 +
local 4,28 inoperableLmod 5,63 inoperableLmod 5,93 +
</p>
<p>TABLE 5 &#8211; Illustration des 10 premi&#232;res entr&#233;es du vecteur de contexte du mot recurrence en
fonction du Odds-Ratio (Odds) pour les repr&#233;sentations graphique (w = 5) et syntaxique
(RelDep) ainsi que par la combinaison a priori
</p>
<p>La table 5 montre aussi que la combinaison a priori a un apport positif en utilisant la mesure
d&#8217;association du Odds-Ratio. Nous remarquons n&#233;anmoins que la combinaison a avantag&#233; la
m&#233;thode relDep, car il n&#8217;y a que ses entr&#233;es qui sont pr&#233;sentes dans les 10 premi&#232;res entr&#233;es du
vecteur de contexte de la m&#233;thode de combinaison a priori.
</p>
<p>w=5 RelDep Combinaison +/-
isolated 8,73 localLmod 14,77 local 16,17 +
geographic 8,15 tumormodN 13,84 localLmod 15,83 +
inoperable 8,00 riskPRPN 12,84 breast 14,64 -
local 7,82 t imePRPN 12,44 rate 14,39 -
ad judicat ion 7,73 distantLmod 12,09 tumor 14,15 -
conspicuous 7,73 ratemodN 11,91 cancer 14,04 -
reconcile 7,73 yearmodN 11,80 riskPRPN 13,90 +
l i berate 7,73 ratePRPN 11,63 patient 13,75 -
quar ter 7,73 tumourmodN 11,63 cancermodN 13,15 +-
</p>
<p>... ... ... ...
</p>
<p>rate 5,59 cancermodN 10,51
survival 4,12 ...
</p>
<p>tumor 3,69
patient 3,21
breast 2,92
cancer 2,28
</p>
<p>TABLE 6 &#8211; Illustration des 10 premi&#232;res entr&#233;es du vecteur de contexte du mot recurrence en
fonction de l&#8217;information mutuelle (IM) pour les repr&#233;sentations graphique (w = 5) et syntaxique
(RelDep) ainsi que par la combinaison a priori
</p>
<p>La table 6 montre que la combinaison a priori a un apport n&#233;gatif pour au moins 5 mots. Ces
mots n&#8217;&#233;taient pas class&#233;s dans les 10 premi&#232;res entr&#233;es des m&#233;thodes w = 5 et RelDep, et le
sont devenus gr&#226;ce &#224; la combinaison a priori. Ce constat indique que la mesure d&#8217;association de
l&#8217;information mutuelle n&#8217;est pas appropri&#233;e car elle ne pr&#233;serve pas le classement des entr&#233;es de
w = 5 et RelDep. Elle affecte des scores &#233;lev&#233;s &#224; des mots qui avaient des scores faibles comme
pour rate ou cancer par exemple, qui passent respectivement de 5,59 &#224; 14,39 et de 2,28 &#224;
14,04.
</p>
<p>Les tables 4, 5 et 6 ont montr&#233; que l&#8217;utilisation du taux de vraisemblance et du Odds-Ratio
dans la m&#233;thode de combinaison a priori avait un apport positif contrairement &#224; l&#8217;utilisation
de l&#8217;information mutuelle. Ce constat se confirme par les r&#233;sultats des exp&#233;riences que nous
pr&#233;sentons dans la section suivante.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>250 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4 &#201;valuation
</p>
<p>4.1 Ressources linguistiques
</p>
<p>Nous avons utilis&#233; deux corpus sp&#233;cialis&#233;s fran&#231;ais-anglais, &#224; savoir un corpus du &#171; cancer du
sein &#187; d&#8217;un million de mots et un corpus &#171; &#233;nergies renouvelables &#187; de 600 000 mots. Le corpus
du cancer du sein a &#233;t&#233; extrait &#224; partir du portail Elsevier 4 tel que d&#233;crit dans l&#8217;article Morin
(2009). Concernant le corpus des &#233;nergies renouvelables, il a &#233;t&#233; construit avec le crawler nomm&#233;
Babook (Groc, 2011). Les deux corpus ont &#233;t&#233; pr&#233;-trait&#233;s (tokenis&#233;s, &#233;tiquet&#233;s, et lemmatis&#233;s).
Pour &#233;valuer les diff&#233;rentes approches utilis&#233;es dans cet article, nous avons s&#233;lectionn&#233; 122
couples de mots simples pour le corpus du cancer du sein (&#224; partir du meta-thesaurus UMLS 5
</p>
<p>et du Grand dictionnaire terminologique 6) et 100 couples de mots simples pour le corpus des
&#233;nergies renouvelables (&#224; partir du dictionnaire en ligne WordReference 7). Comme dictionnaire
bilingue nous avons utilis&#233; le dictionnaire ELRA-M0033. Concernant l&#8217;extraction des relations de
d&#233;pendances syntaxiques, nous avons utilis&#233; l&#8217;outil fournit par Gamallo (2008a) 8.
</p>
<p>4.2 R&#233;sultats
</p>
<p>Nous pr&#233;sentons les r&#233;sultats des exp&#233;riences men&#233;es sur les deux corpus de langue de sp&#233;cialit&#233;.
Nous &#233;valuons la m&#233;thode directe bas&#233;e sur une repr&#233;sentation graphique not&#233;e w = k, o&#249; k
correspond &#224; la taille de la fen&#234;tre (k prend les valeurs : 5, 9 et 15). La m&#233;thode directe bas&#233;e
sur une repr&#233;sentation syntaxique not&#233;e RelDep, et nos deux nouvelles approches, c&#8217;est-&#224;-dire
la combinaison a posteriori des contextes not&#233;e Combpost (qui combine les scores de w = k et
de RelDep) et la combinaison a priori des contextes not&#233;e Combapri (qui exploite les contextes
fournis par une fen&#234;tre contextuelle w = k et les relations de d&#233;pendances RelDep conjointement
dans un m&#234;me vecteur, pour ensuite appliquer la m&#233;thode directe). La comparaison des quatre
m&#233;thodes se fait en fonction de la pr&#233;cision pour les tops 1 et 10. Ainsi une pr&#233;cision au top
10 not&#233;e P10, veut dire que la bonne traduction est pr&#233;sente parmi les 10 candidats renvoy&#233;s
par la m&#233;thode. Nous utilisons aussi la mesure MAP qui renvoie une vision plus globale sur le
comportement de chaque m&#233;thode (Laroche et Langlais, 2010). Comme la m&#233;thode directe est
tr&#232;s sensible aux mesures d&#8217;association et de similarit&#233; utilis&#233;es, nous avons choisi les 3 couples
de mesures les plus connus dans l&#8217;&#233;tat de l&#8217;art, &#224; savoir : le taux de vraisemblance et le Jaccard
not&#233; (Log-Jac) (Morin, 2009), le Odds-Ratio et le cosinus not&#233; (Odds-Cos) (Laroche et Langlais,
2010) ainsi que l&#8217;information mutuelle et le cosinus not&#233; (Im-Cos) (Gamallo, 2008a). Ainsi,
chaque case de la table 7 correspond &#224; une mesure d&#8217;association et &#224; une mesure de similarit&#233;
pour les 4 m&#233;thodes test&#233;es sur le corpus du cancer du sein. La table 8 concerne le corpus des
&#233;nergies renouvelables et respecte la m&#234;me configuration que la premi&#232;re table.
</p>
<p>Dans la table 7, nous constatons que pour la configuration Log-Jac et w = 5, les deux m&#233;thodes
de combinaisons propos&#233;es obtiennent de meilleurs r&#233;sultats que w = 5 et RelDep, avec une
MAP de 0,485 pour Combpost et de 0,488 pour Combapri alors que RelDep et w = 5 n&#8217;obtiennent
</p>
<p>4.
5.
6.
7.
8.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>251 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Log-Jac Odds-Cos Im-Cos
P1 P10 MAP P1 P10 MAP P1 P10 MAP
</p>
<p>RelDep 19,67 49,18 0,297 12,29 46,72 0,237 27,05 48,36 0,332
w = 5 31,15 63,93 0,416 26,23 59,84 0,380 34,43 57,38 0,431
Combpost 36,88 68,85 0,485 38,52 63,93 0,473 41,80 61,48 0,482
Combapri 38,52 68,85 0,488 40,16 71,31 0,497 28,69 52,46 0,373
</p>
<p>&#8212;&#8212;&#8211; &#8212;&#8212;&#8211; &#8212;&#8212;&#8211;
RelDep 19,67 49,18 0,297 12,29 46,72 0,237 27,05 48,36 0,332
w = 9 31,97 66,39 0,435 21,31 60,66 0,343 20,49 51,64 0,305
Combpost 36,07 75,41 0,494 35,25 68,03 0,460 40,98 59,84 0,464
Combapri 41,80 77,05 0,536 38,52 75,41 0,492 16,39 40,16 0,252
</p>
<p>&#8212;&#8212;&#8211; &#8212;&#8212;&#8211; &#8212;&#8212;&#8211;
RelDep 19,67 49,18 0,297 12,29 46,72 0,237 27,05 48,36 0,332
w = 15 27,87 62,30 0,387 17,21 53,28 0,302 13,12 40,16 0,226
Combpost 34,43 70,49 0,475 37,70 64,75 0,472 31,97 59,02 0,412
Combapri 34,43 72,95 0,473 37,70 70,49 0,482 13,12 33,61 0,202
</p>
<p>&#8212;&#8212;&#8211; &#8212;&#8212;&#8211; &#8212;&#8212;&#8211;
</p>
<p>TABLE 7 &#8211; Pr&#233;cision (%) pour les tops 1 et 10 ainsi que la MAP pour le corpus &#171; Cancer du sein &#187;.
Comparaison de l&#8217;approche directe par repr&#233;sentation graphique et de celle par repr&#233;sentation
syntaxique ainsi que des deux m&#233;thodes de combinaisons (les am&#233;liorations indiquent une
significativit&#233; avec un indice de confiance de 0,05 utilisant le test de Student).
</p>
<p>que 0,297 et 0,416. Ce m&#234;me constat peut &#234;tre fait pour les autres valeurs de w (9 et 15). Ainsi
concernant la configuration Log-Jac, les deux m&#233;thodes de combinaison propos&#233;es obtiennent
de meilleurs r&#233;sultats que les deux repr&#233;sentations contextuelles prises s&#233;par&#233;ment, avec un
avantage pour la m&#233;thode Combapri qui obtient une MAP de 0,536 en combinant RelDep
avec w = 9. Nous pouvons constater que, pour la configuration Odds-Cos, c&#8217;est la m&#233;thode
Combapri qui obtient les meilleurs r&#233;sultats avec une MAP de 0,497 pour un w = 5. Concernant
la configuration Im-Cos, c&#8217;est Combpost qui obtient les meilleurs r&#233;sultats, et Combapri n&#8217;apporte
aucune am&#233;lioration et d&#233;grade m&#234;me les r&#233;sultats dans certains cas. Pour r&#233;sumer, nous pouvons
dire que les deux m&#233;thodes propos&#233;es am&#233;liorent les performances de la m&#233;thode directe, avec
une efficacit&#233; variable &#233;troitement li&#233;e aux mesures d&#8217;association et de similarit&#233; utilis&#233;es.
</p>
<p>Pour la table 8 concernant le corpus des &#233;nergies renouvelables, nous pouvons aussi constater que
pour la configuration Log-Jac et w = 5, les deux m&#233;thodes de combinaisons propos&#233;es obtiennent
de meilleurs r&#233;sultats que w = 5 et RelDep, avec une MAP de 0,365 pour Combpost et de 0,354
pour Combapri alors que RelDep et w = 5 n&#8217;obtiennent que 0,257 et 0,272. Globalement, c&#8217;est la
m&#233;thode Combpost qui obtient les meilleurs r&#233;sultats. Ce que l&#8217;on peut retenir des deux tables
c&#8217;est que Combpost et Combapri am&#233;liorent les r&#233;sultats pour toutes les combinaisons de mesures
sauf pour Combapri qui ne fonctionne pas avec le couple (Im-Cos).
</p>
<p>5 Discussion
</p>
<p>Le but de ce travail &#233;tait dans un premier temps, de comparer les deux principales repr&#233;sentations
contextuelles utilis&#233;es dans la m&#233;thode directe, et dans un second temps de proposer deux
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>252 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Log-Jac Odds-Cos Im-Cos
P1 P10 MAP P1 P10 MAP P1 P10 MAP
</p>
<p>RelDep 18,00 40,00 0,257 09,00 32,00 0,163 11,00 41,00 0,191
w = 5 18,00 47,00 0,272 13,00 41,00 0,217 14,00 44,00 0,221
Combpost 28,00 55,00 0,365 22,00 59,00 0,335 21,00 55,00 0,321
Combapri 28,00 56,00 0,354 20,00 55,00 0,317 09,00 38,00 0,177
</p>
<p>&#8212;&#8212;&#8211; &#8212;&#8212;&#8211; &#8212;&#8212;&#8211;
RelDep 18,00 40,00 0,257 09,00 32,00 0,163 11,00 41,00 0,191
w = 9 21,00 42,00 0,270 11,00 36,00 0,194 08,00 31,00 0,152
Combpost 28,00 54,00 0,358 23,00 55,00 0,334 20,00 49,00 0,289
Combapri 26,00 52,00 0,350 19,00 55,00 0,318 07,00 29,00 0,137
</p>
<p>&#8212;&#8212;&#8211; &#8212;&#8212;&#8211; &#8212;&#8212;&#8211;
RelDep 18,00 40,00 0,257 09,00 32,00 0,163 11,00 41,00 0,191
w = 15 12,00 34,00 0,207 06,00 35,00 0,143 03,00 22,00 0,093
Combpost 22,00 50,00 0,316 20,00 52,00 0,316 13,00 42,00 0,234
Combapri 22,00 52,00 0,311 20,00 49,00 0,314 06,00 24,00 0,118
</p>
<p>&#8212;&#8212;&#8211; &#8212;&#8212;&#8211; &#8212;&#8212;&#8211;
</p>
<p>TABLE 8 &#8211; Pr&#233;cision (%) pour les tops 1 et 10 ainsi que la MAP pour le corpus &#171; &#233;nergies
renouvelables &#187;. Comparaison de l&#8217;approche directe par repr&#233;sentation graphique et de celle
par repr&#233;sentation syntaxique ainsi que des deux m&#233;thodes de combinaisons (les am&#233;liorations
indiquent une significativit&#233; avec un indice de confiance de 0,05 utilisant le test de Student).
</p>
<p>nouvelles mani&#232;res de les combiner pour augmenter les performances. La premi&#232;re remarque
concerne l&#8217;utilisation de la repr&#233;sentation graphique w = k. Il est &#233;vident que le choix de la taille
de la fen&#234;tre joue un r&#244;le important, comme nous avons pu le constater dans les diff&#233;rentes
exp&#233;riences montr&#233;es dans les tables 7 et 8. Dans la plupart des cas, ce sont des fen&#234;tres de
taille 5 et 9 qui donnent les meilleurs r&#233;sultats. Ceci montre que la caract&#233;risation du contexte
des mots par ceux qui leurs sont tr&#232;s proches semble &#234;tre la mani&#232;re la plus ad&#233;quate, si l&#8217;on se
base sur une caract&#233;risation par fen&#234;tre contextuelle. Le fait de choisir des fen&#234;tres de taille plus
grande n&#8217;am&#233;liore pas significativement les r&#233;sultats dans nos exp&#233;riences.
</p>
<p>La deuxi&#232;me remarque concerne la m&#233;thode par repr&#233;sentation syntaxique RelDep. Cette m&#233;th-
ode utilis&#233;e par Gamallo (2008a) donne dans ses exp&#233;riences de meilleurs r&#233;sultats que la
m&#233;thode par repr&#233;sentation graphique. Cependant dans nos exp&#233;riences, la m&#233;thode RelDep
reste globalement en de&#231;&#224; de w = k. Ceci s&#8217;explique par deux facteurs. Le premier concerne la
taille des corpus. Gamallo (2008a) avait utilis&#233; des corpus de tr&#232;s grande taille (10 millions de
mots environs) contrairement &#224; nos corpus sp&#233;cialis&#233;s qui sont de petite taille (600 000 et 1
million de mots). Le deuxi&#232;me facteur, qui est directement li&#233; au premier, concerne la mani&#232;re
de consid&#233;rer les entr&#233;es des vecteurs de contexte de la m&#233;thode RelDep. Si dans le vecteur de
contexte d&#8217;un mot X , il existe un mot Y avec une relation Lmod de X avec un score SYLmod et une
autre relation Rob j avec un score SYRob j , alors dans ce vecteur de contexte YLmod et YRob j sont
consid&#233;r&#233;s comme &#233;tant deux mots diff&#233;rents, bien que ce soit le m&#234;me mot avec deux relations
de d&#233;pendances distinctes, ce qui rend la m&#233;thode RelDep plus sensible aux petits corpus que
w = k. Ceci explique les performances de la m&#233;thode de combinaison a priori des contextes. En
effet, la m&#233;thode Combapri comble le manque de la m&#233;thode RelDep, car elle consid&#232;re les deux
informations v&#233;hicul&#233;es par les deux repr&#233;sentations contextuelles. Ainsi, le fait d&#8217;exploiter une
fen&#234;tre de taille k va permettre d&#8217;avoir une information sur le nombre de fois qu&#8217;un mot appara&#238;t
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>253 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>dans le contexte d&#8217;un autre et, comme deuxi&#232;me information plus fine la nature des relations qui
existent entre deux mots.
</p>
<p>Par ailleurs, nous avons pu constater que la m&#233;thode Combapri &#233;tait plus sensible aux modi-
fications des mesures d&#8217;association et de similarit&#233; par rapport &#224; la m&#233;thode Combpost . Ceci
s&#8217;explique par le fait que Combpost agit sur les scores a posteriori alors que Combapri agit di-
rectement sur le contenu des vecteurs de contexte. Les moins bons r&#233;sultats sur le corpus des
&#233;nergies renouvelables s&#8217;expliquent par la moins bonne qualit&#233; de ce corpus en comparaison
avec celui du cancer du sein, ainsi que sa plus petite taille. Son utilisation a n&#233;anmoins permis
de montrer que, m&#234;me avec un corpus de tr&#232;s petite taille, les deux m&#233;thodes propos&#233;es restent
plus performantes que les deux repr&#233;sentations contextuelles prises s&#233;par&#233;ment.
</p>
<p>6 Conclusion
</p>
<p>Nous nous sommes int&#233;ress&#233;s dans cet article aux deux principales mani&#232;res de repr&#233;senter le
contexte des mots, &#224; savoir : une repr&#233;sentation graphique ainsi qu&#8217;une repr&#233;sentation syntaxique.
Nous avons ensuite introduit deux nouvelles techniques de combinaison de ces repr&#233;sentations.
Les deux approches de combinaisons contextuelles propos&#233;es ont montr&#233; des r&#233;sultats sup&#233;rieurs
&#224; l&#8217;utilisation de chaque repr&#233;sentation s&#233;par&#233;ment, pour la plupart des param&#232;tres de configura-
tions. Nous esp&#233;rons que ce travail ouvrira la voie &#224; une recherche plus approfondie concernant
l&#8217;enrichissement du contenu des vecteurs de contexte par des informations multiples sur les
mots les composant. Si les travaux de cet article se sont limit&#233;s &#224; deux types d&#8217;informations
contextuelles, d&#8217;autres informations sont envisageables comme l&#8217;utilisation de thesaurus ou
d&#8217;autres informations comme les cognats, les translitt&#233;rations, les collocations, etc.
</p>
<p>Remerciements
</p>
<p>Ce travail qui s&#8217;inscrit dans le cadre du projet CRISTAL a b&#233;n&#233;fici&#233;
d&#8217;une aide de l&#8217;Agence National de la Recherche portant la r&#233;f&#233;rence ANR-12-CORD-0020.
</p>
<p>R&#233;f&#233;rences
</p>
<p>ANDRADE, D., MATSUZAKI, T. et TSUJII, J. (2011). Effective use of dependency structure for
bilingual lexicon creation. In Proceedings of the 12th International Conference on Computational
Linguistics and Intelligent Text Processing (CICLing&#8217;11), pages 80&#8211;92, Tokyo, Japan.
</p>
<p>ASLAM, J. A. et MONTAGUE, M. (2001). Models for Metasearch. In Proceedings of the 24th Annual
SIGIR Conference (SIGIR&#8217;01,), pages 275&#8211;284, New Orleans, Louisiana.
</p>
<p>BOWKER, L. et PEARSON, J. (2002). Working with Specialized Language : A Practical Guide to
Using Corpora. Routeledge, New York, USA.
</p>
<p>BROSSEAU-VILLENEUVE, B., NIE, J.-Y. et KANDO, N. (2010). Towards an optimal weighting of context
words based on distance. In Proceedings of the 23rd International Conference on Computational
Linguistics (COLING&#8217;10), pages 107&#8211;115, Beijing, China.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>254 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#201;JEAN, H., GAUSSIER, &#201;. et SADAT, F. (2002). An approach based on multilingual thesauri and
model combination for bilingual lexicon extraction. In Proceedings of the 19th International
Conference on Computational Linguistics (COLING&#8217;02), pages 1&#8211;7, Taipei, Taiwan.
D&#201;JEAN, H. et GAUSSIER, E. (2002). Une nouvelle approche &#224; l&#8217;extraction de lexiques bilingues &#224;
partir de corpus comparables. Lexicometrica, Alignement Lexical dans les Corpus Multilingues,
pages 1&#8211;22.
FIRTH, J. R. (1957). A synopsis of linguistic theory 1930&#8211;1955. In Studies in Linguistic Analysis
(special volume of the Philological Society), pages 1&#8211;32. Blackwell, Oxford.
FUNG, P. (1995). Compiling Bilingual Lexicon Entries From a non-Parallel English-Chinese
Corpus. In FARWELL, D., GERBER, L. et HOVY, E., &#233;diteurs : Proceedings of the 3rd Conference of the
Association for Machine Translation in the Americas (AMTA&#8217;95), pages 1&#8211;16, Langhorne, PA, USA.
FUNG, P. (1998). A statistical view on bilingual lexicon extraction : From parallel corpora to
non-parallel corpora. In Proceedings of Machine Translation and the Information Soup, Third
Conference of the Association for Machine Translation in the Americas (AMTA&#8217;98), pages 1&#8211;17,
Langhorne, PA, USA.
FUNG, P. et YEE, L. Y. (1998). An ir approach for translating new words from non parallel,
comparable texts. In Proceedings of the 17th international conference on Computational linguistics
(COLING&#8217;98), pages 414&#8211;420, Quebec, Canada.
GAMALLO, O. (2007). Learning bilingual lexicons from comparable english and spanish corpora.
In Proceedings of Machine Translation Summit XI, pages 191&#8211;198, Copenhagen, Denmark.
GAMALLO, O. (2008a). Evaluating two different methods for the task of extracting bilingual
lexicons from comparable corpora. In Proceedings of LREC 2008 Workshop on Comparable
Corpora (LREC&#8217;08), pages 19&#8211;26, Marrakech, Marroco.
GAMALLO, O. (2008b). The meaning of syntactic dependencies. Linguistik Online.
GARERA, N., CALLISON-BURCH, C. et YAROWSKY, D. (2009). Improving translation lexicon induc-
tion from monolingual corpora via dependency contexts and part-of-speech equivalences. In
Proceedings of Thirteenth Conference on Computational Natural Language Learning (CoNLL&#8217;09),
pages 129&#8211;137, Boulder, Colorado, USA.
GAUSSIER, E., RENDERS, J.-M., MATVEEVA, I., GOUTTE, C. et D&#201;JEAN, H. (2004). A geometric view
on bilingual lexicon extraction from comparable corpora. In Proceedings of the 42nd Annual
Meeting of the Association for Computational Linguistics (ACL&#8217;04), pages 526&#8211;533, Barcelona,
Spain.
GROC, C. D. (2011). Babouk : Focused Web Crawling for Corpus Compilation and Automatic
Terminology Extraction. In Proceedings of The IEEE WICACM International Conferences on Web
Intelligence, pages 497&#8211;498, Lyon, France.
HAGHIGHI, A., LIANG, P., BERG-KIRKPATRICK, T. et KLEIN, D. (2008). Learning bilingual lexicons
from monolingual corpora. In Proceedings of the 46nd Annual Meeting of the Association for
Computational Linguistics (ACL&#8217;08), pages 771&#8211;779, Columbus, Ohio.
LAROCHE, A. et LANGLAIS, P. (2010). Revisiting context-based projection methods for term-
translation spotting in comparable corpora. In Proceedings of the 23rd International Conference
on Computational Linguistics (COLING&#8217;10), pages 617&#8211;625, Beijing, China.
LI, B. et GAUSSIER, &#201;. (2010). Improving corpus comparability for bilingual lexicon extraction
from comparable corpora. In Proceedings of the 23rd International Conference on Computational
Linguistics (COLING&#8217;10), pages 644&#8211;652, Beijing, China.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>255 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>LI, B., GAUSSIER, E., MORIN, E. et HAZEM, A. (2011). Degr&#233; de comparabilit&#233;, extraction lexicale
bilingue et recherche d&#8217;information interlingue. In Actes de la 18&#232;me Conf&#233;rence Traitement
Automatique des Langues Naturelles (TALN&#8217;11), pages 283&#8211;293, Montpellier, France.
</p>
<p>LIN, D. (1998). Dependency-based evaluation of minipar. In Proceedings of the Workshop on
the Evaluation of Parsing Systems, First International Conference on Language Resources and
Evaluation (LREC&#8217;98), Granada, Spain.
</p>
<p>MORIN, E. (2009). Apport d&#8217;un corpus comparable d&#233;s&#233;quilibr&#233; &#224; l&#8217;extraction de lexiques
bilingues. In Actes de la 16&#232;me Conf&#233;rence Traitement Automatique des Langues Naturelles
(TALN&#8217;09), Senlis, France.
</p>
<p>MORIN, E. et DAILLE, B. (2004). Extraction terminologique bilingue &#224; partir de corpus compara-
bles d&#8217;un domaine sp&#233;cialis&#233;. Traitement Automatique des Langues. TAL, 45(3):103&#8211;122.
</p>
<p>MORIN, E., DUFOUR-KOWALSKI, S. et DAILLE, B. (2004). Extraction de terminologies bilingues
&#224; partir de corpus comparables. In Actes de la 11&#232;me Conf&#233;rence Traitement Automatique des
Langues Naturelles (TALN&#8217;04), pages 309&#8211;318, F&#232;s, Maroc.
</p>
<p>PROCHASSON, E. et MORIN, E. (2009). Influence des points d&#8217;ancrage pour l&#8217;extraction lexicale
bilingue &#224; partir de corpus comparables sp&#233;cialis&#233;s. In Actes de la 16&#232;me Conf&#233;rence Traitement
Automatique des Langues Naturelles (TALN&#8217;09), Senlis, France.
</p>
<p>RAPP, R. (1995). Identify Word Translations in Non-Parallel Texts. In Proceedings of the 35th
Annual Meeting of the Association for Computational Linguistics (ACL&#8217;95), pages 320&#8211;322, Boston,
MA, USA.
</p>
<p>RAPP, R. (1999). Automatic Identification of Word Translations from Unrelated English and
German Corpora. In Proceedings of the 37th Annual Meeting of the Association for Computational
Linguistics (ACL&#8217;99), pages 519&#8211;526, College Park, MD, USA.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>256 c&#65535; ATALA</p>

</div></div>
</body></html>