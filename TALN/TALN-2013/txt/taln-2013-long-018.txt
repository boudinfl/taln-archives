TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Extraction de lexiques bilingues a partir de corpus
comparables par combinaison de représentations
contextuelles

Amir HAZEM Emmanuel MORIN
LINA - UMR CNRS 6241, 2 rue de la houssiniere, BP 92208, 44322 Nantes Cedex 03
amir . hazem©univ—nantes .fr , emmanuel .morin@un:'Lv—nantes . fr

RESUME
La caractérisation du contexte des mots constitue le coeur de la plupart des méthodes d’extraction
de lexiques bilingues a partir de corpus comparables. Dans cet article, nous revisitons dans un
premier temps les deux principales stratégies de représentation contextuelle, a savoir celle par
fenétre ou sac de mots et celle par relations de dépendances syntaxiques. Dans un second temps,
nous proposons deux nouvelles approches qui exploitent ces deux représentations de maniére
conjointe. Nos expériences montrent une amélioration signiﬁcative des résultats sur deux corpus
de langue de spécialité.

ABSTRACT
Bilingual Lexicon Extraction from Comparable Corpora by Combining Contextual Repre-
sentations

Word’s context characterisation constitute the heart of most methods of bilingual lexicon
extraction from comparable corpora. In this article, we ﬁrst revisit the two main strategies of
context representation, that is : the window—based and the syntactic based context representation.
Secondly, we propose two new methods that exploit jointly these different representations . Our
experiments show a signiﬁcant improvement of the results obtained on two different domain
speciﬁc comparable corpora.

MOTS-CLES : Multilingualisme, corpus comparables, lexique bilingue, vecteurs de contexte,
dépendances syntaxiques.

KEYWORDS: Multilingualism, comparable corpora, bilingual lexicon, context vectors, syntactic
dependencies.

1 Introduction

Les lexiques bilingues sont une ressource importante pour différentes applications relevant du
traitement automatique des langues comme en traduction assistée par ordinateur ou en recherche
d’information inter—langue. Bien que les travaux s’appuyant sur des corpus paralléles 1 aient
montré de trés bons résultats, ce type de corpus reste difﬁcile a collecter (Fung et Yee, 1998) et

1. Un corpus paralléle est un ensemble de textes accompagnés de leurs traductions dans une ou plusieurs langues
(Bowker et Pearson, 2002).

243 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

plus particulierement quand il s’agit de traiter des corpus spécialisés ou des couples de langues
rares ou moins usitées (Morin et al., 2004). L’exploitation des corpus comparables 2 a marqué un
tournant dans la tache d’extraction de lexiques bilingues, et suscite un intérét constant depuis
le milieu des années 1990 grace a l’abondance et la disponibilité de tels corpus (Rapp, 1995;
Fung, 1995; Rapp, 1999; Déjean et al., 2002; Gaussier et al., 2004; Morin et al., 2004; Laroche
et Langlais, 2010). L’essor du Web ayant sensiblement facilité la collecte de grandes quantités
de données multilingues, les corpus comparables se sont naturellement imposés comme une
alternative aux corpus paralléles. Ils ont donné lieu a plusieurs travaux dont le dénominateur
commun est l’hypothése selon laquelle les mots qui sont en correspondance de traduction,
ont de grandes chances d’apparaitre dans les mémes contextes (Rapp, 1999). Cette hypothése
découle directement de la proposition souvent citée de Firth (1957) : « On reconnaft un mot c‘1 ses

fréquentations » 3.

Rapp (1995) et Fung (1995) ont été les premiers 2 introduire les corpus comparables. Ils se sont
appuyés sur l’idée de caractérisation du contexte des mots, contrairement aux travaux s’appuyant
sur les corpus paralléles, qui eux se basaient sur des informations positionnelles. En 1998, Fung
(1998) a introduit la méthode directe, reprise dans de nombreux travaux, notamment ceux de
(Rapp, 1999). Dans cette méthode, la traduction d’un mot comporte plusieurs étapes. Le mot est
tout d’abord caractérisé par un vecteur représentatif de son contexte. Puis, ce vecteur est traduit
dans la langue cible a l’aide d’un dictionnaire aussi appelé lexique de transfert ou lexique pivot.
Enﬁn, il reste a comparer ce vecteur avec tous les vecteurs de contexte des mots de la langue
cible, et en extraire les n plus proches comme traductions candidates. Par la suite, une partie
des travaux a porté sur l’adaptation et l’amélioration de cette méthode a différents types de
corpus (corpus de langue générale ou de spe’cialité), et a différentes langues et différents types
de termes (termes simples, termes complexes, collocations, etc.) (Déjean et Gaussier, 2002),
(Morin et Daille, 2004). De nouvelles méthodes ont également été proposées telles que l’approche
par similarité interlangue (Déjean et Gaussier, 2002), 1’uti1isation de l’Analyse en Composantes
Canoniques (CCA) (Haghighi et al., 2008). Récemment, Li et Gaussier (2010) et Li et al. (2011) se
sont intéressés a l’aspect inverse qui consiste a améliorer la comparabilité des corpus comparables
aﬁn d’augmenter l’efﬁcacité des méthodes d’extraction de lexiques bilingues.

La plupart des travaux utilisant les corpus comparables ont comme dénominateur commun
le contexte, qui représente le coeur de l’extraction lexicale bilingue. La question principale a
se poser est alors la suivante : étant donné un mot quelconque, comment choisir les mots
qui caractérisent au mieux son contexte ? Selon l’état de l’art, le contexte d’un mot donné est
habituellement représenté par les mots faisant partie de son environnement, c’est—a—dire, les
mots qui l’entourent. Ces mots sont extraits, soit a l’aide d’une fenétre contextuelle (Rapp, 1999;
Déjean et Gaussier, 2002), soit a l’aide des relations de dépendances syntaxiques (Gamallo,
2007). L’un des problemes sous-jacent au contexte extrait a l’aide des fenétres contextuelles est
le choix de la taille des fenétres. Celle-ci est habituellement ﬁxée empiriquement, et bien que
différentes études aient montré une tendance a choisir des fenétres de petite taille quand il s’agit
de caractériser des mots fréquents, et des fenétres de grande taille quand il s’agit de caractériser
des mots peu fréquents (Prochasson et Morin, 2009), cela reste imprécis car il n’y a toujours pas
de méthode dite optimale pour le choix de la taille de la fenétre contextuelle. Quant aux relations
de dépendances syntaxiques, leur efﬁcacité est trés sensible a la taille des corpus, et bien que cette

2. Un COI‘p11S comparable est une collection de documents multilingues produits généralement a la méme période et
traitant des mémes sujets.
3. « You shall know a word by the company it keeps »

244 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Log-Jac Odds-Cos Im-Cos
P1 P10 MAP P1 P1 0 MAP P1 P10 MAP

RelDep 18,00 40,00 0,257 09,00 32,00 0,163 11,00 41,00 0,191
w = 5 18,00 47,00 0,272 13,00 41,00 0,217 14,00 44,00 0,221
Combpost 28,00 55,00 0,365 22,00 59,00 0,335 21,00 55,00 0,321
C ombaP,,- 28,00 56,00 0,354 20,00 55,00 0,317 09,00 38,00 0,177

RelDep 18,00 40,00 0,257 09,00 32,00 0,163 11,00 41,00 0,191
w = 9 21,00 42,00 0,270 11,00 36,00 0,194 08,00 31,00 0,152
C ombpost 28,00 54,00 0,358 23,00 55,00 0,334 20,00 49,00 0,289
CombaP,,~ 26,00 52,00 0,350 19,00 55,00 0,318 07,00 29,00 0,137

RelDep 18,00 40,00 0,257 09,00 32,00 0,163 11,00 41,00 0,191
w = 15 12,00 34,00 0,207 06,00 35,00 0,143 03,00 22,00 0,093
C ombpost 22,00 50,00 0,316 20,00 52,00 0,316 13,00 42,00 0,234
C ombapﬁ 22,00 52,00 0,311 20,00 49,00 0,314 06,00 24,00 0,118

TABLE 8 — Précision (%) pour les tops 1 et 10 ainsi que la MAP pour le corpus << énergies
renouvelables >>. Comparaison de l’approche directe par représentation graphique et de celle
par représentation syntaxique ainsi que des deux méthodes de combinaisons (les améliorations
indiquent une signiﬁcativité avec un indice de conﬁance de 0,05 utilisant le test de Student).

nouvelles maniéres de les combiner pour augmenter les performances. La premiere remarque
concerne l’ut1'lisation de la représentation graphique w = k. 11 est évident que le choix de la taille
de la fenétre joue un role important, comme nous avons pu le constater dans les différentes
expériences montrées dans les tables 7 et 8. Dans la plupart des cas, ce sont des fenétres de
taille 5 et 9 qui donnent les meilleurs résultats. Ceci montre que la caractérisation du contexte
des mots par ceux qui leurs sont tres proches semble étre la maniere la plus adéquate, si l’on se
base sur une caractérisation par fenétre contextuelle. Le fait de choisir des fenétres de taille plus
grande n’améliore pas signiﬁcativement les résultats dans nos expériences.

La deuxieme remarque concerne la méthode par représentation syntaxique RelDep. Cette méth-
ode utilisée par Gamallo (2008a) donne dans ses expériences de meilleurs résultats que la
méthode par représentation graphique. Cependant dans nos expériences, la méthode RelDep
reste globalement en deca de w = k. Ceci s’explique par deux facteurs. Le premier concerne la
taille des corpus. Gamallo (2008a) avait utilise’ des corpus de tres grande taille (10 millions de
mots environs) contrairement a nos corpus spécialisés qui sont de petite taille (600 000 et 1
million de mots). Le deuxiéme facteur, qui est directement lié au premier, concerne la maniére
de considérer les entre’es des vecteurs de contexte de la méthode RelDep. Si dans le vecteur de
contexte d’un mot X, il existe un mot Y avec une relation Lmod de X avec un score Symd et une
autre relation Ro b j avec un score Symj, alors dans ce vecteur de contexte Ymod et Yﬂobj sont
considérés comme étant deux mots différents, bien que ce soit le méme mot avec deux relations
de dépendances distinctes, ce qui rend la méthode RelDep plus sensible aux petits corpus que
w = k. Ceci explique les performances de la méthode de combinaison a priori des contextes. En
effet, la méthode Combam comble le manque de la méthode RelDep, car elle considére les deux
informations véhiculées par les deux representations contextuelles. Ainsi, le fait d’exploiter une
fenétre de taille k va permettre d’avoir une information sur le nombre de fois qu’un mot apparait

253 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

dans le contexte d’un autre et, comme deuxieme information plus ﬁne la nature des relations qui
existent entre deux mots.

Par ailleurs, nous avons pu constater que la méthode Comba,,,,- était plus sensible aux modi-
ﬁcations des mesures d’association et de similarité par rapport a la méthode Combpost. Ceci
s’explique par le fait que Combpos, agit sur les scores a posteriori alors que Comba,,,,- agit di-
rectement sur le contenu des vecteurs de contexte. Les moins bons résultats sur le corpus des
énergies renouvelables s’expliquent par la moins bonne qualité de ce corpus en comparaison
avec celui du cancer du sein, ainsi que sa plus petite taille. Son utilisation a néanmoins permis
de montrer que, méme avec un corpus de trés petite taille, les deux méthodes proposées restent
plus performantes que les deux représentations contextuelles prises séparément.

6 Conclusion

Nous nous sommes intéressés dans cet article aux deux principales maniéres de représenter le
contexte des mots, a savoir : une représentation graphique ainsi qu’une représentation syntaxique.
Nous avons ensuite introduit deux nouvelles techniques de combinaison de ces représentations.
Les deux approches de combinaisons contextuelles proposées ont montré des résultats supérieurs
a l’utilisation de chaque représentation séparément, pour la plupart des parametres de conﬁgura-
tions. Nous espérons que ce travail ouvrira la voie a une recherche plus approfondie concernant
l’enrichissement du contenu des vecteurs de contexte par des informations multiples sur les
mots les composant. Si les travaux de cet article se sont limités a deux types d’informations
contextuelles, d’autres informations sont envisageables comme l’utilisation de thesaurus ou
d’autres informations comme les cognats, les translittérations, les collocations, etc.

Remerciements

Ce travail qui s’inscrit dans le cadre du projet CRISTAL www . pro j et — crist a1 . org a bénéﬁcié
d’une aide de l’Agence National de la Recherche portant la référence ANR—12—CORD-0020.

Références

ANDRADE, D., MATSUZAKI, T. et TSUJII, J. (2011). Effective use of dependency structure for
bilingual lexicon creation. In Proceedings of the 12th International Conference on Computational
Linguistics and Intelligent Text Processing (CICLing’1 1), pages 80-92, Tokyo, Japan.

AsLAM, J. A. et MONTAGUE, M. (2001). Models for Metasearch. In Proceedings of the 24th Annual
SIGIR Conference (SIGIR’01,), pages 275-284, New Orleans, Louisiana.

BOWKER, L. et PEARSON, J. (2002). Working with Specialized Language : A Practical Guide to
Using Corpora. Routeledge, New York, USA.

BROSSEAU-VILLENEUVE, B., NIE, J .—Y. et KANDO, N. (2010). Towards an optimal weighting of context
words based on distance. In Proceedings of the 23rd International Conference on Computational
Linguistics (COLING’10), pages 107-115, Beijing, China.

254 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

DEJEAN, H., GAUSSIER, E. et SADAT, E (2002). An approach based on multilingual thesauri and
model combination for bilingual lexicon extraction. In Proceedings of the 19th International
Conference on Computational Linguistics (COLING’02), pages 1-7, Taipei, Taiwan.

DEJEAN, H. et GAUSSIER, E. (2002). Une nouvelle approche a l’extracu'on de lexiques bilingues a
partir de corpus comparables. Lexicometrica, Alignement Lexical dans les Corpus Multilingues,
pages 1-22.

FIRTH, J. R. (1957). A synopsis of linguistic theory 1930-1955. In Studies in Linguistic Analysis
(special volume of the Philological Society), pages 1-32. Blackwell, Oxford.

FUNG, P. (1995). Compiling Bilingual Lexicon Entries From a non-Parallel English-Chinese
Corpus. In FARWELL, D., GERBER, L. et How, E., éditeurs : Proceedings of the 3rd Conference of the
Association for Machine Translation in the Americas (AMTA’95), pages 1-16, Langhorne, PA, USA.

FUNG, P. (1998). A statistical view on bilingual lexicon extraction : From parallel corpora to
non—parallel corpora. In Proceedings of Machine Translation and the Information Soup, Third
Conference of the Association for Machine Translation in the Americas (AMTA’98), pages 1-17,
Langhorne, PA, USA.

FUNG, P. et YEE, L. Y. (1998). An ir approach for translating new words from non parallel,
comparable texts. In Proceedings of the 17th international conference on Computational linguistics
(COLING’98), pages 414-420, Quebec, Canada.

GAMALLO, O. (2007). Learning bilingual lexicons from comparable english and spanish corpora.
In Proceedings of Machine Translation Summit XI, pages 191-198, Copenhagen, Denmark.

GAMALLO, O. (2008a). Evaluating two different methods for the task of extracting bilingual
lexicons from comparable corpora. In Proceedings of LREC 2008 Workshop on Comparable
Corpora (LREC’08), pages 19-26, Marrakech, Marroco.

GAMALLO, O. (2008b). The meaning of syntactic dependencies. Linguistik Online.

GARERA, N., CALLISON-BURCH, C. et YAROWSKY, D. (2009). Improving translation lexicon induc-
tion from monolingual corpora via dependency contexts and part-of-speech equivalences. In
Proceedings of Thirteenth Conference on Computational Natural Language Learning (CoNLI.’09),
pages 129-137, Boulder, Colorado, USA.

GAUSSIER, E., RENDERS, J.—M., MATVEEVA, I., GOUTTE, C. et DEJEAN, H. (2004). A geometric view
on bilingual lexicon extraction from comparable corpora. In Proceedings of the 42nd Annual
Meeting of the Association for Computational Linguistics (ACL’04), pages 526-533, Barcelona,
Spain.

GROC, C. D. (2011). Babouk : Focused Web Crawling for Corpus Compilation and Automatic
Terminology Extraction. In Proceedings of The IEEE WICACM International Conferences on Web
Intelligence, pages 497-498, Lyon, France.

HAGHIGHI, A., LIANG, R, BERG-KIRKPATRICK, T‘. et KLEIN, D. (2008). Learning bilingual lexicons
from monolingual corpora. In Proceedings of the 46nd Annual Meeting of the Association for
Computational Linguistics (ACI.’08), pages 771-779, Columbus, Ohio.

LAROCHE, A. et LANGLAIS, P. (2010). Revisiting context-based projection methods for term-
translation spotting in comparable corpora. In Proceedings of the 23rd International Conference
on Computational Linguistics (COLING’10), pages 617-625, Beijing, China.

LI, B. et GAUSSIER, E. (2010). Improving corpus comparability for bilingual lexicon extraction
from comparable corpora. In Proceedings of the 23rd International Conference on Computational
Linguistics (COLING’10), pages 644-652, Beijing, China.

255 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

L1, B., GAUSSIER, E., MORIN, E. et HAZEM, A. (2011). Degré de comparabilité, extraction lexicale
bilingue et recherche d’information interlingue. In Actes de la 18e‘me Confe’rence T raitement
Automatique des Langues Naturelles (TALN’1 1), pages 283-293, Montpellier, France.

LIN, D. (1998). Dependency-based evaluation of minipar. In Proceedings of the Workshop on
the Evaluation of Parsing Systems, First International Conference on Language Resources and
Evaluation (LREC’98), Granada, Spain.

MORIN, E. (2009). Apport d’un corpus comparable déséquilibré a l’extraction de lexiques
bilingues. In Actes de la 16e‘me Confe’rence Traitement Automatique des Langues Naturelles
(TALN’09), Senlis, France.

MORIN, E. et DAILLE, B. (2004). Extraction terminologique bilingue a partir de corpus compara-
bles d’un domaine spécialisé. Traitement Automatique des Langues. TAL, 45 (3):103—122.

MORIN, E., DUFOUR-KOWALSKI, S. et DAILLE, B. (2004). Extraction de terminologies bilingues
a partir de corpus comparables. In Actes de la 1 1e‘me Confe’rence T raitement Automatique des
Langues Naturelles (TALN’04), Pages 309-318, Fés, Maroc.

PROCHASSON, E. et MORIN, E. (2009). Inﬂuence des points d’ancrage pour l’extraction lexicale
bilingue a partir de corpus comparables spécialisés. In Actes de la 16éme Conférence Traitement
Automatique des Langues Naturelles (TALN’09), Senlis, France.

RAPP, R. (1995). Identify Word Translations in Non—Parallel Texts. In Proceedings of the 35th
Annual Meeting of the Association for Computational Linguistics (ACE95), pages 320-322, Boston,
MA, USA.

RAPP, R. (1999). Automatic Identiﬁcation of Word Translations from Unrelated English and
German Corpora. In Proceedings of the 37th Annual Meeting of the Association for Computational
Linguistics (ACL’99), pages 519-526, College Park, MD, USA.

256 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

représentation soit plus intéressante d’un point de vue sémantique, elle atteint ses limites lorsqu’il
s’agit de traiter des corpus de petite taille. Une proposition, qui vient naturellement a l’esprit
consiste a uﬁliser conjointement ces deux représentations aﬁn de tirer proﬁt de leurs avantages
respecﬁfs. Une premiere approche exploitant les deux représentations proposée par Andrade et al.
(2011) combine quatre modeles staﬁstiques et compare les dépendances lexicales pour identiﬁer
les traductions candidates. Dans cet article, nous proposons une autre maniere de combiner les
deux précédentes représentations contextuelles, partant de l’intuition que cette combinaison
permettrait un lissage du contexte en prenant en compte deux informations complémentaires
qui sont : (i) l’information globale véhiculée par la représentation par fenétre contextuelle et (ii)
une information sémantique plus ﬁne apportée par les relations de dépendances syntaxiques.
L’objectif étant d’amé1iorer la représentation contextuelle et les performances de 1’extraction de
lexiques bilingues a partir de corpus comparables.

Dans la suite de cet article, nous présentons en section 2 les deux principales stratégies de
représentations contextuelles. La section 3 décrit ensuite nos deux approches de combinaison
de contextes. La section 4 se concentre sur l’évaluation des méthodes mises en oeuvre. Nous
terminons enﬁn par une discussion en section 5 et une conclusion en section 6.

2 COIlStl‘l1CtiOIl de contextes

2.1 Cooccurrences graphiques

Le contexte par sac de mots consiste simplement a collecter des mots entourant un mot donné,
sans regles précises hormis le choix du nombre de mots a sa gauche et a sa droite, appelé aussi
fenétre contextuelle. Soit la phrase suivante : «(...) Pour les cas traités pour danger ostéoporotique
les densitométries osseuses comparatives ont montré une amélioration sous THS (...)».

Pour le terme ostéoporotique, si nous choisissons une fenétre contextuelle de taille 5, c’est—a—dire
deux mots a gauche et deux mots a droite de celui—ci. Le contexte de ostéoporotique sera :
traités, danger, densitométries et osseuses. Ce processus est répété autant de fois que le terme
ostéoporotique apparait dans un corpus donné. Cette technique de représentation du contexte a
montré son efﬁcacité surtout 1orsqu’i1 s’agit de mots tres fréquents. Intuitivement, nous pouvons
nous dire que tous les mots entourant un mot donné n’ont pas la méme importance et qu’il serait
parfois utile de ne pas tous les considérer de la méme maniére. Cependant, toute la difﬁculté
réside dans la prise de décision concernant tel ou tel mot. Brosseau—Villeneuve et al. (2010)
proposent une méthode de pondération des mots du contexte selon leur position pour la tache de
désambiguisation du sens des mots. Une autre méthode pour pallier cette difﬁculté consiste en
l’utilisation des relations de dépendances syntaxiques entre les mots que nous présentons dans la
section suivante.

2.2 Cooccurrences syntaxiques

Aﬁn de mieux représenter le contexte d’un mot, plusieurs travaux se sont intéressés aux relations
de dépendances syntaxiques (Gamallo, 2008a; Garera et al., 2009). L’idée n’est plus de représenter
1e contexte seulement par les mots avoisinants mais de rajouter une information supplémentaire

245 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

qui spéciﬁe le type de relation syntaxique entre les mots. Une relation de dépendance est
une relation binaire asymétrique entre un mot appelé téte ou parent (Head or parent) et un
modiﬁcateur ou dépendant (modiﬁer or dependant). Les relations de dépendances forment un
arbre qui inter-connecte tous les mots d’une phrase. Un mot dans une phrase peut avoir plusieurs
modiﬁcateurs mais chaque mot ne peut modiﬁer qu’au plus un seul mot (Lin, 1998). La racine
de l’arbre de dépendance aussi appelée Head, ne modiﬁe aucun mot de la phrase. Une liste
de tuples est utilisée pour représenter un arbre de dépendances : ([word], [category], [head],
[relationshiP]) avec :

— word : est le mot représenté dans le noeud de l’arbre;

— category : constitue la catégorie lexicale du mot (word) ;

— head : spéciﬁe quel mot est modiﬁé par word;

— relationship : est une étiquette attribuée a la relation de dépendance (subj pour subject, spec

pour speciﬁer, etc.).

En outre, le signe « < » signiﬁe précédent et « > » signiﬁe successeur.
Pour la phrase suivante : « I have a brown dog », l’arbre de dépendance serait celui donné en
table 1 :

'I'ype

Noun < have
Verb - -
Det < spec
<
dog Noun > have comp

 

TABLE 1 — Exemple de relations de dépendances syntaxiques

Pour plus de détails concernant les dépendances syntaxiques et plus particuliérement pour les

taches de désambiguisation de mots et de résolution des dépendances, se rapporter a Gamallo

(2008b). Dans Gamallo (2007), trois notions élémentaires de dénotation sont abordées :

— Les mots lexicaux;

— Les dépendances syntaxiques (sujet, relation d’objet direct, relation prépositionnelle entre
deux noms, relation prépositionnelle entre un verbe et un nom, etc.) ;

— Les modéles lexico—syntaxiques qui consiste a combiner les mots et leurs catégories syntaxiques
en terme de dépendance ( Noun+ subj + Verb).

Les mots lexicaux représentent des ensembles de propriétés {Noun, Verb, Adj, Adv  } alors
que les dépendances et les modeles lexico—syntaxiques sont déﬁnis comme des opérations sur
ces ensembles. Une dépendance est une relation binaire qui prend en entrée deux ensembles
de propriétés et donne en sortie un ensemble plus restreint qui est l’intersection des ensembles
données en entrée. Nous retrouvons sept types de relations de dépendances (Gamallo, 2007)
résumés dans la table 2.

Par exemple, pour le mot recurrence, il existe une relation Lmod avec l’adjecu'f local. Ainsi dans le
processus de construction du contexte de recurrence, nous comptabiliserons le nombre de fois
ou l’adjectif local apparait a gauche de recurrence dans le corpus. Nous ferons de méme pour les
autres relations de dépendances syntaxiques.

246 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Relation type Exemple

Lmod modiﬁcateur gauche si relation Adj - Noun local - recurrence

Rmod modiﬁcateur droite si relation Noun - Adj number - insufﬁcient
modN modiﬁcateur de Nom si relation Noun - Noun breast - cancer

Lobj objet a gauche si relation Noun - Verb study - demonstrate
Robj objet a droite si relation Verb - Noun have - effect

PRP si relation prépositionnelle Noun-PRP-Noun malignancy - in - woman
iobj si relation objet indirecte Verb-PRP-Noun occur - in - portion

TABLE 2 — Liste des relations de dépendances syntaxiques

2.3 Synthése

Nous venons de voir deux maniéres de représenter le contexte, a savoir une représentation
graphique (par sac de mots) et une représentation syntaxique (par relations de dépendances
syntaxiques). L’intérét de passer d’une coloration graphique a une coloration syntaxique des
mots peut étre Vu selon deux aspects. Le premier consiste a se dire que l’information véhiculée
par une coloration graphique n’est principalement qu’une information quantitative trés variable
et fortement dépendante des corpus utilisés. D’o1‘1 l’idée d’abandonner ce type de coloration
pour passer a une coloration syntaxique porteuse d’informations qualitatives et idéalement
indépendante de la taille des corpus. Le deuxiéme aspect serait de dire que malgré tout, la
coloration graphique a un intérét et qu’au lieu de s’en écarter il vaudrait peut étre mieux la
combiner avec la coloration syntaxique aﬁn de tirer le meilleur des deux. C’est notre hypothése
de complémentarité entre les informations qualitatives et quantitatives des mots.

3 Combinaison de contextes

Nous nous positionnons ici dans le cadre de l’amélioration de la méthode directe décrite dans
plusieurs travaux dont Fung (1998) et Rapp (1999). Notre démarche vise a montrer que l’ex-
ploitation des deux principales représentations contextuelles a un intérét particulier pour la
téiche de constitution de lexiques bilingues. Nous proposons donc deux maniéres de combiner
les contextes (graphique et syntaxique) que nous appellerons : la combinaison a posteriori des
contextes et la combinaison a priori des contextes.

Une premiere maniére de combiner les deux représentations contextuelles est une combinaison a
posteriori, c’est—a—dire la combinaison des scores renvoyés par la méthode directe selon les deux
représentations. La seconde maniére consiste en une combinaison a priori qui utilise les deux
informations contextuelles a priori dans un méme vecteur pour ensuite appliquer la méthode
directe une seule fois sur l’ensemble du corpus.

3.1 Combinaison a posteriori des contextes

Dans le domaine de la recherche d’information, la combinaison de plusieurs listes renvoyées
par différents moteurs de recherche est souvent utilisée pour améliorer les performances d’un

247 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

systéme de questions/réponses (Aslam et Montague, 2001). Nous partons du principe que chaque
représentation du contexte correspond a une méthode bien déﬁnie. Nous nous retrouvons donc
dans le cas d’une combinaison de deux méthodes bien distinctes. La premiere est la méthode
directe basée sur une représentation graphique et la seconde est la méthode directe basée sur
une représentation syntaxique. Une maniere classique de fusionner les deux méthodes est de
prendre, comme entrée, la sortie de chacune des méthodes citées. Dans notre cas, pour chaque
mot a traduire, nous prenons comme entrée une liste de scores retournée par chacune des deux
méthodes, puis nous fusionnons les deux listes par une simple combinaison arithmétique des
scores. Ceci nous donne une nouvelle liste de mots ordonnés (sachant que les scores fusionnés
sont compatibles a partir du moment o1‘1 nous utilisons la méme mesure de similarité pour les
deux méthodes). En utilisant les scores comme critere de fusion, nous calculons le score de
similarité d’un candidat a la traduction, en sommant les scores qui sont renvoyés par chacune
des deux méthodes comme suit :

Scomb(W) = Sfen(W) + Srel(W) (1)

cu Sw,,,,,(w) est le score ﬁnal du mot w, S fe,,(w) est le score retourné par la méthode directe
basée sur une représentation graphique et S,e,(w) est le score retourné par la méthode directe
basée sur une représentation syntaxique.

Cette équation peut aussi s’écrire comme suit :

Scomb(W) =  X Sfen(W) + (1 _  X Srel(W) (2)

avec A comme indice de conﬁance donné a chaque méthode (A E [0, 1]). Dans notre cas, A = 0, 5,
notre but n’étant pas de trouver la valeur optimale de A pour obtenir les meilleurs résultats.
Différentes expériences ont été menées qui indiquent que les meilleurs résultats sont globalement
ceux montrés dans la section 4 avec un lambda E [0, 5, 0, 6]. Par ailleurs, d’autres méthodes
de combinaisons de scores ont été testées comme la combinaison harmonique des rangs et des
scores (Morin, 2009), mais la méthode que nous avons choisi (combinaison arithmétique des
scores) est celle qui donne les meilleures performances.

3.2 Combinaison a priori des contextes

Le vecteur de contexte a pour but d’enregistrer un ensemble d’informau'on sur le contexte d’un
mot w donné. Dans le cas de la représentation graphique, ces informations sont les mots qui
cooccurrent avec le mot w. Dans le cas d’une représentation syntaxique, ce sont les mots en
relation avec w qui sont sélectionnés pour faire partie de son vecteur de contexte. Dans un cadre
plus générique, nous pourrions imaginer plusieurs autres sources d’informations a exploiter.
Cependant si chaque nouvelle information engendre un nouveau vecteur de contexte, nous
pourrions Vite étre dépassés par le nombre de sources a fusionner. Pour remédier a cela, une
autre maniere serait de représenter dans un seul vecteur de contexte toutes les informations
concernant le mot w. C’est la position adoptée avec la combinaison a priori des contextes.

Dans cette technique de combinaison, nous considérons le vecteur de contexte d’un mot comme
un descripteur qui contient plusieurs informations pour chaque entrée du vecteur. Dans notre cas,
nous avons deux types d’information : (i) une information de cooccurrence globale fournie par la

248 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Représentation graphique Représentation syntaxique Combinaison

regional13 regionalmodz regionalls, regionalL,,w,,2
local5 localL,,wd1 local5, localL,,,,,d1
oestrogenl - oestrogenl

rate32 rate,,wdNz9,ratePRPV3 rate32, rate,,wdNz9,ratePRPV3

TABLE 3 — Exemple de la représentation du contexte du mot recurrence et du nombre de ses cooc—
currences, en fonction des représentations graphique et syntaxique ainsi que de leur combinaison

représentation graphique et (ii) une information plus spéciﬁque fournie par la représentation
syntaxique. Si nous prenons par exemple le mot regional (représenté dans la table 3), nous
pouvons voir qu’il apparait 13 fois avec le mot recurrence selon la représentation graphique et
2 fois comme modiﬁcateur gauche (Lmod) selon la représentation syntaxique. La combinaison
prend en compte les deux informations, en considérant que le mot regional apparait 13 fois avec
recurrence, dont 2 fois en tant que modiﬁcateur gauche. Une information importante 51 souligner
est que la méthode directe se basant sur les relations de dépendances syntaxiques considere
rate,,,odN29 et ratepﬂpva par exemple, comme étant deux mots distincts. L’un des avantages de la
combinaison a priori est que si l’une des méthodes manque une information (un mot), comme
nous pouvons le constater avec le mot oestrogen par exemple, la fusion permet de pallier ce
manque (grace ici a la représentation graphique). Nous considérons les deux représentations
contextuelles comme étant complémentaires. Le but de la combinaison a priori est de préserver le
classement et renforcer les scores des entrées des vecteurs de contexte aﬁn de lisser les contextes
et corriger certaines erreurs qui peuvent apparaitre.

Nous illustrons dans les tables 4, 5 et 6 les 10 premieres entrées du vecteur de contexte du mot
recurrence extrait du corpus du cancer du sein, en fonction de trois mesures d’association, a
savoir : le taux de vraisemblance (Log), le Odds—Ratio (Odds) et 1’information mutuelle (Im).
La notation (+/-) indique l’apport positif ou négatif de la combinaison a priori. L’indice ’+’
indique qu’un mot classé dans les 10 premieres entrées du vecteur de contexte de la méthode par
fenétre ou par relation de dépendance, conserve son classement dans les 10 premieres entrées
apres combinaison. Le signe ’-’ en revanche, indique 1’appariu'on d’un mot non classé dans les 10
premieres entrées du vecteur de contexte.

w=5 ReIDep C mbinaison +/-
local 818,98 localL,.,,,,d 618,17 localL,.,,,,d 936,05 +
rate 119,71 riskpRpN 96,02 local 791,15 +
distant 72,62 rate,,“,dN 68,34 riskpmw 153,14 +
risk 61,00 tumo r,.,,,,dN 62,82 rate 113,96 +
salvage 39,15 ratepmm 40,18 rate,.,,,,dN 110,28 +
year 39,08 timepmm 32,85 tumor,.,,,,dN 104,71 +
time 31,84 disease,.,,,,dN 28,76 distant 70,23 +
tumor 31,04 isola tedL,.,,,,d 24,29 ratepmm 64,69 +
isolate 30,15 distant Lmod 24,28 risk 54,89 +
inoperable 28,16 patientpmm 23,64 timepmm 53,13 +

TABLE 4 — Illustration des 10 premieres entrées du vecteur de contexte du mot recurrence en
fonction du taux de vraisemblance (Log) pour les représentations graphique (w = 5) et syntaxique
(RelDe p) ainsi que par la combinaison a priori

La table 4 montre que la combinaison a priori a un apport positif car, elle engendre un vecteur
de contexte qui respecte le classement des méthodes w = 5 et RelDep et ceci, grace a la mesure

249 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

d’association du taux de vraisemblance.

w=5 RelDep Combinaison + /-
isolated 5,10 freedompmm 7,83 freedompmw 8,12 +
geographic 4,62 hea tR,,,, 1- 6,72 f at PRPN 7,02 +
adjudication 4,44 ope rableR,.,,,,d 6,72 disappointingxmd 7,02 +
conspicuous 4,44 f at PRPN 6,72 o perableR,.,,,,d 7,02 +
reconcile 4,44 disappointingxmd 6,72 threat PRPN 7,02 +
liberate 4,44 threa tpRpN 6,72 hea tR,,,, 1- 7,02 +
evade 4,44 localL,.,,,,d 5,89 localL,.,,,,d 6,02 +
inoperable 4,38 f earpmm 5,63 f earpmm 5,93 +
quarter 4,29 suspicionpmm 5,63 suspicionpmm 5,93 +
local 4,28 inoperableL,.,,,,,1 5,63 inoperableL,.,,,,d 5,93 +

TABLE 5 — Illustration des 10 premieres entrées du vecteur de contexte du mot recurrence en
fonction du Odds—Ratio (Odds) pour les représentations graphique (w = 5) et syntaxique
(RelDe p) ainsi que par la combinaison a priori

La table 5 montre aussi que la combinaison a priori a un apport positif en utilisant la mesure
d’association du Odds—Ratio. Nous remarquons néanmoins que la combinaison a avantagé la
méthode relDep, car il n’y a que ses entrées qui sont présentes dans les 10 premieres entrées du
vecteur de contexte de la méthode de combinaison a priori.

w=5 RelDep Combinaison +/ -

isolated 8,73 localL,.,,,,d 14,77 local 16,17 +
geographic 8,15 tumor,.,“,dN 13,84 localL,,,,,d 15,83 +
inoperable 8,00 riskpRpN 12,84 breast 14,64 -
local 7,82 timepRpN 12,44 ra te 14,39 -
adjudication 7,73 distantL,.,“,d 12,09 tumor 14,15 -
conspicuous 7,73 rate,.,“,dN 11,91 cancer 14,04 -
reconcile 7,73 year,.,,,,dN 11,80 riskpmm 13,90 +
liberate 7,73 ratepmm 11,63 patient 13,75 -
quarter 7,73 tumour,.,“,dN 11,63 cancermmm 13,15 +-
rate 5,59 cancer,.,“,dN 10,51

survival 4,12 5

tumor 3,69

patient 3,21

breast 2,92

cancer 2,28

TABLE 6 — Illustration des 10 premieres entrées du vecteur de contexte du mot recurrence en
fonction de l’information mutuelle (IM) pour les représentations graphique (w = 5) et syntaxique
(RelDe p) ainsi que par la combinaison a priori

La table 6 montre que la combinaison a priori a un apport négatif pour au moins 5 mots. Ces
mots n’étaient pas classés dans les 10 premieres entrées des méthodes w = 5 et RelDep, et le
sont devenus grace 2‘: la combinaison a priori. Ce constat indique que la mesure d’association de
l’information mutuelle n’est pas appropriée car elle ne préserve pas le classement des entrées de
w = 5 et RelDep. Elle affecte des scores élevés £1 des mots qui avaient des scores faibles comme
pour rate ou cancer par exemple, qui passent respectivement de 5, 59 a 14,39 et de 2, 28 e
14, 04.

Les tables 4, 5 et 6 cm montré que l’utilisation du taux de vraisemblance et du Odds—Ratio
dans la méthode de combinaison a priori avait un apport positif contrairement £1 l’utilisation
de l’information mutuelle. Ce constat se conﬁrme par les résultats des expériences que nous
présentons dans la section suivante.

250 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

4 Evaluation

4.1 Ressources linguistiques

Nous avons utilisé deux corpus spécialisés francais—anglais, a savoir un corpus du << cancer du
sein » d’un million de mots et un corpus << énergies renouvelables >> de 600 000 mots. Le corpus
du cancer du sein a été extrait a partir du portail Elsevier4 tel que décrit dans l’article Morin
(2009). Concernant le corpus des énergies renouvelables, il a été construit avec le crawler nommé
Babook (Groc, 2011). Les deux corpus ont été pré—traités (tokenisés, étiquetés, et lemmatisés).
Pour évaluer les différentes approches utilisées dans cet article, nous avons sélectionné 122
couples de mots simples pour le corpus du cancer du sein (a partir du meta—thesaurus UMLS 5
et du Grand dictionnaire terminologique 5) et 100 couples de mots simples pour le corpus des
énergies renouvelables (a partir du dictionnaire en ligne WordReference 7). Comme dictionnaire
bilingue nous avons utilisé le dictionnaire ELRA—M0033. Concernant l’extraction des relations de
dépendances syntaxiques, nous avons utilisé l’outil foumit par Gamallo (2008a) 8.

4.2 Résultats

Nous présentons les résultats des expériences menées sur les deux corpus de langue de spécialité.
Nous évaluons la méthode directe basée sur une représentation graphique notée w = k, o1‘1 k
correspond a la taille de la fenétre (k prend les valeurs : 5, 9 et 15). La méthode directe basée
sur une représentation syntaxique notée RelDep, et nos deux nouvelles approches, c’est—a—dire
la combinaison a posteriori des contextes notée Combpos, (qui combine les scores de w = k et
de RelDep) et la combinaison a priori des contextes notée Combap,,- (qui exploite les contextes
foumis par une fenétre contextuelle w = k et les relations de dépendances RelDep conjointement
dans un méme Vecteur, pour ensuite appliquer la méthode directe). La comparaison des quatre
méthodes se fait en fonction de la précision pour les tops 1 et 10. Ainsi une précision au top
10 notée P10, veut dire que la bonne traduction est présente parmi les 10 candidats renvoyés
par la méthode. Nous utilisons aussi la mesure MAP qui renvoie une vision plus globale sur le
comportement de chaque méthode (Laroche et Langlais, 2010). Comme la méthode directe est
trés sensible aux mesures d’association et de similarité utilisées, nous avons choisi les 3 couples
de mesures les plus connus dans l’état de l’art, a savoir : le taux de Vraisemblance et le Jaccard
noté (Log—Jac) (Morin, 2009), le Odds—Ratio et le cosinus noté (Odds—Cos) (Laroche et Langlais,
2010) ainsi que l’information mutuelle et le cosinus noté (Im—Cos) (Gamallo, 2008a). Ainsi,
chaque case de la table 7 correspond a une mesure d’association et a une mesure de similarité
pour les 4 méthodes testées sur le corpus du cancer du sein. La table 8 concerne le corpus des
énergies renouvelables et respecte la méme conﬁguration que la premiere table.

Dans la table 7, nous constatons que pour la conﬁguration Log—Jac et w = 5, les deux méthodes
de combinaisons proposées obtiennent de meilleurs résultats que w = 5 et RelDe p, avec une
MAP de 0,485 pour Combpos, et de 0,488 pour Combam alors que RelDep et w = 5 n’obtiennent

www . elsevier . com

www .n1m.nih.gov/research/umls

www . granddictionnaire . com

www . wordreference . com

. http : //gramatica . use . es/pln/tools/deppattern .htm1

251 © ATALA

°°.\‘.°‘S"':"‘

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Log—Jac Odds-Cos Im-Cos
P1 P10 MAP P1 P1 0 MAP P1 P10 MAP

RelDep 19,67 49,18 0,297 12,29 46,72 0,237 27,05 48,36 0,332
w = 5 31,15 63,93 0,416 26,23 59,84 0,380 34,43 57,38 0,431
C ombpost 36,88 68,85 0,485 38,52 63,93 0,473 41,80 61,48 0,482
C ombaP,,- 38,52 68,85 0,488 40,16 71,31 0,497 28,69 52,46 0,373

RelDep 19,67 49,18 0,297 12,29 46,72 0,237 27,05 48,36 0,332
w = 9 31,97 66,39 0,435 21,31 60,66 0,343 20,49 51,64 0,305
C ombpost 36,07 75,41 0,494 35,25 68,03 0,460 40,98 59,84 0,464
Comb,,P,,- 41,80 77,05 0,536 38,52 75,41 0,492 16,39 40,16 0,252

RelDep 19,67 49,18 0,297 12,29 46,72 0,237 27,05 48,36 0,332
w = 15 27,87 62,30 0,387 1 7,21 53,28 0,302 13,12 40,16 0,226
C om bpost 34,43 70,49 0,475 37,70 64,75 0,472 3 1,97 59,02 0,412
C omb,,P,,- 34,43 72,95 0,473 37,70 70,49 0,482 13,12 33,61 0,202

TABLE 7 — Précision (%) pour les tops 1 et 10 ainsi que la MAP pour le corpus << Cancer du sein ».
Comparaison de 1’approche directe par représentation graphique et de celle par représentation
syntaxique ainsi que des deux méthodes de combinaisons (les améliorations indiquent une
signiﬁcativité avec un indice de conﬁance de 0,05 utilisant 1e test de Student).

que 0,297 et 0,416. Ce méme constat peut étre fait pour les autres valeurs de w (9 et 15). Ainsi
concernant la conﬁguration Log—Jac, les deux méthodes de combinaison proposées obtiennent
de meilleurs résultats que les deux représentations contextuelles prises séparément, avec un
avantage pour la méthode Comba,,,,- qui obtient une MAP de 0,536 en combinant RelDep
avec w = 9. Nous pouvons constater que, pour la conﬁguration Odds-Cos, c’est la méthode
C omba,,,,- qui obtient les meilleurs résultats avec une MAP de 0,497 pour un w = 5. Concernant
la conﬁguration Im-Cos, c’est Combpost qui obtient les meilleurs résultats, et Comba,,,,- n’apporte
aucune amélioration et dégrade meme les résultats dans certains cas. Pour résumer, nous pouvons
dire que les deux méthodes proposées améliorent les performances de la méthode directe, avec
une efﬁcacité variable étroitement liée aux mesures d’associau'on et de similarité utilisées.

Pour la table 8 concernant 1e corpus des énergies renouvelables, nous pouvons aussi constater que
pour la conﬁguration Log—Jac et w = 5, les deux méthodes de combinaisons proposées obtiennent
de meilleurs résultats que w = 5 et RelDep, avec une MAP de 0,365 pour Combpos, et de 0,354
pour Comba,,,,- alors que RelDep et w = 5 n’obt1'ennent que 0,257 et 0,272. Globalement, c’est la
méthode Combpos, qui obtient les meilleurs résultats. Ce que l’on peut retenir des deux tables
c’est que Combpos, et Combam, améliorent les résultats pour toutes les combinaisons de mesures
sauf pour Comba1,,,- qui ne fonctionne pas avec le couple (Im-Cos).

5 Discussion

Le but de ce travail était dans un premier temps, de comparer les deux principales représentations
contextuelles utilisées dans la méthode directe, et dans un second temps de proposer deux

252 © ATALA

