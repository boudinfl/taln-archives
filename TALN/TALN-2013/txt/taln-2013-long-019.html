<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>D&#233;couverte de connaissances dans les s&#233;quences par CRF non-supervis&#233;s</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>D&#233;couverte de connaissances dans les s&#233;quences par CRF
non-supervis&#233;s
</p>
<p>Vincent Claveau1 Abir Ncibi2
(1) IRISA-CNRS (2) INRIA-IRISA
</p>
<p>Campus de Beaulieu, 35042 Rennes, France
</p>
<p>R&#201;SUM&#201;
Les t&#226;ches de d&#233;couverte de connaissances ont pour but de faire &#233;merger des groupes d&#8217;entit&#233;s
coh&#233;rents. Ils reposent le plus souvent sur du clustering, tout l&#8217;enjeu &#233;tant de d&#233;finir une notion
de similarit&#233; pertinentes entre ces entit&#233;s. Dans cet article, nous proposons de d&#233;tourner les
champs al&#233;atoires conditionnels (CRF), qui ont montr&#233; leur int&#233;r&#234;t pour des t&#226;ches d&#8217;&#233;tiquetage
supervis&#233;es, pour calculer indirectement ces similarit&#233;s sur des s&#233;quences de textes. Pour cela,
nous g&#233;n&#233;rons des probl&#232;mes d&#8217;&#233;tiquetage factices sur les donn&#233;es &#224; traiter pour faire appara&#238;tre
des r&#233;gularit&#233;s dans les &#233;tiquetages des entit&#233;s. Nous d&#233;crivons comment ce cadre peut &#234;tre mis
en &#339;uvre et l&#8217;exp&#233;rimentons sur deux t&#226;ches d&#8217;extraction d&#8217;informations. Les r&#233;sultats obtenus
d&#233;montrent l&#8217;int&#233;r&#234;t de cette approche non-supervis&#233;e, qui ouvre de nombreuses pistes pour le
calcul de similarit&#233;s dans des espaces de repr&#233;sentations complexes de s&#233;quences.
</p>
<p>ABSTRACT
Unsupervised CRF for knowledge discovery
</p>
<p>Knowledge discovery aims at bringing out coherent groups of entities. They are usually based
on clustering ; the challenge is then to define a notion of similarity between the relevant
entities. In this paper, we propose to divert Conditional Random Fields (CRF), which have
shown their interest in supervised labeling tasks, in order tocalculate indirectly the similarities
among text sequences. Our approach consists in generate artificial labeling problems on the
data to be processed to reveal regularities in the labeling of the entities. We describe how this
framework can be implemented and experiment it on two information retrieval tasks. The results
demonstrate the usefulness of this unsupervised approach, which opens many avenues for
defining similarities for complex representations of sequential data.
</p>
<p>MOTS-CL&#201;S : D&#233;couverte de connaissances, CRF, clustering, apprentissage non-supervis&#233;, ex-
traction d&#8217;informations.
</p>
<p>KEYWORDS: Knowledge discovery, CRF, clustering, unsupervised machine learning, information
extraction.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>257 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>Les t&#226;ches d&#8217;&#233;tiquetage de s&#233;quences sont depuis longtemps d&#8217;un int&#233;r&#234;t particulier pour le
TAL (&#233;tiquetage en parties-du-discours, annotation s&#233;mantique, extraction d&#8217;information, etc.).
Beaucoup d&#8217;outils ont &#233;t&#233; propos&#233;s pour ce faire, mais depuis quelques ann&#233;es, les Champs
al&#233;atoires conditionnels (Conditional Random Fields, CRF (Lafferty et al., 2001)) se sont impos&#233;s
comme l&#8217;un des plus efficaces pour de nombreuses t&#226;ches. Ces mod&#232;les sont supervis&#233;s : des
exemples de s&#233;quences avec leurs labels sont donc n&#233;cessaires.
</p>
<p>Le travail pr&#233;sent&#233; dans cet article se place dans un cadre diff&#233;rent dans lequel on souhaite faire
&#233;merger des informations &#224; partir de ces s&#233;quences. Nous nous inscrivons donc dans une t&#226;che
de d&#233;couverte de connaissances dans laquelle il n&#8217;est plus question de supervision, le but &#233;tant
au contraire de d&#233;couvrir comment les donn&#233;es peuvent &#234;tre regroup&#233;es dans des cat&#233;gories
qui fassent sens. Ces t&#226;ches de d&#233;couvertes reposent donc le plus souvent sur du clustering
(Wang et al., 2011, 2012; Ebadat et al., 2012), la question cruciale &#233;tant de savoir comment
calculer la similarit&#233; entre deux entit&#233;s jug&#233;es int&#233;ressantes. Dans cet article, nous proposons de
d&#233;tourner les CRF en produisant des probl&#232;mes d&#8217;&#233;tiquetage factices pour faire appara&#238;tre des
entit&#233;s r&#233;guli&#232;rement &#233;tiquet&#233;es de la m&#234;me fa&#231;on. De ces r&#233;gularit&#233;s est alors tir&#233;e une notion
de similarit&#233; entre les entit&#233;s, qui est donc d&#233;finie par extension et non par intention.
</p>
<p>D&#8217;un point de vue applicatif, outre l&#8217;usage pour la d&#233;couverte de connaissances, les similarit&#233;s
obtenues par CRF et le clustering qu&#8217;il permet peut servir en amont de t&#226;ches supervis&#233;es :
&#8211; il peut &#234;tre utilis&#233; pour r&#233;duire le co&#251;t de l&#8217;annotation de donn&#233;es. Il est en effet plus simple
</p>
<p>d&#8217;&#233;tiqueter un cluster que d&#8217;annoter un texte instance par instance.
&#8211; il peut permettre de rep&#233;rer des classes difficiles &#224; discerner, ou au contraire d&#8217;exhiber des
</p>
<p>classes dont les instances sont tr&#232;s diverses. Cela permet alors d&#8217;adapter la t&#226;che de classifica-
tion supervis&#233;e en modifiant le jeu d&#8217;&#233;tiquettes.
</p>
<p>Dans la suite de cet article, nous positionnons notre travail par rapport aux travaux existants et
pr&#233;sentons bri&#232;vement les CRF en introduisant quelques notions utiles pour la suite de l&#8217;article.
Notre d&#233;crivons ensuite en section 3 le principe de notre approche de d&#233;couverte utilisant les
CRF en mode non-supervis&#233; pour faire de la d&#233;couverte dans des s&#233;quences. Nous proposons
deux exp&#233;rimentations de cette approche dans les sections 4 et 5, puis nous pr&#233;sentons nos
conclusions et quelques pistes ouvertes par ce travail.
</p>
<p>2 Travaux connexes
</p>
<p>Comme nous l&#8217;avons mentionn&#233; en introduction, les t&#226;ches d&#8217;&#233;tiquetage de s&#233;quences sont tr&#232;s
courantes en traitement automatique des langues. Celles-ci se pr&#233;sentent souvent dans un cadre
supervis&#233;, c&#8217;est-&#224;-dire que l&#8217;on dispose de s&#233;quences annot&#233;es par des experts, et incidemment
du jeu de label &#224; utiliser. C&#8217;est dans ce cadre que les CRF se sont impos&#233;s comme des techniques
d&#8217;apprentissage tr&#232;s performantes, obtenant d&#8217;excellents r&#233;sultats pour de nombreuses t&#226;ches
(Wang et al., 2006; Pranjal et al., 2006; Constant et al., 2011; Raymond et Fayolle, 2010, entre
autres).
</p>
<p>Plusieurs &#233;tudes ont propos&#233; de passer &#224; un cadre non-supervis&#233;. Certaines ne rel&#232;vent pas &#224;
proprement parler de non-supervision mais plut&#244;t de semi-supervision, o&#249; le but est de limiter le
nombre de s&#233;quences &#224; annoter. C&#8217;est notamment le cas pour la reconnaissance d&#8217;entit&#233;s nomm&#233;es
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>258 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>o&#249; beaucoup de travaux s&#8217;appuient sur des bases de connaissances ext&#233;rieures (Wikipedia par
exemple), ou sur des r&#232;gles d&#8217;extraction d&#8217;amor&#231;age donn&#233;es par un expert (Kozareva, 2006;
Kazama et Torisawa, 2007; Wenhui Liao, 2009; Elsner et al., 2009). On peut &#233;galement citer
les travaux sur l&#8217;&#233;tiquetage en parties du discours sans donn&#233;es annot&#233;es (Merialdo, 1994; Ravi
et Knight, 2009; Richard et Benoit, 2010). Dans tous les cas, l&#8217;angle de vue de ces travaux est
la limitation, voire la suppression, des donn&#233;es d&#8217;apprentissage. Ils ne se posent pas dans un
cadre de d&#233;couverte de connaissances : ils reposent donc sur un tagset d&#233;j&#224; &#233;tabli, m&#234;me si
la correspondance mot-tag peut n&#8217;&#234;tre qu&#8217;incompl&#232;tement disponible (Smith et Eisner, 2005;
Goldwater et Griffiths, 2007).
</p>
<p>Le cadre que nous adoptons dans cet article est diff&#233;rent puisque nous proposons de faire &#233;merger
les cat&#233;gories de donn&#233;es non annot&#233;es. &#192; l&#8217;inverse des travaux pr&#233;c&#233;dents, nous ne faisons
donc pas d&#8217;a priori sur les &#233;tiquettes possibles. Notre t&#226;che rel&#232;ve donc d&#8217;un clustering dans
lequel les &#233;l&#233;ments similaires des s&#233;quences doivent &#234;tre group&#233;s, comme cela a &#233;t&#233; fait par
exemple par Ebadat et al. (2012) pour certaines entit&#233;s nomm&#233;es. Le clustering de mots n&#8217;est pas
une t&#226;che nouvelle en soi, mais elle repose sur la d&#233;finition d&#8217;une repr&#233;sentation pour les mots
(typiquement un vecteur de contexte) et une mesure de distance (ou de similarit&#233;, typiquement
un cosinus). Notre approche a pour but d&#8217;utiliser la puissance discriminative des CRF, qui a
montr&#233; son int&#233;r&#234;t dans le cas supervis&#233;, pour offrir une mesure de similarit&#233; plus performante.
Il s&#8217;agit donc de transformer cette technique supervis&#233;e en m&#233;thode non-supervis&#233;e permettant
de d&#233;terminer la similarit&#233; entre deux objets.
</p>
<p>Ce d&#233;tournement de techniques d&#8217;apprentissage supervis&#233; pour faire &#233;merger des similarit&#233;s dans
des donn&#233;es complexes non &#233;tiquet&#233;es a d&#233;j&#224; &#233;t&#233; utilis&#233;. Il a montr&#233; son int&#233;r&#234;t sur des donn&#233;es
de type attributs-valeurs pour lesquelles la d&#233;finition d&#8217;une similarit&#233; &#233;tait difficile (attributs non
num&#233;riques, biais d&#8217;une d&#233;finition ex nihilo), notamment avec le random forest clustering (Liu
et al., 2000; Hastie et al., 2001). L&#8217;approche consiste &#224; g&#233;n&#233;rer un grand nombre de probl&#232;mes
d&#8217;apprentissage factices, avec des donn&#233;es synth&#233;tiques m&#233;lang&#233;es aux donn&#233;es r&#233;elles, et de voir
quelles donn&#233;es sont class&#233;es r&#233;guli&#232;rement ensemble (Shi et Horvath, 2005). Notre approche
s&#8217;inscrit dans ce cadre, mais exploite les particularit&#233;s des CRF pour pouvoir prendre en compte
la nature s&#233;quentielle de nos donn&#233;es.
</p>
<p>2.1 Champs al&#233;atoires conditionnels
</p>
<p>Les CRF (Lafferty et al., 2001) sont des mod&#232;les graphiques non dirig&#233;s qui cherchent &#224; repr&#233;sen-
ter la distribution de probabilit&#233;s d&#8217;annotations (ou &#233;tiquettes ou labels) y conditionnellement
aux observations x &#224; partir d&#8217;exemples labellis&#233;s (exemples avec les labels attendus). Ce sont donc
des mod&#232;les obtenus par apprentissage supervis&#233;, tr&#232;s utilis&#233;s notamment dans les probl&#232;mes
d&#8217;&#233;tiquetage de s&#233;quences. Un bonne pr&#233;sentation des CRF peut &#234;tre trouv&#233;e dans ? ? ?. Nous ne
pr&#233;sentons ci-dessous que les &#233;l&#233;ments et notations utiles pour la suite de cet article.
</p>
<p>Dans le cas s&#233;quentiel, c&#8217;est-&#224;-dire l&#8217;&#233;tiquetage d&#8217;observations xi par des labels yi , la fonction
potentielle au c&#339;ur des CRF s&#8217;&#233;crit :
</p>
<p>P(y |x) = 1
Z(x)
</p>
<p>exp
</p>
<p>&#63723;&#63725; k1&#65535;
k=1
</p>
<p>n&#65535;
i=1
</p>
<p>&#955;k fk(yi , x) +
k2&#65535;
k=1
</p>
<p>n&#65535;
i=1
</p>
<p>&#181;k gk(yi&#8722;1, yi , x)
&#63734;&#63736; (1)
</p>
<p>avec :
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>259 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#8211; Z(x) un facteur de normalisation ;
&#8211; les fonctions caract&#233;ristiques locales et globales (fonctions features) f et g : les fonctions f
caract&#233;risent les relations locales entre le label courant en position i et les observations ; les
fonctions g caract&#233;risent les transitions entre les n&#339;uds du graphe, c&#8217;est-&#224;-dire entre chaque
paires de labels i et i &#8722; 1, et la s&#233;quence d&#8217;observations.
</p>
<p>&#8211; les valeurs k1, k2 et n sont respectivement le nombre de fonctions features f , le nombre de
fonctions features g, et la taille de la s&#233;quence de labels &#224; pr&#233;dire.
</p>
<p>Les fonctions f et g sont g&#233;n&#233;ralement des fonctions binaires v&#233;rifiant une certaine combinaison
de labels et d&#8217;attributs d&#233;crivant les observations et appliqu&#233;es &#224; chaque position de la s&#233;quence.
Ces fonctions sont d&#233;finies par l&#8217;utilisateur ; elles refl&#232;tent sa connaissance de l&#8217;application. Elles
sont pond&#233;r&#233;es par les &#955;k et &#181;k qui estiment l&#8217;importance de l&#8217;information qu&#8217;elles apportent
pour d&#233;terminer la classe.
</p>
<p>L&#8217;apprentissage des CRF consiste &#224; estimer le vecteur de param&#232;tres &#952; =
&#955;1,&#955;2, ....,&#955;k1 ,&#181;1,&#181;2, ...,&#181;k2 (poids des fonctions f et g) &#224; partir de donn&#233;es d&#8217;entra&#238;ne-
ment, c&#8217;est-&#224;-dire N s&#233;quences &#233;tiquet&#233;es (x (i), y (i))i=Ni=1 . en pratique, ce probl&#232;me est ramen&#233; &#224;
un probl&#232;me d&#8217;optimisation, g&#233;n&#233;ralement r&#233;solu en utilisant des m&#233;thodes de type quasi-Newton,
comme l&#8217;algorithme L-BFGS (Schraudolph et al., 2007). Apr&#232;s cette &#233;tape d&#8217;apprentissage,
l&#8217;application des CRF &#224; de nouvelles donn&#233;es consiste &#224; trouver la s&#233;quence de labels la plus
probable &#233;tant donn&#233;e une s&#233;quence d&#8217;observations non-vue. Comme pour les autres m&#233;thodes
stochastiques, celle-ci est g&#233;n&#233;ralement obtenu avec un algorithme de Viterbi.
</p>
<p>3 Principes du mod&#232;le non supervis&#233;
</p>
<p>Nous d&#233;crivons dans cette section le principe de notre approche. Une vue g&#233;n&#233;rale est tout d&#8217;abord
donn&#233;e au travers d&#8217;un algorithme sch&#233;matisant l&#8217;ensemble du processus. Nous en d&#233;taillons
ensuite quelques points cruciaux, ainsi que des aspects plus pragmatiques de l&#8217;utilisation de cette
m&#233;thode.
</p>
<p>3.1 Principe g&#233;n&#233;ral
</p>
<p>Comme nous l&#8217;avons expliqu&#233; pr&#233;c&#233;demment, l&#8217;id&#233;e principale de notre approche est de d&#233;duire
une distance (ou une similarit&#233;) &#224; partir de classifications r&#233;p&#233;t&#233;es de deux objets pour des
t&#226;ches d&#8217;apprentissage al&#233;atoire. Plus les objets sont d&#233;tect&#233;s souvent comme appartenant &#224;
la m&#234;me classe, plus ils sont suppos&#233;s proches. L&#8217;algorithme 1 donne un aper&#231;u global de la
d&#233;marche. Dans notre cadre s&#233;quentiel, la classification est faite gr&#226;ce aux CRF (les &#233;tapes 6
et 7 correspondent simplement &#224; l&#8217;apprentissage et l&#8217;application d&#8217;un mod&#232;le CRF). Celle-ci est
r&#233;p&#233;t&#233;e un grand nombre de fois en faisant varier les donn&#233;es, les labels (les &#969;i sont des classes
factices) et les param&#232;tres des apprentissages. Il est tenu &#224; jour un compte des paire de mots
(xi , x j) recevant les m&#234;mes labels ; ces co-&#233;tiquetages sont contenus dans la matrice&#65535; co-et. Ils
sont mis &#224; jour &#224; chaque it&#233;ration en tenant compte &#233;ventuellement de diff&#233;rents crit&#232;res, selon
une fonction weight (cf. infra pour une discussion sur ce point). Ces co-&#233;tiquetages sont ensuite
transform&#233;s en mesures de similarit&#233; (cela peut &#234;tre une simple normalisation) collect&#233;es dans
&#65535;sim.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>260 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Algorithme 1 Clustering par CRF
</p>
<p>1: input : &#65535;total : s&#233;quences non &#233;tiquet&#233;es
2: for grand nombre d&#8217;it&#233;rations do
3: &#65535;train, &#65535;app &#8592; Diviser(&#65535;total)
4: Tirer al&#233;atoirement les labels yi parmi &#969;1...&#969;L pour les s&#233;quences de &#65535;train
5: G&#233;n&#233;rer al&#233;atoirement un ensemble de fonctions f et g
6: Inf&#233;rence : &#952; &#8592; L-BFGS(&#65535;train,y , f ,g)
7: Application : y&#8727; = argmaxy p(&#952; , f ,g)(y|x) pour tous les x &#8712; &#65535;app
8: for all classe &#969;l parmi &#969;1...&#969;L do
9: for all paire xi , x j de &#65535;app telle que y&#8727;i = y&#8727;j =&#969;l do
</p>
<p>10: &#65535;co-et(xi , x j)+ = weight(xi , x j ,&#969;l)
11: end for
12: end for
13: end for
14: &#65535;sim &#8592; Transformation(&#65535;co-et)
15: &#65535;CRF &#8592; Clustering(&#65535;sim)
16: return &#65535;CRF
</p>
<p>3.2 Apprentissage al&#233;atoire
</p>
<p>L&#8217;approche repose sur le fait que les CRF vont permettre d&#8217;exhiber une similarit&#233; entre des
mots en leur attribuant r&#233;guli&#232;rement les m&#234;mes &#233;tiquettes dans des conditions d&#8217;apprentissage
tr&#232;s vari&#233;es. Pour cela, &#224; chaque it&#233;ration, plusieurs choix al&#233;atoires sont mis-en-&#339;uvre ; ils
concernent :
&#8211; les s&#233;quences servant &#224; l&#8217;apprentissage et leur nombre ;
&#8211; les labels (distribution et nombre) ;
&#8211; les fonctions features d&#233;crivant les mots ;
Ces apprentissages sur des t&#226;ches supervis&#233;es factices doivent ainsi conf&#233;rer, par leur vari&#233;t&#233;,
des propri&#233;t&#233;s importantes &#224; la similarit&#233; obtenue. Celle-ci m&#233;lange ainsi naturellement des
descriptions complexes (attributs nominaux divers sur le mot courant, sur les mots voisins),
op&#232;re par construction une s&#233;lection de variables et prend ainsi en compte les redondances des
descripteurs ou ignore ceux de mauvaise qualit&#233;, et elle est robuste aux donn&#233;es aberrantes.
</p>
<p>Bien s&#251;r, comme nous l&#8217;avons d&#233;j&#224; soulign&#233;, ce r&#244;le important de l&#8217;al&#233;atoire n&#8217;emp&#234;che pas
l&#8217;utilisateur de contr&#244;ler la t&#226;che via des biais. Cela se traduit par exemple par la mise &#224;
disposition des descriptions riches des mots : &#233;tiqueter des s&#233;quences en parties-du-discours,
apport d&#8217;informations s&#233;mantiques sur certains mots... Cela se traduit &#233;galement par la d&#233;finition
de l&#8217;ensemble des fonctions features parmi lesquelles l&#8217;algorithme peut piocher les fonctions f et
g &#224; chaque it&#233;ration. Dans les exp&#233;riences rapport&#233;es ci-dessous, cet ensemble de fonctions est
celui classiquement utilis&#233;s en reconnaissance d&#8217;entit&#233;s nomm&#233;es : forme et parties du discours
du mot courant, des 3 pr&#233;c&#233;dents et 3 suivants, des bigrammes de ces attributs, casse des mots-
formes courants et environnants... Concernant les ensembles &#65535;train et &#65535;app, &#224; chaque it&#233;ration 5%
des phrases sont tir&#233;es al&#233;atoirement pour constituer l&#8217;ensemble d&#8217;entra&#238;nement ; le reste sert
d&#8217;ensemble d&#8217;application.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>261 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>3.3 Labels al&#233;atoires
</p>
<p>Le choix du nombre de labels factices et leur distribution est &#233;galement important (mais il
faut noter que le nombre de labels choisi &#224; ce stade n&#8217;implique pas directement le nombre de
clusters qui seront produits lors de l&#8217;&#233;tape finale de clustering). Un trop grand nombre de labels
lors de l&#8217;apprentissage risque d&#8217;emp&#234;cher de produire ensuite un &#233;tiquetage dans lequel peu
d&#8217;entit&#233;s partagent le m&#234;me label. En soit ce probl&#232;me ne pose pas n&#233;cessairement un probl&#232;me
de qualit&#233; finale, mais risque d&#8217;augmenter le nombre d&#8217;it&#233;rations suffisant pour l&#8217;obtention de
ce r&#233;sultat final. &#192; l&#8217;inverse, si l&#8217;on choisit un nombre trop restreint de labels, l&#8217;application du
mod&#232;le risque de de ne pas suffisamment diff&#233;rencier les entit&#233;s, produisant des co-&#233;tiquetages
fortuits. Ce probl&#232;me est plus g&#234;nant car il va impacter le r&#233;sultat du clustering. Il faut de plus
noter que tout cela est &#224; interpr&#233;ter selon les autres param&#232;tres de l&#8217;apprentissage. Ainsi, les
fonctions features vont permettre ou pas un sur-apprentissage, et donc &#233;ventuellement emp&#234;cher
ou favoriser les co-&#233;tiquetages. La taille de &#65535;train, et notamment le nombre d&#8217;entit&#233;s y recevant un
m&#234;me label intervient aussi : si syst&#233;matiquement d&#232;s l&#8217;entra&#238;nement un grand nombre d&#8217;entit&#233;s,
probablement de classes diff&#233;rentes, re&#231;oivent le m&#234;me label, les mod&#232;les ne vont pas &#234;tre
correctement discriminants.
</p>
<p>Pour correctement prendre en compte ce ph&#233;nom&#232;ne, il serait n&#233;cessaire de caract&#233;riser la
propension du mod&#232;le appris, avant l&#8217;&#233;tiquetage, &#224; trop ou pas assez discriminer les entit&#233;s. Dans
l&#8217;&#233;tat actuel de nos travaux, nous n&#8217;avons pas formalis&#233; un tel crit&#232;re. Nous utilisons simplement
un crit&#232;re a posteriori d&#233;termin&#233; sur le texte apr&#232;s &#233;tiquetage : un co-&#233;tiquetage de deux entit&#233;s
&#8220;rapporte plus&#8221; si peu d&#8217;entit&#233;s ont &#233;t&#233; &#233;tiquet&#233;es avec ce m&#234;me label. Cela est mis en &#339;uvre dans
la fonction weight utilis&#233;e pour mettre &#224; jour la matrice&#65535;co-et. En pratique, dans les exp&#233;riences
rapport&#233;es dans cet article, on a d&#233;fini cette fonction par : weight(xi , x j ,&#969;l) =
</p>
<p>1
|{xk |yk=&#969;l}|
</p>
<p>et le nombre de labels est lui aussi tir&#233; al&#233;atoirement entre 10 et 50 &#224; chaque it&#233;ration.
</p>
<p>Il est aussi possible, selon le probl&#232;me trait&#233; et les connaissances particuli&#232;res qui s&#8217;y appliquent,
de biaiser la distribution des &#233;tiquettes al&#233;atoires. Ainsi, pour un probl&#232;me donn&#233;, si l&#8217;on sait que
toutes les occurrences d&#8217;un mot-forme ont forc&#233;ment la m&#234;me classe, il est important que cette
contrainte soit mise en &#339;uvre lors de la production des donn&#233;es d&#8217;entra&#238;nement. L&#8217;exp&#233;rience
rapport&#233;e en section 4 se place dans ce cadre.
</p>
<p>3.4 Clustering
</p>
<p>L&#8217;&#233;tape finale de clustering peut &#234;tre mise en &#339;uvre de diff&#233;rentes fa&#231;ons gr&#226;ce aux techniques et
outils existants. L&#8217;algorithme c&#233;l&#232;bre du k-means qui n&#233;cessite des calculs de barycentres durant
le processus n&#8217;est bien s&#251;r pas adapt&#233; &#224; notre espace non m&#233;trique. Sa variante k-medoids, qui
utilise un objet comme repr&#233;sentant d&#8217;un cluster et ne n&#233;cessite donc pas d&#8217;autres mesures que
celles fournie par&#65535;sim, peut l&#8217;&#234;tre.
Il faut cependant noter que dans nos t&#226;ches de d&#233;couverte, le nombre de clusters attendus est
inconnu. Pour notre part, dans les exp&#233;rimentations pr&#233;sent&#233;es dans les sections 4 et 5, nous
utilisons donc une autre technique de clustering, le Markov Clustering (MCL). Cette technique a
&#233;t&#233; d&#233;velopp&#233;e initialement pour le partitionnement de grands graphes (van Dongen, 2000). Son
avantage par rapport au k-medoids est de ne pas n&#233;cessiter de fixer a priori le nombre de clusters
attendus, et aussi d&#8217;&#233;viter le probl&#232;me de l&#8217;initialisation de ces clusters. Nous consid&#233;rons donc
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>262 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>simplement nos objets (mots ou autres entit&#233;s) comme des n&#339;uds d&#8217;un graphe dont les arcs sont
valu&#233;s en fonction de la similarit&#233; contenue dans&#65535;sim.
</p>
<p>3.5 Aspects op&#233;rationnels
</p>
<p>Appliqu&#233; tel quel, le processus expos&#233; en section 3 va consid&#233;rer tous les &#233;l&#233;ments composant
les s&#233;quences et tenter de les organiser en clusters. Dans beaucoup d&#8217;applications, la t&#226;che de
clustering n&#8217;est int&#233;ressante que pour une sous-partie de ces &#233;l&#233;ments. C&#8217;est par exemple le
cas en reconnaissance d&#8217;entit&#233;s nomm&#233;es ou plus largement en extraction d&#8217;information, o&#249;
seuls certains mots ou groupe de mots doivent &#234;tre consid&#233;r&#233;s. Dans ce cadre, il est tr&#232;s courant
d&#8217;utiliser des labels dits BIO (Begin-In-Out) qui permettent de mod&#233;liser le fait qu&#8217;une entit&#233; soit
multi-mot (le B pour Begin identifie le d&#233;but de l&#8217;entit&#233;, le I pour In la continuit&#233; et le O indique
le mot ne fait pas partie de l&#8217;entit&#233;). Voici un exemple de s&#233;quences factices tir&#233; des donn&#233;es
utilis&#233;es en section 5 :
</p>
<p>x
</p>
<p>y
</p>
<p>Cette connaissance externe fait partie des biais indispensables pour cadrer le processus d&#8217;ap-
prentissage non-supervis&#233; et faire en sorte qu&#8217;il s&#8217;applique aux besoins sp&#233;cifiques de l&#8217;utilisateur.
Mais il est important de noter que cette connaissance sur les entit&#233;s &#224; consid&#233;rer n&#8217;est pas de
m&#234;me ordre que celle l&#8217;on se propose de d&#233;couvrir via le clustering. Dans le premier cas, il s&#8217;agit
de d&#233;limiter les entit&#233;s int&#233;ressantes, dans le second cas, il s&#8217;agit d&#8217;en faire &#233;merger des classes,
sans a priori leur nature.
</p>
<p>Il est possible dans ce cas de supposer que l&#8217;on sait d&#233;limiter les entit&#233;s int&#233;ressantes dans
les s&#233;quences ; c&#8217;est l&#8217;hypoth&#232;se adopt&#233;e dans plusieurs travaux sur la classification d&#8217;entit&#233;s
nomm&#233;es (Collins et Singer, 1999; Elsner et al., 2009; Ebadat et al., 2012). Il est aussi, bien s&#251;r,
possible de consid&#233;rer ce probl&#232;me comme un probl&#232;me d&#8217;apprentissage pour lequel l&#8217;utilisateur
doit fournir quelques exemples. Dans les deux cas, cela n&#233;cessite de l&#8217;expertise, fournie soit en
intention (crit&#232;res objectifs pour d&#233;limiter les entit&#233;s), soit en extension (exemples ; cf. sous-
section 5.2). Chacune des exp&#233;riences rapport&#233;es ci-dessous adopte l&#8217;un de ces cas de figure.
</p>
<p>Le processus it&#233;ratif propos&#233; dans cet article est &#233;videmment co&#251;teux (mais ais&#233;ment paral-
l&#233;lisable). Dans les exp&#233;riences rapport&#233;es ci-apr&#232;s, le nombre d&#8217;it&#233;rations a &#233;t&#233; fix&#233; &#224; 1000.
Les principales sources de co&#251;t en terme de temps de calcul sont l&#8217;apprentissage du mod&#232;le
CRF et son application. Leur complexit&#233; est elle-m&#234;me d&#233;pendante de nombreux param&#232;tres,
notamment la taille de l&#8217;&#233;chantillon d&#8217;apprentissage, la vari&#233;t&#233; des observations (x), le nombre
de classes al&#233;atoires (&#969;), les attributs consid&#233;r&#233;s (les fonctions features f et g)... Pour minimiser
l&#8217;impact de ce co&#251;t, nous utilisons l&#8217;impl&#233;mentation de CRF WAPITI qui optimise les algorithmes
standard d&#8217;inf&#233;rence (Lavergne et al., 2010).
</p>
<p>4 Validation exp&#233;rimentale en classification de noms propres
</p>
<p>Pour cette premi&#232;re exp&#233;rience, nous reprenons la probl&#233;matique et les donn&#233;es de Ebadat et al.
(2012). Il s&#8217;agit de faire &#233;merger les diff&#233;rentes classes de noms propres au sein de r&#233;sum&#233;s de
matchs de football. Plus pr&#233;cis&#233;ment, dans leurs exp&#233;riences, les auteurs ont cherch&#233; &#224; classer
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>263 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>les noms propres &#224; l&#8217;&#233;chelle du corpus, c&#8217;est-&#224;-dire en consid&#233;rant que toutes les occurrences
relevaient de la m&#234;me entit&#233; et donc de la m&#234;me cat&#233;gorie. Dans ce jeu de donn&#233;e, les entit&#233;s ne
sont donc pas consid&#233;r&#233;es comme possiblement polys&#233;miques ; m&#234;me si ce point est discutable, il
n&#8217;est pas remis en cause dans notre exp&#233;rience pour lequel nous utilisons le jeu de donn&#233;es tel
qu&#8217;utilis&#233; par Ebadat et al. (2012).
</p>
<p>4.1 T&#226;che et donn&#233;es
</p>
<p>Le corpus est compos&#233; de rapports de matchs minute par minute en fran&#231;ais, extraits de diff&#233;rents
sites Web. Les &#233;v&#233;nements importants de chaque minute ou presque d&#8217;un match y sont d&#233;crits (cf.
tableau 1) : remplacement de joueurs, fautes, buts...
</p>
<p>Minute Rapport
80
</p>
<p>82
</p>
<p>TABLE 1: Extrait d&#8217;un rapport minute-by-minute d&#8217;un match de football
</p>
<p>Ces donn&#233;es ont &#233;t&#233; annot&#233;es manuellement par des experts selon des classes d&#233;finies pour
r&#233;pondre &#224; des besoins applicatifs sp&#233;cifiques (voir Fort et Claveau, 2012). On poss&#232;de donc une
v&#233;rit&#233; terrain associant &#224; chaque occurrence de chaque nom propre une classe (voir la figure 1a).
On remarque sans surprise que ces classes sont tr&#232;s d&#233;s&#233;quilibr&#233;es, avec notamment une classe
joueur tr&#232;s peupl&#233;e.
</p>
<p>4.2 Mesures de performance
</p>
<p>Notre t&#226;che de d&#233;couverte se ramenant &#224; une &#233;tape finale de clustering, nous l&#8217;&#233;valuons comme
telle. Une telle &#233;valuation est toujours d&#233;licate : l&#8217;&#233;valuation sur crit&#232;res externes n&#233;cessite
de disposer d&#8217;un clustering de r&#233;f&#233;rence (v&#233;rit&#233; terrain) dont la pertinence peut toujours &#234;tre
discut&#233;e, mais les crit&#232;res internes (par exemple, une mesure de coh&#233;sion des clusters) sont
connus pour n&#8217;&#234;tre pas fiables (Manning et al., 2008). Nous nous pla&#231;ons donc dans le premier
cadre et comparons le clustering obtenu par notre processus &#224; celui de la v&#233;rit&#233; terrain.
</p>
<p>Pour ce faire, diff&#233;rentes m&#233;triques ont &#233;t&#233; propos&#233;es, comme la puret&#233; ou Rand Index (Rand,
1971). Ces mesures sont cependant peu discriminantes et ont tendance &#224; &#234;tre trop optimistes
quand la v&#233;rit&#233; terrain contient des classes de tailles tr&#232;s diff&#233;rentes (Nguyen Xuan Vinh, 2010).
Nous pr&#233;f&#233;rons donc l&#8217;Adjusted Rand Index (ARI), qui est une version du Rand Index tenant
compte des agr&#233;ments de hasard, et qui est connue pour &#234;tre robuste. Son &#233;tude et sa d&#233;finition
peuvent &#234;tre trouv&#233;es dans (Hubert et Arabie, 1985).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>264 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4.3 Impl&#233;mentation et r&#233;sultats
</p>
<p>Pour tester notre m&#233;thode de clustering par CRF, nous avons &#233;tiquet&#233; le corpus en partie du
discours, utilis&#233; le sch&#233;ma d&#8217;annotation BIO et consid&#233;r&#233; la phrase comme s&#233;quence. Dans cette
application particuli&#232;re, nous reprenons l&#8217;hypoth&#232;se de (Collins et Singer, 1999; Elsner et al.,
2009) : les entit&#233;s &#224; cat&#233;goriser sont connues et d&#233;limit&#233;es. En pratique, ce sont donc sur elles
que les annotations al&#233;atoires vont porter, les autres mots du corpus recevant toujours le m&#234;me
label &#8217;O&#8217;. Les fonctions f et g sont celles classiquement utilis&#233;es en extraction d&#8217;information :
les fonctions f lient le label courant yi aux observations (forme ou parties du discours du mot
courant en xi , du mot en xi&#8722;1, xi&#8722;2, xi+1, ou xi+2, ou des combinaisons de ces attributs) ; les
fonctions g lient deux labels successifs (yi&#8722;1, yi). La t&#226;che &#233;tant de classifier les noms propres
au niveau du corpus et non de l&#8217;occurrence, nous for&#231;ons deux occurrence d&#8217;un m&#234;me nom &#224;
avoir le m&#234;me label lors de la g&#233;n&#233;ration des labels al&#233;atoires (&#233;tape 4 de l&#8217;algorithme). En
revanche, l&#8217;application du CRF produit une annotation au niveau de l&#8217;occurrence, la matrice
&#65535;co-et recense donc les classifications &#224; l&#8217;occurrence pr&#232;s. L&#8217;&#233;tape de transformation (&#233;tape 14)
permet de transformer cette matrice en une matrice de similarit&#233;&#65535;sim des noms propres au
niveau du corpus en sommant les lignes et colonnes des diff&#233;rentes occurrences des m&#234;mes noms.
</p>
<p>(a) (b)
</p>
<p>FIGURE 1: (a) R&#233;partition des donn&#233;es football dans la v&#233;rit&#233; terrain (nombre de noms propres
uniques). (b) &#201;valuation des clusterings par rapport &#224; la v&#233;rit&#233; terrain (ARI %).
</p>
<p>Les r&#233;sultats de notre approche sont donn&#233;s dans le tableau 1b en terme d&#8217;ARI (en pourcentage ;
0 signifie un clustering al&#233;atoire et 100 un clustering identique &#224; la v&#233;rit&#233; terrain). &#192; des fins de
comparaison, nous reportons les r&#233;sultats de Ebadat et al. (2012) ; ceux-ci ont &#233;t&#233; obtenus en
utilisant des descriptions vectorielles des contextes des entit&#233;s soit sous forme d&#8217;un vecteur unique,
soit sous forme de sacs de vecteurs, et des fonctions de similarit&#233;s adapt&#233;es &#224; ces repr&#233;sentations.
Le contexte donnant le meilleur r&#233;sultat est de 4 mots &#224; gauche et &#224; droite de l&#8217;entit&#233;. L&#8217;&#233;tape de
clustering est faite avec le m&#234;me algorithme MCL que pour notre syst&#232;me. Ce dernier dispose
d&#8217;un param&#232;tre d&#8217;inflation qui influence indirectement le nombre de cluster produit. Pour une
comparaison &#233;quitable, les r&#233;sultats rapport&#233;s pour chaque m&#233;thode sont ceux pour lesquels ce
param&#232;tre est optimal pour la mesure d&#8217;&#233;valuation ARI. &#192; titre d&#8217;information, cela produit 12
clusters pour la similarit&#233; CRF, 11 pour la similarit&#233; sac-de-vecteurs n-grams.
</p>
<p>Ces r&#233;sultats soulignent l&#8217;int&#233;r&#234;t de notre approche par rapport aux repr&#233;sentations et similarit&#233;s
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>265 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>plus standard. Les quelques diff&#233;rences constat&#233;es entre les clusters form&#233;s par notre approche et
les classes de la v&#233;rit&#233; terrain portent principalement sur la classe autre. Celle-ci contient des
noms de personnalit&#233;s apparaissant dans des contextes divers (personnalit&#233; donnant le coup
d&#8217;envoi, apparaissant dans les tribunes...), avec trop peu de r&#233;gularit&#233;s pour que les CRF, pas
plus que les autres m&#233;thodes, arrivent &#224; faire &#233;merger une similarit&#233;. Il appara&#238;t &#233;galement que
certaines erreurs rapport&#233;es par Ebadat et al. (2012) comme r&#233;currentes ne sont pas commises
par le clustering par CRF. Par exemple, les m&#233;thodes vectorielles ont tendance &#224; confondre les
noms de villes et les noms de joueurs, ceux-ci apparaissant souvent proches les uns des autres et
partageant donc les m&#234;mes contextes. Ces erreurs ne sont pas commises par l&#8217;approche par CRF,
o&#249; la prise en compte de la s&#233;quentialit&#233; pour l&#8217;&#233;tiquetage permet de bien distinguer ces deux
classes.
</p>
<p>5 Validation exp&#233;rimentale sur les entit&#233;s nomm&#233;es
</p>
<p>5.1 T&#226;che et donn&#233;es
</p>
<p>Pour cette t&#226;che, nous utilisons les donn&#233;es de la campagne d&#8217;&#233;valuation ESTER2 (Gravier et al.,
2005). Elles sont compos&#233;es de 150h d&#8217;&#233;missions de radio datant d&#8217;entre 1999 et 2003, provenant
de diverses sources (France Inter, Radio Classique, Africa 1...). Ces &#233;missions, transcrites, ont
&#233;t&#233; annot&#233;es en entit&#233;s nomm&#233;es selon 8 cat&#233;gories : personnes, fonctions, lieux, organisations,
temps, produits humains, quantit&#233;, et une cat&#233;gorie autres.
</p>
<p>Contrairement au jeu de donn&#233;es pr&#233;c&#233;dent, les entit&#233;s sont annot&#233;es au niveau de l&#8217;occurrence
et peuvent &#234;tre des noms propres, communs ou des expressions ; ainsi, l&#8217;entit&#233; peut
&#234;tre annot&#233;e comme un lieu ou une organisation selon le contexte. Nous n&#8217;utilisons pour nos
exp&#233;riences que la partie dev de ce jeu de donn&#233;es ESTER2, transcrite manuellement, mais
respectant les particularit&#233;s d&#8217;un syst&#232;me de reconnaissance de la parole : le texte n&#8217;a donc ni
ponctuation, ni majuscule. Ses caract&#233;ristiques sont donn&#233;es dans la figure 2a
</p>
<p>(a) (b)
</p>
<p>FIGURE 2: (a) R&#233;partition des donn&#233;es ESTER2 dans la v&#233;rit&#233; terrain (nombre d&#8217;occurrences). (b)
Performances de la d&#233;tection des entit&#233;s selon le nombre de s&#233;quences annot&#233;es.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>266 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>5.2 Rep&#233;rage des entit&#233;s
</p>
<p>Bien qu&#8217;il soit possible de se placer dans le m&#234;me cadre que pr&#233;c&#233;demment et supposer que
les entit&#233;s &#224; classifier sont connues et d&#233;limit&#233;es, nous utilisons un cadre interm&#233;diaire plus
r&#233;aliste : nous supposons qu&#8217;une petite partie des donn&#233;es est annot&#233;e par un expert qui d&#233;limite
les entit&#233;s int&#233;ressantes (mais sans leur assigner de classe). Ces donn&#233;es vont nous servir dans
une premi&#232;re &#233;tape &#224; apprendre &#224; d&#233;limiter les entit&#233;s avant de les grouper. On se place donc
dans un cadre supervis&#233; classique avec deux classes (entit&#233; int&#233;ressante ou non), pour lequel
nous utilisons les CRF de mani&#232;re traditionnelle.
</p>
<p>La figure 2b pr&#233;sente les r&#233;sultats obtenus, en fonction du nombre de s&#233;quences (phrases)
utilis&#233;es pour l&#8217;apprentissage. Les performances sont &#233;valu&#233;es en terme de pr&#233;cision, rappel
et F-mesure. Il appara&#238;t qu&#8217;il est possible d&#8217;obtenir des r&#233;sultats de bonne qualit&#233; en analysant
(c&#8217;est-&#224;-dire en d&#233;limitant les entit&#233;s nomm&#233;es) relativement peu de phrases.
</p>
<p>5.3 &#201;valuation du clustering
</p>
<p>Nous reprenons le m&#234;me cadre exp&#233;rimental que celui expliqu&#233; en section 4.3, &#224; la diff&#233;rence
que la classification se fait ici au niveau de l&#8217;occurrence. La transformation de&#65535;co-et en&#65535;sim
consiste donc juste en une normalisation. Les entit&#233;s consid&#233;r&#233;es sont celles rep&#233;r&#233;es par l&#8217;&#233;tape
pr&#233;c&#233;dente (avec 2 000 s&#233;quences annot&#233;es pour l&#8217;apprentissage) sur l&#8217;ensemble du corpus. Les
r&#233;sultats, mesur&#233;s en terme d&#8217;ARI (%), sont pr&#233;sent&#233;s dans la figure 3. Comme pour l&#8217;exp&#233;rience
pr&#233;c&#233;dente, nous pr&#233;sentons les r&#233;sultats obtenus par des techniques de clustering sur ces m&#234;mes
donn&#233;es utilisant des similarit&#233;s plus classiques sur le contexte et les entit&#233;s (&#224; l&#8217;exception de
l&#8217;approche par sacs de vecteurs qui ne peut pas s&#8217;appliquer &#224; la classification au niveau de
l&#8217;occurrence).
</p>
<p>FIGURE 3: &#201;valuation des clusterings par rapport &#224; la v&#233;rit&#233; terrain (ARI %)
</p>
<p>L&#8217;int&#233;r&#234;t de notre approche appara&#238;t clairement. La prise en compte de la s&#233;quentialit&#233; est un
&#233;l&#233;ment important ; les r&#233;sultats avec les n-grammes sont en effet meilleurs que des mots isol&#233;s,
et ceux des CRF, qui prennent plus naturellement en compte cet aspect s&#233;quentiel, sont encore
meilleurs. Les clusters obtenus par notre approche ne sont cependant pas exactement identiques
&#224; ceux de la v&#233;rit&#233; terrain.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>267 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Une analyse d&#233;taill&#233;e montre en effet qu&#8217;un cluster en particulier fait chuter les r&#233;sultats en
groupant des entit&#233;s appartenant &#224; deux classes distinctes de la v&#233;rit&#233; terrain. Ces classes qui
semblent difficiles &#224; distinguer sont celles du temps et des quantit&#233;s. En effet, en l&#8217;absence
d&#8217;informations autres que la forme des mots et les parties-du-discours, il semble impossible de
distinguer des entit&#233;s telles que &#8217; &#8217; et &#8217;
</p>
<p>&#8217;.
</p>
<p>6 Discussion, conclusion et perspectives
</p>
<p>La r&#233;solution de probl&#232;mes d&#8217;apprentissage factices par les CRF permet de faire &#233;merger des
similarit&#233;s au sein des s&#233;quences. Cette similarit&#233; tire ainsi parti de la richesse de description que
permet les CRF (typiquement les parties-du-discours), ainsi que de la prise en compte naturelle
de la s&#233;quentialit&#233;. On d&#233;finit ainsi une similarit&#233; dans un espace non-m&#233;trique se voulant robuste
gr&#226;ce aux choix al&#233;atoires r&#233;p&#233;t&#233;s dans le processus. Bien s&#251;r, ce principe est transposable &#224;
d&#8217;autres m&#233;thodes d&#8217;apprentissage, notamment les m&#233;thodes s&#233;quentielles stochastiques (HMM,
MaxEnt...) ; l&#8217;utilisation des CRF, plus performants en g&#233;n&#233;ral, est cependant plus naturelle.
</p>
<p>Les &#233;valuations men&#233;es sur deux t&#226;ches d&#8217;extraction d&#8217;informations mettent en valeur l&#8217;int&#233;r&#234;t de
l&#8217;approche, m&#234;me si nous sommes bien conscients de la limite de l&#8217;&#233;valuation d&#8217;une t&#226;che de d&#233;-
couverte qui oblige &#224; la constitution d&#8217;une v&#233;rit&#233; terrain que l&#8217;on souhaite justement &#233;viter. Enfin,
il convient de pr&#233;ciser qu&#8217;il n&#8217;y a pas d&#8217;apprentissage sans biais, m&#234;me pour l&#8217;apprentissage non
supervis&#233; (Mitchell, 1990). Ces biais repr&#233;sentent la connaissance de l&#8217;utilisateur et permettent
de d&#233;finir son probl&#232;me. L&#8217;apport de connaissances sur les entit&#233;s int&#233;ressantes, la description
des s&#233;quences et des fonctions features sont autant d&#8217;informations permettant &#224; l&#8217;utilisateur de
canaliser la t&#226;che de d&#233;couverte sur son objet d&#8217;&#233;tude.
</p>
<p>Plusieurs am&#233;liorations et perspectives sont envisageables &#224; la suite de ce travail. D&#8217;un point
de vue technique, l&#8217;&#233;tape de transformation des co-&#233;tiquetages en similarit&#233;s, qui se contente
dans nos exp&#233;riences d&#8217;une simple normalisation, pourrait &#234;tre approfondie. Il doit ainsi &#234;tre
possible d&#8217;utiliser d&#8217;autres fonctions (par exemple celles utilis&#233;es pour rep&#233;rer des associations,
expressions multi-mots, ou termes complexes complexes : information mutuelle, Jaccard, log-
vraisemblance, &#967;2...) pour obtenir des similarit&#233;s encore plus fiables. Cela permettrait de pallier
la faible robustesse de notre algorithme de clustering qui peut fusionner deux clusters sur le
simple fait de quelques entit&#233;s fortement connect&#233;es avec beaucoup d&#8217;autres n&#339;uds. Des variantes
sur l&#8217;&#233;tape de clustering peuvent aussi &#234;tre envisag&#233;es. Il est par exemple possible d&#8217;utiliser des
algorithmes de clustering hi&#233;rarchique. Il est aussi possible d&#8217;utiliser directement les similarit&#233;s
pour d&#8217;autres t&#226;ches, comme la recherche d&#8217;informations, le lissage pour des mod&#232;les de langues...
D&#8217;un point de vue pratique, il serait int&#233;ressant d&#8217;obtenir une d&#233;finition explicite de la similarit&#233;
en r&#233;cup&#233;rant les &#955;i et &#181;i avec les fonctions f et g associ&#233;es. Cela permettrait d&#8217;appliquer la
fonction de similarit&#233; &#224; de nouveaux textes sans refaire les co&#251;teuses &#233;tapes d&#8217;apprentissage,
mais cela n&#233;cessite d&#8217;&#234;tre capable de combiner les diff&#233;rentes fonctions de d&#233;codage utilis&#233;es
pour l&#8217;application des diff&#233;rents mod&#232;les.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>268 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;f&#233;rences
</p>
<p>COLLINS, M. et SINGER, Y. (1999). Unsupervised models for named entity classification. In
Proceedings of Empirical Methods for Natural Language Processing (EMNLP) conference.
CONSTANT, M., TELLIER, I., DUCHIER, D., DUPONT, Y., SIGOGNE, A. et BILLOT, S. (2011). Int&#233;grer
des connaissances liguistiques dans un CRF : Application &#224; l&#8217;apprentissage d&#8217;un segmenteur-
&#233;tiqueteur du fran&#231;ais. In Actes de Traitement Automatique du Langage Naturel, TALN&#8217;11,
Montpellier, France.
EBADAT, A. R., CLAVEAU, V. et S&#201;BILLOT, P. (2012). Semantic clustering using bag-of-bag-of-
features. In Actes de le 9e conf&#233;rence en recherche d&#8217;information et applications, CORIA 2012,
Bordeaux, France.
ELSNER, M., CHARNIAK, E. et JOHNSON, M. (2009). Structured generative models for unsupervised
named-entity clustering. In Proceedings of the Conference on Human Language Technology and
North American chapter of the Association for Computational Linguistics (HLT-NAACL 2009),
Boulder, Colorado.
FORT, K. et CLAVEAU, V. (2012). Annotating football matches : influence of the source medium
on manual annotation. In Proceedings of the 8th International Conference on Language Resources
and Evaluation (LREC&#8217;12), Istanbul, Turquie.
GOLDWATER, S. et GRIFFITHS, T. L. (2007). A fully bayesian approach to unsupervised part-of-
speech tagging. In Proceedings of the ACL.
GRAVIER, G., BONASTRE, J.-F., GEOFFROIS, E., GALLIANO, S., TAIT, K. M. et CHOUKRI, K. (2005).
ESTER, une campagne d&#8217;&#233;valuation des syst&#232;mes d&#8217;indexation automatique. In Actes des Journ&#233;es
d&#8217;&#201;tude sur la Parole, JEP, Atelier ESTER2.
HASTIE, T., TIBSHIRANI, R. et FRIEDMAN, J. H. (2001). The Elements of Statistical Learning : Data
Mining, Inference, and Prediction. New York : Springer.
HUBERT, L. et ARABIE, P. (1985). Comparing partitions. Journal of Classification, 2(1):193&#8211;218.
KAZAMA, J. et TORISAWA, K. (2007). Exploiting wikipedia as external knowledge for named
entity recognition. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural Language Learning, pages 698&#8211;707, Prague.
Association for Computational Linguistics.
KOZAREVA, Z. (2006). Bootstrapping named entity recognition with automatically generated
gazetteer lists. In Proceedings of the Eleventh Conference of the European Chapter of the Association
for Computational Linguistics : Student Research Workshop, pages 15&#8211;21, Trento, Italy.
LAFFERTY, J., MCCALLUM, A. et PEREIRA, F. (2001). Conditional random fields : Probabilistic
models for segmenting and labeling sequence data. In International Conference on Machine
Learning (ICML).
LAVERGNE, T., CAPP&#201;, O. et YVON, F. (2010). Practical very large scale CRFs. In Proceedings the
48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 504&#8211;513.
Association for Computational Linguistics.
LIU, B., XIA, Y. et YU, P. S. (2000). Clustering through decision tree construction. In Proceedings
of the ninth international conference on Information and knowledge management, CIKM &#8217;00, pages
20&#8211;29, New York, NY, USA. ACM.
MANNING, C., RAGHAVAN, P. et SCH&#220;TZE, H. (2008). Introduction to information retrieval. Cam-
bridge University Press.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>269 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>MERIALDO, B. (1994). Tagging english text with a probabilistic model. Computational Linguistics,
20:155&#8211;171.
</p>
<p>MITCHELL, T. M. (1990). The need for biases in learning generalizations. Rutgers Computer
Science Department Technical Report CBM-TR-117, May, 1980. Reprinted in Readings in Machine
Learning.
</p>
<p>NGUYEN XUAN VINH, Julien Epps, J. B. (2010). Information theoretic measures for clusterings
comparison. Journal of Machine Learning Research.
</p>
<p>PRANJAL, A., DELIP, R. et BALARAMAN, R. (2006). Part of speech tagging and chunking with HMM
and CRF. In Proceedings of NLP Association of India (NLPAI) Machine Learning Contest.
</p>
<p>RAND, W. M. (1971). Objective criteria for the evaluation of clustering methods. Journal of the
American Statistical Association, 66(336):pp. 846&#8211;850.
</p>
<p>RAVI, S. et KNIGHT, K. (2009). Minimized models for unsupervised part-of-speech tagging. In
Proceedings of ACL-IJCNLP 2009, pages 504&#8211;512.
</p>
<p>RAYMOND, C. et FAYOLLE, J. (2010). Reconnaissance robuste d&#8217;entit&#233;s nomm&#233;es sur de la parole
transcrite automatiquement. In Actes de Traitement Automatique des Langues Naturelles, TALN&#8217;10,
Montr&#233;al, Canada.
</p>
<p>RICHARD, D. et BENOIT, F. (2010). Semi-supervised part-of-speech tagging in speech applications.
In Interspeech 2010, Makuhari (Japan).
</p>
<p>SCHRAUDOLPH, N. N., YU, J. et G&#220;NTER, S. (2007). A stochastic quasi-Newton method for online
convex optimization. In Proceedings of 11th International Conference on Artificial Intelligence and
Statistics, volume 2 de Workshop and Conference Proceedings, pages 436&#8211;443, San Juan, Puerto
Rico.
</p>
<p>SHI, T. et HORVATH, S. (2005). Unsupervised learning with random forest predictors. Journal of
Computational and Graphical Statistics, 15(1):118&#8211;138.
</p>
<p>SMITH, N. et EISNER, J. (2005). Contrastive estimation : Training log-linear models on unlabeled
data. In Proceedings of ACL.
</p>
<p>van DONGEN, S. (2000). Graph Clustering by Flow Simulation. Th&#232;se de doctorat, Universit&#233;
d&#8217;Utrecht.
</p>
<p>WANG, T., LI, J., DIAO, Q., WEI HU, Y. Z. et DULONG, C. (2006). Semantic event detection using
conditional random fields. In IEEE Conference on Computer Vision and Pattern Recognition
Workshop (CVPRW &#8217;06).
</p>
<p>WANG, W., BESAN&#199;ON, R., FERRET, O. et GRAU, B. (2011). Filtering and clustering relations
for unsupervised information extraction in open domain. In Proceedings of the 20th ACM
international Conference on Information and Knowledge Management (CIKM), pages 1405&#8211;1414,
Glasgow, Scotland, UK.
</p>
<p>WANG, W., BESAN&#199;ON, R., FERRET, O. et GRAU, B. (2012). Evaluation of unsupervised informa-
tion extraction. In Proceedings of the 8th International Conference on Language Resources and
Evaluation (LREC&#8217;12), Istanbul, Turquie.
</p>
<p>WENHUI LIAO, S. V. (2009). A simple semi-supervised algorithm for named entity recognition.
In Proceedings of the NAACL HLT Workshop on Semi-supervised Learning for Natural Language
Processing, pages 58&#8211;65, Boulder, Colorado, USA. Association for Computational Linguistics.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>270 c&#65535; ATALA</p>

</div></div>
</body></html>