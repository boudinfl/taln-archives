TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Utilisation de la similarité sémantique pour l’extraction de
lexiques bilingues a partir de corpus comparables

Dhouha Bouamor L23 Nasredine Semmarl Pierre Zweigenbaumz

(1) CEA-LIST, LVIC, F91191 Gif sur Yvette Cedex, France
(2) LIMSI-CNRS, F-91403 Orsay, France
(3) Univ. Paris Sud, Orsay, France
dhouha .bouamor@cea . fr, nasredine . semmar@cea . fr, pz@limsi . fr

RESUME
Cet article présente une nouvelle méthode visant a améliorer les résultats de l’approche standard
utilisée pour l’extraction de lexiques bilingues a partir de corpus comparables spécialisés. Nous
tentons de résoudre le probléme de la polysémie des mots dans les vecteurs de contexte par
l’introduction d’un processus de désambiguisation sémantique basé sur WordNet. Pour traduire
les vecteurs de contexte, au lieu de considérer toutes les traductions proposées par le dictionnaire
bilingue, nous n’utilisons que les mots caractérisant au mieux les contextes en langue cible.
Les expériences menées sur deux corpus comparables spécialisés frangais-anglais (ﬁnancier
et médical) montrent que notre méthode améliore les résultats de l’approche standard plus
particuliérement lorsque plusieurs mots du contexte sont ambigus.

ABSTRACT

This paper presents a new method that aims to improve the results of the standard approach
used for bilingual lexicon extraction from specialized comparable corpora. We attempt to solve
the problem of context vector word polysemy. Instead of using all the entries of the dictionary to
translate a context vector, we only use the words of the lexicon that are more likely to give the
best characterization of context vectors in the target language. On two specialised French—English
comparable corpora, empirical experimental results show that our method improves the results
obtained by the standard approach especially when many words are ambiguous.

MOTS-CLES : lexique bilingue, corpus comparable spécialisé, désambiguisation sémantique,
WordNet.

KEYWORDS: bilingual lexicon, specialized comparable corpora, semantic disambiguation, Word-
Net.

1 Introduction

Les lexiques bilingues sont des ressources particuliérement utiles pour la Traduction Automatique
et la Recherche d’Informau'on Interlingue. Les recherches en extraction lexicale a partir de corpus
multilingues se sont largement concentrées sur les corpus paralléles. En effet, la rareté de ces
corpus, en particulier pour les domaines spécialisés et pour les couples de langues ne faisant pas
intervenir l’anglais, conduit en outre a orienter les recherches en extraction de lexiques bilingues

327 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

vers l’utilisation de corpus comparables (Fung, 1995; Rapp, 1995; Chiao et Zweigenbaum,
2003; Gamallo Otero, 2007; Prochasson et al., 2009; Kun et Tsujii, 2009). La plupart de ces
travaux héritent de la sémantique distributionnelle (Harris, 1954) et reposent sur la simple
observation que si dans une langue source deux mots cooccurrent plus souvent que par hasard,
alors dans un texte de langue cible, leurs traductions doivent également cooccurrer plus souvent.
Cette approche dite standard se base sur la caractérisation et la comparaison d’environnements
lexicaux des termes sources et cibles, représentés par des vecteurs de contexte. Ces vecteurs
stockent un ensemble d’unités lexicales représentatif de leur voisinage. Dans la pratique, aﬁn
de pouvoir comparer les vecteurs de contexte de langues différentes, le passage d’une langue a
une autre est nécessaire et s’effectue généralement par l’intermédiaire d’un dictionnaire bilingue
amorce.

Le dictionnaire bilingue est au coeur de l’approche standard. Son utilisation pose des problémes
lorsqu’un mot possede plusieurs traductions, qu’il s’agisse de traductions synonyrnes ou d’un
terme source polysémique. Par exemple, le terme Francais “action” se traduit en Anglais par les
termes “share, stock, lawsuit” et “deed”. Dans ce cas, il est difﬁcile d’évaluer dans des ressources
plates comme les dictionnaires bilingues quelles traductions sont les plus pertinentes, vu qu’elle
sont le plus souvent non ordonnées. L’approche standard prend en compte toutes les traductions
disponibles et les conserve avec la meme priorité dans le vecteur traduit indépendamment du
domaine sur lequel porte l’étude. Ainsi, en domaine de la Finance, la prise en compte des termes
“lawsuit” et “deed” ne feront probablement qu’ajouter du bruit dans les vecteurs de contexte.

Dans ce présent travail, nous présentons une nouvelle approche qui tente de résoudre le probléme
de polysémie des mots non traité par l’approche standard. Un mot polysémique est une unité
lexicale ayant plusieurs sens dans une langue ou une fois traduite dans une autre langue. Nous
introduisons un processus de désambiguisation sémantique des vecteurs de contexte construits
par l’approche standard. L’intuition qui sous—tend cette méthode est que, pour chaque mot poly-
sémique du vecteur de contexte, au lieu de considérer toutes les traductions proposées par le
dictionnaire bilingue, nous n’utilisons que les traductions susceptibles de donner la meilleure re-
présentation du vecteur de contexte en langue cible. Le processus de désambiguisation repose sur
une mesure de similarité sémantique calculée en se basant sur le thésaurus WordNet (Fellbaum,
1998). Nous testons cette méthode sur deux corpus comparables spécialisés pour le couple des
langues francais—anglais. Une amélioration des résultats de l’approche standard est reportée plus
particuliérement lorsque plusieurs mot du corpus sont ambigus.

La suite de l’article est organisée comme suit : dans la section 2, nous présentons l’approche
standard et passons en revue les principaux travaux connexes a la tache d’extracu'on de lexiques
bilingues a partir de corpus comparables. Puis, nous décrivons, dans la section 3, le processus
de désambiguisation sémantique propose’. La section 4 sera consacrée aux expériences menées
ainsi qu’a la présentation des résultats obtenus. Notre article se conclura par une présentation
des principales perspectives (section 5).

328 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

lized, comparable corpora. In Proceedings of the 19th international conference on Computational
linguistics — Volume 2, COLING ’02, pages 1-5. Association for Computational Linguistics.

CHIAO, Y.—C. et ZWEIGENBAUM, P. (2003). The effect of a general lexicon in corpus—based
identiﬁcation of French—Eng1ish medical word translations. In Proceedings Medical Informatics
Europe, volume 95 of Studies in Health Technology and Informatics, pages 397-402, Amsterdam.

CHO, M., CHOI, C., KIM, H., SHIN, J. et KIM, P. (2007). Efﬁcient image retrieval using conceptuali-
zation of annotated images. Lecture Notes in Computer Science, pages 426-433. Springer.

CHOI, D., KIM, J., KIM, H., HWANG, M. et KIM, P. (2012). A method for enhancing image
retrieval based on annotation using modiﬁed wup similarity in wordnet. In Proceedings of the
1 1 th WSEAS international conference on Artificial Intelligence, Knowledge Engineering and Data
Bases, AIKED’12, pages 83-87, Stevens Point, Wisconsin, USA. World Scientiﬁc and Engineering
Academy and Society (WSEAS).

DEJEAN, H., GAUSSIER, E. et SADAT, E (2002). An approach based on multilingual thesauri and
model combination for bilingual lexicon extraction. In Proceedings of the 19th international
conference on Computational linguistics — Volume 1, COLING ’02, pages 1-7. Association for
Computational Linguistics.

FELLBAUM, C. (1998). WordNet : An Electronic Lexical Database. Bradford Books.

FUNG, P. (1995). A pattern matching method for ﬁnding noun and proper noun translations from
noisy parallel corpora. In Proceedings of the 33rd annual meeting on Association for Computational
Linguistics, pages 236-243. Association for Computational Linguistics.

FUNG, P. (1998). A statistical view on bilingual lexicon extraction : From parallel corpora to
non—parallel corpora. In Parallel Text Processing, pages 1-17. Springer.

GAMALLO OTERO, R (2007). Learning bilingual lexicons from comparable English and Spanish
corpora. In Proceedings of MT SUMMIT, pages 191-198.

GAUSSIER, E., RENDERS, J.—M., MATVEEVA, I., GOUTTE, C. et DEJEAN, H. (2004). A geometric view
on bilingual lexicon extraction from comparable corpora. In ACL, pages 526-533.

HARRIS, Z. (1954). Distributional structure. Word, pages 146-162.

HAZEM, A. et MORIN, E. (2012a). Adaptive dictionary for bilingual lexicon extraction from
comparable corpora. In Proceedings, 8th international conference on Language Resources and
Evaluation (LREC), Istanbul, Turkey

HAZEM, A. et MORIN, E. (2012b). Qalign :a new method for bilingual lexicon extraction from
comparable corpora. In Proceedings of CICLING, India.

HWANG, M., CHOI, C. et KIM, P. (2011). Automatic enrichment of semantic relation network
and its application to word sense disambiguation. IEEE Transactions on Knowledge and Data
Engineering, 23:845-858.

KUN, Y. et TSUJII, J . (2009). Bilingual dictionary extraction from Wikipedia. In Proceedings of
MT SUMMIT.

LAROCHE, A. et LANGLAIS, P. (2010). Revisiting context-based projection methods for term-
translation spotting in comparable corpora. In 23rd International Conference on Computational
Linguistics (Coling 2010), pages 617-625, Beijing, China.

LI, B. et GAUSSIER,  (2010). Improving corpus comparability for bilingual lexicon extraction
from comparable corpora. In 23rd International Conference on Computational Linguistics (Coling
2010), Beijing, China.

337 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

LIN, D. (1998). An information—theoretic deﬁnition of similarity. In Proceedings of the Fifteenth
International Conference on Machine Learning, ICML ’98, pages 296-304, San Francisco, CA,
USA. Morgan Kaufmann Publishers Inc.

MANNING, C. D., RAGHAVAN, P. et SCHTZE, H. (2008). Introduction to Information Retrieval.
Cambridge University Press, New York, NY, USA.

MORIN, E. et DAILLE, B. (2004). Extraction terminologique bilingue a partir de corpus compa-
rables d’un domaine spécialisé. In Traitement Automatique des Langues (TAL).

MORIN, E. et DAILLE, B. (2006). Comparabilité de corpus et fouille terminologique multilingue.
In Traitement Automatique des Langues (TAL).

MORIN, E. et PRocHAssoN, E. (2011). Bilingual lexicon extraction from comparable corpora
enhanced with parallel corpora. In Proceedings, 4th Workshop on Building and Using Comparable
Corpora (BUCC), page 27-34, Portland, Oregon, USA.

PROCHASSON, E. et MORIN, E. (2009). Points d’ancrage pour l’extraction lexicale bilingue a partir
de petits corpus comparables spécialisés. Traitement Automatique des Langues, page 22.

PROCHASSON, E., MORIN, E. et KAGEURA, K. (2009). Anchor points for bilingual lexicon extraction
from small comparable corpora. In Proceedings, 12th Conference on Machine Translation Summit
(MT Summit XII), page 284-291, Ottawa, Ontario, Canada.

RAPP, R. (1995). Identifying word translations in non—parallel texts. In Proceedings of the
33rd annual meeting on Association for Computational Linguistics, ACL ’95, pages 320-322.
Association for Computational Linguistics.

RUBINO, R. et LINARES, G. (2011). Une approche multi-vue pour l’extraction terminologique
bilingue. In CORIA, pages 97-111.

SADAT, E et TERRASA, A. (2010). Exploitation de vvikipédia pour l’enrichissement et la construc-
tion des ressources linguistiques. In Proceedings of TALN, Montréal, Canada.

VULIC, I. et MOENS, M.-E (2012). Detecting highly conﬁdent word translations from comparable
corpora without any prior knowledge. In Proceedings of the 13th Conference of the European
Chapter of the Association for Computational Linguistics, pages 449-459, Avignon, France.
Association for Computational Linguistics.

WU, Z. et PALMER, M. (1994). Verbs semantics and lexical selection. In Proceedings of the
32nd annual meeting on Association for Computational Linguistics, ACL ’94, pages 133-138.
Association for Computational Linguistics.

338 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
2 Extraction de lexiques bilingues

2. 1 Approche standard

La plupart des travaux traitant la téiche d’extraction de lexiques bilingues a partir de corpus
comparables se basent sur l’approche standard (Fung, 1998; Chiao et Zweigenbaum, 2002;
Laroche et Langlais, 2010). Cette approche se décompose en trois étapes :

— Constitution des vecteurs de contexte : Ces vecteurs sont d’abord extraits en repérant les
mots qui apparaissent autour d’un terme a traduire S dans une fenétre contextuelle de n mots.
Habituellement, des mesures d’associations comme 1’information mutuelle (Morin et Daille,
2006), le taux de vraisemblance (Morin et Prochasson, 2011) ou encore le rapport des chances
(odds—Ratio) (Laroche et Langlais, 2010) sont utilisées pour déﬁnir les entrées du vecteur de
contexte.

— Transfert des vecteurs de contexte : Aﬁn de rendre possible la comparaison des vecteurs
sources et cibles, les vecteurs des termes sources sont traduits par le biais d’un dictionnaire
bilingue amorce. Si le dictionnaire propose plusieurs traductions pour un élément, nous
ajoutons 1’ensemble des traductions proposées. Les mots ne ﬁgurant pas dans le dictionnaire
sont tout simplement ignorés.

— Comparaison des vecteurs sources et cibles : Les vecteurs traduits sont ensuite comparés
a l’ensemble des vecteurs de contexte en langue cible a l’aide d’une mesure de similarité
vectorielle. La plus populaire étant le cosinus, mais de nombreux auteurs ont étudiés des
métriques alternatives comme la distance du Jaccard pondérée ou encore le city-block. En
fonction des valeurs de similarité, nous obtenons une liste ordonnée de traductions candidates
pour le terme S.

2.2 'I'ravaux reliés

La couverture du dictionnaire bilingue assurant le transfert des vecteurs de contexte en langue
cible demeure le noyau de l’approche standard. Si trop peu de mots sont traduits, la comparai-
son de vecteurs traduits et de vecteurs cibles ne sera pas signiﬁcative puisque réalisée sur un
échantillon trop faible de vocabulaire. Pour limiter cet effet, des techniques Visant a améliorer
les résultats de l’approche standard ont vu le jour et ce par l’adjonction de ressources diction-
nariques spécialisées supplémentaires préétablies (Déjean et al., 2002; Chiao et Zweigenbaum,
2003), extraites de corpus paralléles (Morin et Prochasson, 2011) cu encore du méme corpus
d’étude (Vulié et Moens, 2012).

Récemment, des recherches fondées sur l’hypothése que plus les vecteurs de contexte sont
représentatifs, meilleure est la mise en correspondance bilingue ont été menées. (Prochasson
et al., 2009) utilisent les translittérations et mots savants comme ’points d’ancrage’. L’objectif est
que la comparaison des vecteurs se fonde en priorité sur les points d’ancrage, puis sur le reste
d’éléments. Outre les translittérations, (Rubino et Linarés, 2011) combinent la représentation
contextuelle avec une représentation thématique de termes médicaux, en émettant l’hypothése
qu’un terme et sa traduction partagent des similarités d’un point de vue thématique. (Hazem
et Morin, 2012a) proposent deux critéres de ﬁltrage du dictionnaire bilingue dans le but de
ne garder que les mots qui donnent la meilleure représentation du vecteur de contexte dans la
langue cible. Le premier critére se base sur les catégories grammaticales des mots du contexte

329 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

mais aucune amélioration n’a été démontrée. Le deuxieme critere étant basé sur une mesure de
pertinence d’un mot pour un domaine donné. Contrairement au premier critere, celui ci apporte
une petite amélioration (4% en précision) par rapport a la méthode standard.

(Gaussier et al., 2004) tentent de résoudre le probléme d’ambigu'ité de mots des vecteurs
de contexte en langues source et cible. Ils utilisent une vue géométrique et décomposent le
vecteur d’un mot en fonction de ses sens par l’uti1isation de plusieurs méthodes comme l’analyse
canonique de corrélation et 1’analyse sémantique latente. Les meilleurs résultats sont obtenus
par l’utilisation d’une approche mixte avec une amélioration de la F—Mesure au To p20 de +2%
par rapport a l’approche standard. Dans cet article, nous présentons une approche traitant le
probleme d’ambigu'ité des mots des vecteurs de contexte mais qui differe de celle proposée par
(Gaussier et al., 2004). Alors qu’ils mettent l’accent sur l’ambigu'ité des mots en langues source
et cible, nous jugeons qu’il serait sufﬁsant de lever l’ambigu'ité des éléments des vecteurs de
contexte en langue source vu que l’ambigu'ité parvient lors du transfert des vecteurs de contexte
sources

3 Désambiguisation lexicale des vecteurs de contexte

Nous proposons dans cet article une approche qui tente d’améliorer les résultats de l’approche
standard. Nous abordons le probleme associé aux mots polysémiques révélés par le dictionnaire
bilingue amorce lors du transfert des vecteurs de contexte sources. Comme il a été mentionné
dans la section 1, lorsque l’extraction lexicale porte sur un domaine spécialisé, les traductions
proposées par le dictionnaire bilingue ne sont pas toutes pertinentes pour la représentation des
vecteurs de contexte en langue cibles. Par exemple, dans le domaine juridique, la traduction
du mot action (Fr) par share ou stock (An) ne fera qu’introduire du bruit dans les vecteurs
traduits. L’intuition derriére notre approche est qu’il conviendrait d’introduire un processus de
désambiguilsation sémantique lexicale visant a améliorer l’adéquation des vecteurs de contexte
traduits et par conséquent améliorer les résultats de l’approche standard. Dans cette section, nous
commencons par décrire la ressource sémantique sur laquelle se base notre approche. Ensuite,
nous présentons en détail notre méthode de désambiguisation des vecteurs de contexte.

3. 1 Ressource sémantique

Un grand nombre de techniques de désambiguisation lexicale ont été présentées dans la litté—
rature. Les plus populaires sont celles mesurant une similarité sémantique en se basant sur le
thésaurus WordNet. Cette ressource est structurée autour de la notion de synsets, c’est-a-dire en
quelque sorte un ensemble de synonymes qui forment un concept. Chaque synset représente un
sens de mot. Les synsets sont reliés entre eux par des relations, soit lexicales (antonymie par
exemple) ou taxonomiques (hyperonymie, méronymie, etc). Ce thésaurus est largement utilisé
dans des applications reposant sur le calcul de similarité des mots telles que la recherche de
documents (Hwang et al., 2011) ou d’images (Cho et al., 2007; Choi et al., 2012). Dans ce travail,
nous l’utilisons pour dériver une similarité sémantique entre les éléments de chaque vecteur de
contexte permettant de sélectionner les sens des mots les plus saillants a la représentation des
termes a traduire. A notre connaissance, c’est une premiere application de WordNet en extraction
de lexiques bilingues a partir de corpus comparables.

330 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Vecteur de contexte {action}, {dividende}, {liquidité}, 

Dictionnaire bilingue {act, stock, action, deed, lawsuit, fact, operation, plot, share} , {divi-
dend} , {liquidity}

Sems,-,,, {dividend, act}; {dividend,stock}; .. . ; {liquidity, act}; {liqui-
dity,stock} ; 

Ave_Wup(action) share :0.5236, stock :0.5236, action :0.4256, act :0.2139, opera-
tion :0.2045, plot :0.2011, fact :0.1934, deed :0.1594, lawsuit :0.1212

TABLE 1 — Désambiguisation sémantique du vecteur de contexte du terme bénéﬁce

Parmi les mesures de similarité sémantique utilisant WordNet, nous retrouvons les mesures
basées sur la distance taxonomique. Le principe général de ces mesures est de compter le nombre
d’arcs qui séparent deux sens dans WordNet. Dans ce cadre, nous choisissons la mesure déﬁnie
par (Wu et Palmer, 1994). La similarité est déﬁnie selon la distance qui sépare deux concepts par
rapport a leur sens commun le plus spéciﬁque (LCS) que la racine de la taxonomie. La similarité
entre deux sens 51 et 52 est :

2 x depth(LCS)

depth(s1) + depth(s2) (1)

Simwup(51: 52) =

on depth(LCS) est le nombre d’arcs qui séparent LCS de la racine et depth(s,-) avec i le nombre
d’arcs qui séparent s,- de la racine en passant par LCS. Cette mesure a l’avantage d’avoir de
meilleures performances par rapport aux autres mesures de similarité (Lin, 1998).

3.2 Processus de désambiguisation

Une fois transféré en langue cible, le processus de désambiguisation des vecteurs de contexte
intervient. Ce processus tente de trouver pour chacune des entrées polysémiques dans les
vecteurs traduits le sens le plus adéquat. Pour ce faire, nous utilisons les unités non polysémiques
pour déduire les sens de celles polysémiques. Nous émettons l’hypothése qu’un mot est non
polysémique s’il ne posséde qu’une seule traduction dans le dictionnaire bilingue. Cette hypothése
est vériﬁée dans 95% des cas dans WordNet (i.e mots associés a un seul synset).

Précisément, pour chaque entrée polysémique de chaque vecteur, nous mesurons la similarité
sémantique entre toutes les traductions qui lui sont associées et toutes les unités non polysémiques
du méme vecteur. En fonction des valeurs de similarité, nous obtenons une liste ordonnée de
sens ou traductions pour chaque mot polysémique.

Plus formellement, puisqu’un mot peut appartenir a plus d’un sens ou synset dans WordNet, nous
déterminons la similarité sémantique entre deux mots ml et mg comme le maximum de S imwup
entre le ou les synsets qui incluent les s_ynsets(m1) et les synse ts(m2) selon la formule suivante :

Semsl-m(m1, m2) = max{Simwup(51:52); (51,s2) E 5)'n5et5(m1) >< 5ynsets(m2)} (2)

Ensuite, pour identiﬁer le sens le plus approprié pour chaque mot polysémique k dans les
vecteurs de contexte, nous mesurons une moyenne de similarité (Formule 3) pour chacune des

331 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

traductions proposées k j .

2:1 Sem-Sim(mis kj)

N (3)

Ave_Wup(kJ-) =
ou N est le nombre total des mots non polysémique du vecteur traduit et Sems,-,,, est la valeur
de similarité entre kj et le mot non polysémique m,-. Dans le cas ou tous les mots du vecteur
de contexte sont polysémiques, il est possible de calculer la similarité sémantique entre toutes
les combinaisons de mots. Dans de tels cas, nous choisissons de ne pas toucher au Vecteurs de
contexte puisque avec le calcul de ce type de similarité une augmentation de la complexité algo-
rithmique et détérioration des résultats d’extraction ont été constatés dans des expérimentations
préliminaires.

Un exemple de désambiguisation de vecteur de contexte du terrne “bénéﬁce” est décrit dans la
table 1. Ce vecteur est construit a partir de corpus comparable spécialisé et contient les mots
action, dividende, liquidite' et d’autres unités. Lors du transfert de ce vecteur de la langue source
(Francais) a celle cible (Anglais), le dictionnaire bilingues propose les traductions suivantes « act,
stock, action, deed, lawsuit, fact, operation, plot, share », « dividend» et «liquidity» pour traduire
respectivement les mots « action », « dividende » et « liquidite’ ». Nous utilisons les unités lexicales
non polysémiques « dividende » et « liquidite'» pour désambiguiser le mot « action ». En observant
la valeur de Ave_Wup, nous remarquons que dans ce contexte, les mots share et stock sont les
traductions les plus appropriées au mot action. Nous remarquons aussi que les mots issus du
domaine général se placent apres pour retrouver a la ﬁn les unités les moins proches (deed et
lawsuit).

4 Expérimentations et résultats

4.1 Ressources linguistiques

Dans le cadre de cette étude, nous avons construit deux corpus comparables spécialisés francais—
anglais a partir de l’encyclopédie libre Wikipédial. Nous exploitons l’aspect multilingue cette
ressource pour en extraire de la terminologie spécialisée qui pourra créer ou enrichir des
ressources linguistiques existantes. Nous nous intéressons particulierement au domaine de la
«finance des entreprises » et a la thématique du « cancer du sein » relevant du domaine médical.
Notre approche repose en premier lieu sur 1’extraction de pages de Wikipédia en langue source.
Ensuite, les liens interlingues sont utilisés aﬁn de chercher l’informat'1on translinguistique et donc
construire la partie du corpus en langue cible (Sadat et Terrasa, 2010).

Nous considérons que le domaine d’étude constitue une catégorie dans Wikipédia. Les catégories
sont un systéme de classement thématique des articles de Wikipédia. Une requéte composée du
domaine d’étude en langue source (par exempleﬁnance des entreprises) est donc construite pour
extraire une arborescence de catégories ou de themes ayant pour catégorie mere le domaine de
spécialité. Un exemple d’arborescence est présenté dans la ﬁgure 1.

Ensuite, Nous collectons tous les articles associés a chacune des catégories de l’arborescence
pour construire un corpus spécialisé monolingue (en langue source). Aﬁn de collecter les articles

lhttp://dumps.wikimedia.org/
332 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Finance des enlreprise

Analyse Financiére Cmnplabililé générale Indicaleur Financier

Risque Bilan Salaire 3é..é;;m Revenu
Crédil

/'"N2“\ l4\

FIGURE 1 — Arborescence de catégories de la thématique Finance des entreprises

en langue cible, les liens interlingues au sein de chaque article du corpus monolingue sont
utilisés. Un étiquetage morpho—syntaxu'que et une lemmatisation ont été appliqués sur les articles
collectés. Nous avons aussi retiré les mots fonctionnels et ceux apparaissant moins de deux fois
dans les deux parties du corpus comparable. Nous avons ainsi construit deux corpus comparables
de taille réduite. La taille en nombre de mots des corpus résultants est dans la table 2

Corpus Francais Anglais
Finance des entreprises 402.486 756.840
Cancer du sein 396.524 524.805

TABLE 2 — Taille des corpus comparables. La taille est exprimée en nombre de mots

Le dictionnaire bilingue Francais—Anglais assurant le transfert des Vecteurs de contexte comporte
environ 120000 entrées avec en moyenne 7 traductions par entrée. I1 s’agit d’un dictionnaire du
domaine général comportant quelques mots en rapport avec le domaine ﬁnancier et médical.

Pour évaluer la qualité de l’approche standard et celle introduisant la désambiguisation lexicale
des Vecteurs de contexte, nous avons construit une liste de traductions de référence pour chaque
domaine. Habituellement, la taille de ces listes est autour de 100 mots (Hazem et Morin, 2012a;
Chiao et Zweigenbaum, 2002). Précisons que nous nous intéressons dans cet article uniquement
a l’extraction bilingue de termes simples. D’autres recherches se sont portées sur l’extraction
de termes complexes (Morin et Daille, 2004; Laroche et Langlais, 2010). Pour le domaine de
la ﬁnance des entreprises, une liste composée de 125 mots simples est extraite du glossaire
bilingue de la micro-finance 2. En ce qui concerne le domaine du cancer du sein, 79 termes
issus du méta-thésaurus UMLS3 et du MESH4 sont extraits. Ces deux listes sont composées de
paires de termes francais—ang1ais apparaissant au moins cinq fois dans chaque partie des corpus
comparables.

Zhttp : //www .microfinance . lu/la—microfinar1ce—cest—quoi/glossaire . html
3http : //www . nlm. nih . gov/research/umls/
4http : //mesh . inserm. fr/mesh/

333 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
4.2 Expérimentations

Aﬁn de mener a bien nos expériences, nous avons besoin de régler trois principaux parametres :
(1) la taille de la fenétre contextuelle, (2) 1a mesure d’associau'on et (3) 1a mesure de similarité.
Comme dans la plupart des travaux antérieurs (Hazem et Morin, 2012b; Chiao et Zweigenbaum,
2002), nous ﬁxons la taille de la fenétre contextuelle a 7, partant de 1’idée qu’e11e approxime les
dépendances syntaxiques. Une étude de différentes combinaisons entre les mesures d’associau'on
et les métriques de similarité a été présentée dans (Laroche et Langlais, 2010). Pour le domaine
médical, la conﬁguration la plus efﬁcace étant de combiner 1e rapport des chances [Odds—Ratio]
avec le cosinus. Nous avons suivi ces travaux pour la déﬁnition de ces paramétres. La formule du
rapport des chances est déﬁnie dans 1’équau'on ci-dessous :

(011 + %)(022 + %)

OddsRatio - = log T
disc (012 + %)(021 + %)

(4)

Ou O,- 1- sont les cellules d’une table de contingence 2 x 2 regroupant les fréquences d’observau'on
de deux termes dans une fenétre donnée. Le cosinus de 1’ang1e formé par deux vecteurs source vs

et cible vc est déﬁni dans 1’équation 5.

2]. OddsRatioj. x OddsRatioJ°.

(5)

C0-9(Vs,Vc) 2 2
‘/21. OddsRatioj. x  OddsRatio§

4.3 Résultats et discussion

11 est difﬁcile de comparer les résultats de différents travaux en extraction de lexiques bilingues a
partir de corpus comparables, en raison de différences entre les corpus, les domaines d’études
ou encore les ressources linguistiques utilisées (Prochasson et Morin, 2009). A ce jour, aucun
jeu de données pouvant servir de référence n’a été mis en place. C’est pour cette raison que
nous utilisons les résultats de 1’approche standard (AS) comme référence. Nous évaluons les
performances de cette approche et de celle présentée en section 3 en utilisant les métriques
de précision (PN), rappel (RN) au TopN et de MAP (Mean Average Precision) (Manning et al.,
2008). La précision est le nombre de traductions correctes divisé par le nombre de termes pour
lesquels 1e systéme propose au moins une traduction. Le rappel est égal au rapport entre les
traductions correctes et le nombre total des termes. La MAP représente la qualité d’un systeme
en fonction de différents niveaux de rappel :

1 i=1 1 k=1
MAP(Q) = — Z — Z Précision(RJ-k) (6)
Q IQI mi mi
011 Q constitue 1e nombre de termes a traduire, mi est le nombre de traductions de référence pour
le jéme terme et Précision(RJ-k) est égale a 0 si la traduction de référence n’est pas trouvée pour
le jéme terme ou % s’i1 y ﬁgure (r est le rang de la traduction de référence dans les traductions
candidates) .
334 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Méthode P1 P10 P20 R1 R10 R20 MAP
AS 4.6 14 18.6 4 12 16 6.4
WN-S1 6.5 19.6 26.1 5.6 16.8 22.4 8.9
WN-S2 10.2 25.2 30.8 8 21.6 26.4 12.2
WN-S3 10.2 24.2 32.7 8.8 20.8 28 12.2
WN-S4 11.2 22.4 29.9 9 19 25 12.4
WN-S5 9.3 20.5 28 8 17.6 24 11
WN-S5 8.4 20.5 23.3 7.2 17.6 20 9.41
WN-S7 7.4 17.7 24.2 6.4 15.2 20.8 9

TABLE 3 — Corpus de << ﬁnance des entreprises >> : Précision et Rappel au TopN (N = 1, 10, 20) et
MAP (%)

Rappelons que l’AS utilise toutes les traductions proposées par le dictionnaire bilingue pour le
transfert des vecteurs de contexte. Notre méthode de désambiguisation des contextes fournit
pour chaque unité polysémique, un vecteur de sens ordonné en fonction des valeurs de similarité.
A cet égard, il convient de s’interroger sur le nombre de sens a considérer pour chaque mot
polysémique. Devrions nous considérer que l’élément maximisant la similarité sémantique dans
le vecteur de contexte ou envisager un plus grand nombre de sens notamment quand un vecteur
de sens contient des synonymes (share (An) et stock (An) dans la table 1). C’est précisément
pour cette raison que nous prenons en considération pour chaque unité polysémique différents
nombre de sens dans nos expérimentations allant du sens le plus similaire jusqu’au septiéme
sens. L’arrét au septiéme sens ou traduction s’explique par le fait qu’en moyenne, un mot du
corpus comparable posséde 7 traductions dans le lexique bilingue. Ces méthodes sont notées
WN-Si ou i est le nombre de sens associé a chaque unité polysémique. La table 3 présente les
résultats obtenus pour le corpus de la ﬁnance des entreprises.

Nous constatons que notre méthode qui consiste en une désambiguisation des vecteurs de
contexte dépasse les performances de la méthode de référence AS pour toutes les conﬁgurations.
La meilleure MAP est atteinte par (WN—S4), lorsque pour chaque mot polysémique, nous gardons
les quatre traductions les plus similaires aux éléments non polysémiques des vecteurs de contexte.
La précision au Top20 la plus élevée est obtenue par WN—S3. L’uti1isau'on des trois premiers sens
de mots dans le vecteur fait passer la précision au Top20 de 18.6% a 32.7%. Une dégradation de
la MAP, précision et rappel est constatée a partir de WN—S5. L’ajout progressif des traductions
rapproche les résultats obtenus de ceux de l’AS. Nous estimons par conséquent que a partir de
WN—S5, les traductions ajoutées ne font qu’introduire du bruit dans les vecteurs de contextes.

En ce qui concerne le corpus traitant la thématique du cancer du sein, des résultats différents
ont été obtenus. Comme le montre la table 4, lorsque les vecteurs de contexte sont totalement
non ambigus (i.e. chaque unité source est traduite par au plus un mot), une diminution de la
précision, rappel et MAP est notée par rapport 2 l’AS. Néanmoins, dans la plupart des autres cas,
des améliorations plus au moins petites sont obtenues. Dans la méthode WN—S5, nous reportons
le meilleur score avec un gain de +3.4% en MAP par rapport 2‘: AS. Par contre les meilleurs rappel
et précision au Top 10 et 20 sont atteints par WN—S2 et WN-S3.

En observant les résultats (table 3 et 4) des domaines de la ﬁnance des entreprises et celui du
cancer du sein, nous remarquons que dans la plupart des cas l’approche de désambiguisation des

335 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Méthode P1 P10 P20 R1 R10 R20 MAP
AS 34.2 54.2 58.5 25 39.5 42.7 31.4
WN-S1 25.7 50 57.1 18.7 36.4 41.6 25.7
WN-S2 31.4 61.4 67.1 22.9 44.7 48.9 31.3
WN-S3 34.2 62.8 67.1 25 45.8 48.9 34.2
WN-S4 34.2 57.1 64.2 25 41.6 46.8 33.2
WN-S5 35.7 57.1 65.7 26 41.6 47.9 34.8
WN-S5 35.7 57.1 65.2 26 41.6 46.8 34.7
WN-S7 35.7 58.5 65.7 26 42.7 47.9 33.9

TABLE 4 — Corpus du «cancer du sein >> : Précision et Rappel au To pN (N = 1, 10, 20) et MAP (%)

vecteurs de contexte par l’utilisation de la similarité sémantique de WordNet donne de meilleurs
résultats que l’approche de référence AS mais a des degrés différents. Les améliorations reportées
en domaine de la ﬁnance des entreprises dépassent de loin celles du cancer du sein. Ceci peut—étre
dﬁ au fait que le vocabulaire utilisé dans le domaine du cancer du sein est plus spéciﬁque et
donc moins ambigu que celui utilisé dans les textes de la ﬁnance des entreprises. Dans ce cas,
les améliorations restent trouvé dans de larges valeurs de N au TopN (la désambiguisation des
contextes aide a apporter des traductions plus éloignées au Top20).

5 Conclusion

Nous avons présenté dans cet article une nouvelle méthode qui tente d’amé1iorer les résultats de
l’approche standard utilisée en extraction lexicale bilingue. Cette méthode a pour but de lever
l’ambigu'ité des mots polysémiques dans les vecteurs de contexte en sélectionnant uniquement
les traductions susceptibles de représenter au mieux les termes a traduire. La technique proposée
repose sur le calcul d’une similarité sémantique faisant appel au réseau sémantique WordNet.
Les expériences menées sur deux corpus comparables spécialisés montrent que les performances
de cette technique sont dans la plupart des cas supérieures a celles obtenues par l’approche
standard.

Nous considérons que nos expériences initiales sont positives et peuvent étre améliorées de
diverses facons. Nous avons d’abord l’intention d’agrandir la taille des corpus comparables
utilisés. De plus, dans ce travail, nous considérons que les corpus construit sont de bonne qualité,
nous tenterons donc d’agir sur leur qualité en utilisant par exemple la mesure proposée par (Li et
Gaussier, 2010). Outre la métrique déﬁnie par (Wu et Palmer, 1994), nous comptons utiliser
d’autres mesures de similarité sémantique et comparer leurs performances. Nous prévoyons
également d’app1iquer notre méthode a 1’extracu'on de lexiques bilingues a partir d’autre corpus
trés spécialisés pour valider nos hypotheses.

Références

CHIAO, Y.—C. et ZWEIGENBAUM, P. (2002). Looking for candidate translational equivalents in specia-
336 © ATALA

