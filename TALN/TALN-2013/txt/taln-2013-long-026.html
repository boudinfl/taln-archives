<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Regroupement s&#233;mantique de relations pour l&#8217;extraction d&#8217;information non supervis&#233;e</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Regroupement s&#233;mantique de relations pour l&#8217;extraction
d&#8217;information non supervis&#233;e
</p>
<p>Wei Wang1 Romaric Besan&#231;on1 Olivier Ferret1 Brigitte Grau2
(1) CEA, LIST, Laboratoire Vision et Ing&#233;nierie des Contenus, Gif-sur-Yvette, F-91191 France.
</p>
<p>(2) LIMSI, UPR-3251 CNRS-DR4, B&#226;t. 508, BP 133, 91403 Orsay Cedex.
{wei.wang,romaric.besancon,olivier.ferret}@cea.fr brigitte.grau@limsi.fr
</p>
<p>R&#201;SUM&#201;
Beaucoup des recherches men&#233;es en extraction d&#8217;information non supervis&#233;e se concentrent sur
l&#8217;extraction des relations et peu de travaux proposent des m&#233;thodes pour organiser les relations
extraites. Nous pr&#233;sentons dans cet article une m&#233;thode de clustering en deux &#233;tapes pour
regrouper des relations s&#233;mantiquement &#233;quivalentes : la premi&#232;re &#233;tape regroupe des relations
proches par leur expression tandis que la seconde fusionne les premiers clusters obtenus sur la
base d&#8217;une mesure de similarit&#233; s&#233;mantique. Nos exp&#233;riences montrent en particulier que les
mesures distributionnelles permettent d&#8217;obtenir pour cette t&#226;che de meilleurs r&#233;sultats que les
mesures utilisant WordNet. Nous montrons &#233;galement qu&#8217;un clustering &#224; deux niveaux permet
non seulement de limiter le nombre de similarit&#233;s s&#233;mantiques &#224; calculer mais aussi d&#8217;am&#233;liorer
la qualit&#233; des r&#233;sultats du clustering.
</p>
<p>ABSTRACT
Semantic relation clustering for unsupervised information extraction
</p>
<p>Most studies in unsupervised information extraction concentrate on the relation extraction and
few work has been proposed on the organization of the extracted relations. We present in this
paper a two-step clustering procedure to group semantically equivalent relations : a first step
clusters relations with similar expressions while a second step groups these first clusters into
larger semantic clusters, using different semantic similarities. Our experiments show the stability
of distributional similarities over WordNet-based similarities for semantic clustering. We also
demonstrate that the use of a multi-level clustering not only reduces the calculations from all
relation pairs to basic clusters pairs, but it also improves the clustering results.
</p>
<p>MOTS-CL&#201;S : Extraction d&#8217;Information Non Supervis&#233;e, Similarit&#233; S&#233;mantique, Clustering.
KEYWORDS: Unsupervised Information Extraction, Semantic Similarity, Relation Clustering.
</p>
<p>1 Introduction
</p>
<p>Dans le domaine de l&#8217;Extraction d&#8217;Information (EI), les probl&#233;matiques ont &#233;volu&#233; sous l&#8217;impulsion
d&#8217;une s&#233;rie de campagnes d&#8217;&#233;valuation allant de MUC (Message Understanding Conference) &#224;
TAC (Text Analysis Conference) en passant par ACE (Automatic Content Extraction). Les t&#226;ches
d&#233;finies dans les campagnes MUC et ACE concernent l&#8217;extraction d&#8217;information supervis&#233;e, pour
laquelle le type d&#8217;information &#224; extraire est pr&#233;d&#233;fini et des instances sont annot&#233;es dans des
corpus repr&#233;sentatifs. &#192; partir de ces donn&#233;es, des syst&#232;mes d&#233;velopp&#233;s manuellement ou par
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>353 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>apprentissage automatique peuvent &#234;tre d&#233;velopp&#233;s. Les approches semi-supervis&#233;es peuvent
s&#8217;affranchir partiellement des contraintes de disponibilit&#233; de telles donn&#233;es. Par exemple, pour la
t&#226;che KBP (Knowledge Base Population) de la campagne TAC, l&#8217;extraction de relations s&#8217;appuie
sur une base de connaissances existante (construite &#224; partir des infoboxes de Wikip&#233;dia), mais
sans donn&#233;es annot&#233;es. Dans ce cas, des techniques de supervision distante (Mintz et al., 2009)
peuvent &#234;tre appliqu&#233;es. Les m&#233;thodes semi-supervis&#233;es incluent &#233;galement des techniques
d&#8217;amor&#231;age (bootstrapping) (Grishman et Min, 2010) permettant de partir d&#8217;un nombre limit&#233;
d&#8217;exemples pour en extraire d&#8217;autres.
</p>
<p>L&#8217;extraction d&#8217;information non supervis&#233;e diff&#232;re de ces t&#226;ches en ouvrant la probl&#233;matique de
l&#8217;extraction de relations &#224; des relations de type inconnu a priori, ce qui permet de faire face &#224;
l&#8217;h&#233;t&#233;rog&#233;n&#233;it&#233; des relations rencontr&#233;es en domaine ouvert, notamment sur le Web. Le type
de ces relations doit alors &#234;tre d&#233;couvert de fa&#231;on automatique &#224; partir des textes. Dans ce
cadre, les structures d&#8217;information consid&#233;r&#233;es sont en g&#233;n&#233;ral des relations binaires, &#224; l&#8217;instar
de (Hasegawa et al., 2004). Ce travail, parmi les premiers sur cette probl&#233;matique, a avanc&#233;
l&#8217;hypoth&#232;se que les relations les plus int&#233;ressantes entre entit&#233;s nomm&#233;es sont aussi les plus
fr&#233;quentes dans une collection de textes, de sorte que les instances de relations susceptibles
de former des clusters de grande taille peuvent &#234;tre distingu&#233;es des autres. Pour op&#233;rer cette
distinction, un seuil de similarit&#233; minimale appliqu&#233; &#224; une repr&#233;sentation des relations de type sac
de mots &#233;tait &#233;tabli pour d&#233;favoriser les clusters de petite taille. Des am&#233;liorations ont par la suite
&#233;t&#233; apport&#233;es &#224; cette approche initiale par l&#8217;adoption de patrons pour repr&#233;senter les relations au
sein des clusters (Shinyama et Sekine, 2006) ou l&#8217;usage d&#8217;un algorithme d&#8217;ordonnancement de
ces patrons pour la s&#233;lection de relations candidates (Chen et al., 2005).
</p>
<p>Des syst&#232;mes tels que TEXTRUNNER (Banko et al., 2007) ou REVERB (Fader et al., 2011) se
focalisent quant &#224; eux sur l&#8217;extraction de relations &#224; partir de phrases en s&#8217;appuyant sur un
mod&#232;le d&#8217;apprentissage statistique pour garantir la validit&#233; des relations extraites. Des approches
&#224; base de r&#232;gles (Akbik et Bro&#223;, 2009; Gamallo et al., 2012) ou des mod&#232;les g&#233;n&#233;ratifs (Rink
et Harabagiu, 2011; Yao et al., 2011) ont &#233;galement &#233;t&#233; propos&#233;s pour ce faire. Tout en restant
pour l&#8217;essentiel non supervis&#233;es, d&#8217;autres approches font appel &#224; un utilisateur pour d&#233;limiter un
domaine d&#8217;extraction de fa&#231;on peu contrainte. Ainsi, le syst&#232;me On-Demand Information Extraction
(Sekine, 2006) initie le processus d&#8217;extraction par des requ&#234;tes de moteur de recherche.
</p>
<p>Une part notable des travaux men&#233;s en EI non supervis&#233;e se focalisent sur l&#8217;extraction des
relations. Le probl&#232;me de leur regroupement a &#233;t&#233; en revanche moins abord&#233;, en particulier pour
rassembler des relations &#233;quivalentes mais exprim&#233;es de fa&#231;on diff&#233;rente. Nous pr&#233;sentons dans
cet article une m&#233;thode pour r&#233;aliser de tels regroupements efficacement en se fondant sur deux
&#233;tapes de clustering : un premier niveau de regroupement des relations sur la forme, utilisant une
mesure de similarit&#233; simple, et un second niveau permettant de rapprocher les premiers clusters
obtenus en utilisant une mesure de similarit&#233; s&#233;mantique plus sophistiqu&#233;e. Nos exp&#233;riences
montrent que ce clustering &#224; deux niveaux permet d&#8217;am&#233;liorer le regroupement des relations.
</p>
<p>2 Extraction de relations non supervis&#233;e
</p>
<p>La premi&#232;re &#233;tape de notre processus d&#8217;EI non supervis&#233;e est l&#8217;extraction de relations entre
entit&#233;s. Nous avons d&#233;fini pour ce faire un module d&#8217;extraction et de filtrage de relations entra&#238;n&#233;
pour la d&#233;couverte de relations entre entit&#233;s nomm&#233;es. Plus formellement, une relation entre
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>354 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>entit&#233;s nomm&#233;es se caract&#233;rise par un couple d&#8217;entit&#233;s (E1 et E2) et la caract&#233;risation linguistique
de la relation, elle-m&#234;me form&#233;e des trois &#233;l&#233;ments du contexte phrastique autour de ces entit&#233;s
(cf. figure 1) : la caract&#233;risation linguistique principale de la relation est en g&#233;n&#233;ral port&#233;e par la
partie de texte entre les entit&#233;s (Cmid), alors que les &#233;l&#233;ments de chaque c&#244;t&#233; des entit&#233;s (Cpre
et Cpost) apportent en g&#233;n&#233;ral des pr&#233;cisions de contexte.
</p>
<p>!&quot;#$%%$&amp;#'())*#+,-(.#-,#/0-1,)23(#-1(#04(#,5#5,)6(#/7/2&quot;4-#8/../9#2&quot;#!)/:;
</p>
<p>&lt;=#!&quot;#$%&amp;''#( &lt;$#!&quot;#$%&amp;''#(
</p>
<p>&gt;?)( &gt;92. &gt;?,4-
</p>
<p>FIGURE 1 &#8211; Exemple de relation extraite
</p>
<p>Dans les syst&#232;mes d&#8217;EI non supervis&#233;e, les entit&#233;s en relation peuvent &#234;tre des entit&#233;s nomm&#233;es
(Hasegawa et al., 2004) ou, de fa&#231;on plus ouverte, des syntagmes nominaux (Rozenfeld et
Feldman, 2006). Les entit&#233;s nomm&#233;es permettent en g&#233;n&#233;ral d&#8217;avoir une meilleure s&#233;paration
des diff&#233;rents types de relations alors que l&#8217;utilisation de syntagmes nominaux permet d&#8217;avoir un
plus grand nombre de candidats. Nous nous int&#233;ressons dans notre syst&#232;me aux relations entre
entit&#233;s nomm&#233;es, &#224; la fois pour faciliter l&#8217;organisation des relations trouv&#233;es et pour r&#233;pondre au
besoin le plus g&#233;n&#233;ralement r&#233;pandu en contexte applicatif de veille. L&#8217;extraction des relations se
fait alors selon les &#233;tapes suivantes :
&#8211; Analyse linguistique : un traitement linguistique est tout d&#8217;abord appliqu&#233; aux textes du
corpus consid&#233;r&#233; pour extraire les &#233;l&#233;ments pouvant caract&#233;riser les relations candidates. Ce
traitement inclut une reconnaissance des entit&#233;s nomm&#233;es pour les types impliqu&#233;s dans les
relations recherch&#233;es, mais aussi une d&#233;sambigu&#239;sation morpho-syntaxique et une lemmatisa-
tion pour normaliser les contextes linguistiques des relations. Ce traitement a &#233;t&#233; r&#233;alis&#233; avec
les outils OpenNLP ;
</p>
<p>&#8211; Extraction de relations candidates : une premi&#232;re extraction simple est r&#233;alis&#233;e avec peu de
contraintes pour permettre la collecte d&#8217;une grande vari&#233;t&#233; de relations. Toutes les phrases
contenant deux entit&#233;s nomm&#233;es sont donc extraites, avec la seule condition qu&#8217;au moins un
verbe existe entre ces entit&#233;s ;
</p>
<p>&#8211; Filtrage de relations : &#224; l&#8217;issue de l&#8217;extraction initiale, beaucoup de relations candidates ne
sont pas des instances r&#233;elles de relations. Une &#233;tape de filtrage est alors appliqu&#233;e, comprenant
une premi&#232;re passe de filtrage heuristique, pour supprimer efficacement les relations les plus
probablement fausses (discours rapport&#233;, phrases complexes), et une seconde passe de filtrage
par apprentissage statistique, entra&#238;n&#233; sur un corpus annot&#233; de 1 000 exemples positifs et
n&#233;gatifs de relations, et s&#8217;appuyant sur un mod&#232;le de Champs Conditionnels Al&#233;atoires (CRF).
Ce filtrage statistique permet d&#8217;obtenir une pr&#233;cision de 76,2% et un rappel de 78,2% sur les
relations extraites (Wang et al., 2011).
</p>
<p>Pour nos exp&#233;riences, nous avons utilis&#233; une sous-partie du corpus AQUAINT-2 contenant 18
mois d&#8217;articles de presse du journal New York Times. Les relations candidates ont &#233;t&#233; extraites et
filtr&#233;es selon la m&#233;thode pr&#233;sent&#233;e pour six types de relations fond&#233;es sur trois types d&#8217;entit&#233;s
nomm&#233;es faisant consensus : les organisation (ORG), les lieux (LOC) et les personnes (PER). Le
nombre des relations restant apr&#232;s filtrage, pr&#233;sent&#233; dans le tableau 1, montre la n&#233;cessit&#233; de
mettre en &#339;uvre un regroupement de ces relations pour aider un utilisateur &#224; appr&#233;hender les
informations extraites.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>355 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Total ORG-LOC ORG-ORG ORG-PER PER-LOC PER-ORG PER-PER
165 708 15 226 13 704 10 054 47 700 40 238 38 786
</p>
<p>TABLE 1 &#8211; Nombre de relations extraites
</p>
<p>3 Regroupement de relations
</p>
<p>Dans cette section, nous pr&#233;sentons plus sp&#233;cifiquement notre m&#233;thode de clustering multi-niveau
d&#233;finie afin de regrouper les relations extraites en fonction de leur similarit&#233; s&#233;mantique. Cette
m&#233;thode s&#8217;organise en deux &#233;tapes, &#224; l&#8217;instar de (Cheu et al., 2004) : un premier clustering de
base est r&#233;alis&#233; en s&#8217;appuyant sur la similarit&#233; des formes de surface des relations, ce qui permet
de former de mani&#232;re efficace de petits clusters homog&#232;nes ; une seconde &#233;tape de clustering est
ensuite appliqu&#233;e pour rassembler ces clusters initiaux sur la base d&#8217;une similarit&#233; s&#233;mantique
entre relations plus complexe.
</p>
<p>3.1 Regroupement de base
</p>
<p>3.1.1 Principe
</p>
<p>En EI non supervis&#233;e, le nombre de relations extraites est rapidement important comme le
montre le tableau 1. De ce fait, il est quasiment impossible d&#8217;appliquer des mesures de similarit&#233;
s&#233;mantique &#233;labor&#233;es entre toutes les relations extraites. Le tableau 2 illustre cependant le fait
que certaines variabilit&#233;s d&#8217;expression sont tr&#232;s limit&#233;es et peuvent &#234;tre d&#233;tect&#233;es facilement.
</p>
<p>Type de relation Clusters de base
</p>
<p>ORG &#8211; ORG create the, who create . . .establish the, who establish the . . .
</p>
<p>ORG &#8211; LOC base in, a company base in . . .locate in, which be locate in . . .
ORG &#8211; PER found by, a group found by, which be found by . . .
PER &#8211; ORG who be the head of, become head of . . .
PER &#8211; LOC work in, who work in . . .
PER &#8211; PER who call, who call his manager . . .
</p>
<p>TABLE 2 &#8211; Illustration de la variabilit&#233; linguistique des relations
</p>
<p>Cette observation nous a conduit &#224; mettre en &#339;uvre un premier niveau de clustering afin de
former des regroupements de relations proches les unes des autres sur le plan de leur expression
linguistique, comme le fait de regrouper create the et who create. Pour ce faire, nous nous sommes
appuy&#233;s sur une similarit&#233; Cosinus appliqu&#233;e &#224; une repr&#233;sentation de type sac de mots de la
partie Cmid des relations. Outre son compromis int&#233;ressant entre simplicit&#233; et efficacit&#233;, ce choix
a &#233;t&#233; motiv&#233; par la possibilit&#233; d&#8217;appliquer cette similarit&#233; aux larges ensembles de relations
extraites dans notre contexte par une utilisation de l&#8217;algorithme All Pairs Similarity Search (APSS)
(Bayardo et al., 2007). Moyennant la fixation a priori d&#8217;un seuil de similarit&#233; minimale, celui-ci
permet en effet de construire de fa&#231;on optimis&#233;e la matrice de similarit&#233; d&#8217;un ensemble de
vecteurs suivant la mesure Cosinus. Cette matrice &#233;tant calcul&#233;e et transform&#233;e en graphe de
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>356 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>similarit&#233;, nous appliquons ensuite l&#8217;algorithme Markov Clustering (Dongen, 2000) pour former
les regroupements de relations. Cet algorithme identifie les zones d&#8217;un graphe de similarit&#233;
les plus dens&#233;ment connect&#233;es en r&#233;alisant des marches al&#233;atoires dans ce graphe. Outre son
efficacit&#233;, il pr&#233;sente l&#8217;avantage, du point de vue de l&#8217;IE non supervis&#233;e, de ne pas n&#233;cessiter la
fixation pr&#233;alable d&#8217;un nombre de clusters.
</p>
<p>3.1.2 Pond&#233;ration des termes
</p>
<p>Si l&#8217;on consid&#232;re que tous les mots d&#8217;une phrase n&#8217;apportent pas la m&#234;me contribution au sens
g&#233;n&#233;ral de la phrase, il est n&#233;cessaire d&#8217;&#233;tablir une bonne strat&#233;gie de pond&#233;ration pour &#233;tablir
une bonne mesure de similarit&#233; entre phrases. Trois types de pond&#233;ration sont consid&#233;r&#233;s ici :
&#8211; pond&#233;ration binaire : tous les mots de Cmid ont le m&#234;me poids (1,0) ;
&#8211; pond&#233;ration tf-idf : un poids tf-idf est attribu&#233; &#224; chaque mot en prenant en compte la fr&#233;quence
du mot dans la relation et la fr&#233;quence inverse du mot dans l&#8217;ensemble des relations ;
</p>
<p>&#8211; pond&#233;ration grammaticale : des poids sp&#233;cifiques sont donn&#233;s aux mots en fonction de leur
cat&#233;gorie morpho-syntaxique.
</p>
<p>La pond&#233;ration binaire est la plus simple et forme une baseline, qui a &#233;t&#233; utilis&#233;e dans nos
premi&#232;res exp&#233;riences, en particulier en raison de l&#8217;efficacit&#233; de l&#8217;impl&#233;mentation de l&#8217;APSS avec
un poids binaire. La pond&#233;ration tf-idf prend en compte, par le biais du facteur idf, une mesure
de l&#8217;importance du terme dans le corpus. N&#233;anmoins, la fr&#233;quence des mots dans un corpus n&#8217;est
pas n&#233;cessairement corr&#233;l&#233;e &#224; leur r&#244;le dans la caract&#233;risation d&#8217;une relation. Par exemple, le
verbe buy peut &#234;tre fr&#233;quent dans un corpus de documents financiers, et donc avoir un poids
faible, mais n&#8217;en sera pas moins repr&#233;sentatif de la relation BUY(ORG-ORG). C&#8217;est pourquoi nous
avons d&#233;cid&#233; d&#8217;introduire une pond&#233;ration grammaticale.
</p>
<p>Classe Cat&#233;gories morpho-syntaxiques
A (w=1,0) VB VBD VBG VBN VBP VBZ NN NNS JJ JJR JJS IN TO RP
B (w=0,75) RB RBR RBS WDT WP WP$ WRB PDT POS PRP PRP$
C (w=0,5) NNP NNPS UH
D (w=0,0) SYM CC CD DT MD
</p>
<p>TABLE 3 &#8211; Pond&#233;ration grammaticale : distribution des poids selon la cat&#233;gorie morpho-syntaxique
</p>
<p>Une analyse des cat&#233;gories morpho-syntaxiques nous a amen&#233; &#224; les s&#233;parer en plusieurs classes
selon leur importance dans la contribution &#224; l&#8217;expression d&#8217;une relation. Plus pr&#233;cis&#233;ment, nous
consid&#233;rons quatre classes :
&#8211; (A) contribution directe, de poids &#233;lev&#233; : les mots de cette classe contribuent directement au
sens de la relation et incluent les verbes, noms, adjectifs et pr&#233;positions ;
</p>
<p>&#8211; (B) contribution indirecte, de poids moyen : les mots de la classe B ne sont pas directement
li&#233;s au sens de la relation mais sont pertinents dans l&#8217;expression de la phrase, comme les
adverbes et les pronoms ;
</p>
<p>&#8211; (C) information compl&#233;mentaire, de poids faible : cette classe contient des mots fournissant
une information compl&#233;mentaire sur la relation. C&#8217;est le cas des noms propres, qui sont souvent
discriminants d&#8217;un point de vue th&#233;matique mais ont plut&#244;t &#224; introduire des associations
inad&#233;quates sur le plan s&#233;mantique ;
</p>
<p>&#8211; (D) pas d&#8217;information, de poids nul : cette classe contient les mots vides que l&#8217;on veut ignorer
(symboles, nombres, d&#233;terminants etc.).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>357 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Nous pr&#233;sentons dans le tableau 3 une configuration de pond&#233;ration grammaticale. La liste
des cat&#233;gories morpho-syntaxiques est fond&#233;e sur les cat&#233;gories du Penn Treebank. Les poids
1,0, 0,75, 0,5 et 0 sont respectivement attribu&#233;s aux classes A, B, C, D. Pour les cat&#233;gories non
pr&#233;sentes dans cette liste, un poids par d&#233;faut de 0,5 est utilis&#233;. Compte tenu des probl&#232;mes
pos&#233;s par l&#8217;&#233;valuation de la t&#226;che consid&#233;r&#233;e (cf. section 4), ces poids n&#8217;ont pas fait l&#8217;objet d&#8217;une
optimisation telle qu&#8217;elle pourrait &#234;tre men&#233;e avec une proc&#233;dure de type validation crois&#233;e.
</p>
<p>3.1.3 Regroupement par mots-cl&#233;s repr&#233;sentatifs
</p>
<p>Pour renforcer ce premier niveau de clustering, la strat&#233;gie g&#233;n&#233;raliste pr&#233;sent&#233;e ci-dessus a &#233;t&#233;
compl&#233;t&#233;e par une heuristique tenant compte de la sp&#233;cificit&#233; des relations. Au sein d&#8217;un cluster
de base, la forme linguistique de ces derni&#232;res est souvent domin&#233;e par un verbe (founded pour a
group founded by ou which is founded by) ou par un nom (head pour who is the head of, becomes
head of), ce terme dominant poss&#233;dant une fr&#233;quence &#233;lev&#233;e dans le cluster. De ce fait, &#224; l&#8217;instar
de (Hasegawa et al., 2004), nous consid&#233;rons le nom ou le verbe le plus fr&#233;quent au sein d&#8217;un
cluster de base comme son repr&#233;sentant et nous fusionnons les clusters ayant le m&#234;me terme
dominant, appel&#233; mot-cl&#233; dans ce qui suit, pour former des clusters de base plus larges.
</p>
<p>3.2 Regroupement s&#233;mantique
</p>
<p>Le premier niveau de clustering ne peut clairement pas regrouper des relations exprim&#233;es avec
des termes compl&#232;tement diff&#233;rents. Dans l&#8217;exemple a company based in et which is located
in pr&#233;sent&#233; dans le tableau 2, les deux formes linguistiques ont peu en commun. Nous avons
donc consid&#233;r&#233; l&#8217;ajout d&#8217;un second niveau de clustering ayant pour objectif de regrouper les
clusters form&#233;s pr&#233;c&#233;demment sur des bases plus s&#233;mantiques, plus pr&#233;cis&#233;ment en int&#233;grant les
similarit&#233;s s&#233;mantiques au niveau lexical. Contrairement au premier, ce second niveau b&#233;n&#233;ficie
en outre du fait de travailler &#224; partir de clusters et non de relations individuelles, ce qui permet
d&#8217;exploiter une information plus riche. Il n&#233;cessite de ce fait de d&#233;finir trois niveaux de similarit&#233;
s&#233;mantique : similarit&#233; entre les mots, entre les relations et entre les clusters de base de relations.
</p>
<p>3.2.1 &#201;valuation de la similarit&#233; s&#233;mantique entre les mots
</p>
<p>Les mesures de similarit&#233; s&#233;mantique au niveau lexical se r&#233;partissent en deux grandes cat&#233;gories
aux caract&#233;ristiques souvent compl&#233;mentaires : la premi&#232;re rassemble les mesures fond&#233;es sur
des connaissances &#233;labor&#233;es manuellement prenant typiquement la forme de r&#233;seaux lexicaux de
type WordNet ; la seconde recouvre les mesures de nature distributionnelle, construites &#224; partir
de corpus. Pour &#233;valuer la similarit&#233; s&#233;mantique entre relations, nous avons choisi de tester des
mesures relevant de ces deux cat&#233;gories afin de juger de leur int&#233;r&#234;t respectif.
</p>
<p>Concernant le premier type de mesures, le fait de travailler avec des textes en anglais ouvre
le champ des diff&#233;rentes mesures d&#233;finies &#224; partir de WordNet. Nous en avons retenu deux
caract&#233;ristiques : la mesure de Wu et Palmer (Wu et Palmer, 1994), qui &#233;value la proximit&#233; de
deux synsets en fonction de leur profondeur dans la hi&#233;rarchie de WordNet et de la profondeur
de leur plus petit anc&#234;tre commun ; la mesure de Lin (Lin, 1998), qui associe le m&#234;me type de
crit&#232;re que la mesure de Wu et Palmer et des informations de fr&#233;quence d&#8217;usage des synsets
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>358 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>dans un corpus de r&#233;f&#233;rence. Ces mesures &#233;tant d&#233;finies entre synsets, pour se ramener &#224; une
mesure entre mots, nous avons adopt&#233; la strat&#233;gie utilis&#233;e notamment dans (Mihalcea et al.,
2006) consistant &#224; prendre comme valeur de similarit&#233; entre deux mots la plus forte valeur de
similarit&#233; entre les synsets dont ils font partie.
</p>
<p>Les mesures de similarit&#233; distributionnelles sont quant &#224; elles fond&#233;es sur l&#8217;hypoth&#232;se que
les mots apparaissant dans les m&#234;mes contextes tendent &#224; avoir le m&#234;me sens. La notion de
contexte renvoie ici &#224; l&#8217;ensemble des mots cooccurrant avec le mot cible dans un corpus. Cette
cooccurrence peut &#234;tre graphique, au sein d&#8217;une fen&#234;tre de taille fixe, ou bien reposer sur des
relations syntaxiques. Nous avons test&#233; ici les deux types de cooccurrents, les termes au sein des
contextes ainsi form&#233;s &#233;tant pond&#233;r&#233;s gr&#226;ce &#224; la mesure d&#8217;Information Mutuelle et les contextes
eux-m&#234;mes &#233;tant compar&#233;s gr&#226;ce &#224; la mesure Cosinus pour &#233;valuer la similarit&#233; de deux mots.
Ces choix r&#233;sultent d&#8217;un processus d&#8217;optimisation d&#233;crit dans (Ferret, 2010) dont nous avons
utilis&#233; les th&#233;saurus distributionnels pour disposer de ces similarit&#233;s sous une forme pr&#233;calcul&#233;e.
</p>
<p>Dans le cadre de la comparaison de relations, nous nous sommes int&#233;ress&#233;s essentiellement &#224; la
similarit&#233; s&#233;mantique entre des mots appartenant &#224; la m&#234;me cat&#233;gorie morpho-syntaxique en
nous fondant sur le fait que les relations extraites se d&#233;finissent g&#233;n&#233;ralement autour d&#8217;un verbe
(e.g. ORG found by PER, ORG establish by PER) ou d&#8217;un nom (e.g. ORG be partner of ORG, ORG
have cooperation with ORG ), mais pas sous les deux formes pour un m&#234;me type de relations,
sans doute &#224; cause de la focalisation sur la partie Cmid des relations.
</p>
<p>3.2.2 Similarit&#233; s&#233;mantique des relations
</p>
<p>La similarit&#233; s&#8217;applique ici &#224; l&#8217;&#233;chelle de la d&#233;finition linguistique des relations, i.e. leur partie
Cmid, ce qui s&#8217;apparente &#224; la probl&#233;matique de la d&#233;tection de paraphrases. De ce fait, nous avons
repris le principe exp&#233;riment&#233; dans (Mihalcea et al., 2006) pour cette t&#226;che : chaque phrase (ici
relation) &#224; comparer est repr&#233;sent&#233;e sous la forme d&#8217;un sac de mots et lors de l&#8217;&#233;valuation de la
similarit&#233; sim(Pa, Pb) d&#8217;une phrase Pb par rapport &#224; une phrase Pa, chaque mot de Pa est appari&#233;
au mot de Pb avec lequel sa similarit&#233; s&#233;mantique, au sens de la section 3.2.1, est la plus forte.
Ainsi, dans l&#8217;exemple ci-dessous, acquire est appari&#233; &#224; la seule possibilit&#233;, buy, tandis que part est
appari&#233; &#224; stake, avec lequel il partage la plus grande similarit&#233; selon la mesure de Wu-Palmer.
</p>
<p>!&quot;#!!&quot;#$%&amp;'(!&quot;!)&quot;'*!+,!!!!&quot;#-&quot;
</p>
<p>!&quot;#!!.%/!&quot;!0&amp;1+'&amp;*/!2*&quot;3(!&amp;1!!!&quot;#-.
</p>
<p>4567458 4599
</p>
<p>Un mot d&#8217;une phrase peut ne pas &#234;tre appari&#233; si sa similarit&#233; avec tous les autres mots de l&#8217;autre
phrase est nulle. Cette mesure de similarit&#233; n&#8217;&#233;tant pas sym&#233;trique, la similarit&#233; compl&#232;te est
&#233;gale &#224; la moyenne de sim(Pa, Pb) et sim(Pb, Pa). Plus formellement, avec :
</p>
<p>Pa = W1 : f1, W2 : f2, ... ,Wi : fi , ..., WM : fM
Pb = W1 : f1, W2 : f2, ... ,Wj : f j , ..., WN : fN
</p>
<p>o&#249; Wk est un mot d&#8217;une phrase et fk, sa fr&#233;quence dans la phrase, cette similarit&#233; s&#8217;&#233;crit :
</p>
<p>SPa,b =
1
2
(
</p>
<p>1&#65535;
i&#8712;[1,M] wi
</p>
<p>&#65535;
i&#8712;[1,M]
</p>
<p>max
j&#8712;[1,N]{SWi, j} &#183;wi +
</p>
<p>1&#65535;
j&#8712;[1,N] wj
</p>
<p>&#65535;
j&#8712;[1,N]
</p>
<p>max
i&#8712;[1,M]{SWi, j} &#183;wj) (1)
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>359 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>o&#249; SWi, j est la similarit&#233; s&#233;mantique entre les mots Wi et Wj , qu&#8217;elle soit fond&#233;e sur WordNet ou
sur un th&#233;saurus distributionnel et wi et wj sont les poids de ces mots respectivement dans Pa et
Pb, d&#233;finis par leur fr&#233;quence (wi = fi ,wj = f j).
</p>
<p>3.2.3 Similarit&#233; s&#233;mantique des clusters
</p>
<p>Le principe adopt&#233; pour la similarit&#233; de deux relations est trop co&#251;teux &#224; transposer &#224; l&#8217;&#233;chelle
des clusters car il n&#233;cessiterait, pour un cluster Ca de cardinalit&#233; A et un cluster Cb de cardinalit&#233;
B, de calculer A &#183; B similarit&#233;s, lesquelles ne peuvent pas &#234;tre pr&#233;calcul&#233;es comme pour les mots.
La similarit&#233; &#224; l&#8217;&#233;chelle des relations &#233;tant fond&#233;e sur une repr&#233;sentation de type sac de mots,
nous avons choisi de construire pour les clusters une repr&#233;sentation de m&#234;me type, obtenue
en fusionnant les repr&#233;sentations de leurs relations. Au sein de la repr&#233;sentation d&#8217;un cluster,
chaque mot se voit associer sa fr&#233;quence parmi les relations du cluster, les mots de plus fortes
fr&#233;quences &#233;tant suppos&#233;s les plus repr&#233;sentatifs du type de relation sous-jacent au cluster.
</p>
<p>Concernant l&#8217;&#233;valuation de la similarit&#233; entre les clusters, nous avons donc repris la d&#233;finition de
la similarit&#233; entre les relations mais avec une l&#233;g&#232;re adaptation destin&#233;e &#224; pallier le biais pouvant
&#234;tre induit par une trop grande diff&#233;rence d&#8217;effectifs entre les deux clusters. Ainsi, dans l&#8217;exemple
ci-dessous, les clusters Ca et Cb ne sont pas s&#233;mantiquement similaires mais leur similarit&#233; serait
&#233;lev&#233;e avec une mesure telle que SPa,b du fait du poids &#233;lev&#233; du mot actor dans Ca. M&#234;me si dans
un tel cas, sim(Pb, Pa) serait plus faible que sim(Pa, Pb), sim(Pb, Pa) influencerait fortement la
moyenne des deux et conduirait &#224; une similarit&#233; globale assez forte.
</p>
<p>Ca = found :3, actor :3 . . . {i.e. PER an actor who found ORG}
Cb = study :9, actor :1 . . . {i.e. PER study at ORG, PER an actor study at ORG}
</p>
<p>Pour contrecarrer cet effet, nous introduisons la fr&#233;quence des mots dans les deux clusters et non
dans celui servant de r&#233;f&#233;rence seulement, en rempla&#231;ant, dans l&#8217;&#233;quation (1), les poids wi et wj
par wi j , d&#233;fini par wi j = fi &#183; f j .
</p>
<p>3.2.4 Algorithme de clustering
</p>
<p>Pour la construction de nos clusters de base, nous avons fait appel &#224; l&#8217;association d&#8217;un seuillage
sur les valeurs de similarit&#233; entre relations au travers de l&#8217;utilisation de l&#8217;APSS et de l&#8217;algorithme
Markov Clustering. Le seuillage r&#233;alis&#233; conduit &#224; &#233;claircir le graphe de similarit&#233; et rend possible
l&#8217;application du Markov Clustering qui, en d&#233;pit de son efficacit&#233;, ne pourrait g&#233;rer la matrice
compl&#232;te de similarit&#233; des relations. Le cas du regroupement s&#233;mantique des clusters de base est
quelque peu diff&#233;rent. Dans le cas des relations, la taille des clusters &#224; former peut &#234;tre assez
variable selon le contenu du corpus consid&#233;r&#233; mais la valeur de similarit&#233; de deux relations est
assez facile &#224; &#233;talonner &#224; partir de r&#233;sultats de r&#233;f&#233;rence (cf. section 4.1 pour une illustration).
</p>
<p>Le cas du clustering s&#233;mantique est assez diff&#233;rent. Le fait d&#8217;utiliser des ressources de natures
assez diverses rend difficile la fixation a priori d&#8217;un seuil de similarit&#233; car les intervalles de
valeurs ne sont pas les m&#234;mes selon les cas. En revanche, la richesse des ressources s&#233;mantiques
utilis&#233;es permet d&#8217;avoir une id&#233;e approximative du nombre de voisins d&#8217;un cluster de base. Un tel
cluster se d&#233;finissant souvent autour d&#8217;un terme cl&#233;, ce nombre de voisins est assez directement
en rapport avec le nombre de synonymes ou de mots s&#233;mantiquement li&#233;s &#224; ce terme. De ce
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>360 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>fait, pour le clustering s&#233;mantique, nous avons adopt&#233; l&#8217;algorithme Shared Nearest Neighbor
(SNN) propos&#233; dans (Ert&#246;z et al., 2002) plut&#244;t que le Markov Clustering utilis&#233; initialement. Cet
algorithme d&#233;finit en effet implicitement la taille des clusters qu&#8217;il forme en seuillant le nombre
de voisins possibles pour chaque &#233;l&#233;ment &#224; regrouper1.
</p>
<p>4 &#201;valuation
</p>
<p>Nous avons men&#233; l&#8217;&#233;valuation de ce clustering de relations multi-niveau selon une approche
externe en utilisant les mesures standard de pr&#233;cision et rappel (combin&#233;s par la F-mesure). Ces
mesures sont appliqu&#233;es &#224; des paires de relations en consid&#233;rant que les relations peuvent &#234;tre
regroup&#233;es dans le m&#234;me cluster ou s&#233;par&#233;es dans des clusters diff&#233;rents et ce, de fa&#231;on correcte
ou incorrecte par rapport &#224; la r&#233;f&#233;rence. Nous utilisons &#233;galement les mesures standard pour
le clustering de puret&#233;, puret&#233; inverse and Information Mutuelle Normalis&#233;e (NMI) (Amig&#243; et al.,
2009) Le clustering de r&#233;f&#233;rence utilis&#233; a &#233;t&#233; construit manuellement &#224; partir d&#8217;un sous-ensemble
de relations provenant de l&#8217;extraction initiale. Il est form&#233; de 80 clusters couvrant 4 420 relations :
une douzaine de clusters sont construits pour chaque paire de types d&#8217;entit&#233;s en relation, avec
des tailles variant entre 4 et 280 relations. De plus amples d&#233;tails sur la construction de cette
r&#233;f&#233;rence et les mesures d&#8217;&#233;valuation utilis&#233;es sont donn&#233;s dans (Wang et al., 2012).
</p>
<p>4.1 &#201;valuation du clustering de base
</p>
<p>Le seuil de similarit&#233; utilis&#233; pour le clustering de base (utilis&#233; pour &#233;laguer la matrice de similarit&#233;
gr&#226;ce &#224; l&#8217;algorithme APSS) a &#233;t&#233; fix&#233; &#224; 0,45. Ce seuil a &#233;t&#233; choisi empiriquement en &#233;tudiant
le comportement de l&#8217;algorithme de clustering sur les phrases du corpus Microsoft Research
Paraphrase (Dolan et al., 2004) et couvre les trois quarts des valeurs de similarit&#233; de ses phrases
en &#233;tat de paraphrase. Pour la pond&#233;ration grammaticale, qui est moins stricte, un seuil de 0,60
est utilis&#233;. Les r&#233;sultats obtenus pour le clustering de base sont pr&#233;sent&#233;s dans le tableau 4.
</p>
<p>Pr&#233;c. Rappel F-score Pur. Pur. inv. NMI Nb Taille
binaire 0,756 0,312 0,442 0,902 0,407 0,750 15 833 7,50
tf-idf 0,203 0,445 0,279 0,646 0,573 0,722 11 911 11,44
</p>
<p>gramm. 0,810 0,402 0,537 0,963 0,513 0,812 13 648 7,56
mots-cl&#233;s 0,812 0,443 0,573 0,953 0,552 0,825 11 726 8,80
</p>
<p>TABLE 4 &#8211; R&#233;sultats du clustering de base pour plusieurs pond&#233;rations en utilisant le Markov
Clustering (MCL) et un premier regroupement par mots-cl&#233;s
</p>
<p>Le regroupement sur la base de la similarit&#233; utilisant une pond&#233;ration grammaticale donne les
meilleurs r&#233;sultats, avec une meilleure pr&#233;cision et un rappel satisfaisant. Cette pond&#233;ration
utilise en effet plus de connaissances pour mettre en &#233;vidence le r&#244;le des verbes, noms ou adjectifs
et diminuer l&#8217;influence des mots vides qui ne contribuent qu&#8217;&#224; des variations linguistiques l&#233;g&#232;res
(who + verbe, the one that + verbe). La pond&#233;ration tf-idf donne quant &#224; elle de moins bons
r&#233;sultats. Cette pond&#233;ration favorise en effet les mots rares. Or, les noms communs et les verbes,
</p>
<p>1Les hypoth&#232;ses faites sur l&#8217;ad&#233;quation entre le type d&#8217;&#233;l&#233;ments &#224; regrouper et les algorithmes de regroupement ont
&#233;t&#233; confirm&#233;es exp&#233;rimentalement : l&#8217;algorithme SNN donne de moins bons r&#233;sultats que le Markov Clustering pour le
premier niveau de clustering mais l&#8217;ordre s&#8217;inverse pour le clustering s&#233;mantique.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>361 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>qui supportent le plus souvent les relations, sont plus fr&#233;quents que des noms propres ou des
occurrences de nombres, par exemple, qui se verront attribuer un score important avec cette
pond&#233;ration alors qu&#8217;ils n&#8217;apportent pas d&#8217;information sur la relation.
</p>
<p>Les r&#233;sultats utilis&#233;s par la suite pour le clustering s&#233;mantique sont ceux obtenus avec la
pond&#233;ration grammaticale2, sur laquelle l&#8217;&#233;tape de regroupement par mots-cl&#233;s am&#232;ne une
am&#233;lioration l&#233;g&#232;re de la F-mesure, due &#224; un accroissement du rappel ; mais cette &#233;tape permet
surtout de r&#233;duire le nombre de clusters et d&#8217;augmenter leur taille moyenne, comme illustr&#233; par
les deux derni&#232;res colonnes du tableau 4.
</p>
<p>4.2 &#201;valuation du clustering s&#233;mantique
</p>
<p>Pour &#233;valuer l&#8217;am&#233;lioration apport&#233;e par le clustering s&#233;mantique, nous comparons les approches
propos&#233;es &#224; un clustering id&#233;al (id&#233;al) donnant le meilleur regroupement possible des clusters de
base obtenus par la premi&#232;re &#233;tape : chaque cluster de base est associ&#233; au cluster de r&#233;f&#233;rence
avec lequel il partage le plus de relations ; puis les clusters associ&#233;s aux m&#234;mes clusters de
r&#233;f&#233;rence sont regroup&#233;s.
</p>
<p>En pratique, pour les mesures fond&#233;es sur WordNet, la mesure de Wu-Palmer donne de bons
r&#233;sultats pour les similarit&#233;s entre noms alors que la mesure de Lin donne de meilleurs r&#233;sultats
pour les verbes. La premi&#232;re est calcul&#233;e gr&#226;ce &#224; NLTK (nltk.org) tandis que pour la seconde,
nous utilisons les similarit&#233;s pr&#233;calcul&#233;es entre les verbes de WordNet de (Pedersen, 2010). Les
similarit&#233;s distributionnelles sont quant &#224; elles &#233;valu&#233;es &#224; partir du corpus AQUAINT-2, sur la base
d&#8217;une mesure Cosinus entre des vecteurs de contexte obtenus soit avec une fen&#234;tre glissante de
taille 3 (Distcooc), soit en suivant les liens syntaxiques entre les mots (Dists yn). Pour l&#8217;algorithme
SNN, le voisinage de chaque instance de relation est limit&#233; aux 100 plus proches relations. Les
r&#233;sultats obtenus sont pr&#233;sent&#233;s dans le tableau 5.
</p>
<p>Pr&#233;c. Rappel F-score Pur. Pur. inv. NMI Nb Taille
WordNet 0,821 0,507 0,627 0,942 0,622 0,839 9 403 10,98
Distcooc 0,814 0,540 0,649 0,932 0,634 0,841 10 161 10,16
Dists yn 0,831 0,549 0,661 0,950 0,645 0,847 10 116 10,20
id&#233;al 0,847 0,788 0,816 0,957 0,831 0,899 13 468 7,66
</p>
<p>TABLE 5 &#8211; R&#233;sultats du clustering s&#233;mantique
</p>
<p>La similarit&#233; distributionnelle syntaxique donne les meilleurs r&#233;sultats, bien que comparables
&#224; deux de la similarit&#233; distributionnelle graphique. Les deux approches distributionnelles sont
meilleures pour cette t&#226;che que celle fond&#233;e sur WordNet, ce qui signifie que la m&#233;thode pourra
plus facilement &#234;tre adapt&#233;e &#224; d&#8217;autres langues. Compar&#233;s au clustering de base, toutes les
m&#233;thodes de clustering s&#233;mantique montrent une augmentation notable sur toutes les mesures
(le F-score passe de 57,3% &#224; 77,3%).
</p>
<p>Pour les similarit&#233;s WordNet, d&#8217;autres tests ont &#233;t&#233; effectu&#233;s pour v&#233;rifier l&#8217;importance relative
des diff&#233;rentes cat&#233;gories grammaticales dans ce regroupement. Par exemple, si l&#8217;on ne consid&#232;re
que les verbes, les r&#233;sultats sont un peu inf&#233;rieurs, en particulier en termes de rappel. Nous avons
</p>
<p>2Plusieurs seuils et configurations de pond&#233;rations grammaticales ont &#233;t&#233; test&#233;s. La version pr&#233;sent&#233;e (seuil de 0,60 et
poids donn&#233;s dans le tableau 3) est celle donnant les meilleurs r&#233;sultats.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>362 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&#233;galement exp&#233;riment&#233; l&#8217;int&#233;gration des adjectifs dans la mesure de similarit&#233;, mais les r&#233;sultats
ont montr&#233; que ces mots n&#8217;ont pas d&#8217;influence notable sur le regroupement des relations. D&#8217;autres
tests int&#233;grant des mesures de similarit&#233;s entre mots de cat&#233;gories grammaticales diff&#233;rentes ont
&#233;t&#233; effectu&#233;s, sans apporter d&#8217;am&#233;lioration.
</p>
<p>Exemples de clusters s&#233;mantiques Pour donner une id&#233;e qualitative des r&#233;sultats du cluste-
ring s&#233;mantique, nous pr&#233;sentons quelques exemples de clusters s&#233;mantiques, cr&#233;&#233;s en utilisant
la mesure Distcooc . Un exemple de cluster s&#233;mantique obtenu pour chaque type de relation est
pr&#233;sent&#233; dans le tableau 6, o&#249; chaque mot repr&#233;sente un cluster. Il est clair avec ces exemples
que des mots diff&#233;rents mais s&#233;mantiquement similaires sont regroup&#233;s. N&#233;anmoins, des erreurs
subsistent : le fait de ne pas diff&#233;rencier les voies active et passive conduit ainsi &#224; certaines erreurs
de regroupement pour les relations entre des entit&#233;s de m&#234;me type (par exemple, purchase et be
purchased by pour des relations ORG &#8211; ORG).
</p>
<p>Type de relation Clustering s&#233;mantique
ORG &#8211; ORG purchase, buy, acquire, trade, own, be purchased by
ORG &#8211; LOC start in, inaugurate service to, open in, initiate flights to
ORG &#8211; PER sign, hire, employ, interview, rehire, receive, affiliate
PER &#8211; ORG take over, take control of
PER &#8211; LOC grab gold in, win the race at, reign
PER &#8211; PER win over, defeat, beat, oust, topple, defend
</p>
<p>TABLE 6 &#8211; Exemples de mots regroup&#233;s dans les clusters s&#233;mantiques
</p>
<p>4.3 &#201;tude des avantages du clustering multi-niveau
</p>
<p>Comme indiqu&#233; au d&#233;but de la section 3.1, le calcul des similarit&#233;s s&#233;mantiques est beaucoup plus
co&#251;teux que le calcul d&#8217;une simple mesure Cosinus. Le nombre total de relations atteint 165 708
(cf. tableau 1), alors que le nombre de clusters de base n&#8217;est que de 11 726 (cf. tableau 4). Un
premier avantage du clustering multi-niveau est donc d&#8217;&#233;viter de calculer un trop grand nombre
de similarit&#233;s co&#251;teuses. Mais, parall&#232;lement, il permet &#233;galement d&#8217;am&#233;liorer la qualit&#233; de
l&#8217;organisation s&#233;mantique des relations, en exploitant la redondance d&#8217;information pr&#233;sente dans
les clusters de base. Pour v&#233;rifier cette hypoth&#232;se, nous avons compar&#233;, en nous appuyant sur
notre r&#233;f&#233;rence, la distribution des similarit&#233;s entre les relations initiales et entre les clusters de
base. Dans un premier temps, nous avons examin&#233; toutes les similarit&#233;s entre deux instances
de relations appartenant au m&#234;me cluster de r&#233;f&#233;rence (distribution intra-cluster Dintra) et les
similarit&#233;s entre deux instances appartenant &#224; des clusters diff&#233;rents (distribution intra-cluster
Dinter), avec l&#8217;hypoth&#232;se que ces distributions sont bien s&#233;par&#233;es (avec une moyenne &#233;lev&#233;e pour
Dintra et basse pour Dinter). Dans un second temps, nous &#233;tablissons les m&#234;mes distributions
de similarit&#233;s pour les clusters de base, en associant &#224; chaque cluster de r&#233;f&#233;rence l&#8217;ensemble
des clusters de base qu&#8217;il recouvre. Les distributions de similarit&#233; obtenues sont pr&#233;sent&#233;es &#224; la
figure 2 pour la similarit&#233; Distcooc , la m&#234;me tendance &#233;tant observ&#233;e pour les autres similarit&#233;s.
</p>
<p>On voit clairement sur ces figures que le clustering s&#233;mantique effectu&#233; &#224; partir des clusters de
base peut obtenir de meilleurs r&#233;sultats parce que les distributions de similarit&#233; &#224; l&#8217;int&#233;rieur des
clusters de r&#233;f&#233;rence ou entre clusters sont mieux s&#233;par&#233;es et que la moyenne des similarit&#233;s pour
des relations entre des clusters diff&#233;rents est relativement basse. Ceci confirme notre hypoth&#232;se
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>363 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>FIGURE 2 &#8211; Distribution des similarit&#233;s entre les relations et entre les clusters de base
</p>
<p>que l&#8217;information redondante dans les clusters de base peut &#234;tre utilis&#233;e pour diminuer le bruit
caus&#233; par les mots non repr&#233;sentatifs de la relation.
</p>
<p>5 Travaux li&#233;s au clustering s&#233;mantique de relations
</p>
<p>Le clustering de relations occupe des positions diverses dans le domaine de l&#8217;EI non supervis&#233;e.
En premier lieu, il est absent des travaux se concentrant essentiellement sur la d&#233;couverte et
l&#8217;extraction de relations, &#224; l&#8217;instar du syst&#232;me TEXTRUNNER dans lequel les relations extraites sont
directement index&#233;es pour &#234;tre interrog&#233;es. Dans la plupart des autres travaux, la finalit&#233; du
clustering de relations peut &#234;tre qualifi&#233;e de s&#233;mantique dans la mesure o&#249; son objectif est de
regrouper des relations &#233;quivalentes, cette &#233;quivalence &#233;tant situ&#233;e plus ou moins explicitement
sur le plan s&#233;mantique. Enfin, quelques travaux plus marginaux, &#224; l&#8217;image de (Sekine, 2006),
int&#232;grent &#233;galement une dimension plus th&#233;matique dans les regroupements r&#233;alis&#233;s.
</p>
<p>M&#234;me lorsque le clustering de relations poss&#232;de une vocation s&#233;mantique, les moyens pour le
mettre en &#339;uvre ne sont pas n&#233;cessairement eux-m&#234;mes s&#233;mantiques. &#192; l&#8217;image de notre premier
niveau de clustering, (Hasegawa et al., 2004) retrouve ainsi des variations s&#233;mantiques comme
(offer to buy &#8211; acquisition of) au sein des clusters de relations entre entit&#233;s nomm&#233;es qu&#8217;il forme
en appliquant une simple mesure Cosinus au contexte imm&#233;diat de ces relations. (Sekine, 2006)
va quant &#224; lui un peu plus loin en exploitant un ensemble de paraphrases constitu&#233; a priori sur
la base de cooccurrences d&#8217;entit&#233;s nomm&#233;es pour faciliter l&#8217;appariement de phrases issues de
plusieurs articles journalistiques relatant un m&#234;me &#233;v&#233;nement. Concernant toujours l&#8217;&#233;valuation
de la similarit&#233; entre les relations, (Eichler et al., 2008) s&#8217;appuie pour sa part sur WordNet pour
d&#233;tecter les relations de synonymie entre verbes. La d&#233;marche se rapproche d&#8217;une partie de ce
que nous avons exp&#233;riment&#233;, m&#234;me si nous avons &#233;galement inclus les noms dans notre champ
d&#8217;&#233;tude, car ceux-ci sont dominants pour exprimer certaines relations, que nous avons appliqu&#233;
cette recherche au niveau des clusters de base, et non des relations individuelles, et qu&#8217;avec les
similarit&#233;s distributionnelles, nous ne sommes pas restreints aux seules relations de synonymie.
</p>
<p>La notion de clustering multiple appara&#238;t quant &#224; elle dans quelques travaux. (Kok et Domingos,
2008) propose ainsi de construire un r&#233;seau de relations s&#233;mantiques de haut niveau &#224; partir
des r&#233;sultats du syst&#232;me TEXTRUNNER gr&#226;ce &#224; une m&#233;thode de co-clustering engendrant simulta-
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>364 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>n&#233;ment des classes d&#8217;arguments et des classes de relations. (Min et al., 2012) fait quant &#224; lui
appara&#238;tre deux niveaux de clustering mais avec une optique plus proche de (Kok et Domingos,
2008) que de la n&#244;tre. Son premier niveau de clustering porte en effet sur les arguments des
relations tandis que le second se focalise sur les relations proprement dites. L&#8217;objectif du premier
niveau de clustering est ainsi de regrouper des relations ayant la m&#234;me expression et de trou-
ver des arguments &#233;quivalents tandis que le second niveau de clustering vise &#224; regrouper des
relations ayant des expressions similaires en s&#8217;appuyant notamment sur les classes d&#8217;arguments
d&#233;gag&#233;es par le premier clustering. Ce dernier exploite un vaste graphe de relations de similarit&#233;
et d&#8217;hyperonymie entre entit&#233;s construit automatiquement &#224; la fois sur la base de similarit&#233;s
distributionnelles et de patrons lexico-syntaxiques. S&#8217;y ajoute pour le second niveau de clustering
une large base de paraphrases elle aussi construite automatiquement &#224; partir de corpus.
</p>
<p>Conclusion et perspectives
</p>
<p>Nous avons pr&#233;sent&#233; dans cet article une m&#233;thode de clustering &#224; plusieurs niveaux pour
regrouper des relations extraites dans un contexte d&#8217;EI non supervis&#233;e. Une premi&#232;re &#233;tape
est appliqu&#233;e pour regrouper des relations ayant des expressions linguistiques proches de
fa&#231;on efficace et avec une bonne pr&#233;cision. Une seconde &#233;tape permet d&#8217;am&#233;liorer ce premier
regroupement en utilisant des mesures de similarit&#233; s&#233;mantique plus riches afin de rassembler
les clusters d&#233;j&#224; form&#233;s et augmenter le rappel. Nos exp&#233;riences montrent que dans ce contexte,
des mesures de similarit&#233; distributionnelle donnent des r&#233;sultats plus stables que des mesures
fond&#233;es sur WordNet. Une analyse des distributions des similarit&#233;s entre les relations initiales et
entre les clusters de premier niveau met &#233;galement en &#233;vidence l&#8217;int&#233;r&#234;t d&#8217;un clustering &#224; deux
niveaux. Parmi les perspectives envisag&#233;es, nous envisageons d&#8217;exploiter le contexte des relations,
que ce soit de fa&#231;on locale au niveau de la phrase au travers des parties Cpre et Cpost ou plus
globalement en prenant en compte les contextes th&#233;matiques des relations pour am&#233;liorer le
regroupement des relations et pouvoir les pr&#233;senter de fa&#231;on plus pertinente &#224; un utilisateur.
</p>
<p>R&#233;f&#233;rences
</p>
<p>AKBIK, A. et BROSS, J. (2009). Extracting semantic relations from natural language text using
dependency grammar patterns. In SemSearch 2009 workshop of WWW 2009.
AMIG&#211;, E., GONZALO, J., ARTILES, J. et VERDEJO, F. (2009). A comparison of extrinsic clustering
evaluation metrics based on formal constraints. Information Retrieval, 12(4):461&#8211;486.
BANKO, M., CAFARELLA, M. J., SODERLAND, S., BROADHEAD, M. et ETZIONI, O. (2007). Open
information extraction from the web. In IJCAI&#8217;07, pages 2670&#8211;2676.
BAYARDO, R. J., MA, Y. et SRIKANT, R. (2007). Scaling up all pairs similarity search. In WWW&#8217;07,
pages 131&#8211;140.
CHEN, J., JI, D., TAN, C. et NIU, Z. (2005). Unsupervised feature selection for relation extraction.
In IJCNLP-2005, pages 262&#8211;267.
CHEU, E., KEONGG, C. et ZHOU, Z. (2004). On the two-level hybrid clustering algorithm. In
International conference on artificial intelligence in science and technology, pages 138&#8211;142.
DOLAN, B., QUIRK, C. et BROCKETT, C. (2004). Unsupervised construction of large paraphrase
corpora : exploiting massively parallel news sources. In COLING&#8217;04.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>365 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>DONGEN, S. V. (2000). Graph Clustering by Flow Simulation. Th&#232;se de doctorat, University of
Utrecht.
EICHLER, K., HEMSEN, H. et NEUMANN, G. (2008). Unsupervised relation extraction from web
documents. In LREC&#8217;08.
ERT&#214;Z, L., STEINBACH, M. et KUMAR, V. (2002). A new shared nearest neighbor clustering
algorithm and its applications. In Workshop on Clustering High Dimensional Data and its
Applications of SIAM ICDM 2002.
FADER, A., SODERLAND, S. et ETZIONI, O. (2011). Identifying relations for open information
extraction. In EMNLP&#8217;11, pages 1535&#8211;1545.
FERRET, O. (2010). Testing semantic similarity measures for extracting synonyms from a corpus.
In LREC&#8217;10.
GAMALLO, P., GARCIA, M. et FERN&#193;NDEZ-LANZA, S. (2012). Dependency-based open information
extraction. In Joint Workshop on Unsupervised and Semi-Supervised Learning in NLP.
GRISHMAN, R. et MIN, B. (2010). New York University KBP 2010 Slot-Filling System. In Text
Analysis Conference (TAC). NIST.
HASEGAWA, T., SEKINE, S. et GRISHMAN, R. (2004). Discovering relations among named entities
from large corpora. In ACL&#8217;04.
KOK, S. et DOMINGOS, P. (2008). Extracting Semantic Networks from Text Via Relational
Clustering. In ECML PKDD&#8217;08, pages 624&#8211;639.
LIN, D. (1998). An information-theoretic definition of similarity. In ICML&#8217;98, pages 296&#8211;304.
MIHALCEA, R., CORLEY, C. et STRAPPARAVA, C. (2006). Corpus-based and knowledge-based
measures of text semantic similarity. In AAAI&#8217;06, pages 775&#8211;780.
MIN, B., SHI, S., GRISHMAN, R. et LIN, C.-Y. (2012). Ensemble semantics for large-scale unsuper-
vised relation extraction. In EMNLP&#8217;12, pages 1027&#8211;1037.
MINTZ, M., BILLS, S., SNOW, R. et JURAFSKY, D. (2009). Distant supervision for relation extraction
without labeled data. In ACL-IJCNLP 2009, pages 1003&#8211;1011.
PEDERSEN, T. (2010). Information content measures of semantic similarity perform better
without sense-tagged text. In HLT-NAACL&#8217;10, pages 329&#8211;332.
RINK, B. et HARABAGIU, S. (2011). A generative model for unsupervised discovery of relations
and argument classes from clinical texts. In EMNLP&#8217;11, pages 519&#8211;528.
ROZENFELD, B. et FELDMAN, R. (2006). High-performance unsupervised relation extraction from
large corpora. In ICDM&#8217;06, pages 1032&#8211;1037.
SEKINE, S. (2006). On-demand information extraction. In COLING-ACL&#8217;06, pages 731&#8211;738.
SHINYAMA, Y. et SEKINE, S. (2006). Preemptive information extraction using unrestricted relation
discovery. In HLT-NAACL&#8217;06, pages 304&#8211;311.
WANG, W., BESAN&#199;ON, R., FERRET, O. et GRAU, B. (2011). Filtering and clustering relations for
unsupervised information extraction in open domain. In CIKM 2011, pages 1405&#8211;1414.
WANG, W., BESAN&#199;ON, R., FERRET, O. et GRAU, B. (2012). Evaluation of unsupervised information
extraction. In LREC&#8217;12.
WU, Z. et PALMER, M. (1994). Verbs semantics and lexical selection. In ACL&#8217;94, pages 133&#8211;138.
YAO, L., HAGHIGHI, A., RIEDEL, S. et MCCALLUM, A. (2011). Structured relation discovery using
generative models. In EMNLP&#8217;11, pages 1456&#8211;1466.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>366 c&#65535; ATALA</p>

</div></div>
</body></html>