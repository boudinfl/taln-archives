TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Fouille de r‘egles d’annotation partielles
pour la reconnaissance des entités nommées

Damien Nouvel 1: 2 Jean-Yves Antoine 1 Natha1ie.Friburger 1
Arnaud.Soulet 1
(1) LI, 3 place Jean Jaurés, 41000 Blois
(2) Alpage, INRIA 8: Université Paris-Diderot, 75013 Paris
{prenom . nom}@univ—tours . fr

RESUME
Ces dernieres décennies, l’accroissement des volumes de données a rendu disponible une diversité
toujours plus importante de types de contenus échangés (texte, image, audio, vidéo, SMS, tweet,
données statistiques, spatiales, etc.). En conséquence, de nouvelles problématiques ont vu le
jour, dont la recherche d’information au sein de données potentiellement bruitées. Dans cet
article, nous nous penchons sur la reconnaissance d’entités nommées au sein de transcriptions
(manuelles ou automatiques) d’émissions radiodiffusées et télévisuelles. A cet effet, nous mettons
en oeuvre une approche originale par fouille de données aﬁn d’extraire des motifs, que nous
nommons regles d’annotation. Au sein d’un modele, ces regles réalisent l’annotation automatique
de transcriptions. Dans le cadre de la campagne d’évaluation Etape, nous mettons a l’épreuve
le systéme implémenté, mXS, étudions les régles extraites et rapportons les performances du
systeme. Il obtient de bonnes performances, en particulier lorsque les transcriptions sont bruitées.

ABSTRACT
Mining Partial Annotation Rules for Named Entity Recognition

During the last decades, the unremitting increase of numeric data available has led to a more
and more urgent need for efﬁcient solution of information retrieval (IR). This paper concerns a
problematic of first importance for the IR on linguistic data : the recognition of named entities
(NE) on speech transcripts issued from radio or TV broadcasts. We present an original approach for
named entity recognition which is based on data mining techniques. More precisely, we propose to
adapt hierarchical sequence mining techniques to extract automatically from annotated corpora
intelligible rules of NE detection. This research was carried out in the framework of the Etape NER
evaluation campaign, where mXS, our text—mining based system has shown good performances
challenging the best symbolic or data—driven systems

MOTS-CLES : Entités nommées, Fouille de données, Regles d’annotation.

KEYWORDS: Named Entities, Data Mining, Annotation Rules.

421 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
1 Introduction

Ces dernieres décennies, le développement considérable des technologies de l’information et de la
communication a modiﬁé la maniére dont nous accédons et manipulons les connaissances. Nous
constatons une diversité toujours plus importante des types de contenus échangés (texte, image,
audio, vidéo, SMS, tweet, données statistiques, spatiales, etc.), ce qui nécessite de résoudre
de nombreuses problématiques, parmi lesquelles la recherche d’information, qui a intéressé la
communauté du TALN dés les années 90 avec les campagnes d’évaluation MUC (Grishman et
Sundheim, 1996). Les travaux sur le sujet ont porté une attention particuliére aux noms propres
de personnes, de lieux et d’organisations, appelés entités nommées (EN). Au gré des besoins,
celles—ci ont été étendues aux dates, aux expressions numériques, aux marques ou aux fonctions,
avant de recouvrir un large spectre d’expressions linguistiques.

De nombreux systemes ont été élaborés pour réaliser la reconnaissance d’enu'tés nommées (REN),
selon des approches orientées connaissances ou orientées données. Les premieres ont générale-
ment une grande précision mais nécessitent un coup humain de développement important, ce
qui se traduit généralement par une couverture (et donc un rappel) perfectible. Les approches
orientées données, par ajustement automatique de paramétres d’un modéle numérique, per-
mettent d’obtenir de bonnes performances, avec un coup d’entrée limité, du moment on l’on
dispose d’une base d’apprentissage de taille sufﬁsante. Ils sont également réputés présenter une
dégradation graduelle de leurs performances sur des données bruitées. Cependant, l’aspect “boite
noire” des algorithmes d’apprentissage rend difﬁcile 1’amélioration ciblée de leurs performances.

Ces constats ont été vériﬁés par de nombreuses campagnes d’évaluation. A titre d’exemp1e, lors
de la campagne d’évaluau'on francophone Ester2 (Galliano et al., 2009), portant sur le traitement
de transcriptions de parole radio ou télédiffusée, les deux meilleurs systémes travaillant sur
des transcriptions manuelles étaient des systémes a base de connaissance, tandis que les tests
effectués sur des sorties de reconnaissance de la parole ont été dominés par un systéme orienté
données.

Les travaux que nous présentons dans cet article ont été menés dans le cadre de la campagne

Etape (qui a fait suite 2‘: Ester2) qui visait notamment a évaluer des systémes de REN sur des ﬂux

de parole conversationnelle. Nous y proposons une approche novatrice pour la REN : l’utilisau'on

de méthodes de fouille de données séquentielle hiérarchique. A nos yeux, ces travaux présentent
plusieurs originalités du point de vue du TALN :

(i) nous élaborons un moyen—terme entre les approches orientées données et orientées connais-
sances reposant sur la recherche, a partir de données d’apprentissage, de motifs pour la REN :
cette technique centrée données permet l’extraction de connaissances interprétables;

(ii) la stratégie de détection des entités nommées est originale, par la recherche séparée du
début et de la ﬁn des entités, en nous appuyant sur le contexte immédiat pour placer les balises
d’annotation : cela présente l’intérét de conserver une certaine robustesse en cas de disﬂuence
ou d’erreur de reconnaissance au sein de l’entité nommée.

Cet article porte sur l’élaborau'on, l’implémentau'on et l’évaluation d’une telle approche. En partie
2, nous faisons un état de 1’art des approches pour la REN. La partie 3 présente le formalisme de
fouille pour l’extraction de régles d’annotation et leur utilisation pour reconnaitre des entités
nommées. En partie 4, nous décrivons le jeu de données utilisé et les résultats obtenus lors de
l’évaluation dans le cadre de la campagne Etape.

422 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
2 Approches pour la reconnaissance d’EN structurées

2.1 Approches orientées connaissances

Les approches orientées connaissances sont basées sur la description de regles décrivant les
entités nommées et leur contexte a l’aide d’indices linguistiques fournis par le texte lui—méme et
des ressources externes (dictionnaires). Généralement, les textes sont étiquetés syntaxiquement
(éventuellement sémantiquement) grace aux dictionnaires, puis un ensemble de regles, qui
prennent en compte les indices morphologiques (présence de majuscule, ponctuation), morpho-
syntaxiques et sémantique, permettent de repérer les ENs. Les régles utilisent ces éléments, soit
comme preuves internes de la présence d’une entité nommée, soit par description de son contexte
d’apparition (McDonald, 1996; Friburger et Maurel, 2004). Une preuve interne sera, par exemple,
la présence d’un prénom avant un mot commencant par une majuscule; ce prénom indiquera un
nom de personne (ex : ’Francois Hollande’). Nous voyons que c’est la “connaissance” qui guide
cette approche, celle de l’expert qui créé les régles, selon les informations a sa disposition (dont
les ressources extemes).

Des les années 1990, un certain nombre de systémes (Stephens, 1993; Hobbs J. R. et Tyson, 1996)
mettent en oeuvre cette approche orientée connaissances. Les automates sont particulierement
adaptés a l’élaboration et l’uti1isation des regles. De plus, 1’uti1isation de transducteurs 1 permet
de produire tres intuitivement une annotation a l’aide de balises (‘<pers>’, ‘</pers>’, ‘<org>’,
‘</org>’, etc.), ils sont donc largement utilisés pour ce type de tache (Friburger et Maurel, 2004;
Brun et Ehrmann, 2010; Béchet et al., 2011). Enﬁn, les transducteurs peuvent étre organisés
sous forme de cascades, chaque transducteur permettant de lever des ambiguités et de mettre a
disposition des reconnaissances pour les transducteurs suivants (ce qui permet de reconnaitre des
imbrications). L’ordre dans lequel sont appliqués les transducteurs a alors une grande importance.

Etant donné les traitements qu’elles mettent en oeuvre, les approches orientées connaissances
insérent au sein des séquences de mots ce que nous appelons des marqueurs, comme le montre la
ﬁgure 1 pour l’expression ‘fondation Cartier’.

     

   

(<P9TS>) (</pers>)

FIGURE 1 — Annotation par balises

Les approches orientées connaissances peuvent étre utilisées et adaptées a des textes sans
apprentissage préalable. Leur limitation est liée au fait que les ressources utilisées sont rarement
exhaustives (par exemple, les noms propres forment une classe “ouverte”) : il semble illusoire de
batir ce type d’approche sur l’hypothése d’un lexique complet des entités nommées existantes.

1. Automates qui modiﬁent le texte fourni en entrée par insertion de balises

423 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
2.2 Approches orientées données

Les approches orientées données parametrent un modele automatiquement grace a un apprenu's—
sage sur un corpus d’entrainement. Ce corpus d’entrainement, créé par des experts, fournit de
nombreux exemples de données : le systéme apprend sur ces exemples puis prédit l’étiquette
d’une nouvelle donnée, selon son modele. Le corpus d’entrainement est constitué d’un ensemble
de textes annotés en entités nommées par des experts. L’apprentissage automatique sera chargé
d’ajuster les paramétres disponibles, cette procédure étant guidée a chaque itération par les
erreurs que commet le systéme sur les jeux de données disponibles. Une fois l’apprentissage
réalisé, le systéme est en mesure d’annoter de nouveaux textes en entités nommées selon les
parametres de son modele. Traditionnellement, l’apprentissage automatique se rapproche plutot
d’une classiﬁcation (attribution d’une classe a un mot) que d’une annotation (délimitation d’une
expression linguistique).

Pour la REN, le format BIO 2 s’est imposé. La ﬁgure 2 présente la classiﬁcation par mots réalisée
pour l’énoncé ‘<org> fondation <pers> Cartier </pers> </org>’. Signalons qu’en partie
3, nous présentons une approche orientée donnée, mais qui est apparentée a un mécanisme de
transduction (a l’aide d’indices locaux) plutot que de classiﬁcation.

 

FIGURE 2 — Annotation par classiﬁcation

Généralement, ces approches estiment la probabilité des classes selon les tokens et les informa-
tions qui y sont associées. Parmi les modeles numériques adaptés, ﬁgurent les modeles bayésiens,
la régression logistique (ou maximum d’entropie), les machines a vecteur de support (SVM) ,
etc. La régression logistique a démontré son efﬁcacité pour la reconnaissance d’entités nommées
(Mikheev et al., 1999; Ekbala et al., 2010), permettant de prendre en compte de multiples
traits discriminants (morphologiques, morpho—syntaxiques, lexicaux) interdépendants. D’autres
modéles tirent parti de la séquentialité, comme les HMM (Bikel et al., 1999), par modélisation
des transitions entre états (types d’entités nommées) et des générations d’observations (mots).

Pour prendre en compte simultanément la multiplicité des indices locaux et les aspects séquentiels
au sein d’un modéle uniﬁé, les MEMM3 (McCallum et al., 2000) puis les CRF4 (Raymond
et Fayolle, 2010; Zidouni et al., 2010) sont les modéles réputés les plus adéquats a ce jour.
L’inconvénient est qu’ils restent difﬁciles a interpréter : les traits découverts sont généralement
composites et exhibent des dépendances complexes dont il est difﬁcile d’afﬁrmer qu’elles sont
nécessaires ou sufﬁsantes pour déterminer les entités nommées.

A ce jour, les approches orientées données se basent majoritairement sur une représentation
“plate” des entités nommées. Comme nous le verrons en partie 4, nous cherchons a réaliser la

2. Begin, Inside, Outside
3. Modéles markoviens a maximum d’entropie
4. Champs aléatoires conditionnels

424 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

REN structurée (avec imbrications). Notons que quelques travaux (Finkel et Manning, 2005;
Dinarelli et Rosset, 2011) ont adapté avec un certain succes des méthodes orientées données a la
reconnaissance de structure.

De maniére générale, nous remarquons que les approches automatiques nécessitent un travail
préalable conséquent (préparation des jeux de données, implémentation du modele, des procé—
dures d’apprentissage et d’estimation, sélection des traits et dépendances pertinents, etc.) avant
d’étre en mesure de paramétrer les modeles, et qu’il reste difﬁcile de les utiliser pour extraire des
connaissances ou pour étudier des phénomenes particuliers.

2.3 Proposition : les marqueurs d’annotation

Nous le voyons, les approches guidées par les données s’appuient sur des indices locaux variés.
La nature “locale” de la structuration en entités nommées est alors un atout. Les systémes
orientés connaissances ont l’avantage de modéliser la structure interne des entités nommées.
Ainsi un systeme a base de connaissances aura plus de facilité a analyser l’encapsulation d’entités
nommées comme dans l’exemple suivant (issu d’Etape) : ‘le députe’ UMP de Haute—Sa6ne’ ou
l’entité nommée globale est construite a l’aide de l’entité ‘UMP’, de type organisation, et de l’entité
‘Haute—Sa6ne’, de type division géographique administrative.

Cependant, ces derniéres approches utilisent une connaissance dont la construction est coﬁteuse et
délicate. Aussi avons—nous souhaité développer une approche permettant l’extraction automatique
sur corpus de motifs se rapprochant des régles de reconnaissance mises en oeuvre par la REN
symbolique. La fouille hiérarchique séquentielle de données est adéquate a cet effet.

Par ailleurs, les systémes orientés connaissances sont aujourd’hui contraints a modéliser inté-
gralement la structure des entités, voire de ses contextes d’introduction. Ce choix est discutable
et met a l’épreuve la robustesse des systémes lorsqu’ils traitent de la parole spontanée. Une
erreur de reconnaissance sur un seul mot de l’entité (due par exemple a une disﬂuence) empéche
l’application de la regle de détection.

Aﬁn de répondre a cette insufﬁsance, nous proposons de séparer la détection du début et de
la fin de l’entité, pour ensuite chercher a associer une marque de début et de ﬁn d’entité. Notre
hypothese est que l’on dispose de sufﬁsamment d’indices locaux pour caractériser précisément 1e
début ou la ﬁn d’une entité.

Considérons pas exemple l’énoncé annoté suivant ‘En <date> <num> 1969 </num> </date>
<pers> <prenom> Georges </prenom> <famille> Pompidou </famille> </pers> dirige la
<org> <loc> France </loc> </org>’. Notre hypothese est que chacune des marques d’annota-
tion (‘<pers>’, ‘<prenom>’, ‘</prenom>’, ‘</pers>’, etc.) est détectable séparément. De plus,
la détection d’une entité encapsulée telle que ‘<prenom>’ peut guider la détection de l’entité
englobante. I1 s’agira, pour le systéme, d’extraire des régles d’annotation, d’estimer1ocalement
les marqueurs probables, puis de déterminer, par leurs combinaisons, l’annotation la plus vrai—
semblable. Nous implémentons un systéme de reconnaissance d’entités nommées, mXS, selon
cette approche originale. Grace a ce procédé, notre systéme reconnait par exemple le montant
‘deux cent ca compte mille’ (erreur de transcription pour deux cent cinquante mille), alors qu’un
systeme symbolique sera mis en difﬁculté.

425 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
3 Extraction de régles d’annotation pour la REN

3.1 Enrichissement ambigu des données

axe paradigmatique

Sémantique

4

I
Morpho-syntaxe

Lemmatisation

Tokenisation

Pierre

 

FIGURE 3 — Représentation des structures a fouiller

L’approche que nous mettons en oeuvre repose sur des analyses fréquemment conduites pour
traiter le langage naturel (morpho—syntaxe, lexiques). Pour la fouille, ces traitements sont
interprétés comme autant d’enrichissements des données, a utiliser pour rechercher des motifs
généralisés dans les données. La ﬁgure 3 présente de maniére schématique, sur l’exemple ‘Pierre
a visite' le Centre Georges Pompidou’, la maniére dont se superposent ces enrichissements.

La fouille de données devra alors tenir compte de deux axes : paradigmatique, pour la superposi-
tion d’enrichissements, et structurel, pour l’examen des contigiiités entre items. Comme nous le
verrons par la suite, ce processus est ﬂexible : les enrichissements peuvent étre plus ou moins
profonds selon les e’1e’ments considérés. Nous pouvons moduler a Volonté l’axe paradigmatique
selon les éléments observés et la tache d’annotation a réaliser.

3.1. 1 Morpho-syntaxe

Nous réalisons conjointement la tokenisation, la lemmatisation et l’étiquetage morpho-syntaxique
avec TreeTagger (Schmid, 1994). De surcroit, nous en adaptons la sortie comme suit :

Déterminants : les déterminants déﬁnis (‘le’, ‘la’, ‘les’, ‘l”) sont sous-catégorisés en ‘DET/DEF’.
Prépositions : la sous—catégorie ‘PRP:det ’ (‘au’, ‘du’, ‘des’) forme une catégorie ‘PRPDET’.
Nombres : les nombres sont sous-catégorisés selon leur nombre de chiffres 5.

Noms propres et abréviations : ces deux catégories se généralisent en ‘ NAMABR’.

Nom propres, abréviations, noms, verbes : ces éléments sont sous-catégorisés par le sufﬁxe
des trois derniers caractéres (‘NOM/SUFF: ier ’, ‘1\IAMABR/NAM/ SUFF:ges ’, ‘VER/SU'FF:vre ’).
— Verbes : les sous—catégories relatives au mode et temps du verbe sont supprimées.

Pour le processus de fouille de données, nous omettons les Variations surfaciques (majuscules)
et ﬂexionnelles (déclinaisons et conjugaisons) : nous ne conservons pas les items lexicaux eux—
mémes et faisons reposer la recherche de motifs sur les lemmes proposés par TreeTagger. Par
exemple, le ‘En 1970 les socialistes [...]’ donnera la séquence :

‘ PRP/en NUM/DIGITS : 4/PREF: 19/1970 DET/DEF/le NOM/SUFF : ste/socialiste ’.

5. Ce nombre est précisé s’il est inférieur ou égal z‘1 quatre le préﬁxe est utilisé dans ce dernier cas :
‘N'U'M/DIGITS:MAN'Y’, ‘NUM/DIGITS:4/PREF:20’ ..., ‘NUM/DIGITS: 1’)

426 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

3.1.2 Lexiques

Les lexiques nous permettent d’ajouter un niveau sémantique aux hiérarchies. Nous exploitons
des ressources diverses, dont certaines sont importées a partir des dictionnaires et motifs du
systeme CasEN6. Nous y ajoutons quelques listes, constituées manuellement, en particulier
pour les fonctions, lieux, organisations, quantités et dates. Ces ressources contiennent 221
547 expressions distinctes qui produisent 443 112 catégorisations sémantiques 7. Une large
part est dédiée a la reconnaissance des personnes et des lieux. Signalons qu’une partie de
ces ressources est générée a partir d’automates (transducteurs CasEN) qui reconnaissent des
expressions linguistiques utiles a la REN.

Ces ressources sont utilisées telles quelles pour produire les enrichissements. Ceux—ci peuvent
alors étre sémantiquement ambigus, ce que nous notons comme une disjonction exclusive
€B. Par exemple, au nom propre Washington seront affectées les catégories sémantiques
‘CELEBEBTOP0€BORG—LOC—GOVQBPRENEBVILLE’. Notons ici que nous considérons que les noms
propres forment une classe ouverte et qu’i1s n’ont pas vocation a étre utilisés lexicalisés au
sein des motifs extraits : lorsqu’i1s ont donné lieu a des enrichissements sémantiques, les items
lexicaux sont omis aﬁn que la fouille de données ne repose que sur les catégories sémantiques.

3.2 Exploration de régles d’annotation de segments

Les données ainsi enrichies forment le langage .9, et ont vocation a étre fouillées aﬁn d’y
rechercher des motifs séquentiels d’intérét (Fischer et al., 2005; Cellier et Charnois, 2010) pour
la REN.

Le langage des motifs $p+ comprend celui des données enrichies et toutes leurs généralisa—
tions. Un élément de motif (item) couvre une donnée, notée 50,-, lorsqu’il s’y trouve en tenant
compte des disjonctions €B. Par exemple, l’item ‘TOPO/Washington’ couvre la donnée enrichie
‘CELEB/Washington€BTOP0/Washington’. Des lors, nous nous inspirons de travaux intégrant
des hiérarchies aux séquences (Srikant et Agrawal, 1996), en y ajoutant la notion de segments
particulierement adaptée au traitement de structures au sein desquelles des items se répetent
(comme des syntagmes sémantiquement catégorisés).

Couverture d’un motif de segments sur des données : soient un motif de segments P =
p1p2...p,, E .2, et une séquence de la base de données enrichie I = i1i2...i1, E $,,+, alors P
couvre les segments de 1, noté P 30+ I , s’il existe une fonction discrete croissante S() déﬁnie de
[1,p] vers [1, n] telle que, pour tout j E [1,p], alors pj sci ism

Ce meme mécanisme sera pris en compte lorsqu’il s’agit de généraliser selon l’axe paradigmatique :
l’objectif est que, par exemple, ‘CELEB’ couvre indifféremment ‘Pompidou’ et ‘Valery Giscard
d’Estaing’. Plus généralement, nous déﬁnissons trois relations de généralisation entre motifs :

— Généralisation hiérarchique entre motifs de segments : soient deux motifs de segments
P = p1p2...p,, E .2’1,+ et Q = qlqz . . .qp E $,,+, alors P généralise hiérarehiquement les segments
de Q, noté P ﬁg Q, s’il existe une une fonction discrete croissante S() déﬁnie de [1, p] vers
[1, n] telle que, pour toutj E [1,p], alors pj Sci qso-).

6. http ://tln. Zi. univ-tours.fr/'I'ln_CasEN. html
7. Il est fréquent que plusieurs catégories sémantiques soient associées aux entrées
8. Pour respecter l’anti-monotonie, deux items contigus ne peuvent étre identiques ou parents l’un de l’autre

427 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

— Généralisation par affixation entre motifs : soient deux motifs P = p1p2...p,, E .%’,,+ et
Q = qlqz . . .qp E $,,+, alors P ge’ne’ralise par aﬂixation Q, noté P ﬁg Q, si p Z n et s’il existe au
moins un k E [0,p — n] tel que, pour tout j E [1, n], alors q,-+k = pj.

— Généralisation sur marqueurs entre motifs : soient deux motifs P = p1p2...p,, E .2’1,+ et
Q = q1q2...q1, E $1,+, alors P généralise sur marqueurs Q, noté P ﬁg Q, si p Z n et s’il existe
une fonction discrete strictement croissante C () déﬁnie de [1, n] vers [1, p] telle que, pour tout
j E [1, n], alors pi = qw) et, pour tout k E [1,p] tel que k ¢ {C(j),j E [1, n]}, alors qk 6 Elm.

Ces généralisations nous permettent de rechercher des motifs dans lesquels apparaissent les
marqueurs d’entités nommées. Par exemple, au sein de l’énoncé ‘Le <fonc> président </fonc>
<pers> Georges Pompidou </pers> débattait souvent.’, nous relevons, par relations de couverture
et de généralisation, une occurrence pour les motifs ‘NOM/président <pers> CELEB </pers>’
ou ‘NOM/président CELEB </pers> VERB/débattre’, par exemple.

Finalement, La notion de regle d’annotation partielle découle de celle de motif de segments :

Régle d’annotation partielle une regle d’annotation partielle est un motif de segments P E .2’1,+
contenant au moins un élément de 2], et un élément de Em.

Notons qu’a ce stade les regles d’annotation contiennent un nombre indéterminé de marqueurs.
I1 conviendra de ﬁltrer au besoin lors de l’extraction des motifs et de s’assurer que l’on utilise ces
regles de maniere adéquate aﬁn de produire une annotation.

3.3 Filtrage et extraction de régles d’annotations partielles

La combinatoire du langage .$’p+ étant importante, il est nécessaire de ﬁltrer les regles. Pour cela,
nous déterminons la fréquence et la conﬁance des régles, afin d’éliminer celles qui n’ont que peu
d’intérét. A l’aide de la couverture et des généralisations déﬁnies ci-dessus, nous déterminons la
fréquence Freq(P, 9) d’une régle P comme son nombre d’occurrences au sein du corpus 9. La
conﬁance d’une régle d’annotation P estime la proportion de phrases ou la régle est appliquée
avec justesse :

Conf(P, 9) = Freq(P’ 9)

T 1 f ' R P ' 1 d P
Freq(Retm(P),9) (a onction et,,,( )ret1re es marqueurs e )

Meme en ﬁxant des seuils de support et conﬁance sélectifs, les regles d’annotation peuvent étre
trop nombreuses a cause des combinaisons possibles au travers de la hiérarchie. Aﬁn de contenir
cette abondance de regles, nous proposons de grouper les regles, puis d’éliminer celles qui ne sont
pas informatives, a l’instar de (Pasquier et al., 1999). L’idée forte est que deux motifs qui couvrent
les memes exemples sont redondants car ils appartiennent a la meme classe d’équivalence :

Equivalence de motifs au regard d’une base de données : soient P et Q deux motifs et 9 une
base de données, alors P est équivalent 61 Q au regard de 9, notée P E9 Q, si P ﬁg Q ou Q ﬁg P
et Freq(P, 9) = Freq(Q, 9)

Dans la suite, plutot que d’extraire toutes les regles d’une méme classe d’équivalence, nous nous
contentrerons des motifs les plus spéciﬁques car ils sont porteurs de plus de corrélations. Par
ailleurs, nous étendons cette équivalence par une marge de tolérance lors de la comparaison des
fréquences a 5%, ce que nous appellons alors ﬁltrage 5.

428 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
3.4 Annotation automatique a partir des régles d’annotation

Les regles d’annotation sont utilisées par mXS pour réaliser l’annotation en entités nommées.
Pour une position j d’un texte, de nombreuses regles peuvent proposer des marqueurs. Nous
estimons la probabilité d’insérer des marqueurs en Mj (transductions) par régression logistique,
ce qui nous permet de tenir compte de la multiplicité des régles P E .99? selon la formule :

Ptm e M,-I9’,-) = fl, -expzmj, Am

Dans une annotation (et plus particuliérement si elle est structurée), plusieurs marqueurs peuvent
se trouver a une position donnée. I1 nous faut étre en mesure de faire le lien entre la probabilité
d’insérer un marqueur individuel et celle d’insérer une séquence de marqueurs. Pour cela, nous
tenons compte des statistiques issues du corpus sous forme de probabilités conditionnelles 9 :

1 p

‘ ' Z P(mk E Mkl3”k)P(m1---mplmk)

P k=1

Lorsque les probabilités de séquences de marqueurs P(M,-) sont estimées, nous les utilisons aﬁn
de déterminer quelle est, pour un énoncé donné, l’annotation la plus vraisemblable parmi les
annotations valides. Une hypothese d’indépendance entre marqueurs au sein d’un énoncé nous
permet de résoudre la recherche de l’annotation par programmation dynamique.

P(MJ- = m1m2...mp) =

4 Expériences sur le corpus Etape

4. 1 Données

Corpus Sources(nombre de ﬁchiers) Tokens Enoncés EN
Etape—Train BFMTV (5), France Inter (16), LCP (23) 355 975 14 989 46 259
Etape—Dev BFMTV (1), France Inter (6), LCP(6), TV8 (2) 115 530 5 724 14 112
Etape—Test BFMTV (1), France Inter (6), LCP (5), TV8 (2) 123 221 6 770 13 055
| Total | 74 enregistrements | 594 726 | 27 483 | 73 426 |
Etape—Quaero France Classique (1), France Culture (1), France 1 596 427 43 828 279 797
Inter (62), France Info (13), RFI (14), RTM (97)

TABLE 1 — Caractéristiques du corpus Etape

Le travail a été réalisé dans le contexte de la campagne d’évaluau'on Etape 1°, en interaction avec
le programme Quaero 11. Cette campagne a porté sur le traitement d’émissions radiodiffusées et
télévisuelles, donc orales et en partie spontanées. L’objectif est d’annoter les entités nommées
structurées, tant sur les transcriptions manuelles qu’en sortie de systemes de reconnaissance
de la parole. La table 1 indique les parties a disposition. Le corpus Etape—Test étant en
cours d’adjudication, nous ne 1’uti1isons pas pour mener nos expériences. Etape-Quaero 12
est volumineux et reste difﬁcile a exploiter par la fouille. En conséquence, nous n’utilisons que
Etape—Train (extraction des régles et paramétrage du modéle) et Etape—Dev (évaluation).

9. Ces probabilités sont normalisées a posteriori
10. Evaluations en 'I‘raitement Automatique de la Parole (201 1-2012)
11. http : //www . quaero . org (2008-2013)
12. Adaptation du corpus Ester au format Etape

429 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Les types principaux d’entités nommées sont les personnes (pers)), fonctions (f onc), organisa-
tions (org), lieux (loc), productions humaines (prod), points dans le temps (time), quantités
(amount) et évenements (event). A granularité ﬁne (sur laquelle est réalisée l’évaluation), ils
sont répartis en 34 sous-types. La ﬁgure 4 indique leur répartition au sein du corpus Etape.
Notons que les entités nommées sont étendues a des expressions construites a partir de noms
communs, ce qui améne a considérer une large gamme d’expressions linguistiques.

   

(a) Etape-'I‘rain (b) Etape-Dev (c) Etape-Test
FIGURE 4 — Répartition des types principaux d’entités

En plus des entités nommées, leurs composants sont annotés, soit spéciﬁques a certains types
(jour, mois, etc. pour une date) ou transverses (valeur, unité, qualiﬁcateur, etc.). Ces éléments
permettent de mieux décrire les entités lors de leur annotation (Rosset et al., 2011).

Le nombre d’entités nommées rapporté au nombre de tokens du corpus est de 12,3%, dont 4,8%
pour les entités et 7,5% pour les composants. Globalement, ce corpus, quoiqu’assez volumineux,
est bien équilibré pour les types principaux d’entités et de composants. Notons que nous réalisons
l’explorau'on des données sur un corpus qui contient des disﬂuences, répétitions, etc.

4.2 Extraction de régles d’annotation

Pour implémenter la fouille de données, nous construisons un arbre des préﬁxes communs
par niveaux, le processus est optimisé en exploitant la propriété d’anti—monotonie (Agrawal et
Srikant, 1995) et les hiérarchies (Wang et Han, 2004). De plus, nous poussons deux contraintes
supplémentaires pour l’extraction des régles d’annotation :

— Nombre de marqueurs : une régle d’annotation partielle ne contient qu’un marqueur.
— Niveaux : le nombre d’itérations de l’algorithme par niveaux est limité a 7.

L’approche que nous adoptons nous permet d’explorer exhaustivement les motifs fréquents et
conﬁants. Les seuils minimaux sont ﬁxés a 3 en fréquence et 5% en conﬁance. Le systéme extrait
alors 143 205 régles d’annotation parﬁelles 13. La ﬁgure 5 montre que la longueur des régles varie
autour de trois éléments, et leur profondeur d’items 14 se situe autour de quatre. Ces statistiques
conﬁrment que les regles d’annotation sont explorées sur les deux axes que nous avons déﬁnis.
Nous voyons aussi que la répartition des régles d’annotation par types d’EN est diversement
corrélée au corpus. Les types time et amount sont moins représentés : il y a moins de descripteurs
pour ces types, il pourrait alors étre assez homogéne dans les données. Inversement, le type
prod, est sur—représenté et nous faisons l’hypothése qu’il est assez hétérogéne.

13. En 15 minutes, sur un seul coeur, en consommant 1,5Go de RAM
14. Somme sur les items des spécialisations au dela de la racine

430 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

     

  
   

 

-104 4 -104
I 100 5 F I 100 5 F
5 I30SF<100 I30SF<100
I35F<30 3 I35F<30
4
2 == 2
z
2 | | 1 | I
0 — . _. 0 |III-_____
2 4 6 0 5 10 15
(a) Longueur des regles (b) Profondeur des regles (C) 'I‘ypes d’entités des regles

FIGURE 5 — Caractéristjques des régles d’annotation extraites

4.3 Reconnaissance d’entités nommées

Nous utilisons 1’outi1scikit—leam 15 (Pedregosa et al., 2011) pour réaliser la régression logistique.
La ﬁgure 6 présente les résultats obtenus en SER 16 et les taux par types d’erreurs (Galibert et al.,
2011). Ces graphiques conﬁrment que le systéme réduit graduellement ses erreurs 2‘1 mesure que
les seuils de fréquence et de conﬁance sont abaissés.

 

100 100
—F 2 21 : Insertions
80 ----F Z 42 80 . ---- Délétion
' ~ ' F 2 63 9 — — — Substitutions
:3
m 60 -v vFZ84 E, 60
LL] ' 5)
m 40 E 40 -
3 
E ‘ ______________________ __
20 20
. { 
0 0 '
80 60 40 20 80 60 40 20
C C
(a) Performances (b) Erreurs, F 2 21

FIGURE 6 — Performances (SER) et erreurs selon la Fréquence (F) et la Conﬁance (C)

Nous menons des expériences supplémentaires , dont les résultats sont reportés dans le tableau 2
pour les conﬁgurations suivantes :

— Logit : systéme par défaut

— Logit—Dicos : désactivation des ressources lexicales

— Logit+Test : apprentissage en fusionnant les corpus Etape—Train et Etape—Dev
— Logit—D25 : ﬁltrage 5 a 25%,

— Logit—D50 : ﬁltrage 5 a 50%,

— Logit—D75 : ﬁltrage 5 2‘: 75%,

15. http : //scikit — learn . org
16. Slot Error Rate, taux d’erreur pondéré

431 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Le systeme donne des résultats satisfaisants, étant donné la difﬁculté de la tache. Sans surprise, la
désactivation des dictionnaires dégrade considérablement les performances. Lorsque les données
comportent les données d’évaluation (Logit+Te st), le surapprentissage est modéré, ce qui est
lié au fait que les régles d’annotation ne sont pas lexicalisées. Les expériences Logit—DXX nous
montrent clairement que le systéme obtient encore des performances trés acceptables lorsque
l’on réduit signiﬁcativement le nombre de régles extraites a l’aide du ﬁltrage 5 .

| Approche | Régles | SER | I | D | S | P | R | Fm
| Logit | 143 205 | 35,9 | 5,6 | 24,2 | 10,8 | 79,8 | 64,9 | 71,6
Logit —Dicos 80 231 45,2 5,9 30,2 16,3 70,7 53,5 60,9
Logit+Test 141 550 26,3 3,2 18,6 8,1 86,6 73,3 79,4
Logit—D25 100 027 36,2 5,6 24,6 10,9 79,7 64,6 71,3
Logit—D50 73 332 36,7 5,4 25,2 11,0 79,5 63,8 70,8
Logit—D75 50 408 39,0 5,4 27,0 11,7 78,2 61,3 68,7

TABLE 2 — Performances (SER), erreurs d’Insertion (I), de Délétion (D), de Substitution (S),
Précision (P), Rappel (R), F—mesure (Fm) des approches

Nous menons des évaluations séparées des types primaires (sans sous-types) d’entités nommées
et de composants. La ﬁgure 7 en donne les résultats. Les entités nommées sont moins bien
reconnues que les composants et plusieurs types (en particulier les expressions de temps) posent
encore probléme. Ceci dit, le systéme équilibre relativement bien sa précision et son rappel et la
reconnaissance d’entités nommées selon l’approche présentée donne des résultats.

100
80

|'I'ypes |SER|P|R|Fm| 60
Entités 38,9 76,4 62,3 68,6 40
Composants 33,0 86,4 68,5 76,4 20
| Tous | 35,9 | 79,8 | 64,9 | 71,6 | o

Prod ‘*'vou..,%o Ive We 0% 

FIGURE 7 — SER, précision (gauche) et rappel (droite) par types primaires et composants

La phase d’adjudication de la campagne d’évaluation ETAPE n’est pas achevée a l’heure de
la rédaction de cet article. Nous avons cependant été autorisés a reporter en table 3 les per-
formances anonymes des systémes avant adjudication. Les SER présentés sont donnés sur les
transcriptions manuelles et sur les sorties de différents systemes de reconnaissance, pour lesquels
sont mentjonnés les WER 17.

Parmi les autres systémes participants, le systéme 3 utilise des CRF (binarisés, un par type), le
systéme 6/ 7/8 utilise un CRF pour les composants et un PCFG pour reconstituer les entités,
CasEN utilise des transducteurs. De maniere générale, mXS afﬁche de bonnes performances (entre
la 1 ére et la 3 éme position). Les taux d’erreurs élevés sont liés a la difﬁculté de la tache (parole
spontanée, imbrications, typologie ﬁne). Sans surprise, les performances sont dégradées sur
les données bruitées par la reconnaissance de parole. Nous voyons que mXS et résiste bien aux
erreurs de reconnaissance de la parole.

17. Word Error Rate
432 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Part. Type Man Rover WER23 WER24 WER25 WER30 WER35
1 OC 84.8 98,1 100,7 94,2 98,9 98,4 1 00,9
2 0C 172.0 147,4 178,8 160,4 168,0 163,9 168,2
3 CRF 33.8 57,2 59,3 64,7 62,0 61,7 71,8
4 OC 55.6 88,0 98,8 76,8 92,8 94,9 99,6
5 CRF 43.6 69,7 73,8 72,1 73,7 74,8 86,0
6 CRF+PCFG na 79,2 79,5 66,8 80,8 80,0 87,0
7 CRF+PCFG na 67,8 68,4 67,6 70,9 69,9 85,2
8 CRF+PCFG 36.4 na na na na na na
9 CRF 62.8 75,8 79,2 76,9 79,8 80,5 90,5
10 OC 42.9 65,0 69,9 66,3 70,5 69,9 87,0
CasEN OC 49.3 na na 68,4 na na na
mXS Régles 41 .0 63,7 67,5 64, 1 69,1 68,6 80,4

TABLE 3 — SER de la campagne Etape par systeme (OC=Orienté Connaissances) sur les transcrip-
tions avant adjudication (manuel : Man, transcription automatiques : Rover et WERXX, dont
WER24 avec majuscules)

5 Conclusion

La reconnaissance d’enu'tés nommées structurées sur de la parole spontanée nécessite de mettre
au point des systemes robustes. Dans cet article, nous présentons une approche originale a base
de fouille de données, qui extrait des régles d’annotation partielles et paramétre un modéle
numérique les utilisant.

Les résultats obtenus dans le cadre de la campagne Etape indiquent que notre approche novatrice
fait jeu égal avec les systemes état de l’art. Pour éviter tout biais méthodologique, nous restons
toutefois en attente d’une référence débarrassée de toute erreur d’annotation : c’est l’objectif de
la phase d’adjudicau'on en cours. Notre objectif a court terme est de mieux caractériser les points
forts et limitations du modéle (détection séparée du début et de la ﬁn des annotations). Nous
comptons également mettre a l’épreuve le systeme sur d’autres taches qui pourraient bénéﬁcier
de 1’extraction de motifs de segments.

Remerciements

Ces travaux ont été réalisés dans le cadre du projet ANR Etape. Merci en particulier a Olivier
Galibert (LNE), Matthieu Carré (ELDA) et Guillaume Gravier (IRISA).

Références

AGRAWAL, R. et SRIKANT, R. (1995). Mining sequential patterns. In International Conference on Data
Engineering (ICDE’95), pages 3-14.

BIKEL, D., SCHWARTZ, R. et WEISCHEDEL, R. M. (1999). An algorithm that learns what’s in a name. Machine
Learning, 34:211-231.

BRUN, C. et EHRMANN, M. (2010). Un systéme de détection d’entités nommées adapté pour la campagne
d’évaluation ester 2. In Traitement Automatique du Langage Naturel (TALN’10).

BECHET, E, SAGOT, B. et STERN, R. (2011). Coopération de méthodes statistiques et symboliques pour
l’adaptation non-supervisée d’un systéme d’étiquetage en entités nommées. In Traitement Automatique des
Langues Naturelles (TALN’1 1).

433 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

CELLIER, P et CHARNo1s, T. (2010). Fouille de données séquentielles d’itemsets pour l’apprentissage de
patrons linguistiques. In Traitement Automatique des Langues Naturelles (TALN’1 0).

DINARELLI, M. et RossET, S. (2011). Models cascade for tree-structured named entity detection. In
International Joint Conference on Natural Language Processing (IJCNLP’1 1).

EKBALA, A., SOURJIKOVA, E., FRANK, A. et PoNzETTo, S. P. (2010). Assessing the challenge of ﬁne-grained
named entity recognition and classiﬁcation. In Annual Meeting of the Association for Computational
Linguistics (ACL’10) - Named Entities Workshop, pages 93-101, Uppsala, Sweden.

FINKEL, J. R. et MANNING, C. D. (2005). Nested named entity recognition. In Conference on Empirical
Methods in Natural Language Processing (EMNLP’09).

FISCHER, J., HEUN, V et KRAMER, S. (2005). Fast frequent string mining using sufﬁx arrays. In 5th IEEE
International Conference on Data Mining (ICDM’05), pages 609-612.

FRIBURGER, N. et MAUREL, D. (2004). Finite-state transducer cascades to extract named entities in texts.
Theoretical Computer Sciences (T CS), 313293-104.

GALIBERT, 0., ROSSET, S., GRoU1N, C., ZWEIGENBAUM, P. et QUINTARD, L. (2011). Structured and extended
named entity evaluation in automatic speech transcriptions. In International Joint Conference on Natural
Language Processing (LICNLP’1 1).

GALLIANO, S., GRAVIER, G. et CHAUBARD, L. (2009). The ester 2 evaluation campaign for the rich transcription
of french radio broadcasts. In International Speech Communication Association (INTERSPEECH’09).
GR1sHMAN, R. et SUNDHEIM, B. (1996). Message undersrtanding conference - 6 : A brief history. In
International Conference on Computational Linguistics (COL1NG’96), pages 466-471, Copenhagen, Denmark.
HOBBS J. R., Appelt D., B. J. I. D. K. M. S. M. et TYsoN, M. (1996). FASTUS :A Cascaded Finite-State
Transducer for Extracting Information from Natural-Language Text, pages 383-406.

MCCALLUM, A., FREITAG, D. et PEREIRA, F. (2000). Maximum entropy markov models for information
extraction and segmentation. In International Conference on Machine Learning (ICME00), pages 591-598.
MCDONALD, D. D. (1996). Internal and External Evidence in the Identification and Semantic Categorisation
of Proper Names, pages 32-43.

MIKHEEV, A., MOENS, M. et GROVER, C. (1999). Named entity recognition without gazetteers. In Proc. of
the Ninth Conference of the European Chapter of the Association for Computational Linguistics, pages 1-8.
PASQUIER, N., BASTIDE, Y., TAoU1L, R. et LAKHAL, L. (1999). Efﬁcient mining of association rules using closed
itemset lattices. INE SYST, 24(1):25-46.

PEDREGOSA, F., VAROQUAUX, G., GRAMFORT, A., MICHEL, V, TH1R1oN, B., GRISEL, 0., BLONDEL, M., PR1-:rr1-:N-
HOFER, P, W1-:1ss, R., DUBOURG, V, VANDERPLAS, J., PAssos, A., COURNAPEAU, D., BRUCHER, M., P1~:RRoT, M.
et Edouard DUCHESNAY (201 1). Scikit-learn : Machine leaming in python. Journal of Machine Learning
Research, 12:2825—2830.

RAYMOND, C. et FAYOLLE, J. (2010). Reconnaissance robuste d’entités nommées sur de la parole transcrite
automatiquement. In Traitement Automatique des Langues Naturelles (TALN’1 0).

ROSSET, S., GROUIN, C. et ZWEIGENBAUM, E (2011). Entité nommées structurées : guide d’annotation quaero.
Rapport technique, LIMSI (2011-04).

SCHMID, H. (1994). Probabilistic pos tagging using decision trees. In New Meth. in Lang. Proc. (NEMLP’94).
SRIKANT, R. et AGRAWAL, R. (1996). Mining sequential patterns : Generalizations and performance
improvements. In International Conference on Extending Database Technology (EDBT’96), pages 3-17.
STEPHENS, C. S. (1993). The analysis and acquisition of proper names for the understanding of free text.
Computers and the Humanities, 26:441-456.

WANG, J. et HAN, J. (2004). Bide : Efﬁcient mining of frequent closed sequences. In International Conference
on Data Engineering (ICDE’04).

ZIDOUNI, A., ROSSET, S. et GLOTIN, H. (2010). Efﬁcient combined approach for named entity recognition in
spoken language. In Conference of the International Speech Communication Association (INT ERSPEECH’1 0).

434 © ATALA

