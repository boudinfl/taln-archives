TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Un cadre d’apprentissage intégralement discriminant pour la
traduction statistique

Thomas Lavergne1’2 Alexandre Allauzen1:2 Francois Yvon1’2
(1) Université Paris Sud 91 405 Orsay
(2) LIMSI/CNRS rue John von Neuman 91 405 Orsay
{lavergne , allauzen , yvon}<01imsi . fr

RESUME
Une faiblesse des systémes de traduction statistiques est le caractére ad hoc du processus d’ap-
prentissage, qui repose sur un empilement d’heuristiques et conduit a apprendre des paramétres
dont la Valeur est sous—optimale. Dans ce travail, nous reformulons la traduction automatique
sous la forme familiére de l’apprentissage d’un modele probabiliste structuré utilisant une pa-
ramétrisation log—linéaire. Cette entreprise est rendue possible par le développement d’une
implantation efﬁcace qui permet en particulier de prendre en compte la présence de Variables
latentes dans le modéle. Notre approche est comparée, avec succés, avec une approche de l’état
de l’art sur la tache de traduction de données du BTEC pour le couple Francais-Anglais.

ABSTRACT
A fully discriminative training framework for Statistical Machine Translation

A major pitfall of existing statistical machine translation systems is their lack of a proper training
procedure. In fact, the phrase extraction and scoring processes that underlie the construction of
the translation model typically rely on a chain of crude heuristics, a situation deemed problematic
by many. In this paper, we recast machine translation in the familiar terms of a probabilistic
structure learning problem, using a standard log-linear parameterization. The tractability of
this enterprise is achieved through an efﬁcient implementation that can take into account all
the aspects of the underlying translation process through latent variables. We also address the
reference reachability issue by using oracle decoding techniques. This approach is experimentally
contrasted with a state-of-the-art system on the French-English BTEC translation task.

MOTS-CLES : Traduction Automatique, Apprentissage Discriminant.

KEYWORDS: Machine Translation, Discriminative Learning.

1 Introduction

L’objectif d’un systéme de traduction statistique (STS) consiste a calculer, pour toute phrase
en langue source s, la traduction t* qui lui est la plus probablement associée. Ce résultat est
typiquement obtenu en maximisant une fonction de score <I>9(s, t), paramétrisée par le Vecteur
0, sur l’ensemble de toutes les traductions possibles de s. Un choix raisonnable pour <I> est la
probabilité conditionnelle de t sachant s p9(t I s).

Etant donnée la taille des espaces d’entrée et de sortie sur lesquels de tels modéles probabilistes
450 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

doivent étre déﬁnis, un modéle pour t sachant s doit étre décomposé en modélisant la traduction
par une séquence d’étapes de dérivation. Dans les systemes a base de segments (phrase—based
systems) (Zens et al., 2002; Koehn et al., 2003), qui seront considérés dans cette étude, ces
étapes de dérivation correspondent a des décisions qui portent (a) sur la délimitation des unités
de traduction en langue source, (b) sur le choix d’un équivalent de traduction pour chaque unité
déﬁnie en (a) ; enﬁn sur l’ordre relatif dans lequel sont réarrangées (on dira réordonnées) les
unités cibles sélectionnées en (b). Dans la mesure ou l’apprentissage se fonde uniquement sur
l’observation des paires (s, t), ces dérivations ne sont pas observées pendant l’apprentissage et
doivent étre incorporées sous la forme de variables latentes.

Chacune de ces étapes de dérivation doit étre modélisée et associée a un paramétre numé—
rique, qui est réglé de facon a ce que le systéme résultant engendre les meilleures traductions
possibles. Ainsi, dans les systémes a base de segments, chaque unité de traduction source est
nantie d’un ensemble de parametres qui valuent les différentes alternatives de traduction et de
réordonnancement pour ce segment.

Dans la plupart des systémes de traduction (voir (Koehn, 2010) pour un état de l’art récent, ou, en
francais (Allauzen et Yvon, 2011)), l’apprentissage de ces paramétres s’effectue en deux temps :
(i) en premier lieu, plusieurs modeles probabilistes sont estimés de maniere indépendante, en
utjlisant de tres gros corpus monolingues ou bilingues paralléles. Une étape supplémentaire (ii)
d’apprentissage (souvent désignée sous le nom de tuning) est ensuite nécessaire pour équilibrer
la contribution de chacun de ces modéles a la fonction de score. Cette seconde étape, réalisée
sur des corpus de développement de taille réduite, conduit au calcul de paramétres globaux (un
pour chaque modéle estimé en (i)), qui sont réglés de maniere discriminante, c’est—a—dire en
cherchant a maximiser explicitement une mesure de qualité de la traduction, sous l’hypothese
que les scores se combinent linéairement. Ceci implique, par exemple, que le paramétre 05;) qui
évalue la plausibilité que le segment 1 source 3 se traduise ? est calculé comme le produit d’un
poids global, réglé de maniére discriminante sur un ensemble de développement, avec un score
local, calculé de maniére heuristique sur de larges corpus. Comme souligné dans de nombreuses
études, ce processus a deux étages conduit a des parametres sous—optimaux; pour obtenir des
résultats stables, il est également nécessaire de limiter le nombre de modeles combinés en (ii)
a quelques dizaines d’unités (voir cependant (Liang et al., 2006; Chiang et al., 2009; Blunsom
et al., 2008; Simianer et al., 2012) pour des tentatives de contourner cette limitation).

Dans ce travail, a la suite de (Liang et al., 2006; Blunsom et al., 2008; Dyer et Resnik, 2010), nous
explorons une approche alternative, dans laquelle tous les paramétres du modéle sont appris
simultanément (plutot qu’indépendamment) et de maniére discriminante (plutot qu’heuristique) ;
cet apprentissage est réalisé en optimisant une fonction objectif bien connue sur Pintégralité des
données d’entrﬁnement (plutét qu’un petit ensemble de développement). Notre architecture
permet de se dispenser presqu’entiérement du besoin d’estimer des modéles séparés puis de
régler les paramétres pour les recombiner : ces deux étapes sont ici réalisées simultanément.

Dans cette approche, l’apprentissage ne demande que (a) un corpus paralléle, (b) un inventaire
des unités de traductions et (c) un mécanisme pour produire des hypotheses de réordonnance-
ment. Il est important de noter que (b) peut étre obtenu de plusieurs maniéres, par exemple
en fouillant des corpus comparables, et/ou en exploitant des dictionnaires et des terminologies
bilingues. De méme, plusieurs options existent pour (c), comme d’utiliser des modéles de réor-
donnancement simples tels que IBM-n (Tillmann et Ney, 2003) et WJ—n (Kumar et Byrne, 2005)

1. La situation est un peu plus complexe car les systémes standard comprennent plusieurs modéles de traduction.

451 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Conﬁguration | devel03 | test09 | test10
Systeme n-code |
Modele de traduction 2g 68,7 61,1 —
Modele de traduction 3g 68,0 61,6 53,4
| Systeme entrainé discriminativement |

Inférence Viterbi 64,0 58,8 51,5
+ marginalisation 64,7 59,3 52,0
+ LM cible 67,7 61,7 53,9

TABLE 2 — Performance des systémes de traduction (scores BLEU).

deux ou trois minutes.

Le tableau 3 compare les différentes maniére de gérer les références non atteignables (voir
section 4) 7. I1 apparait clairement que supprimer les exemples pour laquelle la référence est
non atteignable est la pire, puisque dans notre cas elle conduit a abandonner environ 8% des
exemples. Augmenter localement le modele de traduction permet d’amé1iorer trés nettement les
résultats; la stratégie la plus efﬁcace consiste toutefois a utiliser des pseudo—références oracles.

Conﬁguration devel03 test09
Suppression 59,2 52,6
Augmentation locale 62,4 56,4
Pseudo—références 64,0 58,8

TABLE 3 — Différentes manieres de gérer les références non atteignables

7 Discussion

L’approche standard en traduction statistique, rappelée a la section 2, réalise l’apprentissage
des modeles en deux étapes successives et repose grandement sur une procédure d’optimisation
ad hoc, connue sous le nom de MERT (Och, 2003). De nombreux travaux récents ont tenté de
reformuler MERT comme un probleme d’apprentissage standard, aﬁn de le rendre plus robuste
a des situations ou le nombre de caractéristiques est grand. MERT a ainsi été reformulé par
exemple comme un probléme d’apprentissage structuré (Tillmann et Zhang, 2006; Watanabe
et al., 2007; Cherry et Foster, 2012) cu encore comme un probléme d’apprentissage de fonc-
tion d’ordonnancement (Hopkins et May, 2011). Ces approches visent a améliorer la seconde
étape de l’apprentissage, sans remettre toutefois en cause 1’architecture globale du systeme. Par
comparaison, les travaux cherchant a déﬁnir des cadres d’apprentissage intégrés sont plus rares.

Un pas important dans cette direction est le modéle de Liang et al. (2006), qui utilise un
perceptron structuré pour apprendre les paramétres du modéle. Cette approche requiert toutefois
de ﬁxer la valeur des variables latentes impliquées dans une dérivation aussi bien a l’apprentissage
que lors de l’inférence, la ou nous utilisons une procédure de marginalisation. Une autre différence
avec notre travail est 1’uu'1isation d’un modéle de réordonnancement plus simple. Une autre source

7. Ces résultats sont obtenus pour la stratégie d’inférence dite de Viterbi.

460 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

d’inspirau'on est le travail décrit dans (Blunsom et al., 2008), qui décrit une version discriminante
du modéle hiérarchique de Chiang (2005). Comme dans notre approche, 1’apprentissage repose
sur 1’optimisation de la log—vraisemblance conditionnelle, impliquant de sommer sur toutes les
dérivations (hors—contexte) d’une traduction. La complexité de l’algorithme de parsage sous-
jacent au calcul du gradient O(|t|3|s|3) semble toutefois limiter l’approche a des phrases courtes 8.
Une différence signiﬁcative avec notre travail est la gestion des références non—atteignables, qui
sont purement et simplement supprimées du corpus d’apprentissage. Le travail plus récent de
Dyer et Resnik (2010) mérite enﬁn mention, puisqu’il utilise la méme architecture que la n6tre, a
la différence pres que le modéle de réordonnancement est un modele hors—contexte p1ut6t que
rationnel. Ce travail est toutefois focalisé sur1’apprentissage du modéle de réordonnancement et
conserve le besoin d’entrainer séparément le modele de traduction.

En résumé, notre approche se distingue de la plupart des approches discriminantes en traduction
statistique en ceci que nous réalisons 1’apprenu'ssage simultané de tous les paramétres du mo-
déle de maniére intégrée, par optimisation d’une fonction objectif bien fondée théoriquement
(la log-vraisemblance conditionnelle régularisée).

Conclusion

Nous avons présenté une architecture intégrée pour réaliser en une seule étape l’apprentissage
discriminant de tous les parametres des systemes de traduction. Cette architecture, qui emprunte
beaucoup a des techniques d’apprenu'ssage bien connues, permet d’introduire dans le modéle un
tres grand nombre de caractéristiques. En utilisant cette architecture, nous avons développé un
systéme qui surpasse un systéme de base trés performant sur la tache de traduction du BTEC.
Notons en particulier que notre approche conduit a des meilleurs scores BLEU que n—code, qui
est pourtant spéciﬁquement entrainé pour optimiser cette métrique. Une propriété importante de
notre approche est son caractere modulaire, puisqu’e11e s’accomode d’inventaires d’unités et de
modeles de réordonnancement variés.

Dans le futur, la priorité principale sera de réaliser des expériences sur des taches plus complexes,
impliquant a la fois de plus gros corpus d’apprentissage et des langues plus éloignées. Diverses
améliorations du modéle présenté ici sont également a 1’étude : ainsi l’utilisation de modéles de
réordonnancement plus puissants, a la maniere de Dyer et Resnik (2010) ; l’utilisation d’unités
de traduction avec trous, poursuivant les propositions de (Simard et al., 2005; Crego et Yvon,
2009) ; ou l’utilisation d’une fonction objectif intégrant une mesure plus directe de la qualité de
traduction, a l’instar par exemple de (Gimpel et Smith, 2010).

Remerciements

Ce travail a été partjellement ﬁnancé par OSEO dans le cadre du programme Quaero.

8. Les résultats de (Blunsom et aL, 2008) utilisent des phrases de moins de 15 mots.
461 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
Références

ALLAUZEN, A. et YvoN, F. (2011). Méthodes statistiques pour la traduction automatique. In
GAUssIER, E. et YvoN, E, éditeurs : Mode‘les statistiques pour l’accés c‘I l’inforrnation textuelle,
chapitre 7, pages 271-356. Hermes, Paris.

ALLAUZEN, C., RILEY, M., ScHALI<wYI<, J., SKUT, W. et MOHRI, M. (2007). OpenFst : A general and
efficient weighted ﬁnite—state transducer library. In Proc. of CIAA, pages 11-23.

BLUNSOM, R, COHN, T. et OSBORNE, M. (2008). A discriminative latent variable model for
statistical machine translation. In Proc. ACL/HLT, pages 200-208.

CHEN, S. E et GOODMAN, J. T. (1996). An empirical study of smoothing techniques for language
modeling. In Proc. ACL, pages 310-318.

CHERRY, C. et F0sTER, G. (2012). Batch tuning strategies for statistical machine translation. In
Proc. of the 2012 Conf HLT—NAACL, pages 427-436.

CHIANG, D. (2005). A hierarchical phrase—based model for statistical machine translation. In
Proc. ACL, pages 263-270.

CHIANG, D., KNIGHT, K. et WANG, W. (2009). 11,001 new features for statistical machine
translation. In Proc. NAACL/HLT, pages 218-226.

CREGO, J. M. et MARINO, J. B. (2007). Improving SMT by coupling reordering and decoding.
Machine Translation, 20(3):199-215.

CREGO, J. M. et YvoN, E (2009). Gappy translation units under left—to—right SMT decoding. In
Proc. of the conf EAMT, pages 66-73.

CREGO, J. M., YvoN, E et MARINO, J. B. (2011). N—code : an open-source Bilingual N—gram SMT
Toolkit. Prague Bulletin of Mathematical Linguistics, 96:49-58.

DREYER, M., SMITH, J. et EIsNER, J. (2008). Latent—variable modeling of string transductions
with ﬁnite—state methods. In Proc. EMNLP, pages 1080-1089.

DYER, C. et RESNIK, P. (2010). Context-free reordering, ﬁnite-state translation. In Proc
NAACL/HLT, pages 858-866, Los Angeles.

GIMPEL, K. et SMITH, N. A. (2010). Softmax-margin CRFs : training log-linear models with cost
functions. In Proc. HL'11NAACL, HLT ’10, pages 733-736.

HOPKINS, M. et MAY, J. (2011). Tuning as ranking. In Proc. EMNLP, pages 1352-1362.
KOEHN, R (2010). Statistical Machine Translation. Cambridge University Press.

KoEHN, R, HOANG, H., BIRCH, A., CALLIsoN—BURcH, C., FEDERICO, M., BERTOLDI, N., CowAN, B.,
SHEN, W, MORAN, C., ZENs, R., DYER, C., BOJAR, 0., CONSTANTIN, A. et HERBST, E. (2007). Moses :
Open source toolkit for statistical machine translation. In Proc. ACL, pages 177-180.

KoEHN, R, OCH, E J. et MARCU, D. (2003). Statistical phrase—based translation. In Proc of the
conﬁ HLT—NAACL, pages 127-133.

KUMAR, S. et BYRNE, W. (2005). Local phrase reordering models for statistical machine translation.
In Proc. HLT-EMNLP, pages 161-168.

KUMAR, S., DENG, Y. et BYRNE, W. (2006). A weighted ﬁnite state transducer translation template
model for statistical machine translation. Natural Language Engineering, 12(1):35—75.
LAFFERTY, J., MCCALLUM, A. et PEREIRA, F. (2001). Conditional random ﬁelds : probabilistic
models for segmenting and labeling sequence data. In Proc. ICML, pages 282-289.

462 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

LAVERGNE, 'I‘., ALLAUZEN, A., CREGO, J. M. et Yv0N, E (2011). From n—gram—based to CRF—based
translation models. In Proc. WMT, pages 542-553.

LIANG, P, BoUcHARD—Cc‘>T11:, A., KLEIN, D. et TASKAR, B. (2006). An end—to—end discriminative
approach to machine translation. In Proc. ACL, pages 761-768.

MARINO, J. B., BANCHS, R. E., CREGO, J. M., de GISPERT, A., LAMBERT, P, FoNoLLosA, J. A. et
C0sTA—JUssA, M. R. (2006). N-gram—based machine translation. Comp. Ling., 32(4):527—549.

OCH, E J. (2003). Minimum error rate training in statistical machine translation. In Proc. ACL,
pages 160-167.

PAPINENI, K., RoUKos, S., WARD, T. et ZHU, W.-J. (2002). BLEU : a method for automatic
evaluation of machine translation. In Proc. ACL, pages 311-318.

PAUL, M., FEDERICO, M. et STUCKER, S. (2010). Overview of the IWSLT 2010 Evaluation Campaign.
In FEDERICO, M., LANE, 1., PAUL, M. et Yv0N, E, éditeurs : Proc. IWSLT, pages 3-27.

RIEDMILLER, M. et BRAUN, H. (1993). A direct adaptive method for faster backpropagation
learning : The RPROP algorithm. In Proc. ICNN, pages 586-591.

SIMARD, M., CANCEDDA, N., CAVESTRO, B., DYMETMAN, M., GAUSSIER, E., GOUTTE, C., YAMADA, K.,
LANGLAIS, P. et MAUSER, A. (2005). Translating with non-contiguous phrases. In Proc. HLT-EMNLP,
pages 755-762.

SIMIANER, P, RIEZLER, S. et DYER, C. (2012). Joint feature selection in distributed stochastic
learning for large-scale discriminative training in SMT. In Proc. ACL, pages 11-21.

SOKOLOV, A., WISNIEWSKI, G. et YvoN, F. (2012). Computing lattice BLEU oracle scores for
machine translation. In Proc. EACL, pages 120-129.

SUTTON, C. et MCCALLUM, A. (2006). An introduction to conditional random ﬁelds for relational
learning. In GETOOR, L. et TASKAR, B., éditeurs : Introduction to Statistical Relational Learning.
The MIT Press.

TAKEZAWA, 'I‘., SUMITA, E., SUGAYA, E, YAMAMOTO, H. et YAMAMOT0, S. (2002). Toward a broad-
coverage bilingual corpus for speech translation of travel conversations in the real world. In
Proc. of LREC, volume 1, pages 147-152.

TIBSHIRANI, R. (1996). Regression shrinkage and selection via the Lasso. J.R.Statist.Soc.B,
58(1):267-288.

TILLMAN, C. (2004). A unigram orientation model for statistical machine translation. In DUMA1s,
S., MARCU, D. et RoUKos, S., éditeurs : HLT-NAACL 2004 : Short Papers, pages 101-104.
TILLMANN, C. et NEY, H. (2003). Word reordering and a dynamic programming beam search
algorithm for statistical machine translation. Comp. Ling., 29(1):97-133.

TILLMANN, C. et ZHANG, T. (2006). A discriminative global training algorithm for statistical mt.
In Proc. of the can)‘. of the ACL, pages 721-728.

WATANABE, T., SUZUKI, J ., TSUKADA, H. etIsozA1<1, H. (2007). Online 1arge—margin training for
statistical machine translation. In Proc. of EMNLP-CoNLL, pages 764-773.

ZENS, R., OCH, F. J . et NEY, H. (2002). Phrase—based statistical machine translation. In JARKE,
M., KOEHLER, J. et LAKEMEYER, G., éditeurs : KI—2002 : Advances in AI, volume 2479 de LNAI,
pages 18-32. Springer.

463 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
ou encore d’apprendre les regles de réordonnancement, comme nous le ferons ici.

L’im lantation d’un cadre discriminant inté re’ our la traduction statisti ue im li ue toutefois
P 8 P q P

de résoudre plusieurs problemes pratiques et théoriques lie’s a la pre’sence de variables latentes
dans le modele et a l’impossibilité de disposer de données de supervision pour certaines paires
de phrases lorsque la traduction de référence ne peut étre produite par le modéle (on dit alors
que la référence est non atteignable). Ces problémes sont résolus respectivement en sommant
(marginalisant) sur toutes les dérivations possibles et en recourant a des traductions oracles.

Les contributions de ce travail, qui développe et étend la proposition présentée dans (Lavergne
et al., 2011) en s’affranchissant du besoin de disposer d’alignements de référence, sont multiples :
la conception d’un modele intégré pour la traduction automatique, qui rend possible l’utilisation
d’un grand nombre de traits linguistiques; une implémentation modulaire qui, en s’appuyant
sur le formalisme des transducteurs ﬁnis pondérés (WFST), bénéﬁcie d’algorithmes efﬁcaces
aussi bien pour l’apprentissage que pour l’inférence; et l’étude de plusieurs manieres de traiter le
probleme des références non atteignables. Notre contribution est aussi expérimentale, puisque
nous montrons que le systéme ainsi construit s’avére capable de surpasser un systéme trés
performant sur une tache de complexité moyenne.

Le reste de cet article est organisé comme suit. Nous commencons par clariﬁer, a la section 2, les
concepts nécessaires a la formulation de notre cadre discriminant et comparons notre approche
avec d’autres implantations de l’apprentissage discriminant en traduction automatique. Nous
introduisons ensuite plus précisément (section 3), notre modéle de traduction et discutons
plusieurs détails d’implantation. Les sections ultérieures sont consacrées respectivement a deux
aspects pratiques : le probléme des références non atteignables (Section 4), puis la conception
d’un ensemble performant de descripteurs (section 5). Nous décrivons a la section 6 les principaux
résultats expérimentaux obtenus sur la tache de traduction francais—anglais utilisant les données
du corpus B'I'EC. Les sections conclusives permettent ﬁnalement de positionner notre travail par
rapport a l’état de l’art (section 7), puis de présenter briévement diverses extensions de cette
approche.

2 Apprentissage discriminant en traduction statistique

2. 1 Inférence

Comme expliqué supra, les STS modélisent le processus de génération d’une traduction sous
la forme d’une successions d’étapes de dérivation. Ainsi, dans l’approche a base de n—gramme
(Mariﬁo et al., 2006; Crego et Mariﬁo, 2007), sur laquelle nous nous appuyons principalement
dans cet article, les traductions sont engendrées de la maniere suivante 2 :

1. la phrase source est réordonnée de maniere non-déterministe et transformée en un graphe
de réordonnancement;

2. ce graphe est ensuite étendu en considérant toutes les décompositions possibles de la
phrase source en segments;

2. Les dérivations des systémes a base de segment telles que formulées dans (Koehn et al., 2007) ou dans (Kumar
et aL, 2006) utilisent essentiellement le méme ensemble de variables latentes, alors que le modele hiérarchique de Chiang
(2005) utilise les dérivations d’une grammaire hors-contexte synchrone.

452 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

3. un modéle de traduction est alors appliqué sur cette entrée étendue, de maniere a générer
le graphe de recherche de toutes les traductions possibles;

4. ce graphe est ﬁnalement parcouru pour rechercher la traduction de meilleur score.

Chaque hypothése de traduction t d’une phrase source s est ainsi associée a une ou plusieurs
dérivations latentes a, on a représente toutes les variables qui sont impliquées dans les étapes de
dérivation (1-3). Chaque triplet (s, a, t) est représente’ comme un vecteur de caractéristiques G
et son score est calculé par le produit scalaire (0 est le vecteur de parametres) :

<I>(s, a, t) = 0 TG(s, a, t) (1)
Il est aisé de transformer ces scores en probabilités en déﬁnissant p9(t, a | s) comme suit :

exp (0TG(t, a, s))
2 exp (0TG(t’, a’, s)) ’

a’e.d(s)
t’ e:?(a’,s)

pa(t,a I S) = (2)

ou .21 (s) est l’ensemble de toutes les assignations possibles des variables latentes et oil .9 (a, s)
représente l’ensemble de toutes les traductions possibles de s sachant une assignation particuliere
de a. La probabilité conditionnelle de t sachant s s’en déduit par sommation selon :

Pa(t|s)= Z pacnals) can

aeazi (s)

La regle d’inférence optimale consiste a choisir la meilleure traduction t* pour s selon :

t*=af8maXPa(t|S)=ar8II1aX Z Pa(t,a|s), (4)
t ae.vzi(s)

La somme (4) devant étre réalisée pour chaque traduction possible t, il s’avére toutefois que
l’inférence ainsi déﬁnie donne lieu a un probléme combinatoire NP-difﬁcile. C’est pourquoi la
plupart des systemes de traduction se contentent d’utiliser une approximation, dite de Viterbi, qui
correspond a l’utilisation de la regle d’inférence plus simple suivante :

t* = he (s) = arg maxpg (t, a | s), (5)
La

On notera que cette regle permet également de recouvrer la dérivation latente optimale a*.

2.2 Apprentissage discriminant (version standard)

Le modéle introduit ci—dessus est sufﬁsamment général pour rendre compte de la plupart des
systemes a base de segments et peut étre instancié de multiples manieres. Comme mentionné plus
haut, l’architecture la plus utilisée (Koehn, 2010) s’appuie sur plusieurs couches de modélisaﬁon
statistique. La premiere couche correspond a l’estimation, sur des corpus monolingues et/ou
paralleles, d’un ensemble de modeles probabilistes, les plus importants étant le modele de langue,
le modéle de traduction et le modéle de réordonnancement, qui sont usuellement estimés au

453 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

maximum de vraisemblance 3. Cha ue modéle ainsi calculé corres ond a une com osante du

q P P
vecteur G introduit en (1) : Gk(t, a, s) est le score, pour le kéme modéle, de la dérivation a qui
produit t a partir de s.

Le seconde couche d’apprentissage est effectue’e de maniére discriminante : son implantation la
plus utilisée, Minimum Error Rate Training (MERT) (Och, 2003), consiste a résoudre le probléme
d’opu'misau'on suivant : étant donné un ensemble de couples entrée/ sortie {(s", t"), n = 1 . . .N},
trouver les parametres optimaux satisfaisant :

0*=argmax ({(s",h9(s"),t"),n= 1...N}), (6)
BLEU

ou BLEU (Papineni et al., 2002) est une mesure automatique de la qualité de traduction. La
résolution de ce probleme n’est en pratique faisable que lorsque 0 est de dimension réduite. On
retiendra également que sa résolution requiert d’identiﬁer une dérivation optimale, par exemple
celle qui conduit au meilleur score BLEU parmi une liste de n meilleurs candidats.

3 Apprentissage discriminant (version intégrée)

Dans cette section, nous proposons une autre instanciation du cadre d’apprentissage décrit
ci—dessus, dans lequel l’estimation de tous les paramétres du modéle est réalisée de maniére
intégrée et discriminante, ce qui constitue une différence fondamentale avec la plupart des
autres approches discriminantes en traduction statistique (voir également la discussion de la
section 7). Comme on le verra, notre modéle s’inspire largement du modéle des champs aléatoires
conditionnels (CRF, voir (Lafferty et al., 2001)) qu’il étend de plusieurs manieres.

3.1 Apprentissage du modéle

L’apprentissage est réalisé en maximisant la (log) vraisemblance conditionnelle déﬁnie par :

$(0)=Z log 2 exp (0TG(t",a,s"))—log 2 exp (0TG(t,a,s")) (7)

ae_;zi(s") aed(s")
te:?(a,s")

Comme expliqué ci—dessus, nous ne considérons que des dérivations a qui sont rationnelles et
correspondent a la série d’étapes (1-3) introduites a la section 2.

L’introduction de variables latentes fait que la fonction objectif (7) n’est pas convexe, contraire—
ment au cas des CRF standard (Sutton et McCallum, 2006). En pratique, son optimisation reste
possible, et, si elle ne conduit qu’a des optimums locaux, les résultats obtenus ne semblent pas
trop de’pendants des conditions initiales. Comme détaillé a la section 3.3, l’optimisation repose

3. L’estimation du modéle de traduction est en fait plus complexe et implique un empilement d’étapes heuristiques :
calcul d’alignements de mots asymétriques, symétrisation des alignements, extraction et évaluation des couples bilingues
de segments, etc.

454 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

sur un algorithme de descente de gradient qui demande de calculer le gradient suivant :

8.2’ 0
i = Z] Z Gk<t",a,s") — Z 0kGk(t:a;5n)P0(t:a I s"), (8)
8 0 k T1 ae.:zi(s“) a::(s’;))

Dans cette é uation les deux termes re résentent res ectivement l’es érance em iri ue et
1
l’espérance pour le modele calculées sur1’ensemble des données d’apprentissage.

En théorie, dans cette approche, les composants de G peuvent tester des propriétés arbitraires
du triplet (t",a,s") ; en pratique, toutefois, le choix des caractéristiques a un impact sur la
complexité computationnelle des algorithmes d’inférence et d’apprentissage. Dans cette étude,
nous nous limitons a des caractéristiques de portée locale, reproduisant les dépendances locales
qui sont modélisées dans un CRF linéaire standard (Lafferty et al., 2001) : la portée d’une
caractéristique ne peut excéder un bigramme de segments cibles. Cette restriction permet de
calculer efﬁcacement les deux termes de l’équation (8) en utilisant une variante de l’algorithme
forward-backward (voir, par exemple, (Dreyer et al., 2008) pour une présentation détaillée de
l’apprentissage de modeles globalement normalisés avec des variables latentes).

La fonction objectif est usuellement augmentée d’un terme de régularisation pour limiter les
problémes de sur—apprenu'ssage. Dans cette étude, nous utilisons une régularisation (1 (Tibshirani,
1996), qui permet d’aboutir a des ensembles de paramétres « creux » et donc implicitement de
sélectionner les caractéristiques les plus importantes.

3.2 Inférence

L’inférence est déﬁnie par l’équation (4), qui exige en principe de sommer sur toutes les variables
latentes pour calcu1er1’hypothése de traduction optimale. Cette tache correspond a un probléme
NP—difﬁcile ; en pratique, il est possible de 1’approximer de maniére efﬁcace en élaguant et
déterminisant l’espace de recherche, comme expliqué section 3.3.

11 est important de noter que les dépendances qui sont modélisées se limitent a des bigrammes
de segments cibles qui ne fournissent qu’une trés mauvaise approximation des contraintes
syntaxiques a respecter en langue cible. Pour compenser cette faiblesse, nous utilisons durant
l’inférence un modele de langue n-gramme d’un ordre supérieur a deux, ce qui permet d’améliorer
sensiblement les performances du seul modele CRF.

3.3 Détails d’implantation

Transducteurs finis Toutes les opérations nécessaires pour réaliser l’apprentissage et l’inférence
sont implantées comme des opérations standard sur des transducteurs pondérés. Pour l’essentiel,
nous nous reposons sur les fonctionnalités génériques de la bibliotheque OpenFst (Allauzen et al.,
2007) ; pour des raisons d’efﬁcacité, nous avons toutefois réimplanté une version optimisée de
l’algorithme forward—backward et des interactions avec le modele de traduction.

Pour l’essentiel, notre décodeur est donc implanté comme une cascade de transducteurs ﬁnis,
impliquant les étapes suivantes : (i) réordonnancement et segmentation de la phrase source;

455 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

(ii) application du modele de traduction et (optionnellement) (iii) composition avec un modele
de langue cible, une architecture tres similaire a celle proposée par (Kumar et al., 2006). Plus
précisément, étant donnés un modele de réordonnancement et un inventaire d’unités, nous
dérivons les transducteurs suivants :

— 1, un accepteur pour la phrase source s;

— R, qui implémente les regles de réordonnancement ;

— C, qui regroupe des séquences de mots sources en segments de taille variable;

— T, qui réalise 1’association entre segments sources et toutes leurs traductions possibles.

Si l’on note 0 l’opération de composition entre transducteurs, alors S = I oRoC o T déﬁnit l’espace
de recherche qui est utilisé pour l’apprentissage et pour 1’inférence.

Apprentissage du modele L’optimisation de la log—vraisemblance (équation (7)) est effectuée
en utilisant l’algorithme R—Prop (Riedmiller et Braun, 1993) qui implémente une stratégie de
descente de gradient adaptée a l’optimisation des modeles log—linéaires a grande échelle. Cet
algorithme demande de calculer les espérances déﬁnies par l’équation (8). Le premier terme est
obtenu en collectant les statistiques pour les caractéristiques actives dans le transducteur déﬁni
par S o 0, cu O est l’accepteur représentant la traduction de référence. La seconde espérance
demande de collecter ces memes statistiques sur l’intégralité de l’espace de recherche S, de
nouveau par application de l’algorithme forward—backward.

Inférence des traductions Dans notre implantation, l’inférence est réalisée en quatre temps :
S est tout d’abord reparcouru pour calculer la probabilité a posteriori de chaque arc; nous
déterminisons ensuite le transducteur ainsi repondére’, ce qui a pour effet de réaliser la somme
impliquée par l’équation (4) ; le score du modele de langue est ensuite ajouté simplement par une
opération de composition pondérée (le poids du modele de langue est obtenu par une recherche
sur un corpus de développement) ; ﬁnalement, le meilleur chemin dans le transducteur est extrait.
Dans la mesure ou l’opération de déterminisation est la plus exigeante en temps, nous la réalisons
de maniere approchée en ne considérant a ce stade que les n-meilleures hypotheses de l’espace
de recherche. La somme (4) est donc seulement calculée sur ces n meilleures hypotheses, ce qui
ne semble pas trop limitant en pratique.

4 Les références non atteignables

Un probleme spéciﬁque qui se pose dans le cadre de l’apprentissage discriminant pour la traduc-
tion est celui de la non atteignabilité des références, correspondant aux situations ou la traduction
de référence ne peut pas étre dérivée dans le modele (Liang et al., 2006) . Cela arrive, par
exemple, quand on utilise un inventaire d’unités bilingues trop restreint, ou que l’on considere
des réordonnancements trop limités. Il est alors possible qu’une traduction de référence contienne
une traduction inconnue d’un mot source connu, ou bien des déplacements de groupes qui vont
au—dela de ceux qu’explore le décodeur. Un remede radical consiste alors a supprimer ces cas pro-
blématiques du corpus d’apprenu'ssage (Blunsom et al., 2008; Dyer et Resnik, 2010) — conduisant
ainsi a abandonner de nombreux exemples potentiellement utiles.

Une autre solution simple, utilisée dans plusieurs études, consiste a utiliser des pseudo-références
oracles, qui sont les meilleures hypotheses (au sens de la métrique d’évaluation) réellement

456 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

SWi_1: 1e nobel de la paix

Spi_1: DET ADJ PRP DET NN

sri_1:134-56

O

tw. : the nobel peace
1-]
tpi_1: DETADJ NN

 

FIGURE 1 — Deux arcs consécutifs dans l’espace de recherche : informations dont sont dérivées les
caractéristiques.

présentes dans l’espace de recherche. Comme le soulignent les auteurs de (Liang et al., 2006),
une bonne traduction (au sens de la métrique) peut toutefois s’appuyer localement sur des étapes
de dérivation qui ont une tres faible probabilité, et ne devraient pas étre utilisées comme exemple.
Cette observation suggere des stratégies plus prudentes, selon lesquelles l’oracle est choisi parmi
les 11 hypotheses les plus probables (au sens du modele). Des stratégies hybrides sont également
envisageables, selon lesquelles les oracles sont choisis parmi les hypotheses qui sont a la fois
proches de la référence et bien évaluées par le modele.

Diverses stratégies ont été implantées et évaluées dans nos expériences. La premiere consiste
a supprimer tous les exemples non atteignables. Une seconde alternative consiste a augmenter
le modele localement de facon a compenser les lacunes du modele : dans notre architecture,
cela revient par exemple a simuler l’existence d’unités de traduction qui seraient manquantes. La
troisieme alternative, qui s’est avérée la meilleure, consiste a utiliser des pseudo-référence oracles
calculées non pas sur des listes de n-meilleures hypotheses, mais sur l’intégralité de l’espace
de recherche (Voir (Sokolov et al., 2012) pour une description des algorithmes permettant de
calculer ces oracles lorsque la métrique mesurant la qualité des traductions est le score BLEU).

5 Caractéristiques

Pour présenter les principales caractéristiques utilisées dans notre modele, reportons nous a
la Figure 1 qui donne a Voir deux arcs consécutifs dans l’espace de recherche S. Chaque arc
porte toutes les informations nécessaires au calcul des caractéristiques : les segments source et
cible (sw et tw), les séquences de parties du discours (POS) associées (s p et tp ), ainsi que les
positions originales (avant réordonnancement) des mots sources (sr). Les indices i et i— 1 servent
seulement a noter le fait que l’arc i — 1 précede l’arc i et constitue le contexte gauche de l’arc
courant. Etant donnée cette représentation, il est possible de déﬁnir des caractéristiques binaires
qui chacune teste une propriété particuliere du couple d’arcs (i — 1, i). La liste de descripteurs de
base est dans le tableau 1.

La forme des caractéristiques de base simule les dépendances d’un modele de langue bigramme
en cible : ainsi, les caractéristiques notées LM :* correspondent a des modeles unigrammes

457 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

LM zuni-tphr ]I(tw,- = tw)

LM zuni-tpos ]I(tp,- = tp)

LM zbig-tphr ]I(tw,- = tw A tw,-_1 = tw’)

LM zbig-tpos ]I(tp,- = tp A tp,-_1 = tp’)

TM :ci-phrp ]I(tw,- = tw A sw,- = sw

TM :ci-posp ]I(tp,- = tp A spi =sp)

TM :ci-mixp ]I(tw,- = tw A spi =sp)

TM :cd-phrs ]I(tw,- = tw A swi = sw A sw,-_1 = sw’)
TM :cd-poss ]I(tp,- = tp A spi =sp A sp,-_1 =sp’)
TM :cd-phrt ]I(tw,- = tw A tw,-_1 = tw’ A swi = sw)
TM zcd-post ]I(tp,- = tp A tp,-_1 = tp’ A sp,- =sp)

TABLE 1 — Caractéristiques de base avec les notations de la Figure 1.

et bigrammes respectivement de segments de mots et de POS. L’autre groupe principal de
caractéristiques, noté TM :* modélise les relations de traduction. Il comprend des caractéristiques
indépendantes du contexte (qui ne regardent que le segment courant) TM :ci-phrp et TM :ci-
posp qui testent respectivement l’association d’un segment source avec un segment cible au
niveau lexical et au niveau des étiquettes grammaticales; les caractéristiques dépendantes du
contexte gauche (TM :cd*) sont plus spéciﬁques et prennent en compte le segment précédent.

Les réordonnancements sont évalués par un autre ensemble de caractéristiques intégrant des tests
qui simulent les modeles de réordonnancement lexicalisés standard (Tillman, 2004; Crego et al.,
2011). Dans notre approche, cinq classes de déplacements sont considérées : ’monotone’, ’swap’,
’1eft discontinuous’, ’right discontinuous’ and ’othe1’. Pour chaque catégorie, deux caractéristiques
testent respectivement l’association avec le segment cible et la séquence de POS correspondante.

Nous utilisons ﬁnalement deux caractéristiques supplémentaires : la premiere est toujours active
et permet d’ « encourager >> l’insertion de nouveaux segments dans la phrase en construction. La
seconde est relative aux recopies, et est active quand les mots source et cibles sont identiques, ce
qui permet de << récompenser >> la recopie d’un mot source inconnu dans la cible, une stratégie
qui s’avere souvent gagnante. (pour les noms propres, les dates, etc)

6 Expériences

6.1 Corpus et systéme de base

La tache de traduction considérée utilise les données paralléles francais/anglais du Basic Traveling
Expression Corpus (BTEC), tel qu’il a été utilisé dans les évaluations internationales de l’atelier
IWSL'I‘. Ce corpus contient des phrases semblables a ce que l’on peut trouver dans des guides
touristiques, en plusieurs langues (Takezawa et al., 2002). Le corpus de développement est
devel03, qui contient 506 lignes et 16 références par lignes; nous utilisons comme jeu de test les
corpus test09 et test10 qui contiennent respectivement 469 lignes et 464 lignes, avec 7 traductions
de référence. Notre mesure principale de la qualité des traductions est le score BLEU calculé
en utilisant le maximum de références disponibles. Cette tache est souvent considérée comme

458 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

relativement simple, au vu de la longueur moyenne des phrases, et du relativement faible nombre
de données d’apprentissage : l’utilisation de notre cadre intégré d’apprentissage discriminant
implique toutefois d’entrainer le systeme sur environ 20K phrases, soit 10 fois plus que ce qui est
usuellement utilisé pour entrainer discrimininativement (avec MERT) des systémes standard sur
des « grosses » taches.

Notre systeme de base est n—code4 (Crego et al., 2011), une implantation domaine public
de l’approche a base de n—gram introduite dans (Mariﬁo et al., 2006). Selon cette approche,
le modele de traduction est représenté par un transducteur stochastique correspondant a un
modéle n—gramme de couples de segments (n = 3 dans nos expériences). L’entrainement d’un tel
modele demande au préalable de réordonner les phrases sources pour reproduire l’ordre des
mots en langue cible. Ce réordonnancement est également effectué par un transducteur ﬁni
non—déterrniniste, qui utilise des informations morpho—syntaxiques (calculées par le TreeTagger5)
pour généraliser les régles de reordonnancement au niveau des POS.

Le modele complet utilise quatorze caractéristiques : le modele de traduction, un modele
(trigramme) de langue cible, quatre modéles d’a1ignementlexicalisés 6, six modéles de réordon-
nancement lexicalisés (Tillman, 2004; Crego et al., 2011) ; un modele de distortion ainsi que deux
modéles supplémentaires qui encouragent respectivement la génération de mots et de segments
cibles. Les poids des différents modeles sont estimés en utilisant la procédure MERT (Och, 2003).

Pour toutes nos expériences, le modele de langue cible est estimé en utilisant un lissage de Kneser—
Ney modiﬁé (Chen et Goodman, 1996). Notons également que tous les systemes évalués ci—desous
utilisent le meme inventaire d’unités de traduction et le meme mécanisme de réordonnancement,
qui sont ceux construits pour le systéme de base, ce qui permet une comparaison équitable entre
systemes. Tous nos résultats respectent les contraintes de la tache spéciﬁée pour la campagne
IWSLT 2010, et peuvent étre directement comparés avec les résultats de (Paul et al., 2010).

6.2 Résultats

Le tableau 2 récapitule nos principaux résultats en termes de scores BLEU. Premiere observation :
le systeme de base est légerement meilleur que le meilleur systeme ayant participé a la campagne
IWSLT 2010 ((Paul et al., 2010, p.20) mentionne un score de 52, 69 pour le meilleur systéme).
Trois conﬁgurations différentes du systeme discriminant sont comparées : la premiere réalise
l’inférence en ut1'lisantl’approximation dite de Viterbi (équation (5)) et obtient des performances
tres inférieures au systeme n-code; la seconde conﬁguration implante la procédure de margi-
nalisation approximative décrite a la section 3.3, ce qui permet une légere amélioration des
performances. La troisieme conﬁguration (+LM cible) integre également, comme c’est le cas pour
les systémes n—code, un modéle trigramme en langue cible et permet de surpasser légérement le
systéme de base sur les deux jeux de test.

A l’initialisation de l’apprentissage, le modele de traduction contient environ 13 millions de
caractéristiques. Au terme de l’apprentissage, seulement 4% sont sélectionnées, les autres étant
éliminées du modele sous l’action de la pénalité £1. Au total, apprendre un tel modele prend une
dizaine de minutes sur un gros serveur de calcul et la traduction du jeu de test ne demande que

4. Accessible depuis ncode . limsi . f r/ .
5. Accessible depuis www . ims . uni— stuttgart . de/ pro j ekte/ corp1ex/ TreeTagger/ .
6. Ces modéles sont similaires a ceux qui sont utilisés dans les systémes standard.

459 © ATALA

