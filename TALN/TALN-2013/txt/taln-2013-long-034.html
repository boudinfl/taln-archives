<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Annotation s&#233;mantique pour des domaines sp&#233;cialis&#233;s et des ontologies riches</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Annotation s&#233;mantique pour des domaines sp&#233;cialis&#233;s et des
ontologies riches
</p>
<p>Yue Ma1 Fran&#231;ois L&#233;vy2 Adeline Nazarenko2
(1) TU-Dresden, Germany
</p>
<p>(2) LIPN, Universit&#233; Paris 13-CNRS, France
mayue@tcs.inf.tu-dresden.de,
</p>
<p>{francois.levy,adeline.nazarenko}@lipn.univ-paris13.fr
</p>
<p>R&#201;SUM&#201;
Explorer et maintenir une documentation technique est une t&#226;che difficile pour laquelle on
pourrait b&#233;n&#233;ficier d&#8217;un outillage efficace, &#224; condition que les documents soient annot&#233;s s&#233;manti-
quement. Les annotations doivent &#234;tre riches, coh&#233;rentes, suffisamment sp&#233;cialis&#233;es et s&#8217;appuyer
sur un mod&#232;le s&#233;mantique explicite &#8211; habituellement une ontologie &#8211; qui mod&#233;lise la s&#233;mantique
du domaine cible. Il s&#8217;av&#232;re que les approches d&#8217;annotation traditionnelles donnent pour cette
t&#226;che des r&#233;sultats limit&#233;s. Nous proposons donc une nouvelle approche, l&#8217;annotation s&#233;mantique
statistique bas&#233;e sur les syntagmes, qui pr&#233;dit les annotations s&#233;mantiques &#224; partir d&#8217;un ensemble
d&#8217;apprentissage r&#233;duit. Cette mod&#233;lisation facilite l&#8217;annotation s&#233;mantique sp&#233;cialis&#233;e au regard
de mod&#232;les s&#233;mantiques de domaine arbitrairement riches. Nous l&#8217;&#233;valuons &#224; l&#8217;aide de plusieurs
m&#233;triques et sur deux textes d&#233;crivant des r&#233;glementations m&#233;tier. Notre approche obtient de
bons r&#233;sultats. En particulier, la F-mesure est de l&#8217;ordre de 91,9% et 97,6% pour la pr&#233;diction de
l&#8217;&#233;tiquette et de la position avec diff&#233;rents param&#232;tres. Cela sugg&#232;re que les annotateurs humains
peuvent &#234;tre fortement aid&#233;s pour l&#8217;annotation s&#233;mantique dans des domaines sp&#233;cifiques.
</p>
<p>ABSTRACT
Semantic Annotation in Specific Domains with rich Ontologies
</p>
<p>Technical documentations are generally difficult to explore and maintain. Powerful tools can
help, but they require that the documents have been semantically annotated. The annotations
must be sufficiently specialized, rich and consistent. They must rely on some explicit semantic
model &#8211; usually an ontology &#8211; that represents the semantics of the target domain. We observed
that traditional approaches have limited success on this task and we propose a novel approach,
phrase-based statistical semantic annotation, for predicting semantic annotations from a limited
training data set. Such a modeling makes the challenging problem, domain specific semantic
annotation regarding arbitrarily rich semantic models, easily handled. Our approach achieved a
good performance, with several evaluation metrics and on two different business regulatory texts.
In particular, it obtained 91.9% and 97.65% F-measure in the label and position predictions
with different settings. This suggests that human annotators can be highly supported in domain
specific semantic annotation tasks.
</p>
<p>MOTS-CL&#201;S : Annotation s&#233;mantique, Ontologie de domaine, Annotation automatique, Analyse
s&#233;mantique des textes, M&#233;thodes statistiques.
</p>
<p>KEYWORDS: Semantic Annotation, Domain Ontology, Automatic annotation, Semantic Text
Analysis, Statistical methods.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>464 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>1 Introduction
</p>
<p>Les documents techniques sont souvent complexes &#224; lire et &#224; maintenir mais ce sont des ressources
critiques pour de nombreuses organisations. Les textes r&#233;glementaires d&#233;crivent les proc&#233;dures,
les r&#232;gles et les politiques auxquels les organisations doivent se conformer ; ce sont des sources
importantes, qui guide souvent la prise de d&#233;cision dans ces organisations. Les instructions
d&#8217;utilisation indiquent comment utiliser et maintenir des objets techniques qui sont parfois
extr&#234;mement complexes. Les experts ont besoin d&#8217;outils pour les aider &#224; ma&#238;triser et &#224; valider ces
documents autant que pour les maintenir &#224; jour quand des &#233;volutions techniques se produisent.
Les textes sont de longueur variable (de quelques dizaines &#224; plusieurs centaines de pages), mais
souvent trop longs pour &#234;tre faciles &#224; lire, en particulier quand les informations importantes sont
dispers&#233;es dans diff&#233;rentes parties. Ils contiennent des descriptions g&#233;n&#233;riques plut&#244;t que des
exemples et reposent sur des vocabulaires sp&#233;cialis&#233;s, qui sont souvent d&#233;finis de fa&#231;on plus ou
moins formelle et pr&#233;cise dans des thesaurus ou des ontologies.
</p>
<p>Il est possible d&#8217;aider les experts qui consultent ces textes en leur fournissant des outils. Le b&#233;n&#233;fice
est plus important si les documents sources sont enrichis par des informations s&#233;mantiques
(ontologiques), qui assurent une certaine interop&#233;rabilit&#233; et qui permettent de faire des recherches
s&#233;mantiques plut&#244;t que de simples recherches de cha&#238;nes de caract&#232;res (Welty et Ide, 1999; Uren
et al., 2006; Nazarenko et al., 2011). L&#8217;annotation s&#233;mantique aide &#224; visualiser et &#224; rassembler
l&#8217;information importante, mais aussi &#224; contr&#244;ler la documentation technique (v&#233;rification de
coh&#233;rence, aide &#224; la d&#233;cision et tra&#231;abilit&#233;, mise &#224; jour, etc.).
</p>
<p>Des outils ont &#233;t&#233; d&#233;velopp&#233;s, tels que GATE (Cunningham et al., 2011) ou SemEx (Nazarenko
et al., 2011), pour explorer des textes dont certaines portions sont li&#233;es par des annotations &#224;
divers &#233;l&#233;ments d&#8217;un mod&#232;le s&#233;mantique de domaine. L&#8217;annotation s&#233;mantique automatique de
la documentation technique sp&#233;cialis&#233;e pr&#233;sente cependant deux caract&#233;ristiques importantes.
</p>
<p>En premier lieu, les annotations s&#233;mantiques int&#233;ressantes &#233;tiquettent souvent des notions
g&#233;n&#233;riques ou des concepts plut&#244;t que des mentions d&#8217;entit&#233;s mod&#233;lis&#233;es comme des instances
de concepts. Ceci diff&#232;re de la Reconnaissance des Entit&#233;s Nomm&#233;es (REN) qui vise &#224; rep&#233;rer
les instances de certains types s&#233;mantiques 1. Par exemple, dans le texte de la figure 1, le
fragment &#8220;Service conducting approval tests&#8221; est annot&#233; par le concept TestConductingService
et pas par l&#8217;une ses instances. Les notions g&#233;n&#233;riques susceptibles d&#8217;&#234;tre annot&#233;es sont plus
nombreuses que les types canoniques des entit&#233;s nomm&#233;es, et les approches d&#8217;annotation
s&#233;mantique traditionnelles sont handicap&#233;es dans ce cas par des caract&#233;ristiques moins r&#233;guli&#232;res
et des ressources plus rares. On observe que les m&#233;thodes d&#8217;annotation au regard d&#8217;une ontologie
se concentrent g&#233;n&#233;ralement sur les instances de concepts dans une perspective de peuplement
d&#8217;ontologies (Kiryakov et al., 2004; Amardeilh et al., 2005; Uren et al., 2006).
</p>
<p>FIGURE 1 &#8211; Exemple : texte r&#233;glementaire avec annotations s&#233;mantiques
</p>
<p>1. Typiquement : Personne, Organisation, Lieu, Temps.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>465 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>En second lieu, les ontologies g&#233;n&#233;riques (par ex. DBpedia) utilis&#233;es par de nombreux services
d&#8217;annotation s&#233;mantique ouverts sont peu utiles pour les documents techniques. Nous avons test&#233;
plusieurs d&#8217;entre elles sur un corpus traitant de la r&#233;glementation dans l&#8217;industrie automobile.
Quatre produisent tr&#232;s peu d&#8217;annotations : OpenCalais 2, Zemanta 3 et DBpedia Spotlight (Mendes
et al., 2011) ont des rappels de 3,3 %, 0,8 % et 0 % ; AlchemyAPI 4 reconna&#238;t la mention de deux
organisations 5 et d&#8217;une ville 6, mais deux de ces annotations sont manifestement erron&#233;es dans le
domaine consid&#233;r&#233;. A l&#8217;inverse, la Wiki Machine (LiveMemories, 2010) annote surabondamment
le r&#232;glement : dans le fragment &#8220;In the case of an assembly incorporating a retractor&#8221;, &#8220;case&#8221; est
annot&#233; par Law, Justice et &#8220;assembly&#8221; est li&#233; &#224; Parliamentary procedure et Meetings, mais ce n&#8217;est
pas le sens qu&#8217;ont ces termes dans nos donn&#233;es. Ces annotateurs du Web bas&#233;s sur des ontologies
publiques renvoient souvent une interpr&#233;tation trompeuse des textes sp&#233;cialis&#233;s.
</p>
<p>Nous en concluons qu&#8217;un syst&#232;me d&#8217;annotation s&#233;mantique des documents techniques devrait
avoir les propri&#233;t&#233;s suivantes : (1) pouvoir noter un concept et pas seulement des instances de
types g&#233;n&#233;raux comme signification d&#8217;un terme ; (2) fournir une interpr&#233;tation pr&#233;cise et fiable,
en tenant compte des mod&#232;les s&#233;mantiques du domaine trait&#233; ; (3) avoir une bonne couverture
du texte, de sorte que les fragments textuels int&#233;ressants puissent &#234;tre facilement d&#233;tect&#233;s et
reli&#233;s. Notre approche repose sur le constat qu&#8217;un expert m&#233;tier peut fournir un petit nombre
d&#8217;exemples annot&#233;s manuellement, mais ne peut pas annoter des documents volumineux. Nous
avons vu que les approches de l&#8217;&#233;tat de l&#8217;art r&#233;pondent mal &#224; ces sp&#233;cifications.
</p>
<p>Nous proposons donc une nouvelle approche d&#8217;annotation, &#224; la fois simple et naturelle, qui
s&#8217;inspire de la traduction automatique bas&#233;e sur les syntagmes et qui est adapt&#233;e &#224; l&#8217;annotation
sp&#233;cialis&#233;e requise par les textes techniques.
</p>
<p>Nous transposons le mod&#232;le de la traduction automatique statistique (TAS) bas&#233;e sur les syn-
tagmes &#224; notre probl&#232;me et nous montrons exp&#233;rimentalement, avec diff&#233;rentes m&#233;triques
d&#8217;&#233;valuation, que l&#8217;annotateur ainsi construit obtient des r&#233;sultats significatifs &#224; partir d&#8217;un corpus
r&#233;duit annot&#233; manuellement. Par effet de bord, il peut int&#233;grer dans un mod&#232;le unique les inter-
pr&#233;tations que diff&#233;rents experts auraient donn&#233;es du m&#234;me texte. Les exp&#233;riences rapport&#233;es
ici portent sur un r&#232;glement international sur le contr&#244;le des ceintures de s&#233;curit&#233; (par la suite
&#171; R&#232;glement des ceintures de s&#233;curit&#233; &#187;), auquel les constructeurs d&#8217;automobiles doivent se
conformer.
</p>
<p>Le reste de l&#8217;article est structur&#233; ainsi : nous discutons l&#8217;&#233;tat de l&#8217;art dans la section qui suit
et d&#233;finissons la t&#226;che dans la section 3. Puis notre m&#233;thode est d&#233;crite dans la section 4. Les
exp&#233;riences et leur &#233;valuation sont pr&#233;sent&#233;es dans les sections 5 et 6.
</p>
<p>2. http://www.opencalais.com
3. http://www.zemanta.com
4. http://www.alchemyapi.com
5. &#8220;cabinet&#8221; dans &#8220;... shall be placed in a refrigerated cabinet at -10 C + 1 C for two hours&#8221; et&#8220;Technical Service&#8221; dans
</p>
<p>&#8220;One of these axes shall be in the direction chosen by the Technical Service conducting the approval test&#8221;.
6. &#8220;anchorage&#8221; dans la phrase &#8220;except in the case of retractors having a pulley or strap guide at the upper belt
</p>
<p>anchorage&#8221;.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>466 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>2 Etat de l&#8217;art
</p>
<p>Les deux facettes de notre probl&#232;me, pr&#233;dire les labels s&#233;mantiques et les fronti&#232;res de ces
&#233;tiquettes, se retrouvent dans la REN (Nadeau et Sekine, 2007) et les annotateurs du Web
s&#233;mantique (Uren et al., 2006). Dans la REN, les &#233;tiquetages sont souvent limit&#233;s &#224; quelques
grandes cat&#233;gories g&#233;n&#233;riques comme Personne, Endroit, Organization, Produit, et Date. Quant
aux annotateurs du Web, dont les &#233;tiquetages proviennent g&#233;n&#233;ralement d&#8217;ontologies g&#233;n&#233;rales,
comme TAP (Dill et al., 2003), DBpedia Lexicalization Dataset 7), ils ne sont pas efficaces pour
les textes sp&#233;cialis&#233;s et des domaines diff&#233;rents. De plus, ils privil&#233;gient souvent la pr&#233;cision au
d&#233;triment du rappel, produisant moins de deux annotations par page en moyenne (Dill et al.,
2003; Mihalcea et Csomai, 2007; Cucerzan, 2007).
</p>
<p>Un premier type d&#8217;approches de l&#8217;annotation s&#233;mantique consiste &#224; appliquer des r&#232;gles sur des
segments s&#233;lectionn&#233;s par des wrappers (Ciravegna, 2003; Etzioni et al., 2004; Cimiano et al.,
2004). S&#8217;agissant d&#8217;une annotation s&#233;mantique pr&#233;cise et sp&#233;cialis&#233;e, il est difficile d&#8217;apprendre
des r&#232;gles pour chaque type d&#8217;annotation, &#224; cause du grand nombre de cat&#233;gories s&#233;mantiques.
De plus, les r&#232;gles sont souvent plus complexes que pour la REN, o&#249; les entit&#233;s cibles ont
g&#233;n&#233;ralement une forme particuli&#232;re (par ex. d&#233;butant par une majuscule) ou sont associ&#233;es &#224;
des d&#233;clencheurs comme un titre (par ex. &#171; M. &#187;, &#171; Le pr&#233;sident &#187;). Dans l&#8217;annotation sp&#233;cialis&#233;e,
les fragments de texte &#224; annoter sont tr&#232;s vari&#233;s et leurs fronti&#232;res sont difficiles &#224; identifier. Par
exemple, dans le r&#232;glement des ceintures de s&#233;curit&#233;, &#8220;tested according to paragraph 7.6.4.2.&#8221; a
&#233;t&#233; &#233;tiquet&#233; manuellement par Method (voir section 5).
</p>
<p>Une seconde famille d&#8217;approches d&#8217;annotation s&#233;mantique repose sur des mod&#232;les statistiques
ou l&#8217;apprentissage automatique (par ex. HMM (Zhou et Su, 2002; Ratinov et Roth, 2009), CRF
(Finkel et Manning, 2009), et Perceptron ou Winnow (Collins, 2002)). Ces approches exploitent
la richesse des ressources textuelles du Web (Dill et al., 2003; LiveMemories, 2010; Mendes
et al., 2011) ou de journaux (Nadeau et Sekine, 2007; Ratinov et Roth, 2009) comme donn&#233;es
d&#8217;entra&#238;nement pour la d&#233;sambigu&#239;sation. Le traitement de l&#8217;ambigu&#239;t&#233; est important quand on
consid&#232;re diff&#233;rents niveaux de granularit&#233; ontologique : selon le contexte, un terme comme
&#8220;test&quot; peut faire r&#233;f&#233;rence au concept g&#233;n&#233;nral Test, &#224; une cat&#233;gorie pr&#233;cise de tests o&#249; &#224; une
instance de test particuli&#232;re. Cependant, dans les domaines sp&#233;cialis&#233;s, on a rarement de gros
volumes de donn&#233;es. Notre approche repose sur un mod&#232;le statistique diff&#233;rent, qui prend en
compte la forme brute des textes (sans traitement linguistique pr&#233;alable) et montre de meilleures
performances que les champs al&#233;atoires conditionnels en cha&#238;nes lin&#233;aires (CRF) sur un petit
volume de donn&#233;es.
</p>
<p>Les recherches sur la REN dans des corpus sp&#233;cialis&#233;s (Wang, 2009; Liu et al., 2011) indiquent
qu&#8217;il faudrait entra&#238;ner des syst&#232;mes d&#8217;annotation sp&#233;cifiques m&#234;me dans le cas o&#249; le jeu d&#8217;&#233;ti-
quettes est le m&#234;me que pour la REN classique (Wang, 2009; Liu et al., 2011) quand le corpus
est sp&#233;cialis&#233; (ex. Tweet, notes cliniques). Le pr&#233;sent travail s&#8217;int&#233;resse aux cas o&#249; le corpus
et les jeux d&#8217;&#233;tiquettes sont sp&#233;cialis&#233;s, comme dans (Aronson et Lang, 2010; M&#252;ller et al.,
2004) qui proposent un entra&#238;nement sp&#233;cialis&#233; pour la biom&#233;dicine. A la diff&#233;rence de cette
approche qui est difficile &#224; adapter &#224; un autre domaine, notre m&#233;thode, fond&#233;e sur TAS, peut &#234;tre
facilement appliqu&#233;e sur un autre domaine sp&#233;cialis&#233; &#224; condition qu&#8217;un petit volume de donn&#233;es
d&#8217;entrainement annot&#233;es soit disponible.
</p>
<p>7. http://dbpedia.org/Lexicalizations
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>467 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Les mod&#232;les de TAS ont &#233;t&#233; appliqu&#233;s &#224; d&#8217;autres questions que la traduction, en particulier
&#224; la normalisation de textes et de SMS (Aw et al., 2006; Beaufort et al., 2010) et &#224; l&#8217;analyse
s&#233;mantique (Wong et Mooney, 2006). Selon ces auteurs, leurs r&#233;sultats, mesur&#233;s par les m&#233;triques
de traduction automatique, sont bons. S&#8217;agissant de l&#8217;annotation s&#233;mantique de documents
sp&#233;cialis&#233;s, nous adoptons nous aussi un mod&#232;le de TAS bas&#233;e sur les syntagmes, mais nous
l&#8217;&#233;valuons diff&#233;remment parce que les m&#233;triques de traduction automatique s&#8217;av&#232;rent limit&#233;es
pour notre t&#226;che.
</p>
<p>3 D&#233;finition de la t&#226;che
</p>
<p>On dispose d&#8217;une ontologie pour un domaine sp&#233;cialis&#233; dont le volet lexical est utilis&#233; pour
annoter un petit corpus d&#8217;entra&#238;nement. La t&#226;che consiste &#224; identifier &#224; la fois les fronti&#232;res et la
cat&#233;gorie ontologique des &#233;l&#233;ments s&#233;mantiques majeurs de chaque phrase du corpus &#224; annoter.
</p>
<p>En plus des termes sp&#233;cialis&#233;s qu&#8217;il est utile de d&#233;tecter et d&#8217;annoter, un autre probl&#232;me fr&#233;quent
pour l&#8217;annotation s&#233;mantique de documents techniques au regard d&#8217;une ontologie riche est qu&#8217;un
grand nombre de mots identiques en surface peuvent &#234;tre annot&#233;s avec plusieurs &#233;tiquettes
ontologiques qui ne sont pas logiquement disjointes comme c&#8217;est le cas dans l&#8217;homonymie, mais
qui refl&#232;tent simplement une granularit&#233; de sens variable en contexte. Par exemple, dans les
quatre phrases ci-dessous, &#171; test &#187; a &#233;t&#233; annot&#233; par l&#8217;expert comme BuckleTest &#224; trois reprises
(S1, S2 et S3) et Method une fois (S4). La r&#233;solution de l&#8217;ambigu&#239;t&#233; est importante pour le
succ&#232;s de cette t&#226;che.
S1. The force required to open the buckle in the test as prescribed in paragraph 7.8. below shall not
</p>
<p>exceed 6 daN.
S2. In the case of harness belt buckles, this test may be carried out without all the tongues being
</p>
<p>introduced.
S3. In the case of buckles which incorporate a component common to two assemblies, the strength
</p>
<p>and release tests of paragraphs 7.7. and 7.8. shall also be carried out with the part of the buckle
pertaining to one assembly being engaged in the mating part pertaining to the other, if it is possible
for the buckle to be so assembled in use.
</p>
<p>S4. Retractors shall be subjected to tests and shall fulfill the requirements specified below, including
the tests for strength prescribed in paragraphs 7.5.1. and 7.5.2.
</p>
<p>4 Annotation s&#233;mantique statistique bas&#233;e sur les syntagmes
</p>
<p>Nous mod&#233;lisons l&#8217;annotation s&#233;mantique des documents sp&#233;cialis&#233;s comme une t&#226;che de tra-
duction automatique ayant les caract&#233;ristiques suivantes : (1) les unit&#233;s textuelles pertinentes
pour traduire ou annoter sont des syntagmes plut&#244;t que de simples mots ; (2) de m&#234;me qu&#8217;un
mot peut &#234;tre traduit de diff&#233;rentes fa&#231;ons, on peut annoter un fragment de texte de plusieurs
mani&#232;res, des &#233;l&#233;ments ontologiques diff&#233;rents pouvant avoir des lexicalisations communes.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>468 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4.1 L&#8217;annotation s&#233;mantique en tant que traduction automatique
</p>
<p>Dans cette vision d&#8217;une annotation s&#233;mantique comme traduction, le texte initial non annot&#233; est
consid&#233;r&#233; comme le texte &#224; &#171; traduire &#187; et le texte annot&#233; comme le texte cible &#171; traduit &#187;.
</p>
<p>Formellement, on a deux phrases &#9001;s1, s2&#9002; dans deux &#171; langages &#187; L1 and L2 : L1 est ici l&#8217;anglais
et L2 = L1 &#8746; Voc(O) est l&#8217;union de l&#8217;anglais et du vocabulaire de l&#8217;ontologie, Voc(O), utilis&#233;
comme ensemble d&#8217;&#233;tiquettes 8. Nous disons que s2 est une version annot&#233;e de s1 s&#8217;il est obtenu
en rempla&#231;ant certains groupes de mots anglais de s1 par des &#233;l&#233;ments de Voc(O) comme illustr&#233;
dans la figure 2.
</p>
<p>disjoint
</p>
<p>If an AAdvantage  participant  agreement  changes 
or terminates,  you may find ...
</p>
<p>If an AAdvantage XXAirline_Participant agreement 
changes or terminates, you may find ...
</p>
<p>S1
</p>
<p>S2
</p>
<p>FIGURE 2 &#8211; L&#8217;annotation s&#233;mantique en tant que traduction
</p>
<p>D&#8217;apr&#232;s (Tomeh, 2012), la TAS a conceptuellement trois &#233;tapes 9 : 1) les phrases appari&#233;es sont
align&#233;es sur les mots &#8211; ou les syntagmes &#8211; pour constituer la relation de traduction qui sp&#233;cifie
quel &#233;l&#233;ment de s2 est la traduction de quel &#233;l&#233;ment de s1 ; 2) des r&#232;gles de traduction sont
apprises sur ces donn&#233;es, en g&#233;n&#233;ral en s&#8217;appuyant sur une table de traduction ; 3) chaque
phrase &#224; traduire est segment&#233;e en syntagmes qui sont traduits s&#233;par&#233;ment puis r&#233;ordonn&#233;s
pour adapter le r&#233;sultat au langage cible. Quand il s&#8217;agit d&#8217;annotation s&#233;mantique, la relation
de traduction est monotone (sans r&#233;arrangement). C&#8217;est m&#234;me l&#8217;identit&#233; pour tous les &#233;l&#233;ments
qui restent non-annot&#233;s. Les donn&#233;es en entr&#233;e de l&#8217;algorithme d&#8217;apprentissage sont donc moins
bruit&#233;es que dans le cas d&#8217;un alignement bilingue. L&#8217;obtention d&#8217;annotations correctes quand
l&#8217;information lexicale est ambig&#252;e repose sur l&#8217;algorithme d&#8217;apprentissage et la projection de
ses r&#233;sultats sur le texte, dans la mesure o&#249; cet algorithme prend en compte le contexte pour
apprendre les r&#232;gles. A noter que le mod&#232;le tient compte dans ses calculs des &#233;l&#233;ments qui ne
doivent pas &#234;tre annot&#233;s : il apprend aussi &#224; traduire &#224; l&#8217;identique.
</p>
<p>8. Pour diff&#233;rentier les &#233;l&#233;ments de Voc(O) du vocabulaire anglais, les noms de O sont pr&#233;fix&#233;s par &#8217;XX&#8217; dans L2.
9. M&#234;me si elles peuvent &#234;tre entrelac&#233;es dans le calcul.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>469 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4.2 Le mod&#232;le
</p>
<p>Notre approche repose sur le mod&#232;le du canal bruit&#233;, qui consid&#232;re que les phrases annot&#233;es
constituent l&#8217;information vis&#233;e (en entr&#233;e du canal) mais qu&#8217;elles ont &#233;t&#233; brouill&#233;es, produisant
ainsi le texte brut (re&#231;u en sortie). Il s&#8217;agit donc de reconstituer l&#8217;entr&#233;e. On attribue une &#233;tiquette
s&#233;mantique &#224; une phrase vue pour la premi&#232;re fois s1 &#8712; L1 en recherchant la phrase s2 &#8712; L2 qui a
la plus grande valeur pour P(s2|s1). Par la r&#232;gle de Bayes et puisque P(s1) est fix&#233;e, il s&#8217;agit de
calculer
</p>
<p>s&#8727; = argmax
s2
</p>
<p>P(s2|s1) = argmaxs2 {P(s2)P(s1|s2)}.
</p>
<p>Suivant le mod&#232;le de traduction bas&#233; sur les syntagmes, la phrase d&#8217;entr&#233;e non annot&#233;e s1 est
segment&#233;e pendant le d&#233;codage en une suite de m syntagmes, not&#233;e {si1}mi=1. Chaque segment
si1 est associ&#233; &#224; sa version annot&#233;e s
</p>
<p>i
2 de sorte que P(s1|s2) = &#928;mi=1P(si1|si2). On suppose que la
</p>
<p>distribution de probabilit&#233; sur toutes les segmentations possibles est uniforme et on a
</p>
<p>s&#8727; = argmax
s2
</p>
<p>{P(s2)&#215;&#928;mi=1P(si1|si2)}.
</p>
<p>Il y a deux param&#232;tres &#224; calculer dans le mod&#232;le ci-dessus : le mod&#232;le de langage P(s2) et la table
de traduction des syntagmes P(si1|si2). Le mod&#232;le de langage s&#233;lectionne la phrase annot&#233;e la
plus probable parmi toutes celles qui sont possibles et la table de traduction des syntagmes joue
le r&#244;le d&#8217;un dictionnaire sophistiqu&#233; entre les langages source et cible. Nous ne pouvons entrer
ici dans les d&#233;tails, mais, pour nos exp&#233;rimentations, nous utilisons SRILM (Stolcke, 2002), la
boite &#224; outils du SRI servant &#224; construire et exploiter des mod&#232;les de langage, pour apprendre
un mod&#232;le de trigrammes. Parmi les nombreuses solutions propos&#233;es pour l&#8217;apprentissage d&#8217;une
table de traduction (Marcu et Wong, 2002; Koehn et al., 2003; Och et Ney, 2003; Chiang, 2007),
nous utilisons la m&#233;thode relativement simple mais efficace d&#233;finie dans (Koehn et al., 2003). A
cause de la proximit&#233; des langages source et cible, les donn&#233;es fournies &#224; cet algorithme sont peu
bruit&#233;es. Le d&#233;codage est r&#233;alis&#233; par une recherche en faisceau telle qu&#8217;impl&#233;ment&#233;e par Moses
(Koehn et al., 2007).
</p>
<p>4.3 Rep&#233;rage des annotations s&#233;mantiques
</p>
<p>Pour identifier la position pr&#233;cise des annotations s&#233;mantiques pr&#233;dites par l&#8217;annotation s&#233;man-
tique statistique bas&#233;e sur les syntagmes (ASSS), nous utilisons l&#8217;alignement des traductions au
niveau du mot. Par exemple, dans un tel alignement, la suite &#8220;15-14 16-14&#8221; indique que les 15&#232;me
et 16&#232;me mots de la phrase originale ont &#233;t&#233; remplac&#233;s par le 14&#232;me mot de la traduction. Si le
14&#232;me mot appartient &#224; Voc(O) (par exemple XXMethod), c&#8217;est que le concept qui la compose
(dans notre exemple, le concept Method) est l&#8217;&#233;tiquette s&#233;mantique associ&#233;e au 15&#232;me et au 16&#232;me
mots de la phrase originale.
</p>
<p>5 Exp&#233;rimentation
</p>
<p>Cette section d&#233;crit les donn&#233;es d&#8217;&#233;valuation et les m&#233;triques utilis&#233;es.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>470 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>L&#8217;approche ASSS a &#233;t&#233; test&#233;e sur deux textes annot&#233;s. L&#8217;un est compl&#232;tement annot&#233;, c&#8217;est-&#224;-dire
annot&#233; par l&#8217;ensemble des &#233;tiquettes s&#233;mantiques provenant d&#8217;une ontologie construite pour le
domaine en question. On trouve dans le texte des mentions de chaque concept, mais en nombre
limit&#233; : ce corpus permet de tester la tol&#233;rance de notre approche &#224; la dispersion des donn&#233;es
d&#8217;annotation s&#233;mantique. L&#8217;autre texte est plus volumineux mais il n&#8217;est annot&#233; que par une partie
de l&#8217;ontologie, par les 17 concepts identifi&#233;s consid&#233;r&#233;s comme ambigus, car &#233;tant associ&#233;s &#224; des
termes ambigus. Ce second corpus permet de tester la capacit&#233; de notre approche &#224; r&#233;soudre les
ambigu&#239;t&#233;s, qui sont fr&#233;quentes en domaine de sp&#233;cialit&#233;, ne serait-ce parce qu&#8217;on peut choisir de
rattacher un terme &#224; diff&#233;rents niveaux de l&#8217;ontologie.
</p>
<p>Deux m&#233;thodes de r&#233;f&#233;rence ont &#233;t&#233; d&#233;finies et sont utilis&#233;es pour les exp&#233;riences. La premi&#232;re
est une approche &#224; base de dictionnaire de fr&#233;quence qui est traditionnelle pour les t&#226;ches de
d&#233;sambigu&#239;sation lexicale et qui peut s&#8217;&#233;tendre &#224; notre sc&#233;nario d&#8217;annotation s&#233;mantique. L&#8217;autre
repose sur un mod&#232;le bas&#233; sur l&#8217;&#233;tiquetage de s&#233;quences, plus particuli&#232;rement sur les champs
al&#233;atoires conditionnels en cha&#238;nes lin&#233;aires (CRF) (Lafferty, 2001; Sutton et Mccallum, 2006)) :
l&#8217;annotation s&#233;mantique est souvent vue comme une t&#226;che d&#8217;&#233;tiquetage de s&#233;quences et les
champs al&#233;atoires conditionnels permettent de tenir compte des noeuds voisins dans un graphe.
L&#8217;&#233;valuation exp&#233;rimentale montre que notre m&#233;thode d&#233;passe significativement des approches
standards sur les deux corpus utilis&#233;s.
</p>
<p>5.1 Donn&#233;es d&#8217;&#233;valuation
</p>
<p>Mat&#233;riel 10 Les corpus choisis sont deux textes extraits d&#8217;un r&#232;glement international d&#233;crivant les
tests auxquels les fabricants d&#8217;automobiles doivent se plier dans la fabrication des ceintures de
s&#233;curit&#233;. Apr&#232;s segmentation par Treetagger (Schmid, 1995), le corpus 1 comporte 133 phrases et
le corpus 2 en a 1821, dont beaucoup sont longues. L&#8217;ontologie 11 qui forme le mod&#232;le s&#233;mantique
contient 154 entit&#233;s s&#233;mantiques (73 concepts, 58 individus, 23 propri&#233;t&#233;s).
</p>
<p>Annotation s&#233;mantique le corpus 1 a &#233;t&#233; compl&#232;tement annot&#233; par un expert du domaine (un
des auteurs), soit 364 annotations (2,78 annotations par phrase). Pour la validation crois&#233;e, 90 %
des donn&#233;es sont utilis&#233;es comme donn&#233;es d&#8217;entra&#238;nement (80 % servent &#224; entrainer le mod&#232;le,
et 10 % au tunning) et les 10 % restant sont utilis&#233;es comme donn&#233;es de test. Les donn&#233;es
d&#8217;entra&#238;nement de chaque exp&#233;rience comportent plus de 50 entr&#233;es s&#233;mantiques distinctes.
</p>
<p>Deux facteurs principaux ont &#233;t&#233; pris en compte dans la constitution du corpus 2 : le degr&#233;
d&#8217;ambigu&#239;t&#233; (une m&#234;me forme lexicale peut &#234;tre annot&#233;e diff&#233;remment dans des contextes
diff&#233;rents &#8211; voir la section 3 pour un exemple) et la taille du corpus, de fa&#231;on que notre seconde
m&#233;thode de r&#233;f&#233;rence puisse &#234;tre calcul&#233;e en un temps raisonnable eu &#233;gard &#224; nos ressources de
calcul (Mac OS X 10.6.8, g++ 4.2.1, avec 2Go de m&#233;moire et un CPU Intel Core 2 Duo 2.26GHz).
Nous avons s&#233;lectionn&#233; 17 entit&#233;s s&#233;mantiques ambigu&#235;s de l&#8217;ontologie, nous nous en sommes
servis pour annoter le document entier et nous avons s&#233;lectionn&#233; les 313 phrases &#233;tiquet&#233;es au
moins une fois.
</p>
<p>Pour le corpus 2, la table 1 liste les graphies choisies, le nombre de leurs occurrences annot&#233;es et
les 17 &#233;tiquettes s&#233;mantiques qui leur sont associ&#233;es. Il y a aussi 14 occurrences suppl&#233;mentaires
</p>
<p>10. Ce mat&#233;riel vient du projet europ&#233;en OntoRule.
11. A noter que, une fois que les exemples annot&#233;s sont disponibles, notre m&#233;thode n&#8217;a plus besoin de l&#8217;ontologie.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>471 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Graphie #Occ Etiquettes possibles dans la r&#233;f&#233;rence
</p>
<p>&#8220;type&#8221; 123 T ypeReactor, T ypeRet ractor, T ypeBel t
</p>
<p>&#8220;tested&#8221; 29
Ret ractor LockingTest, BreakingSt reng thO f St rapTest,
DynamicTest, Method, Cold ImpactTest, NULL
</p>
<p>&#8220;Test(s)&#8221; 19 DynamicTest,Method
</p>
<p>&#8220;tests&#8221; 65
DynamicTest, Ret ractorDurabil i t yTest, Method,
BreakingSt reng thO f St rapTest, Accelerat ionTest,
Decelerat ionTest, Ret ractor LockingTest, BuckleTest
</p>
<p>&#8220;test&#8221; 190
</p>
<p>Cold ImpactTest, Ret ractor LockingTest,
Method, MicroSlipTest, BuckleOpeningTest,
BreakingSt reng thO f St rapTest, DynamicTest, BuckleTest,
CorrosionTest, Ret ractorUnlockingTest, F rontal ImpactTest
</p>
<p>TABLE 1 &#8211; Description des ambigu&#239;t&#233;s du corpus2
</p>
<p>de &#171; tested &#187; non annot&#233;es (not&#233;es NULL en ligne 2, colonne 3), ce qui constitue une forme
particuli&#232;re d&#8217;ambigu&#239;t&#233;.
</p>
<p>5.2 Annotations de r&#233;f&#233;rence
</p>
<p>Nous comparons l&#8217;approche propos&#233;e avec deux m&#233;thodes de r&#233;f&#233;rence : l&#8217;Annotation S&#233;mantique
&#224; base de Dictionnaire et de Fr&#233;quence (ASDF) et l&#8217;Annotation S&#233;mantique par CRF (ASCRF).
</p>
<p>L&#8217;approche ASDF est une extension de la d&#233;sambigu&#239;sation lexicale classique parce qu&#8217;elle int&#232;gre
le fait qu&#8217;une annotation peut couvrir plusieurs mots. L&#8217;ASDF repose essentiellement sur la
construction et la consultation d&#8217;un dictionnaire d&#8217;annotation. Celui-ci a comme entr&#233;es des
mots ou groupes de mots associ&#233;s &#224; des labels s&#233;mantiques. Ces groupes sont extraits des textes
annot&#233;s d&#8217;entra&#238;nement, et pour chaque mot ou groupe de mots, les labels s&#233;mantiques qui
annotent ses occurrences sont enregistr&#233;s dans le dictionnaire. L&#8217;entr&#233;e est lemmatis&#233;e pour
s&#8217;affranchir des variations morphologiques. L&#8217;algorithme d&#8217;annotation cherche d&#8217;abord dans le
texte lemmatis&#233; les entr&#233;es du dictionnaire. Une forme de surface reconnue pouvant &#234;tre incluse
dans une autre, seules les entit&#233;s s&#233;mantiques attach&#233;es &#224; la plus longue sont conserv&#233;es. Pour
d&#233;sambigu&#239;ser une entr&#233;e donn&#233;e, on choisit le label le plus fr&#233;quent. ASDF est impl&#233;ment&#233;e en
Python.
</p>
<p>ASCRF segmente et annote les s&#233;quences de mots gr&#226;ce au mod&#232;le discriminant suivant :
</p>
<p>p&#952; (y | x) = 1Z&#952; (x) exp{
K&#65535;
</p>
<p>k=1
</p>
<p>&#952;kFk(x , y)},
</p>
<p>o&#249; x = (x1, ...xT ) et y = (y1, ..., yT ) sont les s&#233;quences d&#8217;entr&#233;e et de sortie ; Fk(x , y) est
d&#233;fini par
</p>
<p>&#65535;T
t=1 fk(xt&#8722;1, yt), { fk}1&#8804;k&#8804;K &#233;tant un ensemble arbitraire de fonctions de traits ; les{&#952;k}k&#8804;k&#8804;K sont les valeurs param&#233;triques associ&#233;es.
</p>
<p>Pour &#234;tre comparables avec le mod&#232;le ASSS propos&#233;, les patrons extraits par ASCRF sont des
traits orthographiques et lexicaux des unigrammes et des bigrammes figurant dans une fen&#234;tre
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>472 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>de 3 mots avant et apr&#232;s chaque position observ&#233;e. Comme les annotations s&#8217;&#233;tendent &#233;ventuel-
lement sur plusieurs mots, elles sont repr&#233;sent&#233;es selon le sch&#232;me D.I.E. (le D&#233;but, l&#8217;Int&#233;rieur
et l&#8217;Ext&#233;rieur du segment de texte. Enfin, ASCRF est mis en &#339;uvre gr&#226;ce &#224; l&#8217;impl&#233;mentation
hautement optimis&#233;e de la boite &#224; outils Wapiti (Lavergne et al., 2010).
</p>
<p>5.3 M&#233;triques d&#8217;&#233;valuation
</p>
<p>Bien que nous utilisions un mod&#232;le de traduction automatique, le syst&#232;me est &#233;valu&#233; en calculant
la pr&#233;cision, le rappel et la F-mesure, qui sont plus souvent utilis&#233;s dans le domaine de l&#8217;extraction
d&#8217;information. Nous consid&#233;rons en outre deux crit&#232;res diff&#233;rents : la correction des &#233;tiquettes
s&#233;mantiques (label) et celle de leurs fronti&#232;res (position). Bien que seul le crit&#232;re d&#8217;&#233;tiquette im-
porte dans certaines applications, comme en REN, la position peut &#234;tre significative dans d&#8217;autres
cas, comme par exemple pour l&#8217;extraction de relations s&#233;mantiques. On peut former d&#8217;autres
mesures par combinaison des pr&#233;c&#233;dentes, comme label et position consid&#233;r&#233;s ind&#233;pendamment
(le score cumule l&#8217;&#233;valuation des labels et des positions) et label et position consid&#233;r&#233;s group&#233;s.
Dans ce dernier cas, c&#8217;est le couple (label, position) qui est consid&#233;r&#233; globalement comme correct
ou incorrect.
</p>
<p>Pour chaque m&#233;trique &#181; parmi {Pr&#233;cision, Rappel, F-mesure}, nous &#233;crivons &#181;-label, &#181;-posi t ion,
&#181;-indep, et &#181;-couple pour d&#233;signer les quatre crit&#232;res d&#8217;&#233;valuation ci-dessus 12. Pour &#181;-posi t ion,
le crit&#232;re est l&#8217;identit&#233; des positions de l&#8217;annotation dans le candidat et la r&#233;f&#233;rence, m&#234;me si on
pourrait aussi tenir compte du recouvrement partiels des positions.
</p>
<p>6 Evaluation
</p>
<p>Dans cette section, nous comparons d&#8217;abord la m&#233;thode ASSS propos&#233;e et le syst&#232;me ASDF.
Ensuite, nous comparons ASSS et ASCRF sur les m&#234;me corpus sous des r&#233;glages diff&#233;rents. Pour
ces deux comparaisons, les exp&#233;riences ont &#233;t&#233; effectu&#233;es sur les deux corpus en utilisant une
validation crois&#233;e par 10&#232;me. Pour ASCRF, nous avons partiellement r&#233;utilis&#233; la mise en &#339;uvre de
MOSES (Koehn et al., 2007) en inactivant son mod&#232;le de distorsion.
</p>
<p>6.1 Comparaison de ASSS et ASDF sur le corpus 1
</p>
<p>Le tableau 2 compare les performances moyennes de ASDF et ASSS sur le corpus 1 et les confronte
&#224; ceux de l&#8217;approche hybride d&#233;finie ci-apr&#232;s.
</p>
<p>ASSS a &#233;t&#233; l&#233;g&#232;rement meilleur pour la pr&#233;diction des &#233;tiquettes que ASDF (0,26 % d&#8217;am&#233;lioration
de la F-mesure), mais ASDF a fonctionn&#233; mieux qu&#8217;ASSS dans la pr&#233;diction des positions (+5,2 %
sur la F-mesure). Les deux syst&#232;mes ont r&#233;alis&#233; des performances comparables sur le corpus 1.
</p>
<p>Cela signifie que si l&#8217;on ne consid&#232;re que les labels d&#8217;annotations, la m&#233;thode ASSS est un meilleur
choix : contrairement &#224; la consultation de dictionnaires, ASSS permet une correspondance
approch&#233;e. Cependant, ASSS manque plus souvent l&#8217;emplacement exact de l&#8217;&#233;tiquette. Par
</p>
<p>12. Dans la section Exp&#233;rimentation, &#181;-indep et &#181;-couple ne figurent qu&#8217;&#224; titre d&#8217;explication ; en fait ces mesures sont
des combinaisons des deux autres.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>473 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#233;trique ASDF ASSS Hybride
F-mesure d&#8217;&#233;tiquette 0,9885 0,9911 0,9911
F-mesure de position 0,9858 0,9369 0,9797
</p>
<p>TABLE 2 &#8211; Evaluation de la ASSS et ASDF sur Corpus1
</p>
<p>exemple, alors que la phrase &#8220;The test has to be performed separately from the tensile test&#8221; a &#233;t&#233;
annot&#233;e avec Tensiletest pour la position | 9 - 10 | par l&#8217;expert, ASSS n&#8217;a associ&#233; l&#8217;&#233;tiquetage
Tensiletest qu&#8217;&#224; la position | 9 - 9 | 13. Pour rem&#233;dier &#224; cela, nous faisons une combinaison de
ASSS et ASDF pour avoir un syst&#232;me hybride (la 4&#232;me colonne du tableau 2) d&#233;fini comme suit :
</p>
<p>D&#233;finition. (Hybride de ASSS et ASDF) Pour une phrase donn&#233;e, soit ANNOASSS et ANNOASDF
les annotations s&#233;mantiques g&#233;n&#233;r&#233;es respectivement par ASSS et ASDF. Nous disons que deux
annotations provenant de ANNOASSS et ANNOASDF sont unifiables si leurs positions se chevauchent.
</p>
<p>Dans le tableau 2, nous pouvons voir que le syst&#232;me hybride a la m&#234;me F-mesure de label et a
am&#233;lior&#233; la F-mesure de position d&#8217;ASSS de 4,28 %, m&#234;me si cette derni&#232;re est encore inf&#233;rieure
de 0,61 % &#224; celle d&#8217;ASDF.
</p>
<p>6.2 Comparaison d&#8217;ASSS et ASDF sur le corpus 2
</p>
<p>Le tableau 3 montre l&#8217;int&#233;r&#234;t de l&#8217;approche ASSS en cas d&#8217;ambigu&#239;t&#233;. ASSSall signifie que
l&#8217;exp&#233;rience a &#233;t&#233; r&#233;alis&#233;e sur les 313 phrases du Corpus 2 (s&#233;lectionn&#233;es pour la pr&#233;sence
de syntagmes ambigus) mais qu&#8217;elles sont annot&#233;es avec toutes les entr&#233;es s&#233;mantiques possibles
de l&#8217;ontologie. Nous pouvons voir qu&#8217;ASSS est robuste &#224; l&#8217;ambigu&#239;t&#233;, comme en t&#233;moigne la
F-mesure de label &#224; 92,95 %.
</p>
<p>Une autre observation est que, sauf pour la perte de 1,04 % de rappel de position, ASSS a de
meilleures performances qu&#8217;ASDF. En effet, les diff&#233;rences entre ASSS et ASDF sont importantes
pour la pr&#233;diction des &#233;tiquettes (par exemple +21,17 % pour la F-mesure de label), mais assez
faibles pour la pr&#233;diction des positions (par exemple +2,21 % pour la F-mesure de position).
L&#8217;explication est que le choix des annotations appropri&#233;es est plus difficile que la localisation de
ces annotations dans le corpus 2, en raison d&#8217;une plus grande proportion d&#8217;ambigu&#239;t&#233;s dans le
corpus 2 que dans le corpus 1.
</p>
<p>Enfin, le tableau 3 montre que m&#234;me si ASSS a obtenu des scores &#233;lev&#233;s dans la pr&#233;diction
de label sur le corpus 2, les scores sont encore inf&#233;rieurs &#224; ceux de la position (par exemple
une F-mesure de 92,95 % en pr&#233;diction de label vs. 97,65 % en pr&#233;diction de position), ce qui
contredit le r&#233;sultat du corpus 1. C&#8217;est encore parce que dans le corpus 2, la d&#233;sambigu&#239;sation
d&#8217;&#233;tiquettes est plus difficile &#224; r&#233;aliser que d&#233;tection de la position.
</p>
<p>Il convient enfin de noter que l&#8217;approche ASSS fonctionnant mieux en pr&#233;diction de position
qu&#8217;ASDF (97,65 % contre 95,44% pour la F-mesure de position) pour le corpus 2, l&#8217;approche
hybride consid&#233;r&#233;e pour le corpus 1 est inutile pour le corpus 2.
</p>
<p>13. On rappelle que, dans nos d&#233;finitions, seules les positions exactes (m&#234;mes d&#233;but et fin) sont compt&#233;es correctes
dans la F-mesure.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>474 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>M&#233;triques ASDF ASSSall ASSSall -ASDF
Pr&#233;cision-groupe 0,7288 0,9369 0,2081
Pr&#233;cision-label 0,7525 0,9369 0,1844
Pr&#233;cision-indep 0,8613 0,9598 0,0985
Pr&#233;cision-position 0,9293 0,9826 0,0533
Rappel-groupe 0,7699 0,9222 0,1523
Rappel-label 0,6861 0,9222 0,2361
Rappel-indep 0,9029 0,9464 0,0435
Rappel-position 0,9809 0,9705 -0,0104
F-mesure-label 0,7178 0,9295 0,2117
F-mesure-position 0,9544 0,9765 0,0221
</p>
<p>TABLE 3 &#8211; Evaluation d&#8217;ASSS et ASDF sur le corpus 2
</p>
<p>6.3 Comparaison d&#8217;ASSS et ASCRF
</p>
<p>Le tableau 4 compare les performances moyennes d&#8217;ASCRF et de&#8217;ASSS &#224; la fois sur le corpus 1 et
sur le corpus 2. A la diff&#233;rence d&#8217;ASSStous dans le tableau 3, ASSS17 et ASCRF17 correspondent
au cas o&#249; les 313 phrases s&#233;lectionn&#233;es dans le corpus 2 ne sont annot&#233;es que par les 17 entr&#233;es
s&#233;mantiques ambig&#252;es, ceci pour r&#233;duire le temps d&#8217;ex&#233;cution d&#8217;ASCRF 14. Les r&#233;sultats montrent
que :
&#8211; Sur le corpus 1, ASSS a supplant&#233; ASCRF pour toutes les mesures. C&#8217;est parce que la taille des
</p>
<p>donn&#233;es d&#8217;entra&#238;nement dans le corpus 1 n&#8217;est pas suffisante pour qu&#8217;ASCRF parvienne &#224; une
pr&#233;diction pr&#233;cise. La comparaison avec la tableau 2 montre qu&#8217;ASCRF a fonctionn&#233; bien plus
mal qu&#8217;ASDF sur le corpus 1. Cela signifie qu&#8217;ASSS est plus robuste qu&#8217;ASCRF lorsque la taille
des donn&#233;es d&#8217;entra&#238;nement est limit&#233;e.
</p>
<p>&#8211; Sur le corpus 2, ASSS17 a surpass&#233; ASCRF17 de plus de 8 % pour la pr&#233;diction des &#233;tiquettes, &#224;
la fois en pr&#233;cision et en rappel, mais a &#233;t&#233; surpass&#233; de 1,71 % en pr&#233;cision dans la pr&#233;diction
de position. Cela montre qu&#8217;ASSS a une plus forte capacit&#233; de d&#233;sambigu&#239;sation qu&#8217;ASCRF,
mais est moins bon qu&#8217;ASCRF pour placer les annotations parce que le mod&#232;le des positions
d&#8217;&#233;tiquettes est implicite pour ASSS. De plus, il est int&#233;ressant de noter que les deux approches
ASSS et ASCRF ont obtenu des scores relativement &#233;lev&#233;s en pr&#233;diction de position pour le
corpus 2 (&gt; 94 % en pr&#233;cision et en rappel).
</p>
<p>&#8211; ASSSall a une meilleure performance que ASCRF17 et ASSS17 sur le corpus 2. Cela montre
que le pourcentage plus &#233;lev&#233; d&#8217;ambigu&#239;t&#233;s dans les corpus ASCRF17 et ASSS17 augmente la
difficult&#233; de la t&#226;che.
</p>
<p>7 Conclusion et perspectives
</p>
<p>Cet article propose une approche statistique bas&#233;e sur les syntagmes, nouvelle et flexible, qui
permet d&#8217;annoter les entit&#233;s s&#233;mantiques dans des documents sp&#233;cialis&#233;s en utilisant des onto-
</p>
<p>14. Pour ASCRF, l&#8217;ex&#233;cution de la validation crois&#233;e au 10&#232;me a dur&#233; 30 heures en se limitant aux 17 entr&#233;es s&#233;man-
tiques ambig&#252;es. Traiter toutes les entr&#233;es comme pour ASSStous aurait n&#233;cessit&#233; beaucoup plus de temps parce que
l&#8217;entra&#238;nement d&#8217;un mod&#232;le de CRF est quadratique en le nombre d&#8217;&#233;tiquettes (Lavergne et al., 2011).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>475 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>l Corpus 1 Corpus 2
M&#233;trique ASCRF ASSS ASCRF17 ASSS17 ASSSall
Pr&#233;cision-label 0,8239 0,9889 0,8299 0,9142 0,9369
Pr&#233;cision-position 0,8975 0,9389 0,9577 0,9406 0,9826
Rappel-label 0,8239 0,9889 0,8308 0,9235 0,9222
Rappel-position 0,8975 0,9349 0,9588 0,9518 0,9705
</p>
<p>TABLE 4 &#8211; Evaluation de ASSS et ASCRF
</p>
<p>logies de domaine riches. La m&#233;thode a &#233;t&#233; con&#231;ue pour des documents techniques, tels que
des textes r&#233;glementaires, pour lesquels les approches traditionnelles d&#8217;&#233;tiquetage s&#233;mantique
(&#233;tiquetage des entit&#233;s nomm&#233;es et annotation s&#233;mantique g&#233;n&#233;rique) pr&#233;sentent des limitations
importantes. En utilisant plusieurs m&#233;triques d&#8217;&#233;valuation, nous avons montr&#233; que la m&#233;thode
propos&#233;e donne de meilleurs r&#233;sultats qu&#8217;une approche classique &#224; base de dictionnaire de
fr&#233;quence ou qu&#8217;une approche discriminante, avec un ensemble r&#233;duit d&#8217;exemples annot&#233;s. Elle
obtient des scores &#233;lev&#233;s sur le corpus ambigu : une F-mesure de 92,95 % (resp. 97,65 %) pour la
pr&#233;diction de label (resp. de position) pour ASSSall , et une F-mesure de 91.88% (resp. 94,62 %)
pour la pr&#233;diction de label (resp. de position) pour ASSS17
</p>
<p>Nous projetons maintenant d&#8217;am&#233;liorer notre approche en &#233;tendant ASSS pour utiliser des infor-
mations linguistiques rendues accessibles en pr&#233;-traitant les documents source. Nous envisageons
aussi de concevoir des campagnes d&#8217;annotation ontologique dans des domaines sp&#233;cialis&#233;s, en
exploitant cette m&#233;thode qui permet d&#8217;entra&#238;ner un syst&#232;me d&#8217;annotation sur un petit ensemble
d&#8217;annotations manuelles. En effet, il semble qu&#8217;il soit plus facile pour les annotateurs humains de
corriger une annotation initiale, pourvu qu&#8217;elle soit suffisamment bonne, que d&#8217;annoter &#224; partir
de rien (Fort et Sagot, 2010).
</p>
<p>Remerciements
</p>
<p>Ce travail a &#233;t&#233; partiellement financ&#233; par OSEO dans le cadre du programme Qu&#230;ro. Il s&#8217;inscrit
&#233;galement dans l&#8217;axe 5 du labex EFL (ANR/CGI).
</p>
<p>R&#233;f&#233;rences
</p>
<p>AMARDEILH, F., LAUBLET, P. et MINEL, J.-L. (2005). Document annotation and ontology population
from linguistic extractions. In Proceedings of the 3rd international conference on Knowledge
capture (K-CAP &#8217;05), pages 161&#8211;168, New York, NY, USA. ACM.
ARONSON, A. R. et LANG, F.-M. (2010). An overview of metamap : historical perspective and
recent advances. JAMIA, 17(3):229&#8211;236.
AW, A., ZHANG, M., XIAO, J. et SU, J. (2006). A phrase-based statistical model for sms text
normalization. In Proceedings of COLING-ACL &#8217;06 poster sessions, pages 33&#8211;40.
BEAUFORT, R., ROEKHAUT, S., COUGNON, L.-A. et FAIRON, C. (2010). A hybrid rule/model-based
finite-state framework for normalizing sms messages. In ACL, pages 770&#8211;779.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>476 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>CHIANG, D. (2007). Hierarchical phrase-based translation. Comput. Linguist., 33:201&#8211;228.
CIMIANO, P., HANDSCHUH, S. et STAAB, S. (2004). Towards the self-annotating web. In Proceedings
of WWW&#8217;04, pages 462&#8211;471.
CIRAVEGNA, F. (2003). (lp) : Rule induction for information extraction using linguistic constraints.
Rapport technique, Sheffield university.
</p>
<p>COLLINS, M. (2002). Discriminative training methods for hidden markov models : theory and
experiments with perceptron algorithms. In Proceedings of EMNLP&#8217;02, pages 1&#8211;8.
CUCERZAN, S. (2007). Large-scale named entity disambiguation based on wikipedia data. In
Proceedings of EMNLP-CoNLL&#8217;07, pages 708&#8211;716.
CUNNINGHAM, H., MAYNARD, D., BONTCHEVA, K., TABLAN, V., ASWANI, N., ROBERTS, I., GORRELL, G.,
FUNK, A., ROBERTS, A., DAMLJANOVIC, D., HEITZ, T., GREENWOOD, M. A., SAGGION, H., PETRAK, J.,
LI, Y. et PETERS, W. (2011). Text Processing with GATE (Version 6).
DILL, S., EIRON, N., GIBSON, D., GRUHL, D., GUHA, R., JHINGRAN, A., KANUNGO, T., RAJAGOPALAN,
S., TOMKINS, A., TOMLIN, J. A. et ZIEN, J. Y. (2003). Semtag and seeker : bootstrapping the
semantic web via automated semantic annotation. In Proceedings of WWW &#8217;03, pages 178&#8211;186.
ETZIONI, O., CAFARELLA, M., DOWNEY, D., KOK, S., POPESCU, A.-M., SHAKED, T., SODERLAND, S.,
WELD, D. S. et YATES, A. (2004). Web-scale information extraction in knowitall (preliminary
results). In Proceedings of WWW&#8217;04, pages 100&#8211;110.
FINKEL, J. R. et MANNING, C. D. (2009). Nested named entity recognition. In EMNLP &#8217;09, pages
141&#8211;150.
</p>
<p>FORT, K. et SAGOT, B. (2010). Influence of Pre-annotation on POS-tagged Corpus Development.
In ACL 4th Linguistic Annotation Workshop (LAW 2010), pages 56&#8211;63, Uppsala, Su&#232;de. Quaero
(en partie).
</p>
<p>KIRYAKOV, A., POPOV, B., TERZIEV, I., MANOV, D. et OGNYANOFF, D. (2004). Semantic annotation,
indexing, and retrieval. Journal of Web Semantics, 2:49&#8211;79.
KOEHN, P., HOANG, H., BIRCH, A., CALLISON-BURCH, C., FEDERICO, M., BERTOLDI, N., COWAN, B.,
SHEN, W., MORAN, C., ZENS, R., DYER, C., BOJAR, O., CONSTANTIN, A. et HERBST, E. (2007). Moses :
Open source toolkit for statistical machine translation. In Proceedings of ACL&#8217;07, pages 177&#8211;180.
KOEHN, P., OCH, F. J. et MARCU, D. (2003). Statistical phrase-based translation. In HLT-NAACL,
pages 127&#8211;133.
</p>
<p>LAFFERTY, J. (2001). Conditional random fields : Probabilistic models for segmenting and
labeling sequence data. In Proceedings of the International Conference on Machine Learning,
pages 282&#8211;289. Morgan Kaufmann.
</p>
<p>LAVERGNE, T., ALLAUZEN, A., CREGO, J. M. et YVON, F. (2011). From n-gram-based to crf-based
translation models. In Proceedings of the Sixth Workshop on Statistical Machine Translation,
pages 542&#8211;553, Edinburgh, Scotland. Association for Computational Linguistics.
</p>
<p>LAVERGNE, T., CAPP&#201;, O. et YVON, F. (2010). Practical very large scale CRFs. In Proceedings the
48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 504&#8211;513.
Association for Computational Linguistics.
</p>
<p>LIU, X., ZHANG, S., WEI, F. et ZHOU, M. (2011). Recognizing named entities in tweets. In
Proceedings of HLT &#8217;11, pages 359&#8211;367.
LIVEMEMORIES (2010). Livememories : Second year scientific report. Rapport technique,
LiveMemories.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>477 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>MARCU, D. et WONG, W. (2002). A phrase-based, joint probability model for statistical machine
translation. In Proceedings of EMNLP&#8217;02, pages 133&#8211;139.
</p>
<p>MENDES, P. N., JAKOB, M., GARC&#205;A-SILVA, A. et BIZER, C. (2011). DBpedia Spotlight : Shedding
light on the web of documents. In Proceedings of I-Semantics&#8217;11.
</p>
<p>MIHALCEA, R. et CSOMAI, A. (2007). Wikify ! : linking documents to encyclopedic knowledge. In
Proceedings of CIKM&#8217;07, pages 233&#8211;242.
</p>
<p>M&#220;LLER, H., KENNY, E. E. et STERNBERG, P. W. (2004). Textpresso : An ontology-based information
retrieval and extraction system for biological literature. PLoS Biol, 2:309.
</p>
<p>NADEAU, D. et SEKINE, S. (2007). A survey of named entity recognition and classification.
Linguisticae Investigationes, 30(1):3&#8211;26. Publisher : John Benjamins Publishing Company.
</p>
<p>NAZARENKO, A., GUISS&#201;, A., L&#201;VY, F., OMRANE, N. et SZULMAN, S. (2011). Integrating written
policies in business rule management systems. In Proceedings of RuleML&#8217;11.
</p>
<p>OCH, F. J. et NEY, H. (2003). A systematic comparison of various statistical alignment models.
Computational Linguistics, pages 19&#8211;51.
</p>
<p>RATINOV, L. et ROTH, D. (2009). Design challenges and misconceptions in named entity recogni-
tion. In Proceedings of CoNLL&#8217;09, pages 147&#8211;155.
</p>
<p>SCHMID, H. (1995). Improvements in part-of-speech tagging with an application to german. In
Proceedings of the ACL SIGDAT&#8217;95-Workshop.
</p>
<p>STOLCKE, A. (2002). Srilm &#8212; an extensible language modeling toolkit. In In Proceedings of
ICSLP&#8217;02, pages 901&#8211;904.
</p>
<p>SUTTON, C. et MCCALLUM, A. (2006). Introduction to Conditional Random Fields for Relational
Learning, chapitre 4, pages 93&#8211;128. MIT Press.
</p>
<p>TOMEH, N. (2012). Discriminative Alignment Models For Statistical Machine Translation. Th&#232;se
de doctorat, University of Paris 11, Orsay.
</p>
<p>UREN, V. S., CIMIANO, P., IRIA, J., HANDSCHUH, S., VARGAS-VERA, M., MOTTA, E. et CIRAVEGNA, F.
(2006). Semantic annotation for knowledge management : Requirements and a survey of the
state of the art. J. Web Sem., 4(1):14&#8211;28.
</p>
<p>WANG, Y. (2009). Annotating and recognising named entities in clinical notes. In ACL/AFNLP
(Student Workshop), pages 18&#8211;26.
</p>
<p>WELTY, C. et IDE, N. (1999). Using the right tools : Enhancing retrieval from marked-up
documents. In Journal Computers and the Humanities, pages 33&#8211;10.
</p>
<p>WONG, Y. W. et MOONEY, R. J. (2006). Learning for semantic parsing with statistical machine
translation. In Proceedings of HLT-NAACL&#8217;06, pages 439&#8211;446.
</p>
<p>ZHOU, G. et SU, J. (2002). Named entity recognition using an hmm-based chunk tagger. In
Proceedings of ACL&#8217;02, pages 473&#8211;480.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>478 c&#65535; ATALA</p>

</div></div>
</body></html>