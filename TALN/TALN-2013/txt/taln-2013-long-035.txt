TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
Pr√©-segmentation de pages web
et s√©lection de documents pertinents
en Questions-R√©ponses
Nicolas Foucault Sophie Rosset Gilles Adda
LIMSI-CNRS - 508 rue John von Neumann - Plateau du Moulon
Universit√© de Paris-Sud - B.P. 133 - 91403 Orsay Cedex - France
prenom.nom@limsi.fr
R√âSUM√â
Dans cet article, nous pr√©sentons une m√©thode de segmentation de pages web en blocs
de texte pour la s√©lection de documents pertinents en questions-r√©ponses. La segmentation des
documents se fait pr√©alablement √† leur indexation en plus du d√©coupage des segments obtenus
en passages au moment de l‚Äôextraction des r√©ponses. L‚Äôextraction du contenu textuel des pages
est faite √† l‚Äôaide d‚Äôun extracteur maison. Nous avons test√© deux m√©thodes de segmentation.
L‚Äôune segmente les textes extraits des pages web uniform√©ment en blocs de taille fixe, l‚Äôautre les
segmente par TextTiling (Hearst, 1997) en blocs th√©matiques de taille variable. Les exp√©riences
men√©es sur un corpus de 500K pages web et un jeu de 309 questions factuelles en fran√ßais, issus
du projet Quaero (Quintard et al., 2010), montrent que la m√©thode employ√©e tend √† am√©liorer la
pr√©cision globale (top-10) du syst√®me RITEL‚ÄìQR (Rosset et al., 2008) dans sa t√¢che.
ABSTRACT
Web pages segmentation for document selection in Question Answering
In this paper, we study two different kinds of web pages segmentation for document selection
in question answering. The segmentation is applied prior to indexation in addition to the
traditionnal passage retrieval step in question answering. In both cases, the segmentation is
textual and processed once the web pages textual content has been extracted using our own
extraction system. In the first case, a document is tilled homogeneously in text blocs of fixed size
while in the second case the segmentation is based on the TextTiling algorithm (Hearst, 1997).
Evaluation on 309 factoid questions and a collection of 500K French web pages, coming from the
Quaero project (Quintard et al., 2010), showed that such approaches tend to support properly
the RITEL‚ÄìQR system (Rosset et al., 2008) in this task.
MOTS-CL√âS : pages web, TextTiling, s√©lection de documents, questions-r√©ponses, Quaero, Ritel,
segmentation textuelle, segmentation th√©matique.
KEYWORDS: web pages, TextTiling, document selection, question answering, Quaero, Ritel,
textual segmentation, topic segmentation.
479 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
1 Introduction
C‚Äôest un truisme de nos jours de dire qu‚ÄôInternet est une mine d‚Äôinformation, de ressources et
de savoirs qui peuvent sembler infinis. Ces informations sont utiles √† toute personne souhaitant
s‚Äôinformer ou se distraire, mais √©galement aux chercheurs de nombreux domaines (biologie,
sciences sociales, informatique, . . .) pour qui Internet est devenu un objet de recherches. Cepen-
dant, malgr√© les progr√®s li√©s, par exemple par le passage au WEB 2.0, on ne peut que constater
que les informations sur le Web ne sont pas fiables, ni m√™me accessibles ais√©ment.
Les syst√®mes de r√©ponses aux questions sont un moyen efficace de rendre cette information √† la
fois plus accessible et plus fiable. Plus accessible, car ces syst√®mes r√©pondent de fa√ßon pr√©cise,
rapide et concise aux questions qui leur sont pos√©es en langue naturelle (√† l‚Äôinstar des moteurs de
recherche usuels 1). Plus fiable, car les r√©ponses sont valid√©es par le syst√®me (Pe√±as et al., 2007).
Une √©tape primordiale (dans toutes les acceptions du terme) pour les syst√®mes de questions-
r√©ponses (QR) est l‚Äôop√©ration qui consiste √† extraire le contenu textuel des pages. Pour cela, il est
n√©cessaire (Grau, 2004) de nettoyer, restructurer et filtrer leur contenu (par exemple de corriger
les balises HTML et les erreurs d‚Äôencodage, d‚Äô√©liminer les codes javascript r√©siduels et les spams).
La qualit√© (au sens de leur ad√©quation √† la t√¢che QR) des textes obtenus d√©pend fortement de
l‚Äôextracteur employ√© (Baroni et al., 2008) et de la qualit√© intrins√®que de l‚Äôinformation contenue
dans les documents √† l‚Äôorigine. Une t√¢che cruciale, mais souvent m√©sestim√©e, pour un syst√®me
QR est de pouvoir filtrer les documents dont la qualit√© intrins√®que est faible, afin d‚Äôaugmenter la
pr√©cision de la s√©lection des meilleurs candidats lors de l‚Äôextraction de r√©ponses.
Au cours de travaux pr√©c√©dents (Foucault et al., 2011), nous avons mis en place une strat√©gie
de s√©lection des documents pertinents pour un syst√®me QR en fran√ßais, en compl√©ment de la
s√©lection de documents traditionnelle effectu√©e par le moteur de recherche du syst√®me. Cette
s√©lection repose sur une mesure de la qualit√© intrins√®que des documents en utilisant un mod√®le
de langue, qui nous fournit a priori des mesures objectives sur le degr√© d‚Äôinformativit√© d‚Äôun texte.
Cette strat√©gie permet d‚Äô√©carter de la liste des candidats s√©lectionn√©s par le moteur de recherche
du syst√®me, les documents les plus bruit√©s (c‚Äôest-√†-dire de faible qualit√©) pour la t√¢che QR. Ici,
un texte est consid√©r√© comme pertinent ou non dans sa globalit√©.
Il est de coutume en QR (Ligozat, 2006) de d√©couper les documents en passage soit au moment
de leur indexation, soit au cours des recherches. L‚Äôid√©e est de r√©duire la variabilit√© naturelle
des documents en taille et en contenu. En effet, avec des segments textuels plus petits, on peut
esp√©rer une variabilit√© plus faible, et un contenu informationnel (corr√©l√© au contenu linguistique,
en particulier lexical et s√©mantique) plus coh√©rent, ce qui en retour doit permettre l‚Äôextraction
de r√©ponses plus pertinentes que celles issues de la globalit√© du texte. Cette strat√©gie a fait
ses preuves par le pass√© et des travaux r√©cents autour du d√©coupage de textes en passages
(Tiedemann, 2007; Khalid et Verberne, 2008) l‚Äôont consolid√©e.
A notre connaissance, personne n‚Äôa tent√© de segmenter les documents pr√©alablement √† leur
indexation, tout en d√©coupant les segments obtenus en passages au moment des recherches dans
le but de r√©duire plus fortement la variabilit√© des documents. Dans cet article, nous d√©taillons
plusieurs exp√©riences visant √† mesurer l‚Äôimpact d‚Äôune telle pr√©-segmentation sur la t√¢che QR.
1. e.g. Google http://www.google.fr
480 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
2 Travaux connexes
L‚Äôid√©e de segmenter des documents textuels (article de journaux, livres, . . .) en blocs de texte
est un axe de recherche activement explor√© dans les ann√©es 90 en Recherche d‚ÄôInformation
(RI) textuelle. Pour r√©duire la variabilit√© linguistique d‚Äôun texte, une premi√®re id√©e, explor√©e
notamment par Salton (Salton et al., 1996) et Hearst (Hearst, 1997) consiste √† op√©rer une
segmentation en blocs th√©matiques, les fronti√®res de blocs √©tant les endroits o√π on d√©tecte un
changement de th√®me. Des calculs de proximit√© lexicale entre blocs adjacents permettent de
r√©organiser le texte d‚Äôorigine en segments plus homog√®nes (mais toujours de taille variable). Chez
Salton, la proximit√© lexicale est obtenue √† l‚Äôaide de mesures de distances vectorielles, chaque
bloc √©tant repr√©sent√© par un vecteur lexical. En fonction de valeurs seuils sur ces distances, des
fusions entre paragraphes sont op√©r√©es. (Salton et al., 1996) effectue une fusion it√©rative, chaque
it√©ration fusionnant les paragraphes jug√©s similaires selon cette distance, le document √©tant
explor√© du d√©but √† la fin, de gauche √† droite. L‚Äôit√©ration s‚Äôarr√™te lorsque le texte ne contient
plus que des blocs th√©matiquement homog√®nes. A partir de cette segmentation, Salton d√©rive
un graphe des relations th√©matiques qu‚Äôentretiennent les blocs au sein du document. Dans le
m√™me esprit, (Hearst, 1997) fusionne des blocs de textes entre eux, mais de mani√®re plus fine.
Elle se fonde sur une analyse plus linguistique du texte que Salton. En effet, l‚Äôalgorithme de
segmentation de Hearst (TextTiling) utilise la structure du discours (ici la th√©orie des cha√Ænes
lexicales) et se fonde sur une segmentation en unit√©s lexicales √©l√©mentaires (tokens). Ces tokens
forment les unit√©s de base pour la repr√©sentation de chaque bloc textuel. Cet algorithme utilise
une mesure de distance fond√©e sur les statistiques de co-occurence. TextTiling ne fonctionne pas
sur les paragraphes d‚Äôorigine du texte contrairement √† l‚Äôalgorithme de Salton, mais sur des blocs
de pseudo-phrases construits sur la base de ces paragraphes.
Plus r√©cemment, des travaux dans le contexte de la RI dans des documents multim√©dia ont
propos√© une nouvelle m√©thode d‚Äôindexation de pages web (Faessel, 2008). Celle-ci s‚Äôappuie sur
l‚Äôinformation des repr√©sentations DOM2 et CSS des pages web pour segmenter ces derni√®res
avant indexation ; (Bruno et al., 2009) d√©montrent que l‚Äôutilisation de ces informations conduit √†
une augmentation des performances d‚Äôun moteur de recherche dans sa t√¢che. D‚Äôautres travaux
de segmentation pour la classification automatique de pages web en th√®me (Qi et Davison, 2009)
utilisent la repr√©sentation DOM. Dans (Gupta et al., 2003) l‚Äôextraction du contenu textuel des
pages se fait automatiquement √† l‚Äôaide de la structure des arbres DOM. Dans (Asirvatham et al.,
2001), l‚Äô√©chantillonnage des couleurs des images est utilis√© pour cat√©goriser les pages qui les
contiennent. Dans (Kovacevic1 et al., 2004), pour la m√™me t√¢che, on utilise le rendu visuel. (Guo
et al., 2007) utilise des indices visuels (le rendu des pages fourni par le moteur de Mozilla 3),
g√©om√©triques (les coordonn√©es des √©l√©ments de l‚Äôarbre DOM au sein du rendu des pages) et
le style des pages (la r√©p√©tition d‚Äôinformation) pour d√©finir les blocs d‚Äôinformation pertinents
trouv√©s dans les pages et les annoter s√©mantiquement. Dans (Feng et al., 2005), les auteurs
√©tudient l‚Äôimpact d‚Äôindices visuels et structurels sur la segmentation en blocs au travers d‚Äôune
t√¢che de cat√©gorisation fonctionnelle (blocs de type menu, titre, contenu, etc.). Dans (Vadrevu
et al., 2005), les auteurs utilisent des crit√®res de d√©coupage fond√©s sur l‚Äôhomog√©n√©it√© locale
du contenu informationnel des pages web (i.e. mod√®le de segmentation bas√© sur le concept de
path entropy) et d‚Äôindices visuels d√©riv√©s de leur repr√©sentation DOM. Certains syst√®mes comme
VIPS (Cai et al., 2003) se fondent essentiellement sur ce type d‚Äôindices pour segmenter les pages.
2. Document Object Model (DOM) www.w3.org/DOM
3. www.mozilla.org
481 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
A notre connaissance, aucune tentative d‚Äôapplication de ces techniques comme proc√©dure de
segmentation de pages web n‚Äôa √©t√© faite en QR. Nous avons choisi dans un premier temps
d‚Äôutiliser un algorithme de premi√®re g√©n√©ration : le TextTiling de Hearst. Ce dernier a montr√©
son int√©r√™t pour la s√©lection de document pertinent en RI et se fonde sur une philosophie sous-
jacente commune √† notre domaine en TAL (Traitement Automatique des langues). De plus, on en
trouve des impl√©mentations en libre acc√®s (contrairement √† certains des algorithmes √©voqu√©s
plus haut). Par ailleurs, TextTiling pr√©sente l‚Äôavantage de fournir une segmentation en blocs
th√©matiques qui pourrait √™tre mise √† contribution par la suite pour renforcer l‚Äôanalyse s√©mantique
des documents par un syst√®me QR. Dans la perspective de travaux futurs en segmentation
de pages web autour de leur repr√©sentation visuelle en QR, le TextTiling nous permettra de
b√©n√©ficier d‚Äôune segmentation TAL de r√©f√©rence √† comparer √† des approches de RI non textuelles.
C‚Äôest dans cette optique que le travail pr√©sent√© dans cet article se positionne.
Dans la section 3, nous pr√©sentons notre m√©thode de segmentation textuelle d√©velopp√©e sur
la base du TextTiling de Hearst ; dans la section 4 nous √©valuons cette m√©thode sur la t√¢che
Questions-R√©ponses. Nous concluons et pr√©sentons les perspectives de ce travail dans la section 5.
3 Segmentation textuelle de pages web
Dans cette section, nous pr√©sentons la m√©thode de segmentation de pages web que nous avons
mise en place pour la s√©lection de documents pertinents en QR.
La figure 1 pr√©sente les √©tapes-cl√©s de la cha√Æne de traitement qui correspond √† cette m√©tode : de
l‚Äôextraction du contenu textuel des pages √† l‚Äôobtention de blocs de textes normalis√©s. Chaque
√©tape cl√© de cette cha√Æne est d√©crite successivement dans les sections 3.2, 3.3 et 3.4.
3.1 Pr√©sentation g√©n√©rale
	

	
	
 
		  
	 
FIGURE 1 ‚Äì Notre proc√©dure de segmentation de pages web en lien avec les (pr√©-)traitements QR.
482 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
En th√©orie, nous aurions d√ª inverser les √©tapes de normalisation et de segmentation afin que
la segmentation b√©n√©ficie des traitements de normalisation (voir section 3.4). Cependant, une
telle inversion n√©cessite certaines modifications de notre cha√Æne de normalisation : en effet, cette
derni√®re supprime l‚Äôindentation des textes utile √† l‚Äôalgorithme de TextTiling (voir section 3.3.1).
Nous n‚Äôavons malheureusement pas eu le temps de mettre en place les modifications ad√©quates.
3.2 Extraction
Notre proc√©dure d‚Äôextraction se d√©roule en deux temps : pr√©-traitement (section 3.2.1) puis
repr√©sentation et extraction du contenu textuel des pages web (section 3.2.2). La phase de pr√©-
traitement des pages web est prise en charge par Kitten (Falco et al., 2012), un outil de traitement
de documents web d√©velopp√© au LIMSI. La repr√©sentation et l‚Äôextraction du contenu textuel des
pages web se fait sur les versions des pages pr√©-trait√©es par Kitten √† l‚Äôaide du navigateur textuel
de pages web Lynx 4.
3.2.1 Pr√©-traitement des pages web
Le pr√©-traitement des documents web est r√©alis√© √† l‚Äôaide de Kitten. Ce choix est motiv√© par les
performances √©tat de l‚Äôart que ce dernier a obtenu en qualit√© d‚Äôextracteur textuel (Falco et al.,
2012) dans le cadre d‚Äô√©valuations QR sur le syst√®me Fidji (Moriceau et Tannier, 2010).
Kitten est un outil d√©velopp√© au LIMSI, d√©di√© aux traitements et √† la normalisation de donn√©es
Html. Les pages web fournies en entr√©e sont trait√©es et de nouvelles pages web au format Xhtml
valide W3C (encod√©es en UTF8) sont produites en sortie. Ces pages sont bien form√©es (correction
de leur squelette Html via jTidy 5), sans erreurs d‚Äôencodage (correction de leur encodage via
jChardet 6 et conversion des caract√®res Html sp√©ciaux dans une base Unicode via HTMLCleaner 7).
Kitten produit des pages web exploitables en Extraction d‚ÄôInformation (EI) (Baroni et al., 2008)
sans appliquer d‚Äôheuristiques de nettoyage pr√©d√©finies contrairement √† des outils classiques
de nettoyage de contenu comme Boilerpipe (Kohlsch√ºtter et al., 2010) ou Ncleaner (Evert,
2008) ; par exemple Ncleaner pr√©serve pour l‚Äôessentiel le texte des balises <title>, <h1>,
<h2>, <h3>, <div> et <p> contenus dans le corps des pages, toute autre balise √©tant jug√©e
non pertinente pour l‚Äôextraction. Par ailleurs, Kitten dispose de nombreuses fonctions et filtres
configurables qui le rendent flexible. Ainsi, il est possible de conserver le contenu des attributs
<title> associ√© √† un lien tout en supprimant le lien ou au contraire conserver ce lien tout en
supprimant les attributs <title> qui lui sont associ√©s. Kitten se rapproche donc plut√¥t d‚Äôoutils
de d√©veloppement populaires dans le domaine de l‚ÄôEI web comme la librairie Python Beautiful
Soup 8 et le framework de crawling web Scrapy 9.
Kitten dispose de son propre module d‚Äôextraction de pages web et d‚Äôun syst√®me d‚Äôextraction
back-off bas√© sur Lynx. Celui-ci sert d‚Äôextracteur principal dans notre syst√®me de segmentation.
4. lynx.browser.org
5. http://jtidy.sourceforge.net
6. portage Java de la d√©tection automatique d‚Äôencodage d‚Äôune page du moteur de Mozilla
7. http://htmlcleaner.sourceforge.net
8. http://www.crummy.com/software/BeautifulSoup
9. scrapy.org
483 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
3.2.2 Repr√©sentation des pages web et extraction textuelle
La repr√©sentation des pages utilis√©e par notre moteur d‚Äôextraction se fait gr√¢ce √† Lynx. Ce
dernier est un navigateur d‚Äôinformations distribu√©es √† port√©e g√©n√©rale pour Internet. Il permet
de naviguer sur le Web depuis une console, en mode textuel uniquement. C‚Äôest un outil libre
int√©gr√© automatiquement dans la plupart des distributions Linux grand public comme Ubuntu,
qui int√®gre de nombreuses fonctionnalit√©s web, dont l‚Äôextraction du contenu textuel de pages
web.
Nous avons retenu Lynx pour deux raisons. La premi√®re raison est qu‚Äôil fournit une extraction
textuelle de pages web qui refl√®te leur rendu visuel. La seconde raison est que Lynx peut fournir
une d√©composition lin√©aire du contenu des pages web en blocs de texte, adapt√©e √† la plupart des
traitements d‚Äôanalyses de documents en QR.
Si Lynx produit des extractions textuelles fid√®les au rendu visuel des pages web, l‚Äôagencement des
blocs d‚Äôextraction diff√®re de celui observ√© dans un navigateur web classique du type Firefox 10. En
effet, Lynx effectue une travers√©e gauche-droite descendante des pages web. En cons√©quence, les
blocs d‚Äôinformation textuelle rencontr√©s le long du parcours sont mis bout √† bout dans le fichier
d‚Äôextraction r√©sultant. Ainsi, on trouve souvent dans les extractions textuelles de Lynx la suite
de blocs suivant (donn√©s ici selon leur contenu visuel) : bandeau, menus, colonne gauche, bloc
de contenu principal, colonne droite, puis pied de page. On peut aussi trouver des agencements
moins st√©r√©otypiques selon le design des pages et trouver des s√©ries de blocs de contenu principal
qui s‚Äôencha√Ænent. L‚Äô√©tape d‚Äôextraction textuelle est r√©alis√©e par Lynx via le syst√®me d‚Äôextraction
back-off de Kitten.
3.3 Strat√©gie de segmentation
Nous avons utilis√© deux strat√©gies de segmentation en blocs de texte. La premi√®re strat√©gie
consiste √† segmenter les textes extraits par Lynx en blocs th√©matiques de taille variable par
l‚Äôalgorithme de TextTiling de Hearst (Hearst, 1997). La seconde strat√©gie vise √† contr√¥ler la
pr√©c√©dente et segmente les textes extraits par Lynx de fa√ßon uniforme en blocs de taille identique.
3.3.1 Segmentation par TextTiling
L‚Äôalgorithme de TextTiling de Hearst (Hearst, 1997) segmente un texte en unit√©s appel√©es
multi-paragraphes en fonction des th√©matiques abord√©es dans le texte. Traditionnellement, il
est utilis√© pour d√©tecter les th√©matiques dans des textes fortement structur√©s (e.g. articles de
journaux, textes issus de livres . . .) et de grande taille (i.e. de plusieurs pages). Une des questions
sous-jacente aux exp√©riences que nous avons men√©es √©tait de savoir si cet algorithme pourrait
√™tre utile pour la segmentation de pages web.
L‚Äôalgorithme, pr√©sent√© en d√©tail dans (Hearst, 1997) s‚Äôarticule autour des 3 √©tapes suivantes :
‚Äì tokenisation ;
‚Äì calcul de scores lexicaux ;
‚Äì identification de fronti√®res.
10. http://www.mozilla.org
484 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
La proc√©dure de segmentation d√©marre par une √©tape de tokenization du texte qui lui est fourni
en entr√©e. Les mots qui sont des stopwords ne sont pas tokenis√©s et sont √©cart√©s. Les autres
subissent une √©tape de stemming bas√©e sur une fonction d‚Äôanalyse morphologique. Le texte est
tokeniz√© en pseudo-phrases de longueur pr√©d√©finie cens√©e repr√©senter la longueur moyenne d‚Äôun
paragraphe (20 pseudo-phrases par d√©faut). Les paragraphes d‚Äôorigine du texte servent de point
d‚Äôancrage pour la tokenization, qui elle-m√™me d√©pend de l‚Äôindentation dans le texte.
L‚Äôalgorithme √©value ensuite la proximit√© lexicale qui existe entre toutes les paires de blocs
adjacents possibles, et fournit un score fond√© sur des co-occurences lexicales de tokens qui
mesure l‚Äô√©cart entre deux blocs. Les blocs sont constitu√©s des pseudo-phrases obtenues lors de
la phase de tokenization. La d√©termination des scores lexicaux varie selon la strat√©gie utilis√©e.
TextTiling dispose de 2 strat√©gies de comparaison de blocs diff√©rentes. La premi√®re (block
comparison), compare deux blocs adjacents de texte et calcule leur √©cart sur la base du nombre
de tokens qu‚Äôils ont en commun. La seconde m√©thode (vocabulary introduction) √©value ce m√™me
√©cart sur la base des tokens issus des pseudo-phrases qui bordent la fronti√®re entre deux blocs.
Enfin, l‚Äôalgorithme proc√®de au marquage des fronti√®res de blocs pertinentes sur la base des
√©carts mesur√©s √† l‚Äô√©tape pr√©c√©dente. Ceci est fait √† l‚Äôaide d‚Äôune fen√™tre glissante sur les blocs.
Les fronti√®res de blocs pr√©sentant les plus forts √©carts sont s√©lectionn√©es comme fronti√®res
th√©matiques.
L‚Äôimpl√©mentation que nous avons utilis√©e du TextTiling est fournie par le package Python NLTK
sans la fonction d‚Äôanalyse morphologique. Le calcul des scores lexicaux se fait par block comparison.
3.3.2 Segmentation uniforme
Cette segmentation repr√©sente la condition contr√¥le dans nos exp√©riences. Elle se contente de
segmenter chaque fichier texte qui lui est pr√©sent√© en 8 blocs, c‚Äôest-√†-dire la moyenne du nombre
de blocs de segmentation obtenus par TextTiling sur notre corpus d‚Äôexp√©rimentation au cours de
tests pr√©liminaires ; ceci revient √† fixer la taille moyenne des blocs en nombre de lignes (voir la
section 4.3).
La segmentation se fait selon un parcours lin√©aire du texte d‚Äôentr√©e, du d√©but jusqu‚Äô√† la fin, les
points de coupe sont d√©termin√©s √† l‚Äôavance selon le nombre total de lignes dans le texte et le
nombre maximum de blocs fix√© en sortie (8). Les textes trop petits (ceux de moins de 8 lignes)
ne sont pas segment√©s et sont consid√©r√©s comme des blocs uniques.
3.4 Normalisation
La normalisation est une √©tape durant laquelle un texte brut est trait√© afin qu‚Äôune unit√© lexicale
soit explicitement d√©finie. Au cours de la normalisation, le texte est transform√© dans une forme
o√π les mots et les nombres sont clairement d√©limit√©s, la ponctuation est s√©par√©e des mots, et des
phrases ou pseudo-phrases sont clairement form√©es.
Notre normalisation passe par plusieurs √©tapes : s√©paration des mots et nombres de la ponctuation,
reconstruction de la casse sur les mots, ajout de la ponctuation le cas √©ch√©ant et s√©paration en
phrases ou pseudo-phrases du texte d‚Äôentr√©e. Elle s‚Äôappuie sur des lexiques, des dictionnaires de
r√®gles et des mod√®les de langue (D√©chelotte et al., 2007).
485 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
4 Evaluation Questions-R√©ponses
4.1 Hypoth√®ses de travail et conditions exp√©rimentales
Les exp√©riences pr√©sent√©es ont pour but d‚Äôexaminer l‚Äôhypoth√®se selon laquelle une fen√™tre
d‚Äôanalyse plus r√©duite pour traiter les documents web permettrait une s√©lection du syst√®me QR
plus pr√©cise (c‚Äôest-√†-dire obtenir des r√©ponses plus pertinentes et en plus grand nombre). √Ä cette
fin, nous r√©alisons une segmentation avant l‚Äôindexation des documents en plus du d√©coupage
habituel en passages r√©alis√© lors de l‚Äôextraction des r√©ponses. La segmentation des documents est
effectu√©e par TextTiling ou uniform√©ment par notre algorithme de segmentation contr√¥le.
Les √©valuations de l‚Äôimpact de ces algorithmes de segmentation sur le syst√®me RITEL‚ÄìQR (voir
section 4.2) sont pr√©sent√©es section 4.5 selon 3 conditions exp√©rimentales :
‚Äì condition 1 : condition sans segmentation ou baseline (bsln) ;
‚Äì condition 2 : condition en segmentation par TextTiling (TT) ;
‚Äì condition 3 : condition en segmentation contr√¥le (ctrl).
4.2 Syst√®me d‚Äôexp√©rimentation : RITEL‚ÄìQR
Le syst√®me RITEL‚ÄìQR que nous utilisons dans les exp√©riences est compl√®tement d√©crit dans (Ber-
nard et al., 2009) et (Galibert, 2009). Il s‚Äôagit d‚Äôun syst√®me qui a √©t√© con√ßu √† l‚Äôorigine comme
un syst√®me de dialogue (Toney et al., 2008). D‚Äôun point de vue g√©n√©ral, on peut dire que le
syst√®me s‚Äôappuie sur une analyse multi-niveaux, appliqu√©e sur les questions et sur les documents.
Les documents sont totalement analys√©s et index√©s d‚Äôapr√®s les r√©sultats d‚Äôanalyse. La recherche
est effectu√©e dans l‚Äôindex complet des documents. L‚Äôanalyse permet de rep√©rer et typer des
√©l√©ments pertinents d‚Äôinformation qui peuvent prendre la forme d‚Äôentit√©s nomm√©es, complexes
et structur√©es, de chunks morpho-syntaxiques, d‚Äôactes de dialogue et de marqueurs th√©matiques.
La premi√®re √©tape de RITEL‚ÄìQR consiste √† cr√©er un descripteur de recherche (DDR) qui contient
toutes les informations utiles pour la recherche de documents, l‚Äôextraction de passages pertinents
et l‚Äôextraction de r√©ponses. Ces informations sont les √©l√©ments de la question, leurs transforma-
tions possibles (d√©rivations morphologiques, synonymes etc. et les poids associ√©s), et les types
attendus de la r√©ponse (avec les poids associ√©s). Ces types sont le plus souvent des types d‚Äôentit√©s
nomm√©es (personne, lieu . . .) et refl√®tent la taxonomie d‚Äôentit√©s utilis√©e au moment de l‚Äôanalyse.
La s√©lection des documents consiste √† fournir, √† partir de l‚Äôindex, les n documents les plus
pertinents, c‚Äôest-√†-dire ceux contenant le plus d‚Äôinformations pr√©sentes dans le DDR. En fonction
de ces informations et de leur densit√©, les documents obtiennent un score. Ensuite, des passages
sont extraits de chaque document. Ces passages sont de tailles variables (une fen√™tre d‚Äôanalyse
diff√©rente est appliqu√©e selon la cat√©gorie de la question) et sont scor√©s selon le m√™me principe
que les documents. L‚Äôextraction et l‚Äô√©valuation des candidats r√©ponses s‚Äôappuient sur la redon-
dance de ces derniers dans les documents et les passages. On consid√®re que les √©l√©ments de
passages qui correspondent √† un type possible de r√©ponse du DDR et qui ne sont ni des √©lements
ni des sous-√©l√©ments d√©finis dans le DDR, sont des candidats r√©ponses potentiels. A chacun d‚Äôeux
est finalement attribu√© √† un score de pertinence (Bernard et al., 2009).
486 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
4.3 Corpus
Le corpus de pages web utilis√© dans nos exp√©rimentations (ci-apr√®s Q07fr) est compos√© de
499 734 pages web (5Gbytes) tout venant (i.e. journal, Wikip√©dia, blog, site de vente, forum,
etc.) et en fran√ßais. Il nous est fourni par le projet Quaero 11 et sert de corpus standard dans
le cadre des √©valuations QR au sein du projet (Quintard et al., 2010). Les questions de test et
d‚Äôentra√Ænement utilis√©es (309 et 722 questions) proviennent du m√™me projet. Elles ont √©t√© cr√©√©es
√† partir de logs utilisateurs (Quintard et al., 2010) du moteur de recherche fran√ßais Exalead 12 et
sont compos√©es de questions factuelles (e.g. Qui est Gandhi ?, Combien p√®se la tour Eiffel ?, O√π se
situe Pondich√©ry ? et Que signifie CSDPTT ?).
Etape/Cond bsln ctrl TT
extraction 497 228 497 228 497 228
segmentation - 3 686 749 3 857 585
(a) normalisation 485 037 3 660 264 3 686 875
annotation 485 037 3 660 264 3 686 875
indexation 484 060 3 658 988 3 686 857
dur√©e totale 1,1j (26,5h) 2,38j (57,3h) 5,3j (127,5h)
Stat/Index nbB nbL nbB nbL nbB nbL
Min 1 1 1 1 1 1
(b) Max 1 461 075 8 1 262 186 9 277
Sd 0 7 646,5 0,01 18,7 8,4 32,61
Mean 1 295,4 8 19,4 7,3 20,9
TABLE 1 ‚Äì (a) Nombre de blocs par condition exp√©rimentale (Cond) selon leur type : segment√© (ctrl et TT)
ou non (bsln), selon les √©tapes n√©cessaires √† les cr√©er (Etape) et la dur√©e totale de traitement correspondant.
(b) Statistiques (Stat) du nombre de blocs (nbB) et de lignes (nbL) moyens (Mean), minimum (Min),
maximum (Max) et d√©viation standard (Std) des index (Index) relatifs √† chaque condition exp√©rimentale.
Le tableau 1 (a) pr√©sente les r√©sultats des traitements (en terme de nombre de fichiers trait√©s) de
chacune des √©tapes de notre cha√Æne de segmentation, ainsi que des √©tapes de pr√©-traitements
QR (annotation et indexation), pour chacune des conditions d‚Äôexp√©rimentations (Cond) √† partir
de Q07fr. Ces r√©sultats suivent le sch√©ma de la figure 1. Chaque sortie d‚Äôune √©tape d√©pend du
r√©sultat qui pr√©c√®de pour une condition donn√©e. On peut noter que le nombre de fichiers issus de
la segmentation dans les conditions contr√¥le (ctrl) et TextTiling (TT) sont proches (environ 20K
blocs de diff√©rence). Les blocs index√©s dans ces 2 conditions correspondent aux 484 060 textes
index√©s en condition baseline (bsln). La dur√©e des traitements (parall√®les/m√™mes serveurs) dans
ces conditions est respectivement de 2 √† 5 fois plus longue qu‚Äôen condition sans segmentation.
Le tableau 1 (b) pr√©sente le nombre moyen de blocs (nbB) et de lignes par bloc (nbL) obtenus en
conditions contr√¥le et TextTiling. Ces informations sont aussi donn√©es pour la condition baseline
√† titre indicatif (un bloc par fichier). On constate que l‚Äôalgorithme de TextTiling et le contr√¥le se
comportent de fa√ßon tr√®s similaire : en moyenne, le nombre de blocs produits (ctrl : 8 et TT :
7,3) ainsi que leur taille (ctrl : 19,4 et TT : 20,9) sont semblables. Le TextTiling produit une
l√©g√®re sur-segmentation : la d√©viation standard est 2 fois plus √©lev√©e que celle du contr√¥le (ctrl)
en nombre de lignes, le maximum de blocs pour un m√™me document √©tant √©galement plus grand.
11. http://www.quaero.org
12. http://www.exalead.com
487 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
4.4 M√©triques d‚Äô√©valuation
Dans ce travail, nous employons les m√©triques habituellement utilis√©es en QR :
‚Äì la pr√©cision d√©finie √©quation (1), est le ratio entre le nombre de r√©ponses correctes et le nombre
total de questions. Si le syst√®me est capable de fournir plusieurs r√©ponses par question, on ne
consid√®re que la premi√®re. CRi est le rang de la premi√®re r√©ponse correcte pour la question i.
CRi prend pour valeur +‚àû si aucune r√©ponse correcte n‚Äôa √©t√© trouv√©e.
‚Äì Le top-n d√©fini √©quation (2), mesure la pr√©cision selon les r√©ponses correctes de rang 1 √† n.
‚Äì Le Mean Reciprocal Rank (Moyenne des R√©ciproques des Rangs ou MRR) d√©fini √©quation (3),
permet de mesurer la qualit√© du classement des r√©ponses (10 par question) effectu√© par le
syst√®me. La r√©ponse correcte la mieux class√©e est pond√©r√©e par l‚Äôinverse de son rang initial.
Une absence de r√©ponse correcte entra√Æne une contribution nulle. Le score final correspond √†
la moyenne des contributions.
Ôøø
#CR #CR ‚â§ 1n CR
pr√©cision= i
= 1
(1) top-n= i (2) MRR= i (3)
#questions #questions #questions
4.5 R√©sultats
Les r√©sultats sont pr√©sent√©s dans les parties (a) et (b) du tableau 2. On a utilis√© le test de
McNemar (McNemar, 1947; Agresti, 1990) de R 13 pour juger de la significativit√© des r√©sultats
pr√©sent√©s tableau 2 (a). Les r√©sultats du test sont donn√©s tableau 3 14.
On constate, tableau 2 (a), que les deux conditions de segmentation test√©es sont proches de la
condition baseline sugg√©rant ainsi que la segmentation n‚Äôapporte pas de r√©els b√©n√©fices √† notre
syst√®me QR. Les performances du syst√®me sont tr√®s proches en terme de pr√©cision (0,6 point
de diff√©rence au plus entre bsln et TT). Mais le MRR pr√©sente un √©cart plus important entre les
conditions (2 points entre les conditions bsln et ctrl, et 1 point entre les conditions bsln et TT).
La segmentation ctrl semble donc permettre au syst√®me de trouver de meilleures r√©ponses (i.e.
des r√©ponses plus pr√©cises) qu‚Äôen condition baseline ou TextTiling. Toutefois, d‚Äôapr√®s les tests
statistiques des performances QR pr√©sent√©s tableau 3, ceci n‚Äôest qu‚Äôune tendance.
Le test de McNemar (McNemar, 1947), que nous avons utilis√© dans nos exp√©riences, √©tablit la
significativit√© des r√©sultats observ√©s entre 2 conditions A et B et une mesure M donn√©e, selon
des variations observ√©es entre A et B, synth√©tis√©es dans une table de contingence 2x2. De l√†, le
test (bilat√©ral) estime une valeur Q (i.e. khi¬≤ de McNemar) pour un degr√© de libert√© d f donn√© et
d√©rive une valeur p. Si p est inf√©rieure (ou √©gale) au seuil critique Œ±, l‚Äôhypoth√®se nulle H0 est
rejet√©e et la diff√©rence observ√©e entre A et B est jug√©e significative. Dans notre cas, une table
de contingence comptabilise le total de questions (#q) pour lesquelles RITEL-QR trouve une
r√©ponse de m√™me exactitude en conditions A et B. Il y a 4 types de compte, nombre total de
questions avec une r√©ponse : correcte (r) selon A et selon B (#rr), fausse (w, xs ou xl) selon A et
selon B (#WW), correcte selon A et fausse selon B (#rW) et inversement (#Wr).
13. http://www.r-project.org
14. Ces derniers sont les m√™mes sur le top-10 et le MRR, puisque ce test ne distingue pas les r√©ponses selon leur rang.
488 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
Ainsi, on peut constater que l‚Äôhypoth√®se H0 selon laquelle la diff√©rence observ√©e entre les
conditions bsln et ctrl n‚Äôest pas significative pour les performences QR en top-10, est √† peine
rejet√©e : la valeur de p obtenue dans ces conditions n‚Äô√©tant pas inf√©rieure mais tout juste align√©e
sur le seuil critique de significativit√© Œ± 15.
L‚Äô√©tude du nombre total de bonnes r√©ponses fournies par le syst√®me selon leur position au sein
du top-10 tableau 2 (b) (bsln : 178, TT : 183 et ctrl : 190) confirme cette tendance. On voit
aussi dans ce tableau que les r√©ponses apport√©s par le syst√®me en condition ctrl (jusqu‚Äô√† 12
r√©ponses supppl√©mentaires, soit 3,9% de r√©ponses en plus) se trouvent dans le top-3, l√† o√π la
segmentation par TextTiling a tendance √† apporter de nouvelles r√©ponses √† des rangs inf√©rieurs.
Nous avons pu constat√© que la segmentation des documents acc√©l√©rait les (pr√©-)traitements QR.
Cond
rang bsln ctrl TT
Cond P MRR top-10 #q 1 97 98 99
bsln 31.4 39.6 57.6 309 2 26 32 26
ctrl 31.7 41.6 61.5 309 3 17 26 19
TT 32.0 40.5 59.2 309 4 9 7 7
5 8 7 11
Cond #r #xs #xl #w 6 6 4 6
bsln 97 6 8 198 7 7 5 3
ctrl 98 11 5 195 8 6 5 4
TT 99 11 2 197 9 2 2 8
10 0 4 0
Total 178 190 183
(a) (b)
TABLE 2 ‚Äì (a) R√©sultats QR globaux par condition exp√©rimentale (Cond). P : pr√©cision ; MRR : rang moyen
r√©ciproque ; top-10 : pr√©cision sur 10 rangs. #q : nombre total de questions √©valu√©es. #r, #xs, #xl et #w :
nombre total de r√©ponses justes, trop courtes, trop longues et fausses, selon le top-1. (b) Focus sur les r√©sultats
du top-10 pr√©sent√©s en (a), selon chaque position (rang) dans le classement (r√©ponses justes uniquement).
d f =1,Œ±=.05 ctrl (A) / bsln (B) bsln (A) / TT (B) ctrl (A) / TT (B)
mesure #q r W Q p H0 r W Q p H0 r W Q p H0
P r 77 21 0 1 ‚úï 80 17 .02 .86 ‚úï 80 18 0 1 ‚úï
W 20 191 19 193 19 192
top-10 r 167 23 3.55 .05 ‚úì 164 14 .48 .48 ‚úï 174 16 1.44 .23 ‚úï
(MRR) W 11 108 19 112 9 110
TABLE 3 ‚Äì R√©sultats de significativit√© du test (bilat√©ral) de McNeamr pour les r√©sultats QR du tableau 2 (a).
Q : khi¬≤ de McNemar. d f : degr√© de libert√©. p : p-valeur. Œ± : seuil critique. H0 : hypoth√®se nulle (rejet : ‚úì).
#q : nombre total de questions pour lesquelles on a une r√©ponse de m√™me nature ou non entre 2 conditions
A et B. r : r√©ponse juste. W : r√©ponse fausse. Les rectangles rW/rW repr√©sentent des tables de contingence.
15. p=0,059 si on augmente la pr√©cision du test de McNemar fournie tableau 3
489 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
5 Conclusion et perspectives
Au cours de travaux pr√©c√©dents (Foucault et al., 2011) nous avons mis en place une strat√©gie
de s√©lection de documents pertinents pour un syst√®me QR sur le fran√ßais. Elle s‚Äôappuie sur
un mod√®le de langue qui fournit a priori une mesure objective du degr√© d‚Äôinformativit√© d‚Äôun
texte. Cette mesure de la qualit√© intrins√®que des documents sert √† filtrer les documents non
pertinents pour la t√¢che QR. L‚Äôeffet d‚Äôun tel filtrage appliqu√© √† l‚Äô√©chelle globale des documents,
c‚Äôest av√©r√© assez limit√©. La variabilit√© naturelle des pages web en taille et en contenu (comme leur
caract√®re multi-th√©matique) p√©nalise vraisemblablement le syst√®me dans sa t√¢che. Nous avons
donc cherch√© √† d√©velopper un syst√®me de segmentation qui permette d‚Äôappliquer ce filtrage √†
une √©chelle non plus globale mais locale, sur des sous-parties de document. Le travail pr√©sent√©
dans cet article avait pour objectif de mettre un tel syst√®me de segmentation en place.
La question √† laquelle nous avons voulu r√©pondre dans cette article est la suivante : segmenter
les documents avant l‚Äôindexation, en plus du d√©coupage habituel des documents en passages lors
de l‚Äôextraction des r√©ponses, am√©liore-t-il les performances d‚Äôun syst√®me de questions-r√©ponses ?
Pour r√©pondre √† cette question, nous avons test√© deux types de pr√©-segmentation support√©e par
une extraction de contenu textuel de pages web maison. L‚Äôune segmente les textes extraits via un
algorithme de texttiling classique (TextTiling) en blocs th√©matiques de taille variable. L‚Äôautre les
segmente uniform√©ment en blocs de taille fixe, sans d√©coupage th√©matique.
Les r√©sultats obtenus ne nous permettent pas de trancher nettement en faveur de l‚Äôune ou l‚Äôautre
de ces approches de segmentation. Cependant, les tendances observ√©es sugg√®rent qu‚Äôune pr√©-
segmentation des pages web comme nous l‚Äôavons d√©finie peut servir un syst√®me QR ; segmenter
les documents avant l‚Äôindexation afin de renforcer l‚Äôeffet du d√©coupage de ces derniers en
passages lors de l‚Äôextraction des r√©ponses, am√©liore la pr√©cision du syst√®me en terme de top-10
sans pour autant diminuer cette derni√®re en terme de top-1. Cette tendance est plus marqu√©e
pour la segmentation uniforme de pages web que pour une segmentation plus ¬´ intelligente ¬ª √†
l‚Äôaide de l‚Äôalgorithme de TextTiling (sans analyse morphologique, le calcul des scores lexicaux se
faisant par block comparison). Ce constat est contradictoire avec d‚Äôautres travaux, mais confirme
certaines conclusions apport√©es par Hearst dans ses travaux de segmentation th√©matique de
textes en Recherche d‚ÄôInformation (Hearst, 1997). Il serait int√©ressant de d√©terminer les raisons
amenant √† ce constat. Si la nature des documents (page web versus texte), est l‚Äôune des raisons
qui pourrait l‚Äôexpliquer, qu‚Äôen est-il par exemple de la longueur des documents et de la version
du TextTiling que nous avons utilis√© dans nos exp√©riences ?
En perspective des travaux pr√©sent√©s dans cet article, nous projetons d‚Äôabord d‚Äô√©tudier l‚Äôimpact
d‚Äôune pr√©-segmentation uniforme des pages web sur notre strat√©gie de s√©lection de documents
pertinents d√©velopp√©e dans (Foucault et al., 2011). Concernant nos travaux de segmentation
de pages web en QR √† partir de la repr√©sentation visuelle des pages, nous comptons √©valuer la
pertinence de la proc√©dure d‚Äôextraction mise en place au sein du syst√®me de segmentation de
pages web pr√©sent√© dans cet article.
Remerciements
Ce travail a √©t√© financ√© partiellement par l‚ÄôOSEO, dans le contexte du programme Quaero.
490 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
R√©f√©rences
AGRESTI, A. (1990). Categorical data analysis. New York : Wiley, London.
ASIRVATHAM, A. P., RAVI, K. K., PRAKASH, A., KRANTHI, A. et RAVI, K. (2001). Web page classification
based on document structure.
BARONI, M., CHANTREE, F., KILGARRIFF, A. et SHAROFF, S. (2008). Cleaneval : a competition for
cleaning web pages. In LREC. European Language Resources Association.
BERNARD, G., ROSSET, S., GALIBERT, O., BILINSKI, E. et ADDA, G. (2009). The limsi participation
in the qast 2009 track : experimentating on answer scoring. In CLEF‚Äô09, Corfu, Grece.
BRUNO, E., FAESSEL, N., GLOTIN, H., MA√éTRE, J. L. et MICHEL., S. (2009). Ir web search based on
presentation and multimedia content. In Actes des 25emes Journees Bases de Donnees Avancees
(BDA 2009), pages 408‚Äì407.
CAI, D., YU, S., WEN, J.-R. et MA, W.-Y. (2003). VIPS : a vision-based page segmentation
algorithm. Rapport technique, Microsoft (MSR-TR-2003-79).
D√âCHELOTTE, D., SCHWENK, H., ADDA, G. et GAUVAIN, J.-L. (2007). Improved machine translation
of speech-to-text outputs. In Interspeech‚Äô07, Antwerp. Belgium.
EVERT, S. (2008). A lightweight and efficient tool for cleaning web pages. In LREC. European
Language Resources Association.
FAESSEL, N. (2008). Indexation de blocs extraits de pages web en utilisant le rendu visuel. In
CORIA, pages 393‚Äì400. Universit√© de Renne 1.
FALCO, M.-H., MORICEAU, V. et VILNAT, A. (2012). Kitten : a tool for normalizing html and
extracting its textual content. In CHAIR), N. C. C., CHOUKRI, K., DECLERCK, T., DOGÃÜAN, M. U.,
MAEGAARD, B., MARIANI, J., ODIJK, J. et PIPERIDIS, S., √©diteurs : Proceedings of the Eight Interna-
tional Conference on Language Resources and Evaluation (LREC‚Äô12), Istanbul, Turkey. European
Language Resources Association (ELRA).
FENG, J., HAFFNER, P. et GILBERT, M. (2005). A learning approach to discovering web page
semantic structures. In Proceedings of the Eighth International Conference on Document Analysis
and Recognition, ICDAR‚Äô05, pages 1055‚Äì1059, Washington, DC, USA. IEEE Computer Society.
FOUCAULT, N., ADDA, G. et ROSSET, S. (2011). Language modeling for document selection in
question answering. In RANLP‚Äô11, pages 716‚Äì720, Hissar, Bulgaria.
GALIBERT, O. (2009). Approches et m√©thodologies pour la r√©ponse automatique √† des questions
adapat√©es √† un cadre int√©ractif en domaine ouvert. Th√®se de doctorat, Paris-Sud11, LIMSI/CNRS.
GRAU, B. (2004). M√©thodes Avanc√©es pour les Syst√®mes de Recherche d‚ÄôInformations. In
Visualisation d‚ÄôInformation et Interaction, chapitre 10 : Syst√®mes de question-r√©ponse, pages
189‚Äì218. Herm√®s. Dir. M. Ihadjadene.
GUO, H., MAHMUD, J., BORODIN, Y., STENT, A. et RAMAKRISHNAN, I. (2007). A general approach
for partitioning web page content based on geometric and style information. In Proceedings of
the Ninth International Conference on Document Analysis and Recognition - Volume 02, ICDAR
‚Äô07, pages 929‚Äì933, Washington, DC, USA. IEEE Computer Society.
GUPTA, S., KAISER, G., NEISTADT, D. et GRIMM, P. (2003). Dom-based content extraction of html
documents. In Proceedings of the 12th international conference on World Wide Web, WWW ‚Äô03,
pages 207‚Äì214, New York, NY, USA. ACM.
491 Ôøøc ATALA
TALN-R√âCITAL 2013, 17-21 Juin, Les Sables d‚ÄôOlonne
HEARST, M. A. (1997). Texttiling : Segmenting text into multi-paragraph subtopic passages.
Computational Linguistics, 23:33‚Äì64.
KHALID, M. A. et VERBERNE, S. (2008). Passage retrieval for question answering using sliding
windows. In In Proceedings of COLING 2008, Workshop IR4QA.
KOHLSCH√úTTER, C., FANKHAUSER, P. et NEJDL, W. (2010). Boilerplate detection using shallow text
features. In Proc. of 3rd ACM International Conference on Web Search and Data Mining New York
City, NY USA (WSDM 2010).
KOVACEVIC1, M., DILIGENTI, M., GORI, M. et MILUTINOVIC1, V. (2004). Visual adjacency mul-
tigraphs . a novel approach for a web page classification. In Proceedings of the Workshop on
Statistical Approaches to Web Mining (SAWM), pages 38‚Äì49.
LIGOZAT, A. L. (2006). Exploitation et fusion de connaissances locales pour la recherche d‚Äôinforma-
tions precÃÅises. Th√®se de doctorat, Paris-Sud11, LIMSI/CNRS.
MCNEMAR, Q. (1947). Note on the sampling error of the difference between correlated propor-
tions or percentages. Psychometrika, 12(2):153‚Äì157.
MORICEAU, V. et TANNIER, X. (2010). Fidji : using syntax for validating answers in multiple
documents. Information Retrieval, 13(5):507‚Äì533.
PE√ëAS, A., RODRIGO, √Å. et VERDEJO, F. (2007). Overview of the answer validation exercise 2007.
In CLEF, pages 237‚Äì248.
QI, X. et DAVISON, B. D. (2009). Web page classification : Features and algorithms. ACM
Computing Surveys, 41(2):12 :1‚Äì12 :31.
QUINTARD, L., GALIBERT, O., ADDA, G., GRAU, B., LAURENT, D., MORICEAU, V., ROSSET, S., TANNIER,
X. et VILNAT, A. (2010). Question answering on web data : The QA evaluation in Qu√¶ro. In
LREC‚Äô10, Valletta, Malta.
ROSSET, S., GALIBERT, O., BERNARD, G., BILINSKI, E. et ADDA, G. (2008). The limsi participation
to the qast track. In Working Notes of CLEF 2008 Workshop, Aarhus, Denmark.
SALTON, G., SINGHAL, A., BUCKLEY, C. et MITRA, M. (1996). Automatic text decomposition using
text segments and text themes. In Proceedings of the the seventh ACM conference on Hypertext,
HYPERTEXT ‚Äô96, pages 53‚Äì65, New York, NY, USA. ACM.
TIEDEMANN, J. (2007). Comparing document segmentation strategies for passage retrieval in
question answering. In Proceedings of the Conference on Recent Advances in Natural Language
Processing (RANLP‚Äô07), Borovets, Bulgaria.
TONEY, D., ROSSET, S., MAX, A., GALIBERT, O. et BILINSKI, E. (2008). An Evaluation of Spoken and
Textual Interaction in the RITEL Interactive Question Answering System. In (ELRA), E. L. R. A.,
√©diteur : Proceedings of the Sixth International Language Resources and Evaluation (LREC‚Äô08),
Marrakech, Morocco.
VADREVU, S., GELGI, F. et DAVULCU, H. (2005). Semantic partitioning of web pages. In Proceedings
of the 6th international conference on Web Information Systems Engineering, WISE‚Äô05, pages
107‚Äì118, Berlin, Heidelberg. Springer-Verlag.
492 Ôøøc ATALA
