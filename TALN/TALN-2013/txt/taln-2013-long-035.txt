TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Pré-segmentation de pages web
et sélection de documents pertinents
en Questions-Réponses

Nicolas Foucault Sophie Rosset Gilles Adda

LIMSI-CNRS - 508 rue John von Neumann - Plateau du Moulon
Université de Paris-Sud - B.P 133 - 91403 Orsay Cedex - France

prenom . nom@1imsi . fr

RESUME

Dans cet article, nous présentons une méthode de segmentation de pages web en blocs
de texte pour la sélection de documents pertinents en questions—réponses. La segmentation des
documents se fait préalablement a leur indexation en plus du découpage des segments obtenus
en passages au moment de l’extraction des réponses. L’extracu'on du contenu textuel des pages
est faite a l’aide d’un extracteur maison. Nous avons testé deux méthodes de segmentation.
L’une segmente les textes extraits des pages web uniformément en blocs de taille ﬁxe, l’autre les
segmente par TextTiling (Hearst, 1997) en blocs thématiques de taille variable. Les expériences
menées sur un corpus de 500K pages web et un jeu de 309 questions factuelles en frangais, issus
du projet Quaero (Quintard et al., 2010), montrent que la méthode employée tend a améliorer la
précision globale (top—10) du systéme RITEL—QR (Rosset et al., 2008) dans sa tache.

ABSTRACT

Web pages segmentation for document selection in Question Answering

In this paper, we study two different kinds of web pages segmentation for document selection
in question answering. The segmentation is applied prior to indexation in addition to the
traditionnal passage retrieval step in question answering. In both cases, the segmentation is
textual and processed once the web pages textual content has been extracted using our own
extraction system. In the first case, a document is tilled homogeneously in text blocs of ﬁxed size
while in the second case the segmentation is based on the TextTiling algorithm (Hearst, 1997).
Evaluation on 309 factoid questions and a collection of 500K French web pages, coming from the
Quaero project (Quintard et al., 2010), showed that such approaches tend to support properly
the RITEL—QR system (Rosset et al., 2008) in this task.

MOTS-CLES : pages web, TextTiling, sélection de documents, questions-réponses, Quaero, Ritel,
segmentation textuelle, segmentation thématique.

KEYWORDS: web pages, TextTiling, document selection, question answering, Quaero, Ritel,
textual segmentation, topic segmentation.

479 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
1 Introduction

C’est un truisme de nos jours de dire qu’Internet est une mine d’information, de ressources et
de savoirs qui peuvent sembler inﬁnis. Ces informations sont utiles a toute personne souhaitant
s’informer ou se distraire, mais également aux chercheurs de nombreux domaines (biologie,
sciences sociales, informatique, ...) pour qui Internet est devenu un objet de recherches. Cepen—
dant, malgré les progres liés, par exemple par le passage au WEB 2.0, on ne peut que constater
que les informations sur le Web ne sont pas ﬁables, ni méme accessibles aisément.

Les systemes de réponses aux questions sont un moyen efﬁcace de rendre cette information a la
fois plus accessible et plus ﬁable. Plus accessible, car ces systémes répondent de fagon précise,
rapide et concise aux questions qui leur sont posées en langue naturelle (a l’instar des moteurs de
recherche usuels 1). Plus ﬁable, car les réponses sont validées par le systéme (Peﬁas et al., 2007).

Une étape primordiale (dans toutes les acceptions du terme) pour les systémes de questions-
réponses (QR) est l’opération qui consiste a extraire le contenu textuel des pages. Pour cela, il est
nécessaire (Grau, 2004) de nettoyer, restructurer et ﬁltrer leur contenu (par exemple de corriger
les balises HTML et les erreurs d’encodage, d’éliminer les codes javascript résiduels et les spams).

La qualité (au sens de leur adéquation a la tache QR) des textes obtenus dépend fortement de
l’extracteur employé (Baroni et al., 2008) et de la qualité intrinséque de l’information contenue
dans les documents a l’origine. Une tache cruciale, mais souvent mésestimée, pour un systéme
QR est de pouvoir ﬁltrer les documents dont la qualité intrinséque est faible, aﬁn d’augmenter la
précision de la sélection des meilleurs candidats lors de l’extraction de réponses.

Au cours de travaux précédents (Foucault et al., 2011), nous avons mis en place une stratégie
de sélection des documents pertinents pour un systéme QR en francais, en complément de la
sélection de documents traditionnelle effectuée par le moteur de recherche du systéme. Cette
sélection repose sur une mesure de la qualité intrinseque des documents en utilisant un modele
de langue, qui nous foumit a priori des mesures objectives sur le degré d’informativité d’un texte.
Cette stratégie permet d’écarter de la liste des candidats sélectionnés par le moteur de recherche
du systéme, les documents les plus bruités (c’est—a—dire de faible qualité) pour la tache QR. Ici,
un texte est considéré comme pertinent ou non dans sa globalité.

Il est de coutume en QR (Ligozat, 2006) de découper les documents en passage soit au moment
de leur indexation, soit au cours des recherches. L’idée est de réduire la variabilité naturelle
des documents en taille et en contenu. En effet, avec des segments textuels plus petits, on peut
espérer une variabilité plus faible, et un contenu informationnel (corrélé au contenu linguistique,
en particulier lexical et sémantique) plus cohérent, ce qui en retour doit permettre l’extraction
de réponses plus pertinentes que celles issues de la globalité du texte. Cette stratégie a fait
ses preuves par le passé et des travaux récents autour du découpage de textes en passages
(Tiedemann, 2007; Khalid et Verberne, 2008) l’ont consolidée.

A notre connaissance, personne n’a tenté de segmenter les documents préalablement a leur
indexation, tout en découpant les segments obtenus en passages au moment des recherches dans
le but de réduire plus fortement la variabilité des documents. Dans cet article, nous détaillons
plusieurs expériences visant a mesurer l’impact d’une telle pré—segmentau'on sur la tache QR.

1. e.g. Google http : //www . google . fr
480 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Ainsi, on peut constater que 1’hypothése H0 selon laquelle la différence observée entre les
conditions bsln et ctrl n’est pas signiﬁcative pour les performences QR en top-10, est a peine
rejetée : la valeur de p obtenue dans ces conditions n’étant pas inférieure mais tout juste alignée
sur le seuil critique de signiﬁcativité a 15.

L’étude du nombre total de bonnes réponses fournies par le systeme selon leur position au sein
du top-10 tableau 2 (b) (bsln : 178, TT : 183 et ctrl : 190) conﬁrme cette tendance. On voit
aussi dans ce tableau que les réponses apportés par le systéme en condition ctrl (jusqu’a 12
réponses suppplémentaires, soit 3,9% de réponses en plus) se trouvent dans le top—3, la ou la
segmentation par TextTi1ing a tendance a apporter de nouvelles réponses a des rangs inférieurs.

Nous avons pu constaté que la segmentation des documents accélérait les (pré—)traitements QR.

Cond

rang bsln ctrl TT

Cond P MRR top- 10 #q ;   
bsln 31.4 39.6 57.6 309 3 17 26 19
ctrl 31.7 41.6 61.5 309 4 9 7 7
TT 32.0 40.5 59.2 309 5 8 7 11
Cond #r #xs #xl #w 6 6 4 6
bsln 97 6 8 198 7 7 5 3
ctrl 98 1 1 5 195 8 6 5 4
TT 99 1 1 2 197 9 2 2 8
10 0 4 0

Total 178 190 183

(a) (b)

TABLE 2 — (a) Résultats QR globaux par condition expérimentale (Cond). P : précision; MRR : rang moyen
réciproque; top-10 : précision sur 10 rangs. #q : nombre total de questions évaluées. #r, #xs, #xl et #w :
nombre total de réponsesjustes, trop courtes, trop longues etfausses, selon le top-1. (b) Focus sur les résultats
du top-10 présentés en (a), selon chaque position (rang) dans le classement (réponses justes uniquement).

df=1,a=.05 ctrl (A) / bsln (B) bsln (A) / 'IT (B) ctrl (A) / TT (B)
mesure #q r W Q p H0 r W Q p H0 r W Q p H0
P r 77 21 0 1 X 80 17 .02 .86 X 80 18 0 1 X
W 20 191 19 193 19 192
top-10 r 167 23 3.55 .05 / 164 14 .48 .48 X 174 16 1.44 .23 X
(MRR) W 11 108 19 112 9 110

TABLE 3 — Résultats de signiﬁcativité du test (bilatéral) de McNeamr pour les résultats QR du tableau 2 (a).
Q : khiz de McNemar. d f : degré de liberté. p : p-valeur. a : seuil critique. Ho : hypothése nulle (rejet : I).
#q : nombre total de questions pour lesquelles on a une réponse de méme nature ou non entre 2 conditions
A et B. r : réponse juste. W : réponsefausse. Les rectangles rW/rW représentent des tables de contingence.

15. p=0,059 si on augmente la précision du test de McNemar fournie tableau 3

489 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
5 Conclusion et perspectives

Au cours de travaux précédents (Foucault et al., 2011) nous avons mis en place une stratégie
de sélection de documents pertinents pour un systéme QR sur le francais. Elle s’appuie sur
un modéle de langue qui fournit a priori une mesure objective du degré d’informativité d’un
texte. Cette mesure de la qualité intrinséque des documents sert a ﬁltrer les documents non
pertinents pour la tache QR. L’effet d’un tel ﬁltrage appliqué a l’échelle globale des documents,
c’est avéré assez limité. La variabilité naturelle des pages web en taille et en contenu (comme leur
caractere multi—thématique) pénalise vraisemblablement le systeme dans sa tache. Nous avons
donc cherché a développer un systéme de segmentation qui permette d’appliquer ce ﬁltrage a
une échelle non plus globale mais locale, sur des sous—parties de document. Le travail présenté
dans cet article avait pour objectif de mettre un tel systeme de segmentation en place.

La question a laquelle nous avons voulu répondre dans cette article est la suivante : segmenter
les documents avant l’indexation, en plus du découpage habituel des documents en passages lors
de l’extraction des réponses, améliore—t—il les performances d’un systéme de questions—réponses ?

Pour répondre a cette question, nous avons testé deux types de pré—segmentation supportée par
une extraction de contenu textuel de pages web maison. L’une segmente les textes extraits via un
algorithme de texttiling classique (TextTiling) en blocs thématiques de taille variable. L’autre les
segmente uniformément en blocs de taille ﬁxe, sans découpage thématique.

Les résultats obtenus ne nous permettent pas de trancher nettement en faveur de l’une ou l’autre
de ces approches de segmentation. Cependant, les tendances observées suggérent qu’une pré-
segmentation des pages web comme nous l’avons déﬁnie peut servir un systéme QR; segmenter
les documents avant l’indexation aﬁn de renforcer l’effet du découpage de ces derniers en
passages lors de l’extraction des réponses, améliore la précision du systeme en terme de top—10
sans pour autant diminuer cette derniére en terme de top—1. Cette tendance est plus marquée
pour la segmentation uniforme de pages web que pour une segmentation plus << intelligente » a
l’aide de l’algorithme de TextTiling (sans analyse morphologique, le calcul des scores lexicaux se
faisant par block comparison). Ce constat est contradictoire avec d’autres travaux, mais conﬁrme
certaines conclusions apportées par Hearst dans ses travaux de segmentation thématique de
textes en Recherche d’Information (Hearst, 1997). Il serait intéressant de déterminer les raisons
amenant a ce constat. Si la nature des documents (page web versus texte), est l’une des raisons
qui pourrait l’expliquer, qu’en est—il par exemple de la longueur des documents et de la Version
du TextTiling que nous avons utilisé dans nos experiences ?

En perspective des travaux présentés dans cet article, nous projetons d’abord d’étudier l’impact
d’une pré—segmentation uniforme des pages web sur notre stratégie de sélection de documents
pertinents développée dans (Foucault et al., 2011). Concernant nos travaux de segmentation
de pages web en QR a partir de la représentation visuelle des pages, nous comptons évaluer la
pertinence de la procédure d’extraction mise en place au sein du systéme de segmentation de
pages web présenté dans cet article.

Remerciements

Ce travail a été ﬁnancé partiellement par l’OSEO, dans le contexte du programme Quaero.
490 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
Références

AGRESTI, A. (1990). Categorical data analysis. New York : Wiley, London.

ASIRVATHAM, A. P., RAVI, K. K., PRAKASH, A., KRANTHI, A. et RAVI, K. (2001). Web page classiﬁcation
based on document structure.

BARoN1, M., CHANTREE, E, KILGARRIFF, A. et SHAROFF, S. (2008). Cleaneval : a competition for
cleaning web pages. In LREC. European Language Resources Association.

BERNARD, G., ROSSET, S., GALIBERT, 0., BILINSKI, E. et ADDA, G. (2009). The limsi participation
in the qast 2009 track : experimentating on answer scoring. In CLEF’09, Corfu, Grece.

BRUNO, E., FAEssEL, N., GLOTIN, H., MAiTRE, J. L. et MICHEL., S. (2009). Ir web search based on
presentation and multimedia content. In Actes des 25emes Journees Bases de Donnees Avancees
(BDA 2009), pages 408-407.

CAI, D., YU, S., WEN, J.—R. et MA, W.—Y. (2003). VIPS : a vision—based page segmentation
algorithm. Rapport technique, Microsoft (MSR-TR-2003-79).

DECHELOTTE, D., SCHWENK, H., ADDA, G. et GAUVAIN, J.—L. (2007). Improved machine translation
of speech—to—text outputs. In Interspeech’07, Antwerp. Belgium.

EVERT, S. (2008). A lightweight and efﬁcient tool for cleaning web pages. In LREC. European
Language Resources Association.

FAEssEL, N. (2008). Indexation de blocs extraits de pages web en utilisant le rendu visuel. In
CORIA, pages 393-400. Université de Renne 1.

FALco, M.—H., MoRIcEAU, V et VILNAT, A. (2012). Kitten : a tool for normalizing html and
extracting its textual content. In CHAIR), N. C. C., CHOUKRI, K., DECLERCK, 'I‘., DOGAN, M. U.,
MAEGAARD, B., MARIANI, J., ODIJK, J. et PIPERIDIS, S., éditeurs : Proceedings of the Eight Interna-
tional Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey. European
Language Resources Association (ELRA).

FENG, J., HAEENER, P. et GILBERT, M. (2005). A learning approach to discovering web page
semantic structures. In Proceedings of the Eighth International Conference on Document Analysis
and Recognition, ICDAR’05, pages 1055-1059, Washington, DC, USA. IEEE Computer Society.

FOUCAULT, N., ADDA, G. et RossET, S. (2011). Language modeling for document selection in
question answering. In RANLP’1 1, pages 716-720, Hissar, Bulgaria.

GALIBERT, O. (2009). Approches et methodologies pour la réponse automatique c‘t des questions
adapatées a un cadre intéractif en domaine ouvert. These de doctorat, Paris—Sud11, LIMSI/CNRS.

GRAU, B. (2004). Méthodes Avancées pour les Systémes de Recherche d’Informations. In
Visualisation d’Inforrnation et Interaction, chapitre 10 : Systémes de question—réponse, pages
189-218. Hermes. Dir. M. Ihadjadene.

GUo, H., MAHMUD, J ., BORODIN, Y., STENT, A. et RAMAKRISHNAN, I. (2007). A general approach
for partitioning web page content based on geometric and style information. In Proceedings of
the Ninth International Conference on Document Analysis and Recognition — Volume 02, ICDAR
’07, pages 929-933, Washington, DC, USA. IEEE Computer Society.

GUPTA, S., KAISER, G., NEISTADT, D. et GRIMM, R (2003). Dom—based content extraction of html
documents. In Proceedings of the 12th international conference on World Wide Web, WWW ’03,
pages 207-214, New York, NY, USA. ACM.

491 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

HEARST, M. A. (1997). Texttiling : Segmenting text into multi—paragraph subtopic passages.
Computational Linguistics, 23:33-64.

KHALID, M. A. et VERBERNE, S. (2008). Passage retrieval for question answering using sliding
windows. In In Proceedings of COLING 2008, Workshop IR4QA.

KOHLSCHUTTER, C., FANKHAUSER, P et NEJDL, W. (2010). Boilerplate detection using shallow text
features. In Proc. of 3rd ACM International Conference on Web Search and Data Mining New York
City, NY USA (WSDM 2010).

KoVAcEvIc1, M., DILIGENTI, M., GORI, M. et M1LUTINoVIc1, V (2004). Visual adjacency mul-
tigraphs . a novel approach for a web page classiﬁcation. In Proceedings of the Workshop on
Statistical Approaches to Web Mining (SAWM), pages 38-49.

LIGOZAT, A. L. (2006). Exploitation etfusion de connaissances locales pour la recherche d’informa—
tions prec’ises. These de doctorat, Paris—Sud11, LIMSI/CNRS.

MCNEMAR, Q. (1947). Note on the sampling error of the difference between correlated propor-
tions or percentages. Psychometrika, 12(2):153—157.

MORICEAU, V et TANNIER, X. (2010). Fidji : using syntax for validating answers in multiple
documents. Information Retrieval, 13(5):507—533.

PENAS, A., RODRIGO, A. et VERDEJO, E (2007). Overview of the answer validation exercise 2007.
In CLEF, pages 237-248.

Q1, X. et DAVISON, B. D. (2009). Web page classiﬁcation : Features and algorithms. ACM
Computing Surveys, 41(2):12 :1—12 :31.

QUINTARD, L., GALIBERT, 0., ADDA, G., GRAU, B., LAURENT, D., MORICEAU, V, ROSSET, S., TANNIER,
X. et VILNAT, A. (2010). Question answering on web data : The QA evaluation in Quero. In
LREC '1 0, Valletta, Malta.

ROSSET, S., GALIBERT, 0., BERNARD, G., BILINSKI, E. et ADDA, G. (2008). The limsi participation
to the qast track. In Working Notes of CLEF 2008 Workshop, Aarhus, Denmark.

SALTON, G., SINGHAL, A., BUCKLEY, C. et MITRA, M. (1996). Automatic text decomposition using
text segments and text themes. In Proceedings of the the seventh ACM conference on Hypertext,
HYPERTEX'T ’96, pages 53-65, New York, NY, USA. ACM.

TIEDEMANN, J. (2007). Comparing document segmentation strategies for passage retrieval in
question answering. In Proceedings of the Conference on Recent Advances in Natural Language
Processing (RANLP’07), Borovets, Bulgaria.

TONEY, D., ROSSET, S., MAx, A., GALIBERT, O. et BILINSKI, E. (2008). An Evaluation of Spoken and
Textual Interaction in the RITEL Interactive Question Answering System. In (ELRA), E. L. R. A.,
éditeur : Proceedings of the Sixth International Language Resources and Evaluation (LREC’08),
Marrakech, Morocco.

VADREVU, S., GELGI, E et DAVULCU, H. (2005). Semantic partitioning of web pages. In Proceedings
of the 6th international conference on Web Information Systems Engineering, WISE’05, pages
107-118, Berlin, Heidelberg. Springer—Verlag.

492 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
2 Travaux connexes

L’idée de segmenter des documents textuels (article de journaux, livres, ...) en blocs de texte
est un axe de recherche activement exploré dans les années 90 en Recherche d’Information
(RI) textuelle. Pour réduire la variabilité linguistique d’un texte, une premiere idée, explorée
notamment par Salton (Salton et al., 1996) et Hearst (Hearst, 1997) consiste a opérer une
segmentation en blocs thématiques, les frontieres de blocs étant les endroits ou on détecte un
changement de theme. Des calculs de proximité lexicale entre blocs adjacents permettent de
réorganiser le texte d’origine en segments plus homogenes (mais toujours de taille variable). Chez
Salton, la proximité lexicale est obtenue a l’aide de mesures de distances vectorielles, chaque
bloc étant représenté par un vecteur lexical. En fonction de valeurs seuils sur ces distances, des
fusions entre paragraphes sont opérées. (Salton et al., 1996) effectue une fusion itérative, chaque
itération fusionnant les paragraphes jugés similaires selon cette distance, le document étant
exploré du début a la ﬁn, de gauche a droite. L’itération s’arréte lorsque le texte ne contient
plus que des blocs thématiquement homogenes. A partir de cette segmentation, Salton dérive
un graphe des relations thématiques qu’entretiennent les blocs au sein du document. Dans le
meme esprit, (Hearst, 1997) fusionne des blocs de textes entre eux, mais de maniere plus ﬁne.
Elle se fonde sur une analyse plus linguistique du texte que Salton. En effet, l’algorithme de
segmentation de Hearst (TextTiling) utilise la structure du discours (ici la théorie des chaines
lexicales) et se fonde sur une segmentation en unités lexicales élémentaires (tokens). Ces tokens
forment les unités de base pour la représentation de chaque bloc textuel. Cet algorithme utilise
une mesure de distance fondée sur les statistiques de co—occurence. TextTiling ne fonctionne pas
sur les paragraphes d’origine du texte contrairement 2 l’algorithme de Salton, mais sur des blocs
de pseudo-phrases construits sur la base de ces paragraphes.

Plus récemment, des travaux dans le contexte de la RI dans des documents multimédia ont
propose’ une nouvelle méthode d’indexation de pages web (Faessel, 2008). Celle—ci s’appuie sur
l’information des représentations DOM2 et CSS des pages web pour segmenter ces dernieres
avant indexation; (Bruno et al., 2009) démontrent que l’utilisation de ces inforrnations conduit 2‘:
une augmentation des performances d’un moteur de recherche dans sa tache. D’autres travaux
de segmentation pour la classiﬁcation automatique de pages web en theme (Qi et Davison, 2009)
utilisent la représentation DOM. Dans (Gupta et al., 2003) l’extraction du contenu textuel des
pages se fait automatiquement a l’aide de la structure des arbres DOM. Dans (Asirvatham et al.,
2001), l’échantillonnage des couleurs des images est utilisé pour catégoriser les pages qui les
contiennent. Dans (Kovacevicl et al., 2004), pour la meme tache, on utilise le rendu visuel. (Guo
et al., 2007) utilise des indices visuels (le rendu des pages fourni par le moteur de Mozilla 3),
géométriques (les coordonnées des éléments de l’arbre DOM au sein du rendu des pages) et
le style des pages (la répétition d’information) pour déﬁnir les blocs d’information pertinents
trouvés dans les pages et les annoter sémantiquement. Dans (Feng et al., 2005), les auteurs
étudient l’impact d’indices visuels et structurels sur la segmentation en blocs au travers d’une
tache de catégorisation fonctionnelle (blocs de type menu, titre, contenu, etc.). Dans (VadreVu
et al., 2005), les auteurs utilisent des criteres de découpage fondés sur l’homogénéité locale
du contenu informationnel des pages web (i.e. modele de segmentation base’ sur le concept de
path entropy) et d’indices visuels dérivés de leur représentation DOM. Certains systemes comme
VIPS (Cai et al., 2003) se fondent essentiellement sur ce type d’indices pour segmenter les pages.

2. Document Object Model (DOM) www.w3. org/DOM
3. www.mozi11a.org

481 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

A notre connaissance, aucune tentative d’application de ces techniques comme procédure de
segmentation de pages web n’a été faite en QR. Nous avons choisi dans un premier temps
d’utiliser un algorithme de premiere génération : le TextTiling de Hearst. Ce dernier a montré
son intérét pour la sélection de document pertinent en RI et se fonde sur une philosophie sous-
jacente commune a notre domaine en TAL (Traitement Automatique des langues). De plus, on en
trouve des implémentations en libre acces (contrairement a certains des algorithmes évoqués
plus haut). Par ailleurs, TextTiling présente l’avantage de fournir une segmentation en blocs
thématiques qui pourrait étre mise a contribution par la suite pour renforcer l’analyse sémantique
des documents par un systeme QR. Dans la perspective de travaux futurs en segmentation
de pages web autour de leur représentation Visuelle en QR, le TextTiling nous permettra de
bénéﬁcier d’une segmentation TAL de référence a comparer a des approches de RI non textuelles.
C’est dans cette optique que le travail présenté dans cet article se positionne.

Dans la section 3, nous présentons notre méthode de segmentation textuelle développée sur
la base du TextTiling de Hearst; dans la section 4 nous évaluons cette méthode sur la tache
Questions-Réponses. Nous concluons et présentons les perspectives de ce travail dans la section 5.

3 Segmentation textuelle de pages web

Dans cette section, nous présentons la méthode de segmentation de pages web que nous avons
mise en place pour la sélection de documents pertinents en QR.

La ﬁgure 1 présente les étapes-clés de la chaine de traitement qui correspond a cette métode : de
l’extraction du contenu textuel des pages a l’obtention de blocs de textes normalisés. Chaque
étape clé de cette chaine est décrite successivement dans les sections 3.2, 3.3 et 3.4.

3.1 Présentation générale

Collection de
pages web

Segmentation

 

FIGURE 1 — Notre procédure de segmentation de pages web en lien avec les (pré-)traitements QR.

482 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

En théorie, nous aurions dﬁ inverser les étapes de normalisation et de segmentation aﬁn que
la segmentation bénéﬁcie des traitements de normalisation (voir section 3.4). Cependant, une
telle inversion nécessite certaines modiﬁcations de notre chaine de normalisation : en effet, cette
derniére supprime l’indentation des textes utile a l’algorithme de TextTiling (voir section 3.3.1).
Nous n’avons malheureusement pas eu le temps de mettre en place les modiﬁcations adéquates.

3.2 Extraction

Notre procédure d’extraction se déroule en deux temps : pré-traitement (section 3.2.1) puis
représentation et extraction du contenu textuel des pages web (section 3.2.2). La phase de pré-
traitement des pages web est prise en charge par Kitten (Falco et al., 2012), un outil de traitement
de documents web développé au LIMSI. La représentation et l’extraction du contenu textuel des
pages web se fait sur les versions des pages pré—traitées par Kitten a l’aide du navigateur textuel
de pages web L_ynx4.

3.2.1 Pré-traitement des pages web

Le pré-traitement des documents web est réalisé a l’aide de Kitten. Ce choix est motivé par les
performances état de l’art que ce dernier a obtenu en qualité d’extracteur textuel (Falco et al.,
2012) dans le cadre d’évaluations QR sur le systéme Fidji (Moriceau et Tannier, 2010).

Kitten est un outil développé au LIMSI, dédié aux traitements et a la normalisation de données
Html. Les pages web fournies en entrée sont traitées et de nouvelles pages web au format Xhtml
valide W3C (encodées en UTF8) sont produites en sortie. Ces pages sont bien forrnées (correction
de leur squelette Html via jTid_y5), sans erreurs d’encodage (correction de leur encodage via
jChardet6 et conversion des caractéres Html spéciaux dans une base Unicode via HTMLCleaner 7).

Kitten produit des pages web exploitables en Extraction d’Inforrnation (EI) (Baroni et al., 2008)
sans appliquer d’heuristiques de nettoyage prédéﬁnies contrairement a des outils classiques
de nettoyage de contenu comme Boilerpipe (Kohlschiitter et al., 2010) ou Ncleaner (Evert,
2008) ; par exemple Ncleaner préserve pour l’essentiel le texte des balises <title>, <h1>,
<h2> , <h3>, <div> et <p> contenus dans le corps des pages, toute autre balise étant jugée
non pertinente pour l’extraction. Par ailleurs, Kitten dispose de nombreuses fonctions et ﬁltres
conﬁgurables qui le rendent ﬂexible. Ainsi, il est possible de conserver le contenu des attributs
<title> associé a un lien tout en supprimant le lien ou au contraire conserver ce lien tout en
supprimant les attributs <title> qui lui sont associés. Kitten se rapproche donc plutét d’outils
de développement populaires dans le domaine de l’EI web comme la librairie Python Beautiful
Soup 8 et le framework de crawling web Scrap_y9.

Kitten dispose de son propre module d’extraction de pages web et d’un systeme d’extraction
back—off basé sur Lynx. Celui—ci sert d’extracteur principal dans notre systéme de segmentation.

lynx .browser . org

. http : //jtidy. sourceforge .net

. portage Java de la détection automatique d’encodage d’une page du moteur de Mozilla
. http : //htmlcleaner . sourcef orge . net

. http : //www . crummy . com/software/Beautifulsoup

. scrapy . org

\O<X!\10\U'I:I>

483 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

3.2.2 Représentation des pages web et extraction textuelle

La représentation des pages utilisée par notre moteur d’extraction se fait grace a Lynx. Ce
dernier est un navigateur d’informations distribuées a portée générale pour Internet. 11 permet
de naviguer sur le Web depuis une console, en mode textuel uniquement. C’est un outil libre
intégré automatiquement dans la plupart des distributions Linux grand public comme Ubuntu,
qui intégre de nombreuses fonctionnalités web, dont l’extraction du contenu textuel de pages
web.

Nous avons retenu Lynx pour deux raisons. La premiere raison est qu’il fournit une extraction
textuelle de pages web qui reﬂéte leur rendu visuel. La seconde raison est que Lynx peut fournir
une décomposition linéaire du contenu des pages web en blocs de texte, adaptée a la plupart des
traitements d’analyses de documents en QR.

Si Lynx produit des extractions textuelles ﬁdéles au rendu visuel des pages web, l’agencement des
blocs d’extraction differe de celui observé dans un navigateur web classique du type Firefox 1°. En
effet, Lynx effectue une traversée gauche—droite descendante des pages web. En conséquence, les
blocs d’information textuelle rencontrés le long du parcours sont mis bout a bout dans le ﬁchier
d’extraction résultant. Ainsi, on trouve souvent dans les extractions textuelles de Lynx la suite
de blocs suivant (donnés ici selon leur contenu visuel) : bandeau, menus, colonne gauche, bloc
de contenu principal, colonne droite, puis pied de page. On peut aussi trouver des agencements
moins stéréotypiques selon le design des pages et trouver des séries de blocs de contenu principal
qui s’enchainent. L’étape d’extraction textuelle est réalisée par Lynx via le systeme d’extraction
back—off de Kitten.

3.3 Stratégie de segmentation

Nous avons utilisé deux stratégies de segmentation en blocs de texte. La premiere stratégie
consiste a segmenter les textes extraits par Lynx en blocs thématiques de taille variable par
l’algorithme de TextTiling de Hearst (Hearst, 1997). La seconde stratégie vise a controler la
précédente et segmente les textes extraits par Lynx de fagon uniforme en blocs de taille identique.

3.3.1 Segmentation par TextTiling

L’algorithme de TextTiling de Hearst (Hearst, 1997) segmente un texte en unités appelées
multi—paragraphes en fonction des thématiques abordées dans le texte. Traditionnellement, il
est utilisé pour détecter les thématiques dans des textes fortement structurés (e.g. articles de
journaux, textes issus de livres ...) et de grande taille (i.e. de plusieurs pages). Une des questions
sous—jacente aux expériences que nous avons menées était de savoir si cet algorithme pourrait
étre utile pour la segmentation de pages web.

L’algorithme, présenté en détail dans (Hearst, 1997) s’articule autour des 3 étapes suivantes :

— tokenisation;
— calcul de scores lexicaux;
— identification de frontiéres.

10. http : //www .mozi11a. org
484 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

La procédure de segmentation démarre par une étape de tokenization du texte qui lui est fourni
en entrée. Les mots qui sont des stopwords ne sont pas tokenisés et sont écartés. Les autres
subissent une étape de stemming basée sur une fonction d’anal_yse morphologique. Le texte est
tokenizé en pseudo—phrases de longueur prédéﬁnie censée représenter la longueur moyenne d’un
paragraphe (20 pseudo—phrases par défaut). Les paragraphes d’origine du texte servent de point
d’ancrage pour la tokenization, qui elle—méme dépend de l’indentation dans le texte.

L’algorithme évalue ensuite la proximité lexicale qui existe entre toutes les paires de blocs
adjacents possibles, et fournit un score fondé sur des co-occurences lexicales de tokens qui
mesure l’écart entre deux blocs. Les blocs sont constitués des pseudo—phrases obtenues lors de
la phase de tokenization. La détermination des scores lexicaux Varie selon la stratégie utilisée.
TextTiling dispose de 2 stratégies de comparaison de blocs différentes. La premiere (block
comparison), compare deux blocs adjacents de texte et calcule leur écart sur la base du nombre
de tokens qu’ils ont en commun. La seconde méthode (vocabulary introduction) évalue ce méme
écart sur la base des tokens issus des pseudo—phrases qui bordent la frontiére entre deux blocs.

Enﬁn, l’algorithme procéde au marquage des frontiéres de blocs pertinentes sur la base des
écarts mesurés a l’étape précédente. Ceci est fait a l’aide d’une fenétre glissante sur les blocs.
Les frontiéres de blocs présentant les plus forts écarts sont sélectionnées comme frontiéres
thématiques.

L’imp1émentau'on que nous avons utilisée du TextTiling est fournie par le package Python NLTK
sans la fonction d’anal_yse morphologique. Le calcul des scores lexicaux se fait par block comparison.

3.3.2 Segmentation uniforme

Cette segmentation représente la condition contr6le dans nos expériences. Elle se contente de
segmenter chaque ﬁchier texte qui lui est présenté en 8 blocs, c’est—a—dire la moyenne du nombre
de blocs de segmentation obtenus par TextTiling sur notre corpus d’expérimentation au cours de
tests préliminaires; ceci revient a ﬁxer la taille moyenne des blocs en nombre de lignes (Voir la
section 4.3).

La segmentation se fait selon un parcours linéaire du texte d’entrée, du début jusqu’a la ﬁn, les
points de coupe sont déterminés a l’avance selon le nombre total de lignes dans le texte et le
nombre maximum de blocs ﬁxé en sortie (8). Les textes trop petits (ceux de moins de 8 lignes)
ne sont pas segmentés et sont considérés comme des blocs uniques.

3.4 Normalisation

La normalisation est une étape durant laquelle un texte brut est traité aﬁn qu’une unité lexicale
soit explicitement déﬁnie. Au cours de la normalisation, le texte est transformé dans une forme
ou les mots et les nombres sont clairement délimités, la ponctuation est séparée des mots, et des
phrases ou pseudo—phrases sont clairement formées.

Notre normalisation passe par plusieurs étapes : séparation des mots et nombres de la ponctuation,
reconstruction de la casse sur les mots, ajout de la ponctuation le cas échéant et séparation en
phrases ou pseudo—phrases du texte d’entrée. Elle s’appuie sur des lexiques, des dictionnaires de
régles et des modéles de langue (Déchelotte et al., 2007).

485 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
4 Evaluation Questions-Réponses

4.1 Hypotheses de travail et conditions expérimentales

Les expériences présentées ont pour but d’examiner l’hypothése selon laquelle une fenétre
d’analyse plus réduite pour traiter les documents web permettrait une sélection du systeme QR
plus précise (c’est—a—dire obtenir des réponses plus pertinentes et en plus grand nombre). A cette
ﬁn, nous réalisons une segmentation avant l’indexation des documents en plus du découpage
habituel en passages réalisé lors de l’extraction des réponses. La segmentation des documents est
effectuée par TextTiling ou uniformément par notre algorithme de segmentation controle.

Les évaluations de l’impact de ces algorithmes de segmentation sur le systeme RITEL—QR (voir
section 4.2) sont présentées section 4.5 selon 3 conditions expérimentales :

— condition 1 : condition sans segmentation ou baseline (bsln) ;
— condition 2 : condition en segmentation par TextTiling (TT) ;
— condition 3 : condition en segmentation contréle (ctrl).

4.2 Systéme d’expérimentation : RITEL—QR

Le systéme RITEL—QR que nous utilisons dans les expériences est completement décrit dans (Ber-
nard et al., 2009) et (Galibert, 2009). Il s’agit d’un systeme qui a été concu a l’origine comme
un systéme de dialogue (Toney et al., 2008). D’un point de vue général, on peut dire que le
systéme s’appuie sur une analyse multi—niveaux, appliquée sur les questions et sur les documents.
Les documents sont totalement analysés et indexés d’apres les résultats d’analyse. La recherche
est effectuée dans l’index complet des documents. L’analyse permet de repérer et typer des
éléments pertinents d’information qui peuvent prendre la forme d’entités nommées, complexes
et structurées, de chunks morpho—syntaxiques, d’actes de dialogue et de marqueurs thématiques.

La premiere étape de RITEL—QR consiste a créer un descripteur de recherche (DDR) qui contient
toutes les informations utiles pour la recherche de documents, l’extraction de passages pertinents
et l’extraction de réponses. Ces informations sont les éléments de la question, leurs transforma-
tions possibles (dérivations morphologiques, synonymes etc. et les poids associés), et les types
attendus de la réponse (avec les poids associés). Ces types sont le plus souvent des types d’entités
nommées (personne, lieu ...) et reﬂetent la taxonomie d’entités utilisée au moment de l’analyse.

La sélection des documents consiste a fournir, a partir de l’index, les n documents les plus
pertinents, c’est—a—dire ceux contenant le plus d’informations présentes dans le DDR. En fonction
de ces informations et de leur densité, les documents obtiennent un score. Ensuite, des passages
sont extraits de chaque document. Ces passages sont de tailles Variables (une fenétre d’analyse
différente est appliquée selon la catégorie de la question) et sont scorés selon le méme principe
que les documents. L’extraction et l’éValuation des candidats réponses s’appuient sur la redon-
dance de ces derniers dans les documents et les passages. On considére que les éléments de
passages qui correspondent a un type possible de réponse du DDR et qui ne sont ni des élements
ni des sous—éléments déﬁnis dans le DDR, sont des candidats réponses potentiels. A chacun d’eux
est ﬁnalement attribué a un score de pertinence (Bernard et al., 2009).

486 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

4.3 Corpus

Le corpus de pages web utilisé dans nos expérimentations (ci—apres Q07fr) est composé de
499 734 pages web (5Gbytes) tout venant (i.e. journal, Wikipédia, blog, site de vente, forum,
etc.) et en francais. I1 nous est fourni par le projet Quaero 11 et sert de corpus standard dans
le cadre des évaluations QR au sein du projet (Quintard et al., 2010). Les questions de test et
d’entrainement utilisées (309 et 722 questions) proviennent du méme projet. Elles ont été créées
a partir de logs utilisateurs (Quintard et al., 2010) du moteur de recherche francais Exalead 12 et
sont composées de questions factuelles (e.g. Qui est Gandhi ?, Combien pése la tour Eiﬁel ?, 01‘: se
situe Pondichéry ? et Que signiﬁe CSDPTT ?).

Etape/Cond bsln ctr'l 'IT
extraction 497 228 497 228 497 228

segmentation - 3 686 749 3 857 585

(a) normalisation 485 037 3 660 264 3 686 875
annotation 485 037 3 660 264 3 686 875
indexation 484 060 3 658 988 3 686 857

| durée totale | 1,1j (26,5h) | 2,38j (57,3h) | 5,3j (127,5h) |
Stat/ Index nbB nbL nbB nbL nbB nbL
Min 1 1 1 1 1 1
(b) Max 1 461 075 8 1 262 186 9 277
Sd 0 7 646,5 0,01 18,7 8,4 32,61
Mean 1 295,4 8 19,4 7,3 20,9

TABLE 1 — (a) Nombre de blocs par condition expérimentale (Cond) selon leur type : segmenté (ctrl et TT)
ou non (bsln), selon les étapes nécessaires a les créer (Etape) et la durée totale de traitement correspondant.
(b) Statistiques (Stat) du nombre de blocs (nbB) et de lignes (nbL) moyens (Mean), minimum (Min),
maximum (Max) et déviation standard (Std) des index (Index) relatifs a chaque condition expérimentale.

Le tableau 1 (a) présente les résultats des traitements (en terme de nombre de ﬁchiers traités) de
chacune des étapes de notre chaine de segmentation, ainsi que des étapes de pré—traitements
QR (annotation et indexation), pour chacune des conditions d’expérimentations (Cond) a partir
de Q07fr. Ces résultats suivent le schéma de la ﬁgure 1. Chaque sortie d’une étape dépend du
résultat qui précéde pour une condition donnée. On peut noter que le nombre de ﬁchiers issus de
la segmentation dans les conditions controle (ctrl) et TextTiling (TT) sont proches (environ 20K
blocs de différence). Les blocs indexés dans ces 2 conditions correspondent aux 484 060 textes
indexés en condition baseline (bsln). La durée des traitements (paralléles/mémes serveurs) dans
ces conditions est respectivement de 2 a 5 fois plus longue qu’en condition sans segmentation.

Le tableau 1 (b) présente le nombre moyen de blocs (nbB) et de lignes par bloc (nbL) obtenus en
conditions contréle et TextTiling. Ces informations sont aussi données pour la condition baseline
at titre indicatif (un bloc par ﬁchier). On constate que l’algorithme de TextTiling et le contr6le se
comportent de facon tres similaire : en moyenne, le nombre de blocs produits (ctrl : 8 et TT :
7,3) ainsi que leur taille (ctrl : 19,4 et TT : 20,9) sont semblables. Le TextTiling produit une
légére sur—segmentation : la déviation standard est 2 fois plus élevée que celle du controle (ctrl)
en nombre de lignes, le maximum de blocs pour un méme document étant également plus grand.

11. http://www.quaero.org
12. http://www.exa1ead. com

487 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
4.4 Métriques d’évaluation

Dans ce travail, nous employons les métriques habituellement utilisées en QR :

— la précision déﬁnie équation (1), est le ratio entre le nombre de réponses correctes et le nombre
total de questions. Si le systeme est capable de fournir plusieurs réponses par question, on ne
considere que la premiere. CR, est le rang de la premiere réponse correcte pour la question i.
CR, prend pour valeur +00 si aucune réponse correcte n’a été trouvée.

— Le top—n déﬁni équation (2), mesure la précision selon les réponses correctes de rang 1 a n.

— Le Mean Reciprocal Rank (Moyenne des Réciproques des Rangs ou MRR) déﬁni équation (3),
permet de mesurer la qualité du classement des réponses (10 par question) effectué par le
systéme. La réponse correcte la mieux classée est pondérée par l’inverse de son rang initial.
Une absence de réponse correcte entraine une contribution nulle. Le score ﬁnal correspond a
la moyenne des contributions.

 #CR,-=1 #CR,-Sn 2%,.
precision = T (1) top—n = T (2) MRR = T
#quest1ons #quest1ons #quest1ons

4.5 Résultats

Les résultats sont présentés dans les parties (a) et (b) du tableau 2. On a utilisé le test de
McNemar (McNemar, 1947; Agresti, 1990) de R13 pour juger de la signiﬁcativité des résultats
présentés tableau 2 (a). Les résultats du test sont donnés tableau 3 14.

On constate, tableau 2 (a), que les deux conditions de segmentation testées sont proches de la
condition baseline suggérant ainsi que la segmentation n’apporte pas de réels bénéﬁces a notre
systéme QR. Les performances du systéme sont trés proches en terme de précision (0,6 point
de différence au plus entre bsln et TT). Mais le MRR présente un écart plus important entre les
conditions (2 points entre les conditions bsln et ctrl, et 1 point entre les conditions bsln et TT).
La segmentation ctrl semble donc permettre au systeme de trouver de meilleures réponses (i.e.
des réponses plus précises) qu’en condition baseline ou TextTiling. Toutefois, d’aprés les tests
statistiques des performances QR présentés tableau 3, ceci n’est qu’une tendance.

Le test de McNemar (McNemar, 1947), que nous avons utilisé dans nos expériences, établit la
signiﬁcativité des résultats observés entre 2 conditions A et B et une mesure M donnée, selon
des variations observées er1tre A et B, synthétisées dans une table de contingence 2x2. De la, le
test (bilatéral) estime une valeur Q (i.e. khiz de McNemar) pour un degré de liberté d f donné et
dérive une valeur p. Si p est inférieure (ou égale) au seuil critique a, l’hypothése nulle H0 est
rejetée et la différence observée entre A et B est jugée signiﬁcative. Dans notre cas, une table
de contingence comptabilise le total de questions (#q) pour lesquelles RITEL—QR trouve une
réponse de méme exactitude en conditions A et B. 11 y a 4 types de compte, nombre total de
questions avec une réponse : correcte (r) selon A et selon B (#rr), fausse (w, xs ou xl) selon A et
selon B (#WW), correcte selon A et fausse selon B (#rVV) et inversement (#Wr).

13. http : //www.r—project . org
14. Ces derniers sont les mémes sur le top-10 et le MRR, puisque ce test ne distingue pas les réponses selon leur rang.

488 © ATALA

