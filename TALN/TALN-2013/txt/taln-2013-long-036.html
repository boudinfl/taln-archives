<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title>Approches &#224; base de fr&#233;quences pour la simplification lexicale</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>Approches &#224; base de fr&#233;quences pour la simplification lexicale
</p>
<p>Anne-Laure Ligozat1,2 Cyril Grouin1,3
Anne Garcia-Fernandez4 Delphine Bernhard5
</p>
<p>(1) LIMSI&#8211;CNRS, Orsay (2) ENSIIE, &#201;vry (3) INSERM U872 Eq 20 &amp; UPMC, Paris
(4) LAS, CNRS/EHESS/Coll&#232;ge de France, Paris (5) LiLPa, Universit&#233; de Strasbourg, Strasbourg
</p>
<p>R&#201;SUM&#201;
La simplification lexicale consiste &#224; remplacer des mots ou des phrases par leur &#233;quivalent plus
simple. Dans cet article, nous pr&#233;sentons trois mod&#232;les de simplification lexicale, fond&#233;s sur
diff&#233;rents crit&#232;res qui font qu&#8217;un mot est plus simple &#224; lire et &#224; comprendre qu&#8217;un autre. Nous
avons test&#233; diff&#233;rentes tailles de contextes autour du mot &#233;tudi&#233; : absence de contexte avec un
mod&#232;le fond&#233; sur des fr&#233;quences de termes dans un corpus d&#8217;anglais simplifi&#233; ; quelques mots de
contexte au moyen de probabilit&#233;s &#224; base de n-grammes issus de donn&#233;es du web ; et le contexte
&#233;tendu avec un mod&#232;le fond&#233; sur les fr&#233;quences de cooccurrences.
</p>
<p>ABSTRACT
Studying frequency-based approaches to process lexical simplification
</p>
<p>Lexical simplification aims at replacing words or phrases by simpler equivalents. In this paper,
we present three models for lexical simplification, focusing on the criteria that make one word
simpler to read and understand than another. We tested different contexts of the considered
word : no context, with a model based on word frequencies in a simplified English corpus ; a few
words context, with n-grams probabilites on Web data, and an extended context, with a model
based on co-occurrence frequencies.
</p>
<p>MOTS-CL&#201;S : simplification lexicale, fr&#233;quence lexicale, mod&#232;le de langue.
KEYWORDS: lexical simplification, lexical frequency, language model.
</p>
<p>1 Introduction
</p>
<p>La simplification textuelle consiste &#224; rendre les textes plus faciles &#224; lire, par exemple pour des
enfants ou des locuteurs non natifs. Des documents de tout type peuvent ainsi &#234;tre rendus
accessibles &#224; diff&#233;rents publics ; dans notre travail, nous consid&#233;rerons un public de locuteurs
non natifs de l&#8217;anglais et des documents de domaine g&#233;n&#233;ral.
</p>
<p>Deux sous-t&#226;ches sont g&#233;n&#233;ralement distingu&#233;es dans la simplification textuelle automatique,
bien qu&#8217;elles ne soient pas totalement d&#233;connect&#233;es : la simplification syntaxique et la simplifica-
tion lexicale. Nous nous int&#233;ressons plus particuli&#232;rement &#224; la probl&#233;matique de la simplification
lexicale. Ce type de simplification consiste &#224; remplacer des mots ou des phrases par des &#233;quiva-
lents plus simples. Afin de proc&#233;der &#224; de telles substitutions, il importe d&#8217;abord d&#8217;identifier des
mots &#233;quivalents qui correspondent au contexte, puis de choisir le mot le plus simple. Dans le
cadre de nos travaux sur la simplification, nous nous sommes int&#233;ress&#233;s &#224; la probl&#233;matique de la
simplification lexicale, et plus particuli&#232;rement &#224; l&#8217;&#233;valuation de mots &#233;quivalents en contexte,
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>493 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>en fonction de leur degr&#233; de simplicit&#233;. Dans cet article, nous pr&#233;sentons les exp&#233;riences sup-
pl&#233;mentaires que nous avons men&#233;es &#224; partir des syst&#232;mes que nous avons cr&#233;&#233;s lors de notre
participation &#224; cette campagne (Ligozat et al., 2012). Nous avons d&#233;fini trois types de crit&#232;res
fond&#233;s sur les fr&#233;quences des mots &#224; simplifier et de leurs substituts : les crit&#232;res sur le mot lui-
m&#234;me, des crit&#232;res reposant sur les contextes locaux, et des crit&#232;res sur les contextes th&#233;matiques.
Ce dernier type de crit&#232;re constitue une exp&#233;rience nouvelle par rapport &#224; notre participation
d&#8217;origine &#224; SemEval 2012.
</p>
<p>La simplification lexicale est proche de plusieurs t&#226;ches. Sa premi&#232;re &#233;tape consiste &#224; choisir
les substituts possibles d&#8217;un mot donn&#233; et requiert une d&#233;sambigu&#239;sation s&#233;mantique au niveau
du mot et une recherche de paraphrases. La seconde &#233;tape consid&#232;re tous les substituts ou
paraphrases possibles, et vise &#224; ordonner ces &#233;l&#233;ments en fonction de leur niveau de simplicit&#233;.
La simplification peut &#233;galement &#234;tre consid&#233;r&#233;e comme une t&#226;che de traduction entre une
langue standard et une version simplifi&#233;e de cette langue ; nous notons que dans les traductions
habituelles, il est difficile de produire des corpus totalement parall&#232;les.
</p>
<p>2 &#201;tat de l&#8217;art
</p>
<p>Alors que la simplification syntaxique a fait l&#8217;objet d&#8217;un grand nombre de travaux (Siddhar-
than, 2006; Woodsend et Lapata, 2011; Watanabe et al., 2009), la simplification lexicale a
comparativement &#233;t&#233; moins trait&#233;e.
</p>
<p>Les premiers travaux sur la simplification lexicale ont consist&#233; &#224; remplacer des mots par des
synonymes plus communs issus de WordNet ou d&#8217;autres dictionnaires (Devlin, 1999; Carroll
et al., 1999; Lal et R&#252;ger, 2002). La complexit&#233; lexicale est g&#233;n&#233;ralement estim&#233;e en termes
de (i) longueur du mot (nombre de caract&#232;res) ou nombre de syllabes, ou (ii) de fr&#233;quence du
mot, fond&#233;e sur une analyse en corpus ou une base de donn&#233;es, telle que la base de donn&#233;es
psycholinguistique MRC (Lal et R&#252;ger, 2002). Drndarevic&#769; et Saggion (2012) ont montr&#233; que
la fr&#233;quence des mots et leur longueur en nombre de caract&#232;res ou de syllabes &#233;taient des
indicateurs utiles de complexit&#233; lexicale &#224; partir d&#8217;un corpus parall&#232;le espagnol.
</p>
<p>Des approches plus r&#233;centes se sont int&#233;ress&#233;es &#224; l&#8217;acquisition de simplifications lexicales. Les
travaux de Yatskar et al. (2010) ont port&#233; sur l&#8217;obtention de simplifications lexicales (&#171; collaborate &#187;
&#8594; &#171; work together &#187;) &#224; partir des r&#233;visions des pages Wikipedia r&#233;dig&#233;es en anglais simplifi&#233; 1.
Les auteurs d&#233;rivent ainsi des probabilit&#233;s de simplification au moyen d&#8217;un mod&#232;le fond&#233; sur
les m&#233;ta-donn&#233;es d&#8217;&#233;dition de chaque page. Les 100 plus importantes paires extraites par ces
mod&#232;les constituent des simplifications avec une pr&#233;cision &#233;lev&#233;e (86% sur le meilleur mod&#232;le),
ce qui repr&#233;sente un point de d&#233;part int&#233;ressant pour l&#8217;acquisition de simplification lexicale.
Pr&#233;cisons que ce mod&#232;le ne tient cependant pas compte du contexte.
</p>
<p>Biran et al. (2011) s&#8217;appuient sur des paires de substitution apprises &#224; partir du corpus de la
Wikipedia en anglais et en anglais simplifi&#233;, en fonction de la similarit&#233; des contextes des mots,
de leur fr&#233;quence et de leur longueur. Ces paires sont ensuite utilis&#233;es pour simplifier certains
mots d&#8217;une phrase, en tenant compte de la similarit&#233; entre la phrase et les contextes des mots
consid&#233;r&#233;s.
</p>
<p>1. L&#8217;encyclop&#233;die collaborative en ligne Wikipedia propose, pour certains articles, une version en anglais simplifi&#233;
appel&#233; &#171; Simple English &#187; &#224; destination des locuteurs non natifs de l&#8217;anglais.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>494 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Woodsend et Lapata (2011) ont impl&#233;ment&#233; une approche de simplification fond&#233;e sur une
grammaire quasi synchrone, qui apprend des r&#233;&#233;critures de simplification &#224; partir de phrases
source/cible extraites des pages Wikipedia r&#233;dig&#233;es en anglais et en anglais simplifi&#233;. Ce mod&#232;le
int&#232;gre &#233;galement des substitutions lexicales, avec pour objectif le remplacement d&#8217;un mot
en fonction de son contexte syntaxique. L&#8217;acquisition de substituts lexicaux reste cependant
limit&#233;e aux termes pr&#233;sents en corpus, ce qui r&#233;duit l&#8217;int&#233;r&#234;t d&#8217;un tel mod&#232;le pour une t&#226;che de
simplification lexicale.
</p>
<p>Dans ce travail, nous envisageons d&#8217;&#233;tudier la simplification lexicale en elle-m&#234;me, en nous
attachant &#224; identifier les crit&#232;res qui font qu&#8217;un mot est plus simple &#224; lire et &#224; comprendre qu&#8217;un
autre mot. Notre approche repose principalement sur les mod&#232;les &#224; base de n-grammes, tels
que les mod&#232;les d&#233;crits par Jauhar et Specia (2012). Nous avons cependant essay&#233; d&#8217;affiner ces
mod&#232;les en tenant compte des diff&#233;rents contextes d&#8217;apparition du mot &#233;tudi&#233;. Notre travail
repose sur le cadre exp&#233;rimental fourni par la t&#226;che de simplification lexicale propos&#233;e par la
campagne d&#8217;&#233;valuation SemEval 2012 (Specia et al., 2012).
</p>
<p>3 Crit&#232;res de simplification d&#8217;un &#233;l&#233;ment lexical
</p>
<p>Nous nous proposons donc d&#8217;&#233;tudier la simplification lexicale sous l&#8217;angle de la caract&#233;risation
du caract&#232;re simple d&#8217;&#233;l&#233;ments lexicaux en contexte. L&#8217;&#233;tude de la litt&#233;rature et du corpus de la
campagne SemEval 2012 nous a permis de d&#233;gager plusieurs crit&#232;res pour choisir un &#233;l&#233;ment
lexical dans un contexte donn&#233; (voir par exemple Fran&#231;ois et Fairon (2012); Jauhar et Specia
(2012)) :
&#8211; des crit&#232;res concernant l&#8217;&#233;l&#233;ment lui-m&#234;me, principalement issus des mesures de lisibilit&#233; de
</p>
<p>textes : taille de l&#8217;&#233;l&#233;ment en nombre de caract&#232;res ou de syllabes, fr&#233;quence de l&#8217;&#233;l&#233;ment en
corpus, pr&#233;sence de cet &#233;l&#233;ment dans des listes de mots simples, caract&#233;ristiques psycholin-
guistiques de l&#8217;&#233;l&#233;ment (comme par exemple caract&#232;re concret, &#226;ge d&#8217;acquisition ou autres
provenant de la MRC Psycholinguistic Database)...
</p>
<p>&#8211; le contexte local de l&#8217;&#233;l&#233;ment, et notamment dans le cas de l&#8217;appartenance &#224; une collocation.
Dans la phrase &#171; Put granola bars in bowl . &#187;, le contexte local &#171; granola &#187; nous permet d&#8217;identifier
le substitut &#171; bar &#187; comme meilleur choix possible ;
</p>
<p>&#8211; le contexte plus g&#233;n&#233;ral de l&#8217;&#233;l&#233;ment, notamment son contexte th&#233;matique. Ainsi, dans la
phrase &#171; The film shows Afghan mercenaries to be involved with the separatists , suggesting that
the present struggle in Kashmir has been hijacked by foreign extremists , who are shown discussing
the loss of Bangladesh in the 1971 war , providing it as a justification for their present acts of
revenge . &#187;, il est n&#233;cessaire de prendre en compte tout le contexte du mot cible &#171; film &#187; pour
identifier le substitut &#171; documentary &#187; comme meilleur choix par rapport aux autres substituts
possibles &#171; film, movie, picture &#187;.
</p>
<p>Nous &#233;mettons l&#8217;hypoth&#232;se que l&#8217;utilisation d&#8217;un contexte plus important permet de mieux tenir
compte des sp&#233;cificit&#233;s s&#233;mantiques des substituts et de l&#8217;environnement linguistique dans lequel
ces substituts &#233;voluent.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>495 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>4 Corpus
</p>
<p>Dans le cadre de ce travail, nous avons poursuivi les exp&#233;riences que nous avions men&#233;es lors de
notre participation &#224; la t&#226;che de simplification lexicale de l&#8217;anglais propos&#233;e par la campagne
SemEval 2012 2. &#192; ce titre, nous avons appliqu&#233; nos m&#233;thodes et effectu&#233; de nouvelles exp&#233;riences
en nous appuyant sur les corpus de la campagne.
</p>
<p>4.1 Pr&#233;sentation
</p>
<p>Dans le cadre de cette t&#226;che, deux corpus ont &#233;t&#233; fournis. Le corpus d&#8217;apprentissage contient
300 instances tandis que le corpus de test, utilis&#233; pour l&#8217;&#233;valuation, se compose de 1710
instances. Le corpus d&#8217;apprentissage s&#8217;accompagne des annotations de r&#233;f&#233;rence pour permettre
le d&#233;veloppement des syst&#232;mes.
</p>
<p>Le corpus se compose de textes courts issus de documents r&#233;cup&#233;r&#233;s sur internet, dans lesquels
un mot cible a &#233;t&#233; choisi, et pour lequel plusieurs substituts possibles doivent &#234;tre ordonn&#233;s.
Dans l&#8217;exemple suivant, le mot &#171; outdoor &#187; est la cible &#224; traiter et tous les autres mots du texte
constituent le contexte de ce mot cible.
</p>
<p>&lt;instance id=&quot;270&quot;&gt;
&lt;context&gt;With the growing demand for these fine garden furnishings , they found it
necessary to dedicate a portion of their business to &lt;head&gt;outdoor&lt;/head&gt; living
and patio furnishings .&lt;/context&gt;
&lt;/instance&gt;
</p>
<p>Pour cette cible, les substituts propos&#233;s sont les suivants : {alfresco, outside, open-air, outdoor}.
Les informations disponibles sur la constitution de la r&#233;f&#233;rence nous permettent de savoir que
ces substituts ont &#233;t&#233; ordonn&#233;s par des locuteurs non natifs de l&#8217;anglais (respectivement 4 et 5
annotateurs pour les corpus d&#8217;apprentissage et de test) selon leur degr&#233; de simplicit&#233; d&#233;croissant.
Nous n&#8217;avons cependant pas connaissance d&#8217;un guide d&#8217;annotation auquel se r&#233;f&#233;rer. L&#8217;objectif de
la t&#226;che consiste donc &#224; ordonner ces diff&#233;rents substituts en fonction de leur degr&#233; de simplicit&#233;.
</p>
<p>La s&#233;quence de r&#233;f&#233;rence associ&#233;e &#224; ces substituts est la suivante : (outdoor, open-air, {outside,
alfresco}), o&#249; &#171; outdoor &#187; est consid&#233;r&#233; comme le substitut le plus simple, tandis que &#171; outside &#187; et
&#171; alfresco &#187; sont consid&#233;r&#233;s comme les substituts les plus complexes &#224; &#233;galit&#233;.
</p>
<p>4.2 Statistiques
</p>
<p>Nous donnons ci-apr&#232;s quelques &#233;l&#233;ments statistiques calcul&#233;s sur les corpus d&#8217;apprentissage et
de test, afin de repr&#233;senter la difficult&#233; de la t&#226;che.
</p>
<p>Nombre de tokens dans chaque contexte. Dans un premier temps, nous avons &#233;tudi&#233; le
nombre de tokens dans chaque contexte, un token &#233;tant consid&#233;r&#233; comme une cha&#238;ne de
caract&#232;res entre deux espaces. Alors que les contextes les plus longs se retrouvent dans le corpus
de test, nous avons relev&#233; que les contextes sont, en moyenne, plus courts dans le corpus de test
</p>
<p>2. http://www.cs.york.ac.uk/semeval-2012/task1/
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>496 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>que dans le corpus d&#8217;apprentissage, avec un nombre moyen de 27,6 tokens dans le test contre
28,9 dans l&#8217;apprentissage (tableau 1, gauche). Les contextes les plus courts se composent de 5
tokens dans les deux corpus. Ainsi, le contexte &#171;Well , perhaps not . &#187; se rapporte au mot cible
&#171; well &#187; dans le corpus d&#8217;apprentissage alors que le contexte &#171; The spin&#8217;s are flat . &#187; se rapporte au
mot cible &#171; flat &#187; dans le corpus de test. Cela signifie qu&#8217;il existe des informations contextuelles
pour pratiquement tous les mots cibles, et que ce contexte peut &#234;tre utilis&#233; pour choisir les
substituts qui conviennent le mieux &#224; ce contexte.
</p>
<p>Corpus Nombre de tokens Nombre de substitutsMin Max Moy Min Max Moy
Apprentissage 5 76 28,9 2 9 4,8
Test 5 92 27,6 1 10 5,0
</p>
<p>TABLE 1 &#8211; Nombre minimum, maximum et moyen de tokens par contexte (gauche) et nombre
minimum, maximum et moyen de substituts par instance (droite)
</p>
<p>Nombre de substituts par contexte. Nous avons &#233;galement calcul&#233; le nombre de substituts
propos&#233;s pour chaque cible dans chaque instance &#224; traiter. Il y a, en moyenne, cinq substituts
propos&#233;s par instance dans les deux corpus (tableau 1, droite). Chaque instance se compose ainsi
de plusieurs substituts &#224; ordonner.
</p>
<p>Fr&#233;quence d&#8217;utilisation des substituts en corpus. Un point int&#233;ressant concerne le nombre
de fois que chaque substitut est propos&#233; dans chacun des corpus. La majorit&#233; des ensembles
propos&#233;s de substituts se composent de substituts propos&#233;s une seule fois. Nous remarquons
cependant qu&#8217;il y a davantage de substituts propos&#233;s une seule fois dans le corpus d&#8217;apprentissage
que dans le corpus de test. Nous reportons sur le graphique 1 le pourcentage d&#8217;utilisation des
substituts, class&#233;s par nombre d&#8217;occurrences d&#233;croissant, propos&#233;s respectivement dans les corpus
d&#8217;apprentissage (en rouge) et de test (en bleu).
</p>
<p>1 2 3 4 5 6 7 8 9 10 11 12 13 14
0
</p>
<p>10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>60
</p>
<p>Nombre d&#8217;occurrences
</p>
<p>Po
ur
</p>
<p>ce
nt
</p>
<p>ag
e
</p>
<p>FIGURE 1 &#8211; Pourcentage d&#8217;utilisation de chaque substitut sur le corpus d&#8217;apprentissage (rouge) et
de test (bleu), class&#233; par nombre d&#8217;occurrences d&#233;croissant
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>497 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Si la majorit&#233; des substituts est propos&#233;e une seule fois (62,6% des substituts du corpus d&#8217;appren-
tissage et 51,8% dans le corpus de test ne sont pr&#233;sent&#233;s qu&#8217;une seule fois), certains apparaissent
n&#233;anmoins un nombre &#233;lev&#233; de fois (les substituts pr&#233;sent&#233;s deux fois constituent 16,0% et
17,5% du nombre total de substituts). En mati&#232;re de pr&#233;sentation maximum, le substitut &#171; unplea-
sant &#187; est propos&#233; jusqu&#8217;&#224; 14 fois dans le corpus d&#8217;apprentissage (sur un total de 633 substituts)
alors que &#171; consequently &#187; est propos&#233; 26 fois dans le corpus de test (sur un total de 2 774
substituts).
</p>
<p>Cat&#233;gories morpho-syntaxiques des substituts. Chaque mot cible rel&#232;ve d&#8217;une cat&#233;gorie
morpho-syntaxique parmi quatre cat&#233;gories possibles. Nous avons &#233;tudi&#233; la r&#233;partition des mots
cibles en fonction de leur cat&#233;gorie d&#8217;appartenance (tableau 2).
</p>
<p>Cat&#233;gorie Apprentissage Test
Adjectif 26,5% 27,5%
Adverbe 14,7% 17,5%
Nom 23,5% 29,2%
Verbe 23,5% 25,7%
Adjectif ou Nom 5,9% &#8212;
Nom ou Verbe 5,9% &#8212;
</p>
<p>TABLE 2 &#8211; Pourcentage de mots cibles appartenant &#224; chaque cat&#233;gorie morpho-syntaxique
</p>
<p>Nous remarquons que la r&#233;partition des mots cibles dans chacune des cat&#233;gories morpho-
syntaxique est similaire entre les deux corpus. Cependant, le corpus d&#8217;apprentissage se compose
de mots cibles ambigus dans la mesure o&#249; certains de ces mots peuvent relever de deux cat&#233;gories
potentielles (adjectif ou nom, nom ou verbe). Cette ambigu&#239;t&#233; disparait dans le corpus de test.
</p>
<p>4.3 Exp&#233;riences de base
</p>
<p>Trois exp&#233;riences de base (baselines) ont &#233;t&#233; fournies par les organisateurs en accompagnement
du corpus d&#8217;apprentissage :
&#8211; La premi&#232;re rel&#232;ve d&#8217;un simple ordonnancement au hasard des substituts de chaque ensemble
propos&#233; ;
</p>
<p>&#8211; La seconde conserve la liste de substituts propos&#233;s dans l&#8217;ordre dans lequel elle est fournie ;
&#8211; La troisi&#232;me (appel&#233;e &#171; fr&#233;quence simple &#187;) repose sur l&#8217;utilisation des fr&#233;quences des termes
pr&#233;sents dans le corpus Google Web 1T.
</p>
<p>Ces exp&#233;riences de base permettent, d&#8217;une part de fixer le seuil minimum &#224; atteindre, et d&#8217;autre
part de pr&#233;senter de premi&#232;res approches simples pour r&#233;soudre la probl&#233;matique soulev&#233;e.
</p>
<p>5 M&#233;thodes
</p>
<p>Nous avons impl&#233;ment&#233; trois mod&#232;les distincts qui correspondent &#224; diff&#233;rentes tailles de contextes
que nous avons envisag&#233;s autour des mots cibles : (i) pas de contexte, (ii) quelques mots, et
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>498 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>(iii) le contexte entier. L&#8217;id&#233;e sous-jacente de ces exp&#233;riences concerne le fait qu&#8217;un substitut peut
&#234;tre pr&#233;f&#233;r&#233; &#224; un autre parce qu&#8217;il est plus fr&#233;quent (le contexte n&#8217;est donc pas n&#233;cessaire), parce
qu&#8217;il appartient &#224; une expression (auquel cas, le contexte compos&#233; de quelques mots se r&#233;v&#232;le
utile), ou bien, parce qu&#8217;il est le plus adapt&#233; sur le plan s&#233;mantique (l&#8217;ensemble du contexte est
alors utilis&#233;).
</p>
<p>5.1 Mod&#232;le fond&#233; sur les fr&#233;quences des termes
</p>
<p>Notre premier mod&#232;le ne prend pas en compte le contexte d&#8217;utilisation des mots et repose sur
les fr&#233;quences des substituts trouv&#233;es dans un corpus r&#233;dig&#233; en anglais simplifi&#233;, la Simple
English Wikipedia (SEW). Notre hypoth&#232;se de travail repose sur le fait que les mots les plus
fr&#233;quemment employ&#233;s dans ce corpus seront pr&#233;f&#233;r&#233;s par les locuteurs non natifs de l&#8217;anglais.
Ce public correspond au profil des annotateurs utilis&#233;s pour la t&#226;che de simplification lexicale.
La SEW a d&#233;j&#224; &#233;t&#233; utilis&#233;e dans des travaux portant sur la simplification automatique de textes
(Yatskar et al., 2010). D&#8217;autre part, puisque les corpus SemEval sont constitu&#233;s de donn&#233;es issues
d&#8217;internet, nous estimons qu&#8217;ils sont proches des textes de Wikipedia du point de vue linguistique.
</p>
<p>Dans un premier temps, nous avons converti la SEW au format texte &#224; partir de l&#8217;archive du 27
f&#233;vrier 2012 dont nous avons extrait le contenu textuel gr&#226;ce &#224; l&#8217;outil wikipedia2text 3. Le fichier
texte final contient approximativement 10 millions de mots.
</p>
<p>Nous avons ensuite extrait des n-grammes de mots, en variant la taille des n-grammes de 1 &#224;
3 mots, ce qui est suffisant pour la plupart des substituts. Le corpus d&#8217;apprentissage contient
seulement deux substituts compos&#233;s de quatre mots, ce qui constitue la taille la plus importante.
Nous avons n&#233;anmoins constat&#233; que le corpus de test comprend des substituts pouvant aller
jusqu&#8217;&#224; sept mots, tel que &#171; cause your outer work to be more &#187; ou &#171; stop at the side of the road &#187;,
qui seront de toute fa&#231;on moins fr&#233;quents que des mots plus courts. Nous avons ensuite calcul&#233;
des fr&#233;quences de n-grammes depuis ce corpus gr&#226;ce au module Perl Text-NSP 4 et le script
associ&#233; count.pl qui produit la liste des n-grammes d&#8217;un document avec leurs fr&#233;quences. Nous
renseignons dans le tableau 3 du nombre de n-grammes produits en fonction de la taille des
n-grammes.
</p>
<p>taille des n-grammes 1 2 3 1 &#224; 3
nombre de n-grammes 301 718 2 517394 6 680906 9 500018
</p>
<p>TABLE 3 &#8211; Nombre de n-grammes distincts extraits de Wikipedia, version anglais simplifi&#233;
</p>
<p>Certains des n-grammes ne sont pas valides et r&#233;sultent d&#8217;erreurs lors de l&#8217;extraction du texte des
pages Wikipedia : &#171; 27|ufc 1 &#187; correspond ainsi &#224; une syntaxe du wiki. Puisqu&#8217;il est impossible de
trouver ce type de n-gramme en corpus, nous n&#8217;avons pas cherch&#233; &#224; nettoyer nos listes.
</p>
<p>Sur les corpus de la t&#226;che SemEval et pour une instance donn&#233;e, nous avons ordonn&#233; les substituts
propos&#233;s par fr&#233;quence d&#8217;apparition d&#233;croissante dans la SEW. Ainsi, sur l&#8217;ensemble de substituts
{intelligent, bright, clever, smart}, les fr&#233;quences calcul&#233;es sur la SEW sont respectivement de
</p>
<p>3. Voir http://www.polishmywriting.com/download/wikipedia2text_rsm_mods.tgz et
http://blog.afterthedeadline.com/2009/12/04/generating-a-plain-text-corpus
-from-wikipedia
</p>
<p>4. http://search.cpan.org/~tpederse/Text-NSP-1.25/lib/Text/NSP.pm
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>499 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>(206, 475, 141, 201) ; notre classement final sera donc {bright, intelligent, smart, clever}.
</p>
<p>Sur cette base de travail, nous avons r&#233;alis&#233; plusieurs exp&#233;riences. Nous avons utilis&#233; la version
texte brut de la SEW, ainsi que la version lemmatis&#233;e, puisque les substituts propos&#233;s sont des
lemmes. Nous avons r&#233;alis&#233; cette &#233;tape de lemmatisation gr&#226;ce au TreeTagger 5 (Schmid, 1994)
que nous avons appliqu&#233; sur l&#8217;ensemble du corpus, avant d&#8217;effectuer les d&#233;comptes de n-grammes.
</p>
<p>D&#8217;autre part, puisque les bigrammes et trigrammes augmentent le volume des donn&#233;es, nous
avons cherch&#233; &#224; mesurer leur influence sur les r&#233;sultats produits. En se fondant sur les uni-
grammes uniquement, 158 substituts du corpus d&#8217;apprentissage sont absents des annotations de
r&#233;f&#233;rence ; ce nombre se r&#233;duit &#224; 105 en ajoutant les bigrammes et &#224; 91 lorsque l&#8217;on ajoute les
trigrammes. Deux substituts se composent donc de quatre mots et 89 substituts sont absents de
notre corpus SEW. Les n-grammes manquants (en utilisant des uni-, bi- et tri-grammes) semblent
cependant tr&#232;s peu fr&#233;quents, tels que &#171; undomesticated &#187; ou &#171; telling untruths &#187;.
</p>
<p>5.2 Probabilit&#233;s des termes en contexte
</p>
<p>Notre deuxi&#232;me mod&#232;le repose sur les mod&#232;les de langue, m&#233;thode utilis&#233;e par les organisateurs
dans leur exp&#233;rience de base sur les fr&#233;quences simples. Alors que les organisateurs ont utilis&#233;
les n-grammes de Google 6 pour ordonner les substituts par fr&#233;quence d&#8217;utilisation d&#233;croissante,
nous avons utilis&#233; les n-grammes du service Microsoft Web en retenant le m&#234;me principe de
tri par fr&#233;quence d&#233;croissante. Nous avons &#233;galement ajout&#233; les contextes &#224; chaque substitut.
Notre approche repose sur les n-grammes propos&#233;s par le service Microsoft Web 7, via la librairie
Python 8, pour obtenir la probabilit&#233; de regroupement d&#8217;unit&#233;s textuelles. Parmi les diff&#233;rents
mod&#232;les de n-grammes disponibles, nous avons utilis&#233; le mod&#232;le bing-body/apr10/.
</p>
<p>Nous avons ainsi &#233;tudi&#233; une unit&#233; textuelle compos&#233;e de l&#8217;&#233;l&#233;ment lexical et d&#8217;une fen&#234;tre
contextuelle reposant sur les quatre tokens encadrant l&#8217;&#233;l&#233;ment lexical de part et d&#8217;autre. Ainsi,
sur l&#8217;exemple ci-dessous, nous avons test&#233; la portion d&#8217;origine &#171; He brings an incredibly rich and
diverse background that &#187; et les versions dans lesquelles le mot cible est remplac&#233; par un substitut,
telles que &#171; He brings an incredibly lush and diverse background that &#187;.
</p>
<p>&lt;instance id=&quot;118&quot;&gt;
&lt;context&gt;He brings an incredibly &lt;head&gt;rich&lt;/head&gt; and diverse background
that includes everything from executive coaching , learning &amp;amp ; development
and management consulting , to senior operations roles , mixed with a masters in
organizational development.&lt;/context&gt;
&lt;/instance&gt;
</p>
<p>L&#8217;une des faiblesses de ce mod&#232;le est qu&#8217;il ne prend en compte qu&#8217;un contexte local, alors que
des mots plus &#233;loign&#233;s du contexte pourraient &#233;galement &#234;tre utiles au choix. Pour tester cette
hypoth&#232;se, nous avons mis en &#339;uvre un troisi&#232;me mod&#232;le, qui utilise le texte entier comme
contexte.
</p>
<p>5. http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
6. Le corpus Google Web 1T utilis&#233; dans l&#8217;exp&#233;rience de base des organisateurs n&#8217;est pas disponible gratuitement.
7. http://research.microsoft.com/en-us/collaboration/focus/cs/web-ngram.
</p>
<p>aspx
8. http://web-ngram.research.microsoft.com/info/MicrosoftNgram-1.02.zip
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>500 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>5.3 Comparaison des contextes et co-occurrents
</p>
<p>Afin de tester la phrase enti&#232;re comme contexte, nous avons utilis&#233; deux ressources de co-
occurrences : Wortschatz (Quasthoff et al., 2006) d&#8217;une part, et une liste de co-occurrents que
nous avons construite depuis la SEW d&#8217;autre part.
</p>
<p>Wortschatz se compose de listes de co-occurrents provenant de plusieurs corpus tels que des
corpus d&#8217;informations ou Wikipedia 9. Dans un premier temps, nous avons utilis&#233; l&#8217;un des corpus
disponible pour l&#8217;anglais, compos&#233; d&#8217;articles Wikipedia potentiellement proches du corpus de
SemEval, de mani&#232;re &#224; produire des listes de co-occurrents avec leur fr&#233;quence en corpus. Ces
co-occurrences ne sont pas dirig&#233;es, c&#8217;est-&#224;-dire que les contextes droit et gauche ne sont pas
distingu&#233;s.
</p>
<p>Nous avons &#233;galement construit une deuxi&#232;me ressource &#224; partir de la Simple English Wikipedia,
en retenant tous les mots qui co-occurrent avec un substitut dans la m&#234;me phrase. Nous avons
n&#233;anmoins limit&#233; les co-occurrences test&#233;es &#224; certaines cat&#233;gories des parties du discours telles
que les noms, les noms propres, les verbes, etc.
</p>
<p>Pour chacune de ces deux ressources, nous avons consid&#233;r&#233; que la fr&#233;quence des co-occurrents
formait un vecteur pour un substitut particulier, et avons calcul&#233; le produit scalaire avec les mots
du contexte. Par exemple, le vocabulaire du contexte suivant est compos&#233; des termes &#171; (and, the,
morans, have, to, ruin, Beethoven&#8217;s, 6th, in, process, too) &#187; qui apparaissent une seule fois dans
la phrase, sauf l&#8217;article &#171; the &#187; qui apparait trois fois. Leur fr&#233;quence de co-occurrence avec le
substitut &#171; audacity &#187; est (0, 102, 0, 29, 0, 0, 0, 0, 3, 0, 0), le produit scalaire final est de 338.
</p>
<p>&lt;instance id=&quot;217&quot;&gt;
&lt;context&gt;And the morans have the &lt;head&gt;gall&lt;/head&gt; to ruin Beethoven&#8217;s 6th in
the process , too .&lt;/context&gt;
&lt;/instance&gt;
</p>
<p>Sur la base de ces listes de co-occurrents, nous avons ordonn&#233; les substituts en nous fondant sur
le poids calcul&#233;, en classant les substituts par ordre d&#233;croissant.
</p>
<p>6 &#201;valuation
</p>
<p>L&#8217;&#233;valuation officielle de la t&#226;che de simplification lexicale repose sur une comparaison par paire
des listes de rangs fournis par le syst&#232;me avec les rangs de r&#233;f&#233;rence (Specia et al., 2012). Pour
chaque paire de substituts, le script d&#8217;&#233;valuation compare la position de chaque terme de la paire
entre l&#8217;hypoth&#232;se et la r&#233;f&#233;rence en termes de position dans la hi&#233;rarchie (position identique, plus
haute, plus basse). Le score final d&#8217;un jeu de substituts correspond &#224; la moyenne des coefficients
&#954; d&#8217;accord inter-annotateur (Formule 1) calcul&#233;s sur chaque paire d&#8217;un contexte.
</p>
<p>&#954;=
Po&#8722; Pe
1&#8722; Pe (1)
</p>
<p>Dans cette formule, pour un jeu de substituts donn&#233;, &#171; Po &#187; renvoie &#224; la probabilit&#233; observ&#233;e
(le nombre d&#8217;accords divis&#233; par le nombre total de paires) tandis que &#171; Pe &#187; correspond &#224; la
</p>
<p>9. http://corpora.informatik.uni-leipzig.de/download.html
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>501 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>probabilit&#233; attendue (calcul&#233;e en faisant la somme des accords de position identique, plus haute,
plus basse, divis&#233;e par le nombre total de paires).
</p>
<p>Consid&#233;rons la liste de substituts {A,C,B} fournie par un syst&#232;me et la liste de r&#233;f&#233;rence {A,B,C}
correspondante. Sur la paire {A,B}, le terme A occupe la m&#234;me position dans les deux listes de
substituts ; le terme B n&#8217;occupe pas la m&#234;me position mais il suit le terme A dans les deux listes.
Sur cette paire, l&#8217;&#233;valuation rapporte deux points d&#8217;accord au syst&#232;me : un point pour la position
identique, et un point pour l&#8217;ordre identique des termes A et B dans la paire (relation &#171; plus
grand que &#187;). Le m&#234;me calcul est poursuivi sur les paires {A,C} et {B,C}.
</p>
<p>6.1 Exp&#233;riences de base
</p>
<p>Nous indiquons dans le tableau 4 les scores calcul&#233;s sur les corpus d&#8217;apprentissage et de test pour
les exp&#233;riences de base fournies par les organisateurs.
</p>
<p>Apprentissage Test
Tri au hasard 0,016 &#8212;
Pas de tri 0,050 &#8212;
Fr&#233;quence simple 0,398 0,471
</p>
<p>TABLE 4 &#8211; R&#233;sultats des exp&#233;riences de base
</p>
<p>6.2 Mod&#232;le fond&#233; sur les fr&#233;quences des termes
</p>
<p>Le tableau 5 r&#233;sume les r&#233;sultats obtenus par notre mod&#232;le fond&#233; sur les fr&#233;quences de la SEW.
</p>
<p>Type de n-grammes Lemmes Apprentissage Test
Unigrammes uniquement non 0,333 &#8212;
Uni- et bigrammes non 0,371 &#8212;
Uni-, bi- et trigrammes non 0,381 0,465
Uni-, bi- et trigrammes oui 0,380 0,462
Uni-, bi- et trigrammes (Wikipedia standard) non 0,343 &#8212;
Exp&#233;rience de base (fr&#233;quence simple) 0,398 0,471
WLV-SHEF-SimpLex (meilleur syst&#232;me &#224; SemEval 2012) &#8212; 0,496
</p>
<p>TABLE 5 &#8211; R&#233;sultats obtenus par notre syst&#232;me fond&#233; sur la Simple English Wikipedia et compa-
raison avec d&#8217;autres exp&#233;riences (Wikipedia standard, exp&#233;rience de base, meilleur syst&#232;me &#224;
SemEval 2012)
</p>
<p>La diff&#233;rence que nous observons dans les r&#233;sultats entre la version lemmatis&#233;e et la version
fl&#233;chie de Wikipedia s&#8217;explique de deux mani&#232;res. En premier lieu, puisque les substituts propos&#233;s
sont pr&#233;sent&#233;s sous forme lemmatis&#233;e, nous en identifions davantage dans la version lemmatis&#233;e
(par exemple, le substitut &#171; abnormal growth &#187; n&#8217;est pr&#233;sent que sous la forme au pluriel &#171; abnormal
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>502 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>growths &#187; dans la version fl&#233;chie de Wikipedia). En second lieu, certains substituts font d&#233;faut
dans la version lemmatis&#233;e, la plupart en raison d&#8217;erreurs du TreeTagger (par exemple, &#171; be scared
of &#187; devient &#171; be scare of &#187;).
</p>
<p>L&#8217;hypoth&#232;se selon laquelle l&#8217;utilisation de Wikipedia en anglais simplifi&#233; est plus adapt&#233;e &#224; cette
t&#226;che que la version standard est valid&#233;e, dans la mesure o&#249; nous obtenons un score plus faible
en utilisant la version standard de la Wikipedia 10.
</p>
<p>Pour l&#8217;&#233;valuation finale, nous avons conserv&#233; le syst&#232;me qui a obtenu le meilleur score (0,381)
sur les donn&#233;es d&#8217;apprentissage, en l&#8217;occurrence le syst&#232;me fond&#233; sur des uni-, bi- et trigrammes
non lemmatis&#233;s. Ce syst&#232;me a obtenu un score de 0,465 sur le corpus de test, nous classant
seconds ex-&#230;quo lors de l&#8217;&#233;valuation SemEval.
</p>
<p>6.3 Probabilit&#233;s des termes en contexte
</p>
<p>Nous avons r&#233;alis&#233; plusieurs exp&#233;riences suppl&#233;mentaires, fond&#233;es sur diff&#233;rents mod&#232;les de
n-grammes et des tailles de contexte distinctes. Les r&#233;sultats les plus significatifs sont pr&#233;sent&#233;s
dans le tableau 6.
</p>
<p>Taille du contexte gauche 0 3 2 3 4
Taille du contexte droit 3 0 2 3 4
Score 0,362 0,358 0,365 0,358 0,370
</p>
<p>TABLE 6 &#8211; R&#233;sultats obtenus avec le service Microsoft Web N-gram, sur le corpus d&#8217;apprentissage
</p>
<p>Nous observons que la fen&#234;tre de contexte compos&#233;e de quatre tokens encadrant le substitut
&#233;tudi&#233; est celle qui nous a permis d&#8217;obtenir les meilleurs r&#233;sultats sur le corpus d&#8217;apprentissage
(0,370). Avec cette configuration, nous avons obtenu un score de 0,396 sur les donn&#233;es de test.
</p>
<p>6.4 Co-occurrents
</p>
<p>Enfin, nous renseignons dans le tableau 7 des scores obtenus par notre mod&#232;le &#224; base de co-
occurrents. Sur le corpus d&#8217;apprentissage, cette m&#233;thode nous permet d&#8217;obtenir un score de 0,373
avec la meilleure configuration, celle reposant sur la ressource constitu&#233;e depuis la SEW. Nous
notons par ailleurs que l&#8217;ajout d&#8217;informations de parties-du-discours am&#233;liore les r&#233;sultats.
</p>
<p>Ressource Wortschatz Wortschatz SEW SEW SEW
Param&#232;tres Corpus 3M Corpus 10M POS : NN, NP, JJ POS + VB Toutes les POS
Score 0,280 0,271 0,255 0,264 0,373
</p>
<p>TABLE 7 &#8211; Scores obtenus avec le mod&#232;le de co-occurrences sur le corpus d&#8217;apprentissage
</p>
<p>10. La Wikipedia standard &#233;tant bien plus volumineuse que la version simplifi&#233;e, nous en avons utilis&#233; un extrait
al&#233;atoire de 375M, du m&#234;me ordre de grandeur que la Wikipedia simplifi&#233;e (156M).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>503 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>6.5 &#201;valuation sur les substituts non compos&#233;s
</p>
<p>Nous avons par ailleurs observ&#233; que nos mod&#232;les ont rencontr&#233; des difficult&#233;s &#224; tenir compte
des substituts compos&#233;s de plusieurs mots. Afin de pallier cette difficult&#233;, nous avons lanc&#233; une
&#233;valuation en ne consid&#233;rant que les substituts compos&#233;s d&#8217;un seul mot (tableau 8). Comme nous
nous y attendions, tous les mod&#232;les voient leurs performances augmenter en ne consid&#233;rant que
les substituts simples (1 mot), en particulier pour le mod&#232;le fond&#233; sur les co-occurrences.
</p>
<p>Mod&#232;le SEW Web N-grams Co-occurrences Fr&#233;quence simple
Tous types de substituts 0,381 0,370 0,373 0,398
Substituts simples (1 mot) 0,390 0,385 0,414 0,408
</p>
<p>TABLE 8 &#8211; Scores obtenus en consid&#233;rant tous les substituts et les substituts simples sur les
donn&#233;es d&#8217;apprentissage
</p>
<p>7 Discussion
</p>
<p>Malgr&#233; des performances relativement bonnes, l&#8217;une des limites du mod&#232;le fond&#233; sur les fr&#233;-
quences calcul&#233;es sur la SEW concerne le fait que ce mod&#232;le s&#8217;appuie uniquement sur les formes
de surface des mots (ou des n-grammes), et que certaines fr&#233;quences se trouvent biais&#233;es. Ainsi,
le mot &#171; light &#187; est aussi bien un nom qu&#8217;un adjectif dans Wikipedia ; lorsque nous traitons
le jeu de substituts {light, bright, luminous, clear, well-lit}, les fr&#233;quences des deux cat&#233;gories
morpho-syntaxiques du terme &#171; light &#187; sont combin&#233;es, accordant plus de poids &#224; ce terme et
permettant &#224; ce substitut de mieux se classer. Une solution consisterait &#224; utiliser des n-grammes
annot&#233;s en parties du discours.
</p>
<p>D&#8217;autre part, ce mod&#232;le ne tient pas compte du contexte du mot, alors que les m&#234;mes substituts
sont parfois ordonn&#233;s diff&#233;remment. Dans l&#8217;exemple suivant, le mot cible &#171; film &#187; a &#233;t&#233; pr&#233;f&#233;r&#233; au
substitut possible &#171;movie &#187; dans les instances 16 et 19 par les annotateurs, et dans l&#8217;ordre inverse
pour les instances 15 et 17.
</p>
<p>&lt;instance id=&quot;15&quot;&gt;
&lt;context&gt;Film Music Literature Cyberplace - Includes &lt;head&gt;film&lt;/head&gt; reviews
, message boards , chat room , and images from various films .&lt;/context&gt;
&lt;/instance&gt;
&lt;instance id=&quot;16&quot;&gt;
&lt;context&gt;His feature &lt;head&gt;film&lt;/head&gt; debut HEROES / DE STARSTE HELTE (
1996 ) won awards at Rouen and Madrid .&lt;/context&gt;
&lt;/instance&gt;
&lt;instance id=&quot;17&quot;&gt;
&lt;context&gt;( Some people keep their TVs on for company. ) In Malta , news is the
main reason we turn to TV , followed by &lt;head&gt;films&lt;/head&gt; , talk shows , docu-
mentaries , serials , and music , in that order .&lt;/context&gt;
&lt;/instance&gt;
&lt;instance id=&quot;19&quot;&gt;
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>504 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>&lt;context&gt;A fine score by George Fenton ( THE CRUCIBLE ) and beautiful photo-
grahy by Roger Pratt add greatly to the effectiveness of the &lt;head&gt;film&lt;/head&gt;
.&lt;/context&gt;
&lt;/instance&gt;
</p>
<p>Cet exemple montre que, selon le contexte du mot dans la phrase, des substituts diff&#233;rents
peuvent &#234;tre choisis.
</p>
<p>Sur le mod&#232;le &#224; base de co-occurrences, l&#8217;un des principaux probl&#232;mes concerne l&#8217;absence de
co-occurrences dans le corpus SEW. Il ne nous a donc pas &#233;t&#233; possible d&#8217;obtenir des informations
de co-occurrences pour 182 substituts du corpus d&#8217;apprentissage (sur un total de 1 452) qui n&#8217;ont
donc pu &#234;tre trait&#233;s. L&#8217;un des moyens de pallier cette difficult&#233; consisterait &#224; &#233;largir la taille de la
fen&#234;tre de recherche des co-occurrents &#224; deux phrases par exemple, ou d&#8217;utiliser un corpus plus
volumineux. Les corpus d&#8217;anglais simplifi&#233; sont cependant rares.
</p>
<p>Enfin, la principale difficult&#233; &#224; laquelle nous avons &#233;t&#233; confront&#233;s sur l&#8217;ensemble des mod&#232;les
concerne les substituts compos&#233;s de plusieurs mots, pour lesquels la comparaison des fr&#233;quences
avec celles des mots simples ne s&#8217;av&#232;re gu&#232;re possible.
</p>
<p>8 Conclusion
</p>
<p>Dans cet article, nous avons pr&#233;sent&#233; trois types de crit&#232;res &#224; prendre en compte pour la t&#226;che de
simplification lexicale et mis en &#339;uvre trois mod&#232;les fond&#233;s sur les fr&#233;quences et sur ces types de
crit&#232;res pour effectuer une simplification lexicale. Le premier mod&#232;le repose sur des fr&#233;quences
d&#8217;utilisation de termes dans la version r&#233;dig&#233;e en anglais simplifi&#233; de la Wikipedia (SEW). Le
second se fonde sur des probabilit&#233;s de n-grammes fournies par le service Microsoft Web N-gram.
Enfin, le dernier mod&#232;le s&#8217;appuie sur des informations de co-occurrences.
</p>
<p>Les meilleurs scores sont obtenus avec les informations de fr&#233;quence dans la Wikipedia en anglais
simplifi&#233; ; cependant, cette information seule ne suffit pas &#224; d&#233;terminer de fa&#231;on satisfaisante le
substitut le plus simple. Puisque les diff&#233;rents mod&#232;les fournissent des caract&#233;ristiques diff&#233;rentes,
nous consid&#233;rons que la combinaison des trois mod&#232;les devrait &#234;tre b&#233;n&#233;fique. Dans cette
optique, nous envisageons de tester un tel type de combinaison au moyen d&#8217;une approche
d&#8217;ordonnancement &#224; base de SVM.
</p>
<p>Il reste bien &#233;videmment des marges de progression, en particulier sur le traitement des substituts
compos&#233;s de plusieurs mots pour lesquels la mobilisation de traitements suppl&#233;mentaires se
r&#233;v&#232;le indispensable pour tenir compte de ces particularit&#233;s.
</p>
<p>En ce qui concerne l&#8217;application de ces m&#233;thodes au fran&#231;ais, nous estimons que cette t&#226;che se
r&#233;v&#232;le d&#8217;autant plus difficile que sur l&#8217;anglais pour deux raisons (en plus de celles identifi&#233;es
sur l&#8217;anglais) : (i) des flexions plus importantes en fran&#231;ais qu&#8217;en anglais et (ii) de l&#8217;absence de
corpus du fran&#231;ais simplifi&#233;. Nous relevons toutefois que des travaux r&#233;cents tendent &#224; produire
ce type de corpus (Brouwers et al., 2012).
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>505 c&#65535; ATALA</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>R&#233;f&#233;rences
</p>
<p>BIRAN, O., BRODY, S. et ELHADAD, N. (2011). Putting it simply : a context-aware approach to
lexical simplification. In Proc of ACL, pages 496&#8211;501, Portland, OR.
</p>
<p>BROUWERS, L., BERNHARD, D., LIGOZAT, A.-L. et FRAN&#199;OIS, T. (2012). Simplification syntaxique de
phrases pour le fran&#231;ais. In Actes de JEP-TALN-RECITAL, pages 211&#8211;224, Grenoble, France.
</p>
<p>CARROLL, J., MINNEN, G., PEARCE, D., CANNING, Y., DEVLIN, S. et TAIT, J. (1999). Simplifying Text
for Language-Impaired Readers. In Proc of EACL, pages 269&#8211;270.
</p>
<p>DEVLIN, S. (1999). Simplifying natural language text for aphasic readers. Th&#232;se de doctorat,
University of Sunderland, UK.
</p>
<p>DRNDAREVIC&#769;, B. et SAGGION, H. (2012). Towards automatic lexical simplification in spanish: An
empirical study. In Proc of Predicting and Improving Text Readability for target reader populations
(PITR) Workshop, pages 8&#8211;16, Montr&#233;al, Canada. NAACL-HLT.
</p>
<p>FRAN&#199;OIS, T. et FAIRON, C. (2012). An &quot;AI readability&quot; formula for french as a foreign lan-
guage. In Proc of the Joint Conference on Empirical Methods in Natural Language Processing and
Computational Natural Language Learning, Jeju-do, South Korea.
</p>
<p>JAUHAR, S. K. et SPECIA, L. (2012). UOW-SHEF: SimpLex &#8211; Lexical Simplicity Ranking based on
Contextual and Psycholinguistic Features. In *SEM.
</p>
<p>LAL, P. et R&#220;GER, S. (2002). Extract-based Summarization with Simplification. In Proc of the
Workshop on Text Summarization at DUC 2002.
</p>
<p>LIGOZAT, A.-L., GROUIN, C., GARCIA-FERNANDEZ, A. et BERNHARD, D. (2012). ANNLOR: A Na&#239;ve
Notation-system for Lexical Outputs Ranking. In Proc of the 6th International Workshop on
Semantic Evaluation (SemEval 2012).
</p>
<p>QUASTHOFF, U., RICHTER, M. et BIEMANN, C. (2006). Corpus Portal for Search in Monolingual
Corpora. In Proc of LREC, Genoa, Italy.
</p>
<p>SCHMID, H. (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. In Proc of the
International Conference on New Methods in Language Processing, Manchester, UK.
</p>
<p>SIDDHARTHAN, A. (2006). Syntactic simplification and text cohesion. Research on Language &amp;
Computation, 4(1):77&#8211;109.
</p>
<p>SPECIA, L., JAUHAR, S. K. et MIHALCEA, R. (2012). SemEval-2012 Task 1 : English Lexical
Simplification. In Proc of Joint Conference on Lexical and Computational Semantics (*SEM), pages
347&#8211;355.
</p>
<p>WATANABE, W., JUNIOR, A., UZ&#202;DA, V., FORTES, R., PARDO, T. et ALU&#205;SIO, S. (2009). Facilita :
reading assistance for low-literacy readers. In Proc of ACM international conference on Design of
communication, pages 29&#8211;36. ACM.
</p>
<p>WOODSEND, K. et LAPATA, M. (2011). Learning to simplify sentences with quasi-synchronous
grammar and integer programming. In Proc of EMNLP.
</p>
<p>YATSKAR, M., PANG, B., DANESCU-NICULESCU-MIZIL, C. et LEE, L. (2010). For the sake of simplicity :
unsupervised extraction of lexical simplifications from Wikipedia. In HLT&#8217;10 Human Language
Technologies, pages 365&#8211;368. ACL.
</p>
<p>TALN-R&#201;CITAL 2013, 17-21 Juin, Les Sables d&#8217;Olonne
</p>
<p>506 c&#65535; ATALA</p>

</div></div>
</body></html>