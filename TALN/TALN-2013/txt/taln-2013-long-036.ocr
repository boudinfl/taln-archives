TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Approches a base de fréquences pour la simpliﬁcation lexicale

Anne-Laure Ligozat1:2 Cyril Grouin1’3
Anne Garcia-Fernandez4 Delphine Bemhard5

(1) LIMSI—CNRS, Orsay (2) ENSIIE, Evry (3) INSERM U872 Eq 20 & UPMC, Paris
(4) LAS, CNRS/EHESS/College de France, Paris (5) LiLPa, Université de Strasbourg, Strasbourg

RESUME
La simpliﬁcation lexicale consiste a remplacer des mots ou des phrases par leur équivalent plus
simple. Dans cet article, nous présentons trois modéles de simpliﬁcation lexicale, fondés sur
différents criteres qui font qu’un mot est plus simple a lire et a comprendre qu’un autre. Nous
avons testé différentes tailles de contextes autour du mot étudié : absence de contexte avec un
modele fondé sur des fréquences de termes dans un corpus d’anglais simpliﬁé; quelques mots de
contexte au moyen de probabilités a base de n-grammes issus de données du web; et le contexte
étendu avec un modele fondé sur les fréquences de cooccurrences.

ABSTRACT
Studying frequency-based approaches to process lexical simplification

Lexical simpliﬁcation aims at replacing words or phrases by simpler equivalents. In this paper,
we present three models for lexical simpliﬁcation, focusing on the criteria that make one word
simpler to read and understand than another. We tested different contexts of the considered
word : no context, with a model based on word frequencies in a simpliﬁed English corpus; a few
words context, with n-grams probabilites on Web data, and an extended context, with a model
based on co—occurrence frequencies.

MOTS-CLES : simpliﬁcation lexicale, fréquence lexicale, modele de langue.

KEYWORDS: lexical simpliﬁcation, lexical frequency, language model.

1 Introduction

La simpliﬁcation textuelle consiste a rendre les textes plus faciles a lire, par exemple pour des
enfants ou des locuteurs non natifs. Des documents de tout type peuvent ainsi étre rendus
accessibles a différents publics; dans notre travail, nous considérerons un public de locuteurs
non natifs de l’anglais et des documents de domaine général.

Deux sous-téiches sont généralement distinguées dans la simpliﬁcation textuelle automatique,
bien qu’elles ne soient pas totalement déconnectées : la simpliﬁcation syntaxique et la simpliﬁca-
tion lexicale. Nous nous intéressons plus particulierement a la problématique de la simpliﬁcation
lexicale. Ce type de simpliﬁcation consiste a remplacer des mots ou des phrases par des équiva-
lents plus simples. Aﬁn de procéder a de telles substitutions, il importe d’abord d’identiﬁer des
mots équivalents qui correspondent au contexte, puis de choisir le mot le plus simple. Dans le
cadre de nos travaux sur la simpliﬁcation, nous nous sommes intéressés a la problématique de la
simpliﬁcation lexicale, et plus particuliérement a l’évaluation de mots équivalents en contexte,

493 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

en fonction de leur degré de simplicité. Dans cet article, nous présentons les expériences sup-
plémentaires que nous avons menées a partir des systemes que nous avons créés lors de notre
participation a cette campagne (Ligozat et al., 2012). Nous avons déﬁni trois types de criteres
fondés sur les fréquences des mots a simpliﬁer et de leurs substituts : les critéres sur le mot lui—
méme, des critéres reposant sur les contextes locaux, et des critéres sur les contextes thématiques.
Ce dernier type de critere constitue une expérience nouvelle par rapport a notre participation
d’origine a SemEval 2012.

La simpliﬁcation lexicale est proche de plusieurs taches. Sa premiere étape consiste a choisir
les substituts possibles d’un mot donné et requiert une désambiguisation sémantique au niveau
du mot et une recherche de paraphrases. La seconde étape considere tous les substituts ou
paraphrases possibles, et Vise a ordonner ces éléments en fonction de leur niveau de simplicité.
La simpliﬁcation peut également étre considérée comme une tache de traduction entre une
langue standard et une version simpliﬁée de cette langue; nous notons que dans les traductions
habituelles, il est difﬁcile de produire des corpus totalement paralléles.

2 Etat de 1’art

Alors que la simpliﬁcation syntaxique a fait l’objet d’un grand nombre de travaux (Siddhar-
than, 2006; Woodsend et Lapata, 2011; Watanabe et al., 2009), la simpliﬁcation lexicale a
comparativement été moins traitée.

Les premiers travaux sur la simpliﬁcation lexicale ont consisté a remplacer des mots par des
synonymes plus communs issus de WordNet ou d’autres dictionnaires (Devlin, 1999; Carroll
et al., 1999; Lal et Riiger, 2002). La complexité lexicale est généralement estimée en termes
de (i) longueur du mot (nombre de caractéres) ou nombre de syllabes, ou (ii) de fréquence du
mot, fondée sur une analyse en corpus ou une base de données, telle que la base de données
psycholinguistique MRC (Lal et Riiger, 2002). Drndarevié et Saggion (2012) ont montré que
la fréquence des mots et leur longueur en nombre de caracteres ou de syllabes étaient des
indicateurs utiles de complexité lexicale a partir d’un corpus paralléle espagnol.

Des approches plus récentes se sont intéressées a l’acquisition de simpliﬁcations lexicales. Les
travaux de Yatskar et al. (2010) ont porté sur l’obtenu'on de simpliﬁcations lexicales (<< collaborate >>
—> « work together >>) a partir des révisions des pages Wikipedia rédigées en anglais simpliﬁé 1.
Les auteurs dérivent ainsi des probabilités de simpliﬁcation au moyen d’un modele fondé sur
les méta-données d’édition de chaque page. Les 100 plus importantes paires extraites par ces
modéles constituent des simpliﬁcations avec une précision élevée (86 % sur le meilleur modéle),
ce qui représente un point de départ intéressant pour l’acquisition de simpliﬁcation lexicale.
Précisons que ce modéle ne tient cependant pas compte du contexte.

Biran et al. (2011) s’appuient sur des paires de substitution apprises a partir du corpus de la
Wikipedia en anglais et en anglais simpliﬁé, en fonction de la similarité des contextes des mots,
de leur fréquence et de leur longueur. Ces paires sont ensuite utilisées pour simpliﬁer certains
mots d’une phrase, en tenant compte de la similarité entre la phrase et les contextes des mots
considérés.

1. L’encyclopédie collaborative en ligne Wikipedia propose, pour certains articles, une version en anglais simpliﬁé
appelé << Simple English >> a destination des locuteurs non natifs de l’anglais.

494 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Woodsend et Lapata (2011) ont implémenté une approche de simpliﬁcation fondée sur une
grammaire quasi synchrone, qui apprend des réécritures de simpliﬁcation a partir de phrases
source/cible extraites des pages Wikipedia rédigées en anglais et en anglais simpliﬁé. Ce modéle
integre également des substitutions lexicales, avec pour objectif le remplacement d’un mot
en fonction de son contexte syntaxique. L’acquisition de substituts lexicaux reste cependant
limitée aux terrnes présents en corpus, ce qui réduit l’intérét d’un tel modele pour une tache de
simpliﬁcation lexicale.

Dans ce travail, nous envisageons d’étudier la simpliﬁcation lexicale en e1le—méme, en nous
attachant 2 identiﬁer les critéres qui font qu’un mot est plus simple a lire et a comprendre qu’un
autre mot. Notre approche repose principalement sur les modeles a base de n—grammes, tels
que les modéles décrits par Jauhar et Specia (2012). Nous avons cependant essayé d’afﬁner ces
modeles en tenant compte des différents contextes d’apparition du mot étudié. Notre travail
repose sur le cadre expérimental fourni par la tache de simpliﬁcation lexicale proposée par la
campagne d’évaluau'on SemEval 2012 (Specia et al., 2012).

3 Critéres de simpliﬁcation d’un élément lexical

Nous nous proposons donc d’étudier la simpliﬁcation lexicale sous l’angle de la caractérisation

du caractére simple d’éléments lexicaux en contexte. L’étude de la littérature et du corpus de la

campagne SemEVal 2012 nous a permis de dégager plusieurs criteres pour choisir un élément
lexical dans un contexte donné (voir par exemple Francois et Fairon (2012); Jauhar et Specia

(2012)) :

— des criteres concernantl’é1ément 1ui—méme, principalement issus des mesures de lisibilité de
textes : taille de l’élément en nombre de caracteres ou de syllabes, fréquence de l’élément en
corpus, présence de cet élément dans des listes de mots simples, caractéristiques psycholin—
guistiques de l’élément (comme par exemple caractere concret, age d’acquisition ou autres
provenant de la MRC Psycholinguistic Database)...

— le contexte local de l’élément, et notamment dans le cas de l’appartenance a une collocation.
Dans la phrase « Put granola bars in bowl . », le contexte local « granola >> nous permet d’identiﬁer
le substitut « bar >> comme meilleur choix possible;

— le contexte plus général de l’élément, notamment son contexte thématique. Ainsi, dans la
phrase << The ﬁlm shows Afghan mercenaries to be involved with the separatists , suggesting that
the present struggle in Kashmir has been hijacked by foreign extremists , who are shown discussing
the loss of Bangladesh in the 1971 war, providing it as a justification for their present acts of
revenge . >>, il est nécessaire de prendre en compte tout le contexte du mot cible «film » pour
identiﬁer le substitut « documentary >> comme meilleur choix par rapport aux autres substituts
possibles «ﬁlm, movie, picture ».

Nous émettons l’hypothése que l’utilisau'on d’un contexte plus important permet de mieux tenir

compte des spéciﬁcités sémanﬁques des substituts et de l’environnement linguistique dans lequel

ces substituts évoluent.

495 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
4 Corpus

Dans le cadre de ce travail, nous avons poursuivi les expériences que nous avions menées lors de
notre participation a la tache de simpliﬁcation lexicale de l’anglais proposée par la campagne
SemEval 2012 2. A ce titre, nous avons appliqué nos méthodes et effectué de nouvelles expériences
en nous appuyant sur les corpus de la campagne.

4. 1 Présentation

Dans le cadre de cette tache, deux corpus ont été fournis. Le corpus d’apprentissage contient
300 instances tandis que le corpus de test, utilisé pour l’évaluation, se compose de 1 710
instances. Le corpus d’apprentissage s’accompagne des annotations de référence pour permettre
le développement des systémes.

Le corpus se compose de textes courts issus de documents récupérés sur internet, dans lesquels
un mot cible a été choisi, et pour lequel plusieurs substituts possibles doivent étre ordonnés.
Dans l’exemple suivant, le mot « outdoor >> est la cible a traiter et tous les autres mots du texte
constituent le contexte de ce mot cible.

<instance id="270">

<context>With the growing demand for these ﬁne garden furnishings , they found it
necessary to dedicate a portion of their business to <head>outdoor</head> living
and patio furnishings .< /context>

</instance>

Pour cette cible, les substituts proposés sont les suivants : falfresco, outside, open—air, outdoor}.
Les informations disponibles sur la constitution de la référence nous permettent de savoir que
ces substituts ont été ordonnés par des locuteurs non natifs de l’anglais (respectivement 4 et 5
annotateurs pour les corpus d’apprentissage et de test) selon leur degré de simplicité décroissant.
Nous n’avons cependant pas connaissance d’un guide d’annotation auquel se référer. L’objectif de
la tache consiste donc a ordonner ces différents substituts en fonction de leur degré de simplicité.

La séquence de référence associée a ces substituts est la suivante : (outdoor, open—air, {outside,
alfresco }), o1‘1 << outdoor >> est considéré comme le substitut le plus simple, tandis que << outside >> et
« alfresco >> sont considérés comme les substituts les plus complexes 2‘: égalité.

4.2 Statistiques

Nous donnons ci-aprés quelques éléments statistiques calculés sur les corpus d’apprentissage et
de test, aﬁn de représenter la difficulté de la tache.

Nombre de tokens dans chaque contexte. Dans un premier temps, nous avons étudié le
nombre de tokens dans chaque contexte, un token étant considéré comme une chaine de
caracteres entre deux espaces. Alors que les contextes les plus longs se retrouvent dans le corpus
de test, nous avons relevé que les contextes sont, en moyenne, plus courts dans le corpus de test

2.http://www.cs.york.ac.uk/semeval—2012/task1/
496 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

que dans le corpus d’apprentissage, avec un nombre moyen de 27,6 tokens dans le test contre
28,9 dans l’apprentissage (tableau 1, gauche). Les contextes les plus courts se composent de 5
tokens dans les deux corpus. Ainsi, le contexte << Well, perhaps not . >> se rapporte au mot cible
« well >> dans le corpus d’apprentissage alors que le contexte « The spin’s are ﬂat . » se rapporte au
mot cible «ﬂat >> dans le corpus de test. Cela signiﬁe qu’il existe des informations contextuelles
pour pratiquement tous les mots cibles, et que ce contexte peut étre utilisé pour choisir les
substituts qui conviennent le mieux a ce contexte.

Corpus Nombre de tokens Nombre de substituts
Min Max Moy Min Max Moy

Apprentissage 5 76 28,9 2 9 4,8

Test 5 92 27,6 1 10 5,0

TABLE 1 — Nombre minimum, maximum et moyen de tokens par contexte (gauche) et nombre
minimum, maximum et moyen de substituts par instance (droite)

Nombre de substituts par contexte. Nous avons également calculé le nombre de substituts
proposés pour chaque cible dans chaque instance a traiter. 11 y a, en moyenne, cinq substituts
proposés par instance dans les deux corpus (tableau 1, droite). Chaque instance se compose ainsi
de plusieurs substituts a ordonner.

Fréquence d’utilisation des substituts en corpus. Un point intéressant concerne le nombre
de fois que chaque substitut est proposé dans chacun des corpus. La majorité des ensembles
proposés de substituts se composent de substituts proposés une seule fois. Nous remarquons
cependant qu’il y a davantage de substituts proposés une seule fois dans le corpus d’apprentissage
que dans le corpus de test. Nous reportons sur le graphique 1 le pourcentage d’utilisation des
substituts, classés par nombre d’occurrences décroissant, proposés respectivement dans les corpus
d’apprentissage (en rouge) et de test (en bleu).

60

50
%’o
g 40
5
E 30
33
33 20

2 3

1 4 5 6 7 8 9 10 11 12 13 14

Nombre d’occurrences

FIGURE 1 — Pourcentage d’utilisation de chaque substitut sur le corpus d’apprentissage (rouge) et
de test (bleu), classé par nombre d’occurrences décroissant

497 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

Si la majorité des substituts est proposée une seule fois (62,6 % des substituts du corpus d’appren-
tissage et 51,8 % dans le corpus de test ne sont présentés qu’une seule fois), certains apparaissent
néanmoins un nombre élevé de fois (les substituts présentés deux fois constituent 16,0% et
17,5 % du nombre total de substituts). En matiere de présentation maximum, le substitut « unplea-
sant >> est proposé jusqu’a 14 fois dans le corpus d’apprentissage (sur un total de 633 substituts)
alors que « consequently >> est proposé 26 fois dans le corpus de test (sur un total de 2774
substituts).

Catégories morpho-syntaxiques des substituts. Chaque mot cible releve d’une catégorie
morpho—syntaxique parmi quatre catégories possibles. Nous avons étudié la répartition des mots
cibles en fonction de leur catégorie d’appartenance (tableau 2).

Catégorie Apprentissage Test
Adjectif 26,5 % 27,5 %
Adverbe 14,7 % 17,5 %
Nom 23,5 % 29,2 %
Verbe 23,5 % 25,7 %
Adjectif ou Nom 5,9 % —
Nom ou Verbe 5,9 % —

TABLE 2 — Pourcentage de mots cibles appartenant a chaque catégorie morpho—syntaxique

Nous remarquons que la répartition des mots cibles dans chacune des catégories morpho-
syntaxique est similaire entre les deux corpus. Cependant, le corpus d’apprentissage se compose
de mots cibles ambigus dans la mesure o1‘1 certains de ces mots peuvent relever de deux catégories
potentielles (adjectif ou nom, nom ou Verbe). Cette ambiguité disparait dans le corpus de test.

4.3 Expériences de base

Trois expériences de base (baselines) ont été fournies par les organisateurs en accompagnement

du corpus d’apprentissage :

— La premiere reléve d’un simple ordonnancement au hasard des substituts de chaque ensemble
proposé;

— La seconde conserve la liste de substituts proposés dans l’ordre dans lequel elle est fournie;

— La troisieme (appelée << fréquence simple >>) repose sur l’utilisation des fréquences des termes
présents dans le corpus Google Web 1T.

Ces expériences de base perrnettent, d’une part de ﬁxer le seuil minimum 2 atteindre, et d’autre

part de présenter de premieres approches simples pour résoudre la problématique soulevée.

5 Méthodes

Nous avons im lémenté trois modeles distincts ui corres ondent a différentes tailles de contextes
P ‘l P
que nous avons envisages autour des mots cibles : (1) pas de contexte, (11) quelques mots, et
498 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

(iii) le contexte entier. L’idée sous—jacente de ces expériences concerne le fait qu’un substitut peut
étre préféré a un autre parce qu’il est plus fréquent (le con texte n’est donc pas nécessaire), parce
qu’il appartient a une expression (auquel cas, le contexte composé de quelques mots se révéle
utile), ou bien, parce qu’il est le plus adapté sur le plan sémantique (l’ensemble du contexte est
alors utilise’).

5.1 Modéle fondé sur les fréquences des termes

Notre premier modele ne prend pas en compte le contexte d’utilisation des mots et repose sur
les fréquences des substituts trouvées dans un corpus rédigé en anglais simpliﬁé, la Simple
English W1'k1'pedia (SEW). Notre hypothése de travail repose sur le fait que les mots les plus
fréquemment employés dans ce corpus seront préférés par les locuteurs non natifs de l’anglais.
Ce public correspond au proﬁl des annotateurs utilisés pour la tache de simpliﬁcation lexicale.
La SEW a déja été utilisée dans des travaux portant sur la simpliﬁcation automatique de textes
(Yatskar et al., 2010). D’autre part, puisque les corpus SemEval sont constitués de données issues
d’internet, nous estimons qu’ils sont proches des textes de Wikipedia du point de vue linguistique.

Dans un premier temps, nous avons converu’ la SEW au format texte a partir de l’archive du 27
février 2012 dont nous avons extrait le contenu textuel grace a l’outil wikipedia2text 3. Le ﬁchier
texte ﬁnal contient approximativement 10 millions de mots.

Nous avons ensuite extrait des n-grammes de mots, en variant la taille des n-grammes de 1 a
3 mots, ce qui est sufﬁsant pour la plupart des substituts. Le corpus d’apprentissage contient
seulement deux substituts composés de quatre mots, ce qui constitue la taille la plus importante.
Nous avons néanmoins constaté que le corpus de test comprend des substituts pouvant aller
jusqu’a sept mots, tel que << cause your outer work to be more » ou << stop at the side of the road »,
qui seront de toute facon moins fréquents que des mots plus courts. Nous avons ensuite calculé
des fréquences de n-grammes depuis ce corpus grace au module Perl Text-NSP4 et le script
associé count.p| qui produit la liste des n-grammes d’un document avec leurs fréquences. Nous
renseignons dans le tableau 3 du nombre de n-grammes produits en fonction de la taille des
n—grammes.

taille des n-grammes 1 2 3 1 a 3
nombre de n-grammes 301 718 2 517394 6 680 906 9 500 018

TABLE 3 — Nombre de n-grammes distincts extraits de Wikipedia, version anglais simpliﬁé

Certains des n-grammes ne sont pas valides et résultent d’erreurs lors de l’extracu'on du texte des
pages Wikipedia : « 27 I ufc 1 >> correspond ainsi a une syntaxe du wiki. Puisqu’il est impossible de
trouver ce type de n—gramme en corpus, nous n’avons pas cherché a nettoyer nos listes.

Sur les corpus de la tache SemEval et pour une instance donnée, nous avons ordonné les substituts
proposés par fréquence d’apparition décroissante dans la SEW. Ainsi, sur l’ensemble de substituts
fintelligent, bright, clever, smart}, les fréquences calculées sur la SEW sont respectivement de

3. Voir http : / /www . polishmywriting . com/download/wikipedia2text_rsm_mods . tgz et
http : / /blog . afterthedeadline . com/2 0 0 9/12 / 04 /generating—a—plain—text—corpus
—from—wikipedia

4. http : / /search . cpan . org/~tpederse/Text—NSP— 1 . 25/lib/Text/NSP .pm

499 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
(206, 475, 141, 201) ; notre classement ﬁnal sera donc {bright, intelligent, smart, clever}.

Sur cette base de travail, nous avons réalisé plusieurs expériences. Nous avons utilisé la version
texte brut de la SEW, ainsi que la version lemmatisée, puisque les substituts proposés sont des
lemmes. Nous avons réalisé cette étape de lemmatisation grace au TreeTagger5 (Schmid, 1994)
que nous avons appliqué sur l’ensemble du corpus, avant d’effectuer les décomptes de n-grammes.

D’autre part, puisque les bigrammes et trigrammes augmentent le volume des données, nous
avons cherché a mesurer leur inﬂuence sur les résultats produits. En se fondant sur les uni-
grammes uniquement, 158 substituts du corpus d’apprentissage sont absents des annotations de
référence; ce nombre se réduit a 105 en ajoutant les bigrammes et a 91 lorsque l’on ajoute les
trigrammes. Deux substituts se composent donc de quatre mots et 89 substituts sont absents de
notre corpus SEW. Les n—grammes manquants (en utilisant des uni—, bi— et tri—grammes) semblent
cependant tres peu fréquents, tels que « undomesticated » ou « telling untruths ».

5.2 Probabilités des termes en contexte

Notre deuxieme modele repose sur les modeles de langue, méthode utilisée par les organisateurs
dans leur expérience de base sur les fréquences simples. Alors que les organisateurs ont utilisé
les n—grammes de Google 6 pour ordonner les substituts par fréquence d’utilisation décroissante,
nous avons utilisé les n—grammes du service Microsoft Web en retenant le meme principe de
tri par fréquence décroissante. Nous avons également ajouté les contextes a chaque substitut.
Notre approche repose sur les n—grammes proposés par le service Microsoft Web 7, via la librairie
Python 8, pour obtenir la probabilité de regroupement d’unités textuelles. Parmi les différents
modeles de n—grammes disponibles, nous avons utilisé le modele bing—bod_y/apr10/.

Nous avons ainsi étudié une unité textuelle composée de l’élément lexical et d’une fenétre
contextuelle reposant sur les quatre tokens encadrant l’élément lexical de part et d’autre. Ainsi,
sur l’exemple ci—dessous, nous avons testé la portion d’origine << He brings an incredibly rich and
diverse background that >> et les versions dans lesquelles le mot cible est remplacé par un substitut,
telles que << He brings an incredibly lush and diverse background that ».

<instance id="118">

<context>He brings an incredibly <head>rich</head> and diverse background
that includes everything from executive coaching , learning &amp; development
and management consulting , to senior operations roles , mixed with a masters in
organizational development. < / context>

</instance>

L’une des faiblesses de ce modele est qu’il ne prend en compte qu’un contexte local, alors que
des mots plus éloignés du contexte pourraient également étre utiles au choix. Pour tester cette
hypothese, nous avons mis en oeuvre un troisieme modele, qui utilise le texte entier comme
contexte.

5.http://www.ims.uni—stuttgart.de/projekte/corplex/TreeTagger/

6. Le corpus Google Web 1T utilisé dans l’expérience de base des organisateurs n’est pas disponible gratuitement.

7.http://research.microsoft.com/en—us/collaboration/focus/cs/web—ngram.
aspx

8.http://web—ngram.research.microsoft.com/info/MicrosoftNgram—1.02.zip

500 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
5.3 Comparaison des contextes et co-occurrents

Aﬁn de tester la phrase entiere comme contexte, nous avons utilisé deux ressources de co-
occurrences : Wortschatz (Quasthoff et al., 2006) d’une part, et une liste de co-occurrents que
nous avons construite depuis la SEW d’autre part.

Wortschatz se compose de listes de co-occurrents provenant de plusieurs corpus tels que des
corpus d’informations ou Wikipedia 9. Dans un premier temps, nous avons utilisé l’un des corpus
disponible pour l’anglais, composé d’articles Wikipedia potentiellement proches du corpus de
SemEval, de maniere a produire des listes de co-occurrents avec leur fréquence en corpus. Ces
co—occurrences ne sont pas dirigées, c’est—a—dire que les contextes droit et gauche ne sont pas
distingués.

Nous avons également construit une deuxiéme ressource a partir de la Simple English Wikipedia,
en retenant tous les mots qui co—occurrent avec un substitut dans la méme phrase. Nous avons
néanmoins limité les co—occurrences testées a certaines catégories des parties du discours telles
que les noms, les noms propres, les verbes, etc.

Pour chacune de ces deux ressources, nous avons considére’ que la fréquence des co-occurrents
formait un vecteur pour un substitut particulier, et avons calculé le produit scalaire avec les mots
du contexte. Par exemple, le vocabulaire du contexte suivant est composé des termes « (and, the,
morans, have, to, ruin, Beethoven’s, 6th, in, process, too) >> qui apparaissent une seule fois dans
la phrase, sauf l’article « the >> qui apparait trois fois. Leur fréquence de co-occurrence avec le
substitut « audacity » est (0, 102, 0, 29, 0, 0, 0, 0, 3, 0, 0), le produit scalaire ﬁnal est de 338.

<instance id="217">

<context>And the morans have the <head>gall</head> to ruin Beethoven’s 6th in
the process , too .</context>

</instance>

Sur la base de ces listes de co-occurrents, nous avons ordonné les substituts en nous fondant sur
le poids calculé, en classant les substituts par ordre décroissant.

6 Evaluation

L’évaluation officielle de la tache de simpliﬁcation lexicale repose sur une comparaison par paire
des listes de rangs fournis par le systeme avec les rangs de référence (Specia et al., 2012). Pour
chaque paire de substituts, le script d’évaluation compare la position de chaque terme de la paire
entre l’hypothése et la référence en termes de position dans la hiérarchie (position identique, plus
haute, plus basse). Le score final d’un jeu de substituts correspond 2 la moyenne des coefficients
K d’accord inter—annotateur (Formule 1) calculés sur chaque paire d’un contexte.
Po — Pe

K‘_

1 — Pe (1)

Dans cette formule, pour un jeu de substituts donné, « Po » renvoie a la probabilité observée
(le nombre d’accords divisé par le nombre total de paires) tandis que « Pe » correspond a la

9. http : //corpora . informatik . uni—leipzig . de/download. html
501 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

probabilité attendue (calculée en faisant la somme des accords de position identique, plus haute,
plus basse, divisée par le nombre total de paires).

Considérons la liste de substituts {A,C,B} fournie par un systéme et la liste de référence {A,B,C}
correspondante. Sur la paire {A,B}, le terme A occupe la méme position dans les deux listes de
substituts; le terme B n’occupe pas la méme position mais il suit le terme A dans les deux listes.
Sur cette paire, l’éValuation rapporte deux points d’accord au systéme : un point pour la position
identique, et un point pour l’ordre identique des termes A et B dans la paire (relation « plus
grand que >>). Le méme calcul est poursuivi sur les paires {A,C} et {B,C}.

6.1 Expériences de base

Nous indiquons dans le tableau 4 les scores calculés sur les corpus d’apprentissage et de test pour
les expériences de base fournies par les organisateurs.

Apprentissage Test
Tri au hasard 0,016 —
Pas de tri 0,050 —
Fréquence simple 0,398 0,471

TABLE 4 — Résultats des expériences de base

6.2 Modéle fondé sur les fréquences des termes

Le tableau 5 résume les résultats obtenus par notre modéle fondé sur les fréquences de la SEW.

Type de n-grammes Lemmes Apprentissage Test
Unigrammes uniquement non 0,333 —
Uni- et bigrammes non 0,371 —
Uni-, bi- et trigrammes non 0,381 0,465
Uni-, bi- et trigrammes oui 0,380 0,462
Uni-, bi- et trigrammes (Wikipedia standard) non 0,343 —
Expérience de base (fréquence simple) 0,398 0,471
WLV—SHEF—SimpLex (meilleur systéme a SemEva1 2012) — 0,496

TABLE 5 — Résultats obtenus par notre systéme fondé sur la Simple English Wikipedia et compa-
raison avec d’autres expériences (Wikipedia standard, expérience de base, meilleur systeme a
SemEva1 2012)

La différence que nous observons dans les résultats entre la version lemmatisée et la version
ﬂéchie de Wikipedia s’explique de deux maniéres. En premier lieu, puisque les substituts proposés
sont présentés sous forme lemmatisée, nous en identiﬁons davantage dans la version lemmatisée
(par exemple, le substitut « abnormal growth >> n’est présent que sous la forme au pluriel «abnormal

502 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

growths >> dans la version ﬂéchie de Wikipedia). En second lieu, certains substituts font défaut
dans la version lemmaﬁsée, la plupart en raison d’erreurs du TreeTagger (par exemple, << be scared
of >> devient << be scare of >>).

L’hypothése selon laquelle l’utilisation de Wikipedia en anglais simpliﬁé est plus adaptée a cette
tache que la version standard est validée, dans la mesure ou nous obtenons un score plus faible
en utilisant la version standard de la Wikipedia 1°.

Pour l’évaluation ﬁnale, nous avons conservé le systeme qui a obtenu le meilleur score (0,381)
sur les données d’apprentissage, en l’occurrence le systéme fondé sur des uni-, bi— et trigrammes
non lemmatisés. Ce systeme a obtenu un score de 0,465 sur le corpus de test, nous classant
seconds ex—aquo lors de l’évaluation SemEval.

6.3 Probabilités des termes en contexte

Nous avons réalisé plusieurs expériences supplémentaires, fondées sur différents modeles de
n-grammes et des tailles de contexte distinctes. Les résultats les plus signiﬁcatifs sont présentés
dans le tableau 6.

Taille du contexte gauche 0 3 2 3 4
Taille du contexte droit 3 0 2 3 4
Score 0,362 0,358 0,365 0,358 0,370

TABLE 6 — Résultats obtenus avec le service Microsoft Web N—gram, sur le corpus d’apprentissage

Nous observons que la fenétre de contexte composée de quatre tokens encadrant le substitut
étudié est celle qui nous a permis d’obtenir les meilleurs résultats sur le corpus d’apprentissage
(0,370). Avec cette conﬁguration, nous avons obtenu un score de 0,396 sur les données de test.

6.4 Co-occurrents

Enﬁn, nous renseignons dans le tableau 7 des scores obtenus par notre modele a base de co-
occurrents. Sur le corpus d’apprentissage, cette méthode nous permet d’obtenir un score de 0,373
avec la meilleure conﬁguration, celle reposant sur la ressource constituée depuis la SEW. Nous
notons par ailleurs que l’ajout d’informau'ons de parties—du—discours améliore les résultats.

Ressource Wortschatz Wortschatz SEW SEW SEW
Paramétres Corpus 3M Corpus 10M POS : NN, NB JJ POS + VB Toutes les POS
Score 0,280 0,271 0,255 0,264 0,373

TABLE 7 — Scores obtenus avec le modéle de co—occurrences sur le corpus d’apprentissage

10. La Wikipedia standard étant bien plus volumineuse que la version simpliﬁée, nous en avons utilisé un extrait
aléatoire de 375M, du méme ordre de grandeur que la Wikipedia simpliﬁée (156M).

503 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

6.5 Evaluation sur les substituts non composés

Nous avons par ailleurs observé que nos modéles ont rencontré des difﬁcultés a tenir compte
des substituts composés de plusieurs mots. Aﬁn de pallier cette difﬁculté, nous avons lancé une
évaluation en ne considérant que les substituts composés d’un seul mot (tableau 8). Comme nous
nous y attendions, tous les modeles voient leurs performances augmenter en ne considérant que
les substituts simples (1 mot), en particulier pour le modele fondé sur les co—occurrences.

Modéle SEW Web N—grams Co—occurrences Fréquence simple
Tous types de substituts 0,381 0,370 0,373 0,398
Substituts simples (1 mot) 0,390 0,385 0,414 0,408

TABLE 8 — Scores obtenus en considérant tous les substituts et les substituts simples sur les
données d’apprentissage

7 Discussion

Malgré des performances relativement bonnes, l’une des limites du modéle fondé sur les fré—
quences calculées sur la SEW concerne le fait que ce modele s’appuie uniquement sur les formes
de surface des mots (ou des n—grammes), et que certaines fréquences se trouvent biaisées. Ainsi,
le mot « light >> est aussi bien un nom qu’un adjectif dans Wikipedia; lorsque nous traitons
le jeu de substituts ﬂight, bright, luminous, clear, well—lit}, les fréquences des deux catégories
morpho-syntaxiques du terme «light >> sont combinées, accordant plus de poids a ce terme et
permettant a ce substitut de mieux se classer. Une solution consisterait a utiliser des n—grammes
annotés en parties du discours.

D’autre part, ce modele ne tient pas compte du contexte du mot, alors que les memes substituts
sont parfois ordonnés différemment. Dans l’exemple suivant, le mot cible «ﬁlm » a été préféré au
substitut possible «movie » dans les instances 16 et 19 par les annotateurs, et dans l’ordre inverse
pour les instances 15 et 17.

<instance id="15">

<context>Film Music Literature Cyberplace — Includes <head>ﬁlm</head> reviews
, message boards , chat room , and images from various ﬁlms .</context>
</instance>

<instance id="16">

<context>His feature <head>film</head> debut HEROES / DE STARSTE HEL'IE (
1996 ) won awards at Rouen and Madrid .</context>

</instance>

<instance id="17">

<context>( Some people keep their TVs on for company. ) In Malta , news is the
main reason we turn to TV , followed by <head>ﬁlms</head> , talk shows , docu-
mentaries , serials , and music , in that order .</context>

</instance>

<instance id="19">

504 © ATALA

TALN-RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne

<context>A ﬁne score by George Fenton ( THE CRUCIBLE ) and beautiful photo-
grahy by Roger Pratt add greatly to the effectiveness of the <head>ﬁlm</head>
.</context>
</instance>

Cet exemple montre que, selon le contexte du mot dans la phrase, des substituts différents
peuvent étre choisis.

Sur le modele a base de co—occurrences, l’un des principaux problemes concerne l’absence de
co—occurrences dans le corpus SEW. I1 ne nous a donc pas été possible d’obtenir des informations
de co—occurrences pour 182 substituts du corpus d’apprenu'ssage (sur un total de 1 452) qui n’ont
donc pu étre traités. L’un des moyens de pallier cette difﬁculté consisterait a élargir la taille de la
fenétre de recherche des co-occurrents a deux phrases par exemple, ou d’uti1iser un corpus plus
volumineux. Les corpus d’anglais simpliﬁé sont cependant rares.

Enﬁn, la principale difﬁculté a laquelle nous avons été confrontés sur l’ensemble des modeles
concerne les substituts composés de plusieurs mots, pour lesquels la comparaison des fréquences
avec celles des mots simples ne s’avére guére possible.

8 Conclusion

Dans cet article, nous avons présenté trois types de critéres a prendre en compte pour la tache de
simpliﬁcation lexicale et mis en oeuvre trois modéles fondés sur les fréquences et sur ces types de
critéres pour effectuer une simpliﬁcation lexicale. Le premier modéle repose sur des fréquences
d’utilisation de termes dans la version rédigée en anglais simpliﬁé de la Wikipedia (SEW). Le
second se fonde sur des probabilités de n—grammes foumies par le service Microsoft Web N-gram.
Enﬁn, le dernier modéle s’appuie sur des informations de co—occurrences.

Les meilleurs scores sont obtenus avec les informations de fréquence dans la Wikipedia en anglais
simpliﬁé; cependant, cette information seule ne sufﬁt pas a déterminer de facon satisfaisante le
substitut le plus simple. Puisque les différents modéles foumissent des caractéristiques différentes,
nous considérons que la combinaison des trois modeles devrait étre bénéﬁque. Dans cette
optique, nous envisageons de tester un tel type de combinaison au moyen d’une approche
d’ordonnancement a base de SVM.

Il reste bien évidemment des marges de progression, en particulier sur le traitement des substituts
composés de plusieurs mots pour lesquels la mobilisation de traitements supplémentaires se
révéle indispensable pour tenir compte de ces particularités.

En ce qui concerne l’application de ces méthodes au francais, nous estimons que cette tache se
révele d’autant plus difﬁcile que sur l’anglais pour deux raisons (en plus de celles identiﬁées
sur l’anglais) : (i) des ﬂexions plus importantes en francais qu’en anglais et (ii) de l’absence de
corpus du francais simpliﬁé. Nous relevons toutefois que des travaux récents tendent a produire
ce type de corpus (Brouwers et al., 2012).

505 © ATALA

TALN—RECITAL 2013, 17-21 Iuin, Les Sables d’Olonne
Références

BIRAN, 0., BRODY, S. et ELHADAD, N. (2011). Putting it simply: a context—aware approach to
lexical simpliﬁcation. In Proc of ACL, pages 496-501, Portland, OR.

BROUwERs, L., BERNHARD, D., LIGOZAT, A.-L. et FRANCOIS, T. (2012). Simpliﬁcation syntaxique de
phrases pour le francais. In Actes de JEP—TALN—RECITAL, pages 211-224, Grenoble, France.

CARROLL, J., MINNEN, G., PEARCE, D., CANNING, Y., DEVLIN, S. et TAIT, J. (1999). Simplifying Text
for Language—Impaired Readers. In Proc of EACL, pages 269-270.

DEVLIN, S. (1999). Simplifying natural language text for aphasic readers. These de doctorat,
University of Sunderland, UK.

DRNDAREvI<':, B. et SAGGION, H. (2012). Towards automatic lexical simpliﬁcation in spanish: An
empirical study. In Proc of Predicting and Improving Text Readability for target reader populations
(PITR) Workshop, pages 8-16, Montréal, Canada. NAACL—HL'I‘.

FRAN(;OIs, T. et FAIRON, C. (2012). An "Al readability" formula for french as a foreign lan-

guage. In Proc of the Joint Conference on Empirical Methods in Natural Language Processing and
Computational Natural Language Learning, Jeju—do, South Korea.

JAUHAR, S. K. et SPECIA, L. (2012). UOW—SHEF: SimpLex - Lexical Simplicity Ranking based on
Contextual and Psycholinguisﬁc Features. In *SEM.

LAL, P. et RI"JGER, S. (2002). Extract-based Summarization with Simpliﬁcation. In Proc of the
Workshop on Text Summarization at DUC 2002.

LIGOZAT, A.-L., GROUIN, C., GARCIA-FERNANDEZ, A. et BERNHARD, D. (2012). ANNLOR: A Na'1've
Notation—system for Lexical Outputs Ranking. In Proc of the 6th International Workshop on
Semantic Evaluation (SemEval 2012).

QUASTHOFF, U., RICHTER, M. et BIEMANN, C. (2006). Corpus Portal for Search in Monolingual
Corpora. In Proc of LREC, Genoa, Italy.

SCHMID, H. (1994). Probabilistic Part—of—Speech Tagging Using Decision Trees. In Proc of the
International Conference on New Methods in Language Processing, Manchester, UK.

SIDDHARTHAN, A. (2006). Syntactic simpliﬁcation and text cohesion. Research on Language &
Computation, 4(1):77-109.

SPECIA, L., JAUHAR, S. K. et MIHALCEA, R. (2012). SemEval—2012 Task 1 : English Lexical
Simpliﬁcation. In Proc of Joint Conference on Lexical and Computational Semantics (*SEM), pages
347-355.

WATANABE, W., JUNIOR, A., UZEDA, V, FORTEs, R., PARDO, T. et ALUis1O, S. (2009). Facilita:
reading assistance for low—literacy readers. In Proc of ACM international conference on Design of
communication, pages 29-36. ACM.

WOODSEND, K. et LAPATA, M. (2011). Learning to simplify sentences with quasi—synchronous
grammar and integer programming. In Proc of EMNLP.

YATSKAR, M., PANG, B., DANESCU-NICULESCU-MIZIL, C. et LEE, L. (2010). For the sake of simplicity:
unsupervised extraction of lexical simpliﬁcations from Wikipedia. In HLT '10 Human Language
Technologies, pages 365-368. ACL.

506 © ATALA

