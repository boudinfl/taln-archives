21ème Traitement Automatique des Langues Naturelles, Marseille, 2014                                               [O-F.1]
Une évaluation approfondie de différentes méthodes
de compositionalité sémantique

Antoine Bride Tim Van de Cruys Nicolas Asher
IRIT, Université Paul Sabatier, 118 route de Narbonne, F-31062 TOULOUSE CEDEX 9
[nom]@irit.fr

Résumé.         Au cours des deux dernières décennies, de nombreux algorithmes ont été développés pour capturer la
sémantique des mots simples en regardant leur répartition dans un grand corpus, et en comparant ces distributions dans
un modèle d’espace vectoriel. En revanche, il n’est pas trivial de combiner les objets algébriques de la sémantique dis-
tributionnelle pour arriver à une dérivation d’un contenu pour des expressions complexes, composeés de plusieurs mots.
Notre contribution a deux buts. Le premier est d’établir une large base de comparaison pour les méthodes de composition
pour le cas adjectif_nom. Cette base nous permet d’évaluer en profondeur la performance des différentes méthodes de
composition. Notre second but est la proposition d’une nouvelle méthode de composition, qui est une généralisation de
la méthode de Baroni & Zamparelli (2010). La performance de notre nouvelle méthode est également évalueé sur notre
nouveau ensemble de test.
Abstract.        In the course of the last two decades, numerous algorithms have sprouted up that successfully capture
the semantics of single words by looking at their distribution in text, and comparing these distributions in a vector space
model. However, it is not straightforward to construct meaning representations beyond the level of individual words – i.e.
the combination of words into larger units – using distributional methods. Our contribution is twofold. First of all, we
carry out a large scale evaluation, comparing different composition methods within the distributional framework for the
case of adjective-noun composition, making use of a newly developed dataset. Secondly, we propose a novel method for
adjective-noun composition, which is a generalization of the approach by Baroni & Zamparelli (2010). The performance
of our novel method is equally evaluated on our new dataset.
Mots-clés :         sémantique lexicale, sémantique distributionnelle, compositionalité.

Keywords:           lexical semantics, distributional semantics, compositionality.
1    Introduction

Au cours des deux dernières décennies, il y a eu un intérêt croissant dans les méthodes dites « distributionnelles » pour
la sémantique lexicale (Landauer & Dumais, 1997; Lin, 1998; Turney & Pantel, 2010). Ces méthodes sont nommeés
ainsi car elles se fondent sur l’hypothèse distributionnelle (Harris, 1954), qui stipule que les mots qui apparaissent dans
les mêmes contextes ont tendance à être sémantiquement similaire. Dans l’esprit de cet adage, maintenant bien connu,
de nombreux algorithmes ont été développés pour tenter de capturer la sémantique des mots simples en regardant leur
répartition dans un grand corpus, et en comparant ces distributions dans un modèle d’espace vectoriel.
En comparaison avec les études manuelles de la sémantique formelle lexicale, cette approche apporte une couverture bien
plus vaste et une analyse d’une grande masse de donneés empiriques. En revanche, il n’est pas trivial de combiner les objets
algébriques de la sémantique distributionnelle pour arriver à une dérivation d’un contenu pour des expressions complexes,
composeés de plusieurs mots. A contrario, l’opération de l’application et des représentations qui utilisent le formalisme
du λ -calcul dans la sémantique formelle nous donne des méthodes de composition générales et sophistiqueés qui peuvent
traiter non seulement la composition de sens dans les cas simples mais aussi des phénomènes complexes comme la
coercition ou la composition avec des formules finement typeés (Asher, 2011; Luo, 2010; Bassac et al., 2010). Malgré
des efforts pour trouver une méthode générale de composition et diverses approches proposeés pour la composition des
structures syntaxiques spécifiques (par exemple adjectifs et syntagmes nominaux, ou verbes transitifs et objets (Mitchell
& Lapata, 2008; Coecke et al., 2010; Baroni & Zamparelli, 2010)), le problème de composition demeure un défi pour
149

B RIDE , C RUYS , A SHER                                                       [O-F.1]
l’approche distributionnelle. De plus, la validation des méthodes de composition proposeés s’est souvent faite à petite
échelle (Mitchell & Lapata, 2008). Bien que ces études sur les jugements de similarité soient prometteuses et significatives,
il serait intéressant d’avoir des études ayant une plus large couverture de validation. Elles nous permettraient de mieux
comparer les différentes méthodes de composition proposeés.
Notre contribution a deux buts. Le premier est d’établir une large base de comparaison pour les méthodes de composition
pour le cas adjectif_nom. Pour cela nous avons creé́ un vaste ensemble de test utilisant des paires contenant une expression
composeé (adjectif_nom) et un nom qui doit être proche sinon identique sémantiquement de l’expression composeé. Ces
paires ont été extraites semi-automatiquement du Wiktionnaire français. Cette base de paires similaires nous permet
d’évaluer en profondeur la performance des différentes méthodes de composition. Nous avons testé trois méthodes de
composition déjà existantes, à savoir l’approche additive et multiplicative (Mitchell & Lapata, 2008), ainsi que l’approche
par fonctions lexicales (Baroni & Zamparelli, 2010).
Les deux premières méthodes sont complètement générales et s’appliquent à des vecteurs que l’on peut automatiquement
calculer pour les adjectifs et noms. En revanche, l’approche de Baroni et Zamparelli nécessite d’apprendre une fonction
particulière associeé à chaque adjectif. Notre second but est de généraliser l’approche fonctionnelle afin d’éliminer le
besoin de conserver une fonction par adjectif. Pour cela nous utilisons une fonction généraliseé apprise à l’aide des
fonctions d’adjectifs de l’approche de Baroni et Zamparelli. Cette fonction généraliseé se combine alors avec le vecteur
d’un adjectif et celui d’un nom de manière entièrement générale. La performance de notre nouvelle méthode de l’approche
fonctionnelle généraliseé est également évalueé sur notre ensemble de test.
Nous avons organisé notre contribution de façon suivante. Nous détaillons d’abord les différents modèles de composition
que nous évaluons dans notre étude, avec un rappel sur les différentes méthodes de composition existantes et puis une
description de notre généralisation de l’approche fonctionnelle. Puis nous décrivons notre méthode d’évaluation et les
résultats. Après une section sur les travaux connexes aux nôtres, nous concluons et nous précisons quelques pistes de
travaux futurs.
2      Modèles de composition

Nous expliquons, dans cette section, quels modèles de composition ont été testés et à quoi ceux-ci correspondent. Après
une bref rappel des modèles de composition simples, nous détaillons notamment la méthode des fonctions lexicales de
Baroni & Zamparelli (2010) ainsi que la généralisation que nous en avons faite.
Voici les notations utiliseés dans la suite. Lorsque nous décrivons un objet théorique, sans soucis de sa représentation
physique par l’ordinateur, nous utilisons la police de base. Quand nous discutons de vecteurs, ceux-ci sont écrits en
gras. Les matrices sont représenteés en MAJUSCULES GRASSES. Enfin, nous écrivons les tenseurs 1 d’ordre 3 avec une
majuscule calligraphieé, par exemple A . De plus, comme nous ne manipulons pas de tenseur d’ordre supérieur à 4, nous
appelons simplement les tenseurs d’ordre 3 « tenseurs » 2 . Pour conclure, le coefficient d’indice i d’un vecteur v est noté
vi ; la notation des coefficients des matrices et tenseurs se fait de manière analogue.
Dans la suite de cet article les adjectifs seront représentés par la lettre « a » et les noms par la lettre « n ».
2.1      Modèles de composition simples

Trois modèles de composition que nous avons utilisés sont simples à décrire : les méthodes triviale, additive et multipli-
cative. L’approche triviale, noteé Ct et que nous utilisons comme base de comparaison, ignore l’adjectif :

Ct (a, n) = n

Le modèle additif, noté Ca , consiste à réaliser une combinaison linéaire entre les vecteurs a et n à l’aide de coefficients
indépendants de ceux-ci :
Ca (a, n) = α n + β a

1. Un tenseur est la généralisation d’une matrice à plusieurs indices. Pour une introduction sur les tenseurs, regardez Kolda & Bader (2009).
2. les tenseurs d’ordre 1 étant les vecteurs et les tenseurs d’ordre 2 les matrices.
150

U NE ÉVALUATION APPROFONDIE DE DIFFÉRENTES MÉTHODES DE COMPOSITIONALITÉ SÉMANTIQUE[O-F.1]
C f . l. (a, n) =          A           ×     n
F IGURE 1: Composition dans l’approche par fonctions lexicales

Enfin, tandis que les deux rois faisaient chanter des Te Deum, chacun dans son camp, [Candide] prit le parti d’aller
raisonner ailleurs des effets et des causes. Il passa par-dessus des tas de morts et de mourants, et gagna d’abord un
village voisin ; il était en cendres : c’était un village abare que les Bulgares avaient brûlé, selon les lois du droit public.
[. . .]
Candide s’enfuit au plus vite dans un autre village : il appartenait à des Bulgares, et les héros abares l’avaient traité de
même. . .
F IGURE 2: extrait de Candide de Voltaire, Chapitre 3
Sur un ensemble de développement, nous avons testé le modèle pour différentes valeurs de α et β telles que α + β = 1 3
et conservé les valeurs donnant les meilleurs résultats : α = 0.4 et β = 0.6.
Le modèle multiplicatif, noté Cm , consiste à multiplier les vecteurs a et n terme à terme :

Cm (a, n) = n ⊗ a
o`u (n ⊗ a)i = ni × ai

L’approche par fonctions lexicales de Baroni & Zamparelli (2010) étant plus complexe, nous la décrivons dans la section
suivante. Nous expliquons ensuite pourquoi et comment nous avons tenté de généraliser cette approche.
2.2    Fonctions Lexicales

Le modèle de composition par fonctions lexicales, noté C f . l. , consiste à représenter les adjectifs par des matrices. Ainsi la
combinaison d’un adjectif et d’un nom est le produit de la matrice A et du vecteur n comme le montre la figure 1.
L’approche distributionelle ne permet cependant pas de générer naturellement des matrices. Baroni et Zamparelli pro-
posent donc d’apprendre la matrice d’un adjectif à partir d’exemples de vecteurs nom_adjectif obtenus directement à
partir du corpus. De tels vecteurs nom_adjectif sont obtenus de la même manières que des vecteurs représentant un seul
mot : quand la combinaison de l’adjectif et du nom occurre, on observe son contexte. Prenons l’exemple du paragraphe en
figure 2. Le mot « village » apparaît trois fois. La première occurrence peut contribuer à creér le vecteur village_voisin,
la deuxième à creér village_abare, et la dernière à creér village_autre.
Une fois que l’on a creé́ suffisamment de vecteurs nom_adjectif pour un adjectif donné, on calcule la matrice A. Pour cela,
on réalise une régression partielle des moindres carrés, sur les combinaisons nom_adjectif. Formellement, en notant na
les vecteurs nom_adjectif, il s’agit de trouver A minimisant :

∑     A × n − na 2             o`u     v   2=     ∑ v2i
n                                                  i

Pour reprendre l’exemple précédent, on minimiserait, notamment, {VOISIN×village − village_voisin{2 pour obtenir la
matrice VOISIN.
Il est important de noter qu’une telle approche nécessite un corpus plus important que les autres approches. En effet,
comme il ne s’agit plus seulement d’observer des exemples d’utilisation d’adjectifs ou de noms isolés mais des exemples
d’utilisation de la combinaison d’un adjectif et d’un nom, les occurrences sont intrinsèquement plus rares. Dans le para-
graphe en figure 2, chacune des apparitions du mot « village » peut contribuer à la création du vecteur village mais aucune
ne peut contribuer à la création du vecteur village_félon.
3. Les vecteurs étant normalisés (cf. 3.2), cette condition ne réduit pas la généralité de notre test.
151

B RIDE , C RUYS , A SHER                                  [O-F.1]
C f . l. g. (a, n) =       A            ×     a          ×   n
F IGURE 3: Composition dans l’approche par fonction lexicale généraliseé
Baroni & Zamparelli (2010) expliquent comment limiter les problèmes liés au manque d’exemples. De plus, les expé-
riences présenteés jusqu’à maintenant montrent que les corpus actuels permettent une implémentation efficace de l’ap-
proche par fonctions lexicales pour les adjectifs les plus courants. En effet, celle-ci a obtenu les meilleurs résultats sur un
certain nombre d’expériences.
Néanmoins, l’approche de Baroni et Zamparelli reste limiteé pour traiter des adjectifs relativement rares. Par exemple,
l’adjectif « félon » apparaît 217 fois dans le corpus FRWaC (Baroni et al., 2009). C’est assez pour générer un vecteur félon,
mais très peu pour espérer générer un nombre suffisant de vecteurs nom_félon et donc générer la matrice FÉLON.
De plus, devoir apprendre une matrice pour chaque adjectif pose un problème théorique. En effet, cette approche suppose,
comme l’approche de Montague, que l’effet d’un adjectif sur un nom est idiosyncratique à l’adjectif (Kamp, 1975). Mais
le désavantage de ceci est que les donneés montrent que la plupart des adjectifs dans les langues du monde sont subjectifs
et se comportent selon des principes générales de composition (Partee, 2010; Asher, 2011). La manière dont les adjectifs
sont utilisés dans la langue française laisse supposer qu’il existe une façon générale de combiner adjectifs et noms. Lorsque
l’on connaît la signification d’un adjectif, l’association à un nom est rarement problématique. Ceci, indépendamment de
la présence ou de l’absence d’exemples d’association.
2.3    Généralisation

Pour résoudre ces problèmes, nous proposons de généraliser les fonctions lexicales que sont les matrices d’adjectifs par
une fonction lexicale unique : le tenseur de composition adjectivale A . Dans notre approche, noteé C f . l. g. , la combinaison
d’un adjectif et d’un nom est le produit du tenseur A avec le vecteur adjectif puis le vecteur nom, c.f. figure 3.
On peut noter que le produit du tenseur A et du vecteur a est une matrice dépendante de l’adjectif et multiplieé au vecteur
n. Cette matrice correspond à la matrice A de l’approche par fonctions lexicales de Baroni et Zamparelli. Ainsi, comme
le montre la figure 4, nous obtenons le tenseur A à l’aide d’exemples de matrices obtenues par la méthode de Baroni et
Zamparelli, et de vecteurs obtenus naturellement dans l’approche distributionelle. Plus précisément nous effectuons une
régression partielle des moindres carrés sur les matrices généreés par les équations. Formellement, il s’agit de trouver A
minimisant :
∑ A ×a−A 2              o`u M 2 = ∑ M2i, j
a                                        i, j
Cette équation ressemble beaucoup à l’équation non généraliseé. En effet, dans les deux cas, l’objectif formel est de
trouver une application linéaire 4 minimisant des équations dans un espace vectoriel de dimension finie.
Cependant, la généralisation fait une hypothèse bien plus forte. En effet, l’image d’une application linéaire est toujours
de dimension inférieure à son espace de départ. Or, par construction, si les vecteurs adjectif existent dans un espace de
dimension N, alors les matrices ADJECTIF existent dans un espace de dimension N × N. Ainsi, s’il existe un tenseur A ,
cela signifie que le sous-espace engendré par les matrices ADJECTIF est de taille inférieur à N réduisant considérablement
leur degré de liberté maximal initial (dimension N × N). L’approche de Baroni et Zamparelli n’a pas cette hypothèse
puisque les vecteurs nom et nom_adjectif coexistent dans un même espace (et les espaces engendrés par ceux-ci ont
donc la même dimension maximale).
Moins formellement, chercher une telle application linéaire présuppose qu’il n’y pas plus d’« information » dans le sous-
espace d’arriveé que de le sous-espace de départ. Cela creé́ une différence notable entre les deux méthodes. En effet, dans
la méthode de Baroni et Zamparelli, les vecteurs nom et nom_adjectif existent dans le même espace. L’hypothèse sus-cité
4. représenté par une matrice ou un tenseur.
152

U NE ÉVALUATION APPROFONDIE DE DIFFÉRENTES MÉTHODES DE COMPOSITIONALITÉ SÉMANTIQUE[O-F.1]
Trouver le tenseur A minimisant les normes de :
r
o                                                                   l
e
A
×     u
g
−        ROUGE            ,             A
×     n    −         LENT             ...
e                                                                   t
F IGURE 4: Apprentissage du tenseur A
consiste donc à supposer que l’on a pas besoin de plus d’informations pour décrire voisin_village que pour décrire village ;
uniquement d’informations différentes. Cette hypothèse est partageé par beaucoup de méthodes de composition dont
l’objectif est de pouvoir réaliser des compositions en cascade 5 . A contrario, dans la méthode généraliseé, l’application
linéaire rechercheé a un espace de départ 6 bien plus petit que son espace d’arriveé 7 . La généralisation fait donc une
hypothèse beaucoup plus forte : elle suppose que les matrices A creéés par la méthode de Baroni et Zamparelli ne sont
pas plus informatives que les vecteurs a que l’on peut extraire directement d’un corpus. Ces matrices ne seraient, d’une
certaine manière, qu’une reé́criture des adjectifs pertinente pour la composition.
Ceci étant, de manière similaire à l’approche de Baroni et Zamparelli, notre approche nécessite d’apprendre un nombre
significatif de matrices A. Cela n’est pas un problème, car le FRWaC fournit suffisamment d’adjectifs sur lesquels l’ap-
proche de Baroni et Zamparelli fonctionne parfaitement. Par exemple, le 2000ième adjectif le plus courant dans le FRWaC
(« fasciste ») y occurre plus de 4000 fois.
Pour reprendre l’exemple de l’adjectif « félon », notre approche exige uniquement de connaître le vecteur félon, évitant le
problème de manque de donneés lié à la construction de la matrice FÉLON.
Une fois le tenseur A obtenu, il nous fallait vérifier expérimentalement sa pertinence. En effet, nous n’avions pas garantie
que le tenseur optimisant les équations décrites dans la figure 4 soit intéressant sémantiquement.
3        Évaluation

3.1       Description de la tâche

Pour évaluer les différents modèles de composition, nous avons construit une tâche de similarité inspireé des travaux
de Zanzotto et al. (2010) et utiliseé pour la tâche evaluating phrasal semantics de SEMEVAL-2013 (Korkontzelos et al.,
2013). La tâche propose de juger la similarité entre une combinaison adjectif_nom et un seul nom. Ceci est important,
étant donné que les modèles de composition doivent être capables de traiter des combinaisons adjectifs_nom de taille
arbitraire. La tâche est donc la suivante :
Soient          comb = Combinaison(adjectif, nom1) et nom2
Evaluer         Similarité(comb, nom2)
La « Combinaison » est réalisé par les différents modèles de composition. La « Similarité » doit être une fonction binaire ;
les valeurs de retour étant « similaire » et « non_similaire ». Cependant, l’approche distributionnelle ne fournit naturelle-
ment que des valeurs de similarité continues (e.g. cosinus entre deux vecteurs). Nous avons donc pris des exemples positifs
et des exemples négatifs de notre ensemble de test afin de savoir quelles valeurs de cosinus correspondent à « similaire » et
quelles valeurs de cosinus correspondent à « non_similaire ». Plus précisément, nous avons, pour chaque approche, réalisé
une régression logistique sur 50 exemples positifs et 50 exemples négatifs (dorénavant séparés de notre ensemble de test)
afin d’apprendre le seuil de cosinus à partir duquel une paire est similaire.
Nous avons creé́ notre ensemble de test d’une manière semi-automatique, en utilisant des dictionnaires. Prenons par
exemple la définition de champagne dans le Wiktionnaire français 8 , figure 5. D’une telle définition, il est assez simple
5.   Par exemple, obtenir le sens de « grosse voiture rouge » en composant « grosse » et « voiture » puis « rouge » et « grosse voiture ».
6.   l’espace des vecteurs mot.
7.   l’espace des matrices ADJECTIF.
8.   http://fr.wiktionary.org/wiki/champagne, accédé à 20 février 2014.
153

B RIDE , C RUYS , A SHER                                                       [O-F.1]
d’extraire la paire (mousseux_vin, champagne). En traversant un grand dictionnaire, il est ainsi possible d’extraire des
paires (adjectif_nom, nom) positives (similaires).

champagne /S̃A.pañ/ masculin
1. Vin mousseux produit en Champagne et protégé par une appellation d’origine contrôleé.
2. (Histoire des techniques) Cercle de fer pour soutenir l’étoffe à teindre dans la cuve de teinture.
F IGURE 5: Définition de champagne, extrait du Wiktionnaire français

Nous avons donc téléchargé toutes les entreés du Wiktionnaire français, et nous les avons tageés avec le tageur MElt
(Denis et al., 2010). Ensuite, nous avons sélectionné les définitions qui débutent avec une combinaison adjectif-nom.
Enfin, nous avons supprimé les instances utilisant des mots qui apparaissent trop peu fréquemment dans notre corpus
FRW a C 9 .

Les instances ainsi extraites d’une manière automatique étaient alors contrôleés manuellement. Toutes les paires jugeés
incorrectes étaient rejeteés. Nous avons ainsi obtenu 714 exemples positifs.
Nous avons ensuite creé́ un premier fichier d’exemples négatifs en sélectionnant deux noms (nom1, nom2) et un adjectif
adjectif aléatoirement. Les couples (adjectif_nom1, nom2) ainsi creé́s étaient ensuite vérifiés manuellement.
Nous avons ainsi obtenu 899 exemples négatifs.
L’inconvénient d’un tel procédé est qu’il propose souvent des combinaisons adjectif_nom1 insenseés. Ceci simplifie
la tâche de séparer exemples positifs et négatifs. Nous avons donc creé́ un second fichier d’exemples négatifs en sélec-
tionnant des combinaisons adjectif_nom1 depuis le Wiktionnaire et des noms nom2 aléatoires. Nous avons ensuite
vérifié manuellement que les couples (adjectif_nom1, nom2) ainsi creé́s était bien des exemples négatifs. Nous avons
ainsi obtenu 494 exemples négatifs.
La table 1 montre 5 exemples positifs et 5 exemples négatifs de chaque sorte. Dans cette table, les noms et adjectifs
sont sous forme de lemme. On peut noter que les exemples négatifs générés complètement aléatoirement contiennent
des combinaisons adjectif_nom ayant un sens clair (penchant_autoritaire) et n’en n’ayant pas (chasse_fossile). Les
exemples négatives creé́s à base du Wiktionnaire, en revanche, contiennent uniquement des combinaisons qui ont un sens
clair. 10

exemples positifs                   exemples négatifs aléatoires                  exemples négatifs Wiktionnaire
(mot_court, abréviation)                 (importance_fortuit, gamme)                  (jugement_favorable, discorde)
(ouvrage_littéraire, essai)                 (penchant_autoritaire, ile)            (circonscription_administratif, fumier)
(compagnie_honorifique, ordre)                  (auspice_aviaire, ponton)                    (mention_honorable, renne)
(costume_féminin, ensemble)                (banquette_celeste, discipline)                  (attitude_hautain, racine)
(partie_unitaire, élément)               (chasse_fossile, propulsion)               (examen_attentif, condamnation)

TABLE 1: Une partie des ensembles de test.
3.2     Espace sémantique

Une fois le test choisi et les fichiers de test réalisés nous avons creé́ l’espace sémantique. Pour cela, nous avons utilisé le
corpus FRWaC (Baroni et al., 2009) – un corpus de 1,6 milliard de mots extrait du web – tagé avec le tageur MElt (Denis
et al., 2010) et parsé à l’aide du parseur MaltParser (Nivre et al., 2006), formé sur une version de dépendances du French
treebank (Candito et al., 2010). Nous avons d’abord récupéré les lemmes des mots, adjectifs, et noms du corpus. Nous
avons uniquement conservé les lemmes écrits en toutes lettres 11 puis selectionné les 10000 lemmes les plus fréquents
pour chaque catégorie (mots, adjectifs, noms). Enfin, nous avons généré l’espace en utilisant les adjectifs et les noms
9. i.e. moins de 200 fois pour les adjectifs et moins de 1500 fois pour les noms.
10. Nous fournissons les fichiers correspondant sur simple demande par e-mail.
11. Cette étape élimine principalement les dates, les nombres en chiffre, et la ponctuation. Nous estimons que ceux-ci ont un intérêt limité en approche
distributionnelle.
154

U NE ÉVALUATION APPROFONDIE DE DIFFÉRENTES MÉTHODES DE COMPOSITIONALITÉ SÉMANTIQUE[O-F.1]
comme vecteurs, et les mots comme dimensions en utilisant la méthode des bags of words. Nous avons alors nettoyé
l’espace ainsi creé́s en normalisant les vecteurs et en appliquant le positive point-wise mutual information (ppmi, (Church
& Hanks, 1990)) à l’espace.
Nous avons alors comparé les méthodes sur trois versions de l’espace : l’espace entier, l’espace réduit à 300 dimensions par
la méthode de décomposition en valeurs singulières (svd, (Golub & Van Loan, 1996)), et l’espace réduit à 300 dimensions
par la méthode de factorisation en matrices positives (nmf, (Lee & Seung, 2000)). Nous avons fait cela pour pouvoir tester
chaque méthode dans des conditions optimales. En effet :
– Un espace non réduit contient plus d’informations. Ainsi les méthodes compatibles (additive et multiplicative) peuvent
obtenir de meilleurs résultats. Cependant, utiliser la méthode des fonctions lexicales sur l’espace non réduit demanderait
d’apprendre des matrices de taille 10000 × 10000. Ceci poserait des problèmes de temps de calcul et de parcimonie des
donneés comme on a vu ci-dessus. De même pour les fonctions étendues.
– Un espace réduit avec la méthode svd permet expérimentalement d’obtenir de bon résultats pour les fonctions lexicales.
Cependant, la présence de valeurs négatives dans le vecteurs de l’espace réduit drastiquement l’efficacité de l’approche
multiplicative.
– Un espace réduit avec la méthode nmf ne pénalise pas les approches multiplicatives.
3.3    Résultats

Les espaces sémantiques ayant été creé́s, nous avons d’abord testé les différentes approches sur le jeu de test utilisant
des exemples négatifs complètement aléatoires (deuxième colonne de la table 1). Nous présentons les résultats dans la
table 2a. Plusieurs commentaires peuvent être faits. Nous commentons d’abord les méthodes individuellement, puis nous
les comparons.

triviale    multiplicative        additive     fonctions lexicales   f. l. généraliseés
non-réduit        0.83             0.86              0.88                 N/A               N/A
svd            0.79             0.55              0.84                 0.93              0.61
nmf            0.78             0.83              0.79                 0.90              0.88
(a) Les exemples négatifs sont creé́s entièrement aléatoirement.
triviale    multiplicative        additive     fonctions lexicales   f. l. généraliseés
non-réduit        0.78             0.79              0.83                 N/A               N/A
svd            0.77             0.55              0.82                 0.84              0.46
nmf            0.75             0.73              0.79                 0.78              0.78
(b) Les exemples négatifs sont creé́s à l’aide de combinaisons adjectif-nom existantes.

TABLE 2: Pourcentage de couples (adjectif_nom1, nom2) bien classés selon l’approche et l’espace.

D’abord, l’approche triviale, consistant à comparer les deux noms et ignorer l’adjectif, affiche un taux de réussite relati-
vement élevé (∼ 80%). Ceci est dû au fait que la plupart des adjectifs ne changent pas la nature du nom auquel ils sont
accolés. Une voiture rouge, lente, grosse, ou ancienne reste fondamentalement une voiture. Une voiture miniature n’est
plus nécessairement une voiture mais de tels exemples sont rares.
Ensuite, la méthode multiplicative a de mauvaises performances sur l’espace réduit à l’aide de svd. Cela confirme l’in-
compatibilité de cette méthode avec les valeurs négatives généreés par svd. La figure 6 permet de visualiser la raison à
cela. On peut y voir que multiplier terme à terme deux vecteurs ayant des valeurs négatives résulte en un troisième vecteur
très éloigné des deux autres. Cela va à l’encontre de l’ideé selon laquelle la combinaison d’un nom et d’un adjectif à un
sens proche du nom d’origine.
De plus, nous constatons que le modèle multiplicatif sur l’espace non-réduit n’atteint pas des résultats sensiblement
meilleurs que le modèle trivial. La différence entre le modèle multiplicatif (0.86) et le modèle trivial (0.83) n’est pas
statistiquement significative (χ 2 = 2.69, p > 0.05). 12 Le modèle additif, en revanche, atteint un résultat en mode non-
réduit (0.88) qui est significativement meilleur que la méthode triviale (χ 2 = 24.83, p < 0.01) et le modèle multiplicatif
12. Pour tous nos tests de signification, nous utilisons le test de McNemar (Dietterich, 1998).
155

B RIDE , C RUYS , A SHER                                           [O-F.1]
1                                                               1
v2                                  v1

0.5                                                            0.5
v1
v1 ⊗ v2
−1        −0.5                   0.5            1            −1           −0.5                  0.5      1

v2                       v1 ⊗ v2
−0.5                                                            −0.5
−1                                                             −1

(a) vecteurs à valeurs positives                               (b) vecteurs à valeurs négatives

F IGURE 6: l’effet de valeurs négatives sur l’approche multiplicative
(χ 2 = 21.33, p < 0.01). Les résultats du modèle additif pour les espaces svd et nmf sont également significatifs (χ 2 =
11.82, p < 0.01 et χ 2 = 18.91, p < 0.01, respectivement) mais il sont inférieurs au résultat de l’espace non-réduit. On
constate que le modèle multiplicatif atteint un résultat de 0.83 dans l’espace nmf qui est significativement meilleur que le
modèle multiplicatif (χ 2 = 31.34, p < 0.01), mais toujours inférieur au résultat de l’espace non-réduit.
Ensuite, nous constatons que l’approche par fonctions lexicales de Baroni et Zamparelli dans l’espace svd obtient des
résultats qui sont significativement meilleurs que toute autre approche avec tout autre espace (χ 2 = 33.49, p < 0.01 pour
la différence avec le modèle additif non-réduit). Nous constatons également que la fonction lexicale généraliseé dans
l’espace nmf obtient des résultats qui sont comparables avec l’approche de Baroni et Zamparelli dans ce même espace
(χ 2 = 3.95, p > 0.01) et équivalents aux meilleurs résultats des autres méthodes (notamment le modèle additif non-réduit).
Cependant, la fonction lexicale généraliseé – comme le modèle multiplicatif – a de faibles performances sur l’espace svd
(0.61). Cela semble signifier que, dans cet espace, les matrices de la méthode des fonctions lexicales ne sont pas générables
à l’aide d’un tenseur unique et des vecteurs correspondants.
Nous avons ensuite répété nos tests avec des exemples négatifs utilisant les combinaisons adjectif_nom extraites du
Wiktionnaire français (troisième colonne de la table 1). Nous présentons les résultats dans la table 2b. Nous constatons que
les résultats de nos premiers tests sont largement confirmés. Le modèle additif en espace non-réduit atteint un score qui est
significativement meilleur que la méthode triviale (0.83 vs. 0.78, χ 2 = 10.69, p < 0.01), bien que le modèle multiplicatif
ne donne pas un score supérieur à la méthode triviale. Nous notons, toutefois, que l’approche par fonctions et l’approche
additive obtiennent désormais des résultats globalement équivalents dans leurs meilleurs conditions respectives — 0.83
pour le modèle additif non-réduit vs. 0.84 pour le modèle fonctionel svd, une différence non-significative (χ 2 = 0.20,
p > 0.05). Cela semble indiquer que les fonctions lexicales sont particulièrement efficaces pour séparer les combinaisons
insenseés, mais qu’ils obtiennent un score inférieur quand ils doivent juger la similarité de compositions reélles.
4    Travaux connexes

Un certain nombre de chercheurs a déjà étudié et évalué divers modèles de composition au sein d’un cadre distributionnel.
Une des premières tentatives pour évaluer de manière systématique des modèles simples de composition a été faite par
Mitchell & Lapata (2008). Ils explorent un certain nombre de modèles différents pour la composition de vecteurs, dont les
plus importants sont le modèle additif et le modèle multiplicatif. Ils évaluent leurs modèles sur une tâche de similitude de
phrases nom-verbe. Pour évaluer leur modèle, ils ont demandé à des annotateurs humains de juger la similarité entre deux
paires compositionnelles (par exemple en attribuant un certain score). La tâche du modèle de composition est alors de
reproduire les jugements humains. Les résultats montrent que le modèle multiplicatif ainsi qu’une combinaison pondéreé
du modèle additif et du modèle multiplicatif donnent les meilleurs résultats. Les auteurs ont refait leur étude dans Mitchell
& Lapata (2010) avec un ensemble de test plus large (les paires d’adjectifs et noms étaient également inclues), et ils ont
confirmé leur résultats initiaux. Bien qu’une telle tâche de similitude a ses mérites, l’attribution d’un score de similitude est
156

U NE ÉVALUATION APPROFONDIE DE DIFFÉRENTES MÉTHODES DE COMPOSITIONALITÉ SÉMANTIQUE[O-F.1]
plutôt difficile pour des juges humains 13 . Une décision binaire, comme dans notre tâche, est beaucoup moins floue. Nous
soutenons que l’approche adopteé dans notre contribution donne une image plus claire et plus stable de la performance
des différents modèles de composition.
Baroni & Zamparelli (2010) évaluent leur modèle de fonctions lexicales dans un contexte quelque peu différent. Ils
évaluent leur modèle en regardant la capacité de reconstruire les vecteurs nom_adjectif qui n’ont pas été vus pendant la
phase d’entraînement. Leur résultats montrent que leur modèle de fonctions lexicales atteint les meilleurs résultats pour
reconstruire les vecteurs de co-occurrence originaux, suivi de près par le modèle additif. Notez que nous observons la
même tendance dans notre évaluation.
Grefenstette et al. (2013) proposent aussi une généralisation du modèle de fonctions lexicales par des tenseurs. Leur
généralisation a pour objectif différent, à savoir modéliser les verbes transitifs à l’aide de tenseurs. Cependant, nous
utilisons un approche très similaire pour l’obtention des tenseurs. En effet, ils utilisent la méthode de Baroni et Zamparelli
pour apprendre des matrices correspondant à une combinaison VERBE _ COMPLÉMENT que l’on peut multiplier à un
vecteur sujet, pour obtenir le vecteur sujet_verbe_complément. Par exemple MANGER _ VIANDE multiplié au vecteur
chien permet d’obtenir chien_manger_viande. Ils apprennent alors un tenseur correspondant à chaque verbe de la même
manière que nous apprenons le tenseur A .
Coecke et al. (2010) présentent un cadre théorique abstrait dans lequel un vecteur de phrase est une fonction du produit
de Kronecker de ses vecteurs de mots, ce qui permet une plus grande interaction entre les différentes traits de mots.
Un certain nombre d’instanciations du modèle de Coecke et al. (2010) – où l’ideé clé est que les mots relationnels (par
exemple les verbes) ont une structure riche (multidimensionnelle) qui agit comme un filtre sur leurs arguments – sont
testés expérimentalement dans les articles de Grefenstette & Sadrzadeh (2011a) et Grefenstette & Sadrzadeh (2011b). Les
auteurs évaluent leurs modèles en utilisant une tâche de similitude semblable à celle de Mitchell & Lapata. Cependant,
ils utilisent des constructions compositionnelles plus étendues : plutôt que d’utiliser des compositions de deux mots (par
exemple verbe et objet), ils utilisent des phrases simples transitives (sujet verbe objet). Ils montrent que leurs instancia-
tions du modèle catégoriel obtiennent des meilleurs résultats que les modèles additifs et multiplicatifs sur leur tâche de
similitude transitive.
Socher et al. (2012) présentent un modèle compositionnel basé sur les réseaux de neurones récursifs. Chaque nœud dans
un arbre syntaxique est attribué à la fois un vecteur et une matrice ; le vecteur capture la signification reélle du constituant,
tandis que la matrice modélise la manière dont il change le sens des mots et expressions voisins. L’évaluation s’est faite
extrinsèquement, en utilisant le modèle dans une tâche de prédiction du sentiment. Ils montrent que l’approche baseé sur
les réseaux de neurones obtient de meilleurs résultats que les modèles additifs, multiplicatifs, et par fonctions lexicales.
Cependant, d’autres chercheurs ont rapporté des résultats différents. Blacoe & Lapata (2012) évaluent les modèles additifs
et multiplicatifs ainsi que l’approche de Socher et al. (2012) sur deux tâches différentes : la tâche de similitude de Mitchell
& Lapata (2010) et une tâche de détection de paraphrases. Ils trouvent que les modèles additifs et multiplicatifs atteignent
des meilleurs scores que le modèle de Socher et al. (2012).
Étroitement lieé aux travaux sur la compositionnalité est la recherche sur le calcul de sens du mot en contexte. Erk & Padó
(2008, 2009) font usage de restrictions sélectionnelles pour exprimer le sens d’un mot dans son contexte ; le sens d’un
mot en présence d’un argument est calculé en multipliant le vecteur du mot avec un vecteur qui capture les restrictions
sélectionnelles inverses de l’argument. Thater et al. (2009, 2010) étendent l’approche fondeé sur les restrictions sélection-
nelles en incorporant des co-occurrences du deuxième ordre dans leur modèle. Dinu & Lapata (2010) proposent un cadre
probabiliste qui modélise la signification des mots comme une distribution de probabilité sur des facteurs latents. Cela
permet de modéliser le sens contextualisé comme un changement dans la distribution du mot originel. Dinu et Lapata
utilisent la factorisation de matrice positive (NMF) pour induire les facteurs latents.
En général, les modèles latents se sont avéreés utiles pour la modélisation du sens des mots. L’un des modèles latents
de la sémantique les plus connus est l’analyse de sémantique latente (LSA, Landauer & Dumais (1997)), qui utilise la
décomposition en valeurs singulières afin d’induire automatiquement des facteurs latents de matrices terme-document.
Un autre modèle de sens latent bien connu, qui adopte une approche générative, est l’allocation Dirichlet latente (LDA,
Blei et al. (2003)).
Les tenseurs ont été utilisés auparavant pour la modélisation du langage naturel. Giesbrecht (2010) décrit un modèle de
factorisation de tenseurs pour la construction d’un modèle distributionnel qui est sensible à l’ordre des mots. Et Van de
Cruys (2010) utilise un modèle de factorisation de tenseurs afin de construire un modèle de restrictions sélectionnelles

13. En témoignent le faible taux d’accord d’inter-annotateur – Mitchell & Lapata (2010) rapportent une corrélation entre juges humains assez faible
de 0.52 pour les combinaisons adjectif_nom.
157

B RIDE , C RUYS , A SHER                               [O-F.1]
multidimensionnelles de verbes, sujets et objets.
5    Conclusion
Dans notre contribution, nous avons testé différentes méthodes principales de compositionalité en approche distributio-
nelle. À notre connaissance, nous sommes les premiers à réaliser de tels tests sur la langue française. Nous avons, de plus,
creé́ un nouveau ensemble de test pour l’évaluation de la compositionalité dans un cadre distributionnel pour la langue
française, librement disponible pour d’autres chercheurs.
Nos tests confirment que la méthode des fonctions lexicales de Baroni et Zamparelli a de bonnes performances en com-
paraison des autres approches. Nos tests semblent nuancer ceci par le fait que ces performances ne sont sensiblement
meilleures que lorsque les exemples négatifs sont entièrement aléatoire.
De plus, nous avons proposé une généralisation de la méthode des fonctions lexicales. D’après nos tests, cette générali-
sation ne peut pas se faire dans les conditions optimales pour la méthode des fonctions lexicales. Ainsi bien que notre
généralisation fonctionne correctement, les conditions dans lesquelles elle est utiliseé font qu’elle a des résultats équi-
valent aux méthodes additive et multiplicative de Mitchell et Lapata, mais légèrement inférieurs à ceux de l’approche de
Baroni et Zamparelli.
Dans le futur, il serait intéressant de tester différentes valeurs de réduction dimensionnelle afin d’optimiser notre fonc-
tion lexicale généraliseé. De plus, il est possible que de meilleurs résultats puissent être obtenus en proposant plusieurs
fonctions généraliseés plutôt qu’une. On peut tenter, par exemple, de séparer les adjectifs intersectifs 14 des adjectifs
non-intersectifs 15 .
Il serait également intéressant de réaliser un ensemble de test pour une tâche avec laquelle la méthode des fonctions lexi-
cales n’est pas entièrement compatible, comme la combinaison de noms. En effet, pour obtenir le sens de « laboratoire
d’analyses médicales », il faut appliquer « analyses médicales » à « laboratoire ». Or la méthode des fonctions lexicales
ne propose pas de manière satisfaisante d’obtenir la matrice ANALYSE _ MÉDICALE. En effet, obtenir une telle matrice par
apprentissage à partir d’exemples d’utilisation d’« analyse médicale » est en contradiction avec le principe de compositio-
nalité.
Remerciements
Nous tenons à remercier toute l’équipe du projet composes 16 pour leur boite à outils DisSeCT (Dinu et al. (2013)) qui
nous a sûrement épargné plusieurs mois de développement.
Références
A SHER N. (2011). Lexical Meaning in Context : A Web of Words. Cambridge University Press.
BARONI M., B ERNARDINI S., F ERRARESI A. & Z ANCHETTA E. (2009). The wacky wide web : A collection of very
large linguistically processed web-crawled corpora. Language Resources and Evaluation, 43(3), 209–226.
BARONI M. & Z AMPARELLI R. (2010). Nouns are vectors, adjectives are matrices : Representing adjective-noun
constructions in semantic space. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language
Processing, p. 1183–1193, Cambridge, MA : Association for Computational Linguistics.
BASSAC C., M ERY B. & R ETORÉ C. (2010). Towards a Type-theoretical account of lexical semantics. Journal of
Logic, Language and Information, 19(2), 229–245.
B LACOE W. & L APATA M. (2012). A comparison of vector-based representations for semantic composition. In Procee-
dings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, p. 546–556, Jeju Island, Korea : Association for Computational Linguistics.
14. « Rouge » par exemple. Une voiture rouge est une voiture.
15. « Faux » par exemple. Une fausse voiture n’est pas une voiture.
16. http://clic.cimec.unitn.it/composes/
158

U NE ÉVALUATION APPROFONDIE DE DIFFÉRENTES MÉTHODES DE COMPOSITIONALITÉ SÉMANTIQUE[O-F.1]
B LEI D. M., N G A. Y. & J ORDAN M. I. (2003). Latent dirichlet allocation. The Journal of Machine Learning Research,
3, 993–1022.
C ANDITO M., C RABBÉ B., D ENIS P. et al. (2010). Statistical french dependency parsing : treebank conversion and first
results. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC 2010),
p. 1840–1847.
C HURCH K. W. & H ANKS P. (1990). Word association norms, mutual information & lexicography. Computational
Linguistics, 16(1), 22–29.
C OECKE B., S ADRZADEH M. & C LARK S. (2010). Mathematical foundations for a compositional distributed model
of meaning. Lambek Festschrift, Linguistic Analysis, vol. 36, 36.
D ENIS P., S AGOT B. et al. (2010). Exploitation d’une ressource lexicale pour la construction d’un étiqueteur morpho-
syntaxique état-de-l’art du français. In Traitement Automatique des Langues Naturelles : TALN 2010.
D IETTERICH T. G. (1998). Approximate statistical tests for comparing supervised classification learning algorithms.
Neural computation, 10(7), 1895–1923.
D INU G. & L APATA M. (2010). Measuring distributional similarity in context. In Proceedings of the 2010 Conference
on Empirical Methods in Natural Language Processing, p. 1162–1172, Cambridge, MA.
D INU G., P HAM N. & M. B. (2013). Dissect : Distributional semantics composition toolkit. In Proceedings of the
System Demonstrations of ACL, p. 31–36, East Stroudsburg PA : Association for Computational Linguistics.
E RK K. & PADÓ S. (2008). A structured vector space model for word meaning in context. In Proceedings of the
Conference on Empirical Methods in Natural Language Processing, p. 897–906, Waikiki, Hawaii, USA.
E RK K. & PADÓ S. (2009). Paraphrase assessment in structured vector space : Exploring parameters and datasets. In
Proceedings of the Workshop on Geometrical Models of Natural Language Semantics, p. 57–65, Athens, Greece.
G IESBRECHT E. (2010). Towards a matrix-based distributional model of meaning. In Proceedings of the NAACL HLT
2010 Student Research Workshop, p. 23–28 : Association for Computational Linguistics.
G OLUB G. H. & VAN L OAN C. F. (1996). Matrix Computations (3rd Ed.). Baltimore, MD, USA : Johns Hopkins
University Press.
G REFENSTETTE E., D INU G., Z HANG Y.-Z., S ADRZADEH M. & M. B. (2013). Multi-step regression learning for
compositional distributional semantics. In Proceedings of the 10th International Conference on Computational Seman-
tics (IWCS), p. 131–142, East Stroudsburg PA : Association for Computational Linguistics.
G REFENSTETTE E. & S ADRZADEH M. (2011a). Experimental support for a categorical compositional distributional
model of meaning. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, p.
1394–1404, Edinburgh, Scotland, UK. : Association for Computational Linguistics.
G REFENSTETTE E. & S ADRZADEH M. (2011b). Experimenting with transitive verbs in a discocat. In Proceedings of the
GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics, p. 62–66, Edinburgh, UK : Association
for Computational Linguistics.
H ARRIS Z. S. (1954). Distributional structure. Word, 10(23), 146–162.
K AMP H. (1975). Two theories about adjectives. Formal semantics of natural language, p. 123–155.
KOLDA T. G. & BADER B. W. (2009). Tensor decompositions and applications. SIAM Review, 51(3), 455–500.
KORKONTZELOS I., Z ESCH T., Z ANZOTTO F. M. & B IEMANN C. (2013). Semeval-2013 task 5 : Evaluating phrasal
semantics. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2 : Proceedings of the
Seventh International Workshop on Semantic Evaluation (SemEval 2013), p. 39–47, Atlanta, Georgia, USA : Association
for Computational Linguistics.
L ANDAUER T. & D UMAIS S. (1997). A solution to Plato’s problem : The Latent Semantic Analysis theory of the
acquisition, induction, and representation of knowledge. Psychology Review, 104, 211–240.
L EE D. D. & S EUNG H. S. (2000). Algorithms for non-negative matrix factorization. In Advances in Neural Information
Processing Systems 13, p. 556–562.
L IN D. (1998). Automatic retrieval and clustering of similar words. In Proceedings of the 36th Annual Meeting of the
Association for Computational Linguistics and 17th International Conference on Computational Linguistics (COLING-
ACL98), Volume 2, p. 768–774, Montreal, Quebec, Canada.
L UO Z. (2010). Type-theoretical semantics with coercive subtyping. SALT20, Vancouver.
159

B RIDE , C RUYS , A SHER                                     [O-F.1]
M ITCHELL J. & L APATA M. (2008). Vector-based models of semantic composition. proceedings of ACL-08 : HLT, p.
236–244.
M ITCHELL J. & L APATA M. (2010). Composition in distributional models of semantics. Cognitive Science, 34(8),
1388–1429.
N IVRE J., H ALL J. & N ILSSON J. (2006). Maltparser : A data-driven parser-generator for dependency parsing. In
Proceedings of LREC-2006, p. 2216–2219, Genoa, Italy.
PARTEE B. H. (2010). Privative adjectives : subsective plus coercion. BÄUERLE, R. et ZIM-MERMANN, TE, éditeurs :
Presuppositions and Discourse : Essays Offered to Hans Kamp, p. 273–285.
S OCHER R., H UVAL B., M ANNING C. D. & N G A. Y. (2012). Semantic compositionality through recursive matrix-
vector spaces. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing
and Computational Natural Language Learning, p. 1201–1211, Jeju Island, Korea : Association for Computational
Linguistics.
T HATER S., D INU G. & P INKAL M. (2009). Ranking paraphrases in context. In Proceedings of the 2009 Workshop on
Applied Textual Inference, p. 44–47, Suntec, Singapore.
T HATER S., F ÜRSTENAU H. & P INKAL M. (2010). Contextualizing semantic representations using syntactically en-
riched vector models. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, p.
948–957, Uppsala, Sweden.
T URNEY P. & PANTEL P. (2010). From frequency to meaning : Vector space models of semantics. Journal of artificial
intelligence research, 37(1), 141–188.
VAN DE C RUYS T. (2010). A non-negative tensor factorization model for selectional preference induction. Natural
Language Engineering, 16(4), 417–437.
Z ANZOTTO F. M., KORKONTZELOS I., FALLUCCHI F. & M ANANDHAR S. (2010). Estimating linear models for com-
positional distributional semantics. In Proceedings of the 23rd International Conference on Computational Linguistics
(Coling 2010), p. 1263–1271, Beijing, China : Coling 2010 Organizing Committee.
160
