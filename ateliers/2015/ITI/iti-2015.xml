<?xml version="1.0" encoding="UTF-8"?>
<conference>
    <edition>
        <acronyme>ITI'2015</acronyme>
        <titre>Interface TAL IHM</titre>
        <ville>Caen</ville>
        <pays>France</pays>
        <dateDebut>2015-06-22</dateDebut>
        <dateFin>2015-06-22</dateFin>
        <presidents>
            <president>
                <prenom>Fabrice</prenom>
                <nom>Maurel</nom>
            </president>
        </presidents>
        <typeArticles>
            <type id="invite">Invités</type>
            <type id="long">Articles</type>
        </typeArticles>
        <siteWeb>https://art-adn.greyc.fr/</siteWeb>
    </edition>
    <articles>
		<article id="iti-2015-invite-001" session="Invites">
			<auteurs>
				<auteur>
					<prenom>Frédéric</prenom>
					<nom>Landragin</nom>
					<email>frederic.landragin@ens.fr</email>
					<affiliationId>1</affiliationId>
					<affiliationId>2</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">LATTICE, CNRS, ENS</affiliation>
				<affiliation affiliationId="2">Université de Paris 3, 1 rue Maurice Arnoux, 92120 Montrouge</affiliation>
			</affiliations>
            <titre>Dialogue homme-machine : conception et enjeux</titre>
			<type>invite</type>
			<pages>1</pages>
			<resume>Le but de cette présentation est de faire un point sur les théories, les méthodes, les techniques, les enjeux impliqués dans la conception de programmes informatiques capables de comprendre et de produire de la parole. Comment une machine peut-elle parler, comprendre ce qu'on lui dit, et entretenir un dialogue proche du dialogue naturel entre deux humains ? Quelles sont les étapes de conception d'un système de dialogue homme-machine ? Quelles sont les capacités de compréhension, de raisonnement et d'interaction attendues pour de tels systèmes ? Comment les implémenter ? Comment s'approcher du réalisme et de la fluidité du dialogue humain ? Ces questions sont à l'origine de mon parcours, qui a oscillé entre linguistique et informatique, entre recherche fondamentale et développement, entre laboratoires de recherche publics et privés : INRIA, puis THALES, et actuellement CNRS. Le but ici est de mentionner les principaux problèmes posés par chaque étape de conception d'un système de dialogue homme-machine, et de présenter quelques pistes théoriques et techniques pour traiter ces problèmes. Le but est aussi de montrer qu'il existe bien une école française du dialogue homme-machine, caractérisée par sa pluridisciplinarité, par son implication dans différents secteurs, qu'il s'agisse de développement de systèmes, de mise en œuvre de méthodes et de campagnes d'évaluation, de conception d'architectures logicielles, de dialogue multimodal, d'ergonomie, d'agents conversationnels animés, ou encore d'application de techniques d'apprentissage automatique évoluées au dialogue homme-machine. </resume>
			<mots_cles>Dialogue humain-machine, cycle de conception, généricité, multimodalité, génie logiciel.</mots_cles>
			<title>Human-Machine Dialogue: Design and challenges.</title>
			<abstract>The goal of this presentation is to outline the theories, methods, techniques and challenges involved in the design of computer programs that are able to understand and produce speech. How can a machine talk, understand what is said and carry out a conversation close to natural conversation between two human beings? What are the design stages of a human-machine dialogue system? What are the understanding, thinking, and interaction abilities expected from such systems? How should they be implemented? How can we get closer to the realistic and fluid aspect of human dialogue? These questions are at the origin of my path, which oscillated between linguistics and computer science, between pure research and development, between public and private research laboratories: INRIA, then THALES and currently the CNRS. The goal here is to mention the main issues created by each stage of the design of a human-machine dialogue system, and to present a few theoretical and technical paths used to deal with these issues. The goal here is also to show that today there still is a French school of human-machine dialogue, characterized by its multidisciplinary approach, its involvement in different fields, such as system development, implementation of assessment methods and campaigns, software architecture design, multimodal dialogue, ergonomics, embodied conversational agents, and application of up-to-date machine learning techniques.</abstract>
			<keywords>Human-machine dialogue, design cycle, genericity, multimodality, software engineering.</keywords>
		</article>	
		<article id="iti-2015-invite-002" session="Invites">
			<auteurs>
				<auteur>
					<prenom>Jacques</prenom>
					<nom>Labiche</nom>
					<email>jacques.labiche@univ-rouen.fr</email>
					<affiliationId>1</affiliationId>
				</auteur>
			</auteurs>
			<affiliations>
				<affiliation affiliationId="1">Laboratoire LITIS, Université de Rouen </affiliation>
			</affiliations>
			<titre>Couplage structurel : une autre façon d'appréhender les  interactions langagières homme - machine </titre>
			<type>invite</type>
			<pages>2</pages>
			<resume>A partir de la notion de couplage structurel tel que proposé par les biologistes Maturana et Varela, je revisiterai la problématique des interactions entre utilisateur et système informatisé. Le développement d’une plateforme informatique dans le domaine du droit du transport sera évoqué. Les traces langagières déposées volontairement par l’utilisateur lors de ses interactions avec la plateforme feront l’objet d’un questionnement approfondi. </resume>
			<mots_cles>autopoïèse, couplage structurel, interactions homme-machine. </mots_cles>
			<title>Structural coupling: another way of comprehend the linguistic interactions man – machine</title>
			<abstract>From the concept of structural coupling as proposed by biologists Maturana and Varela, I shall question the problem of interaction between an user and computer system. The development of an IT platform in the area of transportation law will be discussed . Linguistic cyber trail submitted voluntarily by the user when interacting with the platform will undergo a thorough questioning. </abstract>
			<keywords>autipoiesis, structural coupling, man machine interactions.</keywords>
		</article>
        <article id="iti-2015-long-001" session="Interprétation">
            <auteurs>
                <auteur>
                    <prenom>Fadila</prenom>
                    <nom>Taleb</nom>
                    <email>fadila.taleb1@univ-rouen.fr</email>
                    <affiliationId>1</affiliationId>
                    <affiliationId>2</affiliationId>
                </auteur>
            </auteurs>
            <affiliations>
                <affiliation affiliationId="1">Laboratoire Dysola EA 4701 ( Dynamiques sociales et langagières), Normandie Université, Université de Rouen </affiliation>
                <affiliation affiliationId="2">Litis EA 4108 (laboratoire d’informatique, de Traitement de l’Information et des Systèmes), Normandie Université, Université de Rouen et INSA de Rouen </affiliation>
            </affiliations>
            <titre>Les modalités linguistiques pour aider à l’interprétation de textes juridiques</titre>
            <type>long</type>
            <pages>3-9</pages>
            <resume>L’un des objectifs majeur que se fixent les concepteurs des bases de données est celui de permettre un
                accès facile et rapide à de multiples documents et informations soit dans un domaine ciblé ou dans des domaines variés.
                Ces ressources numériques doivent aussi prendre en compte et répondre efficacement aux besoins pratiques de leurs futurs
                utilisateurs. Cependant, l’accès aux documents d’un corpus numérique suscite de nombreuses interrogations, notamment
                sur la recherche d’informations. Cette dernière se voit souvent réduite à un réseau restreint de mots-clés, ce qui ne saurait
                satisfaire à tous les besoins des utilisateurs. Nous proposons dans cet article une approche linguistique dans la recherche
                d’informations en intégrant un module d’aide à l’interprétation qui, permettra à l’utilisateur un accès au plein texte, en lui
                proposant des scenarii textuels vu sous l’angle des scenarii modaux susceptibles de le guider vers des passages textuels
                répondant à ses requêtes en fonction de sa pratique en cours.</resume>
            <mots_cles>Scénario modal, sémantique interprétative, traitement de texte, base de données.</mots_cles>
            <title>Study of linguistics Modality to assistant interpretation of legal texts</title>
            <abstract>One of the main objectives set by the designers of databases is to allow an easy and fast access to multiple documents
                and information either in a targeted area or in different areas. These digital resources must also consider and effectively
                address the practical needs of their future users. However, access to documents of a digital corpus raises many questions,
                including research information. The latter sees often reduced to a restricted network of keywords, which does not respond
                in any case the requirements of users. We propose here a linguistic approach in the search for information by integrating
                a help module for interpretation that will allow the user access to the full text by guiding and proposing textual scenarios
                that meet their requests and taking into account its social profile. </abstract>
            <keywords>Modal script, Interpretive Semantic, word processor, database.</keywords>
        </article>
        <article id="iti-2015-long-002" session="Interprétation">
            <auteurs>
                <auteur>
                    <prenom>Jean-Marc</prenom>
                    <nom>Lecarpentier</nom>
                    <email>jean-marc.lecarpentier@unicaen.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
                <auteur>
                    <prenom>Fabrice</prenom>
                    <nom>Maurel</nom>
                    <email>fabrice.maurel@unicaen.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
                <auteur>
                    <prenom>Stéphane</prenom>
                    <nom>Ferrari</nom>
                    <email>stephane.ferrari@unicaen.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
                <auteur>
                    <prenom>Alexandre</prenom>
                    <nom>Beudin</nom>
                    <email>alexandre.beudin@unicaen.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
            </auteurs>
            <affiliations>
                <affiliation affiliationId="1">GREYC, CNRS, Campus Côte de Nacre, Boulevard du Maréchal Juin, 14032 CAEN cedex 5</affiliation>
            </affiliations>
            <titre>Interprétation rapide et non visuelle de pagesWeb : TAL et Tonnerre de mots</titre>
            <type>long</type>
            <pages>10-18</pages>
            <resume>L’accès rapide à un contenu précis dans une page web est généralement réalisé par une étape dite d’écrémage
                (ou skimming) pour avoir une vue globale, suivi d’une stratégie de balayage (ou scanning) pour repérer les informations
                voulues. Ces deux étapes naturelles pour une navigation visuelle n’existent pas dans la cas d’un accès non visuel
                à la page donnée. Nous présentons dans cet article le travail en cours sur le concept de tonnerre de mots (ou tag thunder),
                traduction à l’oral du concept de nuage de mots. Après avoir segmenté une page web en blocs, les mots-clés significatifs
                sont extraits de chaque bloc et pondérés afin d’obtenir un nuage de mots. Parmi ces mots, les mots-clés navigants permettent
                à l’utilisateur de naviguer en profondeur dans les divers blocs de la page. L’ensemble est transformé en tonnerre
                de mots par vocalisation. La présentation de ce travail en cours permet aussi de présenter les diverses pistes de recherche
                envisagées. </resume>
            <mots_cles>accessibilité, oral, tag thunder, nuage de mots, extraction, segmentation.</mots_cles>
            <title>Tag thunder : providing skimming and scanning techniques in non visual situations</title>
            <abstract>Skimming and scanning are two different strategies for speed reading and are used when accessing web pages. Skimming
                is used when we discover a page and it allows a reader to get a first glance of its content. Scanning usually follows, in
                order to get a more precise idea of the content or to find a specific content. However, these techniques are not available in
                non visual situations. This article introduces the concept of tag thunder, which aims to provide speed reading techniques
                similar to skimming and scanning to visually impaired people. A tag thunder is the oral transposition of a tag cloud, where
                keywords are presented with typographic effects depending on the word’s importance.Within a tag thunder, each keyword
                is pronounced differently to enable the user to perceive its importance. Navigation keywords enable the user to select a
                corresponding block. This work in progress is based on three steps. First the web page is segmented to extract its main
                blocks. Then, for each block, keywords are extracted to create tag clouds. Finally, tag clouds are converted to tag thunders
                and presented to the user. Our solution is implemented within a Firefox extension and opens several research tracks.</abstract>
            <keywords>accessibility, tag thunder, tag cloud, extraction, segmentation.</keywords>
        </article>
        <article id="iti-2015-long-003" session="Handicap">
            <auteurs>
                <auteur>
                    <prenom>Juline</prenom>
                    <nom>Le Grand</nom>
                    <email>juline.le-grand@erocca.com</email>
                    <affiliationId>1</affiliationId>
                </auteur>
            </auteurs>
            <affiliations>
                <affiliation affiliationId="1">eROCCA, 196A route du rocher de Lorzier, 38430 MOIRANS</affiliation>
            </affiliations>
            <titre>Interfaces textuelles, une difficulté pour l’utilisateur sourd ? Réflexion et éléments de réponse autour d’une étude de cas</titre>
            <type>long</type>
            <pages>19-31</pages>
            <resume>Avec l’essor des tablettes tactiles et smartphones, les usages des terminaux mobiles ont profondément évolués, révolutionnant de fait la conception des interfaces homme-machine. A travers cet article nous allons détailler les problématiques soulevées en conception d’interfaces majoritairement textuelle lorsque l’utilisateur est sourd. La personne sourde peut présenter des spécificités linguistiques, socio-culturelles ou encore psychologiques et sensorielles qui requièrent une attention particulière quant à la façon de penser l’interface. Pour le projet Rapsodie, dont l’objectif est de fournir un outil de communication améliorée et alternative dédié aux sourds, nous avons été amenés à réfléchir à la manière de concevoir notre interface centrée sur cet utilisateur atypique. Par notre approche, nous avons cherché à déterminer lesquelles de ses « spécificités » requièrent une prise en compte en conception, en particulier la notion de l’écrit qui, bien que prépondérante de manière générale dans les interfaces, pose un problème important pour certains sourds. Nous proposerons des solutions possibles et exposerons leurs limites, souvent liées à des verrous technologiques. </resume>
            <mots_cles>Surdité, reconnaissance automatique de la parole, synthèse vocale, Communication Améliorée et Alternative, Interface Homme Machine.</mots_cles>
            <title>Textual interface, a difficulty for deaf user? Reflection and elements of response around a case study</title>
            <abstract>With the rise of tablets and smartphones, usage of mobile devices has profoundly evolved, revolutionizing at once the design of human-machine interfaces. Through this article we will detail the issues raised in the design of mainly textual interfaces when the user is deaf. Indeed, the deaf person may have linguistic, socio-cultural, or psychological and sensorial specificities requiring special attention as to how to think the man-machine interface. As part of the Rapsodie project, which aims to provide an improved and alternative communication tool dedicated to the deaf, we have been led to think about how to design our interface centered on an atypical user. With our approach, we sought to determine which of its "specificities" require consideration, in particular the notion of writing which, although generally predominant in interfaces, poses a problem for some deaf. We will propose possible solutions and describe their limitations, mostly related to technological barriers.</abstract>
            <keywords>Deafness, Automatic Speech Recognition, Text To Speech, Augmentative and Alternative Communication, User Interface.</keywords>
        </article>
        <article id="iti-2015-long-004" session="Handicap">
            <auteurs>
                <auteur>
                    <prenom>Waseem</prenom>
                    <nom>Safi</nom>
                    <email>waseem.safi@unicaen.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
                <auteur>
                    <prenom>Fabrice</prenom>
                    <nom>Maurel</nom>
                    <email>fabrice.maurel@unicaen.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
                <auteur>
                    <prenom>Jean-Marc</prenom>
                    <nom>Routoure</nom>
                    <email>jean-marc.routoure@unicaen.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
                <auteur>
                    <prenom>Pierre</prenom>
                    <nom>Beust</nom>
                    <email>pierre.beust@unicaen.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
            </auteurs>
            <affiliations>
                <affiliation affiliationId="1">GREYC, CNRS, Campus Côte de Nacre, Boulevard du Maréchal Juin, 14032 CAEN cedex 5</affiliation>
            </affiliations>
            <titre>Navigation Aveugle des Pages Web sur Dispositifs Mobiles</titre>
            <type>long</type>
            <pages>32-43</pages>
            <resume>De nombreuses techniques spécialisés aux personnes déficientes visuelles ont réussi à extraire les informations affichées sur des écrans numériques et ont réussi à transformer ces informations d'une manière linéaire, soit dans un format écrit sur des dispositifs spéciaux en Braille ou en une sortie vocale. Toutefois, les lecteurs d'écran ne transforment pas la structure 2-dimensionnel de la page web navigué. Dans cet article, nous proposons une nouvelle technique vise à renforcer la capacité des personnes déficientes visuelles à naviguer le Web en se concentrant sur l'amélioration de l'accès vibrotactile non-visuel des pages web sur dispositifs mobiles, basée sur l'extraction et la réorganisation de la structure de textes et les éléments graphiques des pages web, et de conversion automatique de ces structures visuelles et des informations textuelles dans des pages vibrantes utilisant un langage vibro-tactile graphique.</resume>
            <mots_cles>Touch-Screen devices, Document Object Model, Visually Impaired People, first glance, vibro-tactile.</mots_cles>
            <title>Blind Navigation of Web Pages on Touch-Screen Devices</title>
            <abstract>Nowadays, Touch-Screen devices are being used more and more, especially for web navigation. But the small screen size of these devices requires adapting web page contents to be browsed more conveniently. A fundamental step in a successful automatic adaptation process of a web page is perception its visual layout and mining its Document Object Model (DOM) structure. Considering that navigating the Web is one of important missions in the field of computer accessibility. Many specialized techniques for VIP (Visually Impaired People) succeeded to extract the information displayed on digital screens and succeeded to transform this information in a linear way either into a written format on special Braille devices, or into a vocal output using text to speech synthesizers. However, although this success, screen readers failed to transform the 2-dimentional structure of the navigated web page; despite many researches confirm that perception the structure enhances web navigation and memorization. In this paper, we propose a new technique aimed to enhance the VIP ability to navigate the Web by affording a “first glance” web page overview. This technique focuses on improving non-visual vibrotactile access to web pages on touch-screen devices, based on extraction and re-organization the structure of texts and graphical elements for web pages, reformatting and converting automatically these visual structures and textual information into vibrating pages using a graphical vibro-tactile language. We present also a new web-adapted supervised segmentation algorithm dedicated to vibro-tactile access on touch-screen devices. This suggested algorithm is fundamental in our framework. A comparison between automatic and manual segmented pages is presented. The objectives of this comparison are, on the one hand, to know how users understand web page layout structure based on their visual perception, and on the other hand, to explore the main differences between automatic and manual segmentation.</abstract>
            <keywords>Touch-Screen devices, Document Object Model, Visually Impaired People, first glance, vibro-tactile.</keywords>
        </article>
        <article id="iti-2015-long-005" session="Handicap">
            <auteurs>
                <auteur>
                    <prenom>Philippe</prenom>
                    <nom>Boissière</nom>
                    <email>philippe.boissiere@irit.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
                <auteur>
                    <prenom>Nadine</prenom>
                    <nom>Vigouroux</nom>
                    <email>nadine.vigouroux@irit.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
                <auteur>
                    <prenom>Mustapha</prenom>
                    <nom>Mojahid</nom>
                    <email>mustapha.mojahid@irit.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
                <auteur>
                    <prenom>Damien</prenom>
                    <nom>Sauzin</nom>
                    <email>damien.sauzin@irit.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
                <auteur>
                    <prenom>Frédéric</prenom>
                    <nom>Vella</nom>
                    <email>frederic.vella@irit.fr</email>
                    <affiliationId>1</affiliationId>
                </auteur>
            </auteurs>
            <affiliations>
                <affiliation affiliationId="1">CNRS, IRIT - Université Toulouse 3 Paul Sabatier, 118 Route de Narbonne, F-31062 TOULOUSE CEDEX 9</affiliation>
            </affiliations>
            <titre>TALN et IHM : une approche transdisciplinaire pour la saisie de textes de personnes en situation de handicaps</titre>
            <type>long</type>
            <pages>44-54</pages>
            <resume>Ce papier vise d’une part, à présenter une synthèse des méthodes d’optimisation pluridisciplinaires alliant le traitement automatique de la langue naturelle et celui l’interaction homme-machine et d’autre part à soulever les nouveaux verrous scientifiques posés par l’arrivée des nouvelles technologies et des nouveaux modes d’écriture pour la saisie de textes. Cette synthèse abordera les principes d’optimisation des agencements spatiaux des claviers virtuels et ceux de la prédiction de caractères et/ou des mots à afficher en tenant compte des nouveaux supports d’interaction et des nouvelles technologies.</resume>
            <mots_cles>Agencement spatial, techniques d'interaction, système de prédiction, liste de présentation</mots_cles>
            <title>NLP and HCI : a transdisciplinary approach for text input by users with disabilities</title>
            <abstract>This paper aims to present, firstly a synthesis of multidisciplinary optimization methods combining automatic processing of natural language and the human computer interaction and secondly to discuss new scientific challenges raised by new technologies and new modes of writing for text input. This summary will address the principles of optimization of virtual keyboard layout and those of characters and word prediction towards the new technologies (device and interaction technique).</abstract>
            <keywords>Layout, interaction technique, prediction system, presentation list</keywords>
        </article>
    </articles>
</conference>