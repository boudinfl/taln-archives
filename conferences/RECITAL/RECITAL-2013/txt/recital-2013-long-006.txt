
_ l_)év_elop eme_nt de ressources pour l’entra’1‘nement et
l’ut1l1sat1on e l’ét1queteur Ilnorqbosyntaxlque TreeTagger sur
ara e

Dhaou Ghoull
(1) STIH, 1, rue Victor Cousin 75005 Paris
Dhaou . Ghoul @gmail . com

RESUME

Dans cet article, nous présentons les étapes du développement de ressources pour
l'entrainement et l'utilisation d'un nouvel outil de l'étiquetage morphosyntaxique de la
langue arabe. Nous avons mis en oeuvre un systeme basé sur l'étiqueteur stochastique
77‘eeTagger, réputé pour son efﬁcacité et la généricité de son architecture. Pour ce faire, nous
avons commencé par la constitution de notre corpus de travail. Celui-ci nous a d'abord servi
a réaliser l'étape de segmentation lexicale. Dans un second temps, ce corpus a permis
d'effectuer l'entrainement de TreeTagger, grace a un premier étiquetage réalisé avec
l'étiqueteur ASVM 1.0, suivi d'une phase de correction manuelle. Nous détaillons ainsi les
prétraitements requis, et les différentes étapes de la phase d'apprentissage avec cet outil.
Nous terminons par une évaluation sommaire des résultats, a la fois qualitative et
quantitative. Cette évaluation, bien que réalisée sur un corpus de test de taille modeste,
montre que nos premiers résultats sont encourageants.

ABSTRACT

Development of resources for training and the use of the tagger 'I‘reeTagger an Arabic

In this paper, we present the steps of the development of resources for training and the use
of a new tool for the part-of-speech tagging of Arabic. We implemented a tagging system
based on Tree Tagger, a generic stochastic tagging tool, very popular for its efﬁciency. First of
all, we began by gathering a working corpus, large enough to ensure a general linguistic
coverage. This corpus has been used to implement the tokenization process, as well as to
train TreeTagger. We ﬁrst present our method of tokenization, then we describe all the steps
of the preprocessing and training process, using ASVM 1.0 to yield a raw POS tagging that
was subsequently manually corrected. Finally, we implemented a straightforward evaluation
of the outputs, both in a quantitative and qualitative way, on a small test corpus. Though
restricted, this evaluation showed really encouraging results.

MOTS-CLES: TALN, langue arabe, corpus d'apprentissage, étiquetage morphosyntaxique,
segmentation de l'arabe, arbre de décision, lexique, jeux d’étiquette, TreeTagger, ASVM 1.0.
KEYWORDS: NLP, Arabic language, training corpus, POS tagging, tokenization, decision tree,
lexicon, tagsets, TreeTagger, ASVM1.0.
1 Introduction

De nos jours, la langue arabe est de plus en plus utilisée sur le Web. On peut y trouver de
nombreux ouvrages que les auteurs ont décidé de rendre publics. Par ailleurs, il existe de
nombreux logiciels traitant la langue naturelle qui facilitent la recherche et la consultation
des documents électroniques. La réalisation de nouvelles applications en traitement
automatique de la langue (TAL) pour l'arabe nécessite en premier lieu de développer un
systéme d’étiquetage performant et robuste.

L'étiquetage morphosyntaxique d'une langue est un processus qui consiste a ajouter aux
mots des informations morphologiques concernant leurs catégories morphosyntaxiques ou
parties du discours - cette opération étant parfois accompagnée d'une lemmatisation lorsque
les formes ﬂéchies sont ramenées a leur forme canonique (lemme). Selon (Laporte , 2000) :
« l'analyse morpliosyntazdque est 1’ensen1b1e des techniques qui concourent a passer d ’un
teXte brut; exempt d’inf0rn1at7'0ns Iinguistique, a une se’quence des nzots e’tiquete’s par des
informations Iinguistiques ». Pour la langue arabe, l'étiquetage reste toujours une étape
complexe a aborder a cause des ambiguités lexicales des unités. L'étiquetage d'une langue
donnée est principalement basé sur deux types d'approche : étiquetage a base de regles et
étiquetage statistique basé sur des corpus. L'outil TreeTagger que nous avons utilisé dans
notre travail concerne cette derniere catégorie de systeme, et a recours a des modeles
probabilistes (modeles de chaine de Markov cachées HMM et arbres de décision).

7reeTagger a déja été mis en oeuvre sur plusieurs langues (anglais, francais, allemand,
italien, néerlandais, espagnol, bulgare, russe, grec, portugais, chinois, swahili), mais pas sur
l'arabe a notre connaissance. L'objectif de ce travail est d’adapter TreeTagger a la langue
arabe afin de disposer d'un systeme d’étiquetage morphosyntaxique générique et gratuit.

Cet article est organisé comme suit: la section 2 présente quelques étiqueteurs existants en
arabe, la section 3 décrit le principe de segmentation de notre systeme ainsi que les données
utilisées, la section 4 présente le processus de l'étiquetage en se basant sur TreeTagger. Les
résultats obtenus et les perspectives de ce travail feront l'objet de la section 5.

2 Etat de l'art

Reconnaitre la catégorie morphosyntaxique d'un mot dans un contexte est une tache non
triviale du traitement automatique de la langue écrite. En effet rendre une machine capable
d'identiﬁer la catégorie d'un mot exige de mettre en oeuvre des méthodes sophistiquées, en
particulier pour les mots ambigus, c'est-a-dire susceptibles d'appartenir a plusieurs
catégories différentes. Les systemes automatiques dédiés a cette tache sont appelés des
étiqueteurs morphosyntaxiques (part-of-speech tagger, en anglais). Au contraire de langues
comme l'anglais ou le francais, l'analyse morphosyntaxique de l'arabe est une étape
particulierement difficile a cause d'importantes ambiguités graphiques et de la présence
d'agglutinations. De nombreux travaux ont été effectués dans ce domaine en se basant sur

des approches différentes. Nous en mentionnons ici quelques uns :

Aramorph est un analyseur distribué par le Linguistic Data Consortium (LDC), qui permet de
segmenter les mots en trois parties (préﬁxe racine sufﬁxe). Il utilise un lexique et des regles
orthographiques sont encodées directement dans le lexique, spéciﬁées en termes de regles
générales qui interagissent pour réaliser la sortie. Ce systeme est réalisé a partir d'une base
de données qui contient 598 préﬁxes, 906 suffixes et 78 839 racines (Buckwalter, 2002).
Cette base est complétée par trois tables de comptabilité utilisées pour faire la combinaison
entre préﬁxe et racine (2 435 entrées), sufﬁxe et racine (1 612 entrées) et préﬁxe et sufﬁxe
(1 138 entrées). L’algorithme d’analyse est assez simple puisque toutes les décisions
difﬁciles sont codées directement dans le lexique et les tableaux de compatibilités, c'est-a-
dire que le lexique contient toutes les segmentations possibles des mots sous la forme
« préﬁxe racine sufﬁxe » (N.Habash, 2004). Cependant, pour la forme agglutinée d’un mot,
les segmentations ne sont valables que si les différents composants existent dans le lexique.

Les points faibles de cet analyseur se résument ainsi (M.Attia, 2006) : tous les lemmes sont
listés manuellement et tous les lexemes des formes ﬂéchies associées sont énumérés, ce qui
ﬁnit par augmenter le coﬁt de maintenance du lexique ; il y a un probleme au niveau du
traitement des proclitiques interrogatifs qui se localisent au début des verbes et des noms
(exemples : « dﬁﬁ », <<A-«ml ») ; seulement 22 verbes sur un total de 9 198, soit 0,002 % ont
des formes impératives ; seulement 1 404 verbes sur un total de 9 198, soit 15 % sont
conjugués a la voix passive au présent et 110 verbes au passé.

(Diab, Hacioglu et Iurafsky, 2004) ont développé un analyseur syntaxique baptisé ASVM 1.0.
Ils ont entrainé leurs modeles d'étiquetage sur le corpus arabe annoté TreeBank en se basant
sur 24 étiquettes et en utilisant l'outil « Yamcha » qui utilise les machines a vecteurs de
support Le corpus TreeBank utilisé pour évaluer la premiere version d'ASVM est composé
de 4 519 phrases. Le corpus est distribué comme suit : 4 000 phrases pour l'apprentissage,
119 phrases pour le développement et 400 phrases pour le test. Les résultats obtenus sont
de 95,49 % de mots correctement étiquetés. Nous avons analysé les résultats de cet
étiqueteur (nous les avons utilisés pour notre application), et nous avons remarqué que la
majorité des erreurs sont liées a la mauvaise segmentation de l'article « Al » et a la confusion
des noms avec les adjectifs et inversement. L’évaluation de la segmentation (tokens bien
segmentées) de cet étiqueteur sur notre corpus a donné un taux tres faible de segmentation
correcte (46 %).

(Diab, 2009) a réalisé une deuxieme version améliorée de cet étiqueteur. L'amélioration se
résume dans la phase de segmentation concernant les mots composés (par exemple la
séparation de l'article «Al (d|)» et la préposition «b (9) »). Les résultats obtenus de la
nouvelle version sur les mémes données d’ASVM1.0 sont plus performants au niveau de la
segmentation (99,2 %), et avec une précision de plus de 96 % au niveau de l'étiquetage.

(Bahou, Hadrich Belguith, Ben Hamadou, 2005) ont présenté l'analyseur syntaxique
SYNTAXE qui modélise des textes arabes non voyellés (non vocalisés) en se basant sur une
grammaire HPSG (Head-driven P11ra5e Structure Grammar) et un lexique sous forme XML.
Cet analyseur repose sur trois principales étapes. La premiere étape permet la génération
des matrices attribut/valeur HPSG nécessaires pour l'identiﬁcation des structures
syntaxiques des phrases en cours d’analyse. La deuxieme et la troisieme étape représentent
les étapes de l’algorithme « Chart Parsing HPSG » (Popowich, Vogel, 1990). L’évaluation de
cet analyseur a été faite sur un corpus de textes tirés d’un manuel de la 8e année de base de
l’enseignement tunisien. Ce corpus, saisi au sein du laboratoire LARIS, contient 650 phrases
non voyellées (soit 4050 mots). Parmi ces phrases, 96 contiennent des mots non reconnus
par l'analyseur et ont été analysé partiellement Sur un total de 554 phrases, SYNTAXE est
parvenu a analyser correctement 448 phrases (2820 mots) soit 81 %.

MorphArab est un analyseur morphosyntaxique de la langue arabe développé par (Abbes,
2004). D'abord, cet analyseur découpe le mot en pré-base, racine et post-base. Ensuite, il
utilise le lexique Dinar (Dictionnaire Informatisé de l'Arabe)1 pour l’attribution de chaque
composant du mot et l'extraction des traits morphosyntaxique correspondants. Ce lexique
est composé de 19 457 verbes, 70 702 déverbaux (substantif verbaux « J4-I43», participes
actifs et passifs « dam‘; «Lu-I’:J| gm) », adjectifs et noms de temps et de lieu), 39 099 noms, 445
mots outils et 1 384 noms propres (Anizi, Dichy, 2009). Il identiﬁe en outre les traits
morphosyntaxiques des mots. (Abbes, 2004) a trouvé que le moins ambigu des marqueurs
est la racine. L'ajout de nouveaux traits augmente la discrimination dans l'analyse et offre
plus de solutions.

La société XEROX a également développé un étiqueteur. La phase de segmentation pour cet
analyseur est faite par un transducteur a états ﬁnis (Farghaly, Dichy, 2003) en découpant la
chaine d'entrée en unités lexicales qui correspondent a une forme ﬂéchie ou une
ponctuation, et en donnant a chaque segment des étiquettes qui représentent le
comportement morphologique des unités lexicales et leurs catégories. Cet étiqueteur
regroupe 4 930 racines et 400 modeles qui permettent de produire 90 000 lexemes. Il utilise
des regles a large couverture, par contre il génere un taux assez élevé d'ambigu'1'tés lexicales,
et ne traite pas bien la phase de désambiguisation.

TAGGAR est un analyseur morphosyntaxique spécialement développé pour la synthese
vocale arabe des textes voyellés. Il prend en considération l'ordre de traitement des mots
pour minimiser les erreurs d’étiquetage. Le traitement se fait dans l'ordre suivant : analyse
des mots outils et des mots spéciﬁques, analyse des formes verbales et enfin, analyse des
formes nominales. Cet analyseur utilise 35 étiquettes grammaticales qui se répartissent en
trois grandes familles de catégories : 4 étiquettes pour les particules, 16 étiquettes pour les
verbes, et 15 étiquettes pour les noms.

L’évaluation a été faite sur un corpus de 5 563 mots ; TAGGAR a obtenu un taux d'erreur de 2
% sur les étiquettes ce qui a entrainé seulement 1 % d'erreurs sur les frontieres de groupes
syntaxiques. Pres de 98 % des pauses insérées automatiquement sont correctement placées
(Zemirli, Khabet, 2004).

MORPH2 est un analyseur morphologique basé sur un lexique réduit sous forme XML qui
contient 5 754 racines trilitteres et quadrilitteres (Chaabaen Kammoun, Hadrich Belguith,
Ben Hamadou, 2010) qui correspond a des schémas verbaux et nominaux et un ensemble de
regles linguistiques. L’évaluation de cet analyseur a été faite sur un corpus non voyellé qui
contient environ 51 404 mots (23 121 différents). Les résultats obtenus en termes de rappel
et de précision sont respectivement de 89,77 % et 82,51 %. Cet analyseur prend en entrée un
texte en arabe ou une phrase ou un mot pour fournir en sortie toutes les caractéristiques
morphosyntaxiques possibles pour chaque mot sans prendre en compte le contexte dans
lequel il se présente.

3 Segmentation et données utilisées
Le probleme de la segmentation ne se pose pas de la méme maniere pour toutes les langues.

Pour les langues comme l'anglais ou le frangais, les unités lexicales (tokens) sont dans la
plupart des cas reconnaissables par une simple analyse graphique en s’appuyant sur les

1 http://diinar.univlyon2.fr
caracteres séparateurs (espaces, ponctuations, apostrophe, etc.) présents dans les textes.

L'arabe, quant a lui, est en principe monosyllabique, ce qui signifie que chaque syllabe peut
étre une unité lexicale. Il est possible de former des mots complexes a partir de plusieurs
syllabes, ce qui rend difﬁcile le probleme de segmentation. La majorité des travaux de
segmentation se basent sur des regles qui s'appuient sur des listes de clitiques, préﬁxes,
sufﬁxes et racines (Mars, Zrigui, Belgacem, Zouaghi, Antoniadis, 2008). Ces regles s'appuient
sur les principes de constitution d’un mot complexe et son contexte dans la phrase. C'est
pourquoi il est difﬁcile d’identiﬁer la racine (unité lexicale) pour les mots qui contiennent
des ﬂexions (exemple : les terminaisons des verbes conjugués).

Au cours de notre recherche, nous avons essayé d'élaborer un algorithme de segmentation
en nous basant sur des regles qui traitent dans la majorité des cas la forme correcte d’un mot
en arabe. Le succes de notre méthode repose essentiellement sur un grand corpus de mots
non voyellés segmentés manuellement. Notre algorithme de segmentation est composé de
trois modules organisés de maniere séquentielle. D'abord, on effectue une segmentation
grossiere au niveau des espaces et des signes de ponctuations. Ensuite, on examine les
tokens? ainsi obtenus, et on les compare avec les formes déja segmentées d’un corpus traité
de facon semi-automatique (cf section suivante pour une description du corpus). La
segmentation est considérée valide si le token est trouvé dans le corpus. Sinon (c.-al-d. si le
token est absent du corpus), on recherche, grace a une expression réguliere qui représente la
forme complete d’un mot arabe (pré-bases racine post-bases), les éventuelles pré-bases et
post-bases attachées a la racine. Cette expression est construite a partir de listes déﬁnies a
l'avance. Pour chaque pré-base ou post-base identiﬁée, nous vériﬁons le statut de la partie
restante du mot découpé. Avec cette méthode, nous avons noté qu'il reste des ambigu'1'tés de
découpage pour certains mots qui peuvent se découper de plusieurs facons différentes. Le
Erreur! Source du renvoi introuvable.Tableau 1 représente les trois différentes

segmentations du mot arabe (,4-A-ll) en fonction de son contexte dans la phrase :

Segmentation Traducﬁon en francais
‘ah +,a.\ + I les a-t-ilramassés ?
‘:3 +,a.\l leurs douleurs

NJ: +dl l'important

TABLE 1 — Les différents découpages du mot as-All

Ce probleme reste difﬁcile a résoudre puisque le découpage de ces types de mots dépend
obligatoirement du contexte et de sa position dans la phrase. La résolution des cas
d'ambigu'1'té au niveau du découpage reste une tache non triviale. La qualité de la
segmentation dépend de la taille du corpus qui est censé couvrir les mots les plus fréquents
en arabe avec leur segmentation correcte.

2 Ensembles des unités morphosyntaxiques minimales (mot, une partie de mot, clii1'que...).
4- Adaptation de 77'eeTaggerpour l'arabe

4.1 Principe de 77'eeTagez:

77‘eeTagger est un outil permettant l'étiquetage morphosyntaxique et la lemmatisation. II a
été développé par Helmut Schmid3 (1994) dans le cadre du projet TC4. II a été utilisé avec
succes pour de nombreuses langues (anglais, frangais, allemand, italien, néerlandais,
espagnol, bulgare, russe, grec, portugais, chinois, swahili). Il est adaptable sur toutes les
langues en utilisant un lexique et un corpus d’apprentissage manuellement étiquetés. Pour la
langue frangaise, (Stein, 2007) a entrainé cet analyseur sur un corpus d’apprentissage
contenant 2 685 146 mots et l'a évalué en utilisant un corpus contenant 500 000 mots. Il
rapporte un taux de précision de 92,7 % pour l'étiquetage et 97,8 % pour la lemmatisation.
77‘eeTaggerpeut en effet présenter la lemmatisation des mots en plus des étiquettes.

4.1.1 Apprentissage

En général, la phase d’apprentissage des modeles d'étiquetage pour une langue donnée
nécessite un corpus d’apprentissage, un lexique de formes ﬂéchies et la liste des étiquettes
les plus utilisées pour identiﬁer la catégorie des mots absents du corpus d’apprentissage
(classe ouverte). TreeTagger utilise des arbres de décision pour l'estimation des
parametres. L’apprentissage effectué par cet outil permet d’évaluer la probabilité d’une
transition entre un couple « mot/catégorie» et un autre couple aﬁn de produire un arbre de
décision binaire a partir de ces probabilités.

4.1.2 Lexique

En général, l'analyse morphosyntaxique repose sur un lexique contenant les informations
sur l’usage grammatical de chaque unité lexicale. Ces informations varient d’un lexique a
l'autre. Le lexique joue un role important pour l'identiﬁcation des catégories et du lemme de
chaque mot en entrée. Nous avons construit un lexique assez vaste en utilisant la liste de
mots proposés par (Buckwalter, 2002) qui était utilisée pour la réalisation de l'étiqueteur
AraM01p11. Nous avons nettoyé cette liste contenant 82 158 racines représentant 38 600
lemmes. Ce nettoyage consiste a éliminer la redondance des mots sur des lignes différentes
pour obtenir une forme adaptée a TreeTagger. Nous avons ajouté les listes de pré-bases et
post-bases a l’entéte de notre lexique pour le compléter.

Notons bien que le lexique ne contient pas de chiffres. Par ailleurs, il nous a été difﬁcile de
générer automatiquement les lemmes des entrées de notre lexique. Nous avons gardé, pour
la plupart des cas, la forme voyellée du mot, et nous avons ignoré les lemmes des pré-bases
et post-bases ajoutés manuellement.

4.1.3 Ieux d'étiquettes

Pour gagner de temps, nous avons décidé de prendre le jeu des étiquetes proposés par (Diab,
Hacioglu & ]urafsky, 2004) car nous avons utilisé au début ASVM 1.0 pour la préparation de
notre corpus de travail, malgré que dont tres réduits au niveau de leur nombre en ajoutant
une étiquette qui désigne la fin de phrase (étiquette spéciﬁque pour TreeTagger). Ces jeux
des étiquettes contiennent 23 étiquettes qui permettent d'identiﬁer les principaux tokens en

3 http://www.ims.uni-stuttgart.de/~schmid/
4 http://www.ims.uni-stuttgart.de/projek‘oe/tc/
arabes. Le tableau suivant donne une idée précise sur ces étiquettes :

Tag Explication Tag Explication Tag Explication
I] Adjective NNP Nom propre PRP$ Pronom
possessive
RB Adverbe NNPS Nom propre pluriel CD nombre

CC Coordination VBP Verbe a l’imparfait IN Subordination

DT Déterminant VBN Verbe passive UH Interjection
FW Mot étranger VBD Verbe parfait PREP Préposition
NN Nom singulier RP Particule WP Pronom relatif
NNS Nom pluriel PRP Pronom personnel WRB Wh-adverbe

PUNC Ponctuation SENT Le point de ﬁn de
phrase

TABLE 2 — Listes des étiquettes (Tag).

4.2 Etiquetage

Préalablement le texte a analyser doit étre translittéré avec le codage de Buckwalter et
tokenizé avec notre script de segmentation. TreeTagger a beaucoup de points communs avec
les étiqueteurs « n-grammes ». Dans ce type d'approche, on modélise la probabilité d’une
séquence de mots en fonction des étiquettes des mots précédents/suivants en se basant sur
l'équation suivante :

P(w1w2 ...wn,t1t2  tn) = P(tn|t _2t _1)P(wn|tn)P(w1w2 ...wn_1,t1t2tn_1) (1)
Oil w.- représente un mot et ti représente une étiquette.

Ala différence d’un étiqueteur « n-gramme », TreeTagger estime la probabilité de transition
a partir d’un arbre de décision binaire généré pendant la phase d'apprentissage. Les noeuds
de l'arbre représentent des indices contextuels, et la probabilité d’un trigramme est
déterminée par le chemin (de longueur variable) correspondant a travers l'arbre. Par
exemple, considérons la séquence trigramme des mots qui ont les étiquettes suivantes « DT
]/ NN » (avec DT: déterminant, ]]: adjectif et NN: nom). Pour estimer P(NN/DT, ]]), la
probabilité d’un nom précédé par un déterminant et un adjectif, on suit le chemin valide en
commengant de la racine qui contient l'étiquette //jusqu'a la feuille qui contient l’étiquette
NN, enpassantpar Tag-2=D7Z et l'on retient la probabilité P=0,8.
NN : 0.8

JJ : 0.1

FIGURE 1 — Exemple d'arbre de décision binaire.

Par défaut, pour un texte en arabe segmenté, 77‘eeTagger donne une liste de tous les mots
avec leurs catégories et leur lemme s'il existe. Un paramétrage de TreeTagger permet soit
d'attribuer le lemme « unknown » a toutes les formes inconnues, soit de donner la forme
elle-méme sans lemmatisation. Ici, la phase de segmentation est effectuée par notre propre
script et non par les tokenizers génériques de TreeTagger. En résumé, ce processus
d'étiquetage nécessite un enchainement de plusieurs phases, comme le montre la figure

suivante :

I
L

Corpus
d’apprentissage
Li

{I
pp

Lexique
L;

{I
pp

Classe ouverte
Apprentissage
L p

L _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ __

I ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' " \

n . Modele

Et1 ueta e
E 41?; d'étiquetage
I
. T t
Texte I Segmentation ex 6 ,

I segmente

I

I

L _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ __;

FIGURE 2 — Les différents processus d'étiquetage.

76
© ATALA

5 Evaluation

5.1 Corpus de travail

Malgré les différentes recherches effectuées sur le traitement automatique de la langue
arabe, il nous a été difﬁcile de trouver des ressources toutes faites. C'est pourquoi, nous
avons décidé de constituer notre propre corpus de travail. Pour avoir un vocabulaire
sufﬁsamment étendu, nous avons utilisé le corpus EASC proposé par (El-Haj , Kruschwitz,
Fox., 2010 ) qui comporte 153 articles répartis sur une dizaine de domaines différents. Notre
corpus contient 58 233 mots (21 238 mots différents) repartis sur 2 238 phrases. Comme on
l'a dit précédemment, le principe de notre segmentation dépend essentiellement de la
comparaison de chaque mot avec les mots pré-segmentés de notre corpus de référence. Pour
réaliser cette tﬁche de pré-segmentation, nous avons suivi les étapes suivantes:

o D'abord, pour éviter tous les problemes de codage de la langue arabe, et pour
faciliter le traitement automatique, nous avons translittéré nos textes selon la table
de Buckwalter5. Cette translittération, souvent appliquée en TAL, présente l'intérét
de n’utiliser que des caracteres ASCII et d’étre totalement réversible (c'est-?a-dire
qu'il est aisé de retrouver le texte original en appliquant la translittération inverse).

o Ensuite, nous avons appliqué l'étiqueteur ASVM 1.0 (étiqueteur gratuit et n’est pas
le cas pour ASVM 2.0) réalisé par (Diab, Hacioglu, Iurafsky, 2004) aﬁn d'obtenir une
premiere segmentation selon cet étiqueteur. Comme cet étiqueteur fait beaucoup
d'erreurs (segmentation et étiquetage) :31 ce niveau, il a été nécessaire d'en corriger
manuellement les sorties. Nous avons corrigé les 400 premieres phrases (soit
environ 13 000 mots), en définissant, pour chaque correction, des transformations
sous forme d'eXpressions régulieres, que nous avons appliquées :31 l'ensemble du
corpus. A l’issue de ces corrections, la présence de mots mal segmentés ou mal
étiquetés devenait de plus en plus rare (pour donner une estimation; apres la
correction de 400 phrases, une erreur apparait tous les 200 :31 300 mots). Notons
bien que, avant la phase de correction et selon la sortie qu'on a obtenue, le taux
d'erreur est assez élevé (une erreur apparait :31-peu-pres tous les 50 mots).

o Enﬁn pour compléter notre corpus nous avons ajouté la liste de pré-bases et post-
bases les plus utilisées en arabe, donnée par (Abbes, 2004).

5.2 Corpus d'apprentissage et d'évaluation

Pour créer les corpus d'apprentissage et d'évaluation, nous avons pris le corpus de travail
déja utilisé pour la segmentation et nous en avons extrait 234 phrases pour constituer le
corpus de test, le reste étant réservé au corpus d'apprentissage. Le tableau 3 illustre la taille
des corpus utilisés. Le corpus d'apprentissage contient 52 171 mots non segmentés dont
19 086 mots différents regroupés dans 2 096 phrases. Notons que l'ensemble des mots du
corpus est non voyellé. La distribution des 23 étiquettes en question dans le corpus
d'apprentissage donne une valeur minimale pour l'étiquette « FW (mot étranger)» (192 fois)
et une valeur maximale pour l'étiquette « DT (déterminant) » (11 264 fois) sur une totalité
de 78 650 mots étiquetés.

5 http://www.qamus.org/transliberation.htm
Nb. mots Nb. mots Nb mots
Corpus Nb. phrases différents non- Se ' entés
segmentés gm
Apprentissage 2 096 19 086 52 171 78 650
Test 234 3 407 6 029 9 560

TABLE 3 — Statistiques de distribution du corpus pour l'apprentissage et le test.
5.3 Evaluaﬁon quantitative

Le corpus de test est constitué d'articles concernant la thématique de l’art. Pour mettre en
oeuvre l'évaluation, nous avons besoin de réaliser un étiquetage de référence qui contient les
phrases de test bien segmentées et avec des étiquettes vériﬁées manuellement

Nous nous sommes limités au probléme de l'évaluation de la précision de l'étiquetage réalisé
par TreeTagger, c'est-a-dire le taux d'étiquetage correct Cependant, il faut étre conscient que
ce seul taux ne signiﬁe que peu de chose dans la comparaison entre les systémes, car la
précision de chaque systéme dépend du mode de segmentation et du jeu d’étiquettes utilisés,
ainsi que des données de test utilisées.

Une démarche d'évaluation simple consiste :31 comparer le résultat de notre étiqueteur avec
le corpus de référence. Pour faire cette comparaison, nous avons décidé d'utiliser .S‘c11'te5, un
outil générique pour l'évaluation des étiqueteurs morphosyntaxiques. Ce logiciel nous a
permis de faire l'alignement entre le texte étiqueté et la référence, les segmentations
pouvant étre différentes.

Pour l'évaluation d'un systéme d'étiquetage, on peut considérer les éléments suivants :

o Une évaluation des types d’ambigu'1'té pour apprécier la difﬁculté de l'étiquetage : le
nombre moyen d’étiquettes possibles :31 assigner :31 chaque mot, et les types (ou
classes) d'ambigui'té, en précisant notamment la fréquence relative dans le corpus
test de chacune de ces classes.

a Une évaluation des types d'erreurs : les types d'ambigu'1'té conduisant le plus
fréquemment :31 des erreurs d'étiquetage, ainsi qu'au mauvais découpage des mots.

o Une évaluation quantitative de la précision de l’étiquetage.

Par ailleurs, nous avons comparé les résultats obtenus avec ceux d'ASVM1.0 (également
appelé AMIRA1.0), pris comme baseline. Les deux mesures communément utilisées pour
évaluer un systéme d'étiquetage sont le taux de précision P et celui du rappel R. Tous les
mots étant étiquetés, nous avons limité l'évaluation au calcul de la précision en comparant
les couples mot/catégorie des phrases étiquetées :31 ceux des phrases de référence. Nous
avons d'abord calculé la précision au niveau de chaque phrase. Pour calculer la précision

globale, on calcule ensuite la précision moyenne sur l'ensemble des phrases de test:

nombre des couples corrects obtenus

2'-1. Pi
- — X 100 2 P = i 3
I nombre total des mots bien segmentés ( ) may n ( )

5 http://www.it1.nist.gov/iad/mig/tools/

on 11 est le nombre de phrases (n=2 34), et P,-: la précision de la phrase 1'.

Ce mode de calcul a pour effet de minimiser l'impact des erreurs qui apparaissent dans les
phrases tres longues, car il donne une pondération plus importante aux étiquettes des
phrases courtes.

Pour obtenir une évaluation comparative précise, nous avons évalué les deux systemes sur le
méme corpus de test Nous avons obtenu un taux de précision moyen égal a 86.5 % contre 60
% pour ASVM1.0. Nous avons également évalué la tache de segmentation sur le méme
corpus de test, et obtenu un taux de précision de 93 %. Le tableau ci-dessous résume bien
cette évaluation.

Notre ASVM1.0
systeme
Etiquetage 86,5 % 60 %
Segmentation 93 % 85 %

TABLE 4 — Evaluation quantitative de notre systeme et ASVM 1.0.

5.4 Evaluation qualitative

Aﬁn d'avoir une idée plus précise des types d'erreur rencontrés, nous avons procédé a une
évaluation qualitative. Nous avons examiné seulement les 50 premieres phrases. Ces phrases
contiennent 869 mots étiquetés parmi lesquels nous avons trouvé 24 étiquettes fausses
c'est-a-dire 2,75 % d'étiquettes erronées.

Nous avons constaté que les erreurs sont dues, en général, a la mauvaise segmentation des
mots, a l’absence des mots dans le lexique, ainsi qu'aux cas d’ambigu'ité. Le tableau suivant
illustre les différents cas de ﬁgure pour ces 24 étiquettes erronées :

Phrases Mots Etiquettes Mots mal Mots Mots
erronés segmentés absent du ambigus aux
lexique niveaux
lexical et
grammatical
5 0 8 69 2 4 1 1 9 4
pourcentage 2,75 % 1,26 % 1,03 % 0,46 %

TABLE 5 — Les différents cas d'étiquettes erronées sur 50 phrases examinées manuellement.

Pour comparer les résultats de notre étiqueteur et ceux d'ASVM1.0, nous avons choisi, a titre
d'illustration, quelques phrases étiquetées par les deux systémes :

Phrases Notre étiqueteur ASVM1.0

as 015 @1754}! lwdfYj / NNP fAn / NNP bYthwfn / NNP m&lf / 1wdf}7'/NNfAn/ NNP bYthwfn /
NN mwsYqY / 11 >lmAnY / 1] wld / VBN EAm / NNP m&lf / NN mwsYqY/NN
NN 1770 / co m / NN fY / IN mdYnp / NN bwn / >1mAnY/MVPwld / VBN EAm /

g5-.|-aw “-3334
EL:-. 41, g.'.L..Ii
149.95 5 1770 NNP ./SENT NN 1770 / co m / NN fY / IN
-0}! mdYnp / NN bwn / NNP . /
PUNC
J'J_..iL-J,.J__.‘3._... YEtbr/VBNmn/IN>b1z/JJEbAqrp/NNAl/ YEtbr/VBNHH1/IN>b1z/J]
L,§.,....,..JI$,§l._.:. DTmwsYqy/NNtY/IN jmYE/JJAl/DTEswI/ EbAqrp/NNAlmwsYqy/NNtY
‘J}"“"-“¢~"‘.3‘g;5 NNS ,/PUNCw/CC >bdE/VBN >EmAlAF/ /INjmYE/JJA1Eswr. /MV w/
4”‘ 3*‘ 5 NN mwsYqYp/JJ xAldp/JJ. /SENT CC >bdE’ VBN >EmA1AF ’ NN
5‘-J3-,|-aw mwsYqYp / JJ xAldp /JJ . /
PUNC

mu-. 5.4 am 1/IN *1k/WP YnSH/VBD EAdp/NN b/PREP 1*1k/11v YnSH/VBD EAdp/NN
OMOJ4!  >n/RP Ytmrn/VBN mn/IN YrYd /VBN Al/DT b/IN >11/IN Ytmrn/VBN
(MM AM tE7m/VBN b/PREP A1/DT tdrYb/NN Ely/RP mn/IN YrYd /1v1v A1tEYmﬂVN

<xrAj /NN Al/DT Swt/NN >wlA /I] w/CC b/IN A1tdrYb/NN Ely/IN <XrAj

U3‘  mn/IN vm/RB EndmA/IN YstTYE/VBD *1k/WP /NN A1.S'wt/NN >wlA /11 w/CC
«Lu-all 5|}! Ybd>/VBP b/PREP A1/DT tE1m/VBN Ely/RP mn/IN vm/RB EndmA/IN
ms; ego“ Y}: <xrAj /NN A1/DT drjAt/NNS Al/DT SwtYp/NN YstTYE/VBD *lkﬂ)T Ybd>ﬂVN
ha em  (/PUNC tmrYn /NN A1/DT >SAbE /NNS b/IN A1tE1m/NN Ely/IN <xrAj
)/PUNC ./SENT /NN A1d17'.4tyNNS' A1SwtYp/1]

:U'=lu-‘= am-.' (/PUNC tmrYn /NN AI>SAl7E

3-ﬁjml‘ 0‘-n45‘ /NNS )/PUNC ./PUNC
JAG d,i as qdm/NN >w1 / 1] Em1/ NN mwsYqY / 1] w / qdm / VBD >w1 / 1] Eml / NN
Sbﬁcjgsyy CC Emr/NN h/PRP 8/CD snwAt/NNS./ mwsYqY/]]w/CC Emr/NNh
labs” SENT / PRP$ 8 / co snwAt / NNS . /
PUNC

TABLE 6 — Exemples de phrases étiquetées par notre étiqueteur et ASVM1.0.

Si on observe les résultats obtenus par notre étiqueteur sur ces 4 phrases, on remarque bien
qu'il analyse les deux premieres phrases correctement, par contre, il génere des erreurs au
niveau de la troisieme et de la quatrieme phrase. En général, les erreurs d'étiquetage de
notre systéme viennent soit de la mauvaise segmentation du mot ou de l’absence du mot
dans le corpus d'apprentissage, soit de l’ambigu'1'té graphique du mot liée a l’absence des
voyelles (p.ex. qdm (545)/NN).

6 Conclusion et perspectives

Dans ce travail, nous avons essayé d'adapter l'outil TreeTagger sur la langue arabe. Pour ce
faire, nous avons organisé notre travail en trois étapes principales. D'abord, nous avons
récolté et préparé toutes les données nécessaires: lexique, jeux d'étiquettes et corpus
d’apprentissage. Ensuite, nous avons développé une méthode de segmentation des textes
arabes basée sur corpus pré-segmenté manuellement Enﬁn nous avons terminé par une
évaluation qualitative et quantitative de notre systeme. L'évaluation sommaire que nous
avons menée indique que notre étiqueteur arabe donne 86 % de précision. Les résultats de
l'évaluation quantitative montrent un gain de notre méthode par rapport a l'étiqueteur
ASVM1.0. Malgré un corpus d'apprentissage tres restreint, ces résultats sont donc
encourageants.

Pour le moment notre systeme ne permet pas de lemmatiser, car notre lexique, encore
incomplet, ne contient pas de lemmes : dans nos prochains travaux, nous comptons remédier
a cette lacune en ajoutant cette information. De plus, pour obtenir un étiqueteur générique a
large couverture, nous envisageons d'augmenter notre corpus d'apprentissage, sur le plan
quantitatif, mais aussi de l'enrichir en termes de variété typologique (littéraire,
journalistique, scientiﬁque, etc.).

7 Références

ABBES, R. (2004). La conception et la réalistion d'un concordancier. Lyon,ENSSIB/INSA:
These de doctorat en sciences de l’information.

ANIZI, M. et DICHY, ]. (2009). Assessing Word-form based Search for Information in Arabic:
Towards a New. MEDAR Zand International conference on Arabic Language Ressources &
Tools, Cairo Egypt, pages 12-19 .

A'I'I‘IA, M. (2006). An Ambihuity controlled Morphological Analyser for Modern Standard
Arabic Modelling Finite State networks. : Acte de la confe’rence internationale ’tl1e cliallenge
of arabic for NLP/M7} tl1e BI‘ll'5l1 computer society. London.

BUCKWALTER, T. (2002). Arabic Morphological Analyser version 1.0. Linguistic Data
Consortium Catalogue numéro LDC L 49.

BAHOU, Y., HADRICH BELGUITH, L., et BEN HAMADOU, A. (2005). SYNTAXE: Analyseur syntaxique
de l'arabe utilisant XML comme outil de stokage . Souuse,Tunisie: Cinquiémes journe’s
scientiﬁque desjeunes cl1ercl1eurs en ge’nie e’lectrique etinformatique .

CHAABAEN KAMMOUN, N., HADRICH BELGUITH, et BEN HAMADOU, A. (2010). The MORPH2 new
version: A Robust morphological analyser for arabic text. MIRACL Laboratory Tunisia .

DIAB, M. (2009). Second Generation AMIRA for Arabic Processing: Fast and Robust
Tokinisation, Pos Tagging and Base Phrase Chunking. MEDAR 2nd International conference
on Arabic Language Processing & Tools, Cairo Egypt, pages 285-288.

DIAB, M., HACIOGLU, K.,et IURAFSKY, D. (2004). Automatic Tagging of Arabic Text: From Raw
Text to Base Phrase Chunks. . HLT-NAACL , pages 149-152.

EL-HA], M ,KRUscHwI'I'z, U. et Fox, C. (2010). Using Mechanical Turk to Create a Corpus of
Arabic Summaries in the Language Resources (LRs) and Human Language Technologies
(HLT) for Semitic Languages. worksliop lield in conjunction witlz tl1e 7tl1 International
Language Resources and Evaluation Conference (LREC2010), Valletta, Malta, pages 36-39.
FARGHALY, A.et DICHY, ]. (2003). Roots & Patterns VS Stems plus Grammair-Lexis specification
:On what basis should a multilingual lexical database centred on arabic be built? Acte de la
9én1e MT conference, Worksliop on Macliine translation for semitic language .'issues and
approaclies. New Orleans, Louisiana, USA.

LAPORTE, E . (2000). Mot et niveau lexical . jean-n1ariepierre:lngenierie de langues, pages
25-46.

MARS, M., ZRIGUI, M., BELGACEM, M., ZOUAGHI, A. et ANTONIADIS, G. (2008). A Semantic Analyzer
for the Comprehension of the Spontaneous Arabic Speech. International Conference on
Computing CORE08, ]ournal Researcli in Computing Science (journal RC5) , ISSN: 1870-
4069, Vol 34, pages 129-140.

POPOWICH, F. et VOGEL, C. (1990). Chart parsing head-driver phrase structure grammar.
Teclinical Report CSS-IS TR 90- 01, CMPT TR 90-01, Simon Fraser University, Burnaby, BC

SCHMID, H. (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. Proceedings of
International Conference on New Metliods in Language Processing, Manchester, UK, pages
88-96.

STEIN, A. (2007). Part of speech tagging and lemmatisation of Old French.
http : //www. uni—stuttgart . de/lingrom/stein/ fors chung/ resource . html .
[consulté le 10/02/2011].

ZEMIRLI, Z. et KHABET, S. (2004). Un analyseur morphosyntaxique destiné a la synthese vocale
de textes arabes voyellés. /EP-TALN, Fes.

