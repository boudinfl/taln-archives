
Une approche linguistique pour l'extraction des connaissances
dans un texte arabe

Houda Saadane
LIDILEM, Université Stendhal — Grenoble III, 1180, avenue central, F-384-00 Saint Martin
d'Heres
houda.saadane@e.u-grenoble3.fr

RESUME

Nous présentons dans cet article un systeme d'extraction de connaissances en arabe, fondé
sur une analyse morphosyntaxique profonde. Ce systeme reconnait les mots simples, les
expressions idiomatiques, les mots composés et les entités nommées. L'analyse identiﬁe
aussi les relations syntaxiques de dépendance et traite les formes passives et actives.
L'extraction des connaissances est propre a l'application et utilise des regles d'extraction
sémantiques qui s'appuient sur le résultat de l'analyse morphosyntaxique. A ce niveau, le
type de certaines entités nommées peut étre révisé. L'extraction se base, dans nos
expérimentations, sur une ontologie dans le domaine de la sécurité. Le RDF (Resource
Description Framework) produit est ensuite traité pour regrouper les informations qui
concernent un méme événement ou une méme entité nommée. Les informations ainsi
extraites peuvent alors aider a appréhender les informations contenues dans un ensemble
de textes, alimenter une base de connaissances, ou bien servir a des outils de veille.

ABSTRACT
A linguistic approach for knowledge extraction from an Arabic text

We present in this paper a knowledge extraction system for Arabic. The information
extraction is based on a deep morphosyntactic analysis. It also recognizes single words,
idiomatic expressions, compounds and named entities. The analysis also identiﬁes
dependency relations, verb tenses and passive/active forms. Information extraction is
application-independent and uses extraction rules that rely on the result of the
morphosyntactic analysis. At this level, some named entity categories can be reconsidered.
This extraction is based in our experimentations on the security ontology. The Resource
Description Framework (RDF) obtained is then processed to gather information concerning
a single event or named entity. The information extracted can help to understand the
information contained in a set of texts, to infer knowledge into a knowledge base, or be used
for monitoring tools.

MOTS-CLES: Analyse linguistique, fouille de textes, arabe, entités nommées, extraction
d'informations, regles d'extraction, ontologie.

KEYWORDS : Linguistic analysis, Text Mining, Arabic, named entities, information extraction,
extraction rules, ontology.

1 Introduction

Les évolutions rapides des nouvelles technologies sont accompagnées d'un essor important
de la quantité d'information disponible sur le Web, et nécessitent le développement d'outils
pour analyser et structurer les documents textuels. Ainsi, les documents en arabe sur le Web,
a l'instar des auteurs langues, se multiplient en nombre, en contenus et en quantité. Pour
traiter cette grande masse de textes, une possibilité est de recourir a des outils de fouille de
textes ou d'extraction de connaissances. Pourtant, dans ce domaine en pleine émergence, les
outils qui permettent d'analyser les documents arabes se limitent en général a l'extraction
d'entités nommées.

L'objectif de cet article est de présenter un systeme d'extraction des connaissances pour
l'arabe qui, apres avoir effectué une analyse linguistique profonde du texte, extrait les entités
nommées, et les relie a des événements, en se basant sur une ontologie métier. Le
développement d'un tel systeme exige l'étude des propriétés des données textuelles en
soulevant essentiellement les problemes concernant l'analyse et la représentation des
contenus des textes (Cherﬁ., 2002).

Dans cet article, nous commencons par présenter dans la section 2 un état de l'art du
domaine de l'extraction de connaissances, suivi dans la section 3 d'une description des
étapes de l'analyse linguistique profonde. La section 4- décrit le processus d'extraction
sémantique qui se base sur les résultats de l'analyse syntaxique et sur des concepts et des
regles d'extraction spéciﬁques au domaine traité. Dans la section 5, nous présentons le
traitement qui consiste a aligner les informations recueillies au niveau du document pour
regrouper les occurrences qui désignent une méme entité nommée, ou un méme événement.
Nous exposons dans la section 6 les premiers résultats que nous avons obtenus. Nous
terminons par une ouverture sur les perspectives d'amélioration de notre systeme.

2 Etat de l’art

De nombreux travaux de recherche ont abordé la question de l'extraction de connaissances,
citons TEMIS (TExt Mlning Solutions) qui est un éditeur de logiciels d'enrichissement
sémantique des contenus. Sa plateforme Luxid (Kuznik et al., 2010) propose des
fonctionnalités d'extraction d'information qui sont réalisées par le moteur Insight Discoverer
Extractor. Ce serveur d'extraction d'information pour l'analyse des textes enchaine trois
étapes : l'analyse de corpus (identification de la langue), l'analyse linguistique réalisée par
Xelda et l'extraction des connaissances (identiﬁcation des entités nommées, reconnaissance
des relations entre les entités). Cette étape repose sur la technologie Skill Cartridge (Brun et
al., 2009) qui propose un ensemble de regles et de composants linguistiques déﬁnissant
l'information a extraire. La cartouche va permettre de réaliser une analyse sémantique pour
fournir les relations sémantiques. Ces relations sémantiques font référence par la suite a des
entités nommées et a des patrons spécifiques au domaine de l'intelligence économique. Un
role est assigné a chaque entité, aﬁn de déﬁnir sa position dans la relation sémantique. Les
langues analysées par IDE, sont le francais, l'anglais, l'espagnol, l'italien et l'allemand.

Le projet SAMAR1 (Station d'Analyse Multimédia en langue Arabe) est, quant a lui, destiné
aux journalistes travaillant en langue arabe. Son objectif est le développement d'une
plateforme de traitement multimédia a destination de la presse et des médias arabes. Parmi
les principales composantes de ce projet, il y a l'analyse sémantique et l'extraction des

1 http://www.samar.fr/
entités nommées, qui constituent les sujets des informations a analyser. Ces entités sont par
la suite stockées dans une base de connaissances.

Concernant plus particulierement l'extraction des connaissances en langue arabe, les travaux
se sont focalisés sur la reconnaissance et l'extraction des entités nommées. Parmi ces
travaux, nous pouvons mentionner les travaux de (Zitouni et al., 2005) qui utilisent des
techniques d'apprentissage automatique (Modeles de Markov a Entropie Maximale) en
considérant des jeux de descripteurs idoines. L'utilisation d'un corpus parallele pour
l'extraction des entités nommées en arabe a été adoptée par (Samy et al., 2005). Cette
méthode est aussi basée sur des regles, mais avec en plus l'utilisation d'un lexique
monolingue de langue espagnole pour permettre l'extraction des entités nommées en
espagnol. Une fois que ces entités sont extraites, un processus de transcription en arabe est
appliqué sur ces entités.

Enﬁn, le travail de these de Mesfar (2008) avait pour objectif une analyse morpho-
syntaxique et une extraction des entités nommées en arabe standard. Son systeme est basé
sur une combinaison des résultats obtenus par le biais d'un analyseur morphologique et de
grammaires locales représentant des regles d'identiﬁcation écrites a la main. D'autres
travaux récents se basent sur des méthodes a base de regles Shaalan et al., 2009 ; Zaghouani
et al., 2010.

Les études que nous avons décrites ci-dessus proposent une solution a la problématique de
l'extraction des entités nommées, mais n'abordent pas, ou peu, le sujet de l'extraction de
connaissances relatives :31 ces entités. Notre objectif est de proposer un systeme d'extraction
de connaissances pour l'arabe, qui sera capable de repérer les entités nommées, mais aussi
les relations sémantiques qui les relient, pour un domaine particulier modélisé dans une
ontologie. Notre analyse est fondée sur la technologie des automates d'états ﬁnis.

3 Analyse linguistique profonde

L'analyse linguistique profonde est nécessaire pour assurer une extraction d'informations
sﬁre, pertinente et complete, par exemple en reliant des éléments qui peuvent étre éloignés
dans la phrase initiale.

L'analyse que nous avons mise au point se divise en plusieurs étapes allant du découpage en
mots jusqu'aux relations que ceux-ci entretiennent au sein d'une phrase. Les principales
étapes de cette analyse sont décrites dans les sous-sections suivantes :

3.1 Découpage en mots

La tokenisation permet le découpage du texte en mots, les « tokens », séparés par des
ponctuations ou par des espaces. Elle prend aussi en compte les balises, les dates abrégées,
etc. Citons l'exemple de la tokenisation en mots de la phrase -7\S3D\-«-ll; Q9-ll 5*-‘I-pa u-nu‘-.I. » (Paris la
ville des diables et des anges) donnera : 3S3>\-all | 3 | 09-“ | 3-‘I-,I~=A | LJ-“:'.JL.|. C'est une étape qui va
permettre d'attribuer ensuite a chaque token des catégories et des propriétés sur lesquelles
portera l'analyse profonde.

3.2 Analyse morphologique

Le travail de l'analyseur morphologique consiste a retrouver la forme de surface d'un mot
stocké dans le lexique a partir de la forme canonique de ce dernier (inﬁnitif du verbe,
masculin singulier d'un adjectif, etc...). Cette étape est primordiale lors de l'analyse
linguistique. Elle se divise a son tour en plusieurs étapes : la consultation du dictionnaire des
formes ﬂéchies d'une part pour récupérer la normalisation du mot et d'autre part, pour
permettre de récupérer les informations linguistiques (genre, nombre, catégorie
grammaticale, etc.) de ce mot. L'une des particularités de la langue arabe est la présence des
formes agglutinées (formes avec des proclitiques et des enclitiques). Ces formes ne sont pas
présentes dans le dictionnaire des formes ﬂéchies. Pour identiﬁer ces formes et les traiter
correctement, nous avons ajouté un segmenteur de clitiques (proclitiques et enclitiques) a
l'analyse morphologique. Cette segmentation des formes agglutinées se déroule de la
maniere suivante (Semmar et al., 2005) :

1. Recherche de toutes les compositions possibles entre les clitiques (proclitique,
enclitique) et le radical en utilisant les dictionnaires des proclitiques, enclitiques
et formes ﬂéchies.

2. Chaque radical est ensuite recherché dans le dictionnaire des formes ﬂéchies. Si
ce radical n'existe pas dans le dictionnaire, des transformations morphologiques
sont appliquées avant leur sufﬁxation en se basant sur des regles de réécriture,
enﬁn le radical résultat est de nouveau recherché dans le dictionnaire des formes
ﬂéchies. Par exemple, considérons la forme agglutinée ((43JL,,|-H|-_|)) (avec sa voiture)
et les clitiques inclus dans cette forme (0 ,~.—I). Le radical récupéré <<¢Ul.,m>> n'existe
pas dans le dictionnaire des formes ﬂéchies. Mais apres l'application de la regle
de réécriture transformant la lettre «Q» en «E» en ﬁn de mot, le radical modiﬁé
<<3Jl.,m->> (voiture) est trouvé dans le dictionnaire des formes ﬂéchies et la forme
agglutinée <<-‘NU-,ua-.I>> est découpée en proclitique + radical + enclitique comme
suit: 43;‘-H-.' = H + U-,I-u + 0 (avec sa voiture).

3. Une étape supplémentaire permet de vériﬁer la relation d'ordre au sein d'une
représentation des formants du mot sur un vecteur ordonné (Zmantar et al.,
2009). La principale propriété de celui-ci est que chaque proclitique est
incompatible avec un proclitique de méme position, en raison de la relation
d'ordre strict qui régit les formants du mot graphique. Exemples : wa et fa
coordonnants (:45 et 432:1‘ 3'3), qui occupent tous les deux la méme position sur le
vecteur d'ordre, sont incompatibles entre eux (ils ne peuvent pas apparaitre dans
un méme mot). Cette étape doit aussi vériﬁer les regles, syntaxiques mais aussi
sémantiques, de compatibilité et d'incompatibilité entre les proclitiques et les
enclitiques.

Cette analyse reconnait aussi des expressions idiomatiques aﬁn de grouper certains mots
pour les considérer comme une seule unité (dgdall 35»: Chemin de fer). Cette reconnaissance
se fait a l'aide de regles et de dictionnaires.

Si, apres ces étapes, un mot reste inconnu, le systeme lui attribue une (des) catégorie(s) par
défaut, en s'appuyant sur des informations révélées par sa forme de surface. Par exemple, s'il
s'agit d'un mot en caracteres latins majuscules, comme ONU, il sera étiqueté comme un nom
propre.

Apres cette analyse morphologique, et particulierement pour le traitement de la langue
arabe, la majorité des mots restent ambigus a cause de l'absence des voyelles courtes arabes
dans les textes (Debili et al., 1998), ce qui est moins prononcé pour les autres langues. Le
probleme majeur rencontré dans cette phase est celui de l'ambigu'ité lexicale et
grammaticale, qui découle du fait que lorsqu'un mot est reconnu, l'analyseur morphologique
peut fournir plusieurs interprétations qui renvoient a plusieurs catégories syntaxiques ou a
plusieurs sens. Le role du désambiguiseur morpho-syntaxique qui intervient par la suite, est
de réduire le nombre des ambigu'ités grammaticales en utilisant des matrices de
désambiguisation. Ce sont des matrices de bi-grammes et tri-grammes de catégories
obtenues a partir d'un corpus étiqueté du LDC (Arabic Treebank), et désambiguisé
manuellement. Le résultat de l'application des n-grammes nous permet d'obtenir la suite de
couples mot-catégories la plus probable. L'ambigu'ité lexicale est conservée :31 Ce niveau, pour
étre traitée plus tard, au niveau de l'extraction sémantique.

3.3 Repérage des dates

Lors de l'analyse morphologique, un traitement spéciﬁque intervient pour le repérage des
dates. Ceci permet ensuite a la désambiguisation d'étre plus efﬁcace, étant donné que les
dates ne sont plus constituées d'une suite de catégories, mais sont associées a une catégorie
« date ».

Les dates et heures se composent de l'indication normalisée du temps qu'elles représentent
Nous nous sommes basés sur la norme ISO 8601 avec le format AAAAMM]] ou AAAA
représente l'année sur 4- chiffres, MM représente le numéro du mois, sur 2 chiffres et ]]
représente le quantieme dans le mois, sur 2 chiffres. Par exemple, «4.L,U§l1984- (Avril) 01» est
normalisé de la maniere suivante : «1984-04-01 », «J-,1 J51 (Avril) 1984- » est normalisé par
«1984-04-XX», «lab : demain» est normalisé par «XXXXXX+1».

3.4- Mots composés

Une étude linguistique spécifique de la langue arabe nous a permis de déﬁnir et d'écrire un
certain nombre de regles dans le but d'établir des relations de dépendance (contigués et non
contigués) entre les mots au sein du syntagme nominal. Ces relations permettent ensuite de
reconnaitre les mots composés présents dans une phrase.

Citons l'exemple de <<.:.,s4..iJ| -Llaj» (la veuve de martyr), nous avons une relation entre deux
mots associés par annexion (‘iii-2|)?‘-.I -Ur-A), qui relie le mot indéﬁni )veuve( 3-lag‘ et le mot
déﬁni A-1+-5|-ll (martyr) pour donner une relation de type "NomRelNom".

3.5 Relations sujet-verbe-complément

Nous avons déﬁni un certain nombre de regles, issues d'une étude expérimentale pour
l'identification et le repérage des relations syntaxiques dans une phrase. Notons que certains
verbes demandent un complément, contrairement a d'autres. Ces verbes sont appelés des
verbes transitifs. Il faut déﬁnir la liste des verbes transitifs et des verbes intransitifs, étant
donné que, en arabe, la position des mots ne suffit pas :31 en déduire la fonction syntaxique du
mot. Les voyelles courtes l'indiquent, mais elles ne sont généralement pas indiquées dans les
textes écrits. C'est pour cela qu'il faut se baser sur la transitivité ou sur la non transitivité du
verbe pour déterminer quelles sont les relations qui existent entre un nom et un verbe.

Voici les relations que nous détectons :
— Les relations agent-verbe, qui permettent d'identifier l'agent de l'action (pour
répondre a la question : qui a fait l'action?)

— Les relations verbe-complément, qui permettent d'identiﬁer qui a subi l'action, ou
encore les circonstanciels qui nous renseignent sur le moyen (comment? Avec
quoi?), la date (quand?), le lieu (ou ?),  de l'action.

3.6 Passif

Aﬁn de rendre l'étape de construction des regles d'extraction des connaissances plus
efficace, l'analyse linguistique profonde adopte en interne la méme représentation pour une
phrase passive, et pour son équivalent a la forme active. Cette phase consiste donc a
identiﬁer les formes passives et a les transformer en formes actives. Voici quelques
structures syntaxiques exprimant un passif (Ziad, 2010) :

— Passif avec un verbe doublement transitif. 3531+ 39‘-5-5‘  : On a accordé un prix a
l'écrivain
— Passif avec un verbe transitif indirect, précédé par une préposition, ,aLA=‘Y\-.I 4-15°  : II
a été condamné a mort.
— Emploi de tournures modernes du passif, qui expriment le complément d'agent:
~.9‘é£ue‘.=D3=£ue‘dé§(par).
Dans l'exemple suivant: lbgﬁﬂl 4; g,-in H35-ll «L539! (la ﬁlle a été arrétée par la police), pour ne pas
confondre entre la personne qui fait l'action et la personne qui la subit, il est important de
savoir si la forme est active ou passive. Ici, la forme est active mais emploie une tournure
moderne du passif qui exprime le complément d'agent (4; J5), donc le sujet est la police et le
complément est la fille. Nous obtenons donc les relations suivantes :

— relation agent-verbe entre  (arréter) et  (Police) reliés par le mot 4; “J5
(Par)

— relation verbe-complément entre £3333‘ (arréter) et 3‘-'3 (ﬁlle).

<relation reltype="SV">

<head>
<posBeg>112 </posBeg>
<lemma>(J§3'=j </lemma>
<catPos index="no">+verbe</catPos>
<prop

index="no">+vbpassif+acc+3fs</prop>

<posEnd>118</posEnd>

</head>

<dept>
<posBeg>133</posBeg>
<lemma>3\3='J-i3:</lemma>
<catPos index="no">+nom</catPos>
<prop index="no">+fs</prop>
<posEnd>139</posEnd>

</dept>

<lingIndication index="no">
<posBeg>126</posBeg>

<relation reltype="VC">
<head>
<posBeg> 112 </posBeg>
<lemma>(J§3'=j </lemma>
<catPos index="no"> +verbe</catPos>
<prop
index="no"> +vbpassif+acc+3fs</prop>
<posEnd> 118</posEnd>
</head>
<dept>
<posBeg> 119 </posBeg>
<lemma>3LTI</lemma>
<catPos
index="no"> +annppers</catPos>
<prop index="no">+pers+fs</prop>
<posEnd> 125</posEnd>
</dept>
</relation>

129

© ATALA
<lemma>d; ;,1'=</lemma>

<catPos index="no">+prepN</catPos>
<prop index="no">+passif</prop>
<posEnd>132 </posEnd>

</lingIndication>
</relation>

TABLE 1 — Exemple d'extraction des relations syntaxiques dans une phrase passive.

Head : unité qui constitue la téte de la relation

Dept : unité qui constitue le dépendant de la relation

Linglndication : balise qui contient des indications sur les unités qui permettent de relier
les termes d'une relation, et qui serviront lors de l'extraction sémantique.

3.7 Reconnaissance des entités nommées

Cette phase consiste a mettre en oeuvre un systeme de reconnaissance et de typage des
entités nommées. Dans notre approche, nous avons opté pour un systeme a base de regles
linguistiques qui exploitent l'étiquetage syntaxique, des marqueurs lexicaux (déclencheurs)
et des dictionnaires de noms propres. La mise en place de regles de reconnaissance d'entités
nommées a nécessité une recherche profonde sur certains traits linguistiques propres aux
entités nommées en arabe.

Exemple : " 1533» J9 J‘-I-1: full " (le frere Moez Garsallaoui) Dans cet exemple, nous avons le
titre de civilité "full : frere" suivi d'un prénom et d'un nom propre. Voici la représentation
que nous obtenons :

<en entype="pers"> <relation reltype="PrenomNP">
<relation reltype="AnnpNP"> <head>
<head> <posBeg>1104-</posBeg>
<posBeg>1104-</posBeg> <lemma>4;;>\-uja </lemma>
<lemma>4;;>\-uje </lemma> <catPos index="no">+np</catPos>
<catPos index="no">+np</catPos> <posEnd> 111 1</posEnd>
<posEnd>1111</posEnd> </head>
</head> <dept>
<dept> <posBeg>1098</posBeg>
<posBeg>1092 </posBeg> <lemma>,'\=_rJ~</lemma>
<lemma>&l</lemma> <catPos
<catPos ndex="no" > +annppers< /catPos> index="no"> +prenom</catPos>
<prop index="no">+pers+ms</prop> <prop index="no"> +m</prop>
<posEnd>1097</posEnd> <posEnd>1103</posEnd>
</dept> </dept>
</relation> < /relation>
</en>

TABLE 2 — Exemple de reconnaissance des entités nommées de type Personne.
4- Extraction sémantique

L'entrée de cette étape est constituée de la sortie de l'analyse morpho-syntaxique décrite
précédemment Cette analyse fournit les informations suivantes :

— les lemmes des mots ainsi que leur position dans le texte, et leur catégorie
grammaticale

— les relations de dépendance syntaxique entre les mots,

— les entités nommées typées.
Nous avons choisi une représentation interlingue en anglais de toutes les informations, dans
le but de faciliter la lecture des informations extraites par les non arabophones et de faciliter
la fusion d'informations provenant de documents en plusieurs langues. Nous avons eu
recours a deux types d'opérations : l'utilisation de dictionnaires de traduction existants et
l'ajout d'un systeme de translittération pour les entités nommées qui n'existent pas dans les
dictionnaires (Saadane et al., 2012).

L'extraction de connaissances permet de mettre en évidence des entités nommées et des
relations relatives a un concept particulier, par exemple : « arrestation », « attentat »,
« condamnation », « construction ». Le déroulement de cette étape s'effectue en trois temps :
la sélection des concepts potentiellement présents, la sélection des regles a appliquer, puis
l'application des regles.

4-.1 Sélection des concepts probables

Une étape primordiale lors de l'extraction des connaissances consiste a repérer les
déclencheurs. Ces déclencheurs peuvent étre des mots, des expressions ou des relations, et
indiquent qu'une relation relative a un concept peut étre présente dans le texte. Les
déclencheurs sont présentés sous forme de deux colonnes :

— la premiere colonne contient les mots, les expressions ou encore les relations qui
indiquent la présence du concept dans le texte traité.
— la deuxieme colonne déﬁnit le concept (arrestation, transfert, émission, union,...)
associé a l'élément de la premiere colonne.
(33331 Arrest
VC#5\3\-'~»:_J#(J3?I# Emission
Comme nous l'avons mentionné et comme le montre l'exemple précédent, les déclencheurs
peuvent étre des mots (553 ,4J33=J.) :(mariage, interpeller...), des expressions ou bien des
relations (VC# (J3 # 33‘-h_J #) : (VC#transmettre#message#).

Il est nécessaire qu'un déclencheur soit présent dans l'entrée aﬁn d'étre en mesure d'extraire
l'information présente. A partir d'un déclencheur, un concept est obtenu ce qui nous permet
ensuite de sélectionner les regles a appliquer.

4-.2 Sélection des régles £1 appliquer

Les déclencheurs nous ont permis d'obtenir la liste des concepts présents dans le texte. Ces
concepts nous amenent alors vers une liste de regles qui vont étre confrontées aux relations
issues de l'analyse syntaxique. Si les relations syntaxiques correspondent aux regles définies,
elles pourront alors étre extraites. La déﬁnition des regles a appliquer comporte aussi deux
colonnes :

— La premiere colonne indique les concepts. Ils sont ensuite comparés aux concepts
probables sélectionnés a la phase précédente par le biais des déclencheurs

— La deuxieme colonne liste les regles spécifiques a un concept pouvant étre
appliquées. Ces regles contiennent des relations syntaxiques (SV, VC) entre un verbe

et une liste de catégories, avec d'éventuelles prépositions.

Arrest SV#4J§3'=,|#<en># déglb (ArrestSV#arréter#<en># par)
Arrest SV#4J§3'=,|#<en># (Arrest SV#arréter#<en>#)
Arrest VC#d33'=1 |#<en># (Arrest VC#arréter#<en>#)

Pour illustrer notre propos, prenons l'exemple suivant: -Um--’-I-ll 4-,I “la J4-;,\=-ll «LIE-fol (Elaroud a
été arrétée par la police). Lors de la premiere étape, le mot «diicj» (arréter) a été repéré
comme déclencheur du concept « Arrest» (arrestation). Ce concept est associé aux regles
présentées ci-dessus. Afin de pouvoir étre sélectionnées, les regles doivent correspondre a
une relation syntaxique présente dans la phrase. Or, dans la phrase « Elaroud a été arrétée
par la police », « arréter » a un complément « Elaroud » de type entité nommée, et « arréter »
a un sujet « police », étant donné que la phrase est au passif. Donc, ce sont les regles SV#4J§3'=j
#<en>#!-,1 J5 et VC#4J§3'=j #<en># qui seront sélectionnées.

A ce stade intervient un traitement qui permet l'application des regles sélectionnées lors de
la phase précédente aux relations syntaxiques effectivement présentes, afin d'extraire
l'information en question.

4.2.1 L'app1ication des régles sélectionnées

Les regles sélectionnées a l'étape précédente sont appliquées aux relations syntaxiques aﬁn
d'en extraire les connaissances présentes. Les connaissances sont extraites a partir de la
sortie de l'analyse linguistique profonde. La regle d'extraction indique ensuite quels sont les
éléments qui doivent étre extraits, et quelle est leur sémantique. Si nous reprenons l'exemple
« -U=J.~5n.l| A; “Jo Jan 3 )'-ll £1539): Elaroud a été arrétée par la police», l'une des regles sélectionnée
est la relation verbe-complément entre «arréter» et une entité nommée. Cette regle indique
que le concept extrait sera «Arrest» (Arrestation), dont le patient est l'objet de «arréter»,
c'est-a-dire «Elaroud». Le résultat obtenu sera alors de la forme suivante : <gs:Arrest
rdf:11odeID= "1'd1 7Arrest"> <W11:u11dergoer rdf:11odeID= "1'd1EIaroud "/> </gs:Arrest>

4.2.2 L'extraction des entités nommées et son contr6le

Toutes les entités nommées détectées au niveau de l'analyse linguistique sont extraites en
conservant leur type : « Personne », « Lieu », « Organisme », « Mesure », « Date », « Produit »
ou encore « Inconnu ». Mais l'analyse linguistique a pu se tromper sur le type d'une entité
nommée. Cette étape effectue un controle sur le type des entités nommées extraites.

Le controle consiste a vériﬁer l'adéquation entre le type de l'entité nommée issu de l'analyse
linguistique, et le type de l'entité nommée proposé par la regle. Les types des entités
nommées peuvent étre modiﬁés si la regle d'extraction considere que le type de l'entité
nommée est incompatible avec le type de l'entité nommée issu de l'analyse linguistique.

L'exemple suivant illustre ce phénomene d'incompatibilité: « s‘_s.‘-l:=|<3 g»¢__5Jl%_—| Q15: _);1f_3,>-ii : Paris
déclare que I’AIgér1'e ...». Au niveau morpho-syntaxique, Paris est considéré comme une
entité nommée de type «lieu», mais dans le cadre de l'action d'émission d'un message, l'agent
ne peut pas étre un lieu. En fait, l'émission ne peut étre réalisée que par une personne ou une
organisation et si :31 l'origine elle a été considérée comme la capitale de la France, la nouvelle
catégorie est une organisation, et nous pouvons en déduire que c'est le gouvernement
francais.

4.2.3 La création d'entités

Il peut arriver qu'une regle fasse référence a une entité sans que celle-ci existe. C'est le cas
lorsque l'entité nommée n'a pas pu étre repérée au niveau de l'analyse syntaxique, ou bien
lorsqu'il ne s'agit pas d'une entité nommée comme dans l'exemple <<Q.,ul : il a été condamné».
Pour faire apparaitre le patient de l'action, la regle d'extraction va créer l'entité manquante :

VC#C;|3l #<$pers># 9 <e11 e11type='pers"><$pers></en>

Notons que l'extraction et/ou la création d'entités peuvent introduire des ambigu'ités. Une
relation peut demander comme objet ou sujet une entité de type lieu ou organisation. Ces
ambigu'ités sont alors générées, pour étre résolues plus tard, grace a un controle manuel par
exemple, ou bien grace a la mise en cohérence. Cependant, lorsque l'ambigu'ité se situe entre
les types personne ou organisation, le type « agent », qui est générique, sera indiqué.

5 Mise en cohérence

Précisons pour commencer que les résultats de l'extraction de connaissances est un graphe
RDF faisant référence aux concepts et propriétés issus de l'ontologie intégrée dans le
systeme. Cette étape va permettre de rassembler les informations concernant une méme
entité nommée, ou une méme action. Elle permet aussi d'exploiter les métadonnées
attachées au document. La construction de notre systeme d'extraction a nécessité la
déﬁnition des informations d'intérét dans le domaine de sécurité.

Nous avons choisi, pour cela, de développer une ontologie du domaine qui servira de guide
aux différentes étapes d'extraction. La diversité des documents exploités nécessite que
l'ontologie soit assez générale tout en contenant des concepts et des propriétés spécifiques
au domaine de la sécurité.

Nous avons développé une ontologie interne, en nous basant sur des ontologies existantes
telles que foaf pour les agents (Person et Organization) et en ajoutant d'autres concepts
décrivant les connaissances que nous souhaitons extraire tels que les actes de violences, les
déplacements, les transferts d'argent... La construction de cette ontologie a été réalisée
manuellement a base de corpus. A l'heure actuelle, notre ontologie compte 106 classes et
200 propriétés d'objets.

5.1 Regroupement des entités nommées

L'un des problemes des différentes étapes d'extractions réside dans le fait que les graphes
obtenus peuvent contenir des duplications inutiles de noeuds. Ce phénomene est
particulierement visible pour les entités nommées que l'on retrouve a plusieurs reprises
dans un méme document L'objectif de cette étape consiste a regrouper les différentes
occurrences d'une méme entité nommée sous un méme et unique URI. Ce probleme est
généralement connu sous le nom de ‘Record linkage‘ ou ‘Entity resolution‘ et a été abordé
par différentes approches (Elmagarmid et al., 2007).
Dans le contexte d'un graphe RDF, et dans le domaine de l'extraction sémantique, nous
adoptons une méthode basée sur un ensemble de regles. Ces regles ont été déﬁnies pour
identiﬁer les entités nommées dupliquées et permettre leur regroupement. Citons un
exemple de ces regles : deux personnes sont identiques dans un méme document, si elles ont
le méme nom et prénom, et qu'il n'y a pas d'autres informations contradictoires, par
exemple «junior» et «senior».

5.2 Résolution des dates relatives

Parmi les problemes que l'analyse linguistique ne résout pas il y a les dates relatives. Ces
dates ne sont pas toujours exprimées d'une maniere explicite dans les textes. Pour résoudre
ce phénomene, nous nous appuyons sur les trois aspects suivants :

1. La représentation adoptée par l'ontologie : l'ontologie décrit chaque date comme un
intervalle. Elle contient donc les attributs suivant: (1) dtstart : date de début, (2)
dtend : date de ﬁn, (3) type : le type de calendrier utilisé, qui correspond :31 des
constantes prédéﬁnies dans l'ontologie (grégorien, arabe, chinois ...), (4-)
authorValidation : donne une indication sur quand a eu lieu l'action, si cette derniere
se situe dans le passé ou le futur, grace notamment aux temps des verbes liés :31 la
date, (5) day: le jour de la semaine, lorsqu'il est précisé.

2. la sortie de l'analyse linguistique
3. les métadonnées du document analysé (notamment la date d'édition du document).

La sortie de l'analyse linguistique nous permet d'identiﬁer les occurrences ou la date extraite
est incertaine. Dans le contexte de la presse écrite, il est fréquent d'extraire des dates
relatives :31 un jour de la semaine ou :31 une indication dans le temps. Par exemple un
événement devant se dérouler («J-.I§a-ll 3 ;-.1-All 1,114-‘I : le week-end prochain » pour un article paru
le lundi 01 avril 2013 (une métadonnée du document). Les métadonnées sont alors
exploitées pour définir une date incertaine se situant entre le samedi 06/4-/2013 et le

dimanche 07/4/2013.
6 Premiers résultats

Pour estimer l'efficacité de notre systeme, nous avons mené deux types d'évaluation : une
évaluation quantitative concernant la phase de segmentation et la phase d'extraction
d'entités nommées et une évaluation qualitative (intrinseque) de l'extraction de
connaissances.

Nous avons comparé nos performances de segmentation avec l'outil de Stanford? en
apportant quelques modifications aux résultats pour pouvoir les comparer avec ceux de
notre outil. Par exemple, dans l'outil de Stanford, l'article déﬁni fait partie du mot,

contrairement a notre segmenteur qui considere que l'article déﬁni est un token
indépendant.

Nous avons calculé la précision sur un ensemble de documents (articles de presse Aljazeera)
segmentés par l'outil de Stanford et corrigés manuellement Nous avons eu une précision de
0,98% avec notre segmenteur contre 0,96% avec l'outil de Stanford.

2 http://n1p.stanford.edu/projects/arabic.shtml
Pour évaluer notre approche d'extraction d'entités nommées nous avons réalisé nos
expériences sur le corpus ANER3 (Benajiba et al., 2007) qui est composé de 150 000
occurrences de mots. Ce corpus distingue les types d'entité nommée suivantes : lieu
(LOCation qui représente 30.4-% des EN observées), personne (PERSon : 39%), organisation
(0RGanization: 20.6%) et une classe qui regroupe toutes les autres EN, de type « divers »
(MISCellaneous : 10%). Nous nous sommes intéressés a la reconnaissance des trois premiers
types des entités nommées et avons obtenu une précision de 89.05% pour la détection des
entités nommées de type personne, 91% pour les lieux et 83.4-1% pour les organisations.

Nos systemes de segmentation et d'extraction des entités nommées obtiennent de bons
résultats. Par ailleurs, notre systeme présente encore quelques faiblesses comme le montre
la précision pour les entités de types «organisation».

L'absence ou la non disponibilité des outils et des travaux de référence dans le domaine de
l'extraction des connaissances pour le traitement de l'arabe a été un vrai obstacle pour
mesurer la performance de notre systeme, et ne nous permet pas de comparer notre
approche avec les autres travaux. C'est la raison pour laquelle nous avons lancé des phases
de tests afin d'améliorer et de compléter l'extraction d'informations.

Une question engendrée par cette phase est : sur quel corpus peut-on tester notre module ?
Nous avons opté pour les corpus suivants :

— Corpus de textes sur Malika El-Aroud. Ce corpus est assez général et regroupe une
grande partie des concepts présents dans notre ontologie.

— Ensemble de corpus propres a chaque concept, composés d'articles journalistiques.
Ces corpus ne sont pas généraux mais peuvent permettre d'étudier et d'améliorer en
profondeur un type de concept. Les corpus spéciﬁques sont les suivants :
« arrestation », « attentat », « condamnation », « construction », « déces »,
« divorce », « émission », « mariage », « paiement », « rencontre » et « transfert ».

Aﬁn de recouvrir un maximum de cas tout en améliorant la reconnaissance et l'extraction
d'information, l'utilisation conjointe de ces deux types de corpus parait étre la meilleure
solution.

Citons l'exemple suivant : 3:-A «J53-‘Ii; 3-,u«-‘I33 «J;-Al on g;;>\-unja J’-2-in :3?‘-.I 34-.95 al it-U5! -Uh‘)? lkf g5;
U-u-,1}:-J. (A un stade ultérieur Umm Obeyda s'est mariée avec le frere Moez Garsallaoui
d'origine tunisienne et elle s'est installée (partie) avec lui en Suisse.)
Pour cet exemple, notre systeme extrait les connaissances suivantes:

— entités nommées de type Personne : Umm Obeyda et frere Moez Garsallaoui.

— entités nommée de type Lieu : Suisse

— concept «Union» extrait grace au verbe «cuﬁj» «se marier», avec deux bénéficiaires :
«Umm Obeyda » et « Moez Garsalloui».

— concept « Transfert » est extrait grace au verbe «d§1‘I|».

Voici la représentation des connaissances extraites, dans notre outil de visualisation :

3 http: / /users.dsic.upv.es / ~ybenajiba/ down1oads.html

.—.~—-——-
>'

«...a_:  . T 1 =5;
LL]

FIGURE 1 — Représentation des connaissances extraites, dans notre outil de visualisation.
C onclusio n

Nous avons décrit dans cet article un systeme d'extraction des connaissances dans des textes
arabes, basé d'une part sur une analyse linguistique profonde, et d'autre part sur une
extraction sémantique utilisant une ontologie du domaine. L'évaluation effectuée sur ces
premiers travaux nous a permis de déceler globalement la qualité de notre extraction mais
aussi de donner naissances a d'autres problématiques a étudier.

Notre approche a base de regles contextuelles atteint l'état de l'art pour l'extraction d'entités
nommées en arabe. Notre méthode d'extraction de connaissance montre le caractere
indispensable d'une analyse syntaxique profonde dans le repérage de telles informations.

Pour rendre notre systeme d'extraction plus complet, nous allons étendre l'analyse
syntaxique, en y ajoutant la recherche des antécédents des anaphores présentes dans les
textes. En effet, si les pronoms, utilisés fréquemment dans les textes pour éviter les
répétitions, ne sont pas liés a l'entité a laquelle ils font référence, nous risquons de perdre
beaucoup des informations présentes dans les textes. Il faut noter que les limites des
systemes linguistiques et statistiques actuels nous orientent vers une future combinaison de
ces approches pour une meilleure extraction. Nos travaux futurs s'orientent vers une
extension de notre systeme a d'autres domaines.

Remerciements

]e tiens a remercier l'Agence Nationale de la Recherche portant la référence ANR-09 -CSOSG-
08-01, pour son aide qu'elle nous a apportée pour mener a bien ce travail, ainsi que Mme
Aurélie Pradelles-Rossi et M Christian Fluhr.

Références

BENAJIBA, Y., et Rosso, P. (2007). ANERsys 2.0 : Conquering the NER Task for the Arabic
Language by Combining the Maximum Entropy with POS-tag Information. In Proc. Workshop

on Natural Language-Independent Engineering, 3rd Indian Int. Conf on Artiﬁcial
Intelligence, IICAI-2007, Pune, India, December 17-19.
BRUN, C., DESSAIGNE, N., EHRMANN, M., GAILLARD, B., GUILLEMIN-LANNE, S., IACQUET, G., KAPLAN, A.,
KUCHARSKI, M., MIGEOTTE, A., NAKAMURA, T. et VOYATZI, S. (2007). Une expérience de fusion
pour l'annotation d'entités nommées. Actes de TALN 2009 (Traitement automaﬁque des
langues naturelles), Senlis.

CHERFI, H. (2 004-). Etude et réalisation d'un systeme d'extraction de connaissances a partir de
textes. These de doctorat, novembre 2004-, L0 RIA, Nancy.

DEBILI, F. et ACHOUR, H. (1998). Voyellation automatique de l'arabe. In Proceedings of the
Workshop on Computaﬁonal Approaches to Semiﬁc Languagues. Montreal. Canada, pages
4-2-4-9.

DEBILI, F. et SOUISSI, E. (1998). Fltiquetage grammatical de l'arabe voyellé ou non.
Correspondance de l ’IRM C, N ‘’71. Tunis.

ELMAGARMID, A.K., Ipeirotis, P.G. et VERYKIOS, V.S. (2007). Duplicate record detection: A survey.
IEEE Transactions on Knowledge and data Engineering (TKDE). 19(1) pages 1-16.

KUZNIK, L., GUENET, A-L., PERADOTTO, A., et CLAVEL, C. (2010). L'apport des concepts métiers
pour la classiﬁcation des questions ouvertes d'enquéte. Actes de TALN 2010 (Traitement
automaﬁque des langues naturelles), Montréal, Canada .

MESFAR, S. (2008). Analyse morpho-syntaxique automatique et reconnaissance des entités
nommées en arabe standard. These de doctorat, novembre 2008.

MIKATI, Z. (2010). Du Data Mining au Sense mining : modele pour une analyse de la langue
arabe, et ses représentations formelles en vue d'une application a des données demandant
une haute sécurité. These de doctorat se, mai 2010.

SAADANE, H., ROSSI, A., FLUHR, C. et GUIDERE, M. (2012). Transcription of Arabic Names into
Latin. Actes the 6”’ in ternaﬁonal conference SE TI T2012 (Sciences of ElecU'onic, technologies
of Information and Telecommunications). March 2012. Sousse, Tunisia.

SAMY, D., MORENO, A. et MA GUIRAO, ]. (2005). A proposal for an Arabic named entity tagger
leveraging a parrallel corpus. In Proceedings of International Conference on Recent
Advances on Natural Language Processing RANLP '05. Borovets.

SEMMAR, N., GARA, F. et FLUHR, C. (2005). Linguistic resources and analysis for unvowelled
Arabic text processing in information retrieval. In Actes de 21"’ International Conference on
Machine Intelligence, ACID CA-ICMI-2005, Tozur (Tunisia), 5-7 Novembre 2005.

SHAALAN, K. et RAZA, H. (2009). NERA : Named entity recognition for arabic. journal of the
American Societyforlnformation Science and Technology, 60(9) : pages 1652-1663.
ZAGHOUANI, W., POULIQUEN, B., EBRAHIM, M. et STEINBERGER, R. (2010). Adapting a resource-
light highly multilingual named entity recognition system to arabic. Proceedings of the
Seventh conference on Internaﬁonal Language ressources and Evaluation (LRE C '1 0), pages
563-567.

ZITOUNI, I., SORENSEN, ]., LUO, X. et FLORIAN, R. (2005). The impact of morphological stemming
on Arabic mention detection and coreference resolution. In Proceedings of Workshop on
Computational Approaches to Semiﬁc Languages, pages 63-70, Ann Arbor, Michigan.
ZMANTAR, Y. et DICHY, ]. (2009). L'analyse automatique des mots-outils en arabe.2éme
conférence Internationale — Systémes d ’informaa'on et Intelligence Economique 2009.
Hammamet,Tunisia.

