@proceedings{TALN:2000,
  editor    = {Wehrli, Éric},
  title     = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000}
}

@inproceedings{hahn:2000:TALN,
  author    = {Hahn, Udo},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-invite-001},
  language  = {french},
  note      = {Emerging Content Management Technologies},
  resume    = {},
  abstract  = {Recent advances in language engineering have led to diverse techniques by which content items in written documents can be tracked and managed. Some of these techniques elaborate on fairly standard information retrieval methodologies (tf-idf, vector space model, etc.), though different applications are envisaged (e.g., filtering, notification or recommender systems). Current efforts also target on systems which provide automatic summarization based on the extraction of sentences (or phrases). Finally, information extraction is concerned with methodologies to extract relevant data from textual sources. In this talk, some of the core techniques for content tracking and management are identified, evaluation results are presented, and open challenges are discussed.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{elbeze:2000:TALN,
  author    = {El-Bèze, Marc},
  title     = {Entre corpus annoté et lexique sémantique, quelles options pour le TALN ?},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-invite-002},
  language  = {french},
  resume    = {Il est communément admis que la tâche de désambiguïsation sémantique n'est pas une fin en soi. Pour tenter d'apporter un début de solution à ce problème reconnu comme très difficile, de nombreux systèmes ont été développés. Pour la plupart, ces systèmes sont destinés à être les composants de systèmes plus complexes (moteurs de recherche d'information, de dialogue personne-machine, ou d'aide à la traduction). Néanmoins, ils sont testés en tant que tels dans le cadre de campagnes d'évaluation, comme par exemple Senseval ou Romanseval. La seconde édition de ces campagnes est d'ores et déjà planifiée. De fait, on est en droit de se demander - sans pour autant vouloir chercher à enrayer le mouvement -, si la désambiguïsation sémantique a un sens, et si oui lequel. Il ne faut pas voir dans ce questionnement un jeu de mots gratuit, mais bien la nécessité de soumettre à l'examen une pratique dans laquelle s'engagent de plus en plus de chercheurs, qu'ils soient linguistes ou informaticiens. Si l'on s'en tient au protocole suivi lors de la première campagne d'évaluation de Senseval, on peut dégager de ses caractéristiques un certain nombre d'observations qui peuvent alimenter la réflexion. Une quarantaine de mots appartenant à l'une ou l'autre de trois catégories grammaticales avait été retenue : les noms, les verbes et les adjectifs. Pour chacun de ces mots était fournie une liste d'étiquettes sémantiques et pour couvrir l'ensemble de ces sens, en moyenne, une centaine d'exemples étiquetés ainsi qu'une définition pour chaque étiquette. Pour chaque mot, enfin une centaine d'exemples de tests devaient être étiquetés par les différents systèmes en lice. Pour un mot donné, les étiquettes pouvaient entretenir des relations de type hiérarchique, ce qui permettait d'évaluer les systèmes à trois niveaux  de granularité : fin, grossier, et intermédiaire. Une remarque préalable concerne le corpus d'apprentissage disponible pour chacun des mots. Pour un mot donné, seul le mot en question était étiqueté. Pour les mots du contexte aucune étiquette sémantique n'était proposée. Les annotations sémantiques posées par des juges humains sur chacun des exemples relatifs à un mot particulier, avait fait l'objet d'un arbitrage, et quand cela  s'avérait impossible plusieurs étiquettes sémantiques avaient été maintenues. Enfin, détail qui peut avoir son importance : les étiquettes sémantiques utilisées pour annoter le corpus d'apprentissage étaient plus fines que celles qui étaient employés pour le niveau le plus fin d'évaluation. Notre propos n'est pas ici de décrire ifficultés à mettre en relation des définitions et des emplois de mots en contexte .Une des significations d'un mot employé dans un contexte particulier peut se trouver absente de la ressource pour plusieurs raisons. Les lacunes des dictionnaires ont  suffisamment été pointées du doigt à diverses reprises, pour qu'il soit nécessaire d'en rajouter sur le sujet. Par essence, une ressource finie ne peut couvrir toutes les productions résultant des capacités créatives qui s'exercent sur les langages naturels. Certains usages langagiers correspondent à des nuances fines dont il est difficile de rendre compte dans un lexique où par contre figurent souvent des acceptions qui n'ont plus cours. Par ailleurs, il n'y a pas de découpage unique d'un mot en unités de sens. Il suffit pour s'en convaincre de comparer les choix faits par différents dictionnaires. Mais, le problème est plus complexe que cela. En analysant le fonctionnement des métaphores, on peut expliquer comment certaines figures de style permettent de rajouter un sens (le plus souvent figuré) à un mot tout en maintenant en partie son sens premier. Ces évidences expliquent en grande partie la complexité de la relation entre étiquetage et choix d'étiquettes sémantiques. Les méthodes numériques ont leur mot à dire pour tenter de trouver une voie entre lexique et corpus annoté. Toute approche qui entre dans cette catégorie peut non seulement permettre de choisir une étiquette parmi plusieurs, mais aussi servir à classer toutes les étiquettes candidates soit par calcul de distances ou de vraisemblances. Si la méthode retenue est de ce type, le vecteur final associé à un exemple peut être vu comme un moyen de localiser un emploi particulier dans l'espace déterminé par la base que forment les étiquettes sémantiques. Par le biais d'une analyse en composantes principales ou d'une analyse discriminante, des axes orthogonaux peuvent être dégagés un à un, axes correspondant à un compromis entre le jeu d'étiquettes initial et les exemples présents dans le corpus annoté. Même si le processus n'a pas tendance à converger, il ne serait peut-être pas inutile de de le voir comme une étape parmi d'autres d'une procédure itérative appliquée s'il le faut sur des données mouvantes afin de reproduire les aspects dynamiques de toute langue vivante. Si l'on accepte l'idée que Numérique et Métrique ont un rôle à jouer dans le domaine de la Sémantique, il est possible de voir le problème de la désambiguïsation sémantique comme formant un tout avec celui du choix des étiquettes. La question ne serait plus comment choisir entre tel ou tel sens pour un emploi donné, mais dans quelle région se situe cet emploi, sachant que la somme des usages aura tendance à modifier l'espace lui-même, dès qu'il sera patent qu'il aura été pour une raison ou pour autre, sous ou sur dimensionné.},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{danlos-gaiffe:2000:TALN,
  author    = {Danlos, Laurence and Gaiffe, Bertrand},
  title     = {Coréférence événementielle et relations de discours},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-001},
  language  = {french},
  resume    = {La coréférence événementielle est un phénomène largement ignoré tant dans les travaux sur la coréférence que dans ceux sur l'ordre temporel dans le discours. Pourtant, la coréférence événementielle est la clef de voûte sur laquelle reposent au moins quatre types de discours. Les descriptions et analyses linguistiques de ces discours permettront de mettre en avant des phénomènes linguistiques inhabituels (e.g. coréférence entre éléments quantifiés existentiellement). Les relations de discours qui sont en jeu seront ensuite examinées. Cette étude nous amènera à introduire et définir de nouvelles relations de discours qui seront discutées dans le cadre de la SDRT.},
  abstract  = {},
  motscles  = {coréférence événementielle, relation de discours, relation de coréférence},
  keywords  = {},
}

@inproceedings{schauer:2000:TALN,
  author    = {Schauer, Holger},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-002},
  language  = {french},
  note      = {Referential Structure and Coherence Structure},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{burstein-marcu:2000:TALN,
  author    = {Burstein, Jill and Marcu, Daniel},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-003},
  language  = {french},
  note      = {Toward Using Text Summarization for Essay-Based Feedback},
  resume    = {},
  abstract  = {We empirically study the impact of using automatically generated summaries in the context of electronic essay rating. Our results indicate that 40% and 60% discourse-based essay summaries improve the performance of the topical analysis module of e-rater. E-rater is a system that electronically scores GMAT essays. We envision using automatically generated essay summaries for instructional feedback, as a supplement to the e-rater score.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{stein-bagga-wise:2000:TALN,
  author    = {Stein, Gees C. and Bagga, Amit and Wise, G. Bowden},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-004},
  language  = {french},
  note      = {Multi-Document Summarization: Methodologies and Evaluations},
  resume    = {},
  abstract  = {This paper describes a system for the summarization of multiple documents. The system produces multi-document summaries using clustering techniques to identify common themes across the set of documents. For each theme, the system identifies representative passages that are included in the final summary. We also describe a methodology for evaluation of our system which is based upon a question answering task. Results of our evaluation are also presented.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{koit-oim:2000:TALN,
  author    = {Koit, Mare and Oim, Hadur},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-005},
  language  = {french},
  note      = {Reasoning in Interaction: A Model of Dialogue},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{kurdi:2000:TALN,
  author    = {Kurdi, Mohamed-Zakaria},
  title     = {La grammaire sémantique d'unification d'arbres: un formalisme pour l'analyse des dialogues oraux spontanés},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-006},
  language  = {french},
  resume    = {Cet article porte sur la grammaire sémantique d'unification d'arbres (STUO). 11 s'agit d'un formalisme que nous proposons comme une alternative aux approches simplificatrices menées dans le contexte du traitement automatique de la parole ainsi qu'aux approches à base de grammaires classiques qui sont généralement non adaptées au traitement de l'oral. La motivation essentielle de ce formalisme est la combinaison de la robustesse et la simplicité des grammaires sémantiques à la profondeur des grammaires classiques. Les propriétés essentielles de ce formalisme sont : une interaction directe entre la syntaxe et la sémantique, un système de traits économique et une simplicité tant de la mise en oeuvre de la grammaire que pour sa modification. La STUG a été implémentée au sein du système OASIS qui est un système d'analyse partielle de la parole spontanée. Les résultats de l'évaluation ont montré la bonne couverture de notre grammaire tant au niveau des arbres analysés qu'au niveau lexical ainsi que l'efficacité de cette grammaire pour la desambiguïsation et pour l'évitement des erreurs dans l'entrée.},
  abstract  = {},
  motscles  = {grammaire, grammaire sémantique, unification d'arbres, parole, parole spontanée, ambiguïté contextuelle},
  keywords  = {},
}

@inproceedings{ciressan-EtAl:2000:TALN,
  author    = {Ciressan, Cristian and Rajman, Martin and Sanchez, Eduardo and Chappelier, Jean-Cédric},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-007},
  language  = {french},
  note      = {Towards NLP co-processing: An FPGA implementation of a context-free parser},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{kempe:2000:TALN,
  author    = {Kempe, André},
  title     = {Reduction of Intermediate Alphabets in Finite-State Transducer Cascades},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-008},
  language  = {french},
  resume    = {},
  abstract  = {This article describes an algorithm for reducing the intermediate alphabets in cascades of finite-state transducers (FSTs). Although the method modifies the component FSTs, there is no change in the overall relation described by the whole cascade. No additional information or special algorithm, that could decelerate the processing of input, is required at runtime. Two examples from Natural Language Processing are used to illustrate the effect of the algorithm on the sizes of the FSTs and their alphabets. With some FSTs the number of arcs and symbols shrank considerably.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{illouz:2000:TALN,
  author    = {Illouz, Gabriel},
  title     = {Vers un apprentissage en TALN dépendant du type de Texte},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-009},
  language  = {french},
  resume    = {Dans cet article, nous présentons la problématique de l’hétérogénéité des données textuelles et la possibilité d’utiliser cette dernière pour améliorer les traitements automatiques du langage naturel. Cette hypothèse a été abordée dans (Biber, 1993) et a donné lieu à une première vérification empirique dans (Sekine, 1998). Cette vérification a pour limite de ne s’adapter qu’à des textes dont le type est explicitement marqué. Dans le cadre de textes tout venant, nous proposons une méthode pour induire des types de textes, apprendre des traitements spécifiques à ces types puis, de façon itérative, en améliorer les performances.},
  abstract  = {},
  motscles  = {annotation morpho-syntaxique, type de texte, linguistique de corpus, apprentissage, classification},
  keywords  = {},
}

@inproceedings{morin:2000:TALN,
  author    = {Morin, Emmanuel},
  title     = {Complémentarité des approches supervisées et non supervisées pour l'acquisition de relations entre termes},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-010},
  language  = {french},
  resume    = {Cet article a pour objectif de préciser la complémentarité des approches supervisées et non supervisées utilisées en structuration terminologique pour extraire des relations entre termes. Cette étude est réalisée sur un exemple concret où nous cherchons à faire ressortir les avantages et les inconvénients de chaque approche. Au terme de cette analyse, nous proposons un cadre pour les employer de façon synergique.},
  abstract  = {},
  motscles  = {analyse distributionnelle, terminologie, relation conceptuelle entre termes, extraction, extraction de couple},
  keywords  = {},
}

@inproceedings{poibeau:2000:TALN,
  author    = {Poibeau, Thierry},
  title     = {De l'acquisition de classes lexicales à l'induction semi-automatique de grammaires locales},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-011},
  language  = {french},
  resume    = {Cette étude vise à automatiser partiellement l'acquisition de ressources pour un système d'extraction fondé sur la boîte à outils INTEX. Les processus d'apprentissage mis en oeuvre sont symboliques, supervisés et fortement interactifs afin de n'apprendre que ce qui est utile pour la tâche. Nous examinons d'abord la notion d'automate patron, permettant l'acquisition d'éléments apparaissant dans des contextes similaires, nous proposons ensuite plusieurs mécanismes de généralisation avant d'envisager l'induction semi-automatique de grammaires locales.},
  abstract  = {},
  motscles  = {grammaire, grammaire locale, acquisition de classes, classes lexicales, corpus, automate, automate patron, induction de grammaire},
  keywords  = {},
}

@inproceedings{damova-bergler:2000:TALN,
  author    = {Damova, Mariana and Bergler, Sabine},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-012},
  language  = {french},
  note      = {The Aspectual Type BEGIN},
  resume    = {},
  abstract  = {This paper deals with the notion of aspect as it is understood in the eventuality structure based formal approaches to aspect. These approaches typically link aspect to the interpretation of the philosophical and ontological notion of event, seen as a conceptual entity with rigid edges: beginning, protraction and end, and analyse and study extensively the end part of events ((Vendler, 1967),(Moens \& Steedman, 1988), (Smith, 1991), (Pustejovsky, 1991), (Krifka, 1989), (Partee, 1984), (Hinrichs, 1986), etc.). The beginning, a semantic counterpart of the culmination on the other hand, has not been discussed so much at large. We analyse various language means that convey beginning and argue for the need of a mechanism to provide a uniform interpretation for them. We define the aspectual type BEGIN, and develop its semantic representation along the general lines of accounts of temporal reference of Discourse Representation Theory ((Kamp, 1979); (Kamp \& Reyle, 1993)). We extend the DRT analysis of tense and aspect in postulating a three layered formal representation for aspect. The aspectual type BEGIN introduces a DRS aspectual operator, instead of a temporal discourse referent. We embed its explicit event structure into the operator’s definition, by adopting Pustejovsky’s formalisation (Pustejovsky, 1995). We show that the proposed approach represents the aspectual type BEGIN correctly across categories, that is, it works on all relevant levels: lexical semantics, grammatical devices, secondary predication, discourse, and it covers the semantics of BEGIN in a uniform way.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{fong-fellbaum-lebeaux:2000:TALN,
  author    = {Fong, Sandiway and Fellbaum, Christiane and Lebeaux, David},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-013},
  language  = {french},
  note      = {Semantic Templates and Transitivity Alternations in a Computational Lexicon},
  resume    = {},
  abstract  = {A systematic and principled account of verb subcategorization is important for largescale lexicon construction. A given verb may have several subcategorization frames in which its arguments appear. Starting from a lexical-semantic description of event structure, we describe a mechanism for generating subcategorization properties for a large variety of verb classes. In this paper, we motivate this mechanism by proposing a distinction between two kinds of resultative as well as the unaccusative and middle constructions.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{lai:2000:TALN,
  author    = {Laï, Claude},
  title     = {Propagation de traits conceptuels au moyen des métastructures Prolog},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-014},
  language  = {french},
  resume    = {Après avoir effectué une description des métastructures Prolog, nous montrons leur utilité dans le domaine du Traitement Automatique du Langage Naturel, et plus précisément dans la propagation de traits conceptuels complexes comme l'appartenance des individus à des domaines pouvant faire intervenir des unions de produits cartésiens d'ensembles.},
  abstract  = {},
  motscles  = {métastructure Prolog, langage, langage naturel, programmation, programmation par contrainte, produit cartésien},
  keywords  = {},
}

@inproceedings{savoy-rasolofo:2000:TALN,
  author    = {Savoy, Jacques and Rasolofo, Yves},
  title     = {Recherche d'informations dans un environnement distribué},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-015},
  language  = {french},
  resume    = {Le Web ou les bibliothèques numériques offrent la possibilité d'interroger de nombreux serveurs d'information (collections ou moteurs de recherche) soulevant l'épineux problème de la sélection des meilleures sources de documents et de la fusion des résultats provenant de différents serveurs interrogés. Dans cet article, nous présentons un nouvelle approche pour la sélection des collections basée sur les arbres de décision. De plus, nous avons évalué différentes stratégies de fusion et de sélection permettant une meilleure vue d'ensemble des différentes solutions.},
  abstract  = {The Web and digital libraries offer the possibility to send natural language queries to various information servers (corpora or search engines) raising the difficult problem of selecting the best document sources and merging the results provided by different servers. In this paper, a new approach for collections selection based on decision trees is described. Moreover, different merging and selection procedures have been evaluated leading to an overview of the suggested approaches.},
  motscles  = {recherche d'information, modèle vectoriel, arbre, arbre de décision, moteur de recherche, indexation},
  keywords  = {},
}

@inproceedings{l'haire-mengon-laenzlinger:2000:TALN,
  author    = {L'haire, Sébastien and Mengon, Juri and Laenzlinger, Christopher},
  title     = {Outils génériques et transfert hybride pour la traduction automatique sur Internet},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-016},
  language  = {french},
  resume    = {Dans cet article, nous décrivons un système de traduction automatique pour l’allemand, le français, l’italien et l’anglais. Nous utilisons la technique classique analyse-transfert-génération. Les phrases d’entrée sont analysées par un analyseur générique multilingue basé sur la théorie ((Principes \& Paramètres)) de la grammaire générative chomskienne. Le mécanisme de transfert agit sur des représentations hybrides qui combinent des éléments lexicaux avec de l’information sémantique abstraite. Enfin, un générateur inspiré de la même théorie linguistique engendre des phrases de sortie correctes. Nous décrivons également brièvement les différentes interfaces envisagées sur Internet.},
  abstract  = {},
  motscles  = {traduction, traduction automatique, transfert lexico-structural, sémantique, éléments lexicaux},
  keywords  = {},
}

@inproceedings{maillat:2000:TALN,
  author    = {Maillat, Didier},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-017},
  language  = {french},
  note      = {Computing the Spatial Frame of Reference: How to Interpret Directional Prepositions},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{mathet:2000:TALN,
  author    = {Mathet, Yann},
  title     = {Le paradigme monodimensionnel dans l'expression de l'espace et du déplacement},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-018},
  language  = {french},
  resume    = {La sémantique de certains verbes (doubler, distancer, suivre) et de certaines prépositions ou adverbes (devant, derrière) peut poser problème dès lors qu'elle est considérée comme purement spatiale, c'est-à-dire en des termes " classiques " comme la topologie, le repérage ou la distance. Nous proposons dans cet article une description plus générale de ces items lexicaux basée sur la notion d'axe abstrait, rendant compte de leur sens dans différents domaines, ainsi que les différents mécanismes permettant de les plonger dans le domaine qui concerne notre recherche, le spatio-temporel. Ces mécanismes sont intégrés dans un modèle informatique de génération automatique de prédicats verbaux afin d'éprouver leur pertinence.},
  abstract  = {},
  motscles  = {paradigme monodimensionnel, prédication monodimensionnelle, prédicat, prédicat verbal, sémantique},
  keywords  = {},
}

@inproceedings{blache:2000:TALN,
  author    = {Blache, Philippe},
  title     = {Le rôle des contraintes dans les théories linguistiques et leur intérêt pour l'analyse automatique},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-019},
  language  = {french},
  resume    = {Tous les formalismes linguistiques font usage de la notion de contrainte qui, dans son sens le plus large, indique une propriété devant être satisfaite. Les contraintes sont extrêmement utiles à la fois pour représenter l’information linguistique, mais également pour en contrôler le processus d’analyse. Cependant, l’usage qui est fait des contraintes peut être très différent d’une approche à l’autre : dans certains cas, il s’agit simplement d’un mécanisme d’appoint, dans d’autres, les contraintes sont au coeur de la théorie. Il existe cependant un certain nombre de restrictions à leur utilisation, en particulier pour ce qui concerne leur implantation. Plus précisément, s’il semble naturel (au moins dans certains paradigmes) de considérer l’analyse syntaxique comme un problème de satisfaction de contraintes, on constate cependant qu’il est extrêmement difficile de réaliser concrètement une telle implantation. Ce constat est en fait révélateur d’un problème dépassant le simple cadre de l’implémentation : nous montrons dans cet article qu’une approche totalement basée sur les contraintes (permettant donc de concevoir l’analyse comme un problème de satisfaction) est incompatible avec une interprétation générative classique accordant un statut particulier à la relation de dominance. Nous proposons ici un cadre permettant à la fois de tirer parti des avantages des grammaires syntagmatiques tout en s’affranchissant des problèmes liés aux approches génératives pour ce qui concerne l’usage des contraintes en tant qu’unique composant grammatical. Nous présentons ici cette approche, les Grammaires de Propriétés, ainsi que leur implémentation.},
  abstract  = {},
  motscles  = {contrainte contextuelle, grammaire, grammaire de propriétés, relation de dépendance, grammaire de dépendance},
  keywords  = {},
}

@inproceedings{etchegoyhen:2000:TALN,
  author    = {Etchegoyhen, Thierry},
  title     = {Analyse Syntaxique Monotone par Décisions Différées},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-020},
  language  = {french},
  resume    = {Dans cet article nous présentons une approche à l'analyse syntaxique automatique où la levée d'ambiguïtés est différée jusqu'à l'apparition d'éléments de la chaîne d'entrée permettant de procéder à une analyse correcte, la désambiguisation étant alors effectuée en cascade. L'analyseur a pour caractéristiques une croissance monotone de l'information syntaxique au fil de l'analyse, la garantie de ne pas échouer sur des phrases grammaticales telles les phrases-labyrinthe, et une faible complexité computationnelle. Le système présenté cumule ainsi les avantages d'une approche déterministe (efficacité et optimisation des calculs) et ceux d'une approche non-déterministe (adéquation empirique).},
  abstract  = {},
  motscles  = {analyse syntaxique, analyse syntaxique monotone, désambiguïsation, désambiguïsation syntaxique, levée d'ambiguïté structurelle},
  keywords  = {},
}

@inproceedings{kahane:2000:TALN,
  author    = {Kahane, Sylvain},
  title     = {Des grammaires pour définir une correspondance: un point de vue mathématique et épistémologique},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-021},
  language  = {french},
  resume    = {Dans cet article nous introduisons la notion de grammaire transductive, c'est-à-dire une grammaire formelle définissant une correspondance entre deux familles de structures. L'accent sera mis sur le module syntaxique de la théorie Sens-Texte et sur une famille élémentaire de grammaires de dépendance transductives. Nous nous intéresserons à la comparaison avec les grammaires génératives, ce qui nous amènera à discuter de l'interprétation des modèles génératifs actuels.},
  abstract  = {},
  motscles  = {grammaire, grammaire transductive, grammaire générative, grammaire formelle, grammaire de dépendance, lexie},
  keywords  = {},
}

@inproceedings{cerbah:2000:TALN,
  author    = {Cerbah, Farid},
  title     = {Une étude comparative de méthodes de catégorisation sémantique de termes techniques},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-022},
  language  = {french},
  resume    = {L'acquisition et la mise à jour de ressources terminologiques sont des tâches difficiles, en particulier lorsque ces ressources contiennent des informations d'ordre sémantique. Cette article traite de la catégorisation sémantique de termes techniques. Le but de ce processus est d'assigner des domaines sémantiques à de nouveaux termes. Nous proposons deux approches qui reposent sur des sources d'informations différentes. L'approche exogène exploite des informations contextuelles extraites de corpus. L'approche endogène repose sur une analyse lexicale de termes déjà catégorisés. Nous décrivons les deux approches mises en oeuvre ainsi que les expérimentations menées sur des jeux de test significatifs. Les résultats obtenus montrent que la catégorisation de termes peut constituer une aide conséquente dans les processus d'acquisition de ressources terminologiques.},
  abstract  = {},
  motscles  = {acquisition de termes techniques, terminologie, analyse lexicale, corpus},
  keywords  = {},
}

@inproceedings{dechalendar-grau:2000:TALN,
  author    = {De Chalendar, Gaël and Grau, Brigitte},
  title     = {SVETLAN' ou Comment Classer les Mots en fonction de leur Contexte},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-023},
  language  = {french},
  resume    = {L’utilisation de connaissances sémantiques dans les applications de TAL améliore leurs performances. Cependant, bien que des lexiques étendus aient été développés, il y a peu de ressources non dédiées à des domaines spécialisés et contenant des informations sémantiques pour les mots. Dans le but de construire une telle base, nous avons conçu le système SVETLAN’, capable d’apprendre des catégories de noms à partir de textes, quel que soit leur domaine. Dans le but d’éviter de créer des classes générales regroupant tous les sens des mots, les classes sont apprises en fonction de l’usage des mots en contexte.},
  abstract  = {},
  motscles  = {sémantique, langue, langue générale, segment textuel, module d'apprentissage},
  keywords  = {},
}

@inproceedings{paroubek-rajman:2000:TALN,
  author    = {Paroubek, Patrick and Rajman, Martin},
  title     = {MULTITAG, une ressource linguistique produit du paradigme d'évaluation},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-024},
  language  = {french},
  resume    = {Dans cet article, nous montrons comment le paradigme d'évaluation peut servir pour produire de façon plus économique des ressources linguistiques validées de grande qualité. Tous d'abord nous présentons le paradigme d'évaluation et rappelons les points essentiels de son histoire pour le traitement automatique des langues, depuis les premières applications dans le cadre des campagnes d'évaluation américaines organisées par le NIST et le DARPA jusqu'aux derniers efforts européens en la matière. Nous présentons ensuite le principe qui permet de produire à coût réduit des ressources linguistiques validées et de grande qualité à partir des données qui sont produites lorsque l'on applique le paradigme d'évaluation. Ce principe trouve ses origines dans les expériences (Recognizer Output Voting Error Recognition) qui ont été effectuées pendant les campagnes d'évaluation américaine pour la reconnaissance automatique de la parole. Il consiste à combiner les données produites par les systèmes à l'aide d'une simple stratégie de vote pour diminuer le nombre d'erreurs. Nous faisons alors un lien avec les stratégies d'apprentissages automatiques fondées sur la combinaison de systèmes de même nature. Notre propos est illustré par la description de la production du corpus MULTITAG (projet du programme Ingénierie des Langues des département SPI et SHS du CNRS) à partir des données qui avaient été annotées lors de la campagne d'évaluation GRACE, correspondant à un corpus d'environ 1 million de mots annotés avec un jeu d'étiquettes morpho-syntaxiques de grain très fin dérivé de celui qui a été défini dans les projets EAGLES et MULTEXT. Nous présentons le corpus MULTITAG et la procédure qui a été suivie pour sa production et sa validation. Nous concluons en présentant le gain obtenu par rapport à une méthode classique de validation de marquage morho-syntaxique.},
  abstract  = {},
  motscles  = {paradigme d'évaluation, campagne d'évaluation, système d'annotation, corpus},
  keywords  = {},
}

@inproceedings{aloulou-hadrichbelguith-benhamadou:2000:TALN,
  author    = {Aloulou, Chafik and Hadrich Belguith, Lamia and Ben Hamadou, Abdelmajid},
  title     = {Vers un système d'analyse syntaxique robuste pour l'Arabe},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-025},
  language  = {french},
  resume    = {Le degré de profondeur et de finesse de l'analyse syntaxique d'un texte écrit dépend énormément de l'objectif de l'analyse (analyse globale, analyse partielle, analyse détaillée, etc.) ainsi que du type d'application nécessitant cette analyse. Dans cet article, nous présentons une approche originale d'analyse syntaxique robuste appliquée à l'arabe et basée sur l'architecture multiagent. Comme première application de notre approche, notre système sera couplé avec un système de reconnaissance de l'écriture arabe dans le but d'effectuer, d'une part, la validation linguistique des mots reconnus par l'OCR (Optical Character Recognition) et d'autre part la détection et la correction des erreurs d'ordre lexicales, morphologiques, syntaxiques (cas des erreurs d'accord) et qui sont dues à la non ou au mal reconnaissance de certains mots par l'OCR. Le couplage de notre système avec le système de reconnaissance de l'écriture arabe entre dans le cadre d'un projet de coopération avec l'équipe Perception, Système et Information (PSI) de l'université de Rouen.},
  abstract  = {},
  motscles  = {analyse syntaxique, analyse syntaxique robuste, langue, langue arabe, corpus, système de reconnaissance, système de reconnaissance de l'écriture arabe},
  keywords  = {},
}

@inproceedings{bechet-nasr-genet:2000:TALN,
  author    = {Béchet, Frédéric and Nasr, Alexis and Genet, Franck},
  title     = {Enrichissement automatique de lexique de noms propres à partir de corpus},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-026},
  language  = {french},
  resume    = {Cet article présente une méthode d’étiquetage sémantique de noms propres fondé sur la technique des arbres de décision. Ces derniers permettent de modéliser les éléments saillants dans les contextes d’occurrence de noms propres d’une classe donnée. Les arbres de décision sont construits automatiquement sur un corpus d’apprentissage étiqueté, ils sont ensuite utilisés pour étiqueter des noms propres apparaissant dans un corpus de test. Les résultats de l’étiquetage du corpus de test est utilisé pour enrichir un lexique de noms propres. Ce dernier peut être utilisé à son tour pour réestimer les paramètres d’un étiqueteur stochastique. Nous nous intéressons en particulier au cas où le corpus de test a été glané sur le Web.},
  abstract  = {},
  motscles  = {expression régulière, entrée lexicale, étiquetage, arbre, arbre de décision, corpus, corpus de test},
  keywords  = {},
}

@inproceedings{delmonte:2000:TALN,
  author    = {Delmonte, Rodolfo},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-027},
  language  = {french},
  note      = {Parsing with Getarun},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{kraif:2000:TALN,
  author    = {Kraif, Olivier},
  title     = {Extraction automatique de correspondances lexicales: évaluation d'indices et d'algorithmes},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-028},
  language  = {french},
  resume    = {Les bi-textes sont des corpus bilingues parallèles, généralement segmentés et alignés au niveau des phrases. Une des applications les plus directes de ces corpus consiste à en extraire automatiquement des correspondances lexicales, fournissant une information utile aux traducteurs, aux lexicographes comme aux terminologues. Comme pour l’alignement, des méthodes statistiques ont donné de bons résultats dans ce domaine. Nous pensons qu’une exploitation judicieuse d’indices statistiques adaptés et d’algorithmes de conception simple permet d’obtenir des correspondances fiables. Après avoir présenté les indices classiques, auxquels nous essayons d’apporter des améliorations, nous proposons dans cette article une étude empirique destinée à en montrer les potentialités.},
  abstract  = {},
  motscles  = {extraction, extraction automatique de correspondances lexicales, alignement, alignement lexical, lexicographie, relation de traduction},
  keywords  = {},
}

@inproceedings{vandeventer:2000:TALN,
  author    = {Vandeventer, Anne},
  title     = {Diagnostic d'erreurs grammaticales par relâchement de contraintes dans le cadre de l'ELAO},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-029},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{jacquemin-bush:2000:TALN,
  author    = {Jacquemin, Christian and Bush, Caroline},
  title     = {Fouille du Web pour la collecte d'Entités Nommées},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-030},
  language  = {french},
  resume    = {Cette étude porte sur l’acquisition des Entités Nommées (EN) à partir du Web. L’application présentée se compose d’un moissonneur de pages et de trois analyseurs surfaciques dédiés à des structures spécifiques. Deux évaluations sont proposées : une évaluation de la productivité des moteurs en fonction des types d’EN et une mesure de la précision.},
  abstract  = {},
  motscles  = {entité nommée, expression régulière, acquisition lexicale, marqueur, marqueur discursif, moteur de recherche},
  keywords  = {},
}

@inproceedings{carsonberndsen-walsh:2000:TALN,
  author    = {Carson-Berndsen, Julie and Walsh, Michael},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-031},
  language  = {french},
  note      = {Generic Techniques for Multilingual Speech Technology Applications},
  resume    = {},
  abstract  = {This paper is concerned with generic techniques for representing and evaluating phonological information in multilingual speech technology applications. A computational linguistic model of phonological interpretation is enhanced by a framework for constructing and evaluating phonotactic automata and by a generic lexicon model. The techniques make way for the extension of current speech technology to languages which have received little attention thus far.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{basili-moschitti-pazienza:2000:TALN,
  author    = {Basili, Roberto and Moschitti, Alessandro and Pazienza, Maria Teresa},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-032},
  language  = {french},
  note      = {Modeling Terminological Information in Text Classification},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{kurdi:2000:TALN,
  author    = {Kurdi, Mohamed-Zakaria},
  title     = {Une approche intégrée pour la normalisation des extragrammaticalités de la parole spontanée},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-033},
  language  = {french},
  resume    = {Dans cet article, nous présentons une nouvelle approche pour la normalisation des extragrammaticalités de la parole. La particularité de cène approche est l'intégration de différentes sources de connaissances de haut niveau, en particulier le lexique, la syntaxe et la sémantique. Ainsi, le traitement des extragrammaticalités se déroule suivant deux étapes : dans la première, le système normalise les Extragrammaticalités Lexicales (Eis) (hésitations, amalgames, etc.) et dans la deuxième, le système détecte et corrige les Extragrammaticalités Supra Lexicales (ESLs). Ce traitement est base sur des modèles de ESLs (règles et pattems) qui considèrent à la fois les informations syntaxiques et les informations structurales dans la détection et la correction des extragrammaticalités. De même, le système a été doté de patterns de contrôle ainsi que de grammaires sémantiques afin de réduire au maximum la surgénérativité. Les résultats de l'évaluation ont montré l'efficacité de notre approche à détecter et à corriger les extragrammaticalités tout en évitant les cas de surgénérativité.},
  abstract  = {},
  motscles  = {parole, parole spontanée, extragrammaticalité lexicale, corpus, corpus d'apprentissage, information, information structurale},
  keywords  = {},
}

@inproceedings{copeck-EtAl:2000:TALN,
  author    = {Copeck, Terry and Barker, Ken and Delisle, Sylvain and Szpakowicz, Stan},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-034},
  language  = {french},
  note      = {Automating the Measurement of Linguistic Features to Help Classify Texts as Technical},
  resume    = {},
  abstract  = {Text classification plays a central role in software systems which perform automatic information classification and retrieval. Occurrences of linguistic feature values must be counted by any mechanism that classifies or characterizes natural language text by topic, style, genre or, in our case, by the degree to which a text is technical. We discuss the methodology and key details of the feature value extraction process, paying attention to fast and reliable implementation. Our results are mixed but support continued investigation— while a significant level of automation has been achieved, the successfully extracted feature counts do not always correlate with technicality as strongly as anticipated.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{tiberius-evans:2000:TALN,
  author    = {Tiberius, Carole and Evans, Roger},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-035},
  language  = {french},
  note      = {Phonological feature based multilingual lexical description},
  resume    = {},
  abstract  = {This paper presents a framework for compactly describing word forms in terms of phonological features. Using a highly modular default-inheritance based approach, the framework supports the description of lexical generalisations traditionally modelled as morphology and phonology in a single phonology-based representation. This representation is more uniform and more detailed than previous approaches of this kind, allowing us to capture generalisations within a language and between related language elegantly and flexibly. The framework is illustrated with examples taken from English, German, Dutch and Danish.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{ferret-grau:2000:TALN,
  author    = {Ferret, Olivier and Grau, Brigitte},
  title     = {Une analyse thématique fondée sur un principe d'amorçage},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-long-036},
  language  = {french},
  resume    = {L'analyse thématique est une étape importante pour de nombreuses applications en traitement automatique des langues, telles que le résumé ou l'extraction d'information par exemple. Elle ne peut être réalisée avec une bonne précision qu'en exploitant une source de connaissances structurées sur les thèmes, laquelle est difficile à constituer à une large échelle. Dans cet article, nous proposons de résoudre ce problème par un principe d'amorçage : une première analyse thématique, fondée sur l'utilisation d'une source de connaissances faiblement structurée mais relativement aisée à construire, un réseau de collocations, permet d'apprendre des représentations explicites de thèmes, appelées signatures thématiques. Ces dernières sont ensuite utilisées pour mettre en oeuvre une seconde analyse thématique, plus précise et plus fiable.},
  abstract  = {},
  motscles  = {analyse thématique, cohésion lexicale, focalisation, réseau de collocations},
  keywords  = {},
}

@inproceedings{mertens:2000:TALN,
  author    = {Mertens, Piet},
  title     = {Intonation et syntaxe: traitement automatique pour la synthèse de la parole},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-tutoriel-001},
  language  = {french},
  note      = {Intonation and syntax: natural language processing for speech synthesis},
  resume    = {Le tutoriel se propose de décrire comment, en synthèse à partir du texte, on exploite les informations syntaxiques pour générer une intonation "naturelle" (entendez: grammaticale et variée). Un premier volet présentera l'intonation du français sous plusieurs aspects: ses formes auditive (mélodie, accentuation, pauses, rythme) et acoustique, l'analyse interactive par (re)synthèse, avec des éléments de perception tonale. Quelques exercices de discrimination, de transcription et de production, et l'illustration d'outils d'analyse permettront de concrétiser ces notions. On proposera enfin un modèle abstrait de l'intonation (niveaux de hauteur, accents, tons, unités) qui débouche sur une esquisse de ses fonctions communicatives et pragmatiques. Le deuxième volet établit le rapport avec la syntaxe: Est-il possible d'aller de la syntaxe à l'intonation ? Quelles informations sont requises: structure de constituants, rapports de dépendance, autres propriétés ? Qu'est-ce que nous apprennent les cas de non-congruence ? Qu'en est-il de l'autonomie de l'intonation (ou sa priorité) ? Le dernier volet est consacré au TALN pour la synthèse à partir du texte, plus particulièrement au système Mingus pour la génération de l'intonation. Celui-ci comporte deux blocs majeurs: d'une part la génération d'une représentation symbolique de l'intonation à partir de l'arborescence syntaxique et de la phonétisation; d'autre part, le modèle mélodique et le modèle de durée, qui effectuent la conversion de cette notation symbolique en valeurs acoustiques, nécessaires pour le synthétiseur (MBROLA, de la Faculté Polytechnique de Mons). Grâce au caractère paramétrique du module mélodique, il est possible de contrôler certains aspects émotifs. L'entrée à Mingus consiste soit de la sortie de l'analyseur syntaxique FIPS (LATL, Université de Genève), soit d'une analyse syntaxique superficielle propre. Le choix de la représentation de la structure syntaxique (et sa conversion éventuelle) dépend des contraintes explicitées dans le deuxième volet.},
  abstract  = {This tutorial describes how, in text-to-speech synthesis, syntactic information is used to generate natural intonation contours (i.e. which are grammatically correct and varied). A first part presents several aspect of French intonation: its auditory form (pitch, stress, pause, rhythm), its acoustic form, interactive analysis of intonation by (re)synthesis, as well as some notions of tonal perception. Some exercices in discrimination, transcription and production of pitch variations, and the illustration of analysis tools will help to provide a good understanding of these notions. Finally we briefly present an abstract model of French intonation (pitch levels, stress types, tones, units) and sketch its communicative and pragmatic functions. The second part studies the syntax-intonation interface: is it possible to predict intonation from syntactic structure ? What information is required: phrase structure, dependency relations, other properties ? What can be learned from cases of non-agreement ? Is intonation autonomous or anterior to syntax ? The last part deals with NLP for text-to-speech synthesis, more specifically in the Mingus system for intonation generation. There a two major blocks: first the generation of a symbolic representation of intonation, on the basis of the parse tree and grapheme-to-phoneme conversion; second the pitch model and the duration model which convert the symbolic representation into acoustic parameter values needed by the synthesizer (MBROLA, from Faculté Polytechnique de Mons). The parametric design of the pitch model allows for some control of emotional aspects. The input to Mingus is either the output of the full-blown syntactic parser FIPS (LATL, University of Geneva), or of Mingus' home-made shallow parser. The choice of syntactic representation (or its necessary conversion) stems from the constraints mentioned in the second part.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{ballim-EtAl:2000:TALN,
  author    = {Ballim, Afzal and Cristea, Dan and Seydoux, Florian and Moeller, Sebastian},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-tutoriel-002},
  language  = {french},
  note      = {Practical Dialogue Management},
  resume    = {},
  abstract  = {Dialogue modelling is a difficult but necessary task for intelligent human/machine comunication. This tutorial will look at the problems involved, and will introduce the basic concepts and methods in the development of dialogue management systems. The current state of the art in this field will be presented, and particular attention will be paid to semantic and pragmatic models of dialogue based on the intentions of participants. A hands-on session will be organized to present rapid dialogue prototyping environment.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{blanchon-boitet:2000:TALN,
  author    = {Blanchon, Hervé and Boitet, Christian},
  title     = {Traduction de la parole pour le français: une première étage et quelques perspectives},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-001},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{brun-smaili-haton:2000:TALN,
  author    = {Brun, Armelle and Smaïli, Kamel and Haton, Jean-Paul},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-002},
  language  = {french},
  note      = {Topic Identification Challenge Based on Short Word History},
  resume    = {},
  abstract  = {This paper presents several methods for topic detection on newspaper articles based on either a general vocabulary or a set of topic vocabularies. Our topic detection methods will be applied to speech recognition framework. The originality and the difficulty of our work lies in the fact that both training and test corpora contain few words (less than 200 words for test corpora). Test corpora are very small because our objective is to identify topic and adapt the language model, after uttering only few words. Experiments show that beyond 60 words, topic detection methods are not reliable. On and after 80 words, topic detection rate reaches 82% for the two first hypotheses, which is promising due to the conditions of our experimentation.},
  motscles  = {anguage models, topic detection, tfidf, speech recognition, modeles de langage, détection de thèmes, reconnaissance de la parole},
  keywords  = {},
}

@inproceedings{castano:2000:TALN,
  author    = {Castano, José},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-003},
  language  = {french},
  note      = {Some considerations about parsing and the Minimalist program},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{chibout-vilnat:2000:TALN,
  author    = {Chibout, Karim and Vilnat, Anne},
  title     = {SCALP: un Système de Compréhension Automatique du Lexique Polysémique d'inspiration linguistique},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-004},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{gaiffe-reboul-pierrel:2000:TALN,
  author    = {Gaiffe, Bertrand and Reboul, Anne and Pierrel, Jean-Marie},
  title     = {Le traitement des déictiques dans le DOHM},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-005},
  language  = {french},
  resume    = {Dans ce papier, nous proposons une analyse logique des déictiques. Notre travail s'effectue dans le cadre du dialogue de commande homme-machine. Dans un premier temps, nous présentons ce cadre et justifions la nécessité de représenter le contenu propositionnel des énoncé. Dans un second temps, nous illustrons la différence entre forme logique et contenu propositionnel ; cette différence est particulièrement importante dans le cas du traitement des déictiques. Nous montrons ensuite qu'au delà de l'intuition qui fait dire que " je " réfère à celui qui parle, il est nécessaire pour le traitement des déictiques de faire la différence entre l'acte locutionnaire (dans lequel le référent des déictiques doit être recherché) et l'acte illocutionnaire sous le champ duquel on ne peut voir apparaître que le référent des déictiques et pas leur sens.},
  abstract  = {},
  motscles  = {},
  keywords  = {man-machine dialogue, logical form, speech acts, dohm, déictiques, forme logique, actes de langage},
}

@inproceedings{gayral-kayser-levy:2000:TALN,
  author    = {Gayral, Françoise and Kayser, Daniel and Lévy, François},
  title     = {Analyse sémantique des pluriels : une première approche},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-006},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{goldman-wehrli-gaudinat:2000:TALN,
  author    = {Goldman, Jean-Philippe and Wehrli, Éric and Gaudinat, Arnaud},
  title     = {Utilisation de l'analyse syntaxique pour la synthèse de la parole, l'enseignement des langues et l'étiquetage grammatical},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-007},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{herzig-longin:2000:TALN,
  author    = {Herzig, Andreas and Longin, Dominique},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-008},
  language  = {french},
  note      = {A topic-based framework for rational interaction},
  resume    = {},
  abstract  = {Cooperative dialogue is one of the most important challenges of computer science. The background of this work are the dialogue systems developed by France Telecom R\& D as instantiations of its ARTIMIS (Sadek, 1999; Sadek et al., 1997; Sadek et al., 1996) generic rational agent technology. Such systems allow to manage real-time cooperative dialogues in natural language. Our framework is what we call an “intentional approach” of dialogue (Cohen \& Levesque, 1990a; Sadek, 1991; Sadek, 1992; Rao \& Georgeff, 1992). This approach is based on theories of Intentionality (Searle, 1983; Bratman, 1987). Within these theories, an agent is represented by its “mental state”, which is a set of informations. This set contains the different mental attitudes about the world the agent has: beliefs, goals, intentions... These theories are at the base of what is called “BDI-architectures” (for belief, desire and intention) in the literature. Intentional approaches are defined within twofaced formal theories : rational balance and rational interaction. The first theory describes, through properties of mental attitudes and action, the relationships that must be maintained as true (the relationships between the different mental attitudes of an agent firstly, and between these mental attitudes, plans and actions secondly). The second theory characterizes the inter-agent relationship within a multiagent environment (communication, cooperation, ...). Agents built on these twofaced theories are called rational agents. In this paper, we focus on the belief change process, viz. the ability to take into account the dynamics of the world.},
  motscles  = {},
  keywords  = {},
}

@inproceedings{jacquey-gaiffe-pierrel:2000:TALN,
  author    = {Jacquey, Évelyne and Gaiffe, Bertrand and Pierrel, Jean-Marie},
  title     = {Un traitement sémantique de la polysémie lexicale dans le domaine des interfaces homme-machine de dialogues de commandes},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-009},
  language  = {french},
  resume    = {L'objet de cet article est de proposer un traitement lexical des noms polysemiques qui admettent des copredications avec ou sans reprises pronominales. Ces copredications peuvent combiner des predicats vehiculant des restrictions selectionnelles differentes et incompatibles a premiere vue. Ces donnees semblent donc remettre en cause l'hypothese qu'une copredication, par le biais d'une coordination ou d'une reprise pronominale, ne modifie pas le type de l'element qui subit la copredication. Parmi un certain nombre de travaux existants dans ce domaine (Godard and Jayez 96) et (Pustejovsky 94,95) entre autre, (Asher et Pustejovsky 2000) proposent un traitement qui verifie l'hypothese d'un typage constant des arguments par leur predicat sans pour autant interdire ces phenomenes de copredication. Nous montrerons que ces travaux constituent une alternative a l'hypothese de (Godard and Jayez 96). De plus, dans la perspective de l'elaboration d'une interface de dialogue de commandes pour guider les taches accomplies par une application preexistante, nous montrerons que le traitement propose par (Asher and Pustejovsky 2000) fournit des representations semantiques adaptables a deux types possibles de modeles conceptuels.},
  abstract  = {},
  motscles  = {},
  keywords  = {lexical semantics, formal semantics, polysemy, typing, sémantique lexicale, sémantique formelle, polysémie, typage},
}

@inproceedings{lebarde:2000:TALN,
  author    = {Lebardé, Thomas},
  title     = {Analyse Syntaxique par Segments Logiques},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {447--453},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-010},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{menezo:2000:TALN,
  author    = {Menezo, Jacques},
  title     = {CELINE, un système multi-agents de détection-correction d'erreurs, adaptatif et semi-automatique},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-011},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{panchuk:2000:TALN,
  author    = {Panchuk, Victoria},
  title     = {},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-012},
  language  = {french},
  note      = {Computer Lexicography in Ukraine: an Overview},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{ruch-gaudinat:2000:TALN,
  author    = {Ruch, Patrick and Gaudinat, Arnaud},
  title     = {De l'ambiguïté lexicale selon le domaine},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-013},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{amghar-levrat:2000:TALN,
  author    = {Amghar, Tassadit and Levrat, Bernard},
  title     = {Modification et métonymie dans les Graphes Conceptuels},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-poster-014},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{clement:2000:TALN,
  author    = {Clement, Lionel},
  title     = {Une plateforme de développement de Grammaires Lexicales Fonctionnelles},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-demo-001},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}

@inproceedings{menezo-stefanini:2000:TALN,
  author    = {Menezo, Jacques and Stefanini, Marie-Hélène},
  title     = {BRUTAL, une plate-forme générique pour le TAL},
  booktitle = {Actes de la 7ème conférence sur le Traitement Automatique des Langues Naturelles},
  month     = {October},
  year      = {2000},
  address   = {Lausanne, Suisse},
  publisher = {Association pour le Traitement Automatique des Langues},
  pages     = {269--272},
  url       = {http://www.atala.org/taln_archives/TALN/TALN-2000/taln-2000-demo-002},
  language  = {french},
  resume    = {},
  abstract  = {},
  motscles  = {},
  keywords  = {},
}