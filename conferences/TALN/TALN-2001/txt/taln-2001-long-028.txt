
Ontologies for Information Retrieval

Amalia Todiraşcu (1) and François Rousselot (2)
(1) Faculty of Computer Science, University ”Al.I.Cuza” of Iasi, 16, Berthelot
Str., Iasi 6600, Romania
Phone: +40 32 201529, Fax: +40 32 201490
E-mail: amalia@infoiasi.ro
(2) LIIA, ENSAIS, 24, Bd. de la Victoire, 67084 Strasbourg Cedex, France
Phone: +33 3 88 14 47 53, Fax: +33 3 88 24 14 90
E-mail: rousse@liia.u-strasbg.fr
Abstract
The paper presents a system for querying (in natural language) a set of text documents from
a limited domain. The domain knowledge, represented in description logics (DL), is used for
filtering the documents returned as answer and it is extended dynamically (when new concepts
are identified in the texts), as result of DL inference mechanisms. The conceptual hierarchy is
built semi-automatically from the texts. Concept instances are identified using shallow natural
language parsing techniques.
Keywords: dynamically modified ontologies, description logics, NLP for IR systems
Résumé
L’article présente un système destiné à interroger en langue naturelle une base de texte sur
un domaine limité. Les connaissances du domaine, représentées en logique de description,
sont utilisées pour filtrer les documents retournés comme réponse. L’ontologie du domaine est
extraite automatiquement à partir des textes et elle est modifiée dynamiquement avec des faits
déduits par les mécanismes de logique de description. Les références aux concepts dans les
textes sont identifiées par des techniques d’analyse du langage naturel.
1 Introduction
The increasing amount of texts available in electronic format (Web pages, CD-ROMs) from
limited domains requires precise answers from Information Retrieval (IR) systems. Users have
various expectations about the result provided by IR systems for various corpora: medical cor-
pus contains information about precise diagnostic or treatment, while the news corpora contain
information about persons, places, names.
A.Todirascu et F.Rousselot
The main goal of this project is to investigate several approaches of integrating semantic in-
formation into an Information Retrieval system, for querying in natural language a set of doc-
uments from a limited domain. Purely statistical search engines provide bad recall and low
precision (the answers contain an important amount of irrelevant information), because they
ignore hyponyms, hyperonyms and synonyms. We consider that the use of semantics is a good
solution for improving IR systems performances. We integrate a dynamically-modified ontol-
ogy extracted from texts into an IR system, for investigating the possible improvements of recall
or precision. The information extracted from the text is used for building semi-automatically a
hierarchy of domain concepts. The domain hierarchy is represented in description logic (DL),
providing efficiency and fault tolerance when incomplete or erroneous data are processed. Logic
inference mechanisms provided by DL reasoner are used to extend dynamically the domain
model, and to complete and to correct missing information extracted from the user query. The
system could be easily ported for another domain, due to the dynamic maintenance of the do-
main knowledge base. Other systems consulting DL ontologies used fixed, manually build
domain hierarchies (Welty, Ide, 1999), and they accept searches on a few fields (author, title,
book).
NLP techniques have been applied for eliminating some of the drawbacks of IR systems. NLP
tools are used to extract index terms, or to develop linguistic resources dedicated to IR systems.
Terms are identified by robust methods: finite state automata, POS taggers, shallow syntactic
parsers (S.Ait-Mokhtar, J.-P.Chanod, 1997).
Another solution for extracting a better interpretation of the user query and documents is based
on the use of semantic resources (as filters or for identifying index terms) for improving search
results: multiple-word terms ((Riloff, Lorenzen, 1998), (Zhou, 1999)), their semantic variations
(Jacquemin, 1998), thesauri (Corelex (Buitelaar, 1998), EuroWordnet (Vossen, 1998)) or lists
of synonyms (Read, Barcena, 1998), concepts (Ambroziak, Woods, 1998). (Jacquemin, 1998)
proposes a small grammar for term identification.
Existing semantic resources (WordNet, MRD, CoreLex) contain redundant information, but are
often incomplete. These resources are useful for general search, on unrestricted texts, but must
be reorganised to be integrated into an IR system. Searching a text base for a given domain
requires domain-dependent resources. Domain-specific ontologies might help in understanding
user queries and documents. Words might have specific senses, not available in general-purpose
resources. For these reasons, we proposed a method for extracting the ontology from texts and
several possibilities of integrating it into an IR system.
2 Description Logics
Description logics (DL) are formalisms dedicated to knowledge representation (Baader, Hol-
lunder, 1991), more flexible than frame systems, but providing rigurous semantics and syntax.
DL structures the domain knowledge on two levels: a terminological level (T-Box), containing
the classes of domain objects (concepts), with their properties (roles) and an assertional level,
(A-Box), containing individuals of the abstract objects (instances).
The terminological level provides some powerful inference tests: the satisfiability of a concept
definition (there is an interpretation of the concept which is true in the set of domain facts), the
detection of the subsumption relation between two concepts (detecting which concept is more
general than the other one) and classification (ordering the new concepts in the hierarchy).
Ontologies for Information Retrieval
The A-Box provides consistency test (i.e. contradiction-free) or instantiation test (i.e. concept
subsuming the instance) for the individual descriptions, or retrieval inference (retrieving for a
given concept all its individuals).
Among knowledge representation formalisms, Description Logics (DL) are suitable for IR ap-
plications because they handle erroneous or incomplete data, together with the possibility of
organising hierarchically the knowledge (used for ). CLASSIC has been used for indexing a
digital library (Welty, Ide, 1999), but it requires manual indexation and limited search on some
fields. The ontology was fixed and it was built off-line. Some methods based on DL mecha-
nisms were applied to extract terms or relations between terms (Capponi and Toussaint, 2000),
but no IR system integrates a DL ontology, updated dynamically.
DLs handle semi-structured data, they do not define the exclusive list of roles for their individ-
uals (they accept implicit definitions). DL accepts also incomplete definitions.

✁✄✂✆☎✞✝ ✟✞✂✡✠✡☛✆☞✆✟✞☛✌✂ ✍✡✎✑✏✡✒✆✍✞✝ ✟✞✝✡✓ ✎✔  ✏✡✕✆✖✘✗✄✂✌✙✄✓✌☞ ✟✚  ✛✌✜✆✢✌✣✘✤✄✥✄✓ ✏✡✦✡✂✧✏✡✦✡✂✄★
✛✡✜ ✢✡✣✘✤✄✥✄✓✌✩✆✁✡✂✡✥✌✒✧✪✄✒✡✝ ✫✌✬✭✝ ✟✄✦✄★✡★✌★
✝ ✟✞✓ ✎✄✥✆✟✞☛✌✂✧✮✄✯✰  ✏✌✕✌✖✘✏✄✒ ✍✭✝ ✟✭✝✌✓ ✎✚  ✛✡✜ ✢✡✣✘✤✄✥✄✓ ✏✡✦✡✂✧✱✄✯✡★✡★✌★
In the example, the instance y0 of the concept Alpinist defines only the role hasAge, while the
concept has some other roles, like hasIdeal. The concepts are defined by define-concept and
the logical operators AND, OR, NOT and the DL operators SOME (existential quantifier) and
ALL (the universal quantifier).
A specific DL, CICLOP1 (Rudloff et all, 1998), was chosen for representing the domain knowl-
edge because it deals with role hierarchy, inverse roles and transitive roles. It accepts reasoning
simultaneously in several hierarchies (multiple T-Boxes) and implements an A-Box. Some of
the expressiveness (the features defining concepts and roles, role hierarchy, transitive roles) are
necessary for representing domain knowledge into an IR system. Some tests like are useful for
checking inferred facts.
3 System Architecture

The prototype integrates several natural language processing modules (Figure 1) as well as the
DL classifier. We implement the prototype and we use for tests small experimental French
corpora on heart surgery - MENELAS (83600 words), newspaper articles (300000 words) and
NLP articles (250000 words). The system is partially implemented in Java, in Perl and in CLIPS
(the rules combining domain-specific terms). The aim of these modules is to identify domain-
specific terms and eventually relations between terms. From the set of terms and relations, the
system updates a domain-specific hierarchy.
The automatic extraction of ontologies was the object of the TAI group (Terminology for Arti-
ficial Intelligence), defining principles for ontologies (Bouaud and all, 2000), and developping
tools for identifying terms and relations. A bottom-up approach for building a hierarchy was
adopted by several systems: identifying terms and assigning them to concepts (Bachimont,
1
Customizable Inference and Concept Language for Object Processing, developed at LIIA(Laboratoire
d’Informatique et d’Intelligence Artificielle), ENSAIS, Strasbourg, France
A.Todirascu et F.Rousselot
2000), generalising predicate structures to DL concepts (Capponi and Toussaint, 2000). Our
ontology definition is a simplified hierarchical model of the terminological knowledge from a
given domain. Our approach starts also from texts in order to identify terms. Cue phrases (func-
tional words, clause markers) are used to identify potential relations between terms (and also
between concepts). A link between candidate terms and DL representations is proposed, and
the conceptual representations are validated by DL tests.
Input text
NLP Modules
Semantic chunk identification

POS tagging
domain specific knowledge

set of patterns

word list
Sense tagging
functional words,
Border identification
specific patterns
Pattern matcher
Relevance chnuk
grouping partial
semantic descriptions
heuristic rules

conceptual descriptions
retrieve or
DL reasoning           classify          DL hierarchy
Figure 1: System architecture

We adopt a shallow, fault-tolerant approach for identifying term candidates; we need to recog-
nize only the most relevant pieces of information in the text, even if some small errors occur in
the input.
3.1 Semantic chunk identification

The main goal of this module is to identify the word sequences corresponding to the most
significant domain concepts (semantic chunks). A semantic chunk contains a simple syntactic
pattern (simple noun phrase, verb) and it is delimited by two border words. Border words are
functional words, auxiliaries, some prepositional syntagms. The semantic chunk, as we defined
in our system, might contain some errors, which are ignored by the processing modules.

Example. ”la victime, emportée par l’avalanche”
[the victim, taken from the avalanche]

In this example, ”la victime” and ”l’avalanche” are semantic chunks, containing the relevant
information.

This module uses several tools: a POS tagger, a sense tagger, a border identifier and a pattern
matcher. The identification of the semantic chunks is based on lexical information, provided by
the POS tagger.
Ontologies for Information Retrieval
a) The POS tagging (using WinBrill, trained for French with a set of data provided by Insti-
tut National pour la Langue Française (Lecomte, 1998)) identifies the content words (nouns,
adjectives, verbs) and functional words (prepositions, conjunctions etc.). Brill’s tagger uses a
set of contextual and lexical rules (based on prefixes and suffixes identification) learned from
annotated texts, for guessing the POS for the unknown words. It was chosen because it provides
good results (95 %) and it was available, with the French language model.
b) The sense tagger contains a pattern matcher, consulting a set of idiomatic phrases (their sense
could not be composed from the component parts) and their conceptual descriptions assigned by
a human expert. The sense is represented by DL conceptual descriptions. The pattern matcher
annotates each known word or idiomatic phrase with its semantic description.
c) A module for border identification. It identifies the words and the syntactic constructions
delimiting the semantic chunks. This module uses the output of POS tagger (identifying the
functional words), as well as a set of cue phrases (syntactic phrases containing auxiliaries,
composed prepositions). The set of cue phrases is built as a result of studies on experimental
corpora. The determiners and prepositions are best candidates for chunk border.
d) Pattern matcher. The goal of this module is to identify the core of the semantic chunks, which
is represented by simple noun phrases and verb phrases, between two consecutive borders.
✂✁☎✄✆ ✞✝ ,  ✠✟☛✡✞☞✞✁
✄✌ ✞✝  ✎✍✏✟☛✡✞☞✑✁✒✄✆ ✞✝
Examples. A simple noun phrase is identified by the following rules:
Errors might occur between two consecutive borders, and these cases are handled by patterns
like the last one. ’*’ replaces anything in the input text, so errors might be ignored.
e) DLgen interprets the information provided by the POS tagger and generates automatically a
concept definition. A human expert must check the output of this module. A few examples of
rules proposed for generating simple DL descriptions:

✌✲ ✳✌✴ ✫✗✥✆✵✏✶ ✦✗✪✢✶ ✷✆✷✗✷
- S1/N S2/ADJ is associated to the definition                            ✓ ✔✆✕✗✖✌✘ ✙✌✕✌✚✗✛✗✜ ✙✢✛✣✕✣✤✗✥☎✦★✧ ✩✆✦✗✪✂✓ ✫✗✬✗✭✮✦★✧☎✓ ✦✗✯✣✰✗✱
✸✑✹★✺ ✻✣✼✽✹✌✾✣✻✣✼☛✼❀✿❂❁ ❃❅❄✗❃ ❃ ❆✆❇ ❁ ❄✣❈ ❉ ❊❋❈ ❆❀❈ ●✌❉❍❊✌❉ ■★❏✌❁ ❈ ❁ ❆✗❏ ✓ ✔✌✕✣✖★✘ ✙★✕✆✚✆✛✣✜✣✙★✛✗✕ ✤✆✥☎✦✌✧✏✓ ✦✆✯ ✰✆✱ ✲★✳✆✴ ✬ ✳✣❑ ✕
✶ ✦✆✪★✶✣✷✗✷
✸✑✹★✺ ✻✣▲☛▼❖◆✽✲✌✳✌✹✌✴ ✾✣✻✣✼❁ ❃✞❄✣❃ ❃ ❆✆❇ ❁ ❄ ❈ ❉ ❊✽❈ ❆◗❈ ●✌❉❘❊✌❉ ■★❏✌❁ ❈ ❁ ❆✗❏ ✓ ✔✌✕✣✖★✘ ✙★✕✆✚✆✛✣✜✣✙★✛✗✕ ✤✆✥☎✦✗✪✆✩✗✦★✧☎✓ ✫✗✬✗✭✒✦✗✪
✓ ✦✆✯ ✰✆✱ ✫✗✥✆✵✏✶ ✦✌✧✌✶ ✷✆✷✗✷
✸❚❙❍●✌❉❀❯✗❉ ❱ ❲✌❃☛❄✣❱ ❉❀❈ ❱ ❄✗❏✌❃ ❳ ❄ ❈ ❉ ❊✑❁ ❏✣❈ ❆❨❱ ❆✗❳ ❉❀❏✌❄✗❩❬❉ ❃ ❭❍✹★✺ ✻ ❪❀❫✽❁ ❃❍❄✣❃ ❃ ❆✆❇ ❁ ❄ ❈ ❉ ❊❚❈ ❆❨❈ ●✌❉❖❱ ❆✣❳ ❉ hasS1❴
There are also some simple patterns for describing phenomena like negation, in particular, even
if it is impossible to enumerate all the possibilities, to detect correctly the scope of the negation:

- sans/ADV S1/N is associated to the definition                     ✓ ✔✆✕✗✖✌✘ ✙✌✕✌✚✗✛✗✜ ✙✢✛✣✕✣✤✗✥✮✙★✜ ✥★✩✗✦★✧✏✓ ✬✌✯ ❵✒✦✌✧✗✷✗✷
✸❚❄✣❛✌❇ ❛✌❏★✻ ▲❀▼❜❪❝✹★✺✣✻ ✼❞❁ ❃❨❄✣❃ ❃ ❆✆❇ ❁ ❄ ❈ ❉ ❊❂❈ ❆✞❈ ●✌❉❚❃ ❄✗❩❬❉❚❊✌❉ ■★❏✌❁ ❈ ❁ ❆✗❏ ✓ ✔✌✕✣✖★✘ ✙★✕✆✚✆✛✣✜✣✙★✛✗✕ ✤✆✥✮✙★✜ ✥★✩✗✦★✧
✓ ✬✌✯ ❵✒✦★✧✣✷✆✷
Of course, not all the negations might be handled. The output of DLgen module provides
only 61 % right annotations. Its output is checked by the human expert with the use of the DL
classifier to see if the concept definitions generated automatically are correct or not, due to input
errors: determiners starting the sentence, some patterns which are not coded by the system.
A.Todirascu et F.Rousselot
3.2 Relations between terms

This module applies DL inference mechanisms, as well as syntax-based rules, in order to com-
bine the conceptual descriptions associated to each semantic chunk.
1) Relevance chunker. We consider two classes of chunks: main chunks and secondary chunks.
Main chunks are similar to the notion of heads proposed by classical linguistic theories. Sec-
ondary chunks play the role of a modifier, which just add more information to the sense of the
head, which might be absent. We interpreted the order and the position of the chunks in the
sentence, used for combining concepts. Some examples of rules defines various chunks:

- semantic chunks following after a gerund verb, an auxiliary plus a past participle verb or
a preposition are secondary chunks;

- verbs are always Main chunks;

- chunks following after a conjunction are annotated by the same tag as the previous one.

Example.
’[Main Les contrebandiers Main] [Main ont commencé Main] [Second á utiliser ces ” monstres
” Second]’
’The trafficants have started to use monsters’
The main chunks identified here are ”les contrebandiers” (the first chunk in the sentence), and
the ”ont commencé” (comme verb principal). The last chunk is marked as secondary because it
follows after the preposition ”à”.
2) Heuristic rules. The rules are established by a human expert as a result of corpora studies.
The corpora were POS tagged and manually annotated with conceptual descriptions. The set of
heuristic rules is established after a list of patterns extracted from corpora.
Example of syntactic heuristic rules: if a preposition is a delimiter between two semantic
chunks and the preposition is relating a noun to its modifier, then we can combine the conceptual
descriptions of the two chunks into a more complex semantic description.
✁✄✂ ☎ ✆✞✝✞  ✟✞✠☛✡✌☞✍✟✌✎✑✏✑✒✓☎ ✔✖✕☛✗✌✘✌✙✍✗✚✒✓☎ ✛✍✙✞✜ ✠✍✡✍☞✌✟✍✎✖✢✣✒ ✤
✝ ✟✌✘✥✂ ✦✞✕ ☞✌✟✧  ✟★✆✖✝✌  ✟✌✠✍✡✍☞✌✟✍✎✣✏☛✤
✝ ✟✌✘✥✂ ✆✖✕☛✘✖  ✁✖ ☛✙✍✗✧  ✟✧✛✍✙✞✜ ✠✍✡✍☞✌✟✍✎✖✢✌✤
✩ ✡✞✙☛✟✧✜✍✕ ✪✌✫✖  ✟✞✙✬✂ ✭✍✙ ✪✮✂ ✆✖✝✌  ✟✌✠✍✡✍☞✌✟✍✎✣✏☛✤✚✯✰✭☛✙☛✪✱✂ ✛✍✙✞✜ ✠✍✡✍☞✌✟✍✎✖✢✌✤✌✤
✲✱✳☛✴ ✵✷✶✞✳ ✸ ✸ ✹ ✺ ✻✷✼ ✽✾✳☛✻✷✳☛✴ ✸ ✼ ✿☛✳ ✸ ✼ ❀✍✻❁✴ ❀✍✻✞❂✞✼ ✸ ✼ ❀☛✻❄❃ ❀✍✺❅✸ ✵✞✹❆✺ ❇✞❈ ✹☛❉❋❊✱✺ ✹ ✶✑❀☛✽ ✼ ✸ ✼ ❀✍✻✞✽ ●✑✶✞✳☛✽ ✸❆✶✞✳☛✺ ✸ ✼ ✴ ✼ ✶✞❈ ✹✾✿✍✹ ✺ ❍✞✽ ●
✳☛✺ ✹✾✽ ❀☛■❏✹❋✹ ❑✞✳☛■❏✶✞❈ ✹ ✽✮❀☛❃✬❍✖❀✍✺ ❂✞✹ ✺✮▲✮❀✍✺ ❂✞✽ ●✖✼ ✻✞✴ ❈ ❇✞❂✞✹ ❂❄✼ ✻❏✸ ✵✞✹❋✳☛✴ ✸ ✼ ✿☛✳ ✸ ✼ ❀✍✻❏✴ ❀☛✻✞❂✞✼ ✸ ✼ ❀✍✻✞✽✮❀☛❃✣✸ ✵✞✹❋✵✞✹ ❇✞✺ ✼ ✽ ✸ ✼ ✴
✺ ❇✌❈ ✹ ✽ ❉❏❊✬✳ ✸ ✸ ✹ ✺ ✻✞✽❆✳☛✽ ✽ ❀✌✴ ✼ ✳ ✸ ✹ ❂✷▲❅✼ ✸ ✵▼✳❄◆✍✼ ✿✍✹ ✻✷✸ ✺ ✼ ◆✍◆☛✹ ✺❅▲❖❀☛✺ ❂✵✞✳☛✽❆✳☛✽ ✽ ❀✌✴ ✼ ✳ ✸ ✹ ❂▼✳◗▲❖✹ ✼ ◆✍✵☛✸ ●✬✹ ❑✌✸ ✺ ✳☛✴ ✸ ✹ ❂
❃ ✺ ❀✍■✧✴ ❀☛✺ ✶✑❀☛✺ ✳✞❉✬❘★✻✌❇✞■❆❍✑✹ ✺✮❀ ❃✚❙☛❚❆✺ ❇✞❈ ✹ ✽✮✵✞✳☛✽✮❍✖✹ ✹ ✻◗❂✞✹ ✽ ✴ ✺ ✼ ❍✑✹ ❂◗✼ ✻◗❯✮❱✚❲ ❊✮❳✖❉✖❳✌❀☛■❏✹❅✺ ❇✞❈ ✹ ✽❅❨ ✴ ❀☛✻✍✸ ✳☛✼ ✻✞✼ ✻✞◆
✶✞✺ ✹ ✶✖❀✍✽ ✼ ✸ ✼ ❀☛✻✞✽✣❀☛✺✣◆✍✹ ✺ ❇✞✻✞❂✞✽ ❩✣✳☛✺ ✹✱■❏❀✍✺ ✹✚❃ ✺ ✹ ❬✌❇✞✹ ✻✍✸✚✸ ✵✞✳☛✻❋✸ ✵✞❀☛✽ ✹✬✸ ✺ ✼ ◆✍◆☛✹ ✺ ✹ ❂❋❍☛❭❆✴ ❀✍✻ ❪ ❇✞✻✞✴ ✸ ✼ ❀✍✻✞✽ ● ✽ ❀❖✿☛✳✍✺ ✼ ❀☛❇✞✽
✽ ✳☛❈ ✼ ✹ ✻✞✴ ✹ ✽❖✳✍✺ ✹❋✳☛✽ ✽ ✼ ◆✍✻✞✹ ❂◗✸ ❀❫✸ ✵✞✹ ✽ ✹❋✺ ❇✞❈ ✹ ✽ ❉
❚✍❩ CICLOP classifier. ❴ ✹❖❇✞✽ ✹❖✸ ✵✞✹❅✹ ❑✞✶✞✺ ✹ ✽ ✽ ✼ ✿✍✹ ✻✞✹ ✽ ✽❖✳☛✻✞❂❫✸ ✵✞✹❅❈ ❀☛◆✍✼ ✴ ✳✍❈✌✼ ✻✌❃ ✹ ✺ ✹ ✻✞✴ ✹ ✽✬❃ ❀✍✺✬✴ ✵✞✹ ✴ ❵✍✼ ✻✞◆❋✸ ✵✞✹
✿☛✳☛❈ ✼ ❂✞✼ ✸ ❭❋❀ ❃✖✸ ✵✞✹✮✻✞✹ ▲✰✼ ✻✌❃ ✹ ✺ ✺ ✹ ❂❋❃ ✳✍✴ ✸ ✽ ❉✬❛❖✵✞✹❖❀☛❇✌✸ ✶✞❇✌✸✱❀ ❃✖✵✞✹ ❇✞✺ ✼ ✽ ✸ ✼ ✴✱✺ ❇✞❈ ✹ ✽✚✼ ✽✚✺ ✹ ❜✖✻✞✹ ❂❫✳✍✻✞❂❆✴ ❈ ✳☛✽ ✽ ✼ ❜✖✹ ❂❆✳✍✻✞❂
Ontologies for Information Retrieval
✁✄✂✄☎✄✆   ✝✟✞ ✠✡✁☛✞ ☞ ✌✎✍ ✏✑☎✡✒ ☞✓✒ ☞ ✔ ☞ ✞ ✍ ☞ ✝✖✕✡✗✟✍ ✘☛☞✓✏ ✗☛✏ ✍ ☞ ✙✟✚✜✛✜✘☛☞✢✘☛☞ ✣☛✒   ✏ ✍   ✞✓✒ ✣☛✆ ☞ ✏✑☎✄✏ ✏ ✠✎✞   ☎ ✍ ☞✓✍ ✠✤☞ ☎✡✞ ✘✟✍ ✒   ✥✄✥✡☞ ✒
✦ ✠✡✒ ✝✖✠✡✒✑✞ ✣☛☞✢✌☛✘☛✒ ☎✄✏ ☞✢☎✧✥✄☞ ✁☛☞ ✒   ✞✢✒ ☞ ✆ ☎✄✍   ✠✄✁✟✕★☞ ✍ ✦ ☞ ☞ ✁✖✍ ✘☛☞✓✍ ✦ ✠✤✞ ✠✄✁☛✞ ☞ ✌✎✍ ✏ ✚✪✩✎✌★☞ ✞   ✫ ✗✎  ✁☛✥✬✍ ✘☛  ✏✑✒ ☞ ✆ ☎ ✍   ✠✡✁
✦ ✘✎☞ ✁✭✍ ✘☛☞✖✒ ✣☛✆ ☞ ✏✤☎✄✒ ☞✖✝☛☞ ✮✯✁☛☞ ✝✰✙✤☞ ☎✄✁☛✏✬✍ ✠✱✘☛☎ ✂✡☞✖☎✲✏ ☞ ✍✟✠ ✫✓✝☛✠✄✙✤☎✡  ✁✎✳ ✝☛☞ ✌✯☞ ✁☛✝☛☞ ✁✡✍✧✒ ✣☛✆ ☞ ✏ ✚✵✴✷✶ ✴✷✸✺✹✪✻
✁✡✫ ☞ ✒ ☞ ✁☛✞ ☞✟✙✤☞ ✞ ✘☛☎✡✁☛  ✏ ✙✤✏✬☎✡✒ ☞✟✣☛✏ ☞ ✝✭✍ ✠✲✒ ☞ ✮✯✁☛☞✧✍ ✘☛☞✟✒ ✠✡✆ ☞✧✝☛☞ ✮✯✁☛  ✍   ✠✄✁★✼✷✞ ✘☛☞ ✞ ✽✡  ✁☛✥✲✍ ✘☛☞✟✞ ✠✡✁☛✞ ☞ ✌✎✍ ✏✤☎✡✁☛✝
✍ ✘✎☞   ✒✜✏ ✣☛✕☛✏ ✣☛✙✤☞ ☞ ✏✑✒ ☞ ✆ ☎✄✍ ☞ ✝✟✕✡✗✧✍ ✘☛☞✓✒ ✠✄✆ ☞ ✏ ✚
✾ ✤   ✙ ✠✄✁☛✥✟✍ ✘☛☞✤✒ ☞ ✏ ✣☛✆ ✍ ✏✓✌☛✒ ✠ ✂☛  ✝☛☞ ✝✱✕✡✗✿✍ ✘☛☞✧✘☛☞ ✣☛✒   ✏ ✍   ✞ ✏✓✒ ✣☛✆ ☞ ✏ ✼❀✠✄✁☛✆ ✗✲❁✎❂✖❃❄☎✡✒ ☞✤☎✄✞ ✞ ☞ ✌✎✍ ☞ ✝✭✕✄✗✲✍ ✘☛☞✤❅✪✸
✞ ✆ ☎✄✏ ✏   ✮✯☞ ✒ ✼✡✕✯☞ ✞ ☎✡✣☛✏ ☞✜✏ ✠✄✙✤☞✷✠✄✫✯✍ ✘☛☞✷  ✁✎✫ ☞ ✒ ✒ ☞ ✝✬✞ ✠✄✁☛✞ ☞ ✌✎✍ ✏❆☎✄✒ ☞✜✁☛✠ ✍❆✞ ✠✄✁☛✏   ✏ ✍ ☞ ✁✄✍ ✦   ✍ ✘✓✍ ✘☛☞✜☞ ❇☛  ✏ ✍   ✁☛✥✪✝☛☞ ✮✯✁☛  ✳
✍   ✠✡✁☛✏ ✼✄✠✄✒❀✕✯☞ ✞ ☎✡✣☛✏ ☞❆✍ ✘☛☞✷❅✪✸✟✘☛  ☞ ✒ ☎✄✒ ✞ ✘✡✗✢  ✏✺✏ ✍   ✆ ✆✡  ✁☛✞ ✠✄✙✤✌☛✆ ☞ ✍ ☞ ✚✺✛✜✘☛☞✜✒ ☞ ✏ ✣☛✆ ✍   ✁☛✥✪✞ ✠✡✁☛✞ ☞ ✌✎✍ ✏❀☎✄✒ ☞❆✂✄☎✡✆   ✝☛☎ ✍ ☞ ✝
✕✄✗✧✍ ✘☛☞✓☞ ❇☛  ✏ ✍   ✁☛✥✬✽✎✁☛✠ ✦ ✆ ☞ ✝☛✥✡☞✓✠✄✁☛✆ ✗✟  ✫✺✍ ✘☛☞✓✠✄✁✡✍ ✠✄✆ ✠✡✥ ✗✧  ✏✜✞ ✠✄✙✤✌☛✆ ☞ ✍ ☞ ✚
3.3 Functionality
✛✜✘✎☞✬❈✪✸❉✻❊✙✤✠✎✝☛✣☛✆ ☞ ✏✪✝☛☞ ✏ ✞ ✒   ✕✯☞ ✝✿☎✡✕✯✠ ✂✡☞✤✌☛✒ ✠✎✞ ☞ ✏ ✏✪✣☛✏ ☞ ✒✓❋✡✣☛☞ ✒   ☞ ✏✓✠✄✒✪✝☛✠✎✞ ✣☛✙✤☞ ✁✡✍ ✏✑✍ ✠✟✕✯☞✬  ✁☛✞ ✆ ✣☛✝☛☞ ✝✿  ✁
✍ ✎✘ ☞✓✕☛☎✡✏ ☞ ✚
✛✜✘✎☞✬✝☛✠✎✞ ✣☛✙✤☞ ✁✄✍✢  ✏✜✮✯✒ ✏ ✍✓✌☛✒ ✠✎✞ ☞ ✏ ✏ ☞ ✝✲✕✄✗✿☎✧✍ ✠✄✽✄☞ ✁☛  ● ☞ ✒ ✼❉  ✝☛☞ ✁✡✍   ✫ ✗✎  ✁☛✥✤✍ ✘☛☞✬✆   ✏ ✍✪✠ ✫❆✍ ✘☛☞✬✙✤✠✄✏ ✍✪✫ ✒ ☞ ❋✡✣☛☞ ✁✄✍
✦ ✠✡✒ ✝☛✏ ✚✢❍✯✠✡✒✑☞ ☎✄✞ ✘ ✦ ✠✡✒ ✝✖✫ ✒ ✠✡✙■✍ ✘☛☞✬✆   ✏ ✍ ✼ ✦ ☞✬☞ ❇✎✍ ✒ ☎✄✞ ✍✪✍ ✘☛☞✬✆ ☞ ✫ ✍✪☎✡✁☛✝✖✍ ✘☛☞✬✒   ✥✄✘✡✍✪✞ ✠✄✁✡✍ ☞ ❇✎✍✤❏ ☎✟✆   ✙✤  ✍ ☞ ✝
✁✡✣☛✙✬✕✯☞ ✒✪✠✄✫ ✦ ✠✡✒ ✝☛✏✑✳✪❑✬✍ ✠✿▲ ▼✎◆ ✚✓❍✯✒ ✠✄✙❖✍ ✘☛  ✏✪✆   ✏ ✍ ✼ ✦ ☞✬☞ ❇✎✍ ✒ ☎✄✞ ✍✪✍ ✘☛☞✬✙✤✠✄✏ ✍✪✫ ✒ ☞ ❋✡✣☛☞ ✁✄✍✢✞ ✠✄✁✡✍ ☞ ✁✡✍ ✦ ✠✄✒ ✝☛✏
❏ ✁✎✠✡✣☛✁☛✏ ✼☛☎✡✝ ✔ ☞ ✞ ✍   ✂✡☞ ✏ ✼★☎✄✁☛✝✧✂✡☞ ✒ ✕☛✏ ◆ ✚✷✛✜✘☛☞✪✞ ✠✄✁✡✍ ☞ ❇✎✍ ✏✑✠ ✫✺✍ ✘☛☞ ✏ ☞✓✞ ✠✡✁✄✍ ☞ ✁✄✍ ✦ ✠✡✒ ✝☛✏✜☎✡✒ ☞✪✌☛✒ ✠✎✞ ☞ ✏ ✏ ☞ ✝✖✕✄✗✧✍ ✘☛☞
❈✑✸❉✻✿✙✤✠✎✝☛✣☛✆ ☞ ✏★✫ ✠✡✒❉✁☛☞ ✦ ✞ ✠✄✁☛✞ ☞ ✌✎✍❀  ✝☛☞ ✁✄✍   ✮✯✞ ☎ ✍   ✠✡✁★✚✺✛✜✘☛☞❆❅✪✸✧✙✤✠✎✝☛✣☛✆ ☞✺✂✄☎✡✆   ✝☛☎ ✍ ☞ ✏★✍ ✘☛☞❆✁☛☞ ✦ ✞ ✠✄✁☛✞ ☞ ✌✎✍ ✣☛☎✡✆
✝☛☞ ✮✯✁☛  ✍   ✠✄✁☛✏✜☎✄✁☛✝✟✍ ✘☛☞ ✗✖☎✄✒ ☞✓☎✄✝☛✝☛☞ ✝✧✍ ✠✬✍ ✘☛☞✓✝☛✠✄✙✤☎✡  ✁✧✘☛  ☞ ✒ ☎✄✒ ✞ ✘✡✗✄✚
❍❀  ✒ ✏ ✍ ✼☛✍ ✘☛☞✓✌☛☎✄✍ ✍ ☞ ✒ ✁✖✙✤☎✄✍ ✞ ✘☛☞ ✑   ✒   ✝☛☞ ✁✡✍   ✮✯☞ ✏✜✍ ✘☛☞✓✏ ✌★☞ ✞   ✮✯✞✓✌☛✘☛✒ ☎✡✏ ☞ ✏✪  ✁✧✍ ✘☛☞✓  ✁☛✌☛✣✎✍✑✍ ☞ ❇✎✍ ✼✯☎✡✁☛✝✟✍ ☛
✘ ☞✓✏ ☞ ✁☛✏ ☞
✍ ☎✄✥✄✥✡☞ ✒✺✆ ☎✡✕✯☞ ✆ ✏❉✍ ✘☛☞✷✽✡✁☛✠ ✦ ✁ ✦ ✠✡✒ ✝☛✏❀☎✄✁☛✝✢✍ ✘☛☞✷  ✝☛☞ ✁✡✍   ✮✯☞ ✝✬✌☛✘☛✒ ☎✄✏ ☞ ✏ ✦   ✍ ✘✓✍ ✘☛☞✜✞ ✠✡✁☛✞ ☞ ✌✎✍ ✣☛☎✄✆☛✝☛☞ ✏ ✞ ✒   ✌✎✍   ✠✄✁☛✏ ✚
✸❉☞ ❇☛  ✞ ☎✡✆★  ✁✎✫ ✠✡✒ ✙✤☎ ✍   ✠✡✁✤  ✏✜☎✡✏ ✏   ✥✄☛
✁ ☞ ✝✧✍ ✠✤☞ ☎✡✞ ✘ ✦ ✠✡✒ ✝✟✕✡✗✧✍ ✘☛☞✓✻✷✹✓✩✤✍ ☎✡✥✄✥✡☞ ✒ ✚
❈✑☞ ❇✎✍ ✼✺✍ ✘☛☞✧✏ ☞ ✙✤☎✡✁✄✍   ✞✤✞ ✘✎✣☛✁☛✽✡✏✤☎✄✒ ☞✤  ✝☛☞ ✁✄✍   ✮✯☞ ✝✱  ✁✿✍ ✘☛☞✧  ✁☛✌☛✣✎✍✓✍ ☞ ❇✡✍ ✚✿❍✯✠✄✒✓☞ ☎✄✞ ✘✭✞ ✘✡✣☛✁☛✽✯✼ ✦ ☞✤✘☛☎ ✂✡☞✧☎
✞ ✠✄✁☛✞ ☞ ✌✎✍ ✣☛☎✡✆❆✝☛☞ ✏ ✞ ✒   ✌✎✍   ✠✄✁★✚✟✛✜✘☛☞✤✘☛☞ ✣☛✒   ✏ ✍   ✞✬✒ ✣☛✆ ☞ ✏ ✦   ✆ ✆❆✕✯☞✤✣☛✏ ☞ ✝✲✫ ✠✄✒✓✞ ✠✄✙✬✕☛  ✁☛  ✁☛✥✟✌☛☎✄✒ ✍   ☎✡✆❀✏ ☞ ✙✤☎✡✁✄✍   ✞
✝☛☞ ✏ ✞ ✒   ✌✎✍   ✠✡✁☛✏ ✚✖✱☞✟  ✝☛☞ ✁✡✍   ✫ ✗✲☎✿✏ ☞ ✍✤✠✄✫✑✁☛☞ ✦ ✞ ✠✡✁☛✞ ☞ ✌✎✍ ✣☛☎✄✆✜✝☛☞ ✏ ✞ ✒   ✌✎✍   ✠✄✁☛✏✧❏ ☎✡✏✬☎✖✒ ☞ ✏ ✣☛✆ ✍✬✠✄✫✑✘☛☞ ✣☛✒   ✏ ✍   ✞
✒ ✣✎✆ ☞ ✏ ◆ ✼❉✞ ✘☛☞ ✞ ✽✄☞ ✝✭✕✄✗✿✍ ✘☛☞✬❅✪✸◗✞ ✆ ☎✡✏ ✏   ✮✯☞ ✒ ✚✬✶ ✫ ✦ ☞✤☎✄✒ ☞✬✌☛✒ ✠✎✞ ☞ ✏ ✏   ✁☛✥✖✣☛✏ ☞ ✒✓  ✁☛✌☛✣✎✍ ✼❉✍ ✘☛☞ ✁✿✍ ✘☛☞✤  ✁☛✏ ✍ ☎✄✁☛✞ ☞ ✏
✠ ✫❀✍ ✘☛☞✬✞ ✠✡✁☛✞ ☞ ✌✎✍ ✏✪☎✡✒ ☞✢✒ ☞ ✍ ✒   ☞ ✂✡☞ ✝★✚✓✶ ✫✷✁☛☞ ✦ ✝☛✠✎✞ ✣☛✙✤☞ ✁✄✍ ✏ ✦ ☞ ✒ ☞✬✌☛✒ ✠✎✞ ☞ ✏ ✏ ☞ ✝✿✍ ✠✧✕✯☞✬☎✄✝☛✝☛☞ ✝✖✍ ✠✤✍ ✘☛☞✓✍ ☞ ❇✡✍
✕☛☎✄✏ ☞ ✼☛✍ ✘☛☞✓✝☛✠✡✙✤☎✄  ✁✟✘☛  ☞ ✒ ☎✡✒ ✞ ✘✄✗✟  ✏✜☞ ❇✡✍ ☞ ✁☛✝☛☞ ✝ ✦   ✍ ✘✟✁☛☞ ✦ ✞ ✠✡✁☛✞ ☞ ✌✎✍ ✏ ✚
4 DL for Indexing
❅✪✸✿✌☛✒ ✠ ✂☛  ✝☛☞ ✏✜✌★✠ ✦ ☞ ✒ ✫ ✣☛✆★  ✁✎✫ ☞ ✒ ☞ ✁☛✞ ☞✪✙✤☞ ✞ ✘☛☎✡✁☛  ✏ ✙✤✏❆✫ ✠✡✒✷✘☛☎✡✁☛✝☛✆   ✁☛✥✢  ✁☛✞ ✠✡✙✤✌☛✆ ☞ ✍ ☞✪☎✄✁☛✝✟✏ ☞ ✙✤  ✳ ✏ ✍ ✒ ✣☛✞ ✍ ✣☛✒ ☞ ✝
✝☛☎ ✍ ☎✎✼✜☎✡✏ ✦ ☞ ✆ ✆✑☎✡✏✬✂✄☎✄✆   ✝☛  ✍ ✗✱✍ ☞ ✏ ✍ ✏✤✫ ✠✡✒✤✁☛☞ ✦   ✁✎✫ ☞ ✒ ✒ ☞ ✝✭✫ ☎✡✞ ✍ ✏ ✚❘✹✪✁✭✍ ✘☛☞✖✠ ✍ ✘☛☞ ✒✤✘☛☎✡✁☛✝★✼✜✶ ❙❖✏ ✗☛✏ ✍ ☞ ✙✤✏
✘☛☎✄✁☛✝☛✆ ☞✪  ✁☛✞ ✠✡✙✤✌☛✆ ☞ ✍ ☞✪✠✄✒✜☞ ✒ ✒ ✠✄✁☛☞ ✠✄✣☛✏✑  ✁☛✌☛✣✎✍✜✝☛☎✄✍ ☎✬☎✡✏ ✦ ☞ ✆ ✆★☎✡✏✷✫ ✣☛● ● ✗✟✝☛✠✄✙✤☎✡  ✁✧✽✡✁☛✠ ✦ ✆ ☞ ✝☛✥✄☞✄✚❆❍✯✠✡✒❆✍ ✘☛☞ ✏ ☞
✒ ☞ ☎✄✏ ✠✡✁☛✏ ✼✎❅✪✸✿  ✏❆✞ ✘☛✠✄✏ ☞ ✁✤☎✡✏❆☎✓✝☛✠✡✙✤☎✄  ✁✤✽✡✁☛✠ ✦ ✆ ☞ ✝☛✥✄☞✑✒ ☞ ✌☛✒ ☞ ✏ ☞ ✁✡✍ ☎ ✍   ✠✡✁✬✫ ✠✡✒ ✙✤☎✄✆   ✏ ✙❘✫ ✠✄✒❆✠✄✣☛✒❆✶ ❙◗✏ ✗✎✏ ✍ ☞ ✙✟✚
✛✜✘✎☞✧  ✁☛✝☛☞ ❇✎  ✁☛✥✿✙✤☞ ✍ ✘☛✠✎✝✱  ✏✢☎✿✸❉☎✄✍ ☞ ✁✡✍✤✩✎☞ ✙✤☎✄✁✡✍   ✞✤✶ ✁☛✝☛☞ ❇☛  ✁☛✥✿✠✡✁☛☞✿❏ ❅✪✣☛✙✤☎✄  ✏ ✼✜▲ ❚✡❚✄❁✎◆ ✼ ✦ ✘☛☞ ✒ ☞✤✍ ☞ ✒ ✙✤✏
✘☛☎ ✂✡☞✪✕★☞ ☞ ✁✖✒ ☞ ✌☛✆ ☎✡✞ ☞ ✝✟✕✡✗✟✞ ✠✡✁☛✞ ☞ ✌✎✍ ✏ ✚✷✛✜✘☛☞✓✙✤☎✄✍ ✒   ❇✧✠ ✫❀✝☛✠✎✞ ✣☛✙✤☞ ✁✡✍ ✏✜☎✡✁☛✝✟✞ ✠✄✁☛✞ ☞ ✌✎✍ ✏✑  ✏✜✒ ☞ ✝☛✣☛✞ ☞ ✝✖✞ ✠✡✙✬✳
✌☛✣✡✍   ✁☛✥✤✏ ✣☛✕☛✏ ✣☛✙✤✌✎✍   ✠✡✁✖✒ ☞ ✆ ☎ ✍   ✠✡✁☛✏✜✕★☞ ✍ ✦ ☞ ☞ ✁✿✞ ✠✄✁☛✞ ☞ ✌✎✍ ✏✓☎✄✁☛✝✟✍ ✘☛☞✢✞ ✠✄✁☛✞ ☞ ✌✎✍ ✦ ☞   ✥✡✘✄✍ ✏✬❏ ✆ ✠✎✞ ☎✡✆❉✠✄✒✑✥✡✆ ✠✄✕☛☎✡✆
✫ ✒ ☞ ❋✡✣☛☞ ✁☛✞   ☞ ✏ ◆ ✚
A.Todirascu et F.Rousselot
Corpus Concepts                         Repeated segments
Menelas  137                                   748
News     98                                   350
Table 1: Various hierarchy size

4.1 Building the DL hierarchy
✂✁☎✄ ✆ ✝✞✄ ✟✡✠☞☛✌✄ ✟✎✍✏✠✎✄ ✁✑✠✎✒✓✍✞☛✕✔ ✖✗✠✎✒✓✘✙✟✎✒ ✒ ✚ ✛✕✜ ✁☎✄ ✖✕✁✢✘✕✆ ✟✌✔ ✁ ✒ ✒✓✟✎✣✤✔ ✆ ✁ ✠ ✄ ✚ ✥✕✦✡✧✕✟☞✍✏✠✎✚ ✥✏✖✕✚ ✁ ✆ ✠✎✆ ✔ ✖☞✝✎★✕✛✕☛✌✄✓✩☎✁
✥✕✁ ✁ ✧✪✠✞✒ ✍✏✠☞✜ ✜✙✒ ✁ ✄✑✟✎✣✫✘✕✆ ✚ ✍✏✚ ✄ ✚ ✬☞✁✑✔ ✟✎✥✕✔ ✁ ✘✌✄ ✒☎✄ ✟✏✒ ✄ ✠✎✆ ✄✢✁ ✭✌✄ ✁ ✥✕✧✕✚ ✥✕✦✏✚ ✄ ✮

4.1.1 Manual building
✯☎✖✌✁✏✰✢✱✲✖✕✚ ✁ ✆ ✠✎✆ ✔ ✖☞✝✳✟✎✣✴✄ ✖✕✁✏✧✕✟✎✍✏✠☞✚ ✥✪✖✕✠☞✒✵✠✎✒✵✚ ✄ ✒✵✔ ✟☞✆ ✁✞✠✶✍✏✠✎✥✌☛✕✠✎✜ ✜ ✝✳✛✕☛✕✚ ✜ ✄✵✚ ✥✕✚ ✄ ✚ ✠✎✜✤✖✕✚ ✁ ✆ ✠☞✆ ✔ ✖✎✝☞✮✏✯☎✖✕✁
✚ ✥✌✚ ✄ ✚ ✠☞✜✎✔ ✟✎✥✕✔ ✁ ✘✌✄ ✒✴✠☞✆ ✁✓✚ ✧✕✁ ✥☞✄ ✚ ✷✸✁ ✧✞✛☞✝✡✠✵✖☞☛✕✍✏✠☞✥✡✁ ✭✌✘✙✁ ✆ ✄✓✚ ✥✵✄ ✖✕✁✓✜ ✚ ✒ ✄✴✟ ✣✙✆ ✁ ✘✙✁ ✠✎✄ ✁ ✧✞✒ ✁ ✦✎✍✏✁ ✥✎✄ ✒✴✁ ✭✌✄ ✆ ✠✎✔ ✄ ✁ ✧
✣ ✆ ✟☞✍✹✠✡✒ ✁ ✄☎✟ ✣✤✚ ✥✕✚ ✄ ✚ ✠✎✜✌✄ ✁ ✭✌✄ ✒ ✮✴✯☎✖✕✁✢✚ ✥✕✚ ✄ ✚ ✠✎✜✌✄ ✁ ✭✌✄ ✒✴✩☎✁ ✆ ✁✢✒ ✁ ✜ ✁ ✔ ✄ ✁ ✧✗✍✏✠✎✥✌☛✕✠✎✜ ✜ ✝✞✣ ✆ ✟✎✍✺✠✡✒ ✁ ✄☎✟✎✣✻✆ ✁ ✒ ☛✕✜ ✄ ✒✓✟ ✣
✼ ✁ ✝☞✩☎✟✎✆ ✧✂✒ ✁ ✠☞✆ ✔ ✖✲✽ ✘✕✆ ✟☞✘✸✟☞✒ ✁ ✧✾✛✎✝✳✄ ✖✕✁✏✁ ✭✕✘✸✁ ✆ ✄ ✒✢✄ ✟✶✛✸✁✏✆ ✁ ✘✕✆ ✁ ✒ ✁ ✥☞✄ ✠ ✄ ✚ ✬☞✁✞✣ ✟☞✆✑✄ ✖✕✁✏✧✕✟✎✍✏✠☞✚ ✥✸✿☎✆ ✁ ✄ ☛✕✆ ✥✕✁ ✧
✛✎✝❁❀✢✟✌✟☞✦✎✜ ✁✎✮✳✯☎✖✕✁✗✁ ✭✌✘✙✁ ✆ ✄✏✧✕✁ ✷✸✥✕✁ ✒✏✠✎✜ ✒ ✟✪✄ ✖✕✁✗✆ ✁ ✜ ✠✎✄ ✚ ✟✎✥✕✒✡✛✙✁ ✄ ✩✓✁ ✁ ✥❁✄ ✖✕✁✗✔ ✟☞✥✕✔ ✁ ✘✌✄ ✒ ✮✂✯☎✖✕✁✏✣ ✟☞✜ ✜ ✟ ✩✑✚ ✥✕✦
✄ ✠✎✛✕✜ ✁✢✘✕✆ ✁ ✒ ✁ ✥✎✄ ✒✑✬✎✠✎✆ ✚ ✟☞☛✕✒☎✖✕✚ ✁ ✆ ✠☞✆ ✔ ✖✎✝✶✒ ✚ ❂ ✁✢✣ ✟✎✆✓✬✎✠☞✆ ✚ ✟✎☛✕✒☎✔ ✟✎✆ ✘✕☛✕✒ ❃

4.1.2 Modifying the hierarchy
❄✖✌✁ ✥✾✠✶✥✕✁ ✩✺✧✕✟✌✔ ☛✕✍✏✁ ✥☞✄✡✚ ✒✢✠☞✧✕✧✕✁ ✧✾✄ ✟✗✄ ✖✕✁✞✚ ✥✕✧✕✁ ✭✾✛✕✠✎✒ ✁✎★✻✷✸✆ ✒ ✄✡✚ ✄✡✚ ✒✢✘✕✆ ✁ ✘✕✆ ✟✌✔ ✁ ✒ ✒ ✁ ✧✂✛☞✝✾✠✶✍✏✟✌✧✕☛✕✜ ✁
✁ ✭☞✄ ✆ ✠☞✔ ✄ ✚ ✥✕✦✏✄ ✖✕✁✡✍✏✟✎✒ ✄✑✣ ✆ ✁ ❅✌☛✕✁ ✥☞✄✵✔ ✟☞✥✎✄ ✁ ✥✎✄✢✩☎✟✎✆ ✧✕✒✞✽ ✥✕✟☞☛✕✥✙★✙✠✎✧ ❆ ✁ ✔ ✄ ✚ ✬☞✁ ✒ ★✸✬☞✁ ✆ ✛✕✒ ✿✑✠✎✥✕✧✶✄ ✖✕✁ ✚ ✆✑✔ ✟☞✥✎✄ ✁ ✭☞✄ ✒ ✮
✯☎✖✌✁✏❇✑✱✤❈❄✍✏✟✌✧✕☛✕✜ ✁ ✒✢✘✕✠✎✆ ✒ ✁✞✄ ✖✕✁✞✔ ✟✎✥☞✄ ✁ ✭✌✄ ✒✏✽ ❉✎❊ ❋ ❉✏✩☎✟✎✆ ✧✕✒ ✿✢✠☞✥✕✧✳✁ ✭☞✄ ✆ ✠☞✔ ✄✡✥✕✁ ✩✺✔ ✟☞✥✕✔ ✁ ✘✌✄ ✒ ✮✏●✸✟✎✆✢✁ ✠✎✔ ✖
✔ ✟✎✥✕✔ ✁ ✘✌✄ ★✸✠✏✰✢✱✂✧✕✁ ✒ ✔ ✆ ✚ ✘✌✄ ✚ ✟✎✥✶✚ ✒✑✛✕☛✕✚ ✜ ✄☎✠☞✥✕✧✶✚ ✄✑✚ ✒☎✠✎✧✕✧✕✁ ✧✗✄ ✟✞✄ ✖✕✁✵✁ ✭✕✚ ✒ ✄ ✚ ✥✕✦✞✖✕✚ ✁ ✆ ✠✎✆ ✔ ✖☞✝✎✮
❍ ✁ ✥✕✒ ✁✏✄ ✠☞✦✎✦☞✚ ✥✕✦✪✠✎✒ ✒ ✚ ✦☞✥✕✒✵✩✓✟☞✆ ✧✕✒✞✠✎✥✕✧❁✚ ✧✕✚ ✟✎✍✏✠✎✄ ✚ ✔✞✘✕✖✕✆ ✠✎✒ ✁ ✒✡✩✑✚ ✄ ✖✾✄ ✖✕✁ ✚ ✆✡✰✢✱❄✧✕✁ ✒ ✔ ✆ ✚ ✘✌✄ ✚ ✟☞✥✕✒ ✮✳❈✫✠✎✆ ✄ ✚ ✠☞✜
✒ ✁ ✍✏✠✎✥☞✄ ✚ ✔✢✧✕✁ ✒ ✔ ✆ ✚ ✘✌✄ ✚ ✟☞✥✕✒☎✠✎✆ ✁✵✔ ✟☞✍✡✛✕✚ ✥✕✁ ✧✶✛☞✝✶✠✎✘✕✘✕✜ ✝✕✚ ✥✕✦✞✆ ☛✕✜ ✁ ✒☎✁ ✥✕✔ ✟✌✧✕✚ ✥✕✦✏✒ ✝✌✥☞✄ ✠✎✔ ✄ ✚ ✔ ✼ ✥✕✟ ✩✑✜ ✁ ✧✕✦☞✁ ✮✓●✸✟✎✆
✁ ✭✌✠☞✍✏✘✕✜ ✁ ★✸✚ ✄☎✚ ✒☎✘✙✟✎✒ ✒ ✚ ✛✕✜ ✁✢✄ ✟✞✔ ✟✎✍✞✛✕✚ ✥✕✁✢✔ ✟✎✥✕✔ ✁ ✘✌✄ ☛✕✠☞✜✻✧✕✁ ✒ ✔ ✆ ✚ ✘✌✄ ✚ ✟☞✥✕✒✓✣ ✟✎✆☎✠✏✥✕✟☞☛✕✥✶✠✎✥✕✧✪✚ ✄ ✒☎✍✏✟✌✧✕✚ ✷✸✁ ✆ ✮
Example. ■
✚ ✥✌✣ ✠✎✆ ✔ ✄ ☛✕✒ ✚ ✒✑✠✗✔ ✟☞✥✎✄ ✁ ✥✎✄✢✩☎✟✎✆ ✧✪✄ ✖✕✠ ✄✢✚ ✒☎✣ ✆ ✁ ❅☞☛✕✁ ✥✎✄✵✚ ✥✶✄ ✖✕✁✡✖✕✁ ✠☞✆ ✄✢✒ ☛✕✆ ✦☞✁ ✆ ✝✪✔ ✟✎✆ ✘✕☛✕✒ ✮✢❏ ✄ ✒
✜ ✁ ✣ ✄☎✠☞✥✕✧✶✆ ✚ ✦☞✖✎✄✑✔ ✟✎✥☞✄ ✁ ✭✌✄ ■ ✒✑✠✎✆ ✁ ■ ✜ ✁ ✒☎✘✕✠✎✄ ✚ ✁ ✥☞✄ ✒☎✠ ✬☞✁ ✔ ■ ✠☞✥✕✧ ■ ✍✏✠✎✚ ✒✓✒ ✠☞✥✕✒✑✠✎✥✕✦☞✚ ✟✎✘✕✜ ✠☞✒ ✄ ✚ ✁ ■ ❃
■ ✱✻✁ ✒☎✘✕✠✎✄ ✚ ✁ ✥☞✄ ✒☎✠ ✬☞✁ ✔ un infarctus ✍✏✠☞✚ ✒✓✒ ✠☞✥✕✒☎✠☞✥✕✦✎✚ ✟☞✘✕✜ ✠✎✒ ✄ ✚ ✁ ■
❑ ✯☎✖✕✁✵✘✕✠ ✄ ✚ ✁ ✥✎✄ ✒☎✩✑✚ ✄ ✖✶✠✞✖✕✁ ✠✎✆ ✄✢✠ ✄ ✄ ✠☞✔ ✼ ✛✕☛✌✄☎✩✑✚ ✄ ✖✕✟☞☛✌✄✑✠✎✥✕✦☞✚ ✟✎✘✕✜ ✠☞✒ ✄ ✝☞✮ ▲
✯☎✖✌✁✗✒ ✝✕✒ ✄ ✁ ✍▼✩✑✚ ✜ ✜✴✁ ✭☞✄ ✆ ✠☞✔ ✄✞✄ ✖✕✁✗✘✕✆ ✚ ✍✏✚ ✄ ✚ ✬☞✁✞✔ ✟✎✥✕✔ ✁ ✘✌✄ ✒ ❃ Patient ★ Infarct ✠✎✥✕✧ (not Angioplasty)
✠✎✥✕✧✲✚ ✄✏✔ ✟✎✍✞✛✕✚ ✥✕✁ ✒✞✄ ✖✕✁ ✍◆✟✎✛✌✄ ✠☞✚ ✥✕✚ ✥✕✦✳✍✏✟☞✆ ✁✶✔ ✟☞✍✏✘✕✜ ✁ ✭✲✧✕✁ ✒ ✔ ✆ ✚ ✘✌✄ ✚ ✟✎✥✕✒ ✮❖ ✂✁✗✩✑✚ ✜ ✜☎✔ ✟✎✍✞✛✕✚ ✥✕✁ Patient
✠✎✥✕✧ Infarct ✽ ✩✑✖✕✚ ✜ ✁ ■ ✠ ✬☞✁ ✔✵☛✕✥✪✚ ✥✌✣ ✠✎✆ ✔ ✄ ☛✕✒ ■ ✍✏✟✌✧✕✚ ✷✸✁ ✒✓✄ ✖✕✁✵✥✕✟☞☛✕✥✪✘✕✖✕✆ ✠✎✒ ✁ ■ ✜ ✁ ✒✑✘✕✠ ✄ ✚ ✁ ✥✎✄ ✒ ■ ✿✓✠☞✥✕✧✶✠☞✜ ✒ ✟
✠✎✥✕✧ (not Angioplasty) ★✴☛✕✒ ✚ ✥✕✦✪✰✢✱❄✆ ✁ ✠✎✒ ✟☞✥✕✚ ✥✕✦✪✍✏✟✌✧✕☛✕✜ ✁✪✽ ✄ ✖✕✁ ✆ ✁✗✚ ✒✡✠✪✆ ✟☞✜ ✁✏✆ ✁ ✜ ✠ ✄ ✚ ✥✕✦✶✄ ✖✕✁
✄ ✩☎✟✞✔ ✟✎✥✕✔ ✁ ✘✌✄ ✒ ✿ ✮
Patient

✰✢☛✌✁☎✄ ✟✵✰✢✱✪✔ ✠✎✘✕✠☞✛✕✚ ✜ ✚ ✄ ✚ ✁ ✒✫✟ ✣✻✧✕✁ ✠☞✜ ✚ ✥✕✦✑✩✑✚ ✄ ✖✏✚ ✥✕✔ ✟☞✍✏✘✕✜ ✁ ✄ ✁☎✠✎✥✕✧✏✒ ✁ ✍✏✚ ❊ ✒ ✄ ✆ ☛✕✔ ✄ ☛✕✆ ✁ ✧✏✧✕✠ ✄ ✠✕★✎✄ ✖✕✁✑✥✕✁ ✩❖✔ ✟✎✥✌❊
✔ ✁ ✘✌✄ ✒✴✚ ✧✕✁ ✥✎✄ ✚ ✷✸✁ ✧✏✚ ✥✡✄ ✖✕✁☎✄ ✁ ✭✌✄✓✠✎✆ ✁✑✔ ✟☞✍✡✛✕✚ ✥✕✁ ✧✞✠☞✥✕✧✏✧✌✝✌✥✕✠☞✍✏✚ ✔ ✠☞✜ ✜ ✝✡✠☞✧✕✧✕✁ ✧✞✄ ✟✢✄ ✖✕✁✑✁ ✭✕✚ ✒ ✄ ✚ ✥✕✦✵✖✕✚ ✁ ✆ ✠☞✆ ✔ ✖✎✝☞✮
❏ ✣✫✄ ✖✕✁✵✥✕✁ ✩✧✕✁ ✷✸✥✕✚ ✄ ✚ ✟✎✥✕✒✑✠☞✆ ✁✵✥✕✟✎✄✢✔ ✟☞✥✕✒ ✚ ✒ ✄ ✁ ✥☞✄✑✩✑✚ ✄ ✖✶✄ ✖✕✁✡✁ ✭✕✚ ✒ ✄ ✚ ✥✕✦✏✟✎✥✕✁ ✒ ★✸✄ ✖✕✁ ✥✶✄ ✖✕✁✡✟✎✜ ✧✕✁ ✆☎✧✕✁ ✷✸✥✕✚ ✄ ✚ ✟✎✥
✚ ✒✓✆ ✁ ✘✕✜ ✠✎✔ ✁ ✧✶✛☞✝✶✠✏✧✕✚ ✒ ❆ ☛✕✥✕✔ ✄ ✚ ✟☞✥✶✟ ✣✤✄ ✩✓✟✏✧✕✁ ✷✸✥✕✚ ✄ ✚ ✟✎✥✕✒ ❃
Ontologies for Information Retrieval
✂✁☎✄✝✆ ✞✠✟✠✡☞☛✂✌✠✍✠✎✑✏✂✒✠✍✑✏✠✏✂✍✔✓ ✕✖✆ ✞✠✗✔✗☞✘✙✍✙✚✑✛✠✜✑✢✔✣✠✏✔✘✙✤✑✢✥✗✙✌✑✦✠✏✠✧✂✍✔★ ✩✠✪✙✎✔✌✔✍✔✚ ✏✂✫✔✫
✔✬✭✄✝✆ ✞✠✟✠✡☞☛✂✌✠✍✠✎✑✏✂✒✠✍✑✏✠✏✂✍✔✓ ✕✖✆ ✛✠✮✑✯✠✰✱✘✂✍✔✚✠✛✑✜✠✢✠✣✔✏✠✘✂✤ ✢✲✆ ✟✙✮ ✳✥✗✔✌✠✦✑✏✔✧✙✍✙★ ✩✔✪✔✎✙✌✠✍✙✚ ✏✴✫✠✫✔✫
✵✷✶✔✸✺✹ ✻✽✼✿✾✙✸ ❀✂❁✙❂ ✹ ❂ ✼✑❁✙❃✷❄✠❅ ✸❇❆ ✼✠❁✑✹ ❅ ❄✠✾✙❂ ❆ ✹ ✼✠❅ ❈❉❃ ✼❊✹ ✶✙✸❇❁✙✸ ✻✱❆ ✼✑❁✙❆ ✸ ❋✔✹ ✡✱✄●✆ ✮✑❍✱ ✴✁☎ ✙✬✔✫ ❅ ✸ ❋✙■ ❄✠❆ ✸ ❃❑❏❑▲✠▼
◆ ✠❁ ❈✠✻✽❄ ❈✠❖✴✻✽✸❊✶✙❄ ✠✸❇✹ ✼❉■ ❂ ◗✿❂ ✹✷✹ ✶✙✸❘✶✙❂ ✸ ❅ ❄✠❅ ❆ ✶✑❈❙❃ ❂ ❚ ✸✑❖✴❄✑❋✙❋✙■ ❈✙❂ ❁✙❯❊✹ ✻✽✼❉❆ ❅ ❂ ✹ ✸ ❅ ❂ ❄✙▼ ◆ ❁✙❄ ✹ ❱✙❅ ❄✠■❲◗✿✸ ✹ ✶✙✼✔✾❳❂ ❃
✹ ✼✿❂ ✾✙✸ ❁✠✹ ❂ ❨ ❈❉✹ ✶✙✸❘◗✿✼✠❃ ✹❑❨ ❅ ✸ ❩✔❱✙✸ ❁✠✹❇❆ ✼✠❁✙❆ ✸ ❋✔✹ ❃✺❂ ❁❬✹ ✶✙✸❘✾✙✼✔❆ ❱✙◗✿✸ ❁✑✹ ❖✴❭✙❱✔✹✺✹ ✶✙✸ ❈❳◗✿❂ ❯✠✶✑✹✺❭✂✸❘❆ ✼✑❁✠✹ ❄✑❂ ❁✙✸ ✾❳❂ ❁
❄✑■ ■✴✹ ✶✙✸❘✾✙✼✔❆ ❱✙◗✿✸ ❁✠✹ ❃ ▼ ◆ ❁✙✼ ✹ ✶✙✸ ❅❑❆ ❅ ❂ ✹ ✸ ❅ ❂ ✼✠❁❳❂ ❃✷✹ ✶✙✸❘❃ ❱✙❭✙❃ ❱✙◗✿❋✔✹ ❂ ✼✠❁❬✹ ✸ ❃ ✹✺❪✷❂ ❁❬✹ ✶✙✸❘✶✙❂ ✸ ❅ ❄✠❅ ❆ ✶✑❈❳✻✽✸❊❫✑✸ ✸ ❋
✼✑❁✙■ ❈❳◗✿✼✑❃ ✹❇❃ ❋✂✸ ❆ ❂ ❀✂❆❊❆ ✼✠❁✙❆ ✸ ❋✔✹ ❃ ▼❘❴✔✼✠◗✿✸❘❯✑✸ ❁✙✸ ❅ ❄✠■❵❆ ✼✑❁✙❆ ✸ ❋✔✹ ❃❇❄✑❅ ✸❊❂ ❁❬✹ ✶✙❂ ❃✺❆ ❄✠❃ ✸❘✸ ■ ❂ ◗✿❂ ❁✙❄ ✹ ✸ ✾❉❨ ❅ ✼✠◗❛✹ ✶✙✸
❂ ❁✔✾✙✸ ❜❉❄✠❁✙✾❬✶✠❈✔❋✴✼✑❁✠❈✔◗❘❈❬✼✠❅✷✶✑❈✙❋✂✸ ❅ ✼✑❁✠❈✔◗❘❈✑▼
4.2 Evaluation
✵❵✼✿✶✙❄ ✠✸❘❄❉❅ ✸ ❄✠■❲❂ ◗✿❄✠❯✑✸❇✼ ❨❝✹ ✶✙✸❘✸ ❞✿❆ ❂ ✸ ❁✙❆ ❈✑❖✴✻✽✸❘❁✙✸ ✸ ✾❳✹ ✼✿✹ ✸ ❃ ✹✺✹ ✶✙✸❇❃ ❈✙❃ ✹ ✸ ◗●✼✠❁❳■ ❄✑❅ ❯✠✸❇❆ ✼✠❅ ❋✂✼✠❅ ❄✔▼❑✵✷✶✙✸
❡❑❢❲❣✱✹ ✼✔✼✑■ ❃❘❱✙❃ ✸ ✾❤❨ ✼✠❅❇❂ ✾✙✸ ❁✑✹ ❂ ❨ ❈✙❂ ❁✙❯❉✹ ✸ ❅ ◗✿❃❇❄✠❁✙✾✐❅ ✸ ■ ❄✑✹ ❂ ✼✑❁✙❃❇❭✴✸ ✹ ✻✽✸ ✸ ❁✐✹ ✸ ❅ ◗✿❃❇✻✷✸ ❅ ✸❉✸ ✑❄✠■ ❱✙❄ ✹ ✸ ✾❙❨ ✼✠❅❇❄
❃ ✸ ✹✽✼ ❨❲❥✠❦❇✾✙✼✔❆ ❱✙◗✿✸ ❁✠✹ ❃❧❄✑❭✴✼✑❱✔✹✽❄✠❆ ❆ ❂ ✾✙✸ ❁✠✹ ❃❑♠ ◗✿❄✠❂ ❁✙■ ❈❘◗✿✼✠❱✙❁✑✹ ❄✠❂ ❁❊❄✠❆ ❆ ❂ ✾✙✸ ❁✠✹ ❃ ♥ ▼❧♦✺❁✙■ ❈✿♣✔▲✑q✥❄✠❁✙❁✙✼ ✹ ❄✑✹ ❂ ✼✑❁✙❃
❋✙❅ ✼ ✙❂ ✾✙✸ ✾❬❭✠❈✿✹ ✶✙✸❇❃ ✸ ◗✿❄✑❁✠✹ ❂ ❆✺❆ ✶✠❱✙❁✙❫❬❂ ✾✙✸ ❁✠✹ ❂ ❀✂✸ ❅✷❄✑❅ ✸❇❆ ✼✠❅ ❅ ✸ ❆ ✹ ▼❧✵✷✶✙✸❇✸ ❅ ❅ ✼✠❅ ❃✷❄✑❅ ✸❇✾✙❱✙✸❇◗✿❄✑❂ ❁✙■ ❈❊✹ ✼✿❣✽♦❇❴
✹ ❄✑❯✑❯✠❂ ❁✙❯❙✼✑❅❊✹ ✼❤✸ ❅ ❅ ✼✑❅ ❃✿❂ ❁☎✹ ✶✙✸❬❂ ❁✙❋✙❱✔✹❙♠ ◗✿❂ ❃ ❃ ❂ ❁✙❯❳❨ ❱✙■ ■✷❃ ✹ ✼✠❋✴❖✽❆ ✼✑◗✿◗✿❄✔♥ ▼r✵✷✶✙✸
◗✿✼✠✾✙❱✙■ ✸❊❋✙❅ ✼ ✙❂ ✾✙✸ ❃❘❄❳❃ ✸ ✹❊✼ ❨❑♣✑s✔q●✼ ❨❑❅ ❂ ❯✑✶✠✹❘❄✑❁✙❁✙✼✑✹ ❄ ✹ ❂ ✼✠❁✙❃ ❖❵❭✴✸ ❆ ❄✑❱✙❃ ✸❉❂ ✹❘❋✙❅ ✼✠❋✂✼✠RelevanceChunker ❃ ✸ ❃❘❄❳❃ ✸ ✹❊✼ ❨❑❄✑✾✔❪ ✶✙✼✔❆
❅ ❱✔■ ✸ ❃ ▼❙✵✷✶✙✸❬❅ ✸ ❃ ❱✙■ ✹✿◗✿❂ ❯✑✶✠✹❊❭✂✸❉❂ ◗✿❋✙❅ ✼ ✠✸ ✾✐❂ ❨❑❆ ✼✠◗✿❋✙■ ✸ ❜✐❅ ❱✙■ ✸ ❃❘◗❊❱✙❃ ✹❊❭✴✸❉✾✙✸ ❃ ❆ ❅ ❂ ❭✂✸ ✾✴▼❤t✠✉❙q✖✼✑❨✷✹ ✶✙✸
❅ ✸ ❃ ❱✙■ ✹ ❂ ❁✙❯❳❆ ✼✑❁✙❆ ✸ ❋✔✹ ❱✙❄✠■✽✾✙✸ ❃ ❆ ❅ ❂ ❋✔✹ ❂ ✼✠❁✙❃❉♠ ❋✙❅ ✼ ✙❂ ✾✙✸ ✾☎❭✠❈❤✹ ✶✙✸❬✶✙✸ ❱✙❅ ❂ ❃ ✹ ❂ ❆❉❅ ❱✙■ ✸❉◗✿✼✔✾✙❱✙■ ✸ ♥✺❄✠❅ ✸✿✑❄✠■ ❂ ✾✙❄ ✹ ✸ ✾
❭✑❈❙✹ ✶✙✸✿✈✺❢✭❆ ■ ❄✠❃ ❃ ❂ ❀✂✸ ❅❇❄✠❃❇❆ ✼✑✶✙✸ ❅ ✸ ❁✠✹❘✻❑❂ ✹ ✶❙✹ ✶✙✸✿✼✑✹ ✶✙✸ ❅❇❆ ✼✑❁✙❆ ✸ ❋✔✹❊✾✙✸ ❀✂❁✙❂ ✹ ❂ ✼✑❁✙❃ ▼❉✵✷✶✙❂ ❃❘◗✿✼✔✾✙✸ ❃ ✹❘❅ ✸ ❃ ❱✙■ ✹
❂ ❃✺✾✙❱✙✸❉◗✿❄✑❂ ❁✙■ ❈❳✹ ✼❬✹ ✶✙✸✿❯✑❅ ❄✠❁✠❱✙■ ❄✠❅ ❂ ✹ ❈❤✼✑❁✠✹ ✼✑■ ✼✠❯ ❈r♠ s✑❥❳❆ ✼✠❁✙❆ ✸ ❋✔✹ ❃❘✸ ❜✠✹ ❅ ❄✠❆ ✹ ✸ ✾❤❨ ❅ ✼✑◗●✹ ✶✙❂ ❃❇❃ ◗✿❄✠■ ■❝❃ ✸ ✹❊✼ ❨
✾✙✼✠❆ ❱✙◗✿✸ ❁✠✹ ❃ ♥ ▼❑✇❝✠✸ ❁❙❂ ❨❝✹ ✶✙✸❘❅ ✸ ❃ ❱✙■ ✹ ❃✺❄✑❅ ✸❘❁✙✼✑✹❑✠✸ ❅ ❈❙❂ ◗✿❋✙❅ ✸ ❃ ❃ ❂ ✠✸ ❖✂✹ ✶✙✸❘❢❝❴✔1✷◗✿✸ ✹ ✶✙✼✔✾❳❂ ◗✿❋✙❅ ✼ ✠✸ ✾❬✻❑❂ ✹ ✶
❆ ✼✑❁✙❆ ✸ ❋✔✹ ❃❧❋✙❅ ✼ ✙❂ ✾✙✸ ✾✿❭✴✸ ✹ ✹ ✸ ❅❧✼✑❅❧❃ ❂ ◗✿❂ ■ ❄✑❅❵❋✙❅ ✸ ❆ ❂ ❃ ❂ ✼✠❁❊❄✑❁✙✾✿❅ ✸ ❆ ❄✠■ ■✠✹ ✼✺✹ ✶✙✸❑❫✑✸ ❈✔✻✽✼✠❅ ✾✔❪ ❭✙❄✠❃ ✸❑❃ ✸ ❄✑❅ ❆ ✶✙❂ ❁✙❯✙❖✠❨ ✼✑❅
▲ 2❘❩✔❱✙✸ ❃ ✹ ❂ ✼✠❁✙❃❇♠ ❨ ❅ ✼✠◗3t✠❦❘✹ ✸ ❃ ✹ ✸ ✾✂♥ ▼
5 Conclusion and further work
✵✷✶✔✸❳❋✙❄✠❋✂✸ ❅✿❋✙❅ ✸ ❃ ✸ ❁✠✹ ❃❉❄✐❃ ✸ ◗✿❄✑❁✠✹ ❂ ❆ ❪ ❭✙❄✑❃ ✸ ✾r❄✠❋✙❋✙❅ ✼✑❄✠❆ ✶☎❨ ✼✠❅✿❅ ✸ ✹ ❅ ❂ ✸ ✙❂ ❁✙❯❤❂ ❁✔❨ ✼✑❅ ◗✿❄✑✹ ❂ ✼✑❁✐❨ ❅ ✼✠◗4❄❤❭✙❄✠❃ ✸
✼ ❨✺✾✙✼✔❆ ❱✙◗✿✸ ❁✑✹ ❃ ▼✭✵✷✶✙✸❬❃ ❈✙❃ ✹ ✸ ◗4❂ ❁✠✹ ✸ ❯✠❅ ❄ ✹ ✸ ❃❊❃ ✶✙❄✠■ ■ ✼ ✻❛❁✙❄ ✹ ❱✙❅ ❄✠■✷■ ❄✑❁✙❯✠❱✙❄✑❯✠✸❉❋✙❅ ✼✔❆ ✸ ❃ ❃ ❂ ❁✙❯❙❨ ✼✠❅❊✸ ❜✠✹ ❅ ❄✠❆ ✹ ❪
❂ ❁✔❯❉✹ ✶✙✸✿◗✿✼✠❃ ✹❇❅ ✸ ■ ✸ ✑❄✠❁✑✹❊❃ ✸ ◗✿❄✠❁✑✹ ❂ ❆✿❆ ✶✠❱✙❁✙❫✔❃ ▼❬1 ✹❘❱✙❃ ✸ ❃❘❄❬✾✙✼✠◗✿❄✑❂ ❁❤✶✙❂ ✸ ❅ ❄✠❅ ❆ ✶✑❈❤◗✿❄✠❂ ❁✑✹ ❄✠❂ ❁✙✸ ✾❙❄✠❁✙✾❤✸ ❜✠❪
✹ ✸ ❁✙✾✙✸ ✾❉✻❑❂ ✹ ✶✿✹ ✶✙✸✺✶✙✸ ■ ❋❉✼✑❨❵✈✺❢❤❅ ✸ ❄✑❃ ✼✠❁✙❂ ❁✙❯✔❖✙❄✑❃✽✻✽✸ ■ ■✴❄✑❃✷✼✑❨❵❃ ✶✙❄✑■ ■ ✼ ✻☞❃ ❈✙❁✑✹ ❄✠❆ ✹ ❂ ❆✺❫✔❁✙✼ ✻❑■ ✸ ✾✙❯✠✸ ❖✂❱✙❃ ✸ ✾❉❨ ✼✑❅
❆ ✼✑◗✿❋✙❱✔✹ ❂ ❁✙❯❉❃ ✸ ◗✿❄✠❁✑✹ ❂ ❆❘❅ ✸ ❋✙❅ ✸ ❃ ✸ ❁✑✹ ❄✑✹ ❂ ✼✑❁❳❨ ✼✠❅✷✹ ✸ ❜✠✹ ❃❇❄✑❁✙✾❙❩✠❱✙✸ ❅ ❂ ✸ ❃ ▼❇✵✷✶✙✸❊✾✙✼✠◗✿❄✑❂ ❁❳✶✙❂ ✸ ❅ ❄✠❅ ❆ ✶✑❈❙❂ ❃✺❭✙❱✙❂ ■ ✹
❃ ✸ ◗✿❂ ❪ ❄✠❱✔✹ ✼✑◗✿❄✑✹ ❂ ❆ ❄✠■ ■ ❈✑❖✠❭✠❈❬❄✿❭✂✼✑✹ ✹ ✼✑◗❊❪ ❱✙❋❉❄✠❋✙❋✙❅ ✼✑❄✠❆ ✶✴▼
References
❪                                                             ❖❝❂ ❁
S.Ait-Mokhtar, J.-P.Chanod Incremental Finite-State Parsing
❖✙5❳❄✑❅ Proceedings
❆ ✶❙▲ s✑s✔2✠❖✔6✐❄✑of
❃ ✶✙❂ the
❁✙❯✑✹ 5th
✼✑❁✴❖
ACL Conference on Application of Natural Language Processing
❋✙❋✴▼✴2✠✉ ❪ 2 s✙▼
❪                                                                                                                ❖❲❂ ❁
J.Ambroziak, W.Woods Natural Language Technology in Precision Content Retrieval
Proceedings of the International
❃ ✹❘▲ ❥ ❪ ✉✠▲✠❖✴▲ s✠on
❖ ◆ ❱✙❯✑❱✙Conference           s✑❥✙Natural     ✼✠❁✴❖✂❡✺✸ ✻✥7✽Processing
❖✂5❬✼✠❁✙❆ ✹ Language       ❅ ❱✙❁✙❃ ✻❑❂ ❆ ❫✂❖✴and
❏ ◆ ❡ Industrial
◆ ✈ ◆
Applications (NLP+IA 98)
A.Todirascu et F.Rousselot
✂✁ ☎  ✄✝✆ ✞✝✟ ✠✡✄✝☛☞✄✍✌✏✎✑✆ ✄✓✒ ✔ ✟ ✟ ✕ ✌✡✖✘✗✙✔ ✒ ✚ ✛✝✆ ✛ ✜ ✕ ✢✝✔✤✣✤✌✡✄ ✥✦✚ ✔ ✧✡✖✝✔ ✁ ✎✑✗✙✣✩★ ✪✡✫✍✬
F.Baader, B.Hollunder A terminological Knowledge Representation systems with Complete
Inference Algorithms

✁ ✕✌
B.Bachimont Engagement sémantique et engagement ontologique: conception et réalisation

✭✯✮✡✆ ✄✍✚ ✚ ✔ ✟✰✎✑✱✡✲✡✚ ✕ ✟ ✠✡✕ ✌✡✖✩  ✳✦✄✝✱✡✟ ✔ ✁✵✴ ✶✝✶✍✶✡✁ ☛✡☛✷✬✹✸ ✶✝✺   ✸ ✴ ✻ ✬                                                                                                ✁
d’ontologies en ingénierie des connaissances        J.Charlet, M.Zacklad, G.Kassel,
D.Bourigault (eds.) Ingénierie des connaissances - Evolutions récentes et nouveaux défis
J.Bouaud, B.Habert, A.Nazarenko, P.Zweigenbaum Regroupements issus de dépendances
✁ ✕✌                                                                    ✭✁ ✯✮✡✆ ✄✍✚ ✚ ✔ ✟✯✎✑✱✡✲✡✚ ✕ ✟ ✠✡✕ ✌✡✖✤✳✦  ✄✝✱✡✟ ✔ ✁✹✴ ✶✝✶✍✶✡✁
syntaxiques sur un corpus de spécialité: catégorisation et confrontation à deux conceptuali-
sations du domaine     J.Charlet, M.Zacklad, G.Kassel, D.Bourigault (eds.) Ingénierie
☛✡☛✷✬ ✝✴ ✼✍✺   ✴ ✪ ✶ ✬
des connaissances - Evolutions récentes et nouveaux défis
P.Buitelaar   CORELEX: Systematic Polysemy and Underspecification ✁
✎✑✠✷✬ ✗✽✬✡✜ ✠✡✔ ✟ ✕ ✟ ✁✹✾ ✆ ✛✍✌
✧✡✔ ✕ ✟✰✿✙✌✡✕ ✢✝✔ ✆ ✟ ✕ ✜ ✮ ✁ ✗✙✔ ☛✡✛✍✆ ✜ ❀✘✔ ✌✍✜✙✄ ❁✑❂❃✄✝❀✘☛✡✱✓✜ ✔ ✆✙❄✓✒ ✕ ✔ ✌✡✒ ✔ ✁ ✫ ✪✝✪✍❅
N.Capponi, Y.Toussaint   Interprétation de classes de termes par généralisation de structures
✕✌
prédicat-argument ✁ J.Charlet, M.Zacklad, G.Kassel, D.Bourigault (eds.)   Ingénierie des
connaissances - Evolutions récentes et nouveaux défis ✁
✭✯✮✡✆ ✄✍✚ ✚ ✔ ✟✯✎✑✱✡✲✡✚ ✕ ✟ ✠✡✕ ✌✡✖✙✳✦✄✝✱✡✟ ✔ ✁✡✴✍✶✍✶✝✶✓✁ ☛✡☛✷✬
✸✝✸ ✼   ✸ ✺ ❆ ✬
S.Dumais   LSI meets TREC: A status report. ❇ D.K.Harman, ed.   The First Text Retrieval
Conference (TREC-1) ✁✵✺ ✶✝✶   ✴ ✶✓✼✝✁
☛✡☛✷✬❈✫ ✸ ✼   ✴ ✶✓✼✝✁✷❉ ✛✝✕ ✜ ✠✡✔ ✆ ✟ ✲✡✱✡✆ ✖ ✁✹❊ ✗ ✁✵❊ ✛✝✆ ✒ ✠❋✫ ✪✝✪✍✸✡✬✡● ❇ ❄✓❍■❄✓☛✷✔
✒ ✕ ✛✍✚✵☛✡✱✡✲✡✚ ✕ ✒ ✛✍✜ ✕ ✄✍✌✷✬
C.Jacquemin   Improving Automatic Indexing through Concept Combination and Term En-
✕✌
(COLING’98) ✁
☛✡✛✝✖✍✔ ✟ ✺ ✪ ✺   ✺ ✪✍✪ ✁✹❊ ✄✝✌✍✜ ✆ ❏ ✛✍✚ ✬
richment Proceedings of the 17th International Conference on Computational Linguistics
J.Lecomte   Le Catégoriseur BRILL14-JL5/WINBRILL-0.3 ✁ ❇
✌✡✛✝❑✵▲ ✁ ❇ ✌✡✛✝❑✵▲✑▼✝❂❃●✦◆✙❄❋✆ ✔ ☛✹✄✝✆ ✜ ✁
✗✙✔ ✒ ✔ ❀✽✲✷✔ ✆✤✫ ✪✍✪✝❅✓✬
T.Read, E.Barcena   JaBot:a multilingual Java-based inteligent agent for Web sites ✁
✕ ✌✩❂✰❖✙❑
❇ ● ❉ ★ ✪✝❅ ✁✷❊ ✄✝✌✍✜ ✆ ✔ ✛✍✚ ✁ ❂❃✛✝✌✡✛✍✧✡✛ ✁ ✫ ✶   ✫ ✻✩ ✱✡✖✍✱✡✟ ✜✽✫ ✪✍✪✝❅
E. Riloff, J.Lorenzen   Extraction-based Text Categorization Generating Domain-Specific
Role Relationships Automatically ✁
✕ ✌✘✔ ✧✷✬ T.Strzalkowski✁ Natural Language Information Re-
trieval ✁
✣✤✚ ✱✍✥✰✔ ✆  ✒ ✛✍✧✡✔ ❀✘✕ ✒✤✎✑✱✡✲✡✚ ✕ ✟ ✠✡✔ ✆ ✟ ✁ ✫ ✪✍✪✝✪
D.Rudloff, F. de Beuvron, M.Schlick   Extending Tableaux Calculus with Limited Regular
Expression for Role Path : an Application to Natural Language Processing ✁
✗✙❑✯★ ✪✍❅ ✁ ❍❈✆ ✔ ✌✝✜ ✄ ✁
✜❇ ✛✍✚ ✮ ✁ ✫ ✪✍✪✝❅
P.Vossen   EuroWordNet - A Multilingual Database with Lexical Semantic Networks ✁
✣✤✚ ✱✍✥✰✔ ✆
 ✒ ✛✍✧✡✔ ❀✘✕ ✒✤✎✑✱✡✲✡✚ ✕ ✟ ✠✡✔ ✆ ✟ ✁ ✫ ✪✝✪✍❅
C. Welty, N. Ide   Using the right tools: enhancing retrieval from marked-up documents ✁
✕✌
J. Computers and the Humanities ✁
✣✤✚ ✱✝✥❃✔ ✆ ✁ ✸✍✸✹◗ ✫ ✶✓❘ ❙ ✺ ✪   ❅ ✻ ✬  ☛✡✆ ✕ ✚ ✁ ✫ ✪✝✪✍✪✡✬
J.Zhou   Phrasal Terms in Real-Word IR Applications ✁ T.Strzalkowski   Natural Language
✕✌
Information Retrieval ✁
✤  ✚ ✍
✱ ✥ ✰ ✔ ✆   ✒ ✛
✍    ✧ ✡ ✔ ❀ ✘ ✕ ✒ ✤ ✎ ✑ ✡
✱ ✡
✲ ✚   ✕ ✟ ✠ ✡ ✔ ✆ ✟ ✁ ✫ ✪✍✪✝✪
