
LOGUS : un système formel de compréhension du français
parlé spontané — présentation et évaluation

Jeanne Villaneau (1), Jean-Yves Antoine (1), Olivier Ridoux (2)
(1) VALORIA — Université de Bretagne Sud
4, rue Jean Zay, 56100 L ORIENT
Jeanne.Villaneau,Jean-Yves.Antoine @univ-ubs.fr
(2) I RISA / I FSIC — Université de Rennes 1
Campus universitaire de Beaulieu, 35042 R ENNES cedex
Olivier.Ridoux@irisa.fr
Résumé - Abstract

Le système de compréhension présenté dans cet article propose une approche logique et
lexicalisée associant syntaxe et sémantique pour une analyse non sélective et hors-cadres
sémantiques prédéterminés. L’analyse se déroule suivant deux grandes étapes ; un chunking
est suivi d’une mise en relation des chunks qui aboutit à la construction de la représentation
sémantique finale : formule logique ou graphe conceptuel. Nous montrons comment le for-
malisme a dˆu évoluer pour accrôıtre l’importance de la syntaxe et améliorer la généricité des
règles. Malgré l’utilisation d’une connaissance pragmatico-sémantique liée à l’application,
la spécificité du système est circonscrite au choix des mots du lexique et à la définition de
cette connaissance. Les résultats d’une campagne d’évaluation ont mis en évidence une bonne
tolérance aux inattendus et aux phénomènes complexes, prouvant ainsi la validité de l’approche.
We present in this paper a speech understanding system with a lexicalized logical approach com-
bining syntax and pragmatic knowledge, but without selective methods or predefined semantic
frames. The analysis is split into two phases: a chunking phase is followed with a second phase
in which different chunks are combined in order to obtain the semantic representation of the
sentence: logical formula or conceptual graph. We show how we have changed the formalism
to increase the part of the syntax and to obtain generic rules. Despite the use of a semantic
knowledge linked to the application, the specificity of the system is limited to the lexicon and
to the definition of this knowledge. The results of an evaluation campaign have showed a good
tolerance with the spontaneous spoken utterances and with the complex phenomena, and so,
they have showed the value of this approach.
Mots-clefs – Keywords

langue parlée spontanée, compréhension automatique, méthodes formelles
spontaneous spoken language, automated understanding, formal methods

165
Jeanne Villaneau, Jean-Yves Antoine, Olivier Ridoux
1 Introduction et présentation générale

L’apparition de serveurs vocaux mis à la disposition du grand public témoigne des progrès ac-
complis depuis quelques années dans la Communication orale Homme-Machine (CHM orale).
Cependant, ces indéniables succès sont encore restreints à des tˆaches très spécifiques dans
des domaines d’application étroits. En aval des modules de reconnaissance de la parole, les
modules de compréhension s’appuient sur des analyses souvent sélectives, minimalistes d’un
point de vue strictement linguistique. Bien que ces méthodes aient prouvé leur efficacité pour
ce type d’application, la question n’est pas tranchée de savoir si elles sont encore utilisables
pour des tˆaches moins restrictives (Hirschman, 1998). Par ailleurs, dans ces applications, la
compréhension d’un énoncé correspond souvent à la reconnaissance d’un schéma lié à la tˆache
et prédéterminé ; la mise en œuvre d’un dialogue plus coopératif passe par une compréhension
plus fine des intentions du locuteur (Pierrel et Romary, 2000). Le problème est donc de proposer
des analyses d’énoncés oraux qui soient flexibles et tolérantes aux inattendus mais néanmoins
détaillées, et qui puissent produire une représentation sémantique souple et fine de ces énoncés.
Notre démarche consiste à faire reposer l’analyse sur une approche à la fois syntaxique et
sémantique1 en nous appuyant, autant que cela est possible, sur les études linguistiques ex-
istantes de l’oral spontané.
Les inattendus de la parole spontanée rendent illusoire une analyse syntaxique complète des énoncés oraux. Cependant, des arguments linguistiques plaident en faveur de la possibilité
d’une analyse syntaxique locale de ces énoncés : les études de Blanche-Benveniste sur le
français parlé (Blanche-Benveniste, 1990) attestent de régularités dans les “modes de produc-
tion de la langue orale”. L’une d’entre elles, particulièrement intéressante pour l’analyse, est
l’entassement paradigmatique : la recherche des mots suscite chez le locuteur un processus de
répétitions-corrections dans lequel les syntagmes sont systématiquement repris en leur début
comme dans cet exemple : “pour la euh vers la station enfin euh vers la station de m étro”.
Ainsi, ce processus préserve des structures minimales de groupes de mots syntaxiquement
cohérentes. Les méthodes d’analyse partielle deviennent courantes en TALN : ex. bunsetsu
pour la langue japonaise, ou chunks pour la langue anglaise, décrits par Abney comme des
unités sémantiques et prosodiques (Abney, 1991). La correspondance entre les syntagmes de
Blanche-Benveniste et les chunks d’Abney est évidente. On peut en conclure qu’un chunking
est possible pour les énoncés oraux, avec l’avantage essentiel de réduire le nombre d’éléments
de l’énoncé tout en rendant chacun d’entre eux plus “signifiants”.
La structure générale de l’énoncé correspond aux liens entre chunks. Or si, en français, l’ordre
des mots est relativement respecté dans un chunk, il n’en est pas de même de l’ordre des chunks
dans un énoncé (Antoine et Goulian, 1999). Dans la mesure cependant o`u les chunks possèdent
une identité sémantique suffisante, on peut penser que la détermination de ces liens entre chunks
peut ê tre étayée par les connaissances sémantiques du système. Il va de soi que celles-ci seront
d’autant plus faciles à mettre en œuvre que le domaine de l’application permettra de restreindre
l’ambigüıté.
Le système de compréhension présenté dans cet article s’appuie sur le principe d’une analy-
se en deux grandes étapes : la première locale et à forte dominante syntaxique, la seconde
plus globale et syntaxico-sémantique. L’approche est logique, tant dans les représentations
choisies pour la compréhension que pour le formalisme des règles appliquées. Le domaine
1
Parmi les travaux adoptant des approches plus ou moins similaires, citons (Lopez, 1999; Kurdi, 2001; Goulian
et Antoine, 2001).

166
LOGUS : présentation et évaluation
d’application est celui du renseignement touristique, suffisamment vaste pour qu’il soit difficile
de prédéterminer toutes les requêtes possibles et néanmoins suffisamment restreint pour qu’il
soit possible de définir une connaissance sémantique spécifique 2 . Notre présentation se base
sur la comparaison entre les deux premiers prototypes du système. En effet, le premier objec-
tif était la mise en œuvre d’une analyse à la fois fine et robuste, sans faire appel à des cadres
sémantiques prédéterminés, mais en s’appuyant sur une connaissance sémantique spécifique au
domaine d’application. Une évaluation du premier prototype a prouvé que cet objectif était,
sinon complètement atteint, du moins réalisable. Le second système, L OGUS 3 , correspond à un
objectif de généricité : en effet, vouloir s’appuyer sur les connaissances sémantiques spécifiques
au domaine et en même temps prétendre concevoir des règles indépendantes de ce domaine peut
sembler a priori paradoxal. Le formalisme adopté dans L OGUS semble prouver qu’il est possi-
ble de concilier une certaine généralité des règles et l’utilisation d’une connaissance sémantique
spécifique. La comparaison des résultats des 2 systèmes montre que L OGUS cumule les avan-
tages d’une plus grande généricité et d’une plus grande finesse dans l’analyse.
2 Premier prototype : principes et limites
Si l’on veut construire un système de compréhension relativement générique, il convient de
choisir une modélisation du “sens” de l’énoncé indépendante de l’application et qui permette
d’exprimer tout acte de dialogue lié à cette dernière : le système cherche à construire une
formule logique de façon compositionnelle (ex. à la Montague (Montague, 1974), mais avec un
formalisme simplifié). La même formule correspond à un graphe conceptuel à la Sowa (Sowa,
1984; Sowa, 1900). Par exemple, l’énoncé
“est-ce que c’est possible de euh de réserver trois chambres non pardon deux chambres doubles
et une chambre simple.”
correspond à la formule suivante ou au graphe conceptuel de la figure 1 :
(interrogation possibilite
(de reservation (et (chambre (et (quantite (entier 2))
(qualites double)))
(chambre (et (quantite (entier 1))
(qualites simple))))))

quantite   (entier 2)
chambre
qualites   double
possibilite    interrogation   reservation    de
quantite   (entier 1)
chambre
qualites    simple
Figure 1: Représentation de la phrase-exemple sous forme de graphe conceptuel
Dans le premier prototype, l’analyse se déroule suivant deux étapes principales (Villaneau et al,
2001) :
2
On considère que le lexique lié à une telle application comprend entre 5000 et 10000 entrées.
3
L OGical Understanding System

167
Jeanne Villaneau, Jean-Yves Antoine, Olivier Ridoux
̄ Le lexique donne, pour chaque lexème connu, une ou plusieurs définitions dont chacune
est un -terme. Dans l’étape de chunking, les règles utilisées sont d’ordre exclusive-
ment syntaxiques. Elles correspondent aux deux règles de composition des grammaires
catégorielles de type AB (Retoré, 2000) :

–   ́      Ò μ           : composition d’un élément de catégorie avec un élément de
catégorie fractionnaire Ò situé à sa droite pour former un élément de catégorie .
–   ́          μ          : composition d’un élément de catégorie fractionnaire       avec
un élément de catégorie situé à sa droite pour former un élément de catégorie .

Les “représentations sémantiques” de ces chunks sont obtenues par composition de
-termes suivant le principe du calcul de Lambeck (Moorgat, 1997). Ainsi par exem-
ple, les mots pas et cher correspondent respectivement aux -termes (adj/adj x.(pas x))
et (adj cher). L’application de la première règle donne en résultat (adj (pas cher)).

̄ A
` l’issue de l’étape de chunking, les syntagmes peuvent ê tre classés en trois catégories :

– les propriétés et objets de l’application,
– les syntagmes qui permettent de connaître la nature de l’énoncé,
– les marqueurs des coordinations : coordinations proprement dites mais aussi mar-
ques d’hésitation ou de reprise.

La connaissance sémantique du système est définie par des relations de deux types :

– Les relations entre les objets, entre les objets et les propriétés et entre les pro-
priétés elles-mêmes peuvent ê tre considérées comme des graphes conceptuels élémentaires ou comme des contraintes imposées à ces graphes, comme par exemple
est sous objet(chambre,de,hotel) ou est propriete de((entier X),quantite,chambre).
Si les objets et propriétés sont spécifiques au domaine d’application, les relations
elles-mêmes ont été choisies pour leur généricité. Le système s’appuie sur ces re-
lations pour construire des graphes conceptuels sémantiquement cohérents (appelés
“chaînes d’objets” ).
– Une autre partie de la connaissance sémantique est générique. Elle concerne par
exemple la nature de l’énoncé. En particulier, lorsque l’énoncé correspond à une
requête, la détermination de la nature de cette requête repose sur une relation d’ordre
partiel définie sur les “mots questions”ou “mots requêtes”. Dans les deux exem-
ples suivants, la requête correspond au “mot” le plus fort indiqué par la relation
d’ordre :
([“je voudrais”],[“savoir s”],[“il y a”])        il y a
([“je voudrais”],[“la liste”],[“s il vous plaît”]) liste

La formule sémantique d’une phrase s’obtient par composition de la nature de l’énoncé
avec la ou les chaînes d’objets obtenues, sous le contrôle de la connaissance sémantique
qui en vérifie la cohérence.

Le premier prototype a été soumis à une campagne d’évaluation dans le cadre du groupe de
travail 5.1 “compréhension robuste” du GDR I3 du CNRS (Antoine, 2001). L’objectif de cette évaluation était de porter un diagnostic sur les systèmes testés par une analyse fine des erreurs
observées en regard des approches adoptées. Les résultats obtenus (les chiffres et quelques

168
LOGUS : présentation et évaluation
commentaires concernant les différentes séries d’énoncés tests sont donnés au Ü4) montrent une
grande robustesse du système face à l’ordre des différents chunks, à la plupart des inattendus
structuraux de l’expression orale (corrections, répétitions, reprises) et aux objets complexes.
Entre autres, très peu d’erreurs sont engendrées par l’étape du chunking et les liens sémantiques établis entre les objets et leurs propriétés sont rarement erronés. Les erreurs les plus fréquentes
concernent les incises et les faux-départs. En effet, l’absence totale de syntaxe dans la deuxième
partie de l’analyse à laquelle s’ajoute une ignorance pure et simple des mots hors vocabulaire
rend impossible leur reconnaissance. Cette même absence de syntaxe ne permet pas de dis-
tinguer les différentes parties d’un énoncé du type information-requête, absent des tests de
l’évaluation mais assez fréquemment rencontré dans les corpus, tel que, par exemple : “j’ai
réservé à l’hôtel Caumartin comment je peux faire pour y aller d’ici”.
Par ailleurs et surtout, ce premier prototype est trop dépendant de l’application étudiée. La
connaissance sémantique y est mal circonscrite, et si ses grands principes sont réapplicables,
il n’en est pas de même des règles utilisées, tant dans la phase du chunking que dans la phase
d’établissement des liens sémantiques.
3 LOGUS : représentations et règles
Des considérations sémantiques peuvent intervenir pour simplifier le chunking : par exemple,
la préposition pour n’est pas indispensable à la compréhension dans l’expression “c’est pour
une demande...”. Mais surtout, l’analyse des erreurs a montré la nécessité d’introduire des éléments syntaxiques dans la deuxième partie de l’analyse.
Le formalisme élaboré pour L OGUS répond donc à un double objectif : d’une part il doit offrir
la possibilité d’associer la syntaxe et la sémantique tout au long de l’analyse ; d’autre part, il
doit aussi permettre de définir des règles de composition indépendantes de l’application et ce,
dans les deux étapes de l’analyse.
3.1 Modélisation

Pour concilier ces exigences, qui peuvent sembler contradictoires, de règles fondées sur des
arguments en grande partie sémantiques et en même temps indépendantes de l’application, les
lexèmes, puis, à chaque étape de l’analyse, les composants obtenus, sont représentés par un
triplet composé de :

1. Une catégorie syntaxique : les catégories peuvent ê tre simples ou fractionnaires, par
exemple : adjectif, nom commun, (det indef plur) (pour (déterminant indéfini pluriel))
sont des catégories syntaxiques simples.

2. Un rôle sémantique qui peut également ê tre simple ou fractionnaire ; il correspond à
une classification des différents constituants en objets, propriétés et autres mots. Par
exemple, objet, (prop quantite) (pour propriété de quantit é), interrogation sont des rôles
sémantiques simples.

3. Une représentation sémantique qui correspond à la traduction proprement dite du consti-
tuant.

169
Jeanne Villaneau, Jean-Yves Antoine, Olivier Ridoux
Ainsi, la définition du mot “réserver” est   Ò Ò Ø Ó Ø Ö × ÖÚ Ø ÓÒ , le lexème “peut-
on” correspond au triplet :        ́ Ú ¿ ÔÖ × ÒØμ ÒØ ÖÖÓ Ø ÓÒ ÔÓ×× Ð Ø           o`u la catégorie
4
syntaxique indique un groupe verbal à la troisième personne au présent . Les mots inconnus se
voient attribuer une catégorie syntaxique et un rôle sémantique spécifiques.
Les catégories syntaxiques sont totalement indépendantes de l’application. Les rôles
sémantiques le sont dans une très large mesure mais pas complètement, en particulier pour
ce qui concerne les étiquettes des propriétés : aussi génériques soient-elles, des propriétés telles
que lieu et temps peuvent ne pas ê tre des propriétés des objets du domaine. Dans le déroulement
de l’analyse, à quelque niveau que ce soit, les règles utilisées sont définies à partir des deux pre-
miers éléments du triplet et des relations qui constituent la connaissance sémantique du système
concernant les objets de l’application.
3.2 Le chunking

Les deux premiers champs du triplet peuvent ê tre de type fractionnaires (au sens des règles des
grammaires AB). La représentation sémantique correspondante est alors une abstraction au sens
des -termes. Le regroupement des mots dans un chunk correspond à l’application des deux
règles suivantes5, directement dérivées des deux règles des grammaires AB. La “représentation
sémantique ” du triplet issu de la règle est le résultat de l’application de l’abstraction à la
représentation sémantique du triplet “atomique” :

̄   ́      1⁄2   Ê1⁄2 Ë1⁄2                1⁄2Ò   3⁄4   Ê1⁄2 ÒÊ3⁄4    ́       ×ØÖ   μ   μ            3⁄4   Ê3⁄4   ́   Ë1⁄2 μ
̄   ́      1⁄2     3⁄4   Ê1⁄2 Ê3⁄4     ́   ×ØÖ       μ             3⁄4   Ê3⁄4 Ë3⁄4     μ            1⁄2   Ê1⁄2   ́   Ë3⁄4 μ

Par exemple, les mots “trop” et “pas” ont respectivement pour catégorie syntaxique
́        Ø Ò     Ø μ et ́     Ø Ò       μ (      correspondant à “chunk adjectival”), pour
rôle sémantique ́ÔÖÓÔ ÊμÒ́ÔÖÓÔ Êμ ; les -termes qui leur sont associés sont respective-
ment 1⁄2         Ü Ü et 3⁄4     Ü ́Ô × Üμ ; C’est ainsi que l’expression “pas trop cher” corres-
pond au triplet          ́ÔÖÓÔ Ø Ö μ ́Ô × Ð Ú μ       o`u ́Ô × Ð Ú μ correspond au -terme
́ Ü ́ 3⁄4 ́ 1⁄2 Üμμ Ð Ú μ.

La mise en œuvre du chunking correspond à l’application de toutes les compositions possibles.
Les solutions retenues sont celles qui aboutissent à un nombre minimum de constituants. Le
chunking est délibérément minimaliste (c-à-d. les chunks sont très courts) 6 ce qui fait que dans
la pratique, le chunking produit rarement plusieurs solutions optimales.
à l’issue du chunking, certains constituants sont éliminés : c’est le cas par exemple des
déterminants et prépositions ainsi que, d’une manière générale de ceux qui correspondent à
des catégories syntaxiques et rôles sémantiques fractionnaires, ce qui constitue un premier
traitement des reprises et hésitations. Ainsi, dans l’exemple ”pour la euh vers la station”,
le syntagme incomplet ”pour la” se trouve éliminé.
4
Ce lexique dépend de l’application dans le choix des mots et de leurs définitions : le mot “prix” ne fait
référence qu’à la valeur vénale (et pas à la récompense) et le mot “ étoile” ne se réfère qu’aux hôtels et restaurants.
5
Les règles utilisées font également intervenir des relations d’ordre sur les catégories suivant un formalisme
inspiré du calcul sur les prégroupes (Buszkowski, 2001).
6
Par exemple, dans l’expression “une chambre double euh non simple”, l’autocorrection est plus facile à gérer
si l’on est en présence des quatre chunks [“une chambre”] [“double”] [“euh non”] [“simple”] que des trois
chunks [“une chambre double”] [“euh non”] [“simple”].

170
LOGUS : présentation et évaluation
3.3 Liens sémantiques

La construction des “chaînes d’objets” se fait à partir d’une base de règles qui utilisent la
connaissance sémantique. Cependant, ces règles ne dépendent que des relations définies entre
les objets et non des objets eux-mêmes. Outre les coordinations, les règles traitent également
les répétitions, reprises et coordinations, lorsqu’elles correspondent à des syntagmes complets.
Ainsi la règle suivante gère une répétition avec enrichissement lexical (“un h ô tel deux étoiles
un hôtel pas trop cher”) :

Ó        Ø ç1⁄2   ·              Ó    Ø ç3⁄4
Ø                                            Ó    Ø Êç
ÑÑ           Ø ÕÙ ØØ ́ç1⁄2 ç3⁄4 μ Ñ Ñ ÔÖ Ốç1⁄2 ç3⁄4 μ
o`u Êç est l’objet obtenu par réunion des propriétés de ç1⁄2 et ç3⁄4 .
Les lexèmes qui permettent de déterminer la nature de l’énoncé sont également traités par ce
type de règles. Par exemple :

1⁄2    ÊÁ1⁄2 ÊÉ1⁄2         ·             3⁄4   ÊÁ3⁄4 ÊÉ3⁄4
Ø                                       ÊÁ ÊÉ
ÊÁ1⁄2       Ø   ÊÁ3⁄4 3⁄4 ÒØ ÖÖÓ Ø ÓÒ Ö ÕÙ Ø

o`u et ÊÁ sont obtenus à partir de relations d’ordre (partiel) définies respectivement sur les
catégories syntaxiques et les rôles sémantiques. La représentation sémantique ÊÉ s’obtient également à partir d’une relation d’ordre, qui correspond à celle définie pour le premier proto-
type sur les “mots questions” et “mots requêtes”. A    ` l’issue de l’application de cette règle, les
triplets correspondants aux deux chunks [“est-ce que”],[“on peut”] correspondent au triplet
́ Ú ¿ ÔÖ × ÒØμ ÒØ ÖÖÓ Ø ÓÒ ÔÓ×× Ð Ø             .
La mise en œuvre des règles fait intervenir plusieurs niveaux d’application 7 qui ont une triple
justification :
̄ logique : les liens sémantiques entre constituants ne sont pas de même “poids” ; cer-
taines règles sont considérées comme prioritaires, par exemple la juxtaposition d’un objet
avec un nom propre correspondant au même objet (composition des deux chunks “le
musée”, “du Louvre”)8 . Le premier niveau de composition correspond à l’application de
ce type de règles. Ensuite, les deux niveaux de composition suivants consistent à appli-
quer les règles dans leur ensemble, d’abord avec la barrière des mots inconnus, puis sans
cette barrière. Ce procédé correspond à un premier traitement, certes très élémentaire, du
problème des mots inconnus. Actuellement, les règles sont donc appliquées suivant trois
niveaux distincts.

̄ linguistique : les hésitations, reprises et auto-corrections induisent des “ratés” dès la phase
du chunking. Certaines compositions évidentes ne sont pas effectuées lors de la phase o`u
elles auraient dˆu l’être. La méthode utilisée correspond en quelque sorte à un relˆachement
progressif des contraintes de composition.
7
On retrouve, appliquées à des règles sémantiques, un idée de l’analyse en cascade d’Abney (Abney, 1996).
8
Le fait que “le musée du Louvre” corresponde à deux chunks est une illustration du caractère “minimaliste”
des chunks dont il a été question précédemment (cf. 3.2).

171
Jeanne Villaneau, Jean-Yves Antoine, Olivier Ridoux
̄ calculatoire : la succession des différentes étapes de composition constitue un procédé
efficace et rapide.
La dernière phase de composition essaie de trouver ce que Blanche-Benveniste appelle le
“noyau principal” de chacune des propositions dont est constitué l’énoncé (par exemple une
question ou un verbe lorsqu’ils existent) et de le relier aux autres éléments (qui à ce stade ne
sont plus si nombreux) ; si l’énoncé est composé de plusieurs noyaux principaux, le système
tente de les coordonner (le premier noyau sert de contexte au noyau suivant). Cette dernière
partie n’est pas actuellement complètement achevée (cf. 5).
4 Quelques résultats
L’évaluation du GDRI3 à laquelle a été soumis le premier prototype consiste en 1200 énoncés
tests répartis suivant quatre séries de 300 énoncés très différentes9. Bien que simulés, ces tests,
qui représentent une sorte de catalogue des difficultés rencontrées par tous les participants du
GDR, avec des points de vue très différents, ont été très révélateurs des comportements des
systèmes testés.
Dans le tableau ci-dessous, les énoncés sont classés dans la catégorie “compréhension in-
complète” lorsque le sens général de l’énoncé a été dégagé mais qu’il y a eu omission d’un élément non essentiel (l’une des propriétés d’un objet par exemple). Les séries 1 et 2 permet-
tent essentiellement de mesurer la résistance du système face aux inattendus de l’expression
orale. Les résultats obtenus par les deux prototypes sont sensiblement égaux. La série 4 per-
met essentiellement de mesurer la couverture sémantique du système. La série 3 est composée
d’énoncés complexes o`u les manifestations de l’expression orale sont poussées à l’extrême (très
larges incises, reprises et expressions diverses). Ce sont essentiellement les résultats de cette
série qui permettent de mesurer les réels progrès de l’analyse induits par la prise en compte
d’éléments syntaxiques lors de la deuxième partie ; en effet, les énoncés tests de la série 3 ap-
partiennent en général à des domaines linguistiques sémantiques déjà couverts par le premier
prototype. Le fait que le système puisse dégager le “sens” général d’énoncés aussi complexes
est un résultat très encourageant.
Premier prototype                       Série 1     Série 2   Série 3   Série 4 Total
énoncés compris : nb                      277          279        144       157     857
Compréhension incomplète : nb                 11           10         50         48    119
Nombre total                           288          289        194       205     976
Enoncés compris : %                      92.3           93         48       52.3    71.4
Compréhension incomplète : %                 3.7          3.3       16.7         16     9.9
% total                              96         96.3       64.7       68.3    81.3

Second prototype                       Série 1     Série 2   Série 3   Série 4 Total
énoncés compris : nb                      278          284       185        219     966
Compréhension incomplète : nb                 16           10         71         50    147
Nombre total                           294          294        256       269     1113
Enoncés compris : %                      92.7         94.7       61.7         73    80.5
Compréhension incomplète : %                 5.3          3.3       23.7       16.7    12.3
% total                              98           98       85.3       89.7    92.8
9
Le protocole est décrit dans (Antoine, 2001).

172
LOGUS : présentation et évaluation
5 Perspectives et conclusion
Actuellement, les erreurs de reconnaissance de la parole ne font l’objet d’aucun traitement par-
ticulier, la plupart étant résorbées par la souplesse donnée à l’analyse. Cependant, certaines
d’entre elles peuvent casser les régularités syntaxiques locales. Ces répercussions sur le chunk-
ing nous font envisager désormais un traitement particulier de ce type d’erreurs.
Par ailleurs, malgré l’introduction d’éléments syntaxiques dans la deuxième partie de l’analyse,
le problème qui consiste à distinguer les différentes propositions d’un énoncé n’est pas en-
core complètement maîtrisé. Le problème est assez simple dans des énoncés comme : “j’ai
réservé une chambre au Caumartin comment je peux aller l à -bas.” o`u les deux propositions
sont centrées sur un groupe verbal et o`u le temps du premier verbe et l’adverbe interrogatif sont
des indices suffisants10. Il en est tout autrement dans des énoncés sans verbe, très fréquents dans
les différents actes de dialogue. Ce problème rejoint alors celui de l’interprétation contextuelle,
qui ne se réduit pas, selon nous, à une simple adjonction à l’interprétation littérale. Mis à
part en effet les cas o`u le contexte permet de compléter un énoncé sémantiquement cohérent
mais incomplet11, certains énoncés ne peuvent se “comprendre” qu’en fonction du contexte.
Pire encore, il est des cas o`u l’absence de prise en compte du contexte rend les énoncés in-
cohérents au sens de l’interprétation littérale telle que nous l’avons définie : dans l’énoncé
“deux pour demain” par exemple, aucun lien sémantique ne relie a priori les deux propriétés 12 .
L’interprétation contextuelle est donc un élément essentiel de notre système dont nous avons
entamé l’implémentation. Le formalisme adopté semble contenir les éléments nécessaires pour
sa réalisation.
La mise au point de ce formalisme est d’ailleurs au centre de notre travail car il correspond à
des réponses possibles à quelques problèmes selon nous fondamentaux :

̄ Représenter le sens d’un énoncé sans faire appel à des cadres sémantiques prédéterminés :
les travaux développés sur les graphes conceptuels (équivalences, inclusions), inutilisés
jusqu’à présent, sont l’une des raisons de notre choix et devraient se révéler bien utiles
par la suite.
̄ Combiner les approches syntaxiques et sémantiques : le double étiquetage syntaxique et
sémantique semble particulièrement bien adapté à cette démarche.
̄ Représenter la connaissance sémantique et concilier son utilisation avec la généricité des
règles utilisées : là encore, le double étiquetage semble ê tre un bon moyen de définir des
règles largement indépendantes de l’application. Le système actuel de ces règles est assez
efficace mais surtout le formalisme adopté le rend aisément perfectible.

En fait, l’efficacité de L OGUS montre que les réponses apportées à ces différentes questions
sont une voie possible pour mettre en œuvre une analyse à la fois fine et robuste des énoncés
10
Dans notre système, l’objet “chambre de l’h ô tel Caumartin” est le contexte de la requête “comment aller l à -
bas” . Les contraintes sémantiques imposent que “l à -bas” corresponde à l’hôtel Caumartin (et non à la chambre...).
11
Cette notion d’incomplétude ne va d’ailleurs pas de soi dès lors que l’on prétend s’abstraire de requêtes
prédéfinies avec des champs sémantiques à remplir d’une manière obligatoire.
12
Ce problème est soulevé par Pierrel et Romary dans (Pierrel et Romary, 2000).

173
Jeanne Villaneau, Jean-Yves Antoine, Olivier Ridoux
oraux. Quelle que soit la méthode adoptée pour y parvenir, les progrès dans le domaine du
DOHM passent, selon nous, par de tels travaux.
Références
S. Abney. Parsing by chunks. In Principle Based Parsing. R.Berwick, S.Abney and C.Tenny, Eds.,
Kluwer Academic Publishers., 1991.
S. Abney. Partial parsing via finite-state cascades. In J. Carroll, editor, Workshop on Robust Parsing
ESSLLI’96, pages 8–15, 1996.
J.-Y. Antoine and J. Goulian. Le français parlé spontané est-il un langage à ordre variable ? In Actes des
Journées Internationales de Linguistique Appliquée, JILA’99, Nice, France, 1999.
J.-Y. Antoine. Evaluation des systèmes de CAP, campagne d’évaluation “par défi”. Technical report,
GDR-PRC-I3, Ple Parole, G.T. 5.1., http://www.univ-ubs.fr/valoria/antoine/Gt51/Eval defi.html, 2001.
C. Blanche-Benveniste. Le français parlé ; études grammaticales. CNRS Editions, Paris, 1990.
W. Buszkowski. Lambek grammars based on pregroups. In Logical Aspects of Computational Linguis-
tics, pages 95–109, Le Croisic, 2001. Springer.
J. Goulian and J.-Y. Antoine. Compréhension automatique de la parole combinant syntaxe locale et
sémantique globale pour une CHM portant sur des tˆaches relativement complexes. In TALN 2001, pages
203–212, Tours, France, 2001.
L. Hirschman. Language understanding evaluation: lessons learned from MUC and ATIS. In 1st Int.
Conf. Language Ressources and Evaluation, LREC’98, Grenade, Espagne, pages 117–122, 1998.
M.Z. Kurdi. A spoken understanding approach which combines the parsing robustness with the inter-
pretation deepness. In ICAI, Las Vegas, USA, 2001.
P. Lopez. Analyse d’énoncés oraux pour le dialogue homme-machine à l’aide de grammaires lexicalisées
d’arbres. PhD thesis, UHP-Nancy I, 1999.
R. Montague. Formal Philosophy. Yale University Press, New Haven, USA, 1974.
M. Moorgat. Categorial Type Logics. In Elsevier Science B.V., editor, Handbook of Logic and Lan-
guage, pages 93–177. J. van Benthem and A. ter Meulen, 1997.
J.M. Pierrel and L. Romary. Ingénierie des langues, chapitre Dialogue Homme-Machine, pages 331–
349. Hermès, 2000.
C. Retoré. Systèmes déductifs et traitement des langues : un panorama des grammaires catégorielles.
Technique et Science Informatique, numéro spécial de Traitement automatique du langage naturel,
20(3):301–336, 2000.
J. F. Sowa. Conceptual Structures : Information Processing in Mind and Machine. Addison-Wesley,
Reading, MA, 1984.
J.F. Sowa. Knowledge Representation. Brooks/Cole Thomson Learning, USA, 2000.
J. Villaneau, J.-Y. Antoine, and O. Ridoux. Combining syntax and pragmatic knowledge for the un-
derstanding of spontaneous spoken sentences. In Logical Aspects of Computational Linguistics, pages
279–295, Le Croisic, 2001. Springer.
174
