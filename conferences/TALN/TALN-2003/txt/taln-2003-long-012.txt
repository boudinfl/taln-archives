
Contextual Grammars and Dependency Trees

Radu Gramatovici (1), Carlos Mart́ın-Vide (2)
(1) Faculty of Mathematics and Computer Science, University of Bucharest
Academiei 14, 70109, Bucharest, Romania
Email: radu@funinf.cs.unibuc.ro
(2) Research Group on Mathematical Linguistics, Rovira i Virgili University
Pl. Imperial Tàrraco 1, 43005 Tarragona, Spain
Email: cmv@astor.urv.es
Mots-clefs – Keywords

Grammaire contextuelle, arbre de dependance, arbre projectif de dépendance
Contextual grammar, dependency tree, projective dependency tree
Résumé - Abstract

On présente une nouvelle variante de grammaire contextuelle structurée, qui produit des arbres
de dépendance. Le nouveau modèle génératif, appelé grammaire contextuelle de dépendance,
améliore la puissance générative forte et faible des grammaires contextuelles, tout en étant un
candidat potentiel pour la description mathématique des modéles syntactiques de dépendance.
A new variant of structured contextual grammar, which generates dependency trees, is intro-
duced. The new generative model, called dependency contextual grammar, improves both the
strong and weak generative power of contextual grammars, while being a potential candidate
for the mathematical description of dependency-based syntactic models.
This work was written during a research visit of the first author at the Research Group on Mathematical
Linguistics of Rovira i Virgili University. The research visit was funded by the NATO Scientific Committee.
R. Gramatovici, C. Mart́ın-Vide
1 Introduction

Contextual grammars were introduced in 1969 by Solomon Marcus (Marcus, 1969) as an at-
tempt to transform in generative devices some procedures developed within the framework of
analytical models (see (Marcus, 1997) for a comprehensive discussion on the linguistic mo-
tivations of contextual grammars). In many respects, (the mathematical model of) contextual
grammars and (the linguistic model of) dependency grammars ((Mel’ˇcuk, 1987) and others)
have the same roots. The similitude between contextual grammars and dependency syntactic
models based on dependency trees go further, since both formalisms deal mostly with symbols
of the language and less or at all with auxiliary symbols as in the case of formalisms based on
constituents trees. A similar argument to this one is presented in (Mŕaz et al., 2000), where
contextual mechanism is described as dual to the analysis by reduction linguistic method.
However, no relationship was established yet between contextual and dependency grammars.
This happened probably because, originally, contextual grammars developed a string generative
mechanism and structures on strings generated by contextual grammars were introduced only
recently in (Mart́ın-Vide & P̆aun, 1998).
In this paper, we propose a new approach to the generation of dependency trees (D-trees),
based on contextual grammars. The notion of internal dependency contextual grammar (DCG)
is introduced, by adding dependency descriptions to contextual rules from ordinary contextual
grammars. In a DCG, the derivation relation is constrained in two ways: contexts are selected
by (strings of) words, but also by the correct construction of the D-tree. Simplifying, string
insertion rules stand for the word order, while dependencies express mainly the dominance
relationship between words, as in unordered syntactic D-trees. Local and long distance depen-
dencies are treated in an uniform way, using the smooth contextual mechanism.
Several formal examples are given through out the paper, in order to emphasize the capability
of DCGs to describe different aspects of language generation. Concerning the strong generative
power, we illustrate in Section 4 the flexibility of DCGs in describing even opposite (top-down
and bottom-up) derivation styles, as well as different kinds of dependencies (nested or cross-
serial), in a very simple and pragmatic way. In Section 5, we prove that the weak generative
power of projective internal DCGs (DCGs that generates only projective D-trees) is beyond the
generative power of internal contextual grammars with choice.
2 Marcus Contextual Grammars

Contextual grammars are based on the interplay between (strings of) words in a sentence. They
start from the assumption that there is a finite set of (simple) sentences (axioms), which are
accepted as well-formed without any doubt. More complex sentences are generated by the
insertion of other words, in the form of contexts (pairs of strings, possibly one-sided) selected
by the strings already present in the sentence.
✂☎✄✝✆✟✞✡✠☞☛✌✠✎✍✏✠✒✑✔✓         ✞
Formally, an internal contextual grammar (CG) is a construct
✛ ✚
✜ ✞           ✆ ✥✞ ✍✌✓              ✍                          ✞✖✕✘✗✙✞✌✕
, where is

✑✦✆★✧✔✓✩✄✪✍       ✧✬✫✙✞ ✕
(the set of contexts) and
✕ ✣ ✢ ✤
an alphabet, is a finite language over (the set of axioms), is a finite subset of
✂                                     ✂✭✄✮✆✯✞✰✠☞☛✱✠✎✍✱✓
is the choice (or selection) recursive map. When
, for all      , we say that is a CG without choice and write                 . The
Contextual Grammars and Dependency Trees
✧✳✲✵✴
✧✣✄✶✧✸✷✹✧✻✺☞✧✻✼ and ✴✽✄✾✧✸✷❀✿❁✧✻✺☞❂❃✧✻✼ for some ✆✥✿❄✠☞❂❅✓✩✫❆✑❇✆❈✧✻✺✒✓❊❉
internal derivation style (introduced in (P̆aun & Nguyen, 1980)) of a CG is defined by:
✲ ✕ is the reflexive and transitive closure      ✲                ✆ ✯ ✂ ✱ ✓
✏ ❍
✄ ● ■ ✧ ❏ ✶
✫ ✞         ✫
 ✌
☛ ✠   ✲ ✕ ✧❘◗
iff

✂      of , then ❋
✕ ✔
❑ ▼
❖ ◆
✍ and ❙ ✍❚✍ the classes of languages   ◆
denotes the language generated by . We denote by ❙
If

generated by internal CGs without, respectively with choice1 .

✖✂ ✷✰✄❯✆✟✞✡✠☞☛✌✠✎✍✏✠✒✑✔✓ , where
✞ ✄ ● John✠ likes✠ Lyn✠ really◗❲❱
Example 2.1 Consider a very simple internal CG with choice
☛ ✄ ● John likes Lyn◗❲❱
✍ ✄ ●❅✆ really ✠✒❳❨✓✒◗❲❱
✑✦✆★✧✔✓☎✄ ❩ ❬●❅✠✆ really✠✒❳✔✓✎◗❲✠ if ✧▲✄ likes❱ ✠
✂❭✷ is: John (really)✕ likes Lyn.
otherwise

The language generated by

Contextual grammars. even without choice, are able to generate interesting languages, which
❪ ❙❴❫ ❵❜❛ ✂ ✍ ❪ ✍✱❝
are spread into (not covering) the traditional Chomsky hierarchy of languages. We denote by
,      ,    ,    the classes of finite, regular, context-free, respectively context-sensitive
languages.

✌✂ ✺✜✄❞✆❡●❣❢✻✠☞❤■◗❲✠✐●❥❳❘◗❲✠❦●❅✆✥❢❁✠✎❤❊✓✒◗❥✓ . We have
❋ ✆✥✂❚✺✒✓☎✄ ● ◆❧❑♠◆ ✫♥●❣❢❁✠✎❤♦◗ ✕ ✠ ❑ ◆♣❑ q ✄ ❑ ◆♣❑ r and ❑ ✧ ❑ q✘s❧❑ ✧ ❑ r ✠✹t❨✧✬✉ ◆ ◗
Example 2.2 Consider a CG without choice
❑ ◆✖◆ ❑ q denotes the✆✯✂❚number
✺ ❊ 1
✓ 2
✫ ✍         ✂             ❢ ◆ ✆✥✂✱✧✈✺❊✓ ✉ ◆ denotes that ◆ ✄✇✧✻✴ (✧ is a
prefix of ). Then, ❋
where
●❣❢❁✠✎❤♦◗                             ❪✇3 ❵❜❛ . The language ❋ is known as the Dyck language
of occurrences of in and

over                    .

✂ ✌ ✼
❴ ❆
✄   ✹
✆ ●
❣ ❢
❁  ✎
✠ ❤ ■ ✠ ✎ 4
■ ◗ ❲ ❦
✠ ●
❥ ❳
✸ ❲
◗ ✠
❦ ❅
● ✆ ❈ ✧ ✻ ✴ ❨ ✠
✎ 5
❃ ✒
✓ ♠
✠ ❈
✆ ❄
✧ ☞
✠ ❅
✴ ❃
5 ✓ ❑ ●
■ ✧ ❄ ✠ 6 ✴ ✔ ✠ ✎ 5 ❴ ◗ ❜ ✄
●❣❢❁✠✎❤■✠✎4♠◗❃◗❥✓
Example 2.3 Consider a CG without choice
❋ ✆✯✂✏✼❊✓7✄ ● ◆❧❑♠◆ ✫8●❣❢❁✠✎❤■✠✎4♠◗ ✕ ✠ ❑ ◆✖❑ q ✄ ❑ ◆♣❑ r ✄ ❑ ◆✖❑ 9 ◗❲❉
. We have
Then, ❋
✆✥✂❚✼❊✓✜✫✬✍✱❝ 3 ✍ ❪ . The language ❋ ✆✯✂❚✼❊✓ is known as the Bach language over ●❣❢❁✠✎❤■✠✎4■◗ .
More expressive languages can be generated using the choice function together with a con-
✂✧✇✫❾✄ ❝✔✆✟❺ ✞✡✠☞☛✌✉➁✠♠✆✯➀✌❝10✷✒✉➁✠✎✍❶➂ ✷❷✓✒✠♦❉♦❉♦❉✐✠♠✆✟❝✔❸❴✆✟❝➃✠✎✍✜❺✟✠✎❸❹✍✜✓6❺➄✓ ✓   ✂ ✄ ✆✟✞✡✠☞☛✌✠☞✍❚✠✒✑✔✓
dition on the type of the languages selecting contexts. A CG in the modular presentation
✍1❺❼❻❽✑❇✆❈✧✔✓
❪ ❿ ✍❚✍➇✆ ❪ ✓ ❪
is a CG                     such that             , for all
,            . A pair          is called a contextual production. We say that a CG has
❝❘❺✘✫ ❪                       ❿ ✉➅➀✽✉➆➂
✍❙ ✱✍♣✆ ❵❜❙❛ ✂✌✓
an choice, where denotes a family of languages, if
note by
, for all           . We de-
the class of languages generated by internal CGs with -choice. For example,
denotes the languages generated by internal CGs with regular selection languages.
1
For details on contextual grammars, the reader is referred to the monograph (P̆aun, 1997).
R. Gramatovici, C. Mart́ın-Vide
Example 2.4 Consider
✂✏➈➉✄❞✆✹●❣❢❁✠✎❤■✠✎4♠✠✎➊➋◗❲✠❦●❣❢❲❤❊4❊➊➋◗❲✠♠✆✯❢❲❤✒➌➃4♠✠❦●❅✆✥❢✻✠☞4❦✓✎◗❥✓❊✠♠✆✥❤❊4❊➌➃➊❁✠❦●❣❤■✠✎➊❴✓✎◗❥✓6✓ a CG in the
modular presentation. We have
✆❋ ✯✂❜➈❊✓☎✄ ●❣❢ ❸ ❤☞➍✜4 ❸ ➊❹➍ ❑ ➂✦✠6➎ s ❿ ◗❲❉
Then, ❋
✆✯✂❜➈✐✓➏✫❆✍✱❝ 3 ✍ ❪ . ❋ ✆✯✂❜➈✐✓ is the schematic representation of linguistic cross dependen-
cies.

Though, there are either simple context-free or linguistic relevant languages that cannot be

✷ ✜  ✄
❯ ● ❣   ❢   ❸ ❑ ➂ s ◗➏➐❆●❣❢ ❸ ❤ ❸ ❑ ➂ s ◗
generated by any (internal) CG, even with choice.
Indeed, the language ❋                                       ❿                                 ❿    cannot be generated with (internal)
➂ s ❿ one needs to define a context ✆❈✿10✠6❂❖✓ containing❢ only the letter ❢ (at least one occurrence)
CG. The problem comes from the fact that, in order to generate all the sentences of the form ,

✆ ✥ ✿ ❄ ✠
☞ ❂ ❅ ✓                                                   ❸       ❸
and selected by a set of strings also made only by s. Then, there
the insertion of the context
❢    ❤
❸❢ ➌ ❺ of❤ ❸ the form➀❭➑➓➒ (for an appropriate ➂ ) and
into sentences
is no mechanism to avoid

language ❋ (details of the proof are in (P̆aun, 1997), page 58). Thus, ❋
producing in this way sentences of the form                                          , with
✷1✫✬✍ ❪➔3 ❙ ✍❚✍ .
, which do not belong to the
A similar problem occurs with the language ❋
✺→✄ ●❣❢ ❸ ❤ ❸ 4 ❸ ❑ ➂ s ➒❴◗ , a non-context-free
in some linguistic constructions. In (P̆aun, 1997), page 46, it is proved that ❋
language, which schematically represents the multiple (triple) agreement that can be found also
✺↔✫➣ ❙ ✍❚✍ using
a pumping lemma, which holds for internal CG. Constructively ✆✯speaking,                                      ❢ ❁  ✎
✠ ❤
✒  4 ❦ ✓       the problem comes
❢     ❤                 4
again from the fact that once one considers a context of the form
❢ s and ❤ s (the left side of the context), respectively between ❤ s and 4 s (its right
to generate only strings

❤ ❸ ➂ side).
with an equal number of s, s and s, this context cannot be applied anywhere, but only between
s ❿ , butThe❤ thisonlyis
not enough, because it would be possible to ❸ apply the context                              ❸
way to do this would be to associate with the context a selector of the form ,
❢ ❤ ➍  ❢
❲  ❤ ❡ ♠
↕ ❤
✒ 4 ✐ ☞
❤ ✒
➙ 4               ➎➅➛♥➜✖➛✶➝❼✄➁➂ , which do not
also to a shorter string of s than

belong to ❋ .
intended and generate strings of the form                                                        , with
In (Mart́ın-Vide et al., 1997) (also (Marcus et al., 1998)), it is shown that languages as ❋ or ❋
✷ ✺
can be generated by internal CGs with a condition of maximality on the length of the substrings
of the given string, which are used to select contexts at some derivation step. In Section 5, we
provide with a different method for the improvement of the (weak) generative power of CGs.
3 Dependency Contextual Grammars
A dependency tree (D-tree) is a tree whose nodes are labelled over an alphabet of terminal
symbols. Sometimes, its edges are also labelled over another alphabet (of syntactic categories),
but we will not use this feature here as it is not relevant for the purpose of this paper. We
will introduce D-trees using the concept of a structured string from (Marcus, 1967) (see also

✞                                    ➂                                                               ✪✧➞ ➂❨➟ ✫✭✞ ➌
(Mart́ın-Vide & P̆aun, 1998), (Marcus et al., 1998)).
Let be an alphabet. If is a natural number, we denote by
✞ ➠❹➡8❻ ➞ ❑ ✧ ❑ ➟➢✗ ➞ ❑ ✧ ❑ ➟ 3 ●❅✆❈➀6✠☞➀➤✓ ❑ ➀✖✫ ➞ ❑ ✧ ❑ ➟✥◗
numbers. A structured string over is a pair
, where
✧ ❄ ✠ ☞ ➠ ❲ ➡
❣ ✓
the set of the first natural
is a non-empty string
over and
✧ ➀✟➠❹➡❊➥ ✧          ✧ ✧❇✧ ✆➦➥❴✓                  is an anti-reflexive binary relation, called
✧ ➀❚✆✥➀❡✫ ✓ ➞ ❑ ✧ ❑ ➟
❇                                                                    ❖
➠ ✧❇➌ ✆✥➀➤✓ ➀
dependency relation on . If is a string and
. If     , then we say that       depends on
, we denote by
➠❲➡ ➀✯➠❴➡➌ ➥
. Let us denote by
the -th symbol of
(and call dominance
✧❇✆❈➀❡✓     ➡         ✧❇✆➧➥❅✓
relation on ) the transitive closure of . If  , then we say that      dominates       .
Contextual Grammars and Dependency Trees
A structured string               ➨ ✧ ✄ ✆❈✧❄✠☞➠❃➡❣✓ ❿ ✉➓➝❆✉ ➞ ❑ ✧ ❑ ➟
is called a D-tree iff the dependency relation
❇ ✆
✥ ➩
➝ ✓
induces a
➠❴➡
✧❇✧ ✆❈➀❡✓➝
structure of tree over , i.e. i) there is
➨    ✰
➀ ✫  ➞ ❑
such that
✧ ❑ ➟ 3   ●
♠ ➝ ❲ ◗
does not depend on any
➥ ➇ ✫ ➞ ❑ ✧ ❑ ➟
✆➫ ✯✞✌✧❇✓ ✆➧➥❅✓ ➠ ➡➌
symbol of ( is called the root of ); ii) for any                  , there is a unique index
✆❈➀6✠☞➀➤✓8✫✭➣ ➠ ➡➌
➀✰✫ ➞ ❑ ✧ ❑ ➟
such that       depends on
. We denote by
; iii)
is an anti-reflexive relation, i.e.
the set of D-trees over a set of terminals.
, for any
Linguistically motivated, the structures over CGs were introduced in (Mart́ın-Vide & P̆aun,
1998) (see al(Marcus et al., 1998), or Section 7.6 in (P̆aun, 1997)). Bracketed CGs, i.e. contex-
tual grammars working on strings of terminal symbols enriched with a well-formed structure
of brackets, were extensively studied in (Kappes, 2000). We are interested here in the second
type of structured CGs introduced in (Mart́ın-Vide & P̆aun, 1998), which do not use brackets
for creating tree-like structures on strings, but binary relations between terminal symbols. How-
ever, the definition of a dependency CG given below is formally different from the definition of

➭✂ ✄➯☛ ✆✯✞✰❻ ✠☞☛✱✠✎➲✰✆✟✷✒✞✱✠♦✓❉❦❉♦❉❦✠✎➲❄❸➩✓ an internal dependency ✞ contextual grammar (IDCG)➀✳iff✫ ✞ ➂✔is➟
a structured CG given in (Mart́ın-Vide & P̆aun, 1998).
➲10❺➳✄➵✆✯❝✔❺➤✠✎4✎❺➤✠✎➊❹❺➄✓ is ➫a dependency                                                                                                                   ➞
We call
an alphabet,                                      is a finite set of D-trees over (the axioms) and for any
❝ ✸ ❺
✱  ❻
➸  ✞ ✕                               ,
4✒❺➺✄➻✆✥✿❁❺✟✠☞❂❣❺★✓✏✫❏✞ ✕ ✗♥✞ ✕ (the context)                                 ➊❃❺✩❻ ➞ ✆ ➞ ❑ ✿❁❺➄❂♠❺ ❑ ➟❖➐✙✞✱✓❶✗❏✆ ➞ ❑ ✿❁❺➄❂♠❺ ❑ (the
contextual production, with
and
➟➋➐❆✞✌set✓❡➟ 3 of✞➁selectors),
✗8✞ (the
set of new dependencies). A derivation in an IDCG is defined as a binary relation over the set

✆❈✧❄✠☞➠❹➡❣✓✰✲➼➳✆✥✴❨✠☞➠❹➽❦✓ iff ✧▲✄✾✧✸✷✹✧✻✺☞✧✻✼■✠6✴➾✄✾✧✸✷❀✿❁✧✻✺☞❂❃✧✻✼ and there is ➀✰✫ ➞ ➂❨➟✟✠ with ✧✻✺❶✫2❝✔❺➤✠
of D-trees over by:

4✒❺➃✄❧✆❈✿❄✠☞❂❅✓ and ➠❹➽ built under the following rules:
➠❹➽                                                            ➠❲➡
- contains all the dependencies in and no other
✧❄✠
➠❹➽
dependencies occur between the symbols originating in
4✐❺➤✠
➊❃❺➤✠ and no other dependencies occur between the
- contains all the dependencies between the symbols of
described in
4❊❺➤✠
➠❹➽
symbols originating in
- may contain dependencies between the symbols of and
4❊❺                         ➊❃❺
the new symbols introduced by as described by i.e.
✿❨❺➚❂❣❺❡✆➦➥❴✓ and a symbol ❢ from ✧❄✠
✆➧➥❹✠✎❢❴✓1✫✬➊❃❺ (respectively ✆✯❢❁✠❡➥❴✓✜✫2➊❃❺★✓✒❉
if a dependency occurs between
then
The difference between the above definition of a IDCG and the definition of a structured CG
from (Mart́ın-Vide & P̆aun, 1998) consists in the fact that the new symbols inserted by some
dependency contextual rule do not attach to some specified (localized) selector symbols, but to

✲◗ ✕ ➼ is the reflexive and transitive closure of ✲✇➼ , then ➪➇❋ ✆✥✂✌✓✩✄❞✂ ● ➨ ✫ ➫ ✆✟✞✱✆✥✂✌✓ ✓➉❑❃▼❁✄✮➶ ●■✫2✧8☛✌✫♥✠ ➶ ✞ ✲➌➔✕ ➼ ❑
some selector symbols having the value specified in the set of new dependencies.
➨▼ ✆❈✧❄denotes
If
set of D-trees) generated by . Then, ❋
✆✯✂✱✓✒◗ denotes the(thelanguage
✠☞➠❹➡♠✓✌✫ the➪❼❋ dendrolanguage                                  ✂
generated by . We denote by ❙❅➪
✍✱✍ the class of
languages generated by IDCGs.

✂✱➹✷ ✄❞✆✟✞✡✠☞☛✌✠✎➲✱✓
Example 3.1 We reconsider Example 2.1, from the previous section, now introducing depen-

✞ ✄ ● John✠ likes✠ Lyn✠ really◗❲❱
dencies on words. We define an internal DCG              , where

☛ ✄ ●❅✆ John likes Lyn✠❦●❅✆✯➘❅✠ ❿ ✓✒✠♠✆✟➘❴✠✎➴❃✓✒◗❥✓✎◗❲❱
R. Gramatovici, C. Mart́ın-Vide
➲ ✄ ✹✆ ● likes◗❲✠♠✆ really✠✒❳❨✓❊✠❦●❅✆ likes✠ ❿ ✓✒◗❃◗❥✓✒❉
✂ ➹✷ is:
✆ John really likes Lyn✠❦●❅✆✥➴❖✠ ❿ ✓✒✠♠✆✯➴❅✠☞➷❲✓❊✠■✆✯➴❖✠✒➘➩✓✒◗❥✓
One of the D-trees generated by
(see Figure 1), which underlies the string: John really likes Lyn.

➬ ➀
❡ ➮ ❖ ➱ ➶
Ï Ï Ï Ï Ï   Ï ❮ ❃Ï ❮ Ð ❮❃❰ ÑÒ Ñ Ñ
❘✃ ❐❥❒ ➂ ➝❥➱■❢ ❮ ➬❈➬ ✴                       Ñ ❋ ✴❅➂
Figure 1: A D-tree for John really likes Lyn

Projectivity is a very common property of D-trees, which expresses the fact that the vertical
projections of the nodes do not intersect the edges of the tree. We will consider in the following

✧                                        ★✆ ✧❇✧❄✆❈✠☞➀❡➠❃✓➃➡❣❉♦✓ ❉♦be❉❀✧❇✆➦a➥❴✓ D-tree.
a particular case of DCG, which generates only projective D-trees.
Let be a string. A sequence               ✧                                           , ❿
✉➸➀✖✉➆➥➔✉ ❑ ✧ ❑ , of consecutive symbols ✧❇of✆✥➀❡✓✧
➀✰✫ ✧ ➞ ❑ ✧ ❑ ➟ ✧ ➀★Ó➳Ô➀✟Õ ✧❇✆✥➀❷✉Ö✷6✓➃➥➇❉♦❉❦Ô➔❉❷✧❇➮▲✆✥➀✥❸❲✉✇✓ ,➂ ➂2✫ ➞ ❑ ✧ ●♠The
is called an interval of . Let
❑ ➀❀➟ ,✷❊of✠♦❉♦maximal
❉♦(not
projection of a symbol
◗❜✄✭●♠➀❷◗1➐2●❊consecutive)
❉✐✠☞➀✯❸❲necessarily
➥ ❑ ➀✯➠❲➌❁➥➋◗ . symbols
, of , is the sequence
of , such that           , for any            ❿                                           , and
(Dikovsky & Modina, 2000)). We denote by ➫
Then, a D-tree is projective iff all the maximal projections of its symbols are intervals (see
✆ ✯    ✞
✌   ✓
✞                                                                                                      the set of projective D-trees over an
alphabet .
✂➁✄➓✆✟✞✡✠☞☛✱✠✎➲✰✷✒✠♦❉♦❉❦❉❦✠✎➲❄❸❃✓ is called a projective                              ☛ ➻        ❻
×      ➲       ✯
✆ ✞ ✌ ✓
An IDCG
✲ ↕ ➼ is defined as the restriction of ✲➔➼ on the set ➲ ➫ ✆✟✞✱✓ of projective
mar (PIDCG) iff the axioms are projective D-trees,                                                                           ➫
internal dependency contextual gram-
, and the derivation relation,
D-trees. Correspond-

but using the derivation relation ↕ . We denote by ❙❴➪
✲ ➼
ingly, the dendrolanguage generated by a PIDCG is defined exactly as in the case of an IDCG,
➲ ✍❚✍ the class of languages generated
by PIDCGs.
The IDCG in Example 3.1 is a PIDCG.
4 Strong Generative Properties
After introducing structures on strings generated by CGs, one may speak about the strong gen-
erative power of the structured CGs. The strong generative power means the capacity of (depen-
dency, in our case) CGs to generate different dendrolanguages, underlying the same language.
In this section, we investigate some structural properties of IDCGs.
Top-down and bottom-up derivation

The derivation of phrases in a context-free grammar is a top-down process starting with the root
of the (constituent) tree and leading to its leaves. Among the novelties brought by tree-adjoining
Contextual Grammars and Dependency Trees
grammars (Joshi, 1987) and other formalisms in the area of the mild context sensitiveness, was
the fact that derivation is not necessarily a top-down process. It is important to remark the
capacity of IDCGs to construct the (same) structure of the (same) string in totally different
ways.

Example 4.1 Consider
✱   Ø
❶  ➆
✄       ❡
✆ ● ❣ ❢ ❁ ✠ ✎ ❤ ♦ ◗
❲ ❦
✠   ●
❅ ✆ ✯ ❢
❲ ■
❤ ❦
✠ ● ❅ ✆ ❿   ✠ ✒
✆✹●❣❢❁✠✎❤♦◗❲✠❦●❅✆✥❢❴❤■✠❦●❅✆ ❿ ✠✒➘❹✓✎◗❥✓✒◗❲✠♠✆✥❢ ➌ ❤ ➌ ✠♠✆✥❢❁✠✎❤❊✓❊✠❦●❅✆ ❿ ✠✎❢❴✓❊✠♠✆ ❿ ✠✒➘❹✓✎◗❥✓6✓ two IDCGs. ❹
➘   ✓ ✒   ◗ ❥ ✓
✎  ◗
❲ ✠
♠ ✆
✹ ● ❥ ✸
❳ ◗ ❲ ✠
♠ ✆ ✥ ✻
❢   ☞
✠ ❤ ✐ ✒
✓  ✠ ❦ ● ❅ ✯
✆ ❢ ❁ ✠ ❿ ❊
✓   ✠ ♠ ✆ ❿ ✒
✠ ➘ ❹ ✓ ✎ ◗ ❥ ✓
6 ✓ and
❚ Ù
❶ ✄
❢   ✼❤✼
The D-tree represented in Figure 2 corresponding to the string
❢   ❤                                                                                                                 ✆✯❢❁✠✎❤❊✓ is added at the
is generated in a top-down

✏  Ù
bottom of the tree) by
✂ ✱  Ø
manner (at any step, the axiom rests in the top, while the new context
and in a bottom-up manner (the new context is added always in the
top) by .

ÑÚÒÛ Ú Ñ Ú ❢
Ú Ú ÑÒ Ú Ñ Ú ❢ Ú Ú
ÚÛ Ú Ú Ú ÑÒ Ú Ñ Ú Ú Ú ❤ Ú Ú ❤ Ú Ú ❤
ÚÚ
❢       ✼   ❤ ✼                                          ✂❚Ø and ✂❚Ù
Figure 2: D-tree of the string                                                               generated by
Nested and cross-serial dependencies
❢✼❤✼
In Example 4.1, we defined two IDCGs, which are rather ambiguous with respect to the struc-
tures associated with well-formed strings. For example, in both grammars we can associate
several D-trees with the string    , and not only the D-tree in Figure 2. The D-tree from Figure
❢              ❤
2 is a projective D-tree, which represents a set of nested dependencies between the symbols
❤                                                    ❢
and that were inserted in the string at the same derivation step. Indeed, one may notice
that the last depends on the first , the second depends on the second , while the first
❤ ❢ ✼❤✼                                                    ❢                    ✂✱Ù                 ❤
depends on the last . Another possible structure of       , generated by the grammar , is the
non-projective D-tree in Figure 3, which encounters mixed dependencies.

❢ ❮ ÜÝ Ü ❮❃❰ Ü
Ü ÚÛ Ü Ú Ú ❢ Ú Ú Ú Ú Ú Ú Ú
ÚÛ Ú Ú
Ú Ú Ú Ú ÑÒ Ú Ñ Ú                Ú Ú❤ Ú Ú Ú ❤
Ñ Ú Ú❤ Ú Ú Ú
❢ ✼❤✼              ✂❚Ù
Figure 3: D-tree of the phrase                generated by
In practice, one may want to control the distribution of dependencies over the string in a very
rigorous manner. The following example illustrates the capacity of PIDCGs to generate D-trees
with specific dependencies.
R. Gramatovici, C. Mart́ın-Vide
Example 4.2 First, we modify the grammar
✂✌Ù
from Example 4.1 in order to obtain only D-
trees representing nested dependencies. Actually, we may keep the same grammar and consider
the projective derivation      .
✲ ↕ ➼ ✂✏Ù
becomes a PIDCG (since the axiom is a projective D-tree).
❢ ✼❤✼
✂❚●❣❢ Ù ❸ ❤ ❸ ❑ ➂ s ◗
Then the D-tree represented in Figure 2 is the only D-tree associated with     and generated by
✂✽Ù
in the projective derivation style. Also the language generated by , in this case, is exactly
❣● ❢ ❸ ❤ ❸ ❑ ➂ s ❿ ◗ ❢ ❤
The second grammar generates the same language,                    , using a totally different
✂✌Þ✌✄❍●❣❢✻✠☞❤■◗❲✠✐●❅✆✯❢❲❤■✠❦●❅❢✆ ❿ ✼ ❤✠✎✼➘❹✓✒◗❥✓✎◗❲✠♠✆✹●❣❢❲➌❘◗❲✠♠✆✯❢❁✠✎❤❊✓❊✠✐●❅✆ ❿ ✠✎❢❴✓✒✠♠✆✯❤■✠✒➘❹✓✎◗❥✓6✓
method, which hides cross-serial dependencies between the symbols and introduced at the
same derivation step. Consider                                                               a
PIDCG. The (only) D-tree associated with the string    is represented in Figure 4.
ÑÒ Ñ ❢
ÑÒ       Ñ ❢
ÚÛ Ú Ú Ú Ú Ú ❤ ❮ ❃❰ ❤
❤ ❮ ❮❃❰ Ú ❮ Ú
Figure 4: D-tree of the string
❢ ✼ ❤ ✼ generated by ✂✱Þ

5 Weak Generative Properties

In this section, we will prove that using PIDCGs also the weak generative capacity of CGs is
improved.

Theorem 5.1 For any internal contextual grammar
✂ ➹ , there exists a weak equivalent internal
projective dependency contextual grammar .

✂ ✄ ✆✟✞✡✠☞☛✌✠♠✆✯❝❇✷✎✠✎✍❶✷❷✓❊✠❦❉♦❉♦❉❦✠■✆✟❝✔❸❴✠✎✍✜❸❹✓6✓ be an ICG. We may consider that each con-
Proof Let
✆✟✞✡✠☞☛❶➹➚✠♠✆✟❝10✷✎✠✎✍❶✷✒✠✎➊❖✷❷✓✒✠♦❉♦❉♦❉❊✠♠✆✟❝✔❸❅✠✎✍✜❸❅✠✎➊❹❸➩✓6✓ , where
textual production corresponds to one context. We construct the following PIDCG
✂➹✄
☛ ➹ ✄ ●❅✆❈✧❄✠6➠❹➡❣✓ ❑ ✧✈✫✈☛✱✠☞➠❹➡❜✄✛●❅✆✥➀❷✠☞➀❨➛ ❿ ✓ ❑ ➀✰✫ ➞ ❑ ✧ ❑♠ß ❿ ➟✥◗❃◗
➊❹❺➆✄ ●❅✆✯❢❁✠❡➥❴✓ ❑ ➥➇✫ ➞ ❑ ✿✻❺➦❂♠❺ ❑ ➟✯✠✎❢♣✫✬✞✖◗❲✠
for
4✒❺✔✄❧✆❈✿❁❺➤✠☞❂♠❺❈✓ and for all ➀✰✫ ➞ ➂✔➟ . Then, ❋ ✆✯✂✏➹à✓✰✄ ❋ ✆✥✂✌✓ .                                                                  áâ
✂                       ✂                                 ✂ ✱ ➹
From the above proof, it is worth to note that on the contextual side nothing changes when
✂                      ❪
adding dependencies:
➹                if
❪ is  without      choice  then       is also without    choice;    if       has an -
choice then                has also an -choice.
✷ ✄ ➻ ●
❣  ❢ ❸ ❑ ➂ s        ◗
❶ ➐ ♥ ● ❣ ❢  ❸ ❤ ❸      ❑
➂ s ❿ ◗ and ❋ ✺❭✄➭●❣❢ ❸ ❤ ❸ 4 ❸ ❑ discussed
Now consider the languages
➂ s ➒❅◗ . inThesethe end of Section 2, ❋
languages cannot be generated by any ICG, but
they can be generated by PIDCGs.
Contextual Grammars and Dependency Trees
✂➾ã❘✄
✆✹●❣✆✯❢❁✂✏✠✎ã✒❤♦✓✘◗❲✠❦✄ ●❅✆✥❢✻✠ ✷ ❬ ✓❊✠♠✆✥❢❴❤■✠❦●❅✆ ❿ ✠✒➘❹✓✎◗❥✓✒◗❲✠❄✆❡●❣❢➋◗❲✠♠✆✯❢❁✠✒❳❨✓❊✠❦●❅✆ ❿ ✠✎❢❴✓✒◗❥✓✒✠♠✆✹●❣❢❲❤♦◗❲✠♠✆✥❢✻✠☞❤✐✓✒✠❦●❅✆✯❤■✠ ❿ ✓❊✠♠✆✥❤♠✠✎➘❹✓✒◗❥✓❷✓
Example 5.1 In order to obtain the first language, let us consider the following PIDCG

❋ ✂✏ã ❋                                                                        ❢✼                           ❢✼❤✼
. We have
. Figure 5 illustrates the unique D-tree and one of the possible D-trees generated
by  and associated with the strings , respectively        .
ÑÒ Ñ ❢                                                      ä  ä ä ❃ å ❢         ÜÑÝÒ Ü Ü Ü❤ Ü ❤ ❤
ÑÒ Ñ ❢                                        ❢ ä ä ❢ ❮ ❮❃❰             ÚÛ Ú Ñ Ú Ú Ú Ú
✼                                                                         Ú
Figure 5: D-trees of , respectively
❢✼❤✼          generated by
✂❚ã
✂❚æ➔✄ ✆✹●❣❢❁✠✎❤■✠✎4■◗❲✠❦●❅✆✯❢❲❤✒4❣✠✐●❅✆✟➘❅✠ ❿ ✓❊✠♠✆✯➘❅✠✎➴❃✓✎✆✯◗❲✂✌✠♠✆✹æ❊●❣✓✬❤ ➌ ✄ ✠♠✆✯❢❁✠✎✺ ❤✒4✐✓❊✠❦●❅✆✥❢❁✠ ❿ ✓❊✠■✆✯❤■✠✒➘❹✓✒✠♠✆✯4♠✠✎➴❃✓✎◗❥✓6✓
Example 5.2 Let
be another PIDCG. We obtain the second language,
✂✌æ
. Figure 6 illustrates one  ❋                             ❋ ❢✼❤✼4✼
of the possible D-trees generated by and associated with the string      .

❢ ÜÝ Ü Ü
ÚÛ ÑÒ Ú Ñ Ú Ü❢ Ú Ü Ú Ú ❢ ❤ ÜÑÝÒ Ü Ü Ü
Ú ÚÛ Ú Ñ Ú ❤ Ú Ü ❤
Ú Ú Ú Ú ä Ú ä Ú ä ä ❮ ä❃❃å ❰ 4
4 4 Ú❮ Ú
Figure 6: D-tree of the string
❢ ✼ ❤ ✼ 4 ✼ generated by ✂❚æ
To conclude this section, we establish the following result.

Theorem 5.2 The strict inclusion                                   ❙ ✍✱✍❯ç✶➲ ➪➇❙ ✍❚✍                  holds.
6 Conclusions

We introduced a formal model for the generation of dependency trees, dealing with free word
order phenomena. The problem is currently under study (see (Holan et al., 1998), (Dikovsky,
2001), (Gramatovici & Pĺatek, 2003)) and is far to be solved.
The model of dependency contextual grammars we propose here is based on two main char-
acteristics: the intrinsic similitude between dependency trees and contextual grammars and the
flexibility of the latter in expressing non-local dependencies. Our approach is closer to the
intrinsic motivations of original dependency grammars than other current similar attempts are.
The research of dependency contextual grammars just started since the model has to be further
tested on both mathematical and linguistical sides.
R. Gramatovici, C. Mart́ın-Vide
References
Dikovsky A. (2001). Grammars for Local and Long Dependencies. Proceedings of the 39th
Annual Meeting of the ACL.

Dikovsky A. & Modina L. (2000). Dependencies on the Other Side of the Curtain. In Traite-
ment Automatique des Langues (TAL), 41 (1), 79-111.

Gramatovici R. & Pĺatek M. (2003). On D-trivial Dependency Grammars. Submitted.

Holan T., Kuboˇn V., Oliva K. & Pĺatek M. (1998). Two Useful Measures of Word Order Com-
plexity. In Proceedings of the Coling’98 Workshop “Processing of Dependency-Based Gram-
mars”, Polguere A. & Kahane S. eds., University of Montreal, Montreal, 21-28.

Joshi A. K. (1987). An Introduction to Tree Adjoining Grammars. In Mathematics of Lan-
guages, Manaster-Ramer A. ed., Amsterdam, Philadelphia: Johm Bejamins, 87-114.

Kappes M. (2000). Bracketed Contextual Grammars. Doctoral Dissertation, Johann Wolfgang
Goethe Universiẗat, Frankfurt am Main.

Marcus S. (1967). Algebraic Linguistics. Analytical Models. New-York, London: Academic
Press.

Marcus S. (1969). Contextual Grammars, Rev. Roum. Math. Pures Appl.. 14 (10), 69-74.

Marcus S. (1997). Contextual Grammars and Natural Languages. In The Handbook of Formal
Languages, Rozenberg G. & Salomaa A. eds., Berlin, Heidelberg, New-York: Springer-Verlag,
vol. 2, 215-235.

Marcus S., Mart́ın-Vide C. & P̆aun Gh. (1998). Contextual Grammars as Generative Models
of Natural Languages. Computational Linguistics, 24 (2), 245-274.

Mart́ın-Vide C. & P̆aun Gh. (1998). Structured Contextual Grammars. Grammars, 1 (1), 33-55.

Mart́ın-Vide C., Mateescu A., Miquel-Verges J. & P̆aun Gh. (1997). Internal contextual gram-
mars: minimal, maximal and scattered use of selectors. In Proceedings of The Fourth Bar-Ilan
Symposium on Foundations of Artificial Intelligence. Focusing on Natural Languages and Ar-
tificial Intelligence - Philosophical and Computational Aspects, Koppel M. & Shamir E. eds.,
Menlo Park: AAAI Press, 159-168.

Mel’ˇcuk I. (1987). Dependency Syntax. Theory and Practice, Albany: State University of
New-York Press.

Mŕaz F., Pĺatek M. & Proch́azcha M. (2000). Restarting automata, deleting and Marcus gram-
mars. In Recent Topics in Mathematical and Computational Linguistics, Martin-Vide C. &
P̆aun Gh. eds., Bucharest: Romanian Academy Publishing House, 218-233.

P̆aun Gh. (1997). Marcus Contextual Grammars, Dordrecht, Boston, London: Kluwer.

P̆aun Gh. & Nguyen X. M. (1980). On the inner contextual grammars, Rev. Roum. Math. Pures
Appl., 25, 641-651.
