
Introduction à la traduction guidée par l’exemple
(Traduction par analogie)

Michael Carl
Institut f̈ur Angewandte Informationsforschung,
Martin-Luther-Straße 14,
66111 Saarbr̈ucken, Germany,
carl@iai.uni-sb.de
Mots-clefs – Keywords

traduction guidée par l’exemple, traduction par analogie, traduction statistique, induction de grammaire
de traduction
example-based machine translation, analogical translation, statistical machine translation, induction of
translation grammar
Résumé - Abstract

Le nombre d’approches en traduction automatique s’est multiplié dans les dernières années. Il existe
entre autres la traduction par règles, la traduction statistique et la traduction guidée par l’exemple. Dans
cet article je decris les approches principales en traduction automatique. Je distingue les approches
qui se basent sur des règles obtenues par l’inspection des approches qui se basent sur des exemples de
traduction. La traduction guidée par l’exemple se caractérise par la phrase comme unité de traduction
idéale. Une nouvelle traduction est génerée par analogie : seulement les parties qui changent par rapport
à un ensemble de traductions connues sont adaptées, modifiées ou substituées.
Je présente quelques techniques qui ont été utilisées pour ce faire. Je discuterai un système spécifique,
EDGAR, plus en detail. Je démontrerai comment des textes traduits alignés peuvent ê tre preparés en
Français produits avec le système EDGAR en les comparant avec ceux d’un
termes de compilation pour extraire des unités de traduction sous-phrastiques. Je présente des résultats
en traduction Anglais
système statistique.
In this paper I characterize a number of machine translation approaches: rule-based machine translation
(RBMT), statistical machine translation (SMT) and example-based machine translation (EBMT). While
RBMT systems make use of hand-build rules, SMT and EBMT systems explore and re-use a set of
reference translations. EBMT systems are rooted in analogical reasoning, where the ideal translation unit
is the sentence. Only if an identical sentence cannot be found in the reference material, EBMT systems
modify, substitute and adapt sequences of the retrieved examples to generate a suitable translation.
I discuss runtime and compilation time techniques and I present a system, EDGAR, in more detail.
French conclude this paper. An
I show how translation units are extracted off-line and how they are re-used during translation. The
description of a series of experiments for the translation English
extended bibliography provides further pointer for interested readers.
Michael Carl
1 Contenu
✁           Caractérisation des approches à la traduction automatique
— Traduction basée sur des règles, traduction statistique et traduction guidée par l’exemple
✁           Traduction guidée par l’exemple (EBMT)
— Approches en termes de temps d’exécution et approches en termes de compilation
✁           Le système EDGAR
— Segmentation, généralisation, spécification et raffinement
✁           Acquisition de grammaires de traduction
— Propriétés de grammaires de traduction

— Algorithme d’extraction de grammaire
Français
Expériences en traduction Anglais

— Acquisition des grammaires Anglais Français à partir du Canadian Hansards
— Echelonnement de l’approche
— Comparaison avec BabelFish et traduction statistique
— Intégration EBMT et SMT
2                   Caractérisation des approches à la traduction automatique

2.1 Traduction automatique basée sur règles (RBMT)

Des approches en traduction basée sur règles (RBMT) sont fréquemment présentés par la pyramide de
(Vauquois, 1968) (voir en dessous). Ces systèmes contiennent typiquement une série de fonctions qui
analysent les phrases à traduire : analyses morphologiques, syntaxiques et/ou sémantiques, un module
de transfert de la langue source en langue cible qui dépend du degré d’abstraction de la représentation
du système, et une série de fonctions qui genèrent la phrase cible. Ces fonctions sont controlées par
des dictionnaires et par des grammaires qui sont le plus souvent obtenues par l’inspection d’un (ou d’un
groupe de) linguiste(s). Ceci a pour conséquence un développement lent du système principalement dˆu
au problème d’acquisition de connaissances car les problèmes linguistiques de traduction doivent ê tre
d’abord complètement compris avant de les formuler en termes de règles. Mais beaucoup de problèmes
en traduction automatique n’ont pas (encore) été entièrement compris ou requièrent une analyse complète
sémantique et pragmatique ce qui n’est pas toujours disponible dans la plus part des cas.
Langage pivot
☎ ☎✆ ✂ ✂          Ressources :
✁ Règles linguistiques d’analyse
☎          ✂
☎              ✂
☎                   ✂     ✁ R`
(morphologique, syntaxique et/ou sémantique)
☎                       ✂    ✁  egles de transfert lexical et structurel
☎          Transfert ✂ ✝
R`
egles linguistiques pour la génération
☎                                         ✂
☎ ☎✆                        ✂
☎                                   ✂                        Problèmes:
✁ Acquisition et maintenance des connaissances
☎                                           ✂
☎                                                   ✂                 ✁ Développement et maintenance de
☎                                                           ✂
☎                                                                   ✂          ✁ Mod́
grandes ressource lexicales et grammaticales
☎                                                                           ✂
☎                                                                                        ✂✝
elisation linguistique détaillé

☎   ☎✆☎                                          Traduction directe                                     ✂ ✂✄
Langue source                                                                                         Langue cible
La traduction guidée par l’exemple
2.2 Traduction basée sur des données

La traduction basée sur des données (Corpus-based Machine Translation (CBMT), mais aussi Data-
driven Machine Translation) subsume un ensemble de méthodes alternatives et récentes qui visent à
resoudre le problème de l’acquisition des connaissances en traduction par règles. Ces méthodes utilisent
des textes bilingues traduits qui sont consultés lors de la traduction d’un texte ou d’une phrase nouvelle.
Les textes bilingues sont alignés en segments de manière suivante:
Texte bilingue aligné (extrait du Canadian Hansard)

1            LA CHARTE CANADIENNE DES DROITS                                   canadian charter of rights and freedoms
ET LIBERTES ́
2                                                   ́ du
L’hon. Benôıt Bouchard (secrétaire d’Etat                       Hon. Benôıt Bouchard (Secretary of State of
Canada):                                                          Canada):
3            Monsieur le Président, je voudrais porter à                     Mr. Speaker, I would like to bring to the
l’attention de la Chambre que nous célébrons                    attention of the House that today, as Hon.
aujourd’hui, comme le savent les honorables                       Members are no doubt aware, we are cele-
députés, l’anniversaire de la proclamation de                   brating the anniversary of the proclamation of
la Charte canadienne des droits et libertés                      the Canadian Charter of Rights and Freedoms
qui a eu lieu le 17 avril 1982, ainsi que son                     which took place on April 17, 1982, and also
parachèvement, il y a un an, avec l’entrée en                   of the coming into effect a year ago of the pro-
vigueur des dispositions garantissant l’égalité                 visions guaranteeing equality for all members
à tous les membres de notre société.                           of our society.

Parmis le paradigme CBMT, deux directions principales peuvent ê tre distinguées : la traduction statis-
tique et la traduction guidée par l’exemple.
2.2.1 Traduction statistique (SMT)

La traduction statistique (SMT) se base sur la théorie mathématique de distribution et d’estimation prob-
abiliste développée par Frederick Jelinek au IBM T.J. Watson Research Center et — en particulier — sur
un article de (Brown et al., 1990). Les systèmes statistiques apprennent un modèle probabiliste de tra-
duction (✞✠✟☛✡✌☞✎✍ ✏✒✑ ) à partir d’un texte bilingue et un modèle probabiliste de la langue cible (✞✠✟☛✡✌☞✓✑ ) à
partir d’un texte monolingue. En temps d’exécution, la meilleure traduction pour une phrase nouvelle
est recherchée grˆace à la maximisation de ces deux modèles probabilistes.
✔ ✟✖✕✘✗ ✚✔ ✙ ✠✞ ✟☛✡✌☞✎✍ ✏✒✑✜✛ ✔ ✟✖✕✘✗ ✔✢✙✤✣ ✞✥✟✦✡✌☞✧✑✩★✪✞✥✟✦✡✫✏✬✍ ☞✓✑✮✭

✁    modèle de traduction ✞✥✟✦✡✫✏✯✍ ☞✧✑
✁        modèle de langue ✞✥✟✦✡✌☞✧✑

Approche d’apprentissage non-supervisée basée sur les formes fléchies.
La traduction cible est synthétisée à partir de traduction(s) de mots individuels.
✁        Grande quantité de textes bilingues alignés nécessaire pour l’entraînement.
Typiquement, RBMT et SMT génèrent la phrase cible à partir des traductions de mots simples et isolés.
La ‘meilleure’ traduction est déterminée:
en SMT par les probabilités de ✞✥✟✦✡✫✏✯✍ ☞✧✑ et ✞✥✟✦✡✌☞✧✑
en RBMT par des contraintes exprimées par des règles
Michael Carl
2.2.2 La traduction guidée par l’exemple (EBMT) : Traduction par Analogie
La traduction guidée par l’exemple (Example-Based Machine Translation, EBMT) prend sa place en-
tre la RBMT et la SMT : beaucoup d’approches intègrent des règles et des techniques statistiques.
Néanmoins il y a des caractéristiques qui distinguent l’EBMT de la SMT et de la RBMT :
✁   La ‘phrase’ est l’unité de traduction idéale.
✁   Traduction guidée par l’exemple consiste à :
— rechercher les meilleurs exemple(s) de référence dans une base de données.
— substituer, modifier et adapter des séquences différentes.
Beaucoup de techniques ont été utilisées et inventées en EBMT pour substituer, modifier et adapter les
séquences de mots qui diffèrent dans les exemples de la base et les nouvelles phrases à traduire. Un
excellent survol de ces techniques et de leur enjeu se trouve dans (Somers, 1999; Somers, 2003). Dans
mon article je présente plus en detail :
✁   Approches en termes de temps d’exécution
✁   Approches en termes de compilation
— Représentations en schémas
— Représentations en arbres syntaxiques
3 La traduction guidée par l’exemple (EBMT)

3.1 Approches en termes de temps d’exécution

3.1.1 Segmentation dynamique
Dans l’approche proposé par (Andriamanankasina et al., 2003; Andriamanankasina et al., 1999) les
exemples sont balisés et les correspondances entre les mots des deux phrases sont marqués. L’exemple
le plus proche à la phrase nouvelle à traduire est rechérché et des séquences égaux sont traduites en
langue cible. Ce processus est iteré jusqu’à ce que la phrase est entièremente traduite o`u il n’y as plus
d’exemple proche disponible dans la base. La traduction peut ê tre corrigée manuellement et inserée
dans la base de manière dynamique. Andriamanankasina et al. montrent que ce cycle d’apprentissage
ameliore les résultats de traduction obtenu.
La traduction guidée par l’exemple
3.1.2 Adaptabilité versus similarité en recherche

Dans le système de (Collins & Cunningham, 1997; Collins, 1998), voir aussi : (Collins & Somers,
2003), les exemples sont balisés et segmentés et portent l’information du rôle syntaxique. Les segments
correspondants sont connectés d’une langue à l’autre. Le processus de recherche inclut une mesure
d’adaptabilité qui indique la similarité de l’exemple par rapport à son contexte externe. La notion
adaptation-guided retrieval (recherche guidée par l’adaptabilité) indique le degré auquel les exemples
retrouvés sont un bon modèle pour la traduction desiré : alors que le “CASE A” est plus similaire du
“INPUT”, “CASE B” est le meilleur modèle pour sa traduction dˆu à sa meilleure adaptabilité.
3.2 Approches en termes de compilation

3.2.1 Extraction “linguistic-light”

G̈uvenir et Cicekli (G̈uvenir & Cicekli, 1998; Cicekli & G̈uvenir, 1996; Cicekli & G̈uvenir, 2003)
présentent un algorithme pour l’extraction des correspondances lexicales de deux exemples de traduction
: des parties du côté source doivent correspondre aux parties similaires du côté cible et des chaînes de
mots différentes en langue source doivent correspondre à des chaînes de mots différentes en cible. Ces
correspondances sont apprises en forme de schémas de traduction (translation template). Un schéma
de traduction est un exemple de traduction géneralisé dont certaines parties ont été remplacées par des
variables liées.

Deux exemples de traduction :
I took a ticket from Mary         ✰    Mary’den bir      bilet      aldim
I took a pen from Mary            ✰    Mary’den bir     kalem       aldim

Généralisation de différences et extraction de correspondances lexicales :
I took a      ✱✳✲ from Mary ✰ Mary’den bir ✴✵✲                      aldim

ticket                  ✰                      bilet
pen                    ✰                     kalem
Michael Carl
3.2.2 Extraction “linguistic-heavy” : Microsoft Research MT (MSR-MT)

(Richardson et al., 2001; Menezes & Richardson, 2003) utilisent des règles pour obtenir les formes
logiques des exemples. Ces représentations sont connectées grˆace à un lexique bilingue. Ensuite des
connections ambigües sont nettoyées avec des règles de préférence. Finalement des structures de transfert
de haute qualité (ce qu’ils apellent des transfer mappings) sont extraites. Pour chaque structure de
transfert la fréquence est calculées et un contexte suffisant est gardé pour distinguer les “mappings”
ambigües pendant la traduction.

✶✷
En Informacíon del hiperv́ınculo, haga clic en la direccíon del hiperv́ınculo.
Exemple de traduction:
Under Hyperlink Information, click the hyperlink address.
Correspondances lexicales entre les formes logiques (FL)          Alignement entre FL espagnol et anglais
Structures de transfert (transfer mappings) acquises de l’espagnol vers l’anglais
La traduction guidée par l’exemple
4 Présentation du système EDGAR

Le système EDGAR (Carl, 1999) utilise des analyseurs morphologique et syntaxique en plus des ex-
emples de traduction. Un mécanisme d’induction généralise des exemples et produit une grammaire de
traduction (Carl, 2003). La segmentation et généralisation d’une nouvelle phrase source ainsi que le raf-
finement de sa traduction dans la langue cible sont guidés par le contenu de la grammaire de traduction.
4.1 Segmentation, généralisation, spécification et raffinement

La grammaire de traduction contient des unités de traduction lexicales et des schémas de traduction vari-
abilisés.

1    (Every handsome man)                ✸✺✹ ✘✻ ✼                           (Jeder stattliche Mann)                      ✸✽✹
2         (a pretty woman)                ✸✺✹ ✘✻ ✼                          (eine ḧubsche Frau)         ✸✺✹
3t        (     love✾✩✸✺✹  )  ✿✺❀❁✸✵❂❃✸✺✹ ❄ ✻✘✼                             (   ✾✩✸✺✹
lieben     ✿✺❀❅✸✵❂❃✸✽✹ ❄

Segmentation et Généralisation                                                                           Spécification et Raffinement

❆Every handsome
❇✧❊ ❈  man❉                                     ❆a pretty❇✧❊ ❈ woman❉                                                          ◗ ❬❘ ❚❱❯ ❋ ❍ ▼❬❲
loves
❈                                        ❉✧❆                                  ❇
❆ ✾●✸✽❋ ✹✽❍ ✸❏■▲❑           ✧❇ ❊ ❈ ✿✺❀❅✸
love                    ❂◆✸✽▼ ✹✽❍ ❖✮✫❉                             ✾ ✺✸ ❋ ✹❭❊ ❍ ✸❪■❬❑                 lieben         ✿✺❀❁✸    ❂ ✸✺❊▼ ✹❭❍ ❖✓✫
◗❙❄❨❘▲❍❚❱✿❩❯ ❀❁❋ ✸ ❍ ▼❳❲                                  ❈                      ❉✓❆                  ❇                         ❈       ❉✧❆            ❇
Jeder stattliche Mann                           liebt             eine ḧubsche Frau
4.2 Représentation dans le programme EDGAR

Les entrées dans la grammaire portent l’information morphologique et les lemmas sous forme d’attribut/valeur,
des traits. Les traits d’une analyse d’un mot peuvent ê tre complexe (p.ex. agr en bas) ou atomiques
(p.ex. lu en bas). De plus, les traits peuvent ê tre atomique disjonctifs (p.ex. case=d;g) ou comples
disjonctifs. Par exemple, la représentation du mot allemand “der” porte les traits suivants:
❫❴❴                                                                ❜ ❴❴ ❴❫❴                                         ❜❴
❴                                                                      ❝    lu=d_rel,c=w,sc=rel,fu=np, ❴❝
❵                ❫❴            ❜ ❴❝ ❫❴
lu=d_art,c=w,sc=art,fu=def
❜ ❴❝ ❫❴         ❜ ❴❝ ❵             ❫❴         ❜ ❴❝ ❫❴           ❜ ❴❝
❴❴         ❵ gen=f, ❵ gen=m, ❵                                                  ❵                 ❵
❴ ; ❴❛ nb=sg, ❴ ; ❴❛ nb=plu, ❴ ❴❴ ; ❴❴❛ agr= ❴❛ g=m, ❴ ; ❴❛ nb=sg, ❴ ❴❴
case=n,         case=g;d,
❴❛    agr= ❴❛ nb=sg,
case=d;g ❞            case=n ❞         case=g ❞ ❞                    nb=sg ❞         g=f        ❞ ❞

4.3 Percoler des traits avec des règles KURD

L’analyseur KURD (Carl & Schmidt-Wigger, 1998) sert à percoler les traits dans les arbres de dérivation
et à unifier et substituer des valeurs dans les noeuds. La règle NP monte l’information d’accord des
noeuds terminaux dans le noeud père.
NP    =         Aa ✣ c=np ✭ [
e ✣ c=w,sc=art,agr=_AGR ✭ ,
Les opérations de KURD
❡ ★ ae ✣ c=adj,agr=_AGR ✭,
c=noun,agr=_AGR ✭
✁             Unification et suppression de traits.
✁             Concaténation et substitution de valeurs.
]                                                                                                ✁
Au ✣ agr=_AGR ✭
Insertion et suppression de noeuds.
Michael Carl
5 Acquisition de grammaires de traduction

5.1 Propriétés des grammaires de traduction

5.1.1 Grammaire de traduction homomorphe et arbres de dérivation isomorphes

Les grammaires homomorphes produisent des arbres isomorphes et rendent possible un transfert 1-à-1
de la source à la cible.
♣Every handsome
q❬t r mans loves ♣a prettyq❬t r womans
♣ ❥ ❢✓❣       q❬t r ❦✧❧ ❢
love             ♠ ❢✧❣s
1    (Every handsome man)             ❢✓❣ ✵❤ ✐        (Jeder stattliche Mann)              ❢✧❣                                    ✉✇✈❬1 ❦✧❧ ❢
2          (a pretty woman)          ❢✓❣ ✵❤ ✐         (eine ḧubsche Frau)           ❢✓❣                                            ✉♦✈❬1 ❦✧❧ ❢
3t       (❥ ❢✧❣ love     ❦✧❧ ❢✜♠ ❢✓❣ ♥ ✵❤ ✐
)                         (    ❥ ❢✓❣
lieben         ❦✧❧ ❢♦♠ ❢✧❣ ♥
r 1                       s▲♣                     q
❥ 2 ❢✓❣ ❢✮3❬4      lieben ❦✓❧ ❢    ♠ ❢✓❣ 2 1 5❨676
r              s❬♣        q                 r        s❬♣       q
Jeder stattliche Mann                  liebt      eine ḧubsche Frau
5.1.2 Traduction compositionelle versus non-monotone (partiellement compositionelle)

Les grammaires compositionelles segmentent la phrase source récursivement en expressions qui sont
traduites indépendamment tandis que les grammaires non-monotones s’arrêtent à un certain point.
Exemple                                                            Grammaire
compositionnelle:                 business trip        8           viaje de negocios                  ❥9❢❩3▲10✮❢ ♠ ❢❩3▲10✮❢       8          ♠ ❢❩3▲10✮❢
de        ❥❶❢✮3▲10❩❢
business          8          negocios
trip         8          viaje

non-compositionnelle:                   field trip     8           viaje de estudio                           field trip        8          viaje de estudio

non-monotone                     long field trip       8           viaje de estudio largo                          long         8          largo
❥ ❨5 ❷❅❸ ♠ ❢❩3▲10✮❢                 ♠ ❢❩3▲10✮❢ ❥ 5❨❷❅❸
field trip                   viaje de estudio

5.1.3 Grammaire ambigüe versus inverse

Les grammaires ambigües permettent plusieurs traductions pour une expression source tandis que les
grammaires inverses ne produisent qu’une seule traduction.

Grammaire ambigüe :                                                        Grammaire inverse :
❥9❢❩3▲10❩❢ ♠ ❢❩3▲10✮❢     8      ♠ ❢❩3▲10❩❢
de         ❥9❢✮3❬10✮❢               ❥✵❢✮3❬10✮❢ ♠ ❢✮3▲10❩❢           8    ♠ ❢❩3▲10✮❢
de       ❥✵❢❩3▲10✮❢
business        8      negocios                                        business trip        8        viaje de negocios
trip       8      viaje                                               business         8        negocios
field       8      estudio                                                   trip       8        viaje
field       8      campo                                               field trip       8        viaje de estudio
studies        8      estudio
La traduction guidée par l’exemple
5.2 Extraction de grammaire de traduction : un algorithme

L’extraction de grammaires à partir d’exemples de traduction se pousuit en quatre étapes.
5.2.1 Alignement partiellement analysé et ancré avec un dictionnaire bilingue

D’abord l’analyse syntaxique partielle des deux côtés de l’alignement est effectuée. Des lexemes des
deux côtés sont connectés grˆace à un dictionnaire bilingue.
All other sniper training is wasted if the sniper misses his target . If the target is missed, the mission is a failure.
S’il rate sa cible , tout le reste de son instruction de tireur d’élite ne lui sert à rien, et la mission est un échec .
5.2.2        Détermination de correspondances phrase à phrase les plus significantes

Les poids des correspondances des arbres sont calculés à partir (i) des poids et le nombre des ancres
lexicales (ii) la fréquence des correspondances dans le texte et (iii) l’isomorphisme des analyses partielles
(cf. (Carl, 2003))
other        sniper       training         the       sniper                     his          target
❹ ❺❘
✷           ❹✷❺❼❻                     ❹✷❺❿❾                                  ❹✷❺               26 correspondances
❋▲▼          des phrases sont
❹✷❺ ❘✮❽ ❻                  ❹✷❺❿➀ ❽ ❾                           ❹✷❺ ❽                                  examinées
❋❬❋ ▲❋ ▼                       Anglais            ❫❴ ❹✷❺ ➀ ❽ ❻
Français
❹ ❺ ❽❻
✷                                                                                                         ❹✷❺ ❽ ❻ ❜ ❴❝            ❴ ❺❿❾ ❋ ❻
▼                                                                                                       ❹✷❺ ▼❘✮❽ ❻       ❵ ❹✷             ❺ ❽ ❽❋ ❻
❹✷❺❿➀ ❽ ❻                                                                                                     ❹✷❺ ❘ ❴                ❴❴ ❹✷
❹ ❺➂➀ ❽ ❾ ❞
✷                      ❛ ❹✷❺ ❋❬❋ ❽ ❋ ❻
❋                                                                                                                                  ❹✷❺ ❋➁❻▼ ❋
❹✷❺❿❾ ❽ ❻                                                                                                               ❋
❋                                                                                                     ❫ ❹✷❺❿➀ ❽ ❻
❹✷❺ ❽ ❻                                                             ❹➃❺ ❽                ❵ ❛ ❹✷❺❿❾ ❋ ❻
❋❬❋ ❋                                                                   ❋❳❋ ❋➁▼➅➄                  ❹✷❺ ❽ ❽ ❋ ❻
❹✷❺❿❾                                                 ❹✷❺ ❽ ❻                                                                        ❋❬❋ ❋
❋▲▼ ❋                                ❹➃❺ ❻ ❽         ❹✷❺ ➀ ❽ ❻
❹✷❺                                 ❹✷❺ ❻              ❹➃❺ ❋ ❾ ❽ ❋➁➆ ❹✷❺ ➀ ❽ ❋ ❻
❋➁▼                             ❋               ❹➃❺ ❋ ❽ ▼▲➇❘ ❹✷❺ ➀ ❽ ❋ ❻
▼❳▼ ▼                      ❋
le        reste         de         son          instruction        de          tireur d’élite

Cet extrait d’alignement de la section 5.2.1 montre trois segments anglais differents connectés avec un
segment français. Sont examinés 26 correspondances de phrases possibles dont la traduction ➈➉✞✩➊✺➋✦➌➍✰
➈➉✞➏➎✺➋➐✲➁➌ : “other sniper training ✰ reste de son instruction de tireur d’élite” est détectée la plus consis-
tente dans le texte aligné.
Michael Carl
5.2.3      Schémas de traduction générés

Les schémas sont générés par la substitution des correspondances compositionelles.
All ➈➑✞    ➊✺➋✦➌   is wasted if the sniper misses ➈➑✞     ✲✧✲✧➋➐✲▲➊ . If the target is missed, ➈➉✞ ➊✧➒✺➋❼➊✺✲   is ➈➑✞   ➊✧➓✺➋❼➊❨➌ .
S’il rate ➈➑✞➏➌✽➋❼➔ , tout le ➈➉✞➏➎✺➋➐✲➁➌ ne lui sert à rien, et ➈➑✞✩➊✧➊✺➋❼➊✧➓ est ➈➉✞✩➊✧➔✺➋❼➊✧→ .
5.2.4      Grammaire de traduction générée

Une grammaire de traduction compositionnelle et homomorphe est extraite récursivement pour chaque
exemple de traduction:
1        All other sniper training is wasted if the sniper misses his target.
If the target is missed, the mission is a failure.
S’il rate sa cible tout le reste de son instruction de tireur d’élite ne lui sert à rien,
✲                                         ➊                              ➓         ➌
et la mission est un échec.
All ➈➉✞ is wasted if the sniper misses ➈➉✞ . If the target is missed, ➈➉✞ is ➈➉✞ .
✰ S’il rate ➈➉✞ tout le ➈➉✞♦✲ ne lui sert à rien, et ➈➑✞ est ➈➑✞ ➌ .
➊                                        ➓
2

other sniper training ✰
3
4           other ➈➑✞ ➈➉✞
✲      ➊ ✰ reste                     ➊       ✲
de son instruction de tireur d’élite
reste de son ➈➉✞ de ➈➉✞
5                       training ✰        instruction
6                          sniper ✰       tireur d’élite
his target ✰
7
8                      his ➈➉✞
✲     ✰ sa ➈➉✞ ✲
sa cible

the mission ✰
9
10                    the ➈➉✞
✲ ✰ lala mission
➈➉✞ ✲
11                      mission ✰         mission
a failure ✰
12
13                       a ➈➉✞
✲   ✰ un ➈➉✞ ✲
un échec
6 Expériences en traduction guidée par l’exemple

Dans cette section nous générons des grammaires avec l’approche presenté en section 5. Un texte test
est traduit avec EDGAR présenté en section 4. Une description plus étendue des expériences peut ê tre
trouvé dans (Carl & Langlais, 2003). Les expériences se basent sur le Canadian Hansards, texte bilingue
Anglais ✰ Français. Nous présentons des expériences différentes d’extraction de grammaire aussi bien
en ce qui concerne le nombre d’exemples que le degré d’ambigüıté de la grammaire générée.
6.1 Extraction d’une grammaire de traduction

Les ressources utilisées pour extraire une grammaire de traduction (GT ✲ ) Anglais ✰ Français incluent
un dictionnaire bilingue de 77.016 entrées, un programme de segmentation en segments et un ensemble
de 50.000 exemples de traduction alignés du Canadian Hansard. Le dictionnaire couvre prèsque 3/4 des
mots anglais et français du ET ✲ mais contient seulement a peu près 1/3 des mots differents qui occurent
dans les deux textes. Le programme de segmentation (parser partiel) génère au moyen 11 et 13 segments
La traduction guidée par l’exemple
rsp. par exemple de traduction pour l’anglais et le français. Plus que la moitie des segments différents
(63% et 50% rsp.) font partie des règles lexicales de la grammaire inverse extraite.
Anglais      Français                                                     Anglais               Français
Exemples de Traduction ET ✲ :                                     Dictionnaire bilingue (DIC) :
#exemples         50.000       50.000                             #entrées du dictionnaire  77.016                77.016
#mots            888.018      947.194                             %couvert en ET ✲          74,77%                74,99%
#mots different   17.915       23.675                             #mots different               7.688               7.714
#mots/exemples     17,76         18,94                            %anchors (en ET ✲ )       42,28%                43,53%

Grammaire de traduction extraite GT ✲ :                           Segments générés par le parser partiel :
#règles lexicales            113.810                             #segments                    581,599 650,136
#schémas de traduction         70.153                            #segments différents        180,006 226,339
6.2 Traduction d’un texte test (TT)

Un texte test de 500 phrases est traduit de l’anglais vers le français avec les règles lexicales de GT ✲ .
Alors que la couverture du dictionnaire bilingue (DIC) est plus grande que celle de la grammaire GT ✲ ,
la qualité de traduction, mesurée en WER1 et en BLEU (Papineni et al., 2002), est mieux en traduction
GT ✲ . Nous voyons ici une corrélation entre la qualité des traductions et la longueur des segments utilisés
lors de la traduction.
Texte Test (TT)                                                 GT ✲          DIC
Anglais Français                     %mots couverts         66,38%       66,99%
#exemples                     500        500                    BLEU                    0,1421       0,0573
#mots                       8.665      9.806                    WER                    68,89%       81,68%
#mots/exemples              17,33      19,61
longueur segments ➣↕↔
#segments             966                146
#mots couverts     2,652                 325
%mots couverts 30,61%                 3,75%
6.3 Echelonnement de grammaires inverses et ambigües

Dans cette expérience nous étudions (i) la capacité de l’algorithme d’utiliser un nombre différent d’exemples
de traduction et (ii) l’effet de l’utilisation d’unités ambigües. Nous comparons trois grammaires dif-
feréntes générées à partir d’ensembles différents d’exemples de traduction , tous extraites du Canadian
Hansards.

ET ➒         ET ✲            ET ➊
#exemples de traduction            10.000       50.000         100.000
#mots anglais (En)                151.954      888.018       1.437.450
#mots français (Fr)              163.113      947.194       1.503.196
#mots différents En                7.343       17.915          22.501
#mots différents Fr                9.528       23.675          29.559

Ces trois ensembles de réference sont utilisés afin de générer deux types de grammaires différentes :
des grammaires inverses GT ➒ , GT ✲ et GT ➊ (dont GT ✲ est égale à celle des sections 6.1 et 6.2) et des
grammaires ambigües GT ➙➒ , GT ➙ ✲ et GT ➙➊ . Les grammaires ambigües contiennent prèsque 20% plus de
règles de transfert lexical, alors que le nombre de mots différents reste à peu près pareil dans les deux
1
Les chiffres WER supérieures et chiffres BLEU inferieures indiquent le meilleur résultat de traduction.
Michael Carl
types de grammaires. On obverve aussi que le nombre moyen de mots par règle augmente dans les
grammaires plus grandes.
Règles inverses de transfert lexical       Règles ambigües de transfert lexical
GT ➒         GT ✲           GT ➊            GT ➙➒       GT ➙ ✲           GT ➙➊
#règles lexicales           23.214      113.810        180.745          28.393     146.684          220.248
#mots Anglais (En)          203.426 1.223.260         1.856.392         222.473 1,355.331          2,030.390
#mots Français (Fr)        220.273 1.314.197         2.007.322         244.615 1,491.559          2,219.455
#mots différents En           7.338       17.910         22.488           7.340     17.914            22.495
#mots différents Fr           9.520       23.659         29.523           9.521     23.670            29.542
En ce qui concerne la qualité des traductions produites, les deux types de grammaire produisent un taux
de WER et BLEU à peu près égal. Ceci alors qu’un nombre considérable de segments de longueur
supérieure à été utilisé pour produire la traduction avec des grammaires ambigües. Nous concluons que
les entrées ambigües représentent pour la plupart des unités de traduction de qualité inferieure.
Qualité du texte test en grammaires inverses . . .                    et qualité en grammaires ambigüe
GT ➒      GT ✲      GT ➊                     GT ➙➒       GT ➙ ✲      GT ➙➊
WER                          71,91% 68,89% 66,93%                         71,88% 69,75%           67,22%
BLEU                          0,1365 0,1421 0,1704                         0,1398 0,1519           0,1706

#segments                          3.581      4.405      4.685             3.599      4.314         4.659
#segments différents                992      1.279      1.387             1.055      1.343         1.450
#mots couverts                     4.611      5.752      6.146             4.680      5.752         6.228

#segments longueur      ➣   2        767        966      1.050               816      1.032         1.108
#segments different                  353        519        589               380        570           646
#mots couverts                     1.952      2.652      2.863             2.170      2.844         3.062
6.4 Comparaison de GT, SMT et BabelFish
Dans cette expérience nous comparons les résultats de traduction obtenus utilisant les grammaires GT ➒✺➋❼➊
avec un système statistique (Langlais, 2002) entrainé sur les mêmes exemples de traduction ET ➒✺➋❼➊ . Nous
voyons que les résultats SMT sont inférieurs (toujours WER et BLEU) à ceux obtenus en GT. Le système
SMT ➓ qui a été entraîné sur un texte de 1,5 millions de exemples (15 fois plus que ET ➊ ) obtient les
meilleurs résultats.
score        GT ➒       GT ✲           GT ➊         SMT ➒      SMT ✲       SMT ➊         SMT ➓       BabelFish
BLEU       0,1365     0,1421         0,1704        0,1156     0,1231      0,1378        0,2061          0,1578
WER       71,91%     68,89%         66,93%        74,72%     73,54%      71,52%        61,66%          66,03%
Le système commercial BabelFish obtient des résultats inférieurs à ceux de SMT ➓ et GT ➊ . Ceci est
surtout dˆu aux particularités du texte traduit : alors que GT et SMT apprennent les traductions parti-
culières, BabelFish n’a pas pu ê tre adapté à ce type de texte. Ainsi, la traduction : “the speaker ✰
le président” a été réalisée par GT et SMT alors que BabelFish génère la traduction “le haut-parleur”.
De même : “some hon. members : oh , oh ! ✰ des voix : oh , oh !” est une traduction qui se voit
fréquemment en Canadian Hansards mais BabelFish produit “membres d’un certain hon : l’ OH OH”.
Alors que ce sont des traductions possibles correctes dans d’autres contextes, elles sont erronées quant à
la traduction du Canadian Hansards.
La traduction guidée par l’exemple
6.5 Intégration SMT et GT

Finalement nous essayons d’intégrer les grammaires GT et le système statistique suivant (Langlais, 2002)
: quand la grammaire GT contient une entrée égale à une séquence de mots dans la phrase à traduire, le
système SMT est forcé d’intégrer la traduction proposée par GT dans sa sortie. La qualité produite du
système hybride est meilleure quant aux grammaires inverses (SMT ➒✺➋❼➊ -GT ➒✺➋❼➊ ); pour l’intégration des
grammaires ambigües dans le systeme statistique (SMT ➒✺➋❼➊ -GT ➙➒✺➋❼➊ ) une amelioration des résultats n’a
pas pu ê tre observé.
SMT ➒ -GT ➒   SMT ✲ -GT ✲    SMT ➊ -GT ➊      SMT ➒ -GT ➙➒   SMT ✲ -GT ➙ ✲   SMT ➊ -GT ➙➊
BLEU         0.1495        0.1684         0.1789           0.1406         0.1541          0.1654
WER         71.19%        70.32%         68.94%           72.70%         72.45%          71.41%
7 Résume et conclusion

Dans cet article je présente d’approches en traduction automatique. Je fais la distinction entre la traduc-
tion par règles (RBMT), la traduction statistique (SMT) et la traduction guidée par l’exemple (EBMT).
Les ressources necessaires en RBMT sont obtenues par l’inspection d’un (ou d’un groupe de) linguiste(s),
tandis que les approches EBMT et SMT extraient les connaissances de traduction à partir des textes
bilingues alignés. Au contraste à la SMT, la ‘phrase’ est l’unité de traduction idéale en EBMT. Je
présente des systèmes EBMT qui extraient et acquirent ces unités en termes de temps d’exécution et en
termes de temps de compilation.
En suite je discute plus en détail le système EDGAR. A partir des exemples de traduction, EDGAR
produit la traduction des phrases nouvelles par analogie de manière compositionnelle et isomorphe. Je
présente un algorithme pour extraire une grammaire de traduction à partir des exemples de traduction.
L’article conclu avec la description d’une série de expériences en traduction guidée par l’exemple. De
ces expériences nous concluons que :
✁   La couverture de la grammaire est fonction du nombre des exemples de référence.
✁   Les grammaires produisent une meilleure qualité de traduction que la traduction SMT
(taille identique de référence)
✁   Les règles ambigües n’améliorent pas la qualité de la traduction.
✁   L’intégration des techniques EBMT et SMT ameliore les résultats de la traduction.
References
Al-Adhaileh, M. H. & Tang E. K. 1999. Example-Based Machine Translation Based on the Syn-
chronous SSTC Annotation Schema. Machine Translation Summit VII, Singapore, 244–249.
Andriamanankasina, T., K. Araki, & K, Tochinai. 2003. Ebmt of pos-tagged sentences with inductive
learning. In (Carl & Way, 2003).
Andriamanankasina, T., K. Araki & K. Tochinai. 1999. Example-Based Machine Translation of Part-
Of-Speech Tagged Sentences by Recursive Division. Machine Translation Summit VII, Singapore,
509–517.
Brown, P. F., J. Cocke, S. A. Della Pietra, V. J. Della Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer
& P. S. Roossin. 1990. A Statistical Approach to Machine Translation. Computational Linguistics 16,
79–85.
Brown, R. D. 1996. Example-Based Machine Translation in the Pangloss System. Coling (1996),
169–174.
Michael Carl
Brown, R. D. 1997. Automated Dictionary Extraction for “Knowledge-Free” Example-Based Transla-
tion. TMI (1997), 111–118.

Brown, R. D. 1999. Adding Linguistic Knowledge to a Lexical Example-based Translation System.
TMI (1999), 22–32.

Carl, M. & A. Way, editors. 2003. Recent Advances in Example-Based Machine Translation. Kluwer,
Academic Publisher, Boston/Dordrecht/London. in press.

Carl, M. 2003. Inducing translation grammars from bracketed alignments. In (Carl & Way, 2003).

Carl, M. & Langlais, P. 2003. Tuning general purpose translation knowledge to a sublanguage. In
Proceedings of EAMT/CLAW.

Carl, M. 1999. Inducing Translation Templates for Example-Based Machine Translation. Machine
Translation Summit VII, Singapore, 250–258.

Carl, M. & Schmidt-Wigger, A.. 1998. Shallow Postmorphological Processing with KURD. In Pro-
ceedings of NeMLaP3/CoNLL98, pages 257–265, Sydney.

Cicekli, I. & H.A. G̈uvenir. 2003. Learning Translation Templates from Bilingual Translation Exam-
ples. In (Carl & Way, 2003).

Cicekli, I. & H. A. G̈uvenir. 1996. Learning Translation Rules From A Bilingual Corpus. NeMLaP-2:
Proceedings of the Second International Conference on New Methods in Language Processing, Ankara,
Turkey, 90–97.

Collins, B. & H. Somers. 2003. EBMT Seen as Case-based Reasoning. In (Carl & Way, 2003).

Collins, B. 1998. Example-Based Machine Translation: An Adaptation-Guided Retrieval Approach.
PhD thesis, Trinity College, Dublin.

Collins, B. & P. Cunningham. 1997. Adaptation Guided Retrieval: Approaching EBMT with Caution.
TMI (1997), 119–126.

Cranias, L., H. Papageorgiou & S. Piperidis. 1994. A Matching Technique in Example-Based Machine
Translation. Coling (1994), 100–104.

Furuse, O. & H. Iida. 1992. An Example-Based Method for Transfer-Driven Machine Translation. TMI
(1992), 139–150.

Furuse, O. & H. Iida. 1994. Constituent Boundary Parsing for Example-Based Machine Translation.
Coling (1994), 105–111.

G̈uvenir, H. A. & I. Cicekli. 1998. Learning Translation Templates from Examples. Information Systems
23, 353–363.

Kaji, H., Y. Kida & Y. Morimoto. 1992. Learning Translation Templates from Bilingual Text. Coling
(1992), 672–678.

Langlais, P. 2002. Ressources terminologiques et traduction probabiliste: premiers pas positifs vers un
système adaptatif. In TALN-2002.

Matsumoto, Y. & M. Kitamura. 1995. Acquisition of Translation Rules from Parallel Corpora. In R.
Mitkov & N. Nicolov (eds) Recent Advances in Natural Language Processing: Selected Papers from
RANLP’95, Amsterdam: John Benjamins, 405–416.

McTait, K. & A. Trujillo. 1999. A Language-Neutral Sparse-Data Algorithm for Extracting Translation
Patterns. TMI (1999), 98–108.
La traduction guidée par l’exemple
Menezes, A. & S.D. Richardson. 2003. A best-first alignment algorithm for automatic extraction of
transfer mappings from bilingual corpora. In (Carl & Way, 2003).

Meyers, A., R. Yangarber, R. Grishman, C. Macleod & A. Moreno-Sandeval. 1998. Deriving Transfer
Rules from Dominance-Preserving Alignments. Coling-ACL (1998), 843–847.

Nagao, M. 1984. A Framework of a Mechanical Translation between Japanese and English by Analogy
Principle. In A. Elithorn and R. Banerji (eds) Artificial and Human Intelligence, 173–180, Amsterdam:
North-Holland.

Nirenburg, S., S. Beale & C. Domashnev. 1994. A Full-Text Experiment in Example-Based Machine
Translation. International Conference on New Methods in Language Processing (NeMLaP), Manch-
ester, England, 78–87.

Papineni, K., S. Roukos, T. Ward, & W.-J. Zhu. 2002. Bleu: a method for automatic evaluation of
machine translation. In Proceedings of the 40th Annual Meeting of the ACL, Philadelphia, Pennsylvania,
USA, 311–318.

Richardson, S.D., W.B. Dolan, A. Menezes & J. Pinkham. 2001. Achieving Commercial-quality Trans-
lation with Example-based Methods. MT Summit VIII: Machine Translation in the Information Age,
Santiago de Compostela, Spain, 293–298.

Sato, S. & M. Nagao. 1990. Toward Memory-Based Translation. Coling (1990), Vol. 3, 247–252.

Somers, H. 1999. Review Article: Example-based Machine Translation. Machine Translation,
14(2):113–157.

Somers, H. 2003. An Overview of EBMT. In (Carl & Way, 2003).

Sumita, E. & H. Iida. 1991. Experiments and Prospects of Example-Based Machine Translation. 29th
Annual Meeting of the Association for Computational Linguistics, Berkeley, California, 185–192.

Sumita, E., H. Iida & H. Kohyama. 1990. Translating with Examples: A New Approach to Machine
Translation. TMI (1990), 203–212.

Vauquois, B. 1968. A Survey of Formal Grammars and Algorithms for Recognition and Transformation
in Machine Translation. IFIP Congress-68, Edinburgh, 254–260; reprinted in Ch. Boitet (ed.) Bernard
Vauquois et la TAO: Vingt-cinq Ans de Traduction Automatique – Analectes, 201–213, Grenoble (1988):
Association Champollion.

Veale, T. & A. Way. 1997. Gaijin: A Bootstrapping Approach to Example-Based Machine Translation.
International Conference, Recent Advances in Natural Language Processing, Tzigov Chark, Bulgaria,
239–244.

Watanabe, H. 1992. A Similarity-Driven Transfer System. Coling (1992), 770–776.

Watanabe, H. 1993. A Method for Extracting Translation Patterns from Translation Examples. TMI
(1993), 292–301.

Watanabe, H. & K. Takeda. 1998. A Pattern-Based Machine Translation System Extended by Example-
Based Processing. Coling-ACL (1998), 1369–1373.

Way, A. 1999. A Hybrid Architecture for Robust MT using LFG-DOP. Journal of Experimental and
Theoretical Artificial Intelligence 11, 441–471.
