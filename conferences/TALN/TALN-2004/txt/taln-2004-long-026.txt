TALN 2004, F√®s, 19‚Äì21 avril 2004
Approche statistique pour le rep√©rage de mots informatifs
dans les textes oraux

Narj√®s Boufaden (1), Yoshua Bengio (2), Guy Lapalme (1)
(1) Laboratoire RALI - Universit√© de Montr√©al
Qu√©bec, Canada
boufaden@iro.umontreal.ca, lapalme@iro.umontreal.ca
(2) Laboratoire LISA - Universit√© de Montr√©al
Qu√©bec, Canada
bengioy@iro.umontreal.ca
R√©sum√© - Abstract

Nous pr√©sentons les r√©sultats de l‚Äôapproche statistique que nous avons d√©velopp√©e pour le rep√©-
rage de mots informatifs √† partir de textes oraux. Ce travail fait partie d‚Äôun projet lanc√© par le
d√©partement de la d√©fense canadienne pour le d√©veloppement d‚Äôun syst√®me d‚Äôextraction d‚Äôin-
formation dans le domaine de la Recherche et Sauvetage maritime (SAR). Il s‚Äôagit de trouver
et annoter les mots pertinents avec des √©tiquettes s√©mantiques qui sont les concepts d‚Äôune on-
tologie du domaine (SAR). Notre m√©thode combine deux types d‚Äôinformation : les vecteurs
de similarit√© g√©n√©r√©s gr√¢ce √† l‚Äôontologie du domaine et le dictionnaire-th√©saurus Wordsmyth ;
le contexte d‚Äô√©nonciation repr√©sent√© par le th√®me. L‚Äô√©valuation est effectu√©e en comparant la
sortie du syst√®me avec les r√©ponses de formulaires d‚Äôextraction d‚Äôinformation pr√©d√©finis. Les
r√©sultats obtenus sur les textes oraux sont comparables √† ceux obtenus dans le cadre de MUC7
pour des textes √©crits .

We present results of a statistical method we developped for the detection of informative words
from manually transcribed conversations. This work is part of an ongoing project for an infor-
mation extraction system in the field of maritime Search And Rescue (SAR). Our purpose is
to automatically detect relevant words and annotate them with concepts from a SAR ontology.
Our approach combines similarity score vectors and topical information. Similarity vectors are
generated using a SAR ontology and the Wordsmyth dictionary-thesaurus. Evaluation is carried
out by comparing the output of the system with key answers of predefined extraction templates.
Results on speech transcriptions are comparable to those on written texts in MUC7.
Mots-clefs ‚Äì Keywords

√âtiquetage s√©mantique, extraction d‚Äôinformation
Semantic tagging, information extraction
Narj√®s Boufaden, Yoshua Bengio, Guy Lapalme
1     Introduction

Le rep√©rage de mots informatifs consiste √† d√©tecter des mots qui apportent de l‚Äôinformation
pertinente1 relativement √† un domaine particulier. Cette t√¢che est une √©tape charni√®re pour
beaucoup d‚Äôapplications du Traitement Automatique de la Langue (TAL) telles que l‚Äôextrac-
tion d‚Äôinformation et la g√©n√©ration automatique de r√©sum√©. Dans cet article nous √©tudions le
rep√©rage de mots informatifs pour l‚Äôextraction d‚Äôinformation (EI) √† partir de textes oraux.
L‚Äôextraction d‚Äôinformation (EI) a pour but la collecte d‚Äôinformations pertinentes dans un do-
maine d‚Äôapplication particulier. Les approches d‚ÄôEI pour les textes √©crits se basent en g√©n√©ral
sur le contexte imm√©diat (partie de phrase) des mots informatifs pour les d√©tecter (Appelt et al.,
1993; Aberdeen et al., 1996). Les approches symboliques utilisant des patrons d‚Äôextraction ainsi
que les approches d‚Äôapprentissage bas√©es sur les HMM (Leek, 1997; McCallum et al., 2000) ou
les r√®gles d‚Äôinduction (Riloff, 1998; Soderland et al., 1995) sont des exemples classiques utili-
sant le contexte imm√©diat. Toutes ces approches reposent sur l‚Äôhypoth√®se de la grammaticalit√©
des textes et de ce fait sont inad√©quates pour les textes oraux.
L‚Äôapproche que nous pr√©sentons diff√®re des approches classiques d‚ÄôEI con√ßues pour les textes
√©crits notamment par sa robustesse aux extra-grammaticalit√©s pr√©sentent dans les textes oraux.
Nous utilisons le contenu du mot et le contexte d‚Äô√©nonciation repr√©sent√© par le th√®me de l‚Äô√©nonc√©
pour rep√©rer les mots informatifs. les mots potentiellement pertinents sont identifi√©s gr√¢ce √†
leur contenu (par opposition au contexte syntaxique d√©finit par une partie de phrase). Cela
contourne les probl√®mes des irr√©gularit√©s grammaticales caus√©es par les r√©p√©titions ou omis-
sions, par exemple, tr√®s pr√©sentes dans les textes oraux. De plus, le th√®me que l‚Äôon associe √† un
√©nonc√© d√©finit un contexte de nature s√©mantique moins vuln√©rable aux extra-grammaticalit√©s et
permet de s√©lectionner les mots informatifs parmi ceux qui sont potentiellement pertinents. De
fait, le th√®me joue un r√¥le de d√©sambiguisation.
Dans ce qui suit nous d√©crivons d‚Äôabord le corpus utilis√© pour ce projet (section 2), puis, les
diff√©rentes parties du syst√®me d‚ÄôEI (section 3). Ensuite, nous explicitons le mod√®le utilis√© pour
le rep√©rage de mots informatifs (section 4) et pr√©sentons les r√©sultats de nos exp√©riences (section
5). Enfin, nous comparons nos r√©sultats √† ceux de travaux existants (section 6).
2     Cadre de projet et description du corpus

Ce travail fait partie d‚Äôun projet qui a pour but d‚Äôimpl√©menter un syst√®me d‚ÄôEI pour rep√©rer
des informations ayant un lien avec les missions de recherche et sauvetage maritimes (domaine
SAR) tels que la nature de l‚Äôincident, l‚Äôendroit de l‚Äôincident, les ressources allou√©es pour la
recherche et les conditions m√©t√©orologiques pendant la mission de recherche. Le projet a √©t√©
men√© par le Centre de Recherche de la D√©fense Valcartier (CRDV) afin de d√©velopper un outil
d‚Äôaide √† la g√©n√©ration de plan de SAR √† partir de conversations t√©l√©phoniques manuellement
transcrites.
Le corpus est une collection de 95 conversations t√©l√©phoniques transcrites manuellement (39.000
mots). Dans la plupart des cas ce sont des conversations impliquant deux locuteurs (l‚Äôappelant
Caller et un op√©rateur Operator) qui discutent des conditions et circonstances entourant un in-
1
Dans la suite de l‚Äôarticle, nous utilisons par abus de langage le mot ‚Äôpertinent‚Äô pour signifier ‚Äôpertinent par
rapport au domaine de la Recherche et Sauvetage‚Äô.
Approche statistique pour le rep√©rage de mots informatifs dans les textes oraux
1-O :Hi, it‚Äôs Mr. Joe Blue.
PERSON
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì OTHER‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-
3-O :We get an overdue boat, missing boat        on the South Coast of Newfoundland...
VESSEL             VESSEL             LOCATION
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì INCIDENT‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-
4-O :They did a radar search for us in the area.
DETECTION               LOCATION
5-C :Hum, hum.
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì MISSION‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-
8-O :And I am wondering about the possibility of outputting an Aurora in there for radar search.
STATUS           STATUS              TASK           SAR - AIRCRAFT      DETECTION
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì SEARCH UNIT‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-

11-O :They got a South East to be flowing there and it‚Äôs just gonna be black thicker fog the whole,
STATUS             DIRECTION                 STATUS    WEATHER
12-C :OK.
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì MISSION‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-
F IG . 1 ‚Äì Exemple d‚Äôune conversation indiquant un incident :an overdue boat, une requ√™te pour
allouer des avions SAR pour la recherche : Aurora. Les mots en gras italiques sont reconnus
par l‚Äô√©tiqueteur s√©mantique (section 3.3). Tandis que les mots en gras uniquement sont des
candidats pour le rep√©rages de mots informatifs (section 4) . Les √©tiquettes sous les groupes de
mots en gras sont des concepts de l‚Äôontologie. Les lignes horizontales sont les fronti√®res des
th√®mes (MISSION, INCIDENT, SEARCH UNIT, OTHER) ajout√©s manuellement.
cident ou une mission de recherche et sauvetage. Les conversations sont : (1) des rapports
d‚Äôincidents survenus tels qu‚Äôune personne port√©e disparue ou un bateau en retard, (2) l‚Äô√©labo-
ration d‚Äôun plan de sauvetage tels que l‚Äôallocation d‚Äôavions et de bateaux pour les besoins de la
recherche, (3) le compte rendu d‚Äôune mission de sauvetage et les r√©sultats de cette mission ou
une combinaison des ces trois cas. La Figure 1 donne un extrait de ces conversations.
Le corpus est particuli√®rement bruit√© et certaines parties d‚Äô√©nonc√©s sont remplac√©es par le mot
‚ÄúINAUDIBLE‚Äù pour indiquer que l‚Äôenregistrement est incompr√©hensible. Plus de la moiti√© des
√©nonc√©s contiennent au moins une extra-grammaticalit√© (Shriberg, 1994) telles que les r√©p√©ti-
tions (Ha, do, is there, is there . . .) , les omissions et interruptions (we‚Äôve been, _ actually had a
. . .). Enfin, nous avons comptabilis√© 3% d‚Äôerreurs de transcriptions qui apparaissent en majorit√©
dans les mots informatifs comme c‚Äôest le cas dans l‚Äô√©nonc√© 11-O o√π le mot flowing devrait
√™tre blowing (Figure 1).
3     Architecture du syst√®me d‚Äôextraction d‚Äôinformation

L‚Äôextraction d‚Äôinformation s‚Äô√©labore en quatre √©tapes. L‚Äô√©tape I est l‚Äôanalyse syntaxique et la
d√©tection des groupes de mots candidats √† l‚Äôextraction. Ce sont essentiellement les groupes
nominaux, verbaux, adverbiaux et adjectivaux. L‚Äô√©tape II, l‚Äô√©tiquetage s√©mantique, annote les
Narj√®s Boufaden, Yoshua Bengio, Guy Lapalme
groupes de mots avec les concepts qu‚Äôil reconna√Æt gr√¢ce √† l‚Äôontologie du domaine que nous
avons construie. L‚Äô√©tape III, permet le rep√©rage et l‚Äô√©tiquetage s√©mantique de groupes de mots
informatifs qui ne font pas partie de l‚Äôontologie du domaine et par cons√©quent qui n‚Äôont pu √™tre
√©tiquet√©s √† l‚Äô√©tape pr√©c√©dente. Enfin, les groupes de mots extraits sont utilis√©s dans le processus
de r√©solution de cor√©f√©rence pour, ensuite, remplir les formulaires d‚Äôextraction. La Figure 2
illustre l‚Äôarchitecture du syst√®me d‚Äôextraction d‚Äôinformation.
Dans la prochaine section, nous d√©crivons de mani√®re concise les trois premi√®res √©tapes, la
conception de l‚Äôontologie du domaine SAR et la segmentation en th√®mes. (Boufaden, 2003;
Boufaden et al., 2002; Boufaden et al., 2001) pr√©sentent une description d√©taill√©e de ces mo-
dules. La r√©solution de cor√©f√©rence et le remplissage de formulaires d‚Äôextraction sont laiss√©s
pour des travaux futurs. Le rep√©rage des groupes de mots informatifs qui fait l‚Äôobjet de cet
article est d√©taill√© dans la section 4.

Conversation
transcrite
√©tape I :Analyse syntaxique               . . .. . .. . .. . .. . .
Extraction
des groupes de mots

√©tape II :√âtiquetage s√©mantique             . . .. . .. . .. . .. . .
√âtiquetage o                        Ontologie
s√©mantique                         qq SAR
qq
Stage III :Rep√©rage des                                                 qqqqq
. . .. . .. . .. . .. . .      qq
mots informatifs
qqqqq
         xqq              Dictionnaire
Calcul des vecteurs o                       th√©saurus
de similarit√©                       Wordsmyth
Mod√®le statistique o                    Annotation
de th√®mes
O
√©tape IV :Remplissage                   . . .. . .. . .. . .. . .         Segmentation
des formulaires                                                     jj en th√®mes
       tjjjj
R√©solution de cor√©f√©rence
et
g√©n√©ration des formulaires d‚ÄôEI

F IG . 2 ‚Äì Cette figure pr√©sente les principales composantes du syst√®me d‚ÄôEI. Les rectangles
simples repr√©sentent les modules qui ont d√©j√† √©t√© d√©velopp√©s et sont d√©crits bri√®vement dans
les sections 3.1, 3.2 et 3.3. Le rectangle en gras est le module qui fait l‚Äôobjet de cet article. Les
rectangles en pointill√©s sont des modules laiss√©s pour des travaux futurs.
3.1    Segmentation en th√®mes

Le mot th√®me utilis√© dans plusieurs travaux (Carbonell et al., 1999; Hearst, 1994) ne jouit pas
d‚Äôune d√©finition formelle. Selon l‚Äôapplication cible, le th√®me peut varier du sujet d‚Äôun texte au
propos d‚Äôune partie d‚Äôun texte. (Hearst, 1994; Brown & Beorge, 1983) s‚Äôaccordent pour dire
que la notion de th√®me dans un contexte de segmentation de textes implique que les phrases
Approche statistique pour le rep√©rage de mots informatifs dans les textes oraux
sont regroup√©es naturellement selon leur ‚Äôpropos‚Äô2 . Dans le cadre de notre application, nous
avons d√©velopp√© un module de segmentation en th√®mes qui permet de regrouper les √©nonc√©s
adjacents qui portent sur un aspect de la mission, tels que l‚Äôannonce d‚Äôun incident (√©nonc√© 3-O
Figure 1) ou le r√©sultat d‚Äôune mission de recherche et sauvetage. Dans (Boufaden et al., 2001;
Boufaden et al., 2002), nous montrons qu‚Äôen utilisant des connaissances pragmatiques, s√©man-
tiques, syntaxiques et lexicales, il est possible moyennant un mod√®le de Markov de g√©n√©rer les
changements de th√®mes3 avec un rappel de 61,4% et une pr√©cision de 67,3%.
3.2     Ontologie du domaine

L‚Äôontologie du domaine est une composante fondamentale dans notre approche de rep√©rage
des mots informatifs. Elle est utilis√©e lors de l‚Äô√©tiquetage s√©mantique (section 3.3) et pour la
g√©n√©ration des vecteurs de similarit√© (Boufaden, 2003). L‚Äôontologie du domaine est utilis√©e pour
quantifier la pertinence d‚Äôun mot par rapport au domaine. Dans la section 4.2, nous montrons
que la probabilit√© qu‚Äôun mot soit informatif est une fonction du degr√© de similarit√© de ce mot
par rapport aux concepts du domaine SAR.
L‚Äôontologie a √©t√© construite √† partir de manuels fournis par le Secr√©tariat de la Recherche et
Sauvetage Nationale et d‚Äôun √©chantillon de 10 conversations choisies au hasard. Elle est consti-
tu√©e de mots ou groupes de mots informatifs tels que radar search, diving pour les
moyens de d√©tections, drifting, overdue pour les incidents et wind, rain, fog pour les
conditions m√©t√©orologiques. Ces mots sont des exemples de r√©ponses pour les champs des for-
mulaires d‚ÄôEI. Ils sont regroup√©s en 24 classes et organis√©es en une hi√©rarchie IS - A et une autre
PART- OF . Les classes de l‚Äôontologie forment les concepts pertinents du domaine SAR. Ils sont
utilis√©s pour √©tiqueter les mots informatifs comme nous l‚Äôexpliquons dans la section 4. Enfin,
chaque entr√©e de l‚Äôontologie contient un mot informatif, une liste exhaustive de synonymes ex-
traite de Wordsmyth4 et leur d√©finitions textuelles aussi extraites du dictionnaire-th√©saurus. La
Figure 3 est un exemple des entr√©es de Wordsmyth que nous avons utilis√© pour la construction
de l‚Äôontologie.
3.3     √âtiquetage s√©mantique

L‚Äô√©tiqueteur s√©mantique est similaire √† un module d‚Äôextraction d‚Äôentit√©s nomm√©es (MUC, 1998).
Il reconna√Æt des entit√©s nomm√©es telles que les lieux, les personnes, les organisations, les noms
d‚Äôavions, de bateaux et de mat√©riel de d√©tection. Il est bas√© sur un automate √† √©tats finis qui
effectue l‚Äô√©tiquetage en deux √©tapes illustr√©es dans la Figure 4. La premi√®re √©tape recherche
un appariement entre la t√™te du syntagme analys√© et les instances des concepts de l‚Äôontologie.
Lorsque un appariement r√©ussit, le t√™te est annot√©e par le concept dont le mot est une instance.
La deuxi√®me √©tape sert √† propager l‚Äô√©tiquette s√©mantique de la t√™te du syntagme vers tout le
syntagme. La sortie de l‚Äô√©tiqueteur s√©mantique est repr√©sent√©e par les mots en gras italique
dans la Figure 1. Dans (Boufaden, 2003), nous montrons que l‚Äô√©tiqueteur s√©mantique attribue
2
Ce terme est la traduction de ‚Äôaboutness‚Äô selon le glossaire fran√ßais-anglais de terminologie linguistique SIL
http ://www.sil.org/linguistics/
3
Les changements de th√®mes sont repr√©sent√©s par une √©tiquette. Quatre autres sont utilis√©es pour distinguer les
√©nonces qui font partie d‚Äôun segment de th√®me de celles qui clos le segment de th√®me, qui initient une conversation
ou qui indiquent la fin d‚Äôune conversation
4
URL http ://www.wordsmyth.net/.
Narj√®s Boufaden, Yoshua Bengio, Guy Lapalme
ENT:              wonder
SYL:              won-der
PRO:              wuhn dEr
POS:              intransitive verb
INF:              wondered, wondering, wonders
DEF:              1. to experience a sensation of admiration or amazement (of-
ten fol.          by at):
EXA:              She wondered at his bravery in combat.
SYN:              marvel
SIM:              gape, stare, gawk
DEF:              2. to be curious or skeptical about something:
EXA:              I wonder about his truthfulness.
SYN:              speculate (1)
SIM:              deliberate, ponder, think, reflect, puzzle, conjecture
...

F IG . 3 ‚Äì Description d‚Äôune entr√©e du dictionnaire-th√©saurus Wordsmyth pour le verbe wonder
qui est un verbe g√©n√©ralement utilis√© pour formuler une requ√™te pour allouer du mat√©riel de re-
cherche. Ce verbe a pour √©tiquette le concept STATUS (8-O Figure 1). Les acronymes ENT, SYL,
PRO , POS, INF, DEF , EXA , SYN , SIM sont respectivement l‚Äôentr√©e, la syllabe, la prononciation,
la cat√©gorie syntaxique, les formes fl√©chies, la d√©finition textuelle, un exemple, les mots syno-
nymes et les mots similaires. Pour construire notre ontologie nous avons utilis√© les informations
contenues dans les champs ENT, DEF, SYN et SIM.

les concepts avec un rappel de 85,3% et une pr√©cision de 94,8%.

√âtape 1 : . . .SN : black thicker fog . . .
WEATHER - TYPE
‚Üê Propagation
√âtape 2 : . . .SN : black thicker fog . . .
WEATHER - TYPE

F IG . 4 ‚Äì Le syntagme nominal SN : black thicker fog est √©tiquet√© avec le concept WEATHER
(√©nonce 11-O). La premi√®re √©tape de l‚Äôanalyse s√©mantique reconna√Æt la t√™te fog comme un type
de conditions climatiques. La deuxi√®me √©tape propage le concept √† tout le syntagme nominal.
4        Rep√©rage des mots informatifs
Le rep√©rage de mots informatifs est une fonction du contexte d‚Äô√©nonciation repr√©sent√© par le
th√®me T et de la pertinence du mot par rapport aux concepts Ck de l‚Äôontologie. Pour calculer
la pertinence, nous utilisons le contenu du mot w repr√©sent√© par sa d√©finition textuelle Dw ,
la mesure de similarit√© OC5 (Manning & Schutze, 2001) (section 4.2) et l‚Äôontologie. Chaque
mot est repr√©sent√© par un vecteur de similarit√© qui contient les scores de similarit√© sim(w, Ck )
obtenus pour chaque concept Ck de l‚Äôontologie. Le th√®me permet d‚Äô√©carter les faux positifs
qui sont les mots w tel que w proche (selon la mesure de similarit√© ) d‚Äôun concept Ck et Ck
5
Overlap Coefficient.
Approche statistique pour le rep√©rage de mots informatifs dans les textes oraux
est rarement observ√© dans le contexte d‚Äô√©nonciation ayant pour th√®me T . Dans ce qui suit,
nous pr√©sentons le mod√®le de rep√©rage. La section 4.2 d√©crit la mod√©lisation de la distribution
des concepts sachant les mots. Ce mod√®le permet de calculer P (Ck |wt ) √† partir des scores de
similarit√© sim(wt , Ck ) (√âquation 2). La section 4.3 explicite la mod√©lisation de la distribution
des concepts Ck √©tant donn√© les th√®mes Tt .
4.1    Mod√®le

Une formulation de notre probl√©matique est : chercher le concept Ck qui maximise la similarit√©
pour un mot wt et Ck fr√©quemment observ√© √©tant donn√© le th√®me Tt . Cela se traduit par un
produit d‚Äôexperts. Un expert, P (Ct |wt ), mod√©lise la distribution des concepts sachant le mot ;
l‚Äôautre, P (Ct |Tt ), mod√©lise la distribution des concepts sachant le th√®me. Les coefficients Œ≤1 et
Œ≤2 sont des poids qui refl√®tent la contribution de chacun des experts dans le mod√®le de rep√©rage.
Lorsque les deux experts P (Ct |Tt ) et P (Ct |wt ) s‚Äôentendent sur le concept qui maximise ces
deux probabilit√©s, il est facile de conclure que wt est informatif. Le cas non trivial est lorsque
les experts ne s‚Äôentendent pas sur le concept. Dans ce cas la d√©cision repose sur un seuil de
confiance Œ¥ d√©termin√© de mani√®re empirique (√âquation 1). Un mot wt est consid√©r√© informatif
lorsque P (C ‚àó |wt , Tt ) est sup√©rieur √† Œ¥. L‚Äô√©quation 1 d√©crit le mod√®le P (C ‚àó |wt , Tt ).
P (Ct = k|wt )Œ≤1 P (Ct = k|Tt )Œ≤2
P (Ct = k|wt , Tt ) =                   Œ≤1                                  (1)
Œ£K
l=1 P (Ct = l|wt P (Ct = l|Tt )
Œ≤2
et
C = argmax P (Ct |wt , Tt ), P (C ‚àó |wt , Tt ) > Œ¥
Ct
k est un des K concepts de l‚Äôontologie, log P (Ct = k|wt ) repr√©sente la log probabilit√©
d‚Äôobserver le concept k √©tant donn√© le mot wt et log P (Ct = k|Tt ) est la log probabilit√©
d‚Äôobserver le concept k √©tant donn√© le th√®me Tt .
4.2    Distribution des concepts par rapport √† un mot

La pertinence d‚Äôun mot est quantifi√©e en utilisant la mesure de similarit√© OC. Cette mesure
correspond √† la proportion de mots en commun, contenus dans la d√©finition textuelle du mot et
celle d‚Äôun concept (√âquation 2). Un mot est jug√© proche du domaine lorsqu‚Äôun des scores de
similarit√© est √©lev√© pour un concept donn√©. (Boufaden, 2003) pr√©sente l‚Äôalgorithme qui permet
de calculer les scores de similarit√©s et de g√©n√©rer les vecteurs de similarit√©.
| Dw(l) | ‚à© | DCk |
sim(w(l), Ck ) =                                                   (2)
min(| Dw(l) |, | DCk |)
w(l) repr√©sente un sens particulier l du mot w et Ck un concept de l‚Äôontologie du domaine.
Dw(l) et DCk sont respectivement les ensembles de mots lemmatis√©s extraits des d√©finitions
textuelles de w(l) et Ck . Les d√©finitions textuelles sont extraites √† partir de Wordsmyth.

La distribution d‚Äôun concept par rapport √† un mot P (Ck |wt ) s‚Äôexprime en fonction de la proba-
bilit√© d‚Äôobserver un concept Ck √©tant donn√© un sens particulier w(l) du mot w et la probabilit√©
d‚Äôobserver un sens particulier w(l) sachant w. P (Ck |w(l)) est obtenue par une redistribution
Narj√®s Boufaden, Yoshua Bengio, Guy Lapalme
des scores du vecteur de similarit√© afin d‚Äôattribuer une probabilit√© tr√®s faible aux scores nuls.
Aussi, pour simplifier nos calculs nous supposons que les sens d‚Äôun mot sont √©quiprobables
(√âquation 3).

P (Ck |w) =               P (Ck |w(l))P (w(l)|w),                     (3)
w(l)‚ààS(w)
1
P (w(l)|w) =
| S(w) |
Avec w(l) ‚àà S(w) sont les diff√©rents sens du mot w, P (Ck |w(l)) est le score de similarit√©
normalis√© entre le concept Ck √©tant donn√© un sens w(l) de w et P (w(l)|w) est la probabilit√©
d‚Äôobserver le sens w(l) √©tant donn√© le mot w.
4.3     Distribution des concepts par rapport √† un th√®me

Selon le d√©coupage effectu√© √† l‚Äô√©tape de segmentation (section 3.1), un segment est compos√©
d‚Äô√©nonc√©s dont le th√®me peut √™tre class√© en cinq cat√©gories :(1)MISSING _ OBJECT qui englobe
toutes les informations faisant r√©f√©rence √† l‚Äôobjet impliqu√© dans un incident ; (2)INCIDENT qui
d√©crit l‚Äôincident, sa cause et l‚Äôendroit o√π il s‚Äôest produit ; (3)SEARCH _ UNIT qui rapporte les faits
et actes des √©quipes de recherches ; (4)MISSION qui d√©crit les conditions m√©t√©orologiques lors
de la mission, l‚Äôendroit o√π sont effectu√©es les recherches ; (5)OTHER qui contient toutes autres
informations qui n‚Äôa pas de lien directe avec le type d‚Äôinformation recherch√©e (section 2). La
probabilit√© P (Ct |Tt ) est d√©finie par l‚Äô√©quation :

P (Ct |Tt ) = Œ±P0 (Ct ) + (1 ‚àí Œ±)P1 (Ct |Tt )                         (4)

CT est la s√©quence des concepts observ√©s, TT la s√©quence des th√®mes observ√©s. Œ± est le
param√®tre libre de notre mod√®le. P0 (Ct ) est la fr√©quence relative des concepts dans le
corpus d‚Äôentra√Ænement et P1 (Ct |Tt ) la fr√©quence relative des concepts sachant le th√®me.
5      Exp√©riences et r√©sultats
Le corpus d‚Äôentra√Ænement est constitu√© de 1850 mots, soit 65% des 64 conversations anno-
t√©es manuellement avec les concepts de l‚Äôontologie et les th√®mes. Les r√©sultats sont obtenus
en comparant les concepts g√©n√©r√©s par le mod√®le de rep√©rage aux r√©ponses des formulaires
pr√©alablement annot√©es avec les concepts de l‚Äôontologie. Le Tableau 1 donne le rappel et la
pr√©cision obtenus pour le seuil Œ¥ = 0.35. Ce seuil est calcul√© de mani√®re empirique sur le cor-
pus de test. Afin de comparer le mod√®le bas√© sur la similarit√© et le mod√®le exponentiel nous
avons consid√©r√© uniquement les P (Ct |wt ) > 0.02. Pour des rappels √©quivalents (38, 5% pour
P (Ct |wt ) et 36, 8% pour P (Ct |wt , Tt )) le mod√®le exponentiel performe mieux que la mod√®le
bas√© uniquement sur la similarit√©. Bien que le mod√®le bas√© sur les th√®mes ait une faible perfor-
mance, celui-ci a permis d‚Äôaugmenter la pr√©cision du rep√©rage de mots informatifs de 16,2 %.
La moyenne performance du mod√®le bas√© sur la similarit√© est probablement due √† l‚Äôapproxi-
mation faite pour passer du vecteur de scores de similarit√© vers P (Ct |wt ). Une am√©lioration
possible est de repr√©senter P (Ct |wt ) comme une mixture de gaussiennes o√π chaque gaussienne
est une fonction de la similarit√© par rapport √† un concept donn√©. Le r√©sultat modeste du mod√®le
de rep√©rage de mots informatifs est en partie d√ª aux erreurs d‚Äô√©tiquetage syntaxique caus√©es
par les extra-grammaticalit√©s qui engendrent un score de similarit√© erron√©. Par ailleurs, √† cause
Approche statistique pour le rep√©rage de mots informatifs dans les textes oraux
P (Ct |Tt )        P (Ct |wt )  P (Ct |Tt , wt )
Mots        Pr√©cision Rappel Pr√©cision Rappel Pr√©cision Rappel
Tous           37,4%         44% 73,33% 76,1%   61,45%        55%
Informatifs    34,6% 21,8%        64,7% 38,5%    75,2% 36,8%

TAB . 1 ‚Äì Classification des mots wt par rapports aux 24 concepts Ct de l‚Äôontologie. Les mots
informatifs sont les r√©ponses des champs des formulaires d‚Äôextraction. Les r√©sultats du mod√®le
P (Ct |wt ) sont obtenus en ne consid√©rant que les probabilit√©s P (Ct |wt ) > 0.02. Le r√©sultat du
mod√®le P (Ct |Tt , wt ) est obtenu pour le seuil de confiance optimale Œ¥ = 0.35
de la taille modeste de notre corpus d‚Äôentra√Ænement, nous avons opt√© pour des param√®tres Œ≤1 et
Œ≤2 ind√©pendants du concept. Cependant, la disparit√© de la distribution des concepts (le concept
STATUS √† lui seul repr√©sente 29,5% du corpus d‚Äôentra√Ænement) dans le corpus d‚Äôentra√Ænement
fait que les coefficients Œ≤1 et Œ≤2 sont influenc√©s de mani√®re √† favoriser une meilleure classi-
fication du concept pr√©dominant. Le passage vers un mod√®le o√π les param√®tres d√©pendent du
concept permettrait une meilleure performance.
6       Conclusion

Le rep√©rage de mots informatifs est une t√¢che fondamentale pour plusieurs applications de TAL
tels que l‚Äôextraction d‚Äôinformation. La plupart des approches √©labor√©es pour les textes √©crits
se basent sur l‚Äôutilisation de patrons formul√©s par des r√®gles ou par des mod√®les stochastiques
(Leek, 1997; Riloff, 1998). Dans les deux cas, la structure des phrases pertinentes constitue une
partie importante des connaissances a priori prises en compte dans la d√©finition de la d√©marche
d‚Äôextraction. Ces approches performantes pour les textes √©crits sont inad√©quates pour les textes
oraux qui ne pr√©sentent pas de structures phrastiques r√©guli√®res. Pour pallier ce probl√®me, nous
avons d√©velopp√© une approche bas√©e sur le contenu des mots et sur le th√®me associ√© au contexte
d‚Äô√©nonciation.
Afin d‚Äô√©valuer la performance du syst√®me, nous avons compar√© nos r√©sultats avec ceux obtenus
lors de MUC7 pour la t√¢che d‚Äôextraction des objets6 ‚ÄôTemplate Object‚Äô √† partir de textes √©crits
(MUC, 1998). Le F-score7 obtenu pour les mots informatifs est de 74.65% alors que le meilleur
r√©sultat obtenu lors de MUC7 est de 80%.
Enfin, bien que l‚Äôapproche pr√©sent√©e soit con√ßue pour les textes oraux, celle-ci pr√©sente des
avantages int√©ressant pour les textes √©crits. En particulier, une approche bas√©e sur le contenu
des mots permet un raisonnement sur le sens des mots plut√¥t que sur le mot en tant qu‚Äôunit√©
lexicale. Une telle approche est un atout pour rem√©dier aux variations langagi√®res tr√®s pr√©sentes
dans les textes √©crits. De plus, l‚Äôabsence d‚Äôextra-grammaticalit√©s dans les textes √©crits permet
d‚Äôenvisager un meilleur r√©sultat pour les textes √©crits.

6
Cela correspond √† l‚Äôextraction des objets qui participent aux √©v√®nements. Dans notre cas les √©v√®nements sont
les incidents
7
Le F-score utilis√© pour MUC7 est F = (Œ≤+1)P.R
Œ≤ 2 .P +R et Œ≤ = 0.5
Narj√®s Boufaden, Yoshua Bengio, Guy Lapalme
Remerciements
Nous remercions Robert Parks pour nous avoir donn√© acc√®s √† la version √©lectronique de Word-
smyth ainsi que le Secr√©tariat National de la Recherche et Sauvetage pour les manuels de SAR.
R√©f√©rences
M UC(1998). Proceedings of the seventh Message Understanding Conference (MUC-7). Morgan Kauff-
man.
A BERDEEN J., B URGER J., DAY D., H IRSCHMAN L., PALMER D., ROBINSON P. & V ILAIN M.
(1996). MITRE :Description of the Alembic System as Used in MET. In Proceedings of the TIPSTER
24-Months Workshop.
A PPELT E., H OBBS J., B EAR J., I SRAEL D. & T YSON M. (1993). FASTUS : A Finite-state Processor
for Information Extraction from Real-world Text. In Proceedings of IJCAI, p. 1172‚Äì1178.
B OUFADEN N. (2003). An Ontology-based Semantic Tagger for IE System. In 41st. Annual Meeting of
the Association for Computational Linguistics(ACL) : Student Workshop, p. 7‚Äì14, Sapporo, Japon.
B OUFADEN N., L APALME G. & B ENGIO Y. (2001). Topic Segmentation : A First Stage to Dialog-based
Information Extraction. In Natural Language Processing Rim Symposium, NLPRS‚Äô01, p. 273‚Äì280.
B OUFADEN N., L APALME G. & B ENGIO Y. (2002). D√©coupage th√©matique des conversations : un outil
d‚Äôaide √† l‚Äôextraction. In Actes de Traitement Automatique de la Langue, volume I, p. 377‚Äì382, Nancy,
France.
B ROWN G. & B EORGE Y. (1983). Discourse Analysis. Cambridge Textbooks in Linguistics Series.
Canbridge University Press.
C ARBONELL J., Y IMMING Y., L AFERTY J., R.D B., P IERCE T. & L IU X. (1999). CMU Report on
TDT-2 : Segmentation, Detection and Tracking. In DARPA Broadcast News Workshop.
H EARST M. (1994). Multi-paragraph Segmentation of Expository Text. In 32nd. Annual Meeting of the
Association for Computational Linguistics (ACL), p. 9‚Äì16, New Mexico State University, Las Cruces,
New Mexico.
L EEK T. (1997). Information Extraction Using Hidden Markov Model. Master‚Äôs thesis, University of
California, San Diego, CA.
M ANNING C. D. & S CHUTZE H. (2001). Foundations of Statistical Natural Language Processing,
chapter Word Sense Disambiguiation, p. 294‚Äì303. The MIT Press Cambridge, Massachussets London
England.
M C C ALLUM A., F REITAG D. & P EREIRA F. (2000). Maximum Entropy Markov Models for Informa-
tion Extraction and Segmentation. In Prroceedings of ICML-2000.
R ILOFF E. (1998). Automatically Generating Extraction Patterns from Untagged Text. In Proceedings
of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), p. 1044‚Äì1049.
S HRIBERG E. (1994). Preliminaries to a Theory of Speech Disfluencies. PhD thesis, University of
California at Berkeley.
S ODERLAND S., F ISHER D., A SELTINE J. & W. L. (1995). Crystal : Inducing a Conceptual Dictionary.
In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95), p.
1314‚Äì1319, Menlo Park.
