
Architecture compositionnelle pour les dépendances croiseés

Alexandre D IKOVSKY
LINA-FRE CNRS 2729, Université de Nantes
Alexandre.Dikovsky@univ-nantes.fr
Résumé.         L’article présente les principes généraux sous-jacent aux grammaires catégo-
rielles de dépendances : une classe de grammaires de types récemment proposeé pour une des-
cription compositionnelle et uniforme des dépendances continues et discontinues. Ces gram-
maires très expressives et analyseés en temps polynomial, adoptent naturellement l’architecture
multimodale et expriment les dépendances croiseés illimiteés.
Abstract. This article presents the general principles underlying the categorial depen-
dency grammars : a class of type logical grammars recently introduced as a compositional and
uniform definition of continuous and discontinuous dependences. These grammars are very
expressive, are parsed in a reasonable polynomial time, naturally adopt the multimodal archi-
tecture and explain unlimited cross-serial dependencies.
Mots-clés :            grammaires catégorielles de dépendances, grammaires multimodales, ana-
lyseur syntaxique.

Keywords:              categorial dependency grammars, multimodal grammars, syntactic parser.
1     Introduction

L’intérêt principal des grammaires de types logiques dont les grammaires catégorielles (GC) est
leur lien direct et transparent avec la sémantique formelle compositionnelle. Ce lien est établi
pour une phrase généreé à travers l’isomorphisme entre une preuve de correction du choix des
types pour les mots dans la phrase et l’expession sémantique extraite de cette preuve. Les rela-
tions syntaxiques entre les mots définies par les types sont formaliseés par un calcul logique de
types qui n’est pas spécifique à une grammaire mais à une classe de grammaires. On construit
ainsi des interfaces simples et élégantes entre la syntaxe et la sémantique à la base de principes
plus ou moins universels. Tant que les relations entre les mots (dépendances) s’accordent bien
avec les relations de précédence (ordre des mots), à savoir lorsqu’elles ne dépassent jamais
les limites des domaines syntaxiques l ocaux des mots (dépendances projectives), les preuves
de correction sont isomorphes aux systèmes de constituents des phrases. A ce niveau de re-
présentation syntaxique il est en principe possible de définir les types directement en termes de
dépendances. En fait, les premières définitions des grammaires de dépendances (GD) (Gaifman,
1961) ont été similaires à celle des GC classiques (Bar-Hillel, 1953) 1 . Cependant, il existe dans
1
Or, même à ce niveau, on peut remarquer qu’à la différence des grammaires de types logiques, les GD traitent
les modifieurs comme adjoints.

165
Alexandre D IKOVSKY
toute langue des dépendances non borneés par les domaines locaux (dépendances non projec-
tives). Elles sont dues aux formes et aux mots fonctionnels discontinus (comme les particules
négatives, les pronoms comparatifs, etc.), ou à l’interférence des éléments des structures extra-
syntaxiques telles que la structure communicative (cf. la topicalisation), la co-référence, les
relations de porteé, etc. ou, au contraire, sont dues au manque en surface, des membres des
relations sémantiques (comme c’est le cas de la relativisation ou de l’extraction au cours de
la coordination). Pour y faire face les calculs logiques sont complétés par des règles qui, d’un
côté, rendent les preuves plus flexibles au détriment du lien direct avec les constituents, e.g. en
montant les types (Lambek, 1961; Steedman, 1996), et d’un autre côté, les rendent plus sélec-
tives, e.g. en choisissant les règles structurelles spécifiques en foncion de connecteurs différents
(règles multimodales dues à Oehrle, Morrill, Moortgat et Hepple (Morrill, 1994; Moortgat,
1997)). Avec ces moyens on peut exprimer les dépendances non borneés tout en gardant l’in-
terprétation sémantique compositionnelle. En même temps, à cause de l’expressivité accrue, la
complexité des preuves devient exponentielle, voire pire.
Dans l’article (Dikovsky, 2004), nous avons proposé une nouvelle architecture compositionnelle
de types invariables de dépendances (sans monteé des types). Elle est établie sur la base de la
distinction faite entre les types neutres des dépendances projectives, qui sont formalisés par la
règle classique d’élimination d’arguments, et les types des dépendances non borneés (valences)
dotés de polarisation et d’orientation, qui sont formalisés par une règle appeleé FA (first avai-
lable) de saturation (appariement) des valences. La base psycholinguistique de cette règle est
l’hypothèse que les dépendances non borneés sont géreés par les piles dans la mémoire dyna-
mique d’analyse. FA sélectionne la plus proche valence polariseé duale dans la direction indi-
queé. Elle est conforme avec la majorité des dépendances non projectives dans maintes langues.
On a élaboré différents calculs de dépendances avec la règle FA (Dekhtyar & Dikovsky, 2004;
Dekhtyar & Dikovsky, 2007). Les Grammaires Catégorielles de Dépendances (CDG) corres-
pondantes s’avèrent expressives. En même temps, elles disposent d’algorithmes d’analyse en
temps polynomial. Tout de même, la règle FA n’est pas universelle. Par exemple, elle n’est pas
adapteé aux dépendances croiseés illimiteés du hollandais exposeés dans (Bresnan et al., 1982).
C’est pourquoi, dans cet article nous explorons une autre règle d’appariement FC (first cross)
qui sélectionne la première valence polariseé duale croiseé dans la direction indiqueé. Ainsi, la
structure dynamique de mémoire qui correspond à cette règle est la file d’attente. FC explique
les dépendances croiseés illimiteés en termes d’un langage simple de structures de dépendances
et non en termes du langage de copies, comme d’habitude. A l’instar de grammaires multimo-
dales de types, nous définissons les CDG multimodales (mmCDG) où les règles d’appariement
sont considéreés comme les modes de compositionnalité propres aux dépendances non projec-
tives. Nous montrons que la règle FC est aussi efficace que la règle FA et nous présentons un
algorithme d’analyse syntaxique de ces grammaires en temps polynomial.
2    Grammaires catégorielles de dépendances

Les CDG sont des grammaires catégorielles (GC) qui, à la différence des GC classiques, dé-
finissent explicitement les relations de dépendance entre les mots dans la phrase et non les
relations de dominance entre les constituants. Elles peuvent déterminer les structures de dé-
pendances (SD) plus générales que les arbres de dépendances (AD). Une SD d’une phrase
w = w1 . . . wn est un graphe orienté dont les nœux sont les mots w1 , . . . , wn ordonnés par
l’ordre dans w, avec un nœux sélectionné (la tête) et dont les arcs sont étiquetés par les noms
166
Architecture compositionnelle pour les dépendances croiseés
Figure 1

des dépendances. E.g., la SD en figure 1 est un AD dont la tête (sa racine) est le mot était.
Comme toutes les GC, les CDG n’ont pas de règles. Une CDG peut être vue comme un lexique
qui affecte à chaque mot un ensemble de types de dépendances. La particularité essentielle des
types des CDG est la distinction faite entre les types de dépendances projectives qui relient le
gouverneur à ses subordonnés appartenants à son domaine local, et les types de dépendances
non projectives (non borneés) qui le relient aux subordonnés déplacés vers les domaines des
autres mots. Les premiers sont définis par les sous types arguments des types du gouverneur,
tandis que les derniers sont définis par les valences doteés d’une polarisation et d’une orienta-
tion (gauche / droite) dont l’ensemble constitue pour chaque type son potentiel. Formellement,
les types de dépendances sont construits à partir d’un ensemble C de types primitifs et d’un
ensemble V (C) de valences polariseés. Les éléments de C sont les noms des relations de
dépendance, dont un type sélectionné S (l’axiome). Les valences dans V (C) sont orienteés :
V (C) = V l (C) ∪ V r (C), où V l (C) consiste des valences gauches d (négative), d (posi-
tive) et V r (C) consiste des valences droites d (positive), d (négative) où d ∈ C.
Un type (de dépendance) est une expression αP , où α est un type basique et P est un potentiel.
gCat(C) va noter l’ensemble des types sur C. Les types basiques B(C) sur C sont les types
fonctionnels traditionnels du 1r ordre destinés à définir les dépendances projectives :
1. C ⊂ B(C). 2. Si α ∈ C et β ∈ B(C), alors [α\β], [α∗ \β], [β/α∗], [β/α] ∈ B(C). ✷
Les constructeurs \, / étant supposés associatifs, tout type basique peut être représenté sous la
forme [alm \...\al1 \f /ar1 /.../arn ]. Intuitivement, f est la dépendance du gouverneur et ali , arj
correspondent aux dépendances des subordonnés gauches et droites. d∗ correspond à la dépen-
dance d itéreé. f = S est le type des SD correctes. Les potentiels sont les suites de valences
polariseés. Ils sont destinés à définir les dépendances non projectives. Dans le cas de dépen-
dances projectives, ils sont vides. Les types avec le potentiel vide sont neutres. Par exemple,
l’AD projectif en figure 1 est défini par les types neutres suivants :
au → [c−copul/prepos−a] commencement → [prepos−a] le → [det]
était → [c−copul\S/pred] Verbe → [det\pred]
Les valences       d et     d, d ∈ C, peuvent être vues comme les parenthèses gauches. Res-
pectivement,       d et    d sont les parenthèses droites. Pour une valence gauche, e.g. d, la
valence correspondante (duale) droite, d, est noteé ̆d = d. Ensemble ces valences duales
apparieés définissent la dépendance non projective d. L’adjacence est exprimeé en utilisant les
types primitifs d’ancrage : pour ancrer une valence négative v ∈ { d, d | d ∈ C} (la fin
d’une dépendance non projective), c’est-à-dire la placer auprès d’un mot d’appui, sont utilisés
les types primitifs particuliers d’ancrage : #(v) dont l’élimination signifie l’adjacence des mots
et ne creé aucune dépendance. E.g., l’AD non projectif en figure 2 est défini par
Figure 2
167
Alexandre D IKOVSKY
les types qui ancrent les clitiques la, lui sur l’auxiliaire a :
elle → [pred]                         a → [#( clit−iobj)\#( clit−dobj)\pred\S/aux]
la → [#( clit−dobj)] clit−dobj lui → [#( clit−iobj)] clit−iobj
donneé → [aux] clit−iobj clit−dobj
Le sens exact des types est défini par le calcul de dépendances suivant 2 :
Ll . C P1 [C\β]P2 [β]P1 P2
Il . C P1 [C ∗ \β]P2 [C ∗ \β]P1 P2
Ωl . [C ∗ \β]P [β]P
DlM . αP1 ( C)P ( C)P2 αP1 P P2 , si P1 ( C)P ( C)P2 satisfait la règle d’appariement M.
Ll est la règle classique d’élimination. En éliminant le sous-type argument C = #(α), elle creé
la dépendance projective C et concatène les potentiels. C = #(α) ne creé aucune dépendance.
Il creé k > 0 exemplaires de C. Ωl sert pour le cas k = 0 et pour éliminer le sous-type itéré.
DlM apparie et élimine deux valences duales C et C selon la règle d’appariement M et creé
la dépendance non projective C. Voici deux règles importantes d’appariement :
FAl : P n’a pas d’occurrence de              C,    C (apparier à la plus proche valence duale disponible).
l
FC : P1 et P n’ont pas d’occurrences, respectivement, de C et de                 C (apparier à la premiere
valence duale croiseé, c’est-à-dire à la plus lointaine disponible).
On voit que les valences ressamblent aux traits Slash des GPSG, HPSG, mais à la place de règles
complexes de « propagation »des traits Slash les CDG utilisent les règles simples d’appariement
FA et FC. En admettant que toute dépendance non projective C peut avoir sa propre règle
d’appariement MC nous considérons cette règle comme un mode de compositionnalité à travers
C. Nous obtenons ainsi par analogie avec l’architecture multimodale pour les grammaires de
Lambek (Morrill, 1994; Moortgat, 1997) la notion suivante de grammaire.
Définition 1 Une grammaire catégorielle multimodale de dépendances (mmCDG) est une
structure G = (W, C, S, δ, μ), où W est un vocabulaire, δ (le lexique) est une fonction qui
affecte à chaque mot dans W un sous ensemble fini de types dans gCat(C) et μ est une fonction
qui affecte une règle d’appariement à toute dépendance non projective dans C.
Le calcul de dépendances détermine la relation de prouvabilité correspondante μ sur les suites
de types. La prouvabilité sans règles D (c’est-à-dire, au cas de dépendances projectives) est
noteé c . Pour une SD D et une phrase w, la relation G(D, w) signifie : « D est creéé au cours
d’une preuve Γ μ S pour une suite de types Γ ∈ δ(w) ».
Le langage et le langage des SD générés par G sont respectivement les ensembles L(G)=df {w |
∃D G(D, w)} et ∆(G)=df {D | ∃w G(D, w)}. mmCDGμ et L(mmCDGμ ) sont respective-
ment la famille des grammaires et des langages correspondants.
3           Expressivité des mmCDG
Les mmCDG sont très expressives. Avec la règle FA elles génèrent tous les langages non
contextuels (algébriques), mais aussi maints langages contextuels dont {an bn cn | n > 0}, les
langages L(m) = {an1 an2 ...anm | n ≥ 1} (Dikovsky, 2004) qui sont faiblement contextuels mais
non-TAG à partir de m > 4, le langage M IX, qui contient toutes permutations des motifs
an bn cn , n > 0, M IX = {w ∈ {a, b, c}+ | |w|a = |w|b = |w|c }. Or, selon l’hypothèse de E.
2
Nous exposons les règles gauches. Les règles droites sont symétriques.

168
Architecture compositionnelle pour les dépendances croiseés
Bach, M IX n’est pas faiblement contextuel, ainsi il ne serait pas généré par une grammaire
minimaliste, ou multi-TAG, etc. Dans (Dekhtyar & Dikovsky, 2007) on peut trouver d’autres
exemples et une preuve du fait que L(mmCDGFA ) est une famille abstraite de langages (AFL).
D’un autre côté, nous croyons (Dikovsky, 2004; Dekhtyar & Dikovsky, 2004) que le langage de
copies Lcopy = {ww | w ∈ {a, b}+ }, qui est généré par une grammaire TAG, n’appartient pas
à la famille L(mmCDGFA,FC ). Ce langage est d’un intérêt particulier parce qu’on croit qu’il
est un modèle de la construction en neérlandais dite des « dépendances croiseés illimiteés ».
Il s’agit des phrases n1 n2 . . . nm nm+1 v1 v(inf )2 . . . v(inf )m , dont un exemple est en figure 3, où
pred
il y a une dépendance prédicative n1 ←− v1 entre le verbe v1 en forme finie et le nom n1 ,
pred
les dépendances prédicatives ni ←− v(inf )i entre les verbes v(inf )i à l’infinitif et les noms ni ,
dobj
pour tout 2 ≤ i ≤ m, et éventuellement, une dépendance d’objet direct nm+1 ←− v(inf )m si le
verbe v(inf )m est transitif et le nom nm+1 est présent (c’est-à-dire, nm+1 = ε).

✬                        inf −dobj                                  ✩
pred
✬                                                                        ✩
✬                                         pred                      ✩

✬                                           pred                 ✩
det                         ✎−dobj ☞
inf      inf −dobj ☞inf −dobj ☞
❄        ❄             ❄             ❄        ☎❄                            ❄                   ❄                   ❄
✞                                    ✎          ✎

Jan       P iet       M arie         de      kinderen           zag         helpen              laten              zwemmen
Jan Piet Marie les enfants a vu aider faire nager
Figure 3.

Par ailleurs, une analyse plus approfondie de cette construction (Pulman & Ritchie, 1985)
montre que l’accord des formes existe seulement entre n1 et v1 . Sinon, la forme du nom su-
bordonné est détermineé seulement par le verbe transitif v(inf )m et son argument nm+1 . Cela
implique que le vrai modèle de cette construction n’est point le langage Lcopy , mais le langage
des SD ∆cross = {D(m) | m > 0} sur W = N ∪ V, où N ∩ V = ∅, D(m) est la SD en figure 4
et nil ∈ N, vjr ∈ V. En même temps, le langage correspondant est algébrique (voire linéaire).

✬                  L                                ✩
✬                           L                       ✩
✬                     L                              ✩
R
✗            ✔ ✗   R                   ✔
❄             ❄                       ❄                          ❄ ...                     ❄
D(m) = ni1               ni2           ...    nim               vj1          vj2               ...     vjm

Figure 4. AD D(m)

Le langage ∆cross est généré par la mmCDGFC suivante :

n → [#(L)] L , [#(L)\#(L)] L ,       pour n ∈ N
Gcross =
v → [#(L)\S/R] L , [R/R] L , [R] L , pour v ∈ V

E.g., une preuve de D(3) ∈ ∆cross est montreé en figure 5.
[#(L)] L [#(L)\#(L)]         L
[R/R] L [R]         L

L L
(Ll )                    L                                   L                       L L
(Lr )
[#(L)]                         [#(L)\#(L)]                   [#(L)\S/R]                              [R]
L L L
(Ll )                                        L L L
(Lr )
[#(L)]                                                     [#(L)\S]
L L L L L L
(Ll )
[S]
(DlFC × 3)
[S]

Figure 5.
169
Alexandre D IKOVSKY
4    Fondements théoriques
Notre solution du problème des dépendances croiseés repose sur l’indépendance des types ba-
siques et des valences polariseés dans les preuves du calcul de dépendances. Cette propriété est
exprimeé en termes de projections et de suites de catégories bien apparieés.
Pour une suite de catégories γ ∈ gCat(C)∗ ses projections locale γ l et de valences γ          v   sont
définies ainsi : pour tous α ∈ gCat(C), γ ∈ gCat(C)∗ et C P ∈ gCAT (C),
1. ε l = ε v = ε; αγ l = α            l   γ   l   et αγ    v   = α   v   γ   v
2. C P l = C et C P v = P.
Pour un potentiel P, sa projection P d sur une paire de valences duales vd, vd̆ est définie
comme h(P ) pour l’homomorphisme h(α) = α si α ∈ {vd, vd}     ̆ et h(α) = ε sinon. P est dit
équilibré si toute projection P d est bien apparieé au sens habituel.
Soit |P |x le nombre d’occurrences de x dans P. Alors l’équilibre d’un potentiel P est incrémen-
talement vérifiable en utilisant les quantités suivantes pour toute α ∈ V l (C) et α
̆ ∈ V r (C) :
∆α (P ) = max{|P |α − |P |ᾰ | P est un suffixe de P },
∆ᾰ (P ) = max{|P |ᾰ − |P |α | P est un préfixe de P }.
Elles expriment respectivement le déficit des α−parenthèses droites et gauches dans P (c’est-
à-dire, le nombre de parenthèses droites (gauches) qu’il faut rajouter à P de droite (de gauche)
pour qu’il devienne équilibré. Les propriétés suivantes sont vérifieés (Dekhtyar & Dikovsky,
2004; Dekhtyar & Dikovsky, 2007) :

Lemme 1 1. Quels que soient des potentiels P1 , P2 et des valences α ∈ V l (C), α
̆ ∈ V r (C),
∆α (P1 P2 ) = ∆α (P2 ) + max{∆α (P1 ) − ∆ᾰ (P2 ), 0},
∆ᾰ (P1 P2 ) = ∆ᾰ (P1 ) + max{∆ᾰ (P2 ) − ∆α (P1 ), 0}.
2. Un potentiel P est équilibré ssi               ∆α (P ) = 0.
α∈V (C)
La propriété suivante d’indépendance des projections (Dekhtyar & Dikovsky, 2004; Dekhtyar
& Dikovsky, 2007) garantit l’existence d’un algorithme polynomial d’analyse de mmCDGFA .

Théorème 1 Pour une mmCDG G = (W, C, S, δ, μ) avec le mode FA et x ∈ W + , x ∈ L(G)
ssi il y a une suite Γ ∈ δ(x) telle que Γ l c S et Γ v est équilibré.

Le seul point de sa preuve sensible aux modes est la proposition suivante vraie pour FA :

Lemme 2 Un potentiel P est équilibré ssi pour toute catégorie αP il y a une preuve αP                α
utilisant exclusivement les règles DlM et DrM .

Pour garantir l’indépendance des projections (et par conséquent, une analyse polynomiale) pour
une mmCDGM , il faut prouver ce lemme pour tout mode M ∈ M. En prouvant le lemme 2
pour FC, nous avons étendu le théorème 1 aux mmCDG avec les modes FA, FC :

Théorème 2 Pour x ∈ W + et pour une mmCDGM G = (W, C, S, δ, μ) avec M = {FA},
ou M = {FC} ou M = {FA, FC}, x ∈ L(G) ssi il y a une suite Γ ∈ δ(x) telle que Γ l c S
et Γ v est équilibré.

Corollaire 1 L(mmCDGFA ) = L(mmCDGFC ) = L(mmCDGFA,FC ).
170
Architecture compositionnelle pour les dépendances croiseés
5        Analyse syntaxique, complexité
Dans l’article (Dekhtyar & Dikovsky, 2004) un algorithme d’analyse en temps polynomial a été
décrit pour une version sous commutative du calcul de dépendances 3 . Dans l’article (Dekhtyar
& Dikovsky, 2007) cet algorithme a été étendu aux mmCDGFA . Ce même algorithme à un
détail près s’applique aussi aux mmCDGFA,FC . Nous l’exposons en figure 6.
Fonctions d’échec. Soit une mmCDGM G = (W, C, S, δ, μ) avec les valences polariseés
gauches V l (C) = {v1 , . . . , vp } et droites V r (C) = {̆
v1 , . . . , v̆p }. Nous allons d’abord définir
deux fonctions d’échec qui vont servir pour une optimisation de l’analyse. Soit w = w1 w2 ...wn
∈ W + . Alors, pour 1 ≤ i ≤ n, α ∈ V l (C) et β ∈ V r (C),
π L (α, i) = max{∆α ( Γ v ) | Γ ∈ δ(w1 ...wi )},
π R (β, i) = max{∆β ( Γ v ) | Γ ∈ δ(wn−i+1 ...wn )}
sont les fonction d’échec gauche et droite. On suppose que π L (α, 0) = π R (β, 0) = 0.
Algorithme d’analyse syntaxique. mmCdgPars est un algorithme typique de « program-
mation dynamique ». Il s’applique à une mmCDGM et à une phrase w = w1 w2 ...wn ∈ W + et
remplit une matrice triangulaire M dont la dimension est n × n. L’élément M [i, j], i ≤ j, de M
correspond à l’intervalle wi ...wj de la phrase et représente un ensemble fini d’« items ». Un item
est une expression I = C, ∆L , ∆R , I l , I r qui code une catégorie C P , où C est une catégorie
basique (C ∈ B(C)), ∆L = (∆v1 , . . . , ∆vp ) et ∆R = (∆v̆1 , . . . , ∆v̆p ) sont les vecteurs entiers
dont chaque composante i correspond à la valence vi , respectivement v̆i , et vaut le déficit cor-
respondant des vi -parenthèses droites (gauches) dans le potentiel P. Finalement, I l , I r sont les
identificateurs des items dans les angles gauches et droites de M à partir desquelles est calculé
l’item I (pour tout I ∈ M [i, i] I l = I r = ∅).
Complexité. Pour une mmCDGM G = (W, C, S, δ, μ), soit lG = |δ| le nombre d’affectations
des catégories aux mots dans le lexique, soit aG = max{k | ∃x ∈ W ([αk \...\α1 \C/β]P ∈
δ(x) ∨ [β\C/α1 /.../αk ]P ∈ δ(x))} le nombre maximal de sous types arguments dans les
catégories affecteés, soit pG = |V l (C)| = |V r (C)| le nombre de valences polariseés et ∆G =
max{∆α (P ) | ∃x ∈ W (C P ∈ δ(x) ∨ α ∈ V (C))} le déficit maximal des valences parenthèses
dans les catégories affecteés. Finalement, soit n la longueur de la phrase analyseé.
Théorème 3 L’algorithme mmCdgPars a une complexité en temps O(lG ·a2G ·(∆G ·n)2pG ·n3 ).

Remarque 1 1. Pour une grammaire fixeé G, les valeurs lG , aG , pG et ∆G sont constantes. Si
G varie, alors le problème d’appartenance devient N P -complèt (Dekhtyar & Dikovsky, 2004).
2. Si G est sans valence polariseé, alors la complexité est O(n3 ).
3. Soit le déficit maximal de valences σG (n) des potentiels survenants dans les preuves des
phrases dont la longueur est limiteé par n. Si σG (n) est borneé par une constante c, alors G
peut être transformeé en une mmCDG G sans valence polariseé dont le langage est algébrique
(Dikovsky, 2001). Or, la taille de G est exponentielle par rapport à G. Si, de plus, le nombre des
dépendances non borneés dans une SD engendreé par G n’est jamais supérieur à une borne
constante uniforme (ce qui est typique pour maintes langues), alors la complexité est O(n3 )
pour la même grammaire G.
4. D’un autre côté, même si toute dépendance de G (sauf S) était définie par une valence
polariseé, la complexité serait toujours polynomiale. Cette remarque explique que les mmCDG
sont bien adapteés aux langages avec l’ordre flexible. Les limites de cet article ne nous laissent
pas faire une analyse plus détailleé de ce cas important.
3
L’algorithme a été réalisé en LISP par Darin et Hristian Todorov et en en C# par Ilya Zaytsev.

171
Alexandre D IKOVSKY
Algorithme mmCdgPars
//Entreé : mmCDG G, phrase w = w1 ...wn                                          //For 1 ≤ i ≤ n
//Sortie : “succ`   es”, DS D ssi w ∈ L(G)                                       Propose( i )
{                                                                                {
CalcFailFuncL() ;                                                                (loop) foreach (C P ∈ δ(wi )
CalcFailFuncR() ;                                                                {
for (k = 1, . . . , n)                                                               foreach (v ∈ V l (C))
{                                                                                    {
Propose( k )                                                                         ∆L [v] := ∆v (P ) ;
}                                                                                         if (∆L [v] > π R [̆ v , n − j]) next (loop) ;
for (l = 2, . . . , n)                                                                    ∆R [̆v ] := ∆v̆(P ) ;
{                                                                                          if (∆R [̆v ] > π L [v, i − 1]) next (loop) ;
for (i = 1, . . . , n − l)                                                      }
{                                                                               AddItem( M [i, i], C, ∆L , ∆R , ∅, ∅ ) ;
j := i + l − 1;                                                       }
for (k = i, . . . , j − l)                                         }
SubordinateL(i, k, j) ;                                     AddItem( M [i, j], C, ∆L , ∆R , I l , I r )
SubordinateR(i, k, j) ;                                     {
}                                                                    M [i, j] := M [i, j] ∪ { C, ∆L , ∆R , I l , I r } ;
}                                                                          if (C = [C ∗ \β])
}                                                                                {
if (I = S, (0, 0, . . . , 0), (0, 0, . . . , 0), I l , I r ∈ M [1, n])                AddItem( M [i, j], [β], ∆L , ∆R , I l , I r ) ;
return “succ`     es”, Expand(I) ;                                         }
//procedure Expand( I ) calcule la SD de sortie.                                 if (C = [β/C ∗])
//Elle seule est sensible aux règles d’appariement                               {
//FA,FC. Elle est technique et n’est pas incluse                                      AddItem( M [i, j], [β], ∆L , ∆R , I l , I r ) ;
else                                                                             }
return “́   echec”, ∅ ;                                                  }
//For 1 ≤ i ≤ k ≤ j ≤ n
SubordinateL( i, k, j )
CalcFailFuncL()                                                                 (loop) foreach (I1 = α1 , ∆L1 , ∆R            l    r
1 , I1 , I1 ∈ M [i, k],
{                                                                                              I2 = α2 , ∆L2 , ∆R         l   r
2 , I2 , I2 ∈ M [k + 1, j])
foreach (v ∈ V l (C))                                                         {
{                                                                                 foreach (v ∈ V l (C))
π L [v, 0] := 0;                                                              {
for (i = 1, . . . , n)                                                              ∆L [v] := ∆L2 (v) + max{∆L1 (v) − ∆R           2 (v), 0} ;
{                                                                                   if (∆L [v] > π R [̆ v , n − j]) next (loop) ;
πmax := 0;                                                                    ∆R [̆v ] := ∆R    v ) + max{∆R
1 (̆                 2 (̆v ) − ∆L1 (̆
v ), 0} ;
foreach (C P ∈ δ(wi ))                                                        if (∆R [̆v ] > π L [v, i − 1]) next (loop) ;
{                                                                       }
πmax := max{πmax , ∆v (P )+                                       if ( α1 = C and α2 = [C\β] )
max{π L [v, i − 1] − ∆v̆(P ), 0}};                         {
}                                                                             AddItem( M [i, j], [β], ∆L , ∆R , I1 , I2 ) ;
π L [v, i] := πmax ;                                                    }
}                                                                             elseif ( (α1 = C and α2 = [C ∗ \β]) or α1 = [ε] )
}                                                                                 {
}                                                                                         AddItem( M [i, j], α2 , ∆L , ∆R , I1 , I2 ) ;
CalcFailFuncR() est similaire.                                                 }

SubordinateR( i, k, j ) est similaire.
Figure 6. Algorithme mmCdgPars

172
Architecture compositionnelle pour les dépendances croiseés
6    Comparaison, discussion
Certes, il y a des grammaires où l’expression des dépendances non borneés ne pose pas pro-
blème, e.g. HPSG (Pollard & Sag, 1988), les extensions multimodales des grammaires de Lam-
bek (Morrill, 1994; Moortgat, 1997), dont certaines visent notamment les dépendances (Kruijff,
2001) et leur fournissent une interface compositionnelle avec la sémantique. Or, l’analyse avec
ces formalismes expressifs est très complexe et parfois nécessite l’utilisation des systèmes de
démonstration des théorèmes. C’est aussi le cas des grammaires qui représentent P T IM E,
dont RCG (Boullier, 2003). A la différence de mmCDG, ces grammaires n’ont pas d’algo-
rithme universel d’analyse en temps O(nk ), où k dépend de l’alphabet. Cela concerne aussi les
grammaires baseés sur l’unification et les contraintes, e.g. (Duchier, 1999). Contrairement à ces
formalismes, les mmCDG n’utilisent que les moyens primitifs d’une complexité faible. E.g.,
les Grammaires Topologiques de Dépendances (Duchier & Debusmann, 2001) (voir aussi (Brö-
ker, 1998; Duchier et al., 2004)) utilisent les hierarchies des domaines de l’ordre des mots
(WO-domains) qui, en cas de discontinuité, servent à exprimer les contraintes de contiguïté,
de distance entre un gouverneur et son modifieur etc. Dans beaucoup des cas, ces contraintes
sont exprimeés dans mmCDG par le moyen de sous types d’ancrage placés dans les positions
correspondantes d’un type du gouverneur.
Les mmCDG représentent une alternative intéressante aux TAG (et équivalentes : CCG, HG
(Vijay-Shanker & Weir, 1994)) et aux grammaires faiblement contextuelles (Joshi et al., 1991),
telles multi-TAG, non contextuelles multi-composantes, minimalistes, etc. Tout comme ces der-
nières, les mmCDG disposent d’une analyse syntaxique en temps polynomial. On peut même
constater, qu’en pratique l’algorithme mmCdgPars va avoir une complexité O(n3 ). Leur avan-
tage décisif est l’architecture compositionnelle de dépendances où toutes les dépendances, pro-
jectives comme non borneés, sont définies par les types fonctionnels, ce qui creé la base né-
cessaire pour une sémantique fonctionnelle de dépendances. En même temps, cette architecture
adopte naturellement la multimodalité des dépendances non borneés correspondant aux règles
de saturation des valences spécifiques aux différentes langues. Il est important de noter que cette
flexibilité syntaxique est atteinte sans explosion du coût de l’analyse syntaxique (par contraste
avec les grammaires de Lambek). Malgré leur simplicité, les mmCDG sont très expressives.
On a vu que pour exprimer les dépendances croiseés illimiteés on n’a pas besoin du langage de
copies, mais d’un langage des SD facilement exprimé par les mmCDG. Et le fait que M IX est
un langage mmCDGFA montre que ces grammaires sont adapteés aux langues naturelles avec
l’ordre des mots flexible.
Enfin, il est difficile de comparer les mmCDG par l’expressivité avec les autres GD qui traitent
les dépendances non borneés et qui les analysent en temps polynomial, e.g. (Kahane et al.,
1998; Bröker, 2000). Le pouvoir de ces grammaires n’est pas détermineé. Leurs définitions
sont opérationnelles (cf. le « lifting »). L’avantage des mmCDG est leur transparence et leur
architecture compositionnelle de dépendances.
Références
BAR -H ILLEL Y. (1953). A quasi-arithmetical notation for syntactic description. Language,
29(1), 47–58.
B OULLIER P. (2003). Counting with range concatenation grammars. Theoretical Computer
Science, 293, 391–416.
173
Alexandre D IKOVSKY
B RESNAN J., K APLAN R., P ETERS S. & Z AENEN A. (1982). Cross-serial dependencies in
dutch. Linguistic Inquiry, 13(4), 613–635.
B RÖKER N. (1998). Separating surface order and syntactic relations in a dependency gram-
mar. In Proc. COLING-ACL, p. 174–180, Montreal.
B RÖKER N. (2000). Unordered and non-projective dependency grammars. Traitement Auto-
matique des Langues (TAL), 41(1), 245–272.
D EKHTYAR M. & D IKOVSKY A. (2004). Categorial dependency grammars. In M. M OORT-
GAT & V. P RINCE, Eds., Proc. of Intern. Conf. on Categorial Grammars, p. 76–91.
D EKHTYAR M. & D IKOVSKY A. (2007). Generalized categorial dependency gram-
mars. In submission, www.sciences.univ-nantes.fr/info/perso/permanents/
dikovsky/.
D IKOVSKY A. (2001). Polarized non-projective dependency grammars. In P. DE G ROOTE , G. M ORILL
& C. R ETORÉ, Eds., Proc. of the Fourth Intern. Conf. on Logical Aspects of Computational Linguistics,
volume 2099 of LNAI, p. 139–157 : Springer.
D IKOVSKY A. (2004). Dependencies as categories. In “Recent Advances in Dependency Grammars".
COLING’04 Workshop, p. 90–97.
D UCHIER D. (1999). Axiomatizing dependency parsing using set constraints. In Sixth Meeting on
Mathematics of Language (MOL-6), p. 115–126, Orlando, Florida.
D UCHIER D. & D EBUSMANN R. (2001). Topological dependency trees : A constraint-based account
of linear precedence. In Proc. of the Intern. Conf. ACL’2001, p. 180–187 : ACL & Morgan Kaufman.
D UCHIER D., D EBUSMANN R. & K RUIJFF G.-J. M. (2004). Extensible dependency grammar : A
new methodology. In COLING’04 Workshop, p. 78–84, Geneva.
G AIFMAN H. (1961). Dependency systems and phrase structure systems. Report p-2315, RAND Corp.
Santa Monica (CA). Published in Information and Control, 1965, v. 8, n ◦ 3, pp. 304-337.
J OSHI A. K., S HANKER V. K. & W EIR D. J. (1991). The convergence of mildly context-sensitive
grammar formalisms. In P. S ELLS , S. S HIEBER & T. WASOW, Eds., Foundational issues in natural
language processing, p. 31–81, Cambridge, MA : MIT Press.
K AHANE S., NASR A. & R AMBOW O. (1998). Pseudo-projectivity : A polynomially parsable non-
projective dependency grammar. In Proc. COLING-ACL, p. 646–652, Montreal.
K RUIJFF G.-J. M. (2001). A Categorial-Modal Logical Architecture of Informativity : Dependency
Grammar Logic & Information Structure. PhD thesis, Charles University, Prague.
L AMBEK J. (1961). On the calculus of syntactic types. In R. JAKOBSON, Ed., Structure of languages
and its mathematical aspects, p. 166–178. Providence RI : American Mathematical Society.
M OORTGAT M. (1997). Categorial type logics. In J. VAN B ENTHEM & A. TER M EULEN, Eds.,
Handbook of Logic and Language, chapter 2, p. 93–177. Elsevier, The MIT Press.
M ORRILL G. V. (1994). Type Logical Grammar. Categorial Logic of Signs. Kluwer.
P OLLARD C. & S AG I. (1988). An Information Based Approach to Syntax and Semantics, Part I.
Stanford, California : CSLI.
P ULMAN S. & R ITCHIE G. (1985). Indexed grammars and interesting dependencies. UEA Papers in
Linguistics, 23, 21–38.
M. S TEEDMAN, Ed. (1996). Surface Structure and Interpretation. The MIT Press.
V IJAY-S HANKER K. & W EIR D. (1994). The equivalence of four extensions of context-free grammars.
Mathematical Systems Theory, 27, 511–545.
174
