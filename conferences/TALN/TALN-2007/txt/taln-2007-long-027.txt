
Les vecteurs conceptuels, un outil complÃ©mentaire
aux rÃ©seaux lexicaux

Didier S CHWAB1 , Lim L IAN T ZE1 , Mathieu L AFOURCADE2
1
Computer-Aided Translation Unit (UTMK)
School of Computer Sciences, Universiti Sains Malaysia
Penang, Malaysia
2
TAL-LIRMM, UniversitÃ© Montpellier II â€“ CNRS
161 rue ada, 34392 Montpellier Cedex 5, France
{didier,liantze}@cs.usm.my, lafourcade@lirmm.fr
RÃ©sumÃ©. FrÃ©quemment utilisÃ©s dans le Traitement Automatique des Langues Naturelles,
les rÃ©seaux lexicaux font aujourdâ€™hui lâ€™objet de nombreuses recherches. La plupart dâ€™entre eux,
et en particulier le plus cÃ©lÃ¨bre WordNet, souffrent du manque dâ€™informations syntagmatiques
mais aussi dâ€™informations thÃ©matiques (Â« problÃ¨me du tennis Â»). Cet article prÃ©sente les vec-
teurs conceptuels qui permettent de reprÃ©senter les idÃ©es contenues dans un segment textuel
quelconque et permettent dâ€™obtenir une vision continue des thÃ©matiques utilisÃ©es grÃ¢ce aux
distances calculables entre eux. Nous montrons leurs caractÃ©ristiques et en quoi ils sont com-
plÃ©mentaires des rÃ©seaux lexico-sÃ©mantiques. Nous illustrons ce propos par lâ€™enrichissement
des donnÃ©es de WordNet par des vecteurs conceptuels construits par Ã©mergence.
Abstract. There is currently much research in natural language processing focusing on
lexical networks. Most of them, in particular the most famous, WordNet, lack syntagmatic infor-
mation and but also thematic information (Â« Tennis Problem Â»). This article describes conceptual
vectors that allows the representation of ideas in any textual segment and offers a continuous
vision of related thematics, based on the distances between these thematics. We show the cha-
racteristics of conceptual vectors and explain how they complement lexico-semantic networks.
We illustrate this purpose by adding conceptual vectors to WordNet by emergence.
Mots-clÃ©s :        WordNet, vecteurs conceptuels, informations lexicales, informations thÃ©ma-
tiques.

Keywords:          WordNet, conceptual vectors, lexical information, thematic information.
1    Introduction
Originellement issus des travaux de Ross Quillian sur la psycholinguistique Ã  la fin des annÃ©es
60 (Quillian, 1968), les rÃ©seaux lexicaux sont toujours aujourdâ€™hui au centre des recherches en
Traitement Automatique des Langues Naturelles. Ils sont utilisÃ©s dans de nombreuses tÃ¢ches
(dÃ©sambiguisation lexicale (Mihalcea et al., 2004)) ou applications du domaine (traduction au-
tomatique avec les rÃ©seaux multilingues comme Papillon (Mangeot-Lerebours et al., 2003) ou
293
Didier S CHWAB, Lim L IAN T ZE, Mathieu L AFOURCADE
(Knight & Luk, 1994), recherche dâ€™informations ou classification de textes (Harabagiu & Chai,
1998)). La plupart de ces rÃ©seaux, et spÃ©cifiquement le plus cÃ©lÃ¨bre dâ€™entre eux WordNet (Fell-
baum, 1988), souffrent du manque dâ€™informations syntagmatiques mais aussi dâ€™informations
concernant le domaine dâ€™usage des termes ou du moins les termes thÃ©matiquement associÃ©s.
Il nâ€™y a ainsi aucune relation directe entre des termes comme teacher - student ( enseignant -
Ã©tudiant ) et boat - port ( bateau - port ). Ce phÃ©nomÃ¨ne a Ã©tÃ© nommÃ© Â« ProblÃ¨me du tennis Â»
[(Fellbaum, 1988), p. 10] lorsquâ€™il a Ã©tÃ© remarquÃ© quâ€™il fallait chercher les Ã©quivalents de balle ,
raquette et court Ã  diffÃ©rents endroits de la hiÃ©rarchie.
Depuis quelques annÃ©es, lâ€™Ã©quipe de traitement automatique des langues (TAL) du LIRMM
(Laboratoire dâ€™Informatique, de Robotique et de MicroÃ©lectronique de Montpellier) travaille
sur une formalisation de la projection de la notion linguistique de champ sÃ©mantique dans un
espace vectoriel, les vecteurs conceptuels. Ils permettent de reprÃ©senter les idÃ©es contenues dans
un segment textuel quelconque et permettent dâ€™obtenir une vision continue des thÃ©matiques
utilisÃ©es grÃ¢ce aux distances calculables entre eux.
Dans cet article, nous prÃ©sentons les vecteurs conceptuels et en particulier leur version Ã©mer-
gente. Nous montrons leurs caractÃ©ristiques et en quoi ils sont complÃ©mentaires des rÃ©seaux
lexico-sÃ©mantiques. Nous illustrons ce propos par une expÃ©rience menÃ©e Ã  Penang en Malaisie
qui a consistÃ© Ã  enrichir les donnÃ©es de WordNet de vecteurs conceptuels par Ã©mergence.
2    RÃ©seaux lexico-sÃ©mantique : lâ€™exemple de WordNet

Principe et lacunes. WordNet est une base de donnÃ©es lexicale pour lâ€™anglais dÃ©veloppÃ©e sous
la direction de George Armitage Miller par le Cognitive Science Laboratory de lâ€™universitÃ© de
Princeton (Ã‰tats-Unis dâ€™AmÃ©rique). Il se veut reprÃ©sentatif du fonctionnement de lâ€™accÃ¨s au
lexique mental humain.
WordNet est organisÃ© en ensembles de synonymes appelÃ©s synsets. Ã€ chaque synset correspond
un concept. Le sens des termes est dÃ©crit dans WordNet par trois moyens : (1) leur dÃ©finition ;
(2) le synset auquel ce sens est rattachÃ© ; (3) les relations lexicales qui unissent entre eux les
synsets. On trouve parmi ces relations, lâ€™hyperonymie, la mÃ©ronymie et lâ€™antonymie.
La version 2 de WordNet compte 152059 termes ce qui constitue une couverture relativement
large de la langue anglaise. Dans les premiÃ¨res versions de WordNet, les relations lexicales ne
connectent que les termes de mÃªme morphologie. Il y a donc une hiÃ©rarchie pour les noms, une
pour les adjectifs, une pour les verbes et enfin une derniÃ¨re pour les adverbes.
Dans (Harabagiu et al., 1999), les auteurs de WordNet (alors Ã  sa version 1.6) relÃ¨vent six
faiblesses dans la construction de leur rÃ©seau : (1) le manque de liens entre les hiÃ©rarchies ;
(2) le nombre limitÃ© de relations entre termes traitant du mÃªme sujet ; (3) le manque de relations
morphologiques ; (4) lâ€™absence de relations thÃ©matiques ; (5) lâ€™absence de certains sens de mots ;
(6) le manque dâ€™uniformisation et de cohÃ©rence dans les dÃ©finitions. Si les points 3, 5 et 6 ne
nous intÃ©ressent pas dans cet article, nous allons montrer lâ€™apport des vecteurs conceptuels pour
la rÃ©solution des autres, tous trois formant le problÃ¨me du tennis.
ExpÃ©riences cherchant Ã  rÃ©soudre le problÃ¨me du tennis. Dans cet article, nous nous intÃ©-
resserons uniquement Ã  la version 2.1 de WordNet qui Ã©tait la derniÃ¨re disponible au moment
294
ComplÃ©mentaritÃ© des rÃ©seaux lexicaux et des vecteurs conceptuels
oÃ¹ nous avons rÃ©alisÃ© nos expÃ©riences. Une nouvelle version (3.0) est sortie en DÃ©cembre 2006
mais elle ne semble pas comporter de rÃ©elles amÃ©liorations par rapport Ã  la version prÃ©cÃ©dente
pour ce qui nous intÃ©resse ici.
Depuis la version 2, des relations comme derivationally related form (formes dÃ©rivationnelles)
permettent de lier des adjectifs Ã  des verbes ou des adjectifs Ã  des noms. De mÃªme, les syn-
sets peuvent se voir attribuer un domaine dâ€™usage. Toutefois, ces donnÃ©es semblent encore
en nombre trop restreint pour Ãªtre suffisamment pertinentes. Des relations typiques comme
teacher - student ( enseignant - Ã©tudiant ) boat - port ( bateau - port ) ou doctor - hospital ( doc-
teur - hÃ´pital ), pourtant souvent indispensables Ã  une tÃ¢che de dÃ©sambiguÃ¯sation lexicale, ne sâ€™y
trouvent toujours pas et le nombre restreint dâ€™indications thÃ©matiques comme lâ€™est le domaine
ne permet pas de compenser ce dÃ©faut. Plusieurs solutions ont Ã©tÃ© proposÃ©es pour rÃ©soudre tout
ou partie de ce problÃ¨me.
Avec eXtended WordNet, (Harabagiu et al., 1999) propose de dÃ©sambiguÃ¯ser lâ€™ensemble des
dÃ©finitions de WordNet de faÃ§on semi-automatique. Lâ€™idÃ©e est, pour chaque dÃ©finition, de dire
quel est le sens utilisÃ© pour chacun des termes. On peut ensuite comparer deux synsets et Ã©valuer
leur similaritÃ©. Nous verrons que nous utilisons ces informations pour fabriquer les vecteurs
conceptuels de cette expÃ©rience. Dâ€™autres eux aussi rajoutent des informations aux synsets.
Ainsi, (Agirre et al., 2001) ajoutent des signatures lexicales issues de corpus taggÃ©s ou du Web.
En revanche, dâ€™autres cherchent plutÃ´t Ã  augmenter le nombre dâ€™arcs existants. (Stevenson,
2002), par exemple, combine diffÃ©rentes mÃ©triques pour crÃ©er des arcs entre synsets Ã  partir de
leur dÃ©finition et dâ€™un thÃ©saurus. (Ferret & Zock, 2006) utilisent eux un rÃ©seau de coocurrences
pour extraire des relations typiques comme celles prÃ©sentÃ©es dans un paragraphe prÃ©cÃ©dent.
On le voit, toutes ses propositions ont en commun dâ€™appartenir en particulier au domaine du
discret. La nÃ´tre est dâ€™introduire une reprÃ©sentation continue des idÃ©es contenues dans le rÃ©seau,
les vecteurs conceptuels.
3        Les vecteurs Conceptuels
Nous prÃ©sentons ici les points fondamentaux Ã  comprendre sur les vecteurs conceptuels. Nous
revenons sur le mode de construction classique des vecteurs conceptuels, câ€™est-Ã -dire tels quâ€™ils
ont Ã©tÃ© Ã©tudiÃ©s au LIRMM depuis 19971 , Ã  partir dâ€™un ensemble de concepts choisis a priori.
Nous expliquons dans cette partie certaines notions de base qui nous seront utiles pour prÃ©senter
ensuite la construction par Ã©mergence, câ€™est Ã  dire sans concepts prÃ©dÃ©finis.
Principe GÃ©nÃ©raux. Nous reprÃ©sentons les aspects thÃ©matiques des segments textuels (do-
cuments, paragraphes, syntagmes, etc.) par des vecteurs conceptuels, une formalisation de la
projection de la notion linguistique de champ sÃ©mantique dans un espace vectoriel. Ã€ partir
dâ€™un ensemble de notions Ã©lÃ©mentaires dont nous faisons lâ€™hypothÃ¨se, les concepts2 , il est pos-
sible de construire des vecteurs dont chaque composante correspond Ã  un concept et est positive.
Par exemple, le vecteur de lâ€™item lexical vie , qui fusionne tous les sens de vie , peut Ãªtre pro-
jetÃ© sur les concepts suivants (les CONCEPT intensitÃ© sont ordonnÃ©s par valeurs dÃ©croissantes de
lâ€™intensitÃ©) : V vie = (VIE 0.7 , NAISSANCE 0.48 , ENFANCE 0.46 , MORT 0.43 , VIEILLESSE 0.41 , . . .).
1
Voir les articles de lâ€™Ã©quipe dans les prÃ©cÃ©dentes Ã©ditions de cette confÃ©rence ou (Schwab, 2005).
2
Dans notre expÃ©rimentation sur le franÃ§ais nous utilisons (Larousse, 1992) qui dÃ©fini 873 concepts.

295
Didier S CHWAB, Lim L IAN T ZE, Mathieu L AFOURCADE
La construction des vecteurs conceptuels se fait Ã  partir de dÃ©finitions extraites de diverses
sources (dictionnaires, listes de synonymes, indexations manuelles, ...). Cette mÃ©thode dâ€™ana-
lyse construit, Ã  partir de vecteurs conceptuels dÃ©jÃ  existants et de nouvelles dÃ©finitions, de
nouveaux vecteurs.
Distance angulaire. La comparaison entre deux vecteurs se fait grÃ¢ce Ã  la distance angulaire
DA . Pour deux vecteurs conceptuels A et B, DA (A, B) = arccos(Sim(A, B)) oÃ¹ Sim est
Sim(X, Y ) = cos(X, Y ) = XXÂ·Y   Ã— Y
. Intuitivement, cette fonction constitue une Ã©valuation de
la proximitÃ© thÃ©matique et en pratique la mesure de lâ€™angle entre les deux vecteurs. Empirique-
ment, nous estimons que pour une distance DA (X, Y ) â‰¤ Ï€4 (45â—¦ ), X et Y sont thÃ©matiquement
proches et partagent plusieurs concepts. Pour DA (X, Y ) â‰¥ Ï€4 , la proximitÃ© thÃ©matique est consi-
dÃ©rÃ©e comme faible et aux alentours de Ï€2 (90â—¦ ), X et Y nâ€™ont aucune relation. Nous obtenons,
par exemple, les angles suivants :
DA (V( fourmilier ), V( fourmilier ))=0 (0â—¦ )   DA (V( fourmilier ), V( mammifÃ¨re ))=0.36 (21â—¦ )
DA (V( fourmilier ), V( animal ))=0.45 (26â—¦ )   DA (V( fourmilier ), V( quadrupÃ¨de ))=0,42 (24â—¦ )
DA (V( fourmilier ), V( train ))=1.18 (68â—¦ )    DA (V( fourmilier ), V( fourmi ))=0,26 (15â—¦ )
Le premier rÃ©sultat a une interprÃ©tation directe, fourmilier ne peut Ãªtre plus proche dâ€™autre
chose que de lui mÃªme. Le fait quâ€™un fourmilier soit un mammifÃ¨re explique le deuxiÃ¨me
rÃ©sultat. Un fourmilier nâ€™a que peu de rapport avec un train ce qui explique lâ€™angle plus im-
portant. Dans le dernier exemple, lâ€™angle peu important entre fourmilier et fourmi se comprend
si on se rappelle que DA est une distance thÃ©matique et non une distance ontologique. Lâ€™examen
de la dÃ©finition de fourmilier, Â« mammifÃ¨re qui se nourrit de fourmis Â», explique le rÃ©sultat.
Le voisinage thÃ©matique, une vision continue de la thÃ©matique. La fonction de voisinage
thÃ©matique permet de connaÃ®tre les items lexicaux voisins dâ€™un item lexical donnÃ©. On dÃ©finit V
la fonction de voisinage qui renvoie les k items les plus proches en termes de distance angulaire
DA dâ€™un texte Z dans une base vectorielle. Soit
|V(DA , Z, k)| = k      âˆ€X âˆˆ V(DA , Z, k), âˆ€Y âˆˆ      / V(DA , Z, k), DA (X, Z) â‰¤ DA (Y, Z)
Par exemple, les 7 termes proches et ordonnÃ©s par distance thÃ©matique croissante du nom mort
peuvent Ãªtre :
V(DA , mort , 7) = ( mort 0) ( meurtre 0.367) ( tueur 0.377) ( Ã¢ge de la vie 0.481) ( tyrannicide
0.516) ( tuer 0.579) ( mort :adj 0.582)
La mÃ©thode de voisinage peut Ãªtre utilisÃ©e lors de lâ€™apprentissage des vecteurs conceptuels pour
vÃ©rifier la cohÃ©rence globale de la base ou en phase dâ€™exploitation pour trouver le meilleur mot
Ã  utiliser dans un Ã©noncÃ©. Ainsi, elle constitue un nouvel outil pour accÃ©der aux mots et Ã  leur
sens, complÃ©mentaire Ã  ceux dÃ©crits dans (Zock, 2002) comme la forme, la morphologie ou la
navigation dans un grand rÃ©seau lexical. La fonction de voisinage permet ainsi une navigation
dans le domaine du continu contrairement aux rÃ©seaux sÃ©mantiques qui ne permettent quâ€™une
navigation discrÃ¨te.
Somme vectorielle. Soient X et Y deux vecteurs, leur somme vectorielle normÃ©e V est dÃ©finie
par : Ï‘2 â†’ Ï‘ : V = X âŠ• Y            | Vi = XX+Y
i +Yi
oÃ¹ Ï‘ est lâ€™ensemble des vecteurs conceptuels,
Vi (resp Xi , Yi ) reprÃ©sente la i-Ã¨me composante du vecteur V (resp. X, Y).
La somme vectorielle normÃ©e de deux vecteurs donne un vecteur Ã©quidistant en termes dâ€™angle
des deux premiers vecteurs. Il sâ€™agit en fait dâ€™une moyenne des vecteurs sommÃ©s. En tant
296
ComplÃ©mentaritÃ© des rÃ©seaux lexicaux et des vecteurs conceptuels
quâ€™opÃ©ration sur les vecteurs conceptuels, on peut donc voir la somme vectorielle normÃ©e
comme lâ€™union des idÃ©es contenues dans les termes.
Soient X et Y deux vecteurs, leur produit terme Ã  terme normalisÃ© V est dÃ©fini par : Ï‘2 â†’
Ï‘ : V = XâŠ—Y            | vi = xi yi Lâ€™opÃ©rateur âŠ— peut Ãªtre interprÃ©tÃ© comme un opÃ©rateur
dâ€™intersection entre vecteurs. Si lâ€™intersection entre deux vecteurs est le vecteur nul, alors ils
nâ€™ont rien en commun. Du point de vue des vecteurs conceptuels, cette opÃ©ration permet donc
de sÃ©lectionner les idÃ©es communes Ã  un ensemble de termes.
Construction des vecteurs par Ã©mergence. Lâ€™approche par Ã©mergence sâ€™affranchit de tout
thÃ©saurus et vecteurs de concept comme base de dÃ©part. Seule d la taille du vecteur est fixÃ©e
a priori. Le mode de construction des vecteurs est identique au modÃ¨le classique Ã  la diffÃ©-
rence que si un des vecteurs entrant dans la somme est inexistant, car non encore calculÃ©, alors
ce vecteur est tirÃ© au hasard. Le processus de calcul est itÃ©rÃ© jusquâ€™Ã  convergence de chaque
vecteur.
Comme nous le montrons de faÃ§on plus dÃ©taillÃ©e dans (Lafourcade, 2006), il y a un certain
nombre dâ€™avantages Ã  utiliser ce modÃ¨le. Le premier dâ€™entre eux est de pouvoir choisir libre-
ment la quantitÃ© de ressources que lâ€™on souhaite utiliser en choisissant la taille des vecteurs de
faÃ§on appropriÃ©e. Pour donner une idÃ©e de lâ€™importance de ce choix, une base de 500000 vec-
teurs de dimension 1000 fait environ 2Go, de taille 2000, 4Go, . . . Comme il ne serait pas alors
ni raisonnable ni facile de dÃ©finir une jeu de concept de la taille choisie, autant chercher une ap-
proche nous permettant de nous en passer. De plus, ce qui peut sembler un pis-aller ou au mieux
un compromis, sâ€™avÃ¨re un avantage car la densitÃ© lexicale dans lâ€™espace des mots calculÃ©s par
Ã©mergence est bien plus constante que dans un espace oÃ¹ les concepts sont prÃ©calculÃ©s. En effet,
les ressources (les dimensions de lâ€™espace) ont tendance Ã  Ãªtre harmonieusement distribuÃ©es en
fonction de la richesse lexicale.
4     ModÃ©lisation hybride du sens : vecteurs conceptuels et rÃ©-
seaux lexicaux

4.1    Apport des rÃ©seaux lexicaux aux vecteurs conceptuels

Les distances utilisÃ©es sur les vecteurs, comme le montre (BesanÃ§on, 2001), mettent en exergue
les composantes communes et/ou les composantes distinctes. Si nous utilisons en particulier
la distance angulaire, câ€™est que ses caractÃ©ristiques mathÃ©matiques, sa simplicitÃ© Ã  comprendre
et Ã  interprÃ©ter linguistiquement ainsi que son efficacitÃ© en termes de temps de calcul en font
un bon outil. Quelle que soit la distance choisie, utilisÃ©e sur ce type de vecteur (reprÃ©sentant
des idÃ©es, des concepts plutÃ´t que des termes cooccurrents), elle est dâ€™autant plus faible que les
vecteurs des objets lexicaux qui en sont les arguments sont dans un champ sÃ©mantique proche
(en isotopie selon la terminologie de Rastier (Rastier, 1985)).
Dans le cadre dâ€™une analyse sÃ©mantique comme celle qui nous intÃ©resse ici, nous lâ€™utilisons
pour tirer profit des informations mutuelles contenues dans les vecteurs conceptuels pour faire
de la dÃ©sambiguÃ¯sation lexicale sur des mots qui ont des sens situÃ©s dans un champ sÃ©mantique
proche. Ainsi, Â« Zidane a marquÃ© un but Â» peut Ãªtre dÃ©sambiguÃ¯sÃ©e grÃ¢ce aux idÃ©es communes
concernant le sport tandis que Â« Lâ€™avocat a plaidÃ© Ã  la cour Â» peut lâ€™Ãªtre grÃ¢ce Ã  celles concer-
297
Didier S CHWAB, Lim L IAN T ZE, Mathieu L AFOURCADE
nant la justice. De mÃªme, en ce qui concerne les rattachements prÃ©positionnels, les vecteurs
peuvent permettre dans Â« Il voit la fille avec un tÃ©lescope. Â» de rattacher Â« avec un tÃ©lescope Â»
au verbe voir grÃ¢ce aux idÃ©es communes sur la vision.
En revanche, les vecteurs conceptuels ne peuvent pas aider Ã  rÃ©soudre des cas oÃ¹ les termes
mis en jeu sont dans des champs sÃ©mantiques diffÃ©rents. On remarquera mÃªme quâ€™une ana-
lyse ne reposant que sur eux peut conduire Ã  de gros contre-sens. Par exemple, dans la phrase
Â« Lâ€™avocat a mangÃ© un fruit Â», avocat ne peut Ãªtre interprÃ©tÃ© que comme le fruit et non comme
lâ€™auxiliaire de justice. Ces limites des vecteurs conceptuels ont Ã©tÃ© expÃ©rimentalement montrÃ©es
pour lâ€™analyse sÃ©mantique sur des algorithmes Ã  fourmis dans (Lafourcade & Guinand, 2006).
Il aurait fallu que des connaissances comme Â« un avocat est un Ãªtre humain Â» et Â« un Ãªtre hu-
main mange Â» puissent Ãªtre identifiÃ©es, ce qui nâ€™est donc pas possible avec des vecteurs concep-
tuels seuls. Les vecteurs conceptuels seuls ne sont ainsi pas suffisants pour exploiter certaines
instances de fonctions lexicales dans les textes et un rÃ©seau lexical peut donc aider Ã  pallier
ces manques. Des publications antÃ©rieures ont montrÃ© la nÃ©cessitÃ© de cette approche hybride :
(Schwab et al., 2002) pour les antonymies, (Lafourcade & Prince, 2003) pour les gÃ©nÃ©riques et
les hyperonymes. (Schwab, 2005) Ã©tend cette constatation Ã  toute relation susceptible dâ€™aider Ã 
la rÃ©solution dâ€™une analyse sÃ©mantique.
4.2    Apport des vecteurs conceptuels aux rÃ©seaux lexicaux

Sâ€™ils bÃ©nÃ©ficient dâ€™une prÃ©cision certaine, le rappel des rÃ©seaux est bien moins fort. Il est, en
effet, difficile de penser que lâ€™on pourrait reprÃ©senter toutes les relations entre les termes. En
effet, comment considÃ©rer deux termes qui sont dans le mÃªme champ sÃ©mantique ? Ils peuvent
trÃ¨s bien ne pas se trouver dans le rÃ©seau car ils ne seraient pas forcÃ©ment reliÃ©s par un des arcs
â€œclassiquesâ€. Envisager lâ€™introduction dâ€™arcs de type champ sÃ©mantique, poserait Ã  nos yeux
deux problÃ¨mes dus au caractÃ¨re flou et flexible de cette relation :
â€“ le premier est liÃ© Ã  lâ€™idÃ©e de la relation que se fait le concepteur de la base, Ã  quel moment
considÃ¨re-tâ€™il que deux synsets sont dans le mÃªme champ sÃ©mantique ? Dans un cas dÃ©favo-
rable, on aurait trÃ¨s peu de ces arcs tandis que dans un cas opposÃ©, on pourrait se trouver avec
une explosion combinatoire du nombre dâ€™arc ;
â€“ le second problÃ¨me, plus fondamental, est liÃ© Ã  la reprÃ©sentation elle mÃªme. Comment envi-
sager de reprÃ©senter par un Ã©lÃ©ment discret une relation floue donc du domaine du continu ?
Ainsi, le domaine du continu offert par les vecteurs conceptuels offre des flexibilitÃ©s que le
domaine du discret offert par les rÃ©seaux ne peut donner. Il permet de pouvoir rapprocher des
mots sur des idÃ©es peu importantes mais pourtant communes Ã  deux objets.
Avec cette approche hybride - vecteurs conceptuels, rÃ©seau lexical - nous proposons de com-
biner des informations de nature complÃ©mentaire. Les vecteurs conceptuels et lâ€™opÃ©ration de
distance thÃ©matique par leur nature peuvent pallier le faible rappel intrinsÃ¨que aux rÃ©seaux
lexicaux tandis que ces derniers peuvent permettre de dÃ©sambiguÃ¯ser les cas qui sont dans un
champs sÃ©mantique diffÃ©rent contrairement aux vecteurs conceptuels. Les dÃ©fauts des uns sont
ainsi compensÃ©s par les qualitÃ©s des autres ce qui fait des vecteurs conceptuels et des rÃ©seaux
lexicaux des outils complÃ©mentaires.
298
ComplÃ©mentaritÃ© des rÃ©seaux lexicaux et des vecteurs conceptuels
5     ExpÃ©rience sur WordNet : utilisation des donnÃ©es

5.1     Exploitation des dÃ©finitions

Le projet eXtended WordNet (Mihalcea & Moldovan, 2001) est menÃ© Ã  la Southern Methodist
University de Dallas au Texas et vise deux objectifs : (1) dÃ©sambiguÃ¯ser lâ€™ensemble des termes
utilisÃ©s dans les dÃ©finitions des synsets, câ€™est-Ã -dire indiquer quels sont les synsets employÃ©s
dans la dÃ©finition ; (2) Transformer ces dÃ©finitions en forme logique pour permettre plus facile-
ment les calculs.
Ces donnÃ©es ont Ã©tÃ© rÃ©alisÃ©es de faÃ§on semi-automatique en utilisant les informations du rÃ©-
seau3 , des distances entre dÃ©finitions ou bien les informations sur le domaine. Ces donnÃ©es sont
en partie contrÃ´lÃ©es Ã  la main et le taux de prÃ©cision de plus de 90%.
Pour les vecteurs conceptuels, nous avons utilisÃ© ces donnÃ©es sous forme logique car elles per-
mettent de repÃ©rer les Ã©lÃ©ments les plus importants de la dÃ©finition, en particulier le genre. Le
calcul se fait ainsi sur un arbre en dÃ©pendances fabriquÃ© Ã  partir de cette dÃ©finition prÃ©traitÃ©e
pour enlever le mÃ©talangage difficilement exploitable pour une analyse thÃ©matique. Dans nos
explications, nous allons prendre pour exemple la forme logique de la dÃ©finition de fourmi.
ant :NN(x1) -> social :JJ(x1) insect :NN(x1) live :VB(e1, x1, x3) in :IN(e1, x2) organized :JJ(x2) colony :NN(x2)

Elle est organisÃ©e en 3 ensembles : x1 = {social, insect}, x2 = {organised, colony} et e1 =
{live}. Ce dernier ainsi que in permettent de hiÃ©rarchiser les ensembles. Le vecteur de chacun
des ensembles est calculÃ© en faisant la somme vectorielle de lâ€™Ã©lÃ©ment le plus porteur de sens
de cet ensemble (verbes, VB ; noms, NN ) et de la moitiÃ© des adjoints (adverbes, RB ; adjectifs,
JJ). Le calcul du vecteur global se fait ensuite par somme vectorielle pondÃ©rÃ©e des diffÃ©rents
ensembles dans lâ€™arbre en commenÃ§ant par la partie la plus basse. Ce mode de calcul permet
de considÃ©rer de faÃ§on prÃ©pondÃ©rante le genre sur les autres termes de la dÃ©finition et de faÃ§on
plus gÃ©nÃ©rale les tÃªtes sur leurs dÃ©pendants syntaxiques. La figure 1 synthÃ©tise ce calcul. Aucun
prÃ©dicat nâ€™Ã©tant dans lâ€™ensemble x3, il nâ€™apparaÃ®t pas sur le schÃ©ma.

âŠ•
         


                                                      âŠ•


                    
      âŠ•
 



F IG . 1 â€“ Construction du vecteur conceptuel de la dÃ©finition de fourmi

3
Par exemple, pour une dÃ©finition aristotÃ©licienne (en genre et diffÃ©rences), si le genre a un sens qui est aussi
un hyperonyme du synset dÃ©fini, on considÃ¨re que ce sens est celui utilisÃ© dans la dÃ©finition.

299
Didier S CHWAB, Lim L IAN T ZE, Mathieu L AFOURCADE
5.2     Exploitation des relations

Lâ€™exploitation des relations se fait Ã  deux niveaux : (1) pour la construction des vecteurs,
elles permettent de fabriquer de maniÃ¨re complÃ©mentaire aux dÃ©finitions le vecteur dâ€™un syn-
set ; (2) pour Ã©viter les phÃ©nomÃ¨nes de regroupement dâ€™ensembles distincts.
5.2.1    Construction des vecteurs

La construction dâ€™un vecteur conceptuel est effectuÃ©e pour chaque nÅ“ud du rÃ©seau par simple
somme pondÃ©rÃ©e des vecteurs des nÅ“uds reliÃ©s. Soit un nÅ“ud N reliÃ© a k nÅ“uds N1 . . . Nk , le
vecteur de N , V (N ) sera Ã©gal Ã  p1 V (N1 ) + p2 V (N2 ) + . . . + pk V (Nk ) oÃ¹ pi est le poids du
i-Ã¨me nÅ“ud. Le vecteur somme est ensuite normalisÃ©.
Cette approche entraÃ®ne naturellement une agglomÃ©ration des vecteurs. Il est donc nÃ©cessaire
dâ€™augmenter le contraste dâ€™un vecteur Ã  la suite de son calcul. Pour ce faire, on calcule le co-
efficient de variation4 de V. Si ce dernier ne se situe pas a 10% du CV moyen alors le vecteur
subit une opÃ©ration non linÃ©aire dâ€™amplification (la mise Ã  une puissance n de chaque compo-
sante puis normalisation), et ce de faÃ§on itÃ©rÃ©e jusquâ€™Ã  lâ€™obtention dâ€™un coefficient de variation
dans la fourchette acceptable. Cette derniÃ¨re a Ã©tÃ© estimÃ©e Ã  partir des valeurs obtenues dans les
expÃ©riences avec concepts prÃ©dÃ©finis.
5.2.2    ProblÃ¨me du regroupement dâ€™ensembles distincts

Un dernier problÃ¨me potentiel est que les vecteurs de deux ensembles distincts (Ã  la fois au sens
du rÃ©seau lexical et de la thÃ©matique) de termes peuvent occuper la mÃªme rÃ©gion de lâ€™espace.
Lâ€™approche du calcul se faisant par activation et les vecteurs Ã©tant tirÃ©s au hasard Ã  lâ€™initialisation
rien nâ€™empÃªche que cela se produise par accident. Il est donc nÃ©cessaire de "sÃ©parer" les vecteurs
proches mais correspondant pourtant Ã  des parties trÃ¨s diffÃ©rentes du rÃ©seau lexical et de la
thÃ©matique.
La dÃ©tection de ce phÃ©nomÃ¨ne se fait par scrutation du voisinage dâ€™un vecteur conceptuel. Si
parmi ses n premiers voisins, la densitÃ© de mots nâ€™ayant rien Ã  voir avec le mot Ã©tudiÃ© est
importante alors une action de sÃ©paration doit Ãªtre entreprise.
Cette action de sÃ©paration consiste Ã  plonger lâ€™ensemble du rÃ©seau dans un champs oÃ¹ les nÅ“uds
ont tendance Ã  se repousser. En sâ€™inspirant directement de la physique, une force de rÃ©pulsion
en 1/d2 est calculÃ©e itÃ©rativement entre les nÅ“uds. Pour un nÅ“ud donnÃ©, on peut ainsi calculer
un vecteur dÃ©placement qui va lâ€™Ã©loigner des nÅ“uds dont il se trouve trop prÃ¨s. Les nÅ“uds ne se
rapprochant pas par voisinage thÃ©matique (lors de la premiÃ¨re phase du calcul) mais se trouvant
proches â€œpar accidentâ€ finissent ainsi naturellement par se sÃ©parer.
4                                                           EC(V )
Le coefficient de variation CV est donnÃ© par la formule    Âµ(V )   avec EC(V) lâ€™Ã©cart type du vecteur V et Âµ(V )
la moyenne arithmÃ©tique des composantes de V.

300
ComplÃ©mentaritÃ© des rÃ©seaux lexicaux et des vecteurs conceptuels
6    Conclusion
Dans cet article, nous avons prÃ©sentÃ© les vecteurs conceptuels construits par Ã©mergence. Nous
avons montrÃ© en quoi ils peuvent aider Ã  rÃ©soudre le Â« problÃ¨me du tennis Â» de par leur carac-
tÃ¨re complÃ©mentaire aux rÃ©seaux lexico-sÃ©mantiques dont lâ€™exemple le plus courant dans les
recherches actuelles est WordNet. En effet, le rappel des rÃ©seaux est faible, ils ne permettent
pas facilement de reprÃ©senter le champs sÃ©mantique contrairement aux vecteurs tandis que ces
derniers ne sont pas suffisants pour reprÃ©senter des relations comme lâ€™hyperonymie ou la mÃ©ro-
nymie.
Notre proposition est de tirer profit de cette complÃ©mentaritÃ© en ajoutant Ã  WordNet des vecteurs
conceptuels construits Ã  partir des dÃ©finitions et des relations contenues dans cette base. La
mÃ©thode proposÃ©e ici tient du domaine du continu contrairement Ã  lâ€™ensemble des mÃ©thodes
que nous avons Ã©tudiÃ©es dans la littÃ©rature qui, elles, font partie du domaine du discret (ajout
dâ€™arcs pour les relations, de symboles sur le domaine, etc.).
Nous avons conscience que cette mÃ©thode ne permet seulement que de rÃ©soudre une partie du
Â« problÃ¨me du tennis Â». En effet, les vecteurs conceptuels ne permettent pas dâ€™exhiber les rap-
ports collocationnels non-thÃ©matiques entre items. Il sâ€™agit essentiellement des relations quâ€™Igor
Melâ€™Ë‡cuk modÃ©lise avec ses fonctions lexicales syntagmatiques (Melâ€™Ë‡cuk et al., 1995) comme
lâ€™intensification (Â« peur bleue Â» ; Magn ( peur ) = bleue )), la dÃ©gradation (Â« lait tourne Â» ;
Degrad ( lait ) = tourner ) ou bien encore le confirmateur (Â« argument valable Â» ; Ver ( ar-
gument ) = valable ). Comme le remarque (Ferret & Zock, 2006), ces relations font partie de
celles quâ€™il faudrait vraisemblablement avoir dans une base lexicale. Nous partageons ce point
de vue, certaines pistes ont Ã©tÃ© explorÃ©es dans (Schwab, 2005) et continuent Ã  lâ€™Ãªtre actuelle-
ment.
RÃ©fÃ©rences
E. AGIRRE, O. A NSA, D. M ARTINEZ, et E. H OVY. Â« Enriching WordNet concepts with topic
signatures Â». Dans les actes de NAACL worshop on WordNet and Other Lexical Resources :
Applications, Extensions and Customizations, Pittsburg, USA, 2001.
Romaric B ESANÃ‡ON. Â« IntÃ©gration de connaissances syntaxiques et sÃ©mantiques dans les
reprÃ©sentations vectorielles de texte Â». ThÃ¨se de doctorat, Ã‰cole Polytechnique FÃ©dÃ©rale de
Lausanne, Laboratoire dâ€™Intelligence Artificielle, 2001.
Christiane F ELLBAUM, . WordNet : An Electronic Lexical Database. The MIT Press, 1988.
Olivier F ERRET et Michael Z OCK. Â« Enhancing Electronic Dictionaries with an Index Based
on Associations Â». Dans les actes de Proceedings of the 21st International Conference on
Computational Linguistics, pp 281â€“288, 2006. Association for Computational Linguistics.
Sanda H ARABAGIU et Joyce Yue C HAI, . Usage of WordNet in Natural Language Processing
Systems, UniversitÃ© de MontrÃ©al, MontrÃ©al, Canada, 1998.
Sanda M. H ARABAGIU, George Armitage M ILLER, et Dan I. M OLDOVAN. Â« WordNet 2
- A Morphologically and Semantically Enhanced Resource Â». Dans les actes de Workshop
SIGLEXâ€™99 : Standardizing Lexical Resources, pp 1â€“8, 1999.
Kevin K NIGHT et Steeve L UK. Â« Building a Large-Scale Knowledge Base for Machine Trans-
lation Â». Dans les actes de AAAIâ€™1994 : National Conference on Artificial Intelligence, 1994.
301
Didier S CHWAB, Lim L IAN T ZE, Mathieu L AFOURCADE
Mathieu L AFOURCADE et FrÃ©dÃ©ric G UINAND. Â« Ants for Natural Language Processing Â».
International Journal of Computational Intelligence Research, 2006. Ã€ paraÃ®tre.
Mathieu L AFOURCADE et Violaine P RINCE. Â« Mixing Semantic Networks and Conceptual
Vectors : the Case of Hyperonymy Â». Dans les actes de ICCI-2003 (2nd IEEE International
Conference on Cognitive Informatics), pp 121â€“128, 2003.
Mathieu L AFOURCADE. Â« Conceptual Vector Learning - Comparing Bootstrapping from a
Thesaurus or Induction by Emergence Â». Dans les actes de LRECâ€™2006, 2006.
L AROUSSE, . ThÃ©saurus Larousse - des idÃ©es aux mots, des mots aux idÃ©es. Larousse, 1992.
Mathieu M ANGEOT -L EREBOURS, Gilles S Ã‰RASSET, et Mathieu L AFOURCADE. Â« Construc-
tion collaborative dâ€™une base lexicale multilingue : Le projet Papillon Â». TAL (Traitement
Automatique des langues) : Les dictionnaires Ã©lectroniques, pp 151â€“176, 2003.
Igor M ELâ€™ CUK
Ë‡   , AndrÃ© C LAS, et Alain P OLGUÃˆRE. Introduction Ã  la lexicologie explicative
et combinatoire. Duculot, 1995.
Rada M IHALCEA et Dan M OLDOVAN. Â« eXtended Wordnet : progress report Â». Dans les
actes de NAACL 2001 - Workshop on WordNet and Other Lexical Resources, Pittsburgh, USA,
2001.
Rada M IHALCEA, Paul TARAU, et Elizabeth F IGA. Â« PageRank on Semantic Networks, with
Application toWord Sense Disambiguation Â». Dans les actes de COLINGâ€™2004 : 20th Inter-
national Conference on Computational Linguistics, pp 1126â€“1132, 2004.
Ross Q UILLIAN. Â« Semantic Informatic processing Â», Chapitre Semantic memory, pp 227â€“
270. MIT Press, 1968.
FranÃ§ois R ASTIER. Â« Lâ€™isotopie sÃ©mantique, du mot au texte Â». ThÃ¨se de doctorat dâ€™Ã‰tat,
UniversitÃ© de Paris-Sorbonne, 1985.
Didier S CHWAB. Â« Approche hybride - lexicale et thÃ©matique - pour la modÃ©lisation, la dÃ©tec-
tion et lâ€™exploitation des fonctions lexicales en vue de lâ€™analyse sÃ©mantique de texte. Â». ThÃ¨se
de doctorat, UniversitÃ© Montpellier 2, 2005.
Didier S CHWAB, Mathieu L AFOURCADE, et Violaine P RINCE. Â« Vers lâ€™apprentissage automa-
tique, pour et par les vecteurs conceptuels, de fonctions lexicales. Lâ€™exemple de lâ€™antonymie
Â». Dans les actes de TALN 2002, volume 1, pp 125â€“134, 2002.
Mark S TEVENSON. Â« Augmenting Noun Taxonomies by Combining Lexical Similarity Me-
trics Â». Dans les actes de COLINGâ€™2002 : 19th International Conference on Computational
Linguistics, volume 2/2, pp 953â€“959, 2002.
Michael Z OCK. Â« Sorry, What Was Your Name Again, Or How to Overcome The Tip-Of-The
Tongue with the help of a computer ? Â». Dans les actes de SemaNetâ€™02 : Building and Using
Semantic Networks, Taipei, Taiwan, 2002.
302
