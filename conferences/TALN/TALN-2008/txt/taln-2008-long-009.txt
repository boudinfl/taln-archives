
Modélisation du principe d’ancrage pour la robustesse des
systèmes de dialogue homme-machine finalisés

Alexandre Denis Matthieu Quignard
UMR 7503 LORIA/CNRS – Campus scientifique
56 506 Vandoeuvre-lès-Nancy Cedex
alexandre.denis@loria.fr, matthieu.quignard@loria.fr

Résumé.         Cet article présente une modélisation du principe d’ancrage (grounding) pour
la robustesse des systèmes de dialogue finalisés. Ce principe, décrit dans (Clark & Schaefer,
1989), suggère que les participants à un dialogue fournissent des preuves de compréhension
afin d’atteindre la compréhension mutuelle. Nous explicitons une définition computationnelle
du principe d’ancrage fondée sur des jugements de compréhension qui, contrairement à d’autres
modèles, conserve une motivation pour l’expression de la compréhension. Nous déroulons enfin
le processus d’ancrage sur un exemple tiré de l’implémentation du modèle.
Abstract.         This paper presents a grounding model for robustness in dialogue systems. The
grounding process (Clark & Schaefer, 1989) suggests that dialogue participants provide evi-
dence of understanding in order to reach mutual understanding. We propose here a computatio-
nal definition of the grounding criterion based on understanding judgments that keeps a motiva-
tion for providing evidence of understanding, as opposed to some existing models. Eventually,
we detail the grounding process on a dialogue generated by the actual implementation.
Mots-clés :           dialogue homme-machine, robustesse, ancrage, compréhension mutuelle.

Keywords:             human-machine dialogue, robustness, grounding, mutual understanding.
1       Introduction
La campagne EVALDA-MEDIA du projet Technolangues (Bonneau-Maynard et al., 2006)
a permis d’évaluer différents systèmes de dialogue élaborés dans des laboratoires français
(LIMSI, LORIA, LIA, VALORIA). Cette évaluation consistait à mesurer la capacité des sys-
tèmes à produire une représentation sémantique correcte hors et en contexte d’énoncés naturels,
recueillis dans un protocole de Magicien d’Oz. Le problème d’une telle évaluation sur corpus
réside dans le fait qu’il n’est pas possible de tirer des conclusions sur la robustesse des sys-
tèmes lorsqu’ils seront engagés dans des situations réelles. Même si un système atteint un score
de compréhension de 80% de couverture sémantique ou référentielle, il n’est pas possible de
savoir si les erreurs commises sont critiques ou non vis-à-vis de la réussite du dialogue1 .
La campagne MEDIA revenait à évaluer la robustesse interne des systèmes, c’est-à-dire leur
capacité à comprendre l’énoncé sans faire appel à l’utilisateur. Le caractère critique ou non
1
Au mieux, on peut faire l’hypothèse qu’un concept est d’autant plus critique pour la tâche que sa fréquence
est élevée dans le corpus, mais est-ce vraiment le cas ?
Alexandre Denis, Matthieu Quignard
d’une erreur de compréhension rejoint la problématique de la robustesse externe : étant donnée
une erreur de compréhension (détectée ou non), le système est-il capable grâce au dialogue
d’atteindre la bonne interprétation, par exemple en posant des questions de clarification ?
La gestion de la compréhension mutuelle des participants d’un dialogue constitue le cœur des
travaux de Clark, notamment (Clark, 1996), dans la théorie du grounding (que nous traduirons
par la suite par le terme « ancrage »). Il s’agit du processus par lequel les participants manifestent
leur compréhension tout en surveillant, consolidant ou corrigeant l’interprétation que fait leur
interlocuteur des énoncés qu’ils produisent.
Nous présentons cette théorie et les différents modèles computationnels qui en découlent dans
la section suivante. Nous proposerons ensuite un modèle qui présente l’avantage de définir un
critère d’ancrage qui ne requiert pas de croyances mutuelles de compréhension tout en motivant
le besoin de manifester des preuves de compréhension. Enfin, nous déroulerons le modèle sur
un exemple de mauvaise compréhension d’une expression référentielle.
2    Modèles d’ancrage computationnels
Le terrain commun est l’ensemble des informations mutuelles qui sert de support aux parti-
cipants d’un dialogue pour l’interprétation et la production de leurs énoncés. Chaque énoncé
provoque la mise à jour de ce terrain commun (Lewis, 1969; Clark, 1996; Stalnaker, 1998).

Modèle des contributions.
Le modèle des contributions (Clark & Schaefer, 1989) critique les modèles dans lesquels le
contenu d’un énoncé est automatiquement ajouté au terrain commun. Il souligne que la mise à
jour du terrain commun requiert au préalable l’établissement d’une compréhension de l’énoncé.
Clark critique également les modèles qui conditionnent la mise à jour à l’absence de preuve né-
gative de compréhension, car ces modèles ne rendent pas compte de la manifestation positive de
compréhension tels les acknowledgements. Le modèle des contributions suppose alors que pour
contribuer au dialogue, les participants cherchent à atteindre une croyance mutuelle de com-
préhension, modélisée sous la forme d’un critère d’ancrage (grounding criterion) : un énoncé
est ancré lorsque « le locuteur et ses interlocuteurs croient mutuellement que les interlocuteurs
ont compris suffisamment le locuteur pour les buts courants ». La volonté d’atteindre ce critère
d’ancrage fournit une motivation à la manifestation (positive ou négative) de la compréhension.
Une contribution au dialogue est un acte collaboratif réalisé en deux phases : la présentation
d’un énoncé et son acceptation par le partenaire. Lorsque A présente un énoncé Ai , il fait l’hy-
pothèse que s’il reçoit une preuve de compréhension de son partenaire B, il peut légitimement
croire que B a compris Ai . Lorsque B accepte Ai , il produit une preuve de compréhension en
supposant qu’une fois que A reçoit cette preuve, A croit que B comprend l’énoncé. La coor-
dination de ces deux phases constitue le processus d’ancrage. Le critère d’ancrage n’est atteint
que lorsque ces deux phases sont terminées, et le cas échéant elles forment une base partagée
pour inférer la croyance mutuelle de compréhension (Clark, 1996). Le modèle des contributions
n’est toutefois qu’un modèle descriptif, non computationnel.

Modèle des échanges.
Le modèle des échanges (Cahn & Brennan, 1999) critique le modèle des contributions car
Modélisation du principe d’ancrage pour la robustesse des systèmes de dialogue
son manque de formalisme le rend inadapté pour le dialogue homme-machine. Celui-ci pose
en outre deux problèmes : il ne représente que le résultat final du processus d’ancrage et pas
ses étapes intermédiaires, et le fait avec une perspective omnisciente. Le modèle des échanges
donne alors une formalisation du processus d’ancrage d’un point de vue interne et incrémen-
tal en rajoutant la structure d’échange. Les échanges sont simplement des paires adjacentes de
contributions plus à même de modéliser la structure du dialogue homme-machine.
Le modèle des échanges est une version très fidèle du modèle des contributions qui en donne une
version computationnelle mais n’en résout pas les principaux problèmes (Denis et al., 2007).
Le plus important est sans doute celui posé par le processus d’ancrage, soulevé dans (Traum,
1999) sous le nom de problème de l’acceptation récursive : si une contribution a besoin d’être
acceptée pour jouer son rôle d’acceptation alors aucune phase d’acceptation ne peut être close.
En effet pour que l’énoncé soit ancré, B doit savoir si oui ou non A a bien reçu sa preuve
de compréhension et attendre alors une nouvelle contribution de A. Mais comment savoir si
cette nouvelle contribution est bien comprise ? B doit effectuer un nouvel énoncé, qui lui-même
nécessitera d’être accepté avant que l’énoncé initial puisse être ancré, etc.
Solutions au problème de l’acceptation récursive.
Dans (Clark & Schaefer, 1989), le problème de l’acceptation récursive est résolu par un principe
de diminution de preuve de compréhension : pour accepter une preuve il suffit de fournir une
preuve moins forte, l’ensemble des preuves pouvant être ordonné. Bien que cette classification
soit discutable (Traum, 1999), ce principe n’explique pas pourquoi on peut initier une nouvelle
contribution sans manifester explicitement sa compréhension de la preuve.
La solution généralement adoptée est alors de supposer la bonne compréhension de cette preuve.
Ainsi dans le modèle des grounding acts (Traum, 1999), la fonction d’acceptation n’a pas à être
acceptée. Dès lors, le problème de l’acceptation récursive ne se pose plus puisque B considère
que A reçoit correctement la preuve de compréhension. Cette solution a deux conséquences :
d’abord elle entraîne dans ce modèle une structure plate du dialogue, les discourse units, qui
rassemblent les énoncés qui peuvent être ancrés ensemble. Cette structure est simple à manipu-
ler mais difficile à réinterpréter. Ensuite elle implique que les énoncés qui n’ont qu’une fonction
d’acceptation sont automatiquement compris (par exemple les acknowledgements). Ce modèle
ne peut donc pas expliquer pourquoi on peut observer deux acknowledgements d’affilée.
L’approche de (Larsson, 2002) va encore plus loin en supposant la bonne compréhension des
énoncés. Ce modèle les considère ancrés par défaut tout en autorisant une possibilité de révision
(stratégie prudente). Mais cette stratégie élimine le besoin de fournir des preuves de compré-
hension : pourquoi le faire puisque l’énoncé est ancré par défaut ?
Nous pensons qu’un bon modèle ne doit pas ancrer les énoncés par défaut afin de conserver
une motivation pour la manifestation positive de leur compréhension. Ces preuves de compré-
hension jalonnent les dialogues homme-homme ; il nous faut conserver un principe motivant
leur emploi. Le problème d’acceptation récursive doit alors être résolu autrement. Nous sug-
gérons de relâcher l’hypothèse forte que le critère d’ancrage n’est atteint qu’avec la croyance
mutuelle de compréhension. Comme Taylor (1996), nous pensons qu’une croyance partagée
peut suffire2 .
2
La croyance mutuelle est la conjonction d’une infinité de croyances réciproques (je crois p, tu crois p, je crois
que tu crois p, tu crois que je crois p, je crois que tu crois que je crois p, etc.), tandis que la croyance partagée est
une conjonction finie (jusqu’à un rang n).
Alexandre Denis, Matthieu Quignard
3         Modélisation de l’ancrage
Avant tout il est nécessaire de rappeler que le critère d’ancrage d’un point de vue interne ne
requiert qu’une croyance de compréhension et non la compréhension effective. Dès lors, l’an-
crage peut être réalisé à tort. Notre hypothèse est qu’un énoncé joue sa fonction d’acceptation
lorsque celui-ci est cru compris ; l’acceptation ne dépend donc pas d’une acceptation ultérieure.
Lorsque A reçoit la preuve de compréhension fournie par B en Bi+1 , il peut estimer si B a
correctement compris son énoncé Ai et juger de son ancrage. La seule condition est que A croit
avoir compris cette preuve. Son interprétation peut être divergente et entraîner le cas échéant un
ancrage erroné de Ai .
Nous proposons alors un principe d’ancrage capable de rendre compte de ce fait, motivant
la manifestation de preuve de compréhension tout en considérant que leur interprétation peut
être erronée et qu’alors la réinterprétation des preuves de compréhension est nécessaire. Ce
principe a été implémenté dans un module adjoint à un système d’interprétation. Son rôle est de
spécifier les preuves de compréhension que le système doit manifester afin d’ancrer les énoncés
antérieurs.
3.1        Formulation en logique épistémique

Le principe d’ancrage que nous proposons est décrit à l’aide d’une croyance partagée au lieu
d’une croyance mutuelle et il est formulé de manière unilatérale afin de rendre compte d’une
perspective interne.

Définition : « un énoncé est ancré pour un participant ssi ce participant entretient
la croyance que le locuteur et l’interlocuteur partagent la croyance (au rang n) que
l’interlocuteur a compris suffisamment le locuteur pour les buts courants. »

Cette définition à l’aide d’une croyance partagée unilatérale présente plusieurs avantages. Elle
résout le problème de l’acceptation récursive car il n’y a pas de nécessité d’avoir une chaîne
infinie de croyances et d’énoncés. Ensuite, elle conserve le besoin de manifester sa compréhen-
sion puisqu’elle ne suppose pas que les énoncés sont ancrés a priori. De plus, elle autorise la
possibilité de construire ces croyances sur la seule base de la rationnalité et ainsi de modéliser
la stratégie prudente3 (Larsson, 2002), ou d’autres stratégies qui ne font pas partie du modèle
collaboratif. Enfin, elle présente un intérêt computationnel indéniable de par son caractère fini.
Une formulation du principe d’ancrage en logique épistémique permet de mettre en évidence
les croyances de compréhension nécessaires à l’ancrage. Au rang deux, que nous supposons
suffisant (Taylor et al., 1996), le principe d’ancrage du point de vue des participants A et B à
propos d’un énoncé Ai peut être formulé par :

BelB Grounded Ai = BelB U ndB Ai ∧ BelB BelA U ndB Ai

BelA Grounded Ai = BelA U ndB Ai ∧ BelA BelB U ndB Ai

Le premier intérêt pratique de cette définition est qu’elle met en lumière les deux modes d’acqui-
sition de la croyance de compréhension : l’évaluation de sa propre interprétation (BelB U ndB Ai ),
3
Il suffit de prendre n = 1 pour l’interlocuteur et n = 0 pour le locuteur.
Modélisation du principe d’ancrage pour la robustesse des systèmes de dialogue
et l’extraction de la preuve de compréhension (BelB BelA U ndB Ai ). De plus, étant donné
qu’elle distingue l’auteur du jugement (BelX ) et l’auteur de l’interprétation (U ndY ), elle
permet une représentation unifiée de la non-compréhension et de la mauvaise compréhension
(McRoy & Hirst, 1993). La non-compréhension est alors un jugement négatif d’un participant
sur sa propre interprétation (BelX ¬ U ndX Yi ), et la mauvaise compréhension un jugement né-
gatif d’un participant sur l’interprétation de son partenaire (BelX ¬ U ndY Xi ).
3.2    Modélisation des jugements

Lorsqu’un participant S reçoit un énoncé On de son partenaire O il se pose alors les questions de
compréhension suivantes, destinées à établir le critère d’ancrage de On et d’énoncés antérieurs ;
nous appelons S (Self ) le participant dont on adopte le point de vue et O son partenaire (Other) :

SS Est-ce que je juge avoir suffisamment compris l’énoncé de mon partenaire ? (BelS U ndS On )
SO Est-ce que je juge que mon partenaire a suffisamment compris mon énoncé antérieur ?
(BelS U ndO Sk )
OO Est-ce que (je crois que) mon partenaire juge avoir suffisamment compris mon énoncé
antérieur ? (BelS BelO U ndO Sk )
OS Est-ce que (je crois que) mon partenaire juge que j’ai suffisamment compris son énoncé
antérieur ? (BelS BelO U ndS Oi )

Ces quatre types de questions découlent de la combinatoire auteur du jugement / auteur de
l’interprétation et on notera XY le jugement de X sur l’interprétation de Y . Par exemple SO est
le jugement de S sur l’interprétation de O ou OO le jugement de O sur sa propre interprétation
(mais toujours du point de vue de S). Nous utilisons la terminologie du modèle des échanges
pour nommer les valeurs de ces jugements. Les jugements positifs et négatifs de OO ou de SS
seront appelés respectivement U (U NDERSTOOD) et U (N OT U NDERSTOOD). Les jugements
positifs et négatifs de SO ou OS seront appelés R (R ELEVANT) et R (N OT R ELEVANT). On
dira par exemple qu’un énoncé On est U R lorsque SS est U et SO est R, et qu’il manifeste U R
lorsque OO est U et OS est R. Enfin nous noterons dans ce cas U R/U R pour représenter à la
fois la compréhension de l’énoncé et la compréhension qu’il manifeste.
Les jugements négatifs permettent de représenter des catégories globales de problème. Ils ne
peuvent être utilisés tels quels et doivent être raffinés par niveau, type et localisation du pro-
blème. Le niveau et le type de problème font l’objet de nombreux travaux qui visent à établir
une taxonomie d’erreurs, voir par exemple (Paek, 2003; Schlangen, 2004). La localisation du
problème doit permettre d’identifier l’unité problématique, différente en fonction du niveau du
problème : les mots au niveau lexical, les sens au niveau sémantique, les référents au niveau
référentiel, etc.
3.3    Acquisition des jugements

La première étape pour déterminer si un énoncé est ancré est d’acquérir ces jugements et nous
faisons l’hypothèse qu’ils sont acquis lors de la phase d’interprétation. Ces jugements sont
d’abord construits, puis utilisés dans un second temps pour produire l’énoncé suivant. Nous ne
nous attachons pas ici à élaborer une théorie ou des algorithmes d’acquisition des jugements
mais donnons quelques pistes en ce sens.
Alexandre Denis, Matthieu Quignard
Les jugements SS et SO peuvent être modélisés comme des attentes vis à vis de l’interprétation.
Le jugement SS correspond à l’attente d’une interprétation unique et certaine : une interpréta-
tion vide, ambiguë ou incertaine conduit alors à un U . En général le calcul du jugement SS
s’appuie sur un score de confiance issu de la reconnaissance de la parole ou d’une combinai-
son de scores à différents niveaux d’analyse (Purver et al., 2006). Si le score est inférieur à
un seuil donné, alors l’énoncé est considéré non compris (le jugement SS est U ). Le jugement
SO peut être acquis par la satisfaction d’attentes vis à vis du contenu de l’énoncé d’autrui. Par
exemple (Danieli, 1996) repère les occurences de mauvaise compréhension par la déviation du
comportement de l’utilisateur vis à vis des prédictions du système, ou (McRoy & Hirst, 1993)
utilise l’abduction pour inférer la cause de la mauvaise compréhension. Pour les jugements OO
et OS, le contenu propositionnel peut expliciter l’existence d’un problème d’interprétation, par
exemple « je ne comprends pas » qui manifeste un U ou encore « non, c’est l’hôtel Ibis » qui
manifeste un U R. Mais la prosodie, les marqueurs de discours, les attitudes gestuelles ou le
regard sont également des indices sur lesquels on peut fonder la construction de ces jugements
(Krahmer et al., 1999; Nakano et al., 2003).
3.4    Gestion de la structure du dialogue

Une fois que les jugements de compréhension ont été construits, il est nécessaire de vérifier
l’état courant du dialogue afin de déterminer si ces jugements modifient le statut d’ancrage
d’un énoncé antérieur. Nous reprenons la proposition du modèle des échanges de représenter
explicitement la composante structurelle du processus d’ancrage en maintenant une structure
de dialogue. De manière analogue au modèle des échanges, Luzzati (Luzzati, 1995) suggère
que le dialogue s’oriente en deux axes : un axe régissant lorsqu’il n’y a pas de problème de
compréhension, et un axe incident en cas de phase de clarification. La structure de dialogue
du modèle des échanges est très proche des Unités Minimales d’Interaction de Coala (Lehuen,
1997) : un échange initié dans l’acceptation d’une contribution correspond à une UMI incidente.
Règles de mise à jour. La structure de dialogue est une structure incrémentale, construite ou
révisée en fonction des jugements de compréhension. Nous proposons de représenter les mises
à jour comme des opérations sur la structure, déclenchées en fonction des jugements de et portés
par l’énoncé courant On . Il existe deux types de règles. Les règles de U ou de U R impliquent
que la réaction du système est entièrement déterminée par la résolution de la divergence, par
exemple grâce à l’initiation d’un échange incident. Les règles de U R impliquent que la réaction
du système est déterminée par l’ancrage d’autres énoncés et/ou par la gestion de la tâche (Denis
et al., 2007). En effet lorsqu’un énoncé On est U R / U R et clôt un échange incident, il provoque
la réinterprétation de l’énoncé accepté Oi , entraînant alors le besoin d’effectuer un nouveau
jugement de compréhension sur Oi et alors de décider en fonction de ce nouveau jugement
les opérations à effectuer. Le cas échéant, le processus d’ancrage s’applique sur Oi et sur On .
Le modèle des grounding acts ne considère pas la réinterprétation des jugements puisque les
preuves de compréhension sont supposées ancrées par défaut.
Réinterprétation. La réinterprétation consiste à effectuer de nouveau l’interprétation d’un
énoncé Oi grâce à de nouvelles informations apportées par un énoncé On , soit qu’il s’agit d’une
réponse à un U initié par S, ou soit qu’On manifeste un U R. La différence principale tient au fait
que dans le premier cas l’interprétation est jugée problématique a priori et dans le second elle
Modélisation du principe d’ancrage pour la robustesse des systèmes de dialogue
l’est a posteriori. Dans les deux cas l’altération de l’ancienne interprétation et du contexte peut
conduire à réviser la structure du dialogue (voir l’effet de l’U R dans le modèle des échanges)
ainsi que les jugements de compréhension de et portés par Oi . L’acquisition de nouveaux ju-
gements permet alors de réagir à l’évolution de la compréhension. Par exemple le fait qu’un
énoncé U demeure U malgré l’emploi d’une stratégie donnée suggère que le problème doit être
abordé avec une stratégie différente. Le fait que plusieurs interprétations se produisent lors-
qu’on reçoit un énoncé entraîne que la sortie du module d’ancrage est une liste de jugements de
compréhension.
3.5    Production des preuves de compréhension

Enfin, lorsque les jugements de compréhension ont été calculés et recalculés, la structure de dia-
logue mise à jour et toutes les réinterprétations effectuées, il est nécessaire de produire l’énoncé
suivant. Une stratégie naïve du type « Je ne comprends pas. Veuillez reformuler. » n’a que
peu de chances de parvenir à la convergence essentiellement parce que la manifestation de la
non-compréhension est trop pauvre : elle n’indique que l’existence d’un problème. Par exemple
« Je ne comprends pas "cet hôtel". C’est vide. Quel hôtel ? » contient quatre indices permettant
à l’utilisateur d’inférer le problème :
– « Je ne comprends pas » qui manifeste l’existence d’un problème d’interprétation,
– « "cet hôtel" » qui désigne la couverture lexicale du problème,
– « C’est vide. » qui présente l’état dans lequel se trouve le système (ici le type de problème
rencontré),
– « Quel hôtel ? » qui correspond à la requête destinée à résoudre le problème.
Ces indices sont construits lorsque le système établit les jugements SS et SO. Leur manifes-
tation dans le dialogue en fait des preuves de compréhension, traduisant l’état des participants
relativement à l’ancrage.
Enfin, le système doit être capable d’exprimer l’ensemble des jugements qu’il effectue à l’aide
de plusieurs preuves de compréhension dans un même énoncé. Nous proposons de coordonner
ces preuves au moyen de connecteurs discursifs, afin de manifester explicitement le résultat
de la réinterprétation (Byron & Heeman, 1997). Ces marqueurs fournissent un compte-rendu
des raisonnements effectués et de l’état dans lequel se trouve le système : si la réinterprétation
aboutit à un jugement U R de l’énoncé, alors utiliser « donc », si elle aboutit à un jugement U
ou U R, alors utiliser « mais ».
4     Exemple détaillé

L’exemple que nous proposons (figure 4), issu de l’implémentation du modèle, illustre la ges-
tion de deux phénomènes : une mauvaise interprétation suivie d’un échec de réinterprétation.
Le dialogue ne s’applique pas sur une tâche extra-linguistique, le seul but du système S est ici
d’ancrer l’interprétation des expressions référentielles de l’utilisateur O. Pour cet exemple, les
jugements sont calculés de manière très simple : SS ne s’appuie que sur le résultat de la réso-
lution de la référence, SO n’est pas calculé, OO et OS sont déduits de la force illocutoire et du
contenu propositionnel (par exemple, un « non » qui n’est pas précédé d’une question fermée
manifeste un U R).
Alexandre Denis, Matthieu Quignard
O0 :     je prends l’hôtel europa
S1 :     OK un hôtel
O2 :     non l’hôtel europa
S3 :     je ne comprends pas "l’hôtel europa".
:     Pour moi, "l’hôtel europa" réfère à un hôtel (quelconque)
O4 :     non ça réfère à l’europa
S5 :     OK OK donc l’europa
O6 :     OK
F IG . 1 – Mauvaise compréhension avec réinterprétation échouée

En recevant O0 , S construit le jugement U R/U R mais interprète mal l’expression « l’hôtel eu-
ropa » sans le percevoir4 . Puisque O0 est le premier énoncé, il initie un échange niveau dialogue
auquel S1 répond par une simple paraphrase (voir figure 2-a).

(a)                               (b)                                         (c)
F IG . 2 – Structures du dialogue 4

Lorsqu’il reçoit O2 , S construit le jugement U R/U R : il croit d’abord comprendre O2 mais
le « non » indique sa mauvaise compréhension de O0 . Cet U R a deux effets : d’abord une
restructuration du dialogue, S1 n’est plus une réponse pertinente à O0 et est déplacée dans
l’acceptation de O0 (voir 2-b), ensuite une réinterprétation de O0 .
Cependant, étant donné que les référents des expressions cible (en O2 ) et source (en O0 ) sont les
mêmes pour S, cette réinterprétation échoue, entraînant alors un jugement U de O2 . S produit
son énoncé S3 en explicitant sa non-compréhension par la couverture du problème (« "l’hôtel
europa" »), le niveau du problème (« réfère à ») et son état (« Pour moi, X réfère à Y »). La
non-compréhension entraîne alors l’initiation par S3 d’un échange incident dans l’acceptation
de O2 (voir figure 2-b).
Lorsque S reçoit O4 , il parvient à analyser correctement « l’europa », grâce cette fois à une
bonne sémantique. S peut alors réinterpréter O2 grâce à l’échange S3 ,O4 . Cette réinterpréta-
tion conduit au jugement de O2 U R/U R, et provoque à son tour la réinterprétation de O0 en
vertu du fait que O2 clôt un échange d’acceptation. Enfin, puisque désormais les référents des
expressions cible et source sont différents, cette réinterprétation réussit et le nouveau jugement
de O0 est alors U R/U R. S produit son énoncé S5 en manifestant trois preuves : sa compréhen-
4
Cette erreur a été réellement observée lors de l’évaluation MEDIA et est causée par une sémantique incomplète
de « europa ».
Modélisation du principe d’ancrage pour la robustesse des systèmes de dialogue
sion de O4 , de O2 , traduites par des « OK » et de O0 , traduite par une paraphrase, coordonnant
les deux dernières par un « donc ». S5 clôt l’échange initié par O0 (voir figure 2-c).
5    Conclusion et perspectives

Le modèle d’ancrage que nous avons présenté a pour avantage de s’appuyer sur des croyances de
compréhension finies tout en motivant le besoin de fournir des preuves de compréhension. Ces
preuves sont la manifestation des jugements de compréhension que chaque participant élabore
lorsqu’il interprète les énoncés de son partenaire. Le modèle permet de rendre compte de la non-
compréhension ou de la mauvaise compréhension, qu’elle soit issue de l’interprétation ou de la
réinterprétation. Il souffre toutefois de nombreuses limitations : la plus importante est qu’il ne
considère que les tours de parole mono-contributifs. En effet, un locuteur peut fournir plusieurs
preuves de compréhension, et si nous avons rendu compte de leur production, l’interprétation
de ces preuves multiples soulève des problèmes difficiles quant à la gestion de la structure du
dialogue. La seconde limitation est que le modèle se limite à la non-compréhension de ces
dernières (Denis et al., 2007) et pas à leur mauvaise compréhension en raison de la complexité
de la réinterprétation des preuves. Il s’agit pourtant d’un enjeu majeur étant donné la difficulté
des systèmes à percevoir qu’ils ne comprennent pas.
Pour évaluer si ces limitations ont un impact sur la robustesse du système, l’évaluation ME-
DIA ne saurait être suffisante en raison de sa nature statique. Il est nécessaire, afin d’évaluer la
robustesse externe de pouvoir évaluer le système dans l’interaction. Nous nous orientons vers
le paradigme SIMDIAL (Allemandou, 2007) qui permet d’évaluer un système en simulant un
utilisateur de manière déterministe. Le but du dialogue est alors l’ancrage des énoncés pro-
posés par l’utilisateur simulé. L’évaluation consiste à déterminer si le système peut atteindre
l’interprétation de l’utilisateur par le dialogue et comment il peut l’atteindre. Nous espérons en
particulier retirer de cette évaluation des indices fins quant aux meilleures stratégies à employer
pour la convergence de l’interprétation.
Références
A LLEMANDOU J. (2007). SIMDIAL, un paradigme d’évaluation automatique de systèmes de
Dialogue homme-machine par simulation déterministe d’utilisateurs. PhD thesis, Université
Paris Sud, Orsay.
B ONNEAU -M AYNARD H., AYACHE C., B ÉCHET F., D ENIS A., K HUN A., L EFÈVRE F.,
M OSTEFA D., Q UIGNARD M., ROSSET S., S ERVAN C. & V ILLANEAU J. (2006). Results of
the french evalda-media evaluation campaign for literal understanding. In Proceedings of the
Language Resources and Evaluation Conference, Gênes, Italie.
B YRON D. & H EEMAN P. (1997). Discourse marker use in task-oriented spoken dialog. In
Proceedings of Eurospeech’97, p. 2223– 2226, Rhodes, Grèce.
C AHN J. & B RENNAN S. (1999). A psychological model of grounding and repair in dialog. In
AAAI Fall Symposium on Psychological Models of Communication in Collaborative Systems,
Sea Cliff, MA.
C LARK H. (1996). Using Language. Cambridge University Press.
Alexandre Denis, Matthieu Quignard
C LARK H. & S CHAEFER E. (1989). Contributing to discourse. Cognitive Science, 13, 259–
294.
DANIELI M. (1996). On the use of expectations for detecting and repairing human-machine
miscommunication. In AAAI-96 Workshop on Detecting, Preventing, and Repairing Human-
Machine Miscommunications, Portland, OR.
D ENIS A., P ITEL G., Q UIGNARD M. & B LACKBURN P. (2007). Incorporating asymmetric
and asychronous evidence of understanding in a grounding model. In Proceedings of DECA-
LOG, the 11th International Workshop on the Semantics and Pragmatics of Dialogue, Trento,
Italie.
K RAHMER E., S WERTS M., T HEUNE M. & W EEGELS M. (1999). Problem spotting in
human-machine interaction. In Eurospeech 1999, p. 1423–1426, Budapest, Hongrie.
L ARSSON S. (2002). Issue-based Dialogue Management. PhD thesis, Goteborg University.
L EHUEN J. (1997). Un modèle de dialogue dynamique et générique intégrant l’acquisition de
sa compétence linguistique - Le système Coala. PhD thesis, Université du Maine - Le Mans.
L EWIS D. (1969). Convention: A Philosophical Study. Harvard University Press.
L UZZATI D. (1995). De l’erreur en DHM. Cahiers de Linguistique Française, 16, 175–192.
M C ROY S. & H IRST G. (1993). Abductive explanations of dialogue misunderstanding. In
6th Conference of the European Chapter of the Association for Computational Linguistic, p.
277–286, Utrecht, Pays-Bas.
NAKANO Y., R EINSTEIN G., S TOCKY T. & C ASSELL J. (2003). Towards a model of face-
to-face grounding. In Proceedings of Association for Computational Linguistics, Sapporo,
Japon.
PAEK T. (2003). Toward a taxonomy of communication errors. In ISCA Workshop on Error
Handling in Spoken Dialogue Systems, p. 53–58, Château d’Oex, Vaud, Suisse.
P URVER M., R ATIU F. & L.C AVEDON (2006). Robust interpretation in dialogue by combi-
ning confidence scores with contextual features. In INTERSPEECH: International Conference
on Spoken Language Processing, Pittsburgh, PA.
S CHLANGEN D. (2004). Causes and strategies for requesting clarification in dialogue. In
Proceedings of SIGDial, Workshop on Discourse and Dialogue, Boston, MA.
S TALNAKER R. (1998). On the representation of context. Journal of Logic, Language and
Information, 7(1), 3–19.
TAYLOR J. A., C ARLETTA J. & M ELLISH C. (1996). Requirements for belief models in
cooperative dialogue. User Modeling and User-Adapted Interaction, 6(1), 23–68.
T RAUM D. R. (1999). Computational models of grounding in collaborative systems. In
Working Papers of the AAAI., p. 124–131, Menlo Park, California: AAAI.
