
Utilisation d_e contextes pour la,correct_ion au_tomatique
ou semi-automatique de reclamations clients

Philippe Suignardl Soﬁane Kerrouaz

(1) Electricité de France R&D, 1 avenue du Général de Gaulle, 92141 Clamart
(2) A.I.D., 4 rue Henri Le Sidaner, 78000 Versailles
philippe.suignard@edf.fr, skerroua@aid.fr

RESUME

Cet article présente deux méthodes permettant de corriger des réclamations contenant
des erreurs rédactionnelles, en s’appuyant sur le graphe des voisins orthographiques et
contextuels. Ce graphe est constitué des formes ou mots trouvés dans un corpus
d’apprentissage. Un lien entre deux formes traduit le fait que les deux formes se
« ressemblent » et partagent des contextes similaires. La premiere méthode est semi-
automatique et consiste a produire un dictionnaire de substitution a partir de ce graphe.
La seconde méthode, plus ambitieuse, est entiérement automatisée. Elle s’appuie sur les
contextes pour déterminer a quel mot correspond telle forme abrégée ou erronée. Les
résultats ainsi obtenus permettent d’améliorer le processus déja existant de constitution
d’un dictionnaire de substitution mis en place an sein d’EDF.

ABSTRACT

Using contexts for automatic or semi-automatic correction of customer complaints

This article presents two methods allowing correcting complaints containing spelling
errors, by using the spelling and contextual neighbors‘ graph. This graph is made of
forms or words found in a learning corpus. A link between two forms conveys the fact
that the two forms "look alike" and share similar contexts. The ﬁrst method is semi-
automatic and consists in producing a substitutional dictionary from this graph. The
second method, more ambitious, is fully automatic. It is based on contexts to determine
to which word corresponds such abbreviated or erroneous form. The results thus
obtained allow us to improve the existing process regarding the creation of a
substitutional dictionary at EDF.

MOTS-CLES : Correction automatique, analyse distributionnelle, graphe, contexte
KEYWORDS : Spelling correction, distributional analysis, graph, context

1 Introduction

An sein des entreprises, un suivi et une analyse rigoureuse des réclamations, de leurs
causes, et de leurs évolutions est une plus-value dans la connaissance du client. Cette
problématique est rencontrée chez EDF qui analyse, rigoureusement, les réclamations,
orales ou écrites, par le biais d’une chaine de traitement. Celle-ci, prend sa source au sein
des « Cemres de Relation Clientele » o1‘1 sont recueillies, suivies et traitées toutes les
demandes ou réclamations par les conseillers clientéles. Ceux-la ont la téche d'accueillir
le client, directement de vive voix ou par téléphone, indirectement par mail on par
courrier, de déterminer les causes de leur requéte, d’en apporter une solution, ou a
défaut d’en avoir une, de contacter tous les services potentiellement capables de le faire,
tout en prenant soin de maintenir le client satisfait des services offerts par leur
foumisseur d’énergie et en lui proposant des offres commerciales. Ainsi, en plus de ces
taches, le conseiller doit saisir et décrire la réclamation du client. Dans ce contexte, les
réclamations saisies par le conseiller sont sujettes a des erreurs rédactionnelles qu’il
convient de corriger et de normaliser pour améliorer la qualité des traitements
ultérieurs.

La suite de cet article décrit plus précisément les réclamations et leur analyse au sein
d’EDF, ceci permettant de présenter le corpus d’apprentissage utilisé dans les parties
suivantes. La partie 3 présente un état de l’art de la correction automatique de texte. La
partie 4 présente les deux méthodes proposées pour la correction automatique. Toutes
deux ayant pour pré-requis commun, la construction automatique du réseau des voisins
orthographiques et contextuels. La partie 5 présente quelques résultats.

2 Les réclamations au sein d’EDF et le corpus d’apprentissage

En traitant les appels, les conseillers saisissent les réclamations des clients en y ajoutant
des informations complémentaires (si le client avait déja appelé, état de sa satisfaction,
réponse apportée, etc.). Rédigée lors de l'appel, dans un cadre et dans un temps imparti
et sans relecture a posteriori, la qualité de la réclamation est tributaire du conseiller qui
la rédige. Ainsi, certaines réclamations, mal orthographiées et abrégées a outrance sont
difﬁcilement compréhensibles. De plus, le vocabulaire utilisé, abondamment abrégé, y
est tres spécialisé.

En France métropolitaine, on dénombre ainsi environ 200 000 réclamations par mois,
exploitées, traitées et analysées par la Direction Commerce d’EDF, permettant ainsi de
suivre l'évolution des demandes des clients.

Dans le but d’améliorer et de faciliter leur analyse, ces réclamations lors de leur
traitement subissent une phase de normalisation qui consiste a remplacer des formes
abrégées ou considérées comme erronées par des formes considérées comme étant
canoniques. Formes canoniques, abrégées et erronées sont réunies dans un dictionnaire
dit de substitution qui est utilisé lors de la normalisation.

Formes canoniques Formes a corriger

agence en ligne ael a.e.l | a-e-l
agent agt

alimentation alim alimention

TABLE 1 - Extrait du dictionnaire de substitution

Ce dictionnaire de substitution est construit manuellement et enrichi au ﬁl du temps par
un expert métier ayant une bonne connaissance de la typologie orthographique des
réclamations. Comme le montre la Table 1 , il s’agit d’un document texte tabulé ou
chaque ligne commence par la forme canonique et est suivie par une ou plusieurs formes
abrégées ou considérées comme erronées. Cependant, ce dictionnaire, du fait de sa
construction manuelle, ne peut pas étre complet, la masse tres importante des
commentaires ne permettant pas d'estimer, méme pour un expert, la majorité des fautes
ou des abréviations.

Nos travaux s’appuient sur un corpus d’apprentissage, composé de réclamations
contenant un total de plus de 7 millions de mots. Les réclamations sont récupérées sans
prétraitement, il s’agit donc des textes directement saisis par les conseillers.

Pour les tests qui suivent nous avons constitué un corpus appelé << corpus 100k»
comprenant 100 000 réclamations.

3 Etat de 1’art de la correction de texte

La correction de texte est un sujet qui a fait l’objet de nombreux brevets et travaux et qui
continue a progresser du fait de l’évolution des moyens de production des textes (textes
scannés, saisis avec des claviers d’ordinateur, puis des claviers de téléphones, etc.) et les
contraintes associées (160 caracteres pour les SMS ou 140 pour les tweets).

Beaucoup d’auteurs se sont penchés sur la problématique de la correction de texte La
plupart d’entre eux comme (Bouraoui et aL, 2009), commence par déﬁnir quelles sont
ces erreurs et en établit une typologie, typologie que nous partageons largement. Notre
corpus comprend :

— des inversions, ajouts ou suppressions de caracteres (<< cleint >>, « clint >>,
<< cllient >> pour << client >>, suppression des << Q >> comme dans << recu >> ou des << e >>
comme dans « cheque ») ;

— des abréviations, formes raccourcies ou non terminées (« logt » pour
<< logement >>, << inter >> pour << intervention >>, << pq >> pour << pourquoi >>) ;

— des sigles et acronymes (« mes » pour « mise en service ») ;

— des textes coupés en deux (« suite a ppel client ») ;

— des textes accolés ou agglutinés (« lavoir » pour « l’avoir >>, « le clienta » pour « le
client a ») ;

— des textes coupés et accolés (« clienta ppel » pour « client appelle >>, « le client
ma pel car... » pour « le client m’appelle car... ») ;

— des écritures phonétiques de type SMS (<< ét » pour « été », « koi » pour « quoi >>,
<< 1client >> pour << un client >>)

— et bien sur des fautes d’accord, de grammaire...

Ensuite, quelle méthode utiliser ? Marion Baranes (Baranes, 2012) en dresse un tres large
panorama: méthodes basées sur des dictionnaires, sur des regles de grammaires,
méthodes utilisant les mots cooccurrents, méthodes utilisant différentes mesures de
proximité (lexicale, clavier, phonétique, notamment pour corriger les SMS),
classiﬁcation, utilisation des n-grammes, etc. D’autres méthodes sont des combinaisons
de toutes ces méthodes. Dans ce panorama, est également citée l’approche
« distributionnelle » (Li, 2006), que nous adapterons par la suite.

Généralement, toutes les méthodes s’accordent pour ne pas sur corriger notamment les
dates, montants et plus généralement les chiffres (numéro de téléphone, heure de rendez-
vous, etc.), ce qui peut avoir de graves conséquences.
4 Présentation des méthodes

Notre approche s’inspire des travaux utilisant l’analyse distributionnelle, généralement
mise en oeuvre pour détecter des relations sémantiques comme la synonymie a l’aide de
corpus textuels (Bourigault, 2002) et (Greffenstette, 1994). Nous reprenons cette
approche mais pour détecter les variantes orthographiques des mots en comparant la
distribution de leurs contextes. Ensuite, a partir du graphe des voisins orthographiques et
contextuels, nous proposons deux méthodes pour corriger les textes bruités : l’une semi-
automatique et l’autre complétement automatique.

Pour ce faire, nous nous sommes basés sur le fait qu’une forme bien orthographiée
apparait plus souvent dans le corpus que ses formes mal orthographiées et qu’ainsi, les
contextes d’une forme mal orthographiée se retrouvent parmi ceux de la forme bien
orthographiée. Par exemple, dans le << corpus 100k», on trouve 292 294 occurrences
pour « client >> et 220 657 pour « cliente », les formes mal orthographiées associées a ces
mots ayant le plus d’occurrence étant « clt» apparaissant 87 257 fois et « clte» qui
apparait 63 439 fois, jusqu’a 221 fois pour << clietn >>. On peut expliquer ce phénoméne
parce que les fautes se répartissent sur un grand nombre de formes (une cinquantaine
pour << client >>).

Néanmoins, ceci n’est pas toujours vrai. En effet, pour certains types d’erreurs, en
particulier pour la suppression de caractéres accentués, les formes mal orthographiées
sont aussi nombreuses voire plus nombreuses que les formes bien orthographiées. Dans
le << corpus 100k >>, << recu >> et << recu >> sont presque aussi fréquents (34 853 contre
36 999), et « cheque» compte 11 870 occurrences alors que la forme sans accents
« cheque >> apparait 15 592 fois.

La suite présente les deux méthodes aprés la partie préliminaire, commune aux deux
méthodes.

4.1 Partie préliminaire commune aux deux méthodes

Pour résumer, cette partie cherche a établir un graphe constitué des mots ou formes qui
se « ressemblent » et qui partagent des contextes similaires.

Etape 1 : pour tous les commentaires ou textes du << corpus 100k >>, la ponctuation est
enlevée car elle n’est pas toujours mise a bon escient. Le texte est considéré comme une
suite de mots mi. Pour chaque mot mi, les contextes sont calculés a l’aide des mots qui le
précedent et qui lui succédent. Les formes sont prises de maniere brutes sans analyse
morpho-syntaxique. Pour chaque mot mi (sauf pour les premiers et derniers), on obtient :

— 2 contextes simples (bigrammes) : << mi_1 _ >>, << _ m1-+1 >>
— 3 contextes doubles (trigrammes) : << mi_2 mi_1 _ >>, << m,-_1 _ 111,- +1 >>, << _ 111,- +1 mi +2 >>

L’association (« mot », « contexte ») est stockée dans une base de données Lucenel, ce qui
permet ensuite de trouver rapidement tous les contextes pour un mot donné ou de
trouver les mots associés a un contexte donné.

1 - Moteur de recherche développé par la fondation Apache (http://lucene.apache.org/)
Etape 2: la base de données est parcourue aﬁn d’éliminer les contextes uniques car
pouvant amener du bruit. Pour le << corpus 100k >>, le nombre total de contextes est de 22
millions. La liste des formes présentes dans le corpus est établie et classée par ordre de
fréquence décroissante.

Etape 3 : les formes de la liste précédente vont étre comparées deux a deux a l’aide de
deux mesures de similarité : simbamem et simkmmde. La mesure simbamem est basée sur la
distance de Damerau-Levenstein (Damerau, 1964) qui consiste a calculer le nombre
minimum d'opérations nécessaires pour transformer une cha’1‘ne de caracteres en une
autre, ou une opération est déﬁnie comme l'insertion, la suppression, la substitution d’un
simple caractere, ou encore la transposition de deux caracteres. La valeur obtenue est
divisée par le maximum des longueurs des deux cha’1‘nes a comparer. Pour << client » et
« cliemnt >> on obtient une distance de 0,1428 ou similarité de 0,8571.

Néanmoins cette mesure ne permet pas de trouver les formes raccourcies ou abrégées
que l’on rencontre assez fréquemment comme << inter » pour «intervention » ou « cl »
pour « client ». On pourrait quand meme les trouver avec cette mesure en baissant le
seuil limite mais au risque d’introduire du bruit. Ces réﬂexions nous ont amenés a
imaginer la mesure simkacmmie qui consiste a compter le nombre de paires de lettres qui
se suivent dans la cha’1‘ne de caracteres la plus courte et qui font partie de la cha’1‘ne la
plus longue, divisée par le nombre de paires de lettres qui se suivent de la cha’1‘ne la plus
courte. On obtient ainsi un score de similarité de 1 entre << cl >> et << client >> ou entre
«inter » et « intervention >>, mais, par exemple, un score de 0,5 entre « tenir » et
<< intervention >>.

A l’aide d’une de ces deux mesures et d’un seuil (seuilmot), la méthode permet de
sélectionner des paires de mots candidats.

Etape 4 : les contextes vont ensuite permettre de déterminer si les deux mots candidats
seront considérés comme des variations orthographiques ou non. Comme le nombre de
contextes des mots peut varier fortement, il faut donc rester prudent sur le mode de
comparaison. Nous adaptons une des mesures de (Bourigault, 2002) et calculons le ratio
entre le nombre de contextes communs des deux mots et le nombre total de contextes du
mot le moins fréquent :

lcmot +fr équent n Cmot —fr équent

ratio =

|Cm0t —fr équent

Si ce ratio est supérieur a un seuil (seuilmmem), on considere qu’un lien existe entre
Inot-fréquent et Inot+ﬁéquent

Dans << corpus 100k >>, le mot << client >> possede au total 260 703 contextes (dont 13 974
différents), « cleint >> 235 contextes (dont 65 différents). << cleint » partage 224 contextes
avec « client » (sur 235 au total), soit un ratio de 0,95, d’ou la présence d’un lien entre
<< client >> et << cleint >>.

Au ﬁnal, on obtient :
— Une liste des mots qui n’ont pas de variation orthographique, soit parce qu’ils

n’en ont effectivement pas, soit parce que la méthode des contextes n’a pas
réussi a leur trouver des mots voisins.
— Un graphe de mots similaires orthographiquement et contextuellement.

A titre d’exemple, voici ce que peut donner une toute petite partie du graphe visualisé
avec le logiciel Gephi2, centré sur le mot << prélevement » :

K Mg“ 1 °'e@e°' "”'*?7“‘b1'@é".:s.eam.s
@ p®!  .\ p¢.,@,n.s
9 @pe.®prQn."'9“'  ‘ Mg“-i"".p«”é‘@‘;""

prengiewiq

195% Q   p@‘ prﬁm‘   "I ‘pral®ents
lies 3 ' 63‘, We rm prélegnenls

\ \ ‘Q! P V ;r\§i@uent
Q5 p®5  f@' praév

:85 2 p A‘ l
@ ‘‘ '°@'' 7 p@, 1  p|'@nt
@ gg   p@V *“@*'"'

FIGURE 1 — Graphe des mots voisins du mot << prélevement >>

4.2 Méthode 1 : semi-automatique et dictionnaire

Cette méthode consiste a utiliser le graphe précédent pour générer un dictionnaire de
substitution en détectant les patties connexes du graphe ou en appliquant un algorithme
de détection de communauté comme (Blondel, 2008). Au ﬁnal, on obtient des groupes de
mots que l’on présente a l’expert en les classant par ordre de fréquences décroissantes, ce
qui Va lui permettre de modiﬁer le dictionnaire de substitution de maniere experte en
fonction des connaissances qu’il a du domaine et des spéciﬁcités des données. En faisant
varier seuilmot et seuilmtem de maniere experte, il fera appara’1‘tre plus ou moins de mots
et de relations entre les mots.

Une fois ce dictionnaire de substitution élaboré, les textes a corriger sont parcourus,
caractere par caractere, et chaque fois qu’une suite de mots correspond a une entrée du
dictionnaire, elle est remplacée par sa forme canonique.

4.3 Méthode 2 : vers le tout automatique

Cette autre méthode est beaucoup plus ambitieuse puisqu’elle cherche a corriger,
automatiquement, les formes erronées en s’appuyant sur le réseau précédent. Pour
corriger une phrase comme : << le cliemnt veut changer d’abonnmnt>>, elle commence par
supprimer la ponctuation puis trouver les mots << candidats» a la substitution pour
chaque mot de la phrase :

— << le >>, << veut >>, << changer >> et << d >> font partie de la liste des mots qui n’ont pas
de variations ou appartiennent a une << stop liste », ils ne sont donc pas traités.
— « cliemnt » et « abonnment » font partie du réseau. Leurs substituants possibles

2 - Logiciel de manipulation, d'édition et de visualisation de graphes (http://gephi.org/)

sont calculés a partir du réseau : il s’agit des péres et ﬁls de ces mots.

Au ﬁnal, on obtient :

I le cliemnt veut I changer I d abonnment
client abonnement
cliente

TABLE 2 — Liste des mots candidats a la substitution

L’étape suivante consiste a trouver, parmi les mots candidats, ceux qui vont maximiser la
probabilité de rencontrer la phrase M, composée des mots mi, selon la formule suivante
(avec un lissage additif encore appelé << ajouter un » pour calculer la probabilité de
rencontrer m,- sachant mi_2 et mi_1(Beaufort, 2002), |V| étant la taille du vocabulaire) :

1 + nb(mi—2rmi—1,mi)
P(M) HP(mzImz—2mz—1) avec P(mzImz—2mz—1) IVI +nb(mi_2'mi_1'*)
Comme le décrit (Cucerzan, 2004), i1 s’agit d’un probléme d’optimisation locale: on
calcule si le fait de changer « cliemnt » en « client » augmente la probabilité de
l’ensemble. Ainsi, de maniére itérative, on corrige la phrase. On peut ensuite lancer
récursivement plusieurs corrections de la phrase, puisque le fait de corriger un mot Va
modiﬁer le contexte de ses mots voisins et peut-étre ainsi permettre des corrections lors
des itérations suivantes. Nous avons observé ce phénoméne, par exemple << recla » est
corrigé en « reclamation >> lors de la 1?“ correction, puis en << réclamation >> lors de la 2&1“
correction.

5 Résultats

Tous ces travaux se placent dans un contexte industriel. Il est donc nécessaire que les
calculs puissent se faire dans des temps << raisonnables ». Ce point est acquis puisque le
calcul du réseau de voisins sur le << corpus 100k >> est obtenu en quelques dizaines de
minutes sur un PC portable de moyenne gamme.

Pour ce qui est de la génération du dictionnaire de substitution a partir du graphe des
voisins (méthode 1), les premiers résultats montrent que le fait de pouvoir générer une
premiere version de ce dictionnaire que l’expert peut ensuite modiﬁer a la main est
appréciable, notamment pour assurer une large couverture des mots a corriger. Présenter
ces groupes de mots triés par nombre d’occurrences totales permet a l’expert de se
concentrer sur les formes erronées les plus importantes. Cette démarche a permis a
l’équipe EDF Commerce de détecter des mots, abréviations, formulations ou raccourcis
qui n’étaient pas pris en compte dans le processus actuel de correction.

Pour la méthode 2, entiérement automatisée, les résultats doivent étre améliorés,
notamment sur la maniére de ﬁxer les seuils. Cette méthode produit des erreurs :

— Sur les mots qui se ressemblent et qui partagent des contextes voisins comme
« peut/veut », << semestrielle/bimestrielle >> (employé dans « facture
semestielle|bimestrielle >>) ou encore << satisfait/insatisfait >> (<< client
satisfait|insatisfait »).
— Sur les mots dont l’orthographe erronée est aussi fréquente voire plus fréquente
que l’orthographe correcte comme pour les mots << recu » ou « cheque ».

6 Conclusion et perspectives

Nous avons présenté deux méthodes, l’une semi-automatique, l’autre entierement
automatisée, pour la correction de réclamations rédigées par des conseillers. En
construisant pour chaque mot un graphe des voisins orthographiques et contextuels,
nous avons montré comment détecter ses formes mal orthographiées aﬁn de construire
un dictionnaire de substitution. En utilisant celui-ci dans la premiere méthode semi-
automatique, nous avons amélioré le processus de normalisation des réclamations déja
existant. En outre, la deuxieme méthode entierement automatisée basée elle aussi sur les
contextes, semble intéressante mais nécessite, du fait de la sur-correction, une grande
vigilance. Néanmoins, ces travaux ne sont pas terminés et constituent le début de
développements et de tests notamment par le biais d’un corpus d’évaluation en cours
d’élaboration.

Références

BARANES, M. (2012). Vers la correction automatique de textes bruités : Architecture
générale et détermination de la langue d’un mot inconnu. In RECITAL'2012-Rencon1re des
Etudiants Chercheurs en Infomiatique pour le Traitement Automatique des Langues.

BEAUFORT, R., DUTOIT, T., 8: PAGEL, V. (2002). Analyse syntaxique du francais.
Pondération par trigrammes lissés et classes d’ambigui'tés lexicales. Proc. JEP, 133-136.

BLONDEL, V. D., GUILLAUME, J. L., LAMBIOTTE, R., & LEFEBVRE, E. (2008). Fast unfolding of
communities in large networks. Journal of Statistical Mechanics: Theory and Experiment,
2008(10), P10008.

BOURAOUI, J. L., BOISSIERE, P., MOJAHID, M., VIGOUROUX, N., LAGARRIGUE, A., VELLA, F., &
NESPOULOUS, J. L. (2009). Problématique d’analyse et de modélisation des erreurs en
production écrite. Approche interdisciplinaire. Actes de TALNRECITAL 2009.

BOURIGAULT, D. (2002, June). Upery : un outil d’analyse distributionnelle étendue pour la
construction d’ontologies a partir de corpus. In Actes de la 9éme conférence annuelle sur le
Traitement Automatique des Langues (TALN 2002), Nancy (pp. 75-84).

CUCERZAN, S., 8: BRILL, E. (2004, July). Spelling correction as an iterative process that
exploits the collective knowledge of web users. In Proceedings of EMNLP (Vol. 4).

DAMERAU, F. J. (1964). A technique for computer detection and correction of spelling
errors. Communications of the ACM, 7(3), 171-176.

GREFENSTETTE, G. (1994). Explorations in automatic thesaurus discovery. Springer.

LI, M., ZHANG, Y., ZHU, M., 8: ZHOU, M. (2006, July). Exploring distributional similarity
based models for query spelling correction. In Proceedings of the 21st International
Conference on Computational Linguistics and the 44th annual meeting of the Association for
Computational Linguistics (pp. 1025-1032). Association for Computational Linguistics.

