
Apprentissage supervisé pour l’identification de relations
sémantiques au sein de structures énumératives parallèles

Jean-Philippe Fauconnier1 Mouna Kamel1 Bernard Rothenburger1
Nathalie Aussenac-Gilles1
(1) IRIT, 118 route de Narbonne 31060 Toulouse Cedex 5
{prénom}.{nom}@irit.fr

RÉSUMÉ
Ce travail s’inscrit dans le cadre de la construction et l’enrichissement d’ontologies à partir
de textes de type encyclopédique ou scientifique. L’originalité de notre travail réside dans
l’extraction de relations sémantiques exprimeés au-delà de la linéarité du texte. Pour cela, nous
nous appuyons sur la sémantique véhiculeé par les caractères typo-dispositionels qui ont pour
fonction de suppleér des formulations strictement linguistiques qui seraient plus difficilement
exploitables. L’étude que nous proposons concerne les relations sémantiques porteés par les
structures énumératives parallèles qui, bien qu’affichant des discontinuités entre ses différents
composants, présentent un tout sur le plan sémantique. Ce sont des structures textuelles qui sont
propices aux relations hiérarchiques. Après avoir défini une typologie des relations porteés par ce
type de structure, nous proposons une approche par apprentissage visant à leur identification.
Sur la base de traits incorporant informations lexico-syntaxiques et typo-dispositionnelles, les
premiers résultats aboutissent à une exactitude de 61,1%.
ABSTRACT
A Supervised learning for the identification of semantic relations in parallel enumerative
structures
This work falls within the framework of ontology engineering and learning from encyclopedic or
scientific texts. Our original contribution lies within the extraction of semantic relations expressed
beyond the text linearity. To this end, we relied on the semantics behind the typo-dispositional
characters whose function is to supplement the strictly linguistic formulations that could be
more difficult to exploit. The work reported here is dealing with the semantic relations carried
by the parallel enumerative structures. Although they display discontinuities between their
various components, these enumerative structures form a whole at the semantic level. They
are textual structures that are prone to hierarchic relations. After defining a typology of the
relationships carried by this type of structure, we are proposing a learning approach aimed at their
identification. Based on features including lexico-syntactic and typo-dispositional informations,
the first results led an accuracy of 61.1%.
MOTS-CLÉS : extraction de relations, structures énumératives parallèles, mise en forme maté-
rielle, apprentissage supervisé, construction d’ontologies.
KEYWORDS: relationship extraction, parallel enumerative structures, material shaping, supervi-
sed learning, ontology learning.
1    Introduction

La construction d’ontologies est un processus fastidieux qui nécessite la contribution d’experts
d’un domaine. Une manière de rendre ce processus moins coûteux consiste à exploiter automati-
quement certains types de textes, comme les textes de nature encyclopédique ou scientifique,
afin d’en extraire les connaissances. Généralement, cette exploitation de textes s’appuie sur des
analyses statistiques et/ou des analyses linguistiques essentiellement focaliseés sur les niveaux
lexicaux et syntaxiques. Citons notamment l’approche par apprentissage automatique (Nédellec
et al., 2009), l’utilisation de patrons (Giuliano et al., 2006) ou encore une approche hybride
combinant les deux (Giovannetti et al., 2008).
Cependant, ces approches souffrent de deux limites : (1) l’analyse se situe en général à un niveau
intraphrastique ou, du moins, textuellement linéaire et (2) l’extraction de connaissances se base
sur des indices syntaxiques sans prendre en compte les caractéristiques de mise en forme du
texte. Or, il existe des relations qui se matérialisent au travers de marqueurs paralinguistiques
(marqueurs typographiques et/ou dispositionnels). Ces derniers, dépassant leur rôle de mise en
forme, sont des éléments structurants porteurs de sémantique. (Virbel et al., 2005) théorise ces
marqueurs et leur utilisation au sein de la notion de mise en forme matérielle (MFM). Des analyses
linguistiques fines ont mis en évidence le rôle fondamental de celle-ci dans l’interprétation d’un
texte et dans la caractérisation de certains objets textuels tels que les titres (Rebeyrolle et al.,
2009), les définitions (Pascual et Péry-Woodley, 1995) et les structures énumératives (Luc, 2001).
Pour améliorer la construction d’ontologies, nous nous intéressons aux structures énumératives
(SE) parallèles avec MFM. En tant que SE, elles sont porteuses de connaissances hiérarchiques.
Leur caractère parallèle implique une composition homogène d’un point de vue grammatical,
typo-dispositionnel et fonctionnel. Elles disposent souvent des propriétés textuelles qui les rendent
visuellement perceptibles et ces propriétés sont suffisamment stables pour que leur repérage
automatique puisse être envisagé (Ho-Dac et al., 2012). Enfin, leur fréquence au sein des textes
scientifiques, procéduraux ou encyclopédiques reste éleveé.
Les approches précédentes (Kamel et Rothenburger, 2011; Kamel et al., 2012) ont montré
les limites d’une approche symbolique pour l’extraction des relations sémantiques au sein des
SE. Dans cet article, nous proposons deux méthodes par apprentissage supervisé. La première
combine des traits linguistiques et paralinguistiques et la seconde repose sur des trigrammes. Ce
travail est une première étape vers l’exploitation de SE pour la construction d’ontologies.
La section 2 introduit les SE. La section 3 présente les classes de relations, le corpus ainsi que
le mode d’évaluation. La section 4 décrit le classifieur d’entropie maximale (MaxEnt) ainsi que
les deux approches. La section 5 présente les résultats obtenus par validation croiseé. Enfin, la
conclusion revient sur l’intérêt de ce travail et esquisse quelques perspectives.
2    Les structures énumératives

L’acte d’énumération consiste à regrouper des éléments indépendants sous un même critère
d’homogénéité (Pery-Woodley, 2001). La forme générale d’une structure énumérative (SE) est
caractériseé par une amorce, une énumération composeé d’au moins deux items et éventuellement
une clôture (ou conclusion). Cette structure logique générique peut se décliner concrètement
par des dispositifs linguistiques ou textuels différents. Elle peut être énonceé au fil du texte en
dehors de toute mise en forme matérielle (MFM) et dans ce cas les items sont introduits par des
marqueurs lexicaux qui sont souvent des groupes adverbiaux (par exemple « premièrement »,
« deuxièmement », « troisièmement » dans (1)), ou au contraire être mise en évidence par l’usage
de marqueurs typographiques et dispositionnels spécifiques (comme les caractères de ponctuation,
les retraits, les tirets dans (2)).
(1) Comment faire pour économiser 68% d’électricité par rapport à une dépense habituelle ?
Premièrement, en éteignant la lumière dès votre sortie d’une pièce. Cela peut paraître
banal, mais ça ne l’est absolument pas. Deuxièmement, évitez les lampes halogènes, car
une lampe halogène de 500 watts consomme l’équivalent de 23 lampes. Troisièmement,
essayez de remplacer les lampes traditionnelles par des lampes basse consommation.
(2) Les formes de communication non parleés sont :
– le langage écrit,
– le langage des signes,
– le langage sifflé.
Il existe plusieurs définitions de l’énumération. La définition qui nous semble le mieux prendre
en compte à la fois les phénomènes architecturaux du texte et l’intention de l’auteur est celle
proposeé par (Virbel, 1999) : « énumérer mobilise deux actes : un acte mental d’identification
des éléments d’une réalité du monde dont on vise un recensement, et où on établit une relation
d’égalité d’importance par rapport au motif de recensement ; et un acte textuel qui consiste à
transposer textuellement la coénumérabilité des entités recenseés, par la coénumérabilité des
segments linguistiques qui les décrivent. ».
(Luc, 2001) a établi une typologie des SE permettant de distinguer les structures homogènes
vs. hétérogènes, les structures syntagmatiques vs. paradigmatiques, et les structures isoleés vs.
non isoleés. Les structures hétérogènes présentent des items ayant des propriétés visuelles non
équivalentes et sont plus difficilement repérables automatiquement en corpus. Les structures
syntagmatiques entretiennent des liens de dépendance entre les items, et les structures non
isoleés entretiennent des relations avec des unités textuelles localiseés en dehors de la structure
énumérative. Les SE paradigmatiques, homogènes et isoleés sont dites parallèles.
FIGURE 1 – Représentations sémantiques de la structure énumérative

Notre étude se focalise ici sur la SE parallèle car son analyse rhétorique (baseé, par exemple, sur
les principes de la RST (Carlson et al., 2001)) permet d’établir une relation noyau-satellite qui relie
l’amorce (unité d’information la plus saillante) à l’énumération (unité d’information qui supporte
l’information d’arrière-plan), et une relation multi-nucléaire qui relie les items (arguments de
même importance). La relation noyau-satellite sera généralement de type elaboration et la
relation multi-nucléaire de type list. Une relation hiérarchique entre l’amorce et chacun des items
est ainsi mise en évidence. Dans ce cadre, nous envisageons de traduire cette structure rhétorique
en une structure hiérarchique où les entités conceptuelles dénoteés par des termes présents dans
les segments textuels seraient extraites et relieés par la relation de type noyau-satellite identifieé
en discours (Figure 1).
Identifier les relations porteés par les SE parallèles avec MFM est l’objet de ce travail, car elles ont
les propriétés (1) d’être homogènes et de bénéficier de traits de formatage assez réguliers pour
que d’une part leur identification automatique en corpus puisse être envisageé, et que d’autre
part les aspects typo-dispositionnels permettent de spatialiser le discours, et donc d’aider à la
désambiguïsation, et (2) d’être paradigmatiques et isoleés, ce qui assure l’unicité de la relation
porteé par la structure. Les processus d’identification des SE en texte ainsi que des concepts et
instances au sein de ces dernières font l’objet de travaux complémentaires non discutés dans
cet article. L’approche que nous développons ici est endogène dans le sens où les indices qui
permettent d’identifier la relation sont recherchés au sein de la SE.
3     Classes, corpus et mode d’évaluation

3.1    Classes

L’arbre issu de l’analyse rhétorique (Figure 1) révèle souvent l’existence de connaissances ontolo-
giques ou lexicales porteés par la SE parallèle. Le but de ce travail est de détecter automatique-
ment la nature de la relation unique entre l’amorce et les items, lorsque cela est possible.

Classes               Description
isA                   Relation hiérarchique d’hyperonymie.
partOf                Relation hiérarchique de méronymie.
instanceOf            Relation entre un concept et les instances de ce
concept.
autreOntologique      Relations non-taxonomiques (e.g : isCauseOf, re-
quires, etc.).
lexical               Relation lexicale entre termes (homonymie, syno-
nymie, etc.).
autres                Cas ambigus et relations que l’on ne peut résoudre.

TABLE 1 – Annotation du corpus en 6 classes par 4 annotateurs

Pour transformer notre problème d’identification de relations en un problème de classification
multi-classes, nous avons défini des classes correspondant aux relations rechercheés. Nous distin-
guons 6 classes (Table 1) : isA, partOf, instanceOf, autreOntologique, lexical et autres.
À proprement parler, toutes les relations que nous désirons identifier sont lexicales, en ce sens
qu’elles lient des termes au sein du texte. Cependant, dans leur dénomination, nous différencions
les relations par le rôle qu’elles peuvent jouer, a posteriori, au sein d’une ressource sémantique.
Par exemple, bien que les classes isA (exemple (2)) et partOf désignent les relations d’hyperony-
mie et de méronymie dans le domaine terminologique, nous nous référons à ces dernières sous
l’appellation usiteé dans le domaine des ontologies.
La classe autreOntologique comprend les relations non-taxonomiques entre concepts
(exemple (3)). La classe lexical reprend les relations lexicales (synonymie, homonymie, etc.) et,
éventuellement, les cas d’inclusion lexicale.
(3) Tous les barrages classés (A, B, C et D) doivent disposer :
– d’une consigne de crue ;
– d’un dispositif d’auscultation adapté.
La classe autres regroupe les cas ambigus, tels que ceux présentés par les SE navigationnelles et
de titraille, et les relations que l’on ne peut résoudre. L’exemple (4) donne une SE de titraille qui
structure un propos, un document. L’exemple (5) reprend une SE à viseé navigationnelle, cas
courant dans les ressources informatiseés qui utilisent des liens hypertextes (indiqués ici par la
mise en gras). Les liens hypertextes nous indiquent qu’il y a une plus grande probabilité que la
relation porteé par la SE lie des documents et non pas des termes. Enfin, l’exemple (6) présente
un cas où il s’agit d’une élaboration argumentative et non ontologique.

(4) Présentation                                  (5) Transports en commun
1 Fonctionnement                                  – Portail des transports en commun
2 Terminologie                                    – Portail du chemin de fer
(6)   Le transformateur d’isolement comporte deux enroulements presque identiques au
primaire et au secondaire :
– le nombre de spires du secondaire est souvent très légèrement supérieur au nombre de
spires du primaire afin de compenser la faible chute de tension en fonctionnement ;
– en théorie, les sections de fil au primaire et au secondaire sont identiques, car
l’intensité des courants est la même.
3.2     Corpus

Les donneés utiliseés dans notre travail sont issues des travaux de (Kamel et Rothenburger, 2011)
visant l’enrichissement de l’ontologie OntoTopo, construite dans le cadre de l’ANR GEONTO 1 .
Cette ontologie modélise les domaines de l’aménagement urbain, l’environnement et l’organi-
sation territoriale. (Kamel et Rothenburger, 2011) ont construit leur corpus en projetant les
concepts de l’ontologie OntoTopo sur les pages de Wikipédia et en extrayant, dans les pages ainsi
retenues, les SE parallèles rencontreés. Par leur caractère encyclopédique, les pages Wikipédia
ordonnent de nombreuses définitions et propriétés au moyen de marqueurs typo-dispositionnels.
Le nombre relativement élevé de SE parallèles par page s’explique notamment par la recomman-
dation du « Manuel of Style » de Wikipédia 2 qui préconise une forme grammaticale identique
pour tous les items d’une SE. Au final, 2317 SE furent extraites de 276 pages.
À partir de ce travail, nous avons construit deux corpus respectivement nommés CORPUS_SE
et CORPUS_DISTRIB. Ces derniers reprennent 1000 SE annoteés par quatre annotateurs : deux
ingénieurs de la connaissance, un ergonome et une étudiante. La tâche d’annotation a consisté
à classer parmi les six classes définies en section 3.1 la relation sémantique porteé par la SE
parallèle. Un κ de Fleiss (Fleiss et al., 1979), sous l’hypothèse nulle de jugements indépendants,

1. Collaboration entre le COGIT, le LRI, le LIUPPA et l’IRIT - http://geonto.lri.fr/
2. http://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style
présente un accord inter-annotateurs, relativement correct pour six classes 3 , de 0,559 (Table
2). Notons que la corrélation entre les deux ingénieurs de la connaissance est nettement plus
grande (0,686). Seule la classe autreOntologique présente un accord relativement bas (0,299) qui
s’explique par ses caractéristiques formelles peu stables. En cas de désaccord dans l’annotation,
la classe finale d’une SE est décideé par consensus entre les différents annotateurs.

Classe                  Kappa           Var          Z-score   p-score      IC 95%
isA                      0,509      0,001033         15,859    < 1E-09   [0,446 ;0,572]
partOf                   0,493      0,001275         13,808    < 1E-09   [0,423 ;0,563]
autreOntologique         0,299      0,000945         09,735    < 1E-09   [0,238 ;0,359]
instanceOf               0,652      0,000975         20,895    < 1E-09   [0,591 ;0,713]
lexical                  0,636      0,000974         20,392    < 1E-09   [0,575 ;0,697]
autres                   0,641      0,001369         17,323    < 1E-09   [0,568 ;0,713]
Corpus                   0,559      3,112E-05        100,269   <1E-09    [0,548 ;0,570]

TABLE 2 – Annotation du corpus en 6 classes par 4 annotateurs

Les deux corpus ont été étiquetés grammaticalement et morpho-syntaxiquement par l’outil
Talismane (Urieli et Fauconnier, 2012) entraîné sur le French TreeBank (Abeillé et al., 2003)
dans sa version en dépendances (Candito et al., 2009). CORPUS_SE totalise 1000 SE et comprend
80 774 tokens. Ces 1000 SE présentent en moyenne 4,31 items par individu. Afin d’évaluer notre
méthode sur sa capacité à identifier la relation entre une amorce et un item, nous avons construit
le corpus CORPUS_DISTRIB en distribuant, pour chaque SE de CORPUS_SE, son amorce sur les n
items qu’elle contient afin de construire n paires amorce-item. CORPUS_DISTRIB totalise 4317
paires amorce-item et comprend 119 272 tokens.
Dans CORPUS_SE, la répartition des SE dénote un déséquilibre entre la classe autres et le reste des
classes (Figure 2). Un autre déséquilibre apparaît au niveau du nombre d’items de chaque SE
(Table 3). La classe instanceOf contient des SE avec un nombre d’items supérieur à 20, dont l’une
énumère plus de soixante types de sports collectifs. Avec une moyenne de 6,95 items par SE, la
classe instanceOf est celle qui présente les valeurs les plus extrêmes, suivie par la classe isA avec
une moyenne de 4,25 items par SE. Ce déséquilibre entre les items influence la répartition des
paires amorce-item au sein de CORPUS_DISTRIB (Figure 2).
FIGURE 2 – Répartition des SE dans          CORPUS _ SE   et des paires amorce-item dans   CORPUS _ DISTRIB
3. Le κ de Fleiss est sensible aux nombres de catégories.
Classe                  SE      Nb. items    min-max       Moyenne        σ        IC 95%
isA                    229         973         2 - 20       4,25        2,71     [3,90 ;4,60]
partOf                  42         173         2 - 11       4,12        1,89     [3,53 ;4,71]
autreOntologique        76         299         2- 10        3,93        1,84     [3,51 ;4,36]
instanceOf             177        1231         2 - 63       6,95        6,99     [5,92 ;7,99]
lexical                 96         377         2 - 14       3,93        2,03     [3,52 ;4,34]
autres                 380        1264         2 - 13       3,33        1,76     [3,15 ;3,50]
Total                  1000       4317         2 - 63       4,31        3,72     [4,07 ;4,54]

TABLE 3 – Nombre d’items par classes
3.3    Mode d’évaluation

Rappelons que les SE parallèles présentent la particularité que chaque item est relié à l’amorce
par une même relation (Section 2). Par conséquent, il est possible d’identifier la relation entière
porteé par une SE si la relation entre son amorce et l’un de ses items est identifieé.
Dans cet objectif, nous proposons deux méthodes de classification par apprentissage supervisé.
La première méthode utilise des traits linguistiques et paralinguistiques. La seconde repose sur
des trigrammes de tokens. En outre, nous posons une baseline naïve qui classe tous les individus
dans la classe majoritaire autres.
Les deux méthodes ainsi que la baseline ont été évalueés dans trois tâches :
– La tâche 1 vise à la classification des SE issues de CORPUS_SE (1000 SE à classer). Dans la
figure 1, il s’agit de classer la SE en identifiant la relation entre l’amorce et l’item1 .
– La tâche 2 vise la classification des paires amorce-item de CORPUS_DISTRIB (4317 paires à
classer). Dans la figure 1, il s’agit de classer les relations unissant amorce-item1 , amorce-item2
et amorce-item3 .
– La tâche 3 vise la classification des SE de CORPUS_SE à partir de la moyenne des prédictions de
leurs paires amorce-item issues de CORPUS_DISTRIB (1000 SE à classer à partir des prédictions de
4317 paires). Dans la figure 1, il s’agit de classer la SE en calculant la moyenne des prédictions
de amorce-item1 , amorce-item2 et amorce-item3 .
Pour les trois tâches (et les 9 évaluations correspondantes), nous procédons à une validation
croiseé à 10 échantillons et mesurons l’exactitude (micro-average) pour la classification toutes
classes confondues ainsi que rappel, précision et F-mesure pour chacune des classes :
�C �             �
i V Pi + V Ni
exactitude = �C �                             �
i V Pi + V Ni + F Pi + F Ni

V Pi                       V Pi                   précisioni rappeli
précisioni =                  rappeli =                  F1i = 2
V Pi + F Pi                V Pi + F Ni              précisioni + rappeli
où V Pi , V Ni , F Pi et F Ni sont respectivement le nombre de Vrais Positifs, Vrais Négatifs, Faux
Positifs et Faux Négatifs de classes i à C où C est le nombre de classes. L’exactitude permet
d’évaluer la capacité prédictive d’un modèle en donnant un poids proportionnel à chaque classe.
Nous donnons aussi un écart type qui, selon (Kohavi et al., 1995), peut être estimé (où N est le
nombre d’individus) :                  �
exactitude (1 − exactitude)
σ=
N

4      Le modèle d’apprentissage

4.1      Maximum d’entropie

Pour notre tâche de classification, nous avons adopté un modèle conditionnel d’entropie maxi-
male, dit aussi MaxEnt (Berger et al., 1996). Ce modèle, qui a déjà fait ses preuves en TAL, permet
de gérer de manière flexible un grand nombre de traits et repose sur le principe de maximisation
d’entropie. Ce dernier vise à définir une contrainte pour chaque information observeé et choisir
la distribution qui maximise l’entropie tout en restant consistante vis-à-vis de l’ensemble de ces
contraintes (Jaynes, 1957). Dans ce cadre d’optimisation sous contraintes, il est mathématique-
ment prouvé qu’une solution unique existe et un algorithme itératif garantit la convergence vers
cette dernière (Ratnaparkhi, 1996). La forme classique du MaxEnt est la suivante :
�                     �
1         � n
P( y|x) =       exp        w i f i (x, y)
Z(x)        i=1

où P( y|x) désigne la probabilité que l’individu x, ici une SE ou une paire amorce-item, appar-
tienne à la classe y (e.g : isA, partOf, etc.). La fonction f i est une fonction binaire appeleé trait
qui permet de définir les contraintes du modèle. Z(x) est une constante de normalisation qui
assure que la somme des probabilités retourneés pour un individu soit équivalente à 1. Chaque
individu x est encodé comme un vecteur avec n traits f i . Le paramètre w i , dit aussi poids, de
chaque trait associe à chaque individu une probabilité d’appartenance à une classe.
En pratique, le calcul de cette maximisation s’effectue au travers de différents algorithmes tels
que le Generalized Iterative Scaling (GIS) (Darroch et Ratcliff, 1972) ou l’Improved Iterative Scaling
(IIS) (Berger et al., 1996). Dans notre travail, nous utilisons l’implémentation Apache OpenNLP
MaxEnt 4 qui applique un GIS sans correction feature tel que recommandé par (Curran et Clark,
2003).
4.2      Approche par traits

Comme présenté dans la section 2, les SE parallèles sont des objets textuels qui conjuguent
marqueurs de MFM et propriétés lexico-syntaxiques partiellement stables. La première approche
proposeé tente de capturer leurs régularités au moyen de deux familles de traits : (1) la première
emploie les informations lexico-syntaxiques extraites de l’analyse des tokens et de leur rôle au sein
de l’arbre de dépendances et (2) la deuxième famille reprend des informations paralinguistiques,
dans ce cas-ci typographiques. La table 4 présente, de manière synthétique, les différents traits.
La distinction entre les deux familles de traits est graduelle et certains traits reprennent des
informations combinant les deux sources. Par exemple, avec un seuil de sélection de traits
paramétré à 5 apparitions dans le corpus 5 , le trait LastTokenPos renvoie dans la majorité des cas
l’étiquette PONCT, car amorces et items ont tendance à être clôturés par une ponctuation.
Les traits HasClassifier, HasMeronym et HasCircumstant sont calculés en projetant des patrons sur
les SE. Ces derniers, comme l’ensemble des traits, sont issus d’intuitions linguistiques. Une étude
approfondie de leurs poids respectifs fera l’objet de travaux ultérieurs.
4. http://opennlp.apache.org/
5. Ce seuil de sélection des traits est appelé cut-off dans la littérature relative au MaxEnt.
Éléments    Traits                Phénomènes captés
(First|Last)Token     Retourne respectivement la catégorie grammaticale et le
(Pos|Lem)             lemme du dernier/premier token de l’amorce.
Amorce      HasClassifier         Présence d’un classifieur (« sortes de », « types de », etc.)
HasMeronym            Présence d’un marqueur de méronymie (« parties de », etc.)
HasVerb               Présence d’un verbe conjugué ou un verbe au participe passé
à la racine de l’arbre de dépendances.
HasProperNoun        Présence d’un nom propre.
HasPlurarlNoun       Présence d’un nom commun au pluriel.
MultiplSentence      Présence de plusieurs phrases dans l’amorce.
(First|Last)Token     Retourne respectivement la cat. gram. et lemme du der-
(Pos|Lem)             nier/premier token de l’item.
HasVerb               Présence d’un verbe conjugué ou un verbe au participe passé
Item                             à la racine de l’arbre de dépendances.
HasProperNoun        Présence d’un nom propre.
HasDate              Présence d’une date en anneés et considéreé comme NC
(« 1996 », etc.)
HasCircumstant        Présence d’un circonstant (« En Belgique », etc.)
StartsWithINF         Présence d’un infinitif en début de phrase.
StartsWithNUM         Présence d’un numéro en début d’item.
StartsWithMaj         Présence d’une majuscule en début d’item.
ContainsPonct         Présence d’une ponctuation inhabituelle au sein de l’item.
MultiplSentence       Présence de plusieurs phrases dans l’item.

TABLE 4 – Tableau synthétique des traits utilisés
La SE en (7) de classe isA exemplifie l’application de traits. Les tokens entre crochets sont
ceux auxquels s’appliquent les traits (First|Last)Token(Pos|Lem). Les éléments en gras sont le
classifieur et le verbe souligné répond au trait HasVerb. L’absence d’autres phénomènes (nom
propre dans l’amorce, etc.) est tout autant informative pour la classification de la SE.
(7) [Pour] un transformateur triphasé, il existe 3 types de couplage d’enroulement [ :]
– [le] couplage étoile, défini par la lettre Y [ ;]
– [le] couplage triangle, défini par la lettre D ou ∆[ ;]
– [le] couplage zig-zag, défini par la lettre Z[.]
L’exemple (8) présente un cas issu de la classe autres où l’on voit que la présence d’un infinitif en
début d’item (indiqués ici par la mise en gras) est un indice des SE procédurales.
(8) Le déroulement
1 [Mélanger] la farine, le sucre, le sucre vanillé, les œufs, l’huile et le lait [.]
2 [Verser] la pâte dans la poêle et retourner la crêpe avec une spatule [.]
4.3    Approche par trigrammes

La deuxième approche proposeé vise à identifier les relations sémantiques au sein des SE
parallèles au moyen de trigrammes. Chaque token est étiqueté soit par sa catégorie grammaticale
seule, soit par sa forme lemmatiseé associeé à sa catégorie grammaticale. L’ajout de la catégorie
grammaticale au lemme permet de diminuer les cas d’ambiguïté. Par ce choix, nous pouvons
distinguer, par exemple, plat-ADJ vs. plat-NC. Pour chaque séquence de trois tokens, nous avons
23 trigrammes différents. Par exemple, pour la séquence « Le chat noir », les trigrammes suivants
sont calculés : « le-DET chat-NC noir-ADJ », « DET chat-NC noir-ADJ », . . ., « DET NC ADJ ». Ces
trigrammes sont appliqués de manière identique sur l’amorce et les items.
5    Résultats

Pour les trois tâches, nous avons procédé à une validation croiseé (k=10) et présentons les
résultats en termes d’exactitude (Table 5).

Approches         Exactitude          σ          IC 95%
Traits ling.        61,10%          0,0154    [58,08 ;64,11]
Tâche 1
Trigrammes          59,80%          0,0155    [56,76 ;62,83]
Baseline autres     38,00%          0,0153    [35,00 ;40,99]
Traits ling.        58,70%          0,0074    [57,25 ;60,15]
Tâche 2
Trigrammes          59,50%          0,0074    [58,04 ;60,95]
Baseline autres     29,30%          0,0069    [27,94 ;30,65]
Traits ling.        58,50%          0,0155    [55,46 ;61,53]
Tâche 3
Trigrammes          59,00%          0,0155    [55,96 ;62,03]
Baseline autres     38,00%          0,0153    [35,00 ;40,99]

TABLE 5 – Évaluation pour les trois tâches

Au regard de cette dernière, nous constatons que, pour les trois tâches, l’approche par traits et
l’approche par trigrammes aboutissent significativement à de meilleurs résultats face à la baseline
autres. Par contre, la comparaison des deux approches est à nuancer. Contrairement aux tâches
2 et 3, l’approche par traits dépasse de peu les trigrammes dans la tâche 1, mais les intervalles
de confiance nous montrent qu’il y a un possible recouvrement entre ces résultats. Cependant,
l’exactitude, qui donne un poids proportionnel à chaque classe (section 3.3), ne révèle pas les
difficultés éprouveés par les trigrammes pour classer les individus des classes minoritaires partOf
et autreOntologique dans les trois tâches. Ces derniers sont souvent classés à tort dans les classes
autres, instanceOf ou isA qui, dans les deux corpus, sont les classes majoritaires. La comparaison
des matrices de confusion issues des deux approches pour la tâche 1 l’exemplifie (Tables 6 et 7).

autrOnto    autres   instOf    isA     lexical    partOf    Précision   Rappel   F1
autrOnto     13          16        5       41          1       0         0,54      0,17     0,26
autres        6         298       29       46          0       1         0,63      0,78     0,70
instOf        0          42      120        9          6       0         0,66      0,68     0,67
isA           5          88        8      120          5       3         0,46      0,52     0,49
lexical       0          12       13       23         47       1         0,80      0,49     0,61
partOf        0          14        8       20          0       0         0,00      0,00     0,00

TABLE 6 – Matrice de confusion pour la Tâche 1 : Trigrammes
autrOnto    autres    instOf    isA   lexical   partOf     Précision    Rappel     F1
autrOnto      25         11         3      29       6         2         0,40        0,33     0,36
autres        10        300        18      37      15         0         0,70        0,79     0,74
instOf         6         20       113      29       5         4         0,70        0,64     0,67
isA           11         66        13     127      12         0         0,50        0,55     0,53
lexical        6         23        12      15      40         0         0,50        0,42     0,45
partOf         4         10         3      17       2         6         0,50        0,14     0,22

TABLE 7 – Matrice de confusion pour la Tâche 1 : Traits linguistiques

Ainsi, de manière transversale, l’approche par traits linguistiques reste toujours préférable à
l’approche par trigrammes car elle discrimine mieux les classes minoritaires partOf et autreOnto-
logique, utiles à la construction de ressources sémantiques.
Les résultats obtenus avec l’approche par traits linguistiques dans les tâches 2 et 3 aboutissent à
une identification correcte des classes utiles à la construction d’ontologies, c’est-à-dire toutes les
classes sauf autres (Tables 8 et 9). Seules les F-mesures des classes instanceOf et isA diminuent
entre la deuxième et la troisième tâche. Une difficulté à classer correctement les nombreux items
de ces deux classes (Section 3.2) expliquerait cette diminution des scores.

autrOnto    autres    instOf    isA   lexical   partOf     Précision    Rappel     F1
autrOnto      94         37        12     111       37        8         0,36        0,31     0,34
autres        35        859       100     195       61       14         0,61        0,68     0,65
instOf        49        140       819      96      104       23         0,76        0,67     0,71
isA           59        244        77     543       31       19         0,52        0,56     0,54
lexical       15         81        50      41      173       17         0,41        0,46     0,43
partOf         8         37        13      54       14       47         0,37        0,27     0,31

TABLE 8 – Matrice de confusion pour la Tâche 2 : Traits linguistiques
autrOnto    autres    instOf    isA   lexical   partOf     Précision    Rappel     F1
autrOnto      22         10         4      31       8         1         0,36        0,29     0,32
autres        11        289        16      50      12         2         0,68        0,76     0,72
instOf         6         29       100      25      15         2         0,70        0,56     0,63
isA           16         65         9     118      13         8         0,47        0,52     0,49
lexical        5         23        11       9      44         4         0,46        0,46     0,46
partOf         1         8          2      16       3        12         0,41        0,29     0,34

TABLE 9 – Matrice de confusion pour la Tâche 3 : Traits linguistiques

En comparant la tâche 1 et la tâche 3 dans l’approche par traits linguistiques, les résultats
suggèrent que l’identification de la relation entre l’amorce et le premier item est à ce jour la
meilleure approche, surtout lorsque les SE présentent un grand nombre d’items (cf. instanceOf
et isA). Seule la F-mesure de la classe partOf est significativement plus haute dans la tâche 3.
Ce phénomène pourrait s’expliquer par le fait que certaines SE de cette classe présentent un
premier item avec du texte rédigé et non un simple syntagme nominal (exemple (9)). Ce type de
variation réduit les performances lorsque l’approche se limite au premier item (Tâche 1).
(9) Les installations de la centrale électrique comprennent :
– un ou plusieurs postes électriques permettant la connexion au réseau électrique par
l’intermédiaire d’une ou plusieurs lignes à haute tension ainsi qu’une interconnexion
limiteé entre tranches,
– les bâtiments administratifs,
– les bâtiments techniques,
– le magasin général.
D’un point de vue qualitatif, les résultats ont aussi montré que, malgré une approche qui se veut
fine et linguistique, il reste difficile de classer les individus où il y a ellipse de constituants au
sein de leur amorce. Ces amorces incomplètes, tant syntaxiquement que lexicalement, sont un
phénomène courant dans les documents numériques où la mise en page et les traits de formatage
suppleént l’aspect lexico-syntaxique (Bush, 2003). Par exemple, la SE en (10) de classe partOf est,
dans toutes les tâches, classeé à tort dans la classe autres. L’absence de marqueurs de méronymie
et de ponctuations ainsi que la présence de numéros en début d’item rendent difficile à distinguer
cet individu d’une SE de titraille.
(10) Système de la cordillère américaine
1 Montagnes rocheuses
2 Chaînes côtières du Pacifique
3 Cordillère des Andes
Plusieurs stratégies sont envisageables pour contourner ce type de difficulté : (1) entreprendre
une approche exogène du problème afin de capter des indices qui se trouvent en-dehors des
SE, (2) étudier davantage l’utilisation de traits paralinguistiques (e.g : changement de police,
présence de liens hypertextes dans les items, etc.) ou (3) identifier les concepts et instances déjà
représentés dans l’ontologie en cours de construction et les utiliser comme de nouveaux indices
pour mieux discriminer les classes de relations.
6    Conclusion

Dans cet article, nous avons défini un premier ensemble de classes des relations sémantiques
porteés par les SE et avons souligné leur intérêt dans la construction de ressources sémantiques.
Dans ce cadre, nous avons proposé deux approches par apprentissage supervisé afin d’identifier
ces relations. La première utilise des traits lexico-syntaxiques et paralinguistiques et la seconde
aborde la classification au moyen de trigrammes. Les résultats montrent l’insuffisance de cette
dernière pour capter des régularités pertinentes au sein des SE, notamment pour les classes
minoritaires partOf et autreOntologique. La comparaison entre la tâche 1 et la tâche 3 suggère
une meilleure classification des SE en se limitant à l’identification de la relation entre l’amorce et
le premier item. Notons que, lors de nos expérimentations, l’augmentation du seuil de sélection
des traits dans les tâches 2 et 3 a abouti à des scores plus élevés. Les causes de cette amélioration
feront l’objet de travaux ultérieurs.
À terme, l’identification des relations au sein des SE s’inscrit dans un projet plus large visant, en
amont, leur repérage automatique, comme cela a déjà été entrepris par (Morin, 1999), et, en
aval, la construction d’une ontologie. Adjointe à un système d’extraction de relations au niveau
intraphrastique, notre approche permettrait d’augmenter le rappel pour la tâche d’identification
des relations en texte.
Par ailleurs, nos travaux ont aussi soulevé des pistes de réflexion au niveau du problème
de classification en lui-même. Premièrement, il serait intéressant d’utiliser d’autres modèles
d’apprentissage, tels que les CRF ou SVM, afin de mesurer l’influence, à traits égaux, du classifieur
utilisé. Deuxièmement, il nous est apparu que la classe autres représentait avant tout une classe
« par défaut » plutôt qu’un reél regroupement de relations et que peu de traits parvenaient
à la discriminer correctement. Certaines méthodes de classification multi-classes préconisent
l’utilisation de multiples modèles binaires et/ou la mise en place d’un seuil statique ou dynamique
sur les probabilités d’appartenance. Une perspective à ce travail consisterait à établir un certain
seuil en deçà duquel les individus seraient classés dans une catégorie sansRelation. Enfin, il serait
utile de procéder à un sur-échantillonnage des classes minoritaires afin de comparer l’influence
de la distribution des individus au sein de notre corpus.
Références
ABEILLÉ, A., CLÉMENT, L. et TOUSSENEL, F. (2003). Building a treebank for french. Treebanks,
pages 165–187.
BERGER, A., PIETRA, V. et PIETRA, S. (1996). A maximum entropy approach to natural language
processing. Computational linguistics, 22(1):39–71.
BUSH, C. (2003). Des déclencheurs des énumérations d’entités nommeés sur le web. Revue
québécoise de linguistique, 32(2):47–81.
CANDITO, M., CRABBÉ, B., DENIS, P. et GUÉRIN, F. (2009). Analyse syntaxique du français : des
constituants aux dépendances. In Actes de la 16e Conférence sur le Traitement Automatique des
Langues Naturelles (TALN 2009), Senlis, France.
CARLSON, L., MARCU, D. et OKUROWSKI, M. (2001). Building a discourse-tagged corpus in the
framework of rhetorical structure theory. In Proceedings of the Second SIGdial Workshop on
Discourse and Dialogue-Volume 16, pages 1–10. Association for Computational Linguistics.
CURRAN, J. et CLARK, S. (2003). Investigating gis and smoothing for maximum entropy taggers.
In Proceedings of the tenth conference on European chapter of the Association for Computational
Linguistics-Volume 1, pages 91–98. Association for Computational Linguistics.
DARROCH, J. et RATCLIFF, D. (1972). Generalized iterative scaling for log-linear models. The
annals of mathematical statistics, 43(5):1470–1480.
FLEISS, J., NEE, J. et LANDIS, J. (1979). Large sample variance of kappa in the case of different
sets of raters. Psychological Bulletin, 86(5):974–977.
GIOVANNETTI, E., MARCHI, S. et MONTEMAGNI, S. (2008). Combining statistical techniques and
lexico-syntactic patterns for semantic relations extraction from text. In Proc. of the 5th Workshop
on Semantic Web Applications and Perspectives. Citeseer.
GIULIANO, C., LAVELLI, A. et ROMANO, L. (2006). Exploiting shallow linguistic information for
relation extraction from biomedical literature. In Proceedings of the eleventh conference of the
European chapter of the association for computational linguistics (EACL-2006), pages 5–7.
HO -DAC, L., FABRE, C., PÉRY-WOODLEY, M., REBEYROLLE, J. et TANGUY, L. (2012). An empi-
rical approach to the signalling of enumerative structures. Discours. Revue de linguistique,
psycholinguistique et informatique, (10).
JAYNES, E. (1957). Information theory and statistical mechanics. Physical review, 106(4):620.
KAMEL, M., MOJAHID, M. et ROTHENBURGER, B. (2012). "quand rédiger c’est décrire" mise en
forme matérielle des textes et construction d’ontologies à partir de textes. Journeés Francophones
d’Ingénierie des Connaissances (IC 2012).
KAMEL, M. et ROTHENBURGER, B. (2011). Elicitation de structures hiérarchiques à partir de
structures enumératives pour la construction d’ontologie. In Journeés Francophones d’Ingénierie
des Connaissances (IC 2011), Annecy.
KOHAVI, R. et al. (1995). A study of cross-validation and bootstrap for accuracy estimation and
model selection. In International joint Conference on artificial intelligence, volume 14, pages
1137–1145. Lawrence Erlbaum Associates Ltd.
LUC, C. (2001). Une typologie des énumérations baseé sur les structures rhétoriques et architec-
turales du texte. In Actes de la 8e Conférence sur le Traitement Automatique des Langues Naturelles
(TALN 2001), pages 263–272.
MORIN, E. (1999). Extraction de liens sémantiques entre termes à partir de corpus de textes
techniques. Thèse de doctorat, Université de Nantes.
NÉDELLEC, C., NAZARENKO, A. et B OSSY, R. (2009). Information extraction. Handbook on
Ontologies, pages 663–685.
PASCUAL, E. et PÉRY-WOODLEY, M. (1995). La définition dans le texte. Textes de type consigne–
Perception, action, cognition, pages 65–88.
PERY-WOODLEY, M. (2001). Modes d’organisation et de signalisation dans des textes procéduraux.
Langages, 35(141):28–46.
RATNAPARKHI, A. (1996). A maximum entropy model for part-of-speech tagging. In Proceedings
of the conference on empirical methods in natural language processing, volume 1, pages 133–142.
Philadelphia, PA.
REBEYROLLE, J., JACQUES, M., PÉRY-WOODLEY, M. et al. (2009). Titres et intertitres dans l’organi-
sation du discours 1. Journal of French Language Studies, 19(2):269.
URIELI, A. et FAUCONNIER, J. (2012). Talismane user manual. CLLE-ERSS, Toulouse.
VIRBEL, J. (1999). Structures textuelles, planches fascicule 1 : Enumérations, version 1,. Rapport
technique, IRIT.
VIRBEL, J., LUC, C., SCHMID, S., CARRIO, L., DOMINGUEZ, C., PERY-WOODLEY, M., JACQUEMIN, C.,
MOJAHID, M., BACCINO, T. et GARCIADEBANC, C. (2005). Approche cognitive de la spatialisation
du langage. de la modélisation de structures spatio-linguistiques des textes à l’expérimentation
psycholinguistique : le cas d’un objet textuel, l’énumération. Agir dans l’espace. Paris : Éditions
de la Maison des sciences de l’homme.
