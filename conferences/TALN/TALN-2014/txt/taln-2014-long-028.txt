[O-S2.3]
21√®me Traitement Automatique des Langues Naturelles, Marseille, 2014
Evaluation d‚Äôune approche de classification possibiliste pour la
d√©sambigu√Øsation des textes arabes

Raja Ayed1 Ibrahim Bounhas2 Bilel Elayeb1, 3 Narj√®s Bellamine Ben Saoud1, 4 Fabrice Evrard5

(1) Laboratoire de recherche RIADI, ENSI, Universit√© de la Manouba, 2010, Tunisie
(2) Laboratoire de l'informatique pour les syst√®mes industriels, Institut Sup√©rieur de Documentation,
Universit√© de la Manouba, 2010,Tunisie
(3) Institut de technologies des √âmirats, P.O. Box: 41009, Abu Dhabi, √âmirats arabes unis
(4) Institut sup√©rieur de l‚Äôinformatique, ISI, Universit√© de Tunis El Manar, 1002, Tunisie
(5) Institut de recherche en informatique de Toulouse (IRIT), 02 rue Camichel, 31071 Toulouse, France
ayed.raja@gmail.com, bounhas.ibrahim@yahoo.fr, bilel.elayeb@riadi.rnu.tn, narjes.bellamine@ensi.rnu.tn,
fabrice.evrard@enseeiht.fr
R√©sum√©.        La d√©sambigu√Øsation morphologique d‚Äôun mot arabe consiste √† identifier l‚Äôanalyse morphologique
appropri√©e correspondante √† ce mot. Dans cet article, nous pr√©sentons trois mod√®les de d√©sambigu√Øsation
morphologique de textes arabes non voyell√©s bas√©s sur la classification possibiliste. Cette approche traite les donn√©es
impr√©cises dans les phases d‚Äôapprentissage et de test, √©tant donn√© que notre mod√®le apprend √† partir de donn√©es non
√©tiquet√©s. Nous testons notre approche sur deux corpus, √† savoir le corpus du Hadith et le Treebank Arabe. Ces corpus
contiennent des donn√©es de types diff√©rents classiques et modernes. Nous comparons nos mod√®les avec des classifieurs
probabilistes et statistiques. Pour ce faire, nous transformons la structure des ensembles d‚Äôapprentissage et de test pour
rem√©dier au probl√®me d‚Äôimperfection des donn√©es.

Abstract.        Morphological disambiguation of Arabic words consists in identifying their appropriate morphological
analysis. In this paper, we present three models of morphological disambiguation of non-vocalized Arabic texts based
on possibilistic classification. This approach deals with imprecise training and testing datasets, as we learn from
untagged texts. We experiment our approach on two corpora i.e. the Hadith corpus and the Arabic Treebank. These
corpora contain data of different types: traditional and modern. We compare our models to probabilistic and statistical
classifiers. To do this, we transform the structure of the training and the test sets to deal with imprecise data.

Mots-cl√©s : Traitement Automatique des Langues Naturelles, D√©sambigu√Øsation Morphologique de l‚ÄôArabe,
Th√©orie des Possibilit√©s, Classification Possibiliste.
Keywords:          Natural Language Processing, Arabic Morphological Disambiguation, Possibility Theory, Possibilistic
Classification.

1        Introduction
De nombreux mots Arabes poss√®dent la m√™me forme orthographique. Ceci est d√ª √† la richesse morphologique de cette
langue (Diab et al., 2004). En effet, l'omission des voyelles courtes peut g√©n√©rer plus de 12 interpr√©tations
morphologiques d'un mot donn√© (Habash et Rambow, 2007). Par cons√©quent, l'une des formes d'ambigu√Øt√© les plus
relev√©es en arabe est l'ambigu√Øt√© morphologique. Un mot peut √™tre ambigu √† l'√©gard de sa structure interne. Le
traitement morphologique porte sur le morph√®me qui constitue l‚Äôunit√© √©l√©mentaire discernable. L'analyse
morphologique d'un mot a pour r√¥le de d√©terminer les valeurs d'un grand nombre de caract√©ristiques ou d‚Äôattributs
morphologiques d‚Äôune entit√© lexicale (un mot), comme la cat√©gorie grammaticale (nom, verbe, etc.), le genre, le
nombre, etc. En fait, un mot non voyell√© peut conduire √† de nombreuses solutions morphologiques. Par exemple, le mot
‚Ä´( ŸàŸÇŸÅ‚Ä¨wqf), en dehors du contexte, peut √™tre interpr√©t√© comme ŸéŸé‚Ä´( ŸéŸàŸÇŸéŸÅ‚Ä¨waqafa, "il s'est lev√©") ou Ÿé‚Ä´( ŸéŸà ŸíŸÇŸÅ‚Ä¨waqfun, "cession") ou
316

[O-S2.3]
Raja Ayed, Ibrahim Bounhas, Bilel Elayeb, Narj√®s Bellamine Ben Saoud et Fabrice Evrard
encore ‚Ä´ŸÅ‚Ä¨ŸéŸí Ÿê‚Ä´( ŸéŸàŸÇ‚Ä¨waqif, "et l√®ve-toi"), o√π ce mot est une concat√©nation de la conjonction ‚Ä´" Ÿà‚Ä¨et" avec le verbe ‚Ä´ŸÅ‚Ä¨
ŸéŸí Ÿê‚Ä´" ŸÇ‚Ä¨se lever"
qui est conjugu√© √† l'imp√©ratif. Malgr√© leur importance, les voyelles courtes ne sont utilis√©es que dans les textes religieux
(Coran, Hadith, etc.) et les manuels didactiques contrairement aux textes modernes trouv√©s dans les journaux et dans les
livres.

L‚Äôambigu√Øt√© morphologique se manifeste lorsque l‚Äôanalyse associe, √† une unit√© lexicale, plusieurs informations non-
conformes au contexte du mot, autrement dit quand l‚Äôanalyse fournit plusieurs valeurs pour certains attributs
morphologiques (Hajic, 2000). Par ailleurs, une approche pour la d√©sambigu√Øsation morphologique arabe est n√©cessaire
pour faire face √† l‚Äôambigu√Øt√© des mots non voyell√©s. La d√©sambigu√Øsation consiste, donc, √† attribuer la valeur exacte
d‚Äôun attribut morphologique parmi celles propos√©es par l‚Äôanalyseur. De nombreux travaux utilisent des approches de
classification pour r√©soudre la t√¢che morphologique de d√©sambigu√Øsation (Roth et al., 2008).

Nous discutons dans ce papier la contribution d'une nouvelle approche pour la d√©sambigu√Øsation morphologique arabe
bas√©e sur la classification possibiliste. Le but principal est d'apprendre des d√©pendances morphologiques √† partir des
textes voyell√©s et de tester sur des textes non voyell√©s. Nous organisons ce document comme suit. Tout d'abord, dans la
section 2, nous pr√©sentons bri√®vement un √©tat de l‚Äôart sur la d√©sambigu√Øsation morphologique arabe. Quant √† la section
3, elle est consacr√©e √† un r√©sum√© sur la th√©orie des possibilit√©s. Notre approche pour la d√©sambigu√Øsation
morphologique possibiliste est d√©taill√©e dans la section 4. Les r√©sultats exp√©rimentaux sont pr√©sent√©s et discut√©s dans la
section 5. Nous concluons, dans la section 6 et nous proposons quelques pistes pour de futures recherches.

2        La d√©sambigu√Øsation morphologique arabe
Plusieurs travaux conduisent la d√©sambigu√Øsation des mots arabes, d‚Äôun texte, √† l‚Äôidentification de leurs cat√©gories gram-
maticales (POS- part-of-speech). La d√©sambigu√Øsation de POS est le fait de d√©terminer la cat√©gorie grammaticale d'un
mot par son utilisation dans un contexte particulier. Elle peut, √©galement, √™tre consid√©r√©e comme un probl√®me de classifi-
cation: l‚Äôensemble des valeurs de POS pr√©sentent les classes et une m√©thode de classification est utilis√©e pour attribuer √†
chaque occurrence d'un mot (analyse d‚Äôun mot) une classe sur la base de la certitude du contexte. L'une des √©tapes impor-
tantes dans la d√©sambigu√Øsation est la s√©lection de la m√©thode de classification. Des m√©thodes de classification automa-
tique supervis√©e ont √©t√© appliqu√©es. Elles utilisent des techniques d'apprentissage pour apprendre un classifieur √† partir
des ensembles d‚Äôapprentissage annot√©s (les valeurs de la classe POS sont identifi√©es). Dans la litt√©rature, les approches de
d√©sambigu√Øsation, se r√©partissent en trois cat√©gories. Principalement, ces approches sont: les approches √† base de r√®gles,
les approches statistiques et les approches hybrides qui combinent les deux derni√®res.

2.1      Les approches √† base de r√®gles

Les approches √† base de r√®gles sont, encore, dites linguistiques. Elles utilisent une base de connaissances des r√®gles
√©crites par des linguistes permettant d'attribuer des √©tiquettes aux diff√©rentes cat√©gories morphologiques (Daoud, 2009 ;
Othman et al., 2004). Nous parlons, principalement, des heuristiques, des r√®gles contextuelles et des r√®gles non
contextuelles (Elshafei et al., 2002). Les arbres de d√©cision (Quinlan, 1986) sont con√ßus pour exposer des bases de
r√®gles. Un arbre de d√©cision est un mod√®le pr√©dictif utilis√© pour repr√©senter les r√®gles de classification avec une
structure en arbre qui partitionne de fa√ßon r√©cursive l‚Äôensemble de donn√©es d'apprentissage. Chaque n≈ìud interne d'un
arbre de d√©cision repr√©sente un test sur une valeur d‚Äôun attribut de classification, et chaque branche repr√©sente un
r√©sultat de test. Une pr√©diction est faite quand un n≈ìud feuille est atteint. Cette approche est √©tendue pour extraire et
calculer des mesures statistiques utilis√©es pour l‚Äô√©tiquetage grammatical (Schmid et al., 1994).

2.2      Les approches statistiques

Les approches statistiques forment des mod√®les d‚Äôapprentissage √† partir des corpus annot√©s. Elles incorporent des
m√©thodes de classification telles que les mod√®les de Markov cach√©s (Garside et Leech, 1987), SVM (Vapnik, 1998), etc.
pour calculer des taux de probabilit√© de chaque valeur r√©sultante d'une cat√©gorie grammaticale d‚Äôun mot. Un mod√®le
peut √™tre utilis√© pour classer automatiquement les autres textes en se r√©f√©rant aux taux d√©j√† calcul√©s. (Diab et al., 2004)
d√©veloppent un classifieur morphologique utilisant SVM. Ils entrainent et testent le classifieur sur un Treebank arabe de
4000 phrases d‚Äôapprentissage et 100 phrases de test. (Habash et Rambow, 2005) utilisent SVM en se basant sur des
informations fournies √† partir d‚Äôun analyseur morphologique. (Mansour et al., 2007) combinent les probabilit√©s
calcul√©es sur des ensembles d‚Äôapprentissage Arabes et H√©breux pour classer les cat√©gories grammaticales des mots des
textes arabes. Ils utilisant les m√™mes param√®tres de test de (Diab et al., 2004). Quelques travaux de recherches
comprennent les mod√®les de Markov cach√©s (HMM). (ElHadj et al., 2009) pr√©sentent un syst√®me d‚Äô√©tiquetage
grammaticale qui combine l‚Äôanalyse morphologique et le mod√®le de Markov. L‚Äô√©tiqueteur se base sur la structure de la
phrase arabe. Dans un premier lieu, le texte est enti√®rement analys√© morphologiquement pour r√©duire le nombre de
valeurs possibles de POS. Dans un second lieu, le mod√®le statistique (HMM), fond√© sur la structure de la phrase arabe,
317

[O-S2.3]
Evaluation d‚Äôune approche de classification possibiliste pour la d√©sambigu√Øsation des textes arabes
est utilis√© pour attribuer √† chaque mot la valeur exacte de sa cat√©gorie grammaticale. (ElHadj et al., 2009) ont utilis√©
leur propre corpus annot√© qui est compos√© de vieux livres arabes. Le total des mots, dans ce corpus, est environ 21000
mots.

2.3      Les approches hybrides

Une approche hybride combine les r√®gles linguistiques avec les informations statistiques afin de r√©soudre l‚Äôambigu√Øt√©
morphologique. Dans (Tlili-Guiassa, 2006), on propose une approche qui analyse les affixes grammaticaux et
flexionnels et les r√®gles grammaticales en se basant sur l‚Äôapproche MBL (Memory based learning) (Lin et al., 1994).
Elle est appliqu√©e pour classer une collection de textes coraniques et √©ducatifs. (Zribi et al., 2006) combinent l'approche
√† base de r√®gles avec un √©tiqueteur trigramme HMM (Collins, 2002). L‚Äôapprentissage du classifieur trigramme a √©t√© fait
sur des textes comportant 6000 mots. Des r√®gles heuristiques ont √©t√© appliqu√©es pour s√©lectionner parmi les r√©sultats
propos√©s.

(Khoja, 2001) a mis en ≈ìuvre une approche hybride qui utilise l‚Äôalgorithme de Viterbi (Forney, 1973; Fettweis et Meyr,
1991). Elle calcule deux probabilit√©s sur un corpus annot√© compos√© de 50000 mots: (i) une probabilit√© lexicale, qui est
la probabilit√© qu'un mot ait une certaine valeur d'un attribut morphologique sp√©cifi√©, et (ii) une probabilit√© contextuelle,
qui est la probabilit√© d'une √©tiquette √† suivre une autre. Une liste de r√®gles grammaticales est pr√©par√©e √† partir de ces
statistiques dans le but d'assurer plus de 90% de pr√©cision.

Les outils de d√©sambigu√Øsation linguistiques sont plus rapides et plus efficaces et fiables que les outils statistiques
(Hoceini et al., 2011). L'approche linguistique qui n'a besoin que de l'intervention manuelle d'un linguiste, d√©finit un
ensemble de r√®gles sp√©cifiques √† un domaine particulier. Alors que, les statistiques calcul√©es pour l‚Äôapprentissage sont
appliqu√©es √† n'importe quel domaine de test. N√©anmoins, les deux approches statistiques et hybrides n√©cessitent une
phase d‚Äôapprentissage dans le but est d‚Äôapprendre les param√®tres requis pour la d√©sambigu√Øsation. Par cons√©quent,
l'approche hybride est consid√©r√©e comme la plus efficace et coh√©rente en termes d'analyse, car elle combine les deux
approches et tire profit de leurs avantages.

La plupart des d√©sambigu√Øseurs morphologiques arabes ne traitent que la cat√©gorie grammaticale (POS). Les travaux
r√©cents (Habash et al., 2009 ; Ayed et al., 2012b) d√©finissent 14 attributs qui d√©crivent les caract√©ristiques
morphologiques d‚Äôun mot. Nous √©tendons, dans cet article, la classification √† ces 14 attributs morphologiques.

3        La th√©orie des possibilit√©s
La th√©orie des possibilit√©s a √©t√© introduite par Zadeh en 1978 pour palier au probl√®me de l‚Äôimperfection des donn√©es et
de l‚Äôincompl√©tude de l‚Äôinformation (Dubois, Prade, 1994). Une information est imparfaite lorsqu‚Äôelle est incertaine
et/ou impr√©cise. Nous d√©crivons, dans les paragraphes suivants, les fonctions, les mesures et les degr√©s utilis√©s pour
traduire l‚Äôincertitude et l‚Äôimpr√©cision des donn√©es dans la th√©orie des possibilit√©s.

3.1      La distribution de possibilit√©

La th√©orie des possibilit√©s est fond√©e sur la notion de distribution des possibilit√©s d√©sign√©e par œÄ. Cette distribution
correspond √† une application de l‚Äôunivers de discours Œ©={œâ1, œâ2,‚Ä¶, œân} vers l‚Äôintervalle [0, 1] mod√©lisant les
connaissances du monde r√©el. Elle distingue les √©tats (les œâi) plausibles et les √©tats peu plausibles. Les valeurs de cette
application sont appel√©es degr√©s de possibilit√©s. Si un degr√© est √©gal √† 1, alors l‚Äô√©tat œâi associ√© est plausible. Toutefois, si
ce degr√© est √©gal √† 0 alors l‚Äô√©tat est dit impossible.

3.2      Les mesures de possibilit√© et de n√©cessit√©

L‚Äôimpr√©cision se manifeste quand un √©tat de la r√©alit√© est d√©crit par une variable propositionnelle de valeurs multiples.
L‚Äôincertitude traduit le fait de ne pas conna√Ætre ou pr√©voir un √©tat de la r√©alit√© pour d√©terminer la valeur de v√©rit√© d‚Äôune
proposition (Dubois et Prade, 1994). Nous √©valuons un √©tat par le calcul de deux mesures qui sont, respectivement, la
possibilit√© et la n√©cessit√©. Nous d√©signons A un sous-ensemble d'√©tats de l'univers du discours Œ©. Nous d√©crivons la
mesure de possibilit√© de A, moyennant une distribution de possibilit√©s œÄ (d√©finie sur Œ©), comme suit:

Œ†(A) = max œÄ(œâ)                                                   (1)
œâ‚ààA
318

[O-S2.3]
Raja Ayed, Ibrahim Bounhas, Bilel Elayeb, Narj√®s Bellamine Ben Saoud et Fabrice Evrard
La mesure de n√©cessit√© est extraite √† partir de la mesure de possibilit√© et elle est d√©crite par:

ÃÖ)
N(A) = min[1 ‚àí œÄ(œâ)] = 1 ‚àí Œ†(A
œâ‚àâA                                                                   (2)
Dans la formule 2, ùê¥ÃÖ d√©finit le compl√©ment de A en d‚Äôautres termes il englobe les √©l√©ments de Œ© qui n‚Äôappartiennent
pas √† A. Œ†(A) √©value le degr√© de consistance de l'√©v√©nement A. N (A) estime dans quelle mesure A est certainement
d√©duit par la connaissance repr√©sent√©e par œÄ. La mesure de n√©cessit√© d√©finit le degr√© auquel on attend l‚Äôoccurrence d‚Äôun
√©v√©nement (Dubois et Prade, 1985).

4         L‚Äôapproche possibiliste de d√©sambigu√Øsation morphologique
Nous proposons une approche de d√©sambigu√Øsation morphologique, des textes arabes, bas√©e sur la th√©orie des
possibilit√©s. Plusieurs travaux utilisent les approches de classification pour r√©soudre l‚Äôambigu√Øt√© morphologique
(Habash et Rambow, 2005). Un mot est consid√©r√© ambigu si l‚Äôanalyseur morphologique fournit plus qu‚Äôune seule
solution pour ses attributs morphologiques. La classification assigne une classe √† une instance de test donn√©e. La t√¢che
de d√©sambigu√Øsation consiste, donc, √† accorder √† un mot ambigu les valeurs des attributs morphologiques appropri√©es.
Elle est divis√©e en deux grandes phases qui sont l‚Äôapprentissage et le test. Les r√©sultats d‚Äôanalyse morphologique donn√©s
par les mots voyell√©s sont, g√©n√©ralement, moins ambigus que ceux donn√©s par les mots non voyell√©s. Ainsi, nous
proposons d‚Äôapprendre √† partir des textes voyell√©s et de tester sur des textes non voyell√©s.

Pour ce faire, nous commen√ßons par d√©finir l‚Äôensemble d‚Äôapprentissage. Cet ensemble est constitu√© d‚Äôune liste
d‚Äôinstances qui sont caract√©ris√©es par des attributs avec des valeurs de classes connues. Par cons√©quent, pour r√©soudre
l'ambigu√Øt√© de la cat√©gorie grammaticale (par exemple), nous d√©terminons d'abord les attributs appropri√©s qui d√©crivent
chaque instance. En nous inspirant de la technique de classification Yamcha (Diab et al., 2004), nous estimons qu‚Äôun
attribut morphologique d‚Äôun mot est fortement li√© √† celui des mots qui le pr√©c√®dent et le suivent. Nous d√©finissons une
fen√™tre qui contr√¥le le nombre de mots (avant et apr√®s) consid√©r√©s comme des attributs d√©crivant la classe d'une
instance. Dans des approches existantes, la taille de la fen√™tre est 2 (Habash et Rambow, 2005). Notre mod√®le applique
une fen√™tre avec une taille quelconque. Pour classer la cat√©gorie grammaticale (POS- part-of-speech) d'un mot
particulier, si la fen√™tre est de 2, nous d√©finissons les attributs POS-2, POS-1, POS+1 et POS+2. Ils indiquent,
respectivement, les cat√©gories grammaticales des deux mots pr√©c√©dents et des deux mots suivants. POS peut √™tre d√©crit
par l'ensemble des autres attributs morphologiques, en plus du POS. Nous pouvons utiliser, par exemple, les attributs
genre-2, genre-1, nombre+1, nombre+2, etc. La valeur de la classe est la cat√©gorie grammaticale du mot courant. A cet
effet, nous identifions, pour chaque mot d‚Äôun texte voyell√©, 14 attributs morphologiques qui sont POS, conjonction,
particule, d√©terminant, pronom, personne, voix, aspect, genre, nombre, cas, pr√©position, mode et adjectif. Ces attributs
sont calcul√©s par l‚Äôanalyseur morphologique Aramorph (Ayed et al., 2012b). Ayant l‚Äôexemple de la phrase suivante
Ÿê Ÿë‚Ä´ÿßÿ≤Ÿä ŸéŸà ŸíÿßŸÑÿ®Ÿé Ÿíÿ∫ÿØŸéÿß ŸêÿØŸä ŸéÿØ Ÿéÿ± Ÿéÿ≥ÿß ŸèÿπŸÑŸèŸà ŸéŸÖ ÿßŸÑÿ∑‚Ä¨
‚Ä´ÿ®‚Ä¨                                             Ÿê ‚Ä´( ÿßŸÑ Ÿéÿ±‚Ä¨Al-Razi et Al-Bagdadi ont √©tudi√© les sciences de la m√©decine), nous d√©terminons,
l‚Äôinstance du tableau 1, associ√©e au mot ¬´‚Ä´( ŸéÿØ Ÿéÿ± Ÿéÿ≥ÿß‚Ä¨ont √©tudi√©)¬ª. Pour cette instance, la classe est la cat√©gorie grammaticale
(POS) et les attributs utilis√©s sont les cat√©gories grammaticales des 2 mots adjacents.

POS-2                       POS-1                       POS+1                    POS+2                    POS

NOM_PROPRE                  NOM_PROPRE                             NOM                     NOM                       VERBE
‚Ä´ÿßÿ≤Ÿä‚Ä¨
Ÿê ‚Ä´( ÿßŸÑ Ÿéÿ±‚Ä¨Al-Razi)  ‚Ä´( ŸéŸà ŸíÿßŸÑÿ®Ÿé Ÿíÿ∫ÿØŸéÿß ŸêÿØŸä‚Ä¨et Al-Bagdadi)       Ÿè Ÿè
‚Ä´( ÿπŸÑŸà ŸéŸÖ‚Ä¨les sciences)   ‚Ä´ÿ®‚Ä¨ Ÿë
Ÿê ‚Ä´( ÿßŸÑÿ∑‚Ä¨de la m√©decine)   ‚Ä´( ŸéÿØ Ÿéÿ± Ÿéÿ≥ÿß‚Ä¨ont √©tudi√©)
TABLEAU 1 : L‚Äôinstance reli√©e au mot ¬´‚Ä´¬ª ŸéÿØ Ÿéÿ± Ÿéÿ≥ÿß‚Ä¨

L‚Äôanalyse morphologique d‚Äôun mot est fournie ind√©pendamment de son contexte. Dans un texte arabe, m√™me les mots
voyell√©s peuvent donner une analyse morphologique ambig√ºe. La forme voyell√©e ¬´‚Ä´ ¬ª ÿ•Ÿêÿ® ŸêŸíŸÜ‚Ä¨fournit des valeurs de l‚Äôattribut
POS √† savoir un verbe (tu construis) et un nom (fils de). Par cons√©quent, les instances d‚Äôapprentissage peuvent fournir
des informations incompl√®tes. Ces informations sont dites impr√©cises lorsque les attributs et ou la classe donnent plus
qu‚Äôune seule valeur.

Nous pouvons affirmer, clairement, que le contexte n√©cessaire pour lever l'ambigu√Øt√© d'un mot donn√© est lui-m√™me
ambigu ce qui est consid√©r√©e comme un cas d'impr√©cision. En effet, la th√©orie des probabilit√©s est incapable de traiter un
tel type de donn√©es (impr√©cises), alors que la th√©orie des possibilit√©s s'applique naturellement √† ces probl√®mes. Nous
proposons des mod√®les d‚Äôapprentissage et de test (classification) bas√©s sur la th√©orie des possibilit√©s.
319

[O-S2.3]
Evaluation d‚Äôune approche de classification possibiliste pour la d√©sambigu√Øsation des textes arabes
4.1      L‚Äôapprentissage possibiliste des attributs morphologiques

Dans la phase d‚Äôapprentissage, nous formons un classificateur pour chaque attribut morphologique. Autrement, nous
instaurons un ensemble d‚Äôapprentissage pour chaque attribut morphologique. Nous obtenons, globalement, 14
ensembles. Chacun est d√©crit par les attributs AM ¬± i o√π AM forme la totalit√© des attributs morphologiques et i constitue
la taille de la fen√™tre. Si cette taille est √©gale √† 2, nous obtenons 56 (14x4) attributs d‚Äôapprentissage. A chaque mot
voyell√© est li√©e une instance d√©crite par les valeurs de ces 56 attributs et dont la classe est reconnue. Cette classe est
l‚Äôattribut morphologique associ√© √† l‚Äôensemble d‚Äôapprentissage.

Nous devons prendre en compte le fait que les attributs et/ou les classes des instances de classification sont impr√©cises
autrement dit ayant plus qu‚Äôune seule valeur possible. L'impr√©cision est g√©r√©e par des distributions de possibilit√©s
d√©sign√©es par œÄ. Soit T un ensemble de donn√©es d‚Äôapprentissage et Ik l'ensemble des valeurs des attributs de l‚Äôinstance k.
On note √©galement Aj le ji√®me attribut de cet ensemble et ajL une valeur possible de Aj. Nous nous inspirons des travaux
de Haouari et al. (Haouari et al., 2009) et le mod√®le de recherche d'information possibiliste d√©velopp√© par Bounhas et al.
(2011) pour calculer la fr√©quence normalis√©e d'une valeur d‚Äôun attribut ajL pour une classe ci comme suit:

ùëÇùëêùëê(ùëéùëóùêø , ùëêùëñ )
ùêπùëüùëíùëû (ùëéùëóùêø , ùëêùëñ ) =                                                         (3)
|Aj |
ùëÄùëéùë•ùëô=1 ùëÇùëêùëê(ùëéùëóùëô , ùëêùëñ )
ùëÇùëêùëê(ùëéùëóùêø , ùëêùëñ ) indique le nombre d‚Äôoccurrences de la classe ci avec la valeur ajL c.√†.d. le nombre d‚Äôinstances dont la classe
est √©gale √† ci et la valeur ajL est une valeur possible de l'attribut Aj. |Aj| est le nombre de valeurs possibles de Aj. Nous
utilisons l'op√©rateur MAX pour obtenir les fr√©quences normalis√©es (Bounhas et al., 2011). La somme de toutes les
fr√©quences associ√©es √† une classe ci n‚Äôest pas √©gale √† 1 ce qui est l'une des principales hypoth√®ses de la th√©orie des
possibilit√©s afin de traiter des donn√©es imparfaites. Dans le cas de l‚Äôimperfection des donn√©es, le nombre d'occurrences
d'une valeur d'un attribut est flou. Nous introduisons une mesure Œ≤jk appel√©e le taux de l‚Äôimpr√©cision de l‚Äôattribut Aj dans
l‚Äôinstance Ik (Haouari et al., 2009). Le nombre d‚Äôoccurrences est calcul√© suivant la formule 4 :

|ùëá|

ùëÇùëêùëê(ùëéùëóùêø , ùëêùëñ ) = ‚àë Œ≤jk ‚àó ‚àÖijkL                                           (4)
ùëò=1

Le taux Œ≤jk = 1/N o√π N est le produit de |Ajk | et |Ck |. Ces derniers repr√©sentent, respectivement, le nombre de valeurs de
Aj dans l‚Äôinstance Ik et le nombre de classes possibles de Ik. Si l‚Äôinstance est parfaite, alors Œ≤jk =1. Si dans une instance
donn√©e, un attribut poss√®de deux valeurs et la classe a une seule valeur alors le taux de l‚Äôimpr√©cision est √©gal √† 0.5. ‚àÖijkL
est √©gale √† 1 si la valeur ajL appartient aux valeurs possibles de Aj dans l‚Äôinstance Ik, et la classe ci appartient aux valeurs
de classes de Ik et 0 sinon.

Les fr√©quences normalis√©es sont calcul√©es pour la totalit√© des instances des diff√©rents ensembles d‚Äôapprentissage. Elles
traduisent les distributions de possibilit√©s de chaque attribut par rapport √† une classe.

4.2      La classification possibiliste des attributs morphologiques

La classification des 14 attributs morphologiques consiste √† d√©sambigu√Øser chaque mot non voyell√© en lui associant les
valeurs correctes et pr√©cises de ces attributs. Pour ce faire, nous commen√ßons par pr√©parer les instances de l‚Äôensemble
de test. En effet, chaque instance d√©crit un mot non voyell√© d‚Äôun texte par des attributs de classification qui repr√©sentent
les m√™mes attributs d‚Äôapprentissage c.√†.d. AM ¬± i. La classe de l‚Äôinstance est la valeur correcte √† identifier de l‚Äôattribut
morphologique. Le tableau 2 d√©crit une instance de test dont l‚Äôattribut morphologique √† classer est le POS. Pour
simplifier la repr√©sentation de l‚Äôinstance, nous nous contentons de 4 attributs de classification √† savoir DET-2, POS-1,
CONJONCTION-1 et POS+2. Elle est r√©ellement d√©crite par les 56 attributs. Cette instance est impr√©cise puisqu‚Äôelle
donne deux valeurs possibles de l‚Äôattribut POS-1.

DETERMINANT-2                    POS-1               CONJONCTION-1                      POS+2           ‚Ä¶             POS
DET                {VERBE;                    NCONJ                             NOM             ‚Ä¶               ?
NOM_PROPRE}
TABLEAU 2 : Un exemple d‚Äôune instance de test impr√©cise
320

[O-S2.3]
Raja Ayed, Ibrahim Bounhas, Bilel Elayeb, Narj√®s Bellamine Ben Saoud et Fabrice Evrard
Nous calculons la possibilit√© de chaque classe ci par rapport √† une instance imparfaite Ik ayant m attributs. Cette mesure
s'inspire du classifieur possibiliste de Haouari et al., (2009). La mesure de possibilit√© est le produit des fr√©quences de
tous les attributs calcul√©es par rapport √† l‚Äôensemble d‚Äôapprentissage. Cependant, un facteur sp√©cifique est ajout√© pour les
attributs impr√©cis. Ce facteur est le taux de l‚Äôimpr√©cision Œ≤jk. Par exemple, si un attribut a quatre valeurs possibles, nous
calculons le produit des fr√©quences de ces quatre valeurs et nous introduisons le taux Œ≤jk √©gal √† ¬º. Ainsi, la mesure de
possibilit√© est donn√©e par la formule 5 :

m |Ajk |

–ü(ci |Ik ) = ‚àè ‚àè ùêπùëüùëíùëû (ùëéùëóùêø , ùëêùëñ ) ‚àó Œ≤jk                                      (5)
j=1 L=1
En se r√©f√©rant √† l‚Äôinstance du tableau 2, si la classe POS poss√®de trois valeurs possibles i.e. NOM, VERBE et
NOM_PROPRE, alors trois mesures de possibilit√©s sont √† calculer par rapport √† cette instance. Ces mesures sont
–ü(POS = NOM|Ik ),      –ü(POS = VERBE|Ik ) et –ü(POS = NOM_PROPRE|Ik ).        Pour     d√©terminer   la  mesure
–ü(POS = NOM|Ik ), les fr√©quences n√©cessaires sont Freq(DETERMINANT-2=DET, POS=NOM), Freq(POS-
1=VERBE, POS=NOM), Freq(POS-1=NOM_PROPRE, POS=NOM), etc. Ces fr√©quences sont calcul√©es dans la phase
d‚Äôapprentissage.

Un classifieur possibiliste a √©t√© d√©fini dans (Ayed et al., 2012a) qui n'√©value pas le pouvoir discriminant des valeurs
d‚Äôun attribut, car il utilise uniquement la mesure de possibilit√© (formule 5). Cependant, nous pouvons d√©couvrir que
certaines valeurs, d'un attribut donn√©, ont un plus grand impact dans la r√©solution de la bonne classe. La th√©orie des
possibilit√©s mod√©lise cet effet par la mesure de n√©cessit√©. Elle d√©termine le degr√© auquel on attend l‚Äôoccurrence d‚Äôun
√©v√©nement (Elayeb et al, 2009). Cette mesure est donn√©e par la formule suivante :

ùëö |Ajk |
ùúÜijL ‚àó ùêπùëüùëíùëû (ùëéùëóùêø , ùëêùëñ )
ùëÅ(ùëêùëñ |Ik ) = 1 ‚àí ‚àè ‚àè (1 ‚àí                                     )                     (6)
Œ≤jk
ùëó=1 L=1
O√π ùù∫ijL = log10(P/nCjL)

Avec P est le nombre de classes possibles et nCjL est le nombre de classes ayant une fr√©quence non nulle avec la valeur
de la valeur ajL ou en d‚Äôautres termes Freq (a jL , ci ) > 0.

Nous d√©finissons trois mod√®les de classification pour d√©terminer la valeur appropri√©e d‚Äôun attribut morphologique. Le
premier mod√®le se base uniquement sur le calcul des mesures de possibilit√©s. Le deuxi√®me mod√®le se base sur les
mesures de n√©cessit√©. Le troisi√®me √©tant une combinaison des deux, il utilise la somme des mesures de possibilit√© et de
n√©cessit√©. La classe choisie correspond √† la valeur c*. La meilleure classe de l'instance Ik est celle ayant le plus grand
score parmi toutes les classes:

c ‚àó = arg max( score (ci |Ik ) ‚àó ùë†ùëêùëúùëüùëí(ci |ùë§ùëò ))                                (23)
ci
Dans cette formule, score (ci | Ik) peut √™tre √©gal √† –ü(ci |Ik ) ou N(ci |Ik ) ou –ü(ci |Ik ) + N(ci |Ik ). Nous introduisons la
score lexical score (ci|wk) (Jurafsky, Martin, 2009). Cette mesure calcule le degr√© de d√©pendance d'un mot wi avec une
classe particuli√®re ci dans l‚Äôensemble d‚Äôapprentissage. Si wi est le mot de l‚Äôinstance de test Ik, alors la possibilit√© lexicale
r√©pond √† la question : si nous nous attendions que ci soit la classe de Ik, quelle est la possibilit√© que le mot soit wi ? De
m√™me ce score peut √™tre calcul√© de trois mani√®res diff√©rentes en utilisant la possibilit√© et/ou la n√©cessit√©.

4.3      La classification non possibiliste des attributs morphologiques

Nous visons √† comparer les r√©sultats de la classification possibiliste avec les r√©sultats donn√©s par des classifieurs non
possibilistes, afin de d√©sambigu√Øser les attributs morphologiques. Ces classifieurs ne traitent pas les donn√©es
imparfaites. Par cons√©quent, nous proposons de transformer la structuration des donn√©es des ensembles d‚Äôapprentissage
et de test, afin de les pr√©parer pour qu‚Äôelles soient utilis√©es par des classifieurs non possibilistes. Les nouveaux attributs
doivent donner des informations pr√©cises. Pour ce faire, nous commen√ßons par pr√©senter un ensemble de donn√©es
imparfaites. La figure 1(a) donne un exemple d'un ensemble d'apprentissage. Nous supposons que la classe √†
d√©sambigu√Øser est POS et que les attributs utilis√©s, pour l‚Äôapprentissage et le test, sont POS-1 et CONJUNCTION+1.
Cet ensemble est compos√© de deux instances. La premi√®re instance est impr√©cise, car elle fournit deux valeurs possibles
de la classe (NOM_PROPRE et VERBE). La deuxi√®me instance est impr√©cise puisqu‚Äôelle fournit deux valeurs de
321

[O-S2.3]
Evaluation d‚Äôune approche de classification possibiliste pour la d√©sambigu√Øsation des textes arabes
l'attribut POS-1 (NOM, VERBE). Nous transformons la structure de donn√©es afin d'obtenir un ensemble parfait sans
perdre les informations qui s‚Äôy trouvent. Pour r√©soudre le probl√®me de l'impr√©cision, nous d√©signons les valeurs, de
l'attribut A, par Ai = {a1, a2, ..., an}. Nous constituons de nouveaux attributs. En effet, nous associons l'attribut A √†
chacune de ses valeurs ai pour former des attributs not√©s "A_ai". Ainsi, l'attribut POS-1 a deux valeurs possibles (NOM
et VERBE) dans l'ensemble de donn√©es de la figure 1. Nous obtenons donc deux attributs POS- 1_NOM et POS-
1_VERBE. Nous accordons, aux nouveaux attributs, des valeurs binaires (oui ou non). Pour une instance donn√©e, si ai
appartient √† une des valeurs de l'attribut, A alors l'attribut "A_ai" est √©gal √† "oui". A partir des donn√©es de la figure 1 (a),
nous formons un nouvel ensemble de donn√©es pr√©cises (voir figure 1 (b)).

Pour r√©soudre l‚Äôimpr√©cision des classes, nous d√©composons une instance en plusieurs ayant chacune une seule valeur de
la classe. Si une instance poss√®de n valeurs possibles de la classe {c1, c2, ‚Ä¶, cn}, alors nous obtenons n instances dont
les valeurs des attributs sont similaires. Nous associons √† chaque instance une valeur ci.

Les instances dont la classe est pr√©cise (ayant une seule valeur) seront dupliqu√©es afin d'augmenter leur poids dans le
calcul des mesures de classification. La figure 1(c) pr√©sente un ensemble de donn√©es parfaites g√©n√©r√©es √† partir des
instances de la figure 1(a). Pour lever l'ambigu√Øt√© des textes non voyell√©s moyennant les approches non possibilistes,
nous utilisons les m√©thodes SVM (Vapnik, 1998), le mod√®le bay√©sien na√Øf (Pearl, 1988) et les arbres de d√©cision
(Quinlan, 1986). Nous alignons les donn√©es au format d‚Äôentr√©e du logiciel WEKA1. Ce logiciel fournit des algorithmes
d‚Äôapprentissage automatique et donne leurs r√©sultats de classification. Nous utilisons WEKA pour classer les attributs
morphologiques selon les mod√®les SVM, les arbres de d√©cision et le mod√®le bay√©sien na√Øf.
POS-1                  CONJONCTION+1                          POS
NOM                       NCONJ                {NOM_PROPRE; VERBE}
{NOM; VERBE}                  CONJ                        NOM
(a) Instances Imparfaites

POS-1_NOM                 POS-1_VERBE            CONJONCTION+1_            CONJONCTION+1_                  POS
CONJ                     NCONJ
Oui                           Non                  Non                             Oui           {NOM_PROPRE;
VERBE}
Oui                           Oui                     Oui                          Non               NOM

(b) Instances dont les attributs sont pr√©cis et les classes sont incertaines

POS-1_NOM           POS-1_VERBE            CONJONCTION+1_CONJ             CONJONCTION+1_NCONJ                   POS
Oui                  Non                       Non                                     Oui              NOM_PROPRE
Oui                  Non                        Non                                  Oui                  VERBE
Oui                   Oui                        Oui                                 Non                   NOM
Oui                   Oui                        Oui                                 Non                   NOM
(c) Instances parfaites

FIGURE 1 : Transformation des instances imparfaites en des instances parfaites

5          Exp√©rimentations
Dans ce paragraphe, nous d√©crivons les corpus utilis√©s pour nos exp√©rimentations. Nous pr√©sentons la m√©thode
d'√©valuation et les r√©sultats exp√©rimentaux mettant en √©vidence les aspects de classification possibiliste et non
possibiliste.

5.1        Les collections de test

L‚Äôobjectif principal de notre approche est d'acqu√©rir des d√©pendances morphologiques √† partir des textes voyell√©s et de
tester sur des textes non voyell√©s. En outre, nous consid√©rons les textes arabes classiques, qui ont √©t√© ignor√©s dans des
travaux connexes pr√©c√©dents. Par cons√©quent, nous utilisons une collection d'histoires arabes "Hadiths" qui a fait le

1
http://weka.wikispaces.com/
322

[O-S2.3]
Raja Ayed, Ibrahim Bounhas, Bilel Elayeb, Narj√®s Bellamine Ben Saoud et Fabrice Evrard
sujet de plusieurs travaux (Bounhas et al., 2011 ; Harrag et al., 2013), etc. Les Hadiths parlent de toutes les
pr√©occupations du monde r√©el et couvrent des connaissances communes et universelles. Pour justifier notre choix, nous
estimons que le corpus de hadiths est l'un des rares corpus arabes voyell√©s. Il contient environ 1400 livres voyell√©s de
hadith, chacun comporte des milliers d‚Äôhistoires arabes. Les six livres les plus reconnus comprennent plus de 2,5
millions de mots et plus de 95 000 fragments (titres et paragraphes). Par ailleurs, ce corpus est bien structur√© et les titres
des chapitres et des sous-chapitres repr√©sentent des informations contextuelles pertinentes pour d√©sambigu√Øser des
textes (Bounhas et al., 2011). Parmi les textes du corpus de hadiths, nous utilisons six livres encyclop√©diques, regroup√©s
par th√®mes, qui sont Sahih Al-Bukhari, Sunan Abi Dawud, Sunan Ettermidhi, Sunan Ibn Majah, Sunan Annasaii et
Sahih Muslim (Ayed et al., 2012a).

Nous menons nos exp√©rimentations √©galement sur le corpus Arabic Treebank (ATB part 2 v2.0) (Maamouri et al.,
2009). Il s'agit d'un corpus de textes arabes non voyell√©s qui a √©t√© produit par Linguistic Data Consortium. Ce corpus
comprend plus de 500 articles du journal √©gyptien Al Oumma. Il contient environ 144K de mots annot√©s (un mot est
annot√© si on indique la valeur de sa cat√©gorie grammaticale).

Les corpus utilis√©s pr√©sentent deux types de textes i.e. modernes et classiques. Pour pouvoir apprendre les d√©pendances
morphologiques du Hadith, nous passons par l‚Äôanalyseur morphologique des textes voyell√©s Aramorph. Cet analyseur
nous fournit les valeurs des 14 attributs morphologiques. L‚Äôannotation du corpus Arabic Treebank nous donne les
valeurs de l‚Äôattribut POS. Le test (ou la classification) se fait directement sur les textes non voyell√©s de Arabic
Treebank. Quant aux textes de Hadith, une √©tape d‚Äô√©limination des voyelles courtes est indispensable pour pouvoir
tester sur des textes non voyell√©s.

Pour √©valuer les r√©sultats des classifications possibilistes et non possibilistes, nous utilisons la m√©thode de la validation
crois√©e (Kohavi, 1995). En effet, nous formons 10 it√©rations pour chaque texte du corpus: 90% d'un texte voyell√© est
utilis√© pour l‚Äôapprentissage et 10% de mots de ce texte seront class√©s apr√®s avoir √©limin√© leurs voyelles courtes.

5.2      Les r√©sultats exp√©rimentaux

Pour classer les 14 attributs morphologiques, nous proc√©dons comme suit : Tout d‚Äôabord nous analysons les textes
voyell√©s de Hadith et nous sauvegardons les solutions morphologiques de chaque attribut. Nous formons, pour tout
attribut morphologique A, un ensemble d‚Äôapprentissage. A chaque mot voyell√© est associ√©e une instance. Les instances
de cet ensemble sont d√©crites par les attributs AM ¬± i (voir section 4.1) et la classe est l‚Äôattribut morphologique A. Nous
aurons 14 ensembles d‚Äôapprentissage. Nous supprimons, par la suite, les voyelles courtes des m√™mes textes. Nous
formons de la m√™me mani√®re des ensembles de test d√©crites par les m√™mes attributs que les ensembles d‚Äôapprentissage.
Les valeurs de classes de leurs instances sont non reconnues (ambig√ºes). Elles constituent les attributs morphologiques
√† classer. Nous d√©sambigu√Øsons, ensuite, chaque mot de ces textes avec nos trois mod√®les de classification possibiliste.
Pour ce faire, nous calculons les mesures de possibilit√© et de n√©cessit√© en se r√©f√©rant aux fr√©quences calcul√©es par
rapport aux ensembles d‚Äôapprentissage (voir section 4). Nous comparons les r√©sultats obtenus avec ceux donn√©s par les
mots voyell√©s. Pour classer les 14 attributs morphologiques en utilisant les classifieurs non possibilistes, nous utilisons
les m√™mes structures des instances d‚Äôapprentissage et de test.

Les approches non-possibilistes ne supportent pas l‚Äôimperfection des donn√©es. Nous les transformons en des donn√©es
parfaites (voir section 4.3) et nous les adaptons au format d‚Äôentr√©e de l‚Äôoutil Weka pour qu‚Äôelles soient appliqu√©es sur
des algorithmes de classification de SVM, Arbres de d√©cision et les classifieurs Bay√©siens Na√Øfs. Le tableau 3 pr√©sente
les taux de d√©sambigu√Øsation des 14 attributs morphologiques.

Les exp√©rimentations prouvent que les classifieurs possibilistes donnent de meilleurs taux de d√©sambigu√Øsation par
rapport aux classifieurs SVM, Bay√©sien Na√Øf et les arbres de d√©cision. Ils en r√©sultent des moyennes de plus de 80%
d‚Äôinstances non voyell√©s correctement class√©es. Certains attributs morphologiques donnent les m√™mes r√©sultats de
classification. Ceci peut √™tre expliqu√© par le fait que les attributs morphologiques associ√©s fournissent peu de nombres
de valeurs de classe (ne d√©passant pas 6 chacune). D‚Äôun autre c√¥t√©, l‚Äôattribut ¬´ PRONOM ¬ª (par exemple) offre environ
64 valeurs de la classe qui peut g√©n√©rer des r√©sultats distincts pour les diff√©rents classifieurs. Parmi les classifieurs
possibilistes, nous remarquons que le mod√®le qui assemble les mesures de possibilit√© et de n√©cessit√© (–ü + N) fournit de
meilleurs r√©sultats (87.43%). Ceci confirme la capacit√© mod√®le possibiliste √† traiter les donn√©es impr√©cises, surtout que
les textes arabes ont un taux d‚Äôambigu√Øt√© √©lev√©.
323

[O-S2.3]
Evaluation d‚Äôune approche de classification possibiliste pour la d√©sambigu√Øsation des textes arabes
Attribut         Classifieur    Arbres de     Classifieur    Classifieur       Classifieur       Classifieur
morphologique       Bay√©sien       d√©cision       SVM          possibiliste      possibiliste      possibiliste
Na√Øf                                     utilisant ùëµ       utilisant –ü       utilisant
–ü+N
POS                  88.62 %        89.58 %       89.98 %         90.17%           91.58 %            90.45%
ADJECTIF             96.51 %        96.51 %       96.51 %         96.86%           97.58%             97.63%
ASPECT               71.20%         71.20%        71.20%          86.20%           81.78%             86.16%
CAS                  56.12 %        56.12%        56.12 %         68.76%           68.40%             76.55%
CONJONCTION          83.03 %        83.03 %       83.03 %         88.66%           95.04%             90.79%
DETERMINANT          64.12%         64.16 %       64.12 %         95.92%           95.25%             96.13%
GENRE                57.15 %        57.15%        57.15 %         90.45%           93.23%             93.78%
MODE                 99.32 %        99.32 %       99.32 %         99.96%           99.93%             99.96%
NOMBRE               85.18 %        85.18 %       85.18 %         87.00%           95.30%             93.25%
PARTICULE            96.65 %        96.65%        96.65 %         98.87%           96.91%             98.87%
PERSONNE             60.22 %        60.22 %       60.22 %         65.07%           66.27%             66.88%
PREPOSITION          82.87 %        82.87%        82.87 %         90.20%           88.60%             95.70%
VOIX                 71.21 %        71.21 %       71.21 %         78.80%           78.75%             79.05%
PRONOM               55.02 %        55.84 %       56.88 %         59.56%           59.10%             58.79%
Moyenne              76.23 %        76.36 %       76.46 %         85.46%           86.27%             87.43%
TABLEAU 3 : Les taux de d√©sambigu√Øsation des attributs morphologiques en utilisant 6 classifieurs possibilistes et non-
possibilistes dans le corpus du Hadith.

Nous essayons de prouver l‚Äôind√©pendance du domaine de nos mod√®les possibilistes. Pour ce faire, nous menons nos
exp√©rimentations sur le corpus Arabic Treebank rassemblant les textes de journaux. Ce corpus donne les r√©sultats de
d√©sambigu√Øsation de l‚Äôattribut POS. A cet effet, les instances des ensembles d‚Äôapprentissage et test seront d√©crites par
les attributs POS-2, POS-1, POS+1 et POS+2 qui repr√©sentent, respectivement, les cat√©gories grammaticales des deux
mots qui suivent et des deux mots qui pr√©c√©dent le mot courant.

Le tableau 4 pr√©sente les taux de d√©sambigu√Øsation de l‚Äôattribut POS pour les deux corpus ¬´ Hadith ¬ª et ¬´ Arabic
Treebank ¬ª donn√©es par les six classifieurs.

Classifieur     Arbres de      Classifieur      Classifieur       Classifieur         Classifieur
Bay√©sien Na√Øf     d√©cision        SVM            possibiliste      possibiliste        possibiliste
utilisant ùëµ       utilisant –ü       utilisant –ü + ùêç
HADITH             88.62 %         89.58 %        89.98 %          90.17%            91.58 %             90.45%

TREEBANK
80.98%         81.85%         81.77%           83.26%             84.23%             83.35%

TABLEAU 4 : Les taux de d√©sambigu√Øsation de la cat√©gorie grammaticale des deux coprus ¬´ Hadith ¬ª et ¬´Arabic
Treebank¬ª

Nous obtenons des r√©sultats proches avec des taux √©lev√©s. Ces r√©sultats r√©v√®lent que l'approche de d√©sambigu√Øsation
possibiliste est ind√©pendante du domaine et de type du texte. Elle fournit des taux raisonnables (plus de 80%) pour les
textes de journaux ainsi que pour les textes de Hadith. Il y a, cependant, une diff√©rence d'environ 7% entre les deux
corpus. Comme les tailles des deux corpus sont presque √©gales, nous pouvons expliquer ce fait par la nature de
l'analyseur morphologique (i.e. Aramorph) dont le lexique est plut√¥t classique. Ainsi, cet outil est incapable d'analyser
certaines entr√©es modernes. Par ailleurs, le corpus du Hadith contient des expressions r√©currentes, qui existent √† la fois
dans les ensembles d‚Äôapprentissage et de test (par exemple "‚Ä´ ; "ÿµŸÑŸâŸéŸáŸÑŸÑÿßŸéÿπŸÑŸäŸáŸéŸàÿ≥ŸÑŸÖ‚Ä¨Paix et la B√©n√©diction soient Sur Lui).

Conclusion et perspectives
Nous avons pr√©sent√©, dans cet article, une nouvelle approche possibiliste pour d√©sambigu√Øser les attributs
morphologiques des textes arabes non voyell√©s. La d√©sambigu√Øsation est consid√©r√©e comme une t√¢che de classification.
A cet √©gard, nous avons d√©fini un classifieur possibiliste pour apprendre et tester des donn√©es impr√©cises. Nous avons
√©tabli trois mod√®les de classification qui calculent, respectivement, les mesures de possibilit√©, de n√©cessit√© et la somme
de ces deux mesures. Nous avons effectu√© une √©tude comparative de ces trois mod√®les de classification possibiliste
avec des classifieurs non-possibilistes pour d√©sambigu√Øser 14 attributs morphologiques. En comparant les r√©sultats des
diff√©rents classifieurs, nous avons conclu que la th√©orie possibiliste a donn√© de meilleurs taux de d√©sambigu√Øsation
quand elle combine les mesures de n√©cessit√© et de possibilit√©.
324

[O-S2.3]
Raja Ayed, Ibrahim Bounhas, Bilel Elayeb, Narj√®s Bellamine Ben Saoud et Fabrice Evrard
Malgr√© ces r√©sultats encourageants, nous avons remarqu√© que notre approche n‚Äôarrive pas √† d√©sambigu√Øser
int√©gralement la totalit√© des attributs morphologiques. Cela peut s'expliquer par un ph√©nom√®ne linguistique connu en
langue Arabe qui se traduit par un ordre relativement al√©atoire des mots dans la phrase (Keskes et al., 2013) et
√©galement par l'incapacit√© de d√©sambigu√Øser les particules qui ont un taux d'ambigu√Øt√© √©lev√©, m√™me dans les textes
voyell√©s. Comme perspectives, nous envisageons de faire face √† ces probl√®mes en adoptant l'une des deux alternatives.
D'une part, nous pouvons agrandir l'ensemble d‚Äôapprentissage. D'autre part, l'int√©gration d‚Äôune analyse linguistique
manuelle dans la phase d‚Äôapprentissage permettra de filtrer les mots vides et de minimiser le taux d‚Äôambigu√Øt√© r√©sultant.
Cependant, nous essaierons de r√©duire le taux d‚Äôintervention, pour √©viter de traiter tout l‚Äôensemble d‚Äôapprentissage √† la
main. Nous visons aussi √† int√©grer notre classifieur dans une application de recherche d'information qui traite des textes
voyell√©s et non voyell√©s, en introduisant une phase primitive de d√©sambigu√Øsation des requ√™tes et des documents. A
cette √©tape, nous pouvons renoncer √† la d√©sambigu√Øsation des particules car elles sont consid√©r√©es comme des mots
vides et ne sont pas utilis√©s pour l'indexation. En outre, les attributs morphologiques calcul√©s par nos outils sont utiles
m√™me pour d'autres niveaux d'analyse √† savoir syntaxiques et s√©mantiques (Bounhas et Slimani, 2009).

R√©f√©rences
AYED R., BOUNHAS I., ELAYEB B., EVRARD F., BENLLAMINE BEN SAOUD N. (2012a). A Possibilistic Approach thfor the
Automatic Morphological Disambiguation of Arabic Texts. In: T. Hochin & R. Lee (Eds.), Proceedings of the 13 ACIS
International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel Distributed
Computing (SNPD), Kyoto, Japan,187-194.

AYED R., BOUNHAS I., ELAYEB B., EVRARD F., BENLLAMINE BEN SAOUD N. (2012b). Arabic Morphological Analysis
and Disambiguation    Using a Possibilistic Classifier. In Intelligent Computing Theories and Applications, Proceedings
of the 8th International Conference on Intelligent Computing (ICIC), China, 274-279.

BOUNHAS I., SLIMANI Y. (2009). A hybrid approach for Arabic multi-word term extraction. In Proceedings of the
International Conference on Natural Language Processing and Knowledge Engineering (NLP-KE), Dalian, China, 1‚Äì8.

BOUNHAS I., ELAYEB B., EVRARD F., SLIMANI Y. (2011). Organizing Contextual Knowledge for Arabic Text
Disambiguation and Terminology Extraction. Knowledge Organization 38(6):473‚Äì490.

COLLINS M. (2002). Discriminative training methods ndfor hidden Markov models: theory and experiments with
perceptron algorithms. In Proceedings of the ACL-2 conference on Empirical methods in natural language
processing, Stroudsburg, PA, USA, 1-8.

DAOUD D. (2009). Synchronized Morphological and Syntactic Disambiguation for Arabic. Advances in Computational
Linguistics 41, 73-86.

DIAB M., HACIOGLU K., JURAFSKY D. (2004). Automatic Tagging of Arabic Text: From Raw Text to Base Phrase
Chunks. In Human Language Technology conference / North American chapter of the Association for Computational
Linguistics annual meeting, Boston, USA, 149-152.

DUBOID D., PRADE H. (1985). h√©orie des possibilit√©s: applications √† la repr√©sentation des connaissances en
informatique. Masson, Paris, France.

DUBOID D., PRADE H. (1994). Possibility Theory: An Approach to computerized Processing of Uncertainty. Plenum
Press, New York, USA.

ELAYEB B., EVRARD F., ZAGHDOUD M., BEN AHMED M. (2009). Towards an intelligent possibilistic web information
retrieval using multiagent system. Interactive Technology and Smart Education 6(1): 40‚Äì59.

ELHADJ Y., AL-SUGHAYEIR I., AL-ANSARI A. (2009). Arabic Part-Of-Speech Tagging using the Sentence Structure.
In: Proceedings of the Second International Conference on Arabic Language Resources and Tools, Cairo, Egypt,
241-245.

ELSHAFEI M., AL-MUHTASEB H., AL-GHAMDI M. (2002). Techniques for high quality Arabic speech synthesis.
Information Sciences 140(3), 255-267.

FETTWEIS G., MEYR H. (1991). High-speed parallel Viterbi decoding: algorithm and VLSI-architecture. IEEE
Communications Magazine, 46- 55.

FORNEY G.D. (1973). The Viterbi algorithm. Proceedings of IEEE 61: 268-278.
325

[O-S2.3]
Evaluation d‚Äôune approche de classification possibiliste pour la d√©sambigu√Øsation des textes arabes

GARSIDE R., LEECH F. (1987). The UCREL probabilistic parsing System. The Computational Analysis of English: A
Corpus-Based Approach, Longman, London, 66-81.

HABASH N., RAMBOW O. (2005). Arabic Tokenization, Part-of-speech Tagging and Morphological Disambiguation in
One Fell Swoop. In: the proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,
Stroudsburg, PA, USA, 573‚Äì580.

HABASH N., RAMBOW O. (2007). Arabic Diacritization Through Full Morphological Tagging. In: Human Language
Technologies: The Conference of the North American Chapter of the Association for Computational Linguistics,
Stroudsburg, PA, USA, 53-56.

HABASH N., RAMBOW O., ROTH R. (2009). Mada+tokan: A toolkit for Arabic tokenization, diacritization, morphological
disambiguation, pos tagging, stemming and lemmatization. In Proceedings of the 2nd International Conference on
Arabic Language Resources and Tools (MEDAR).

HAJIC J. (2000). Morphological Tagging: Data vs. Dictionaries. In: Proceedings of the 1st North American Chapter of
the Association for Computational Linguistics Conference, Stroudsburg, PA, USA, 94-101.

HAOUARI B., BEN AMOR N., ELOUEDI Z., MELLOULI K. (2009). Na√Øve possibilistic network classifiers. Fuzzy Sets and
Systems 160(22): 3224-3238.

HARRAG F., ALOTHAIM A., ABANMY A., ALOMAIGAN F., ALSALEHI S. (2013). Ontology Extraction Approach for
Prophetic Narration (Hadith) using Association Rules. International Journal on Islamic Applications in Computer
Science And Technology 1(2): 48-57.

HOCEINI Y., CHERAGUI M. A., ABBAS M. (2011). Towards a New Approach for Disambiguation in NLP by Multiple
Criterian Decision-Aid. The Prague Bulletin of Mathematical Linguistics 95, 19-32.

JURAFSKY D., MARTIN J.H. (2009). Speech and language processing: an introduction to natural language processing,
computational linguistics, and speech recognition. Pearson Prentice Hall, Upper Saddle River, New Jersey, USA.

KESKES I., BEANAMARA F., HADRICH BELGUITH L. (2013). Segmentation de textes arabes en unit√©s discursives
minimales. TALN-RECITAL, Les sables d‚ÄôOlonne, 435-449.

KHOJA SH. (2001). APT: Arabic part-of-speech tagger. In: Proceedings of Student Workshop at the Second Meeting of
the North American Association for Computational Linguistics, Carnegie Mellon University, Pennsylvania, USA.

KOHAVI R. (1995). Ath Study of Cross-validation and Bootstrap for Accuracy Estimation and Model Selection. In:
Proceedings of the 14 International Joint Conference on Artificial Intelligence, San Francisco, CA, USA, 1137-1143.

LIN J., VITTER S, J., HELLERSTEIN L. (1994). A Theory for Memory-Based Learning. Machine Learning 17(2-3): 143-
167.

MAAMOURI M., BIES A., KULICK S. (2009). Creating a Methodology for Large-Scale Correction of Treebank
Annotation: The Case of the Arabic Treebank. In the proceedings of MEDAR Second International Conference on
Arabic Language Resources and Tools, Cairo, Egypt, 138‚Äì144.

MANSOUR S., SIMA‚ÄôAN K., WINTER Y. (2007). Smoothing a lexicon-based pos tagger for Arabic and Hebrew. ACL07
Workshop on Computational Approaches to Semitic Languages, Prague, Czech, 97-103.

OTHMAN E., SHAALAN K., RAFEA A. (2004). Towards Resolving Ambiguity in Understanding Arabic Sentence. In the
proceedings of International Conference on Arabic Language Resources and Tools, NEMLAR, Egypt, 118-122.

PEARL J. (1988). Probabilistic reasoning in intelligent systems: networks of plausible inference. Probabilistic Reasoning
in Intelligent Systems. Morgan Kaufmman, San Francisco, California, USA.

QUINLAN J. R. (1986). Induction of decision trees. Machine Learning 1(1): 81-106.

ROTH R., RAMBOW O., HABASH N., DIAB M., RUDIN C. (2008). Arabic Morphological Tagging, Diacritization, and
Lemmatization Using Lexeme Models and Feature Ranking. In: Proceedings of the Association for Computational
Linguistics conference (ACL), Columbus, Ohio, USA, 117-120.

SCHMID H. (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings of the International
Conference on New Methods in Language Processing, Manchester, UK, 44-49.
326

[O-S2.3]
Raja Ayed, Ibrahim Bounhas, Bilel Elayeb, Narj√®s Bellamine Ben Saoud et Fabrice Evrard

TLILI-GUIASSA Y. (2006). Hybrid Method for Tagging Arabic Text. Journal of Computer Science 2(3): 245-248.

VAPNIK V. (1998). Statistical Learning Theory. Wiley, New York, USA, 1-736.

ZRIBI C., TORJMEN A., BEN AHMEDth M. (2006). An Efficient Multi-agent System Combining POS-Taggers for
Arabic Texts. In Proceedings of 7 international conference of Computational Linguistics and Intelligent Text
Processing, LNCS Volume 3878, Springer, 121-131.
327
