<!DOCTYPE html>
<html lang="fr">
	<head>
		<meta charset="utf-8">
		<title>RECITAL'2007</title>
		<link rel="stylesheet" href="../../css/style.css">
		<script type="text/javascript">
			function toggle(id) {
				var e = document.getElementById(id);
				if(e.style.display == 'block')
					e.style.display = 'none';
				else
					e.style.display = 'block';
			}
		</script>
	</head>
	<body>
		<div id="container">
			<header>
				<h1><a href="../../index.html">TALN Archives</a></h1>
				<h2>Une archive numérique francophone des articles de recherche en Traitement Automatique de la Langue.</h2>
			</header>

			<section id="info">
				<h1>RECITAL'2007, 9e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues</h1>
				<h2>Toulouse (France), du 2007-06-05 au 2007-06-08</h2>
				<p>Président(s) : Farah Benamara, Sylwia Ozdowska</p>
			</section>

			<nav>
				<h1>Table des matières</h1>
				<ul>
				<li><a href="#long">Papiers longs</a></li>
				<li><a href="#poster">Posters</a></li>
				</ul>
			</nav>

			<section id="content">

				<h1 id="long">Papiers longs</h1>
			

					<div class="article">

						<b>Laurent Mazuel</b>


						<br/>

							<i>Utilisation des ontologies pour la modélisation logique d’une commande en langue naturel</i> <br/>

						<a href="actes/recital-2007-long-001.pdf">recital-2007-long-001</a> 
						<a href="bibtex/recital-2007-long-001.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-long-001-abs');">résumé</a>
							<a onclick="toggle('recital-2007-long-001-key');">mots clés</a> <br/>

							<p id="recital-2007-long-001-abs" class="resume">
							<b>Résumé : </b> Dans cet article, nous nous intéressons à l’interprétation de commandes en langue naturelle pour un agent artificiel. Notre architecture repose sur une modélisation logique de la commande pour l’interprétation sémantique, qui permet de capturer la « structure fonctionnelle » de la phrase, c’est-à-dire les rôles des termes les uns par rapport aux autres. Cet article décrit une méthode d’analyse structurelle de surface qui s’appuie sur l’ontologie de l’agent pour construire cette modélisation logique. Nous définissons tout d’abord un algorithme d’ancrage des termes de la commande dans l’ontologie de l’agent puis nous montrons comment s’en servir pour l’analyse de surface. Enfin, nous expliquons brièvement comment notre modélisation peut être utilisée au moment de l’interprétation sémantique des commandes.
							</p>

							<p id="recital-2007-long-001-key" class="mots_cles">
							<b>Mots clés : </b> commande en langue naturelle, analyse structurelle de surface, modélisation logique, ontologies
							</p>

					</div>
					

					<div class="article">

						<b>Alexia Blanchard</b>


						<br/>

							<i>L’analyse morphologique des réponses d’apprenants</i> <br/>

						<a href="actes/recital-2007-long-002.pdf">recital-2007-long-002</a> 
						<a href="bibtex/recital-2007-long-002.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-long-002-abs');">résumé</a>
							<a onclick="toggle('recital-2007-long-002-key');">mots clés</a> <br/>

							<p id="recital-2007-long-002-abs" class="resume">
							<b>Résumé : </b> Nous présentons une approche empirique de l’évaluation automatique des réponses d’apprenants au sein d’un système d’Apprentissage des Langues Assisté par Ordinateur (ALAO). Nous proposons la mise en place d’un module d’analyse d’erreurs attestées sur corpus qui s’appuie sur des techniques robustes de Traitement Automatique des Langues (TAL). Cet article montre la réalisation d’un module d’analyse de morphologie flexionnelle, en situation hors-contexte, à partir d’un modèle linguistique existant.
							</p>

							<p id="recital-2007-long-002-key" class="mots_cles">
							<b>Mots clés : </b> TAL, ALAO, détection d’erreurs, morphologie flexionnelle, rétroaction(s)
							</p>

					</div>
					

					<div class="article">

						<b>Selja Seppälä</b>


						<br/>

							<i>Repérage automatique de génériques dans les définitions terminographiques</i> <br/>

						<a href="actes/recital-2007-long-003.pdf">recital-2007-long-003</a> 
						<a href="bibtex/recital-2007-long-003.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-long-003-abs');">résumé</a>
							<a onclick="toggle('recital-2007-long-003-key');">mots clés</a> <br/>

							<p id="recital-2007-long-003-abs" class="resume">
							<b>Résumé : </b> Cet article présente une procédure de repérage et de balisage de l’élément générique de la définition terminographique exploitant les caractéristiques formelles du sous-langage définitoire. La procédure, qui comporte quatre étapes, constitue l’une des sous-tâches d’un analyseur (semi-)automatique de la structure conceptuelle des définitions terminographiques, destiné à faciliter l’annotation d’un corpus en vue de l’étude de régularités dans cette structure. La tâche décrite consiste à mettre au point un système d’annotation automatique basé sur le repérage d’indices morphosyntaxiques, sans recourir à d’autres ressources linguistiques informatisées.
							</p>

							<p id="recital-2007-long-003-key" class="mots_cles">
							<b>Mots clés : </b> définition terminographique, annotation automatique, repérage de frontière, indices morphosyntaxiques, sous-langage
							</p>

					</div>
					

					<div class="article">

						<b>François-Régis Chaumartin</b>

						- <span class="important">Prix du Meilleur Papier</span>

						<br/>

							<i>Extraction de paraphrases désambiguïsées à partir d’un corpus d’articles encyclopédiques alignés automatiquement</i> <br/>

						<a href="actes/recital-2007-long-004.pdf">recital-2007-long-004</a> 
						<a href="bibtex/recital-2007-long-004.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-long-004-abs');">résumé</a>
							<a onclick="toggle('recital-2007-long-004-key');">mots clés</a> <br/>

							<p id="recital-2007-long-004-abs" class="resume">
							<b>Résumé : </b> Nous décrivons ici comment enrichir automatiquement WordNet en y important des articles encyclopédiques. Ce processus permet de créer des nouvelles entrées, en les rattachant au bon hyperonyme. Par ailleurs, les entrées préexistantes de WordNet peuvent être enrichies de descriptions complémentaires. La répétition de ce processus sur plusieurs encyclopédies permet de constituer un corpus d’articles comparables. On peut ensuite extraire automatiquement des paraphrases à partir des couples d’articles ainsi créés. Grâce à l’application d’une mesure de similarité, utilisant la hiérarchie de verbes de WordNet, les constituants de ces paraphrases peuvent être désambiguïsés.
							</p>

							<p id="recital-2007-long-004-key" class="mots_cles">
							<b>Mots clés : </b> extraction de paraphrases, fusion d’articles, mesure de similarité, distance sémantique, identification d’hyperonyme, WordNet, Wikipedia, entités nommées, analyse syntaxique, désambiguïsation lexicale, cadres de sous-catégorisation, apprentissage
							</p>

					</div>
					

					<div class="article">

						<b>Anne-Laure Jousse</b>


						<br/>

							<i>Extension de l&#39;encodage formel des fonctions lexicales dans le cadre de la Lexicologie Explicative et Combinatoire</i> <br/>

						<a href="actes/recital-2007-long-005.pdf">recital-2007-long-005</a> 
						<a href="bibtex/recital-2007-long-005.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-long-005-abs');">résumé</a>
							<a onclick="toggle('recital-2007-long-005-key');">mots clés</a> <br/>

							<p id="recital-2007-long-005-abs" class="resume">
							<b>Résumé : </b> Dans les ressources dictionnairiques développées à partir du cadre théorique de la Lexicologie Explicative et Combinatoire telles que le DiCo, les relations sémanticolexicales sont modélisées au moyen de fonctions lexicales. Cependant, seulement la majorité d&#39;entre elles (dites standard) répondent véritablement à un encodage formel. Les autres (dites non standard), représentant des relations plus spécifiques à certaines unités lexicales, sont écrites sous la forme d&#39;un encodage hétérogène et très peu formalisé. Par conséquent, certaines relations ne peuvent entrer en ligne de compte dans les traitements automatiques. Nous proposons dans cet article une méthodologie pour la normalisation des fonctions lexicales non standard afin de les rendre exploitables dans des applications telles que l&#39;analyse et la génération de texte. Pour ce faire, nous discutons certains principes théoriques associés à ce formalisme de description et esquissons des propositions pour un traitement global et homogène de l&#39;ensemble des relations décrites dans le DiCo.
							</p>

							<p id="recital-2007-long-005-key" class="mots_cles">
							<b>Mots clés : </b> Fonctions lexicales (non standard), modélisation des relations sémanticolexicales, DiCo
							</p>

					</div>
					

					<div class="article">

						<b>Ali Choumane</b>


						<br/>

							<i>Traitement de désignations orales dans un contexte visuel</i> <br/>

						<a href="actes/recital-2007-long-006.pdf">recital-2007-long-006</a> 
						<a href="bibtex/recital-2007-long-006.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-long-006-abs');">résumé</a>
							<a onclick="toggle('recital-2007-long-006-key');">mots clés</a> <br/>

							<p id="recital-2007-long-006-abs" class="resume">
							<b>Résumé : </b> Nous nous intéressons aux systèmes multimodaux qui utilisent les modes et modalités suivantes : l’oral (et le langage naturel) en entrée et en sortie, le geste en entrée et le visuel en sortie par affichage sur écran. L’usager échange avec le système par un geste et/ou un énoncé oral en langue naturelle. Dans cet échange, encodé sur les différentes modalités, se trouvent l’expression du but de l’usager et la désignation des objets (référents) nécessaires à la réalisation de ce but. Le système doit identifier de manière précise et non ambiguë les objets désignés par l’usager. Nous traitons plus spécialement dans cet article les désignations orales, sans geste, des objets dans le contexte visuel. En effet, l’ensemble du contexte multimodal, dont le mode visuel, influe sur la production de l’entrée de l’usager. Afin d’identifier une désignation produite en s’appuyant sur le contexte visuel, nous proposons un algorithme qui utilise des connaissances « classiques » linguistiques, des connaissances sur les objets manipulés, et des connaissances sur les aspects perceptifs (degré de saillance) associés à ces objets.
							</p>

							<p id="recital-2007-long-006-key" class="mots_cles">
							<b>Mots clés : </b> communication homme machine multimodale, référence, saillance
							</p>

					</div>
					

					<div class="article">

						<b>Laurianne Sitbon</b>


						<br/>

							<i>Combinaison de ressources linguistiques pour l’aide à l’accès lexical : étude de faisabilité</i> <br/>

						<a href="actes/recital-2007-long-007.pdf">recital-2007-long-007</a> 
						<a href="bibtex/recital-2007-long-007.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-long-007-abs');">résumé</a>
							<a onclick="toggle('recital-2007-long-007-key');">mots clés</a> <br/>

							<p id="recital-2007-long-007-abs" class="resume">
							<b>Résumé : </b> Cet article propose une évaluation combinée et comparative de 5 ressources (descriptive, paradigmatique et syntagmatiques) pour l’aide à l’accès lexical en situation de &#34;mot sur le bout de la langue&#34;, en vue de la création d’un outil utilisant la combinaison de ces ressources. En situation de &#34;mot sur le bout de la langue&#34;, l’utilisateur n’accède plus au mot qu’il veut dire ou écrire mais est capable d’en produire d’autres sémantiquement associés. L’évaluation se base sur un corpus de 20 mots &#34;sur le bout de la langue&#34; pour lesquels on dispose de 50 groupes de 5 associations sémantiques effectuées par des utilisateurs. Les résultats montrent que les ressources sont complémentaires et peu redondantes. De plus au moins une association proposée parmi les 5 permettrait de retrouver le mot &#34;sur le bout de la langue&#34; dans 79% des cas, à condition de le sélectionner parmi les 2500 mot potentiels. Enfin, les résultats montrent des disparités entre les utilisateurs, ce qui permettrait de définir des profils d’utilisateur pour une amélioration des performances.
							</p>

							<p id="recital-2007-long-007-key" class="mots_cles">
							<b>Mots clés : </b> réseaux sémantiques, accès lexical, profil d’utilisateur
							</p>

					</div>
					

					

					

					

					

					

					

					

					

					

				<h1 id="poster">Posters</h1>
			

					

					

					

					

					

					

					

					<div class="article">

						<b>Alejandro Acosta</b>


						<br/>

							<i>Vers une nouvelle structuration de l’information extraite automatiquement</i> <br/>

						<a href="actes/recital-2007-poster-001.pdf">recital-2007-poster-001</a> 
						<a href="bibtex/recital-2007-poster-001.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-poster-001-abs');">résumé</a>
							<a onclick="toggle('recital-2007-poster-001-key');">mots clés</a> <br/>

							<p id="recital-2007-poster-001-abs" class="resume">
							<b>Résumé : </b> Les systèmes d’Extraction d’Information se contentent, le plus souvent, d’enrichir des bases de données plates avec les informations qu’ils extraient. Nous décrivons dans cet article un travail en cours sur l’utilisation de données extraites automatiquement pour la construction d’une structure de représentation plus complexe. Cette structure modélise un réseau social composé de relations entre les entités d’un corpus de biographies.
							</p>

							<p id="recital-2007-poster-001-key" class="mots_cles">
							<b>Mots clés : </b> extraction d’information, analyse de réseaux sociaux, biographies, entités nommées, représentation de connaissances
							</p>

					</div>
					

					<div class="article">

						<b>Aurélien Bossard</b>


						<br/>

							<i>Vers une ressource prédicative pour l’extraction d’information</i> <br/>

						<a href="actes/recital-2007-poster-002.pdf">recital-2007-poster-002</a> 
						<a href="bibtex/recital-2007-poster-002.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-poster-002-abs');">résumé</a>
							<a onclick="toggle('recital-2007-poster-002-key');">mots clés</a> <br/>

							<p id="recital-2007-poster-002-abs" class="resume">
							<b>Résumé : </b> Cet article présente une méthode pour construire, à partir d’une ressource lexicale prédicative existante, une ressource enrichie pouvant servir à une tâche d’extraction. Nous montrons les points forts et les lacunes de deux ressources existantes pour le Français : les Tables du LADL et Volem. Après avoir montré pourquoi nous avons sélectionné Volem, nous listons les données nécessaires à la tâche d’extraction d’information. Nous présentons le processus d’enrichissement de la ressource initiale et une évaluation, à travers une tâche d’extraction d’information concernant des textes de rachats d’entreprise.
							</p>

							<p id="recital-2007-poster-002-key" class="mots_cles">
							<b>Mots clés : </b> ressource prédicative, extraction d’information, patrons lexico-syntaxiques
							</p>

					</div>
					

					<div class="article">

						<b>François Bouchet</b>


						<br/>

							<i>Caractérisation d’un corpus de requêtes d’assistance</i> <br/>

						<a href="actes/recital-2007-poster-003.pdf">recital-2007-poster-003</a> 
						<a href="bibtex/recital-2007-poster-003.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-poster-003-abs');">résumé</a>
							<a onclick="toggle('recital-2007-poster-003-key');">mots clés</a> <br/>

							<p id="recital-2007-poster-003-abs" class="resume">
							<b>Résumé : </b> Afin de concevoir un agent conversationnel logiciel capable d’assister des utilisateurs novices d’applications informatiques, nous avons été amenés à constituer un corpus spécifique de requêtes d’assistance en français, et à étudier ses caractéristiques. Nous montrons ici que les requêtes d’assistance se distinguent nettement de requêtes issues d’autres corpus disponibles dans des domaines proches. Nous mettons également en évidence le fait que ce corpus n’est pas homogène, mais contient au contraire plusieurs activités conversationnelles distinctes, dont l’assistance elle-même. Ces observations nous permettent de discuter de l’opportunité de considérer l’assistance comme un registre particulier de la langue générale.
							</p>

							<p id="recital-2007-poster-003-key" class="mots_cles">
							<b>Mots clés : </b> corpus de requêtes d’assistance, agent conversationnel, activité conversationnelle, actes de dialogue
							</p>

					</div>
					

					<div class="article">

						<b>Romain Brixtel</b>


						<br/>

							<i>Extraction endogène d’une structure de document pour un alignement multilingue</i> <br/>

						<a href="actes/recital-2007-poster-004.pdf">recital-2007-poster-004</a> 
						<a href="bibtex/recital-2007-poster-004.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-poster-004-abs');">résumé</a>
							<a onclick="toggle('recital-2007-poster-004-key');">mots clés</a> <br/>

							<p id="recital-2007-poster-004-abs" class="resume">
							<b>Résumé : </b> Pour des raisons variées, diverses communautés se sont intéressées aux corpus multilingues. Parmi ces corpus, les textes parallèles sont utilisés aussi bien en terminologie, lexicographie ou comme source d’informations pour les systèmes de traduction par l’exemple. L’Union Européenne, qui a entraîné la production de document législatif dans vingtaine de langues, est une des sources de ces textes parallèles. Aussi, avec le Web comme vecteur principal de diffusion de ces textes parallèles, cet objet d’étude est passé à un nouveau statut : celui de document. Cet article décrit un système d’alignement prenant en compte un grand nombre de langues simultanément (&gt; 2) et les caractéristiques structurelles des documents analysés.
							</p>

							<p id="recital-2007-poster-004-key" class="mots_cles">
							<b>Mots clés : </b> alignement multilingue, corpus parrallèles, multitextes, multidocuments, extraction de structures, alignement endogène
							</p>

					</div>
					

					<div class="article">

						<b>Sarra El Ayari</b>


						<br/>

							<i>Évaluation transparente de systèmes de questions-réponses : application au focus</i> <br/>

						<a href="actes/recital-2007-poster-005.pdf">recital-2007-poster-005</a> 
						<a href="bibtex/recital-2007-poster-005.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-poster-005-abs');">résumé</a>
							<a onclick="toggle('recital-2007-poster-005-key');">mots clés</a> <br/>

							<p id="recital-2007-poster-005-abs" class="resume">
							<b>Résumé : </b> Les campagnes d’évaluation ne tiennent compte que des résultats finaux obtenus par les systèmes de recherche d’informations (RI). Nous nous situons dans une perspective d’évaluation transparente d’un système de questions-réponses, où le traitement d’une question se fait grâce à plusieurs composants séquentiels. Dans cet article, nous nous intéressons à l’étude de l’élément de la question qui porte l’information qui se trouvera dans la phrase réponse à proximité de la réponse elle-même : le focus. Nous définissons ce concept, l’appliquons au système de questions-réponses QALC, et démontrons l’utilité d’évaluations des composants afin d’augmenter la performance globale du système.
							</p>

							<p id="recital-2007-poster-005-key" class="mots_cles">
							<b>Mots clés : </b> système de questions-réponses, recherche d’information, évaluation, focus
							</p>

					</div>
					

					<div class="article">

						<b>Marion Laignelet, Christophe Pimm</b>


						<br/>

							<i>La segmentation thématique TextTiling comme indice pour le repérage de segments d&#39;information évolutive dans un corpus de textes encyclopédiques</i> <br/>

						<a href="actes/recital-2007-poster-006.pdf">recital-2007-poster-006</a> 
						<a href="bibtex/recital-2007-poster-006.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-poster-006-abs');">résumé</a>
							<a onclick="toggle('recital-2007-poster-006-key');">mots clés</a> <br/>

							<p id="recital-2007-poster-006-abs" class="resume">
							<b>Résumé : </b> Nous faisons l&#39;hypothèse que les bornes délimitées par la méthode statistique TextTiling peuvent servir d&#39;indices qui, cumulées à des indices de nature linguistique, permettront de repérer automatiquement des segments d&#39;informations évolutives. Ce travail est développé dans le cadre d&#39;un projet industriel plus général dont le but est le repérage automatique de zones textuelles contenant de l&#39;information potentiellement évolutive.
							</p>

							<p id="recital-2007-poster-006-key" class="mots_cles">
							<b>Mots clés : </b> segments d&#39;information évolutive, segmentation, algorithme TextTiling
							</p>

					</div>
					

					<div class="article">

						<b>Marie Piu, Rémi Bove</b>


						<br/>

							<i>Annotation des disfluences dans les corpus oraux</i> <br/>

						<a href="actes/recital-2007-poster-007.pdf">recital-2007-poster-007</a> 
						<a href="bibtex/recital-2007-poster-007.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-poster-007-abs');">résumé</a>
							<a onclick="toggle('recital-2007-poster-007-key');">mots clés</a> <br/>

							<p id="recital-2007-poster-007-abs" class="resume">
							<b>Résumé : </b> Les disfluences (répétitions, amorces, autocorrections, constructions inachevées, etc.) inhérentes à toute production orale spontanée constituent une réelle difficulté en termes d’annotation. En effet, l’annotation de ces phénomènes se révèle difficilement automatisable dans la mesure où leur étude réclame un jugement éminemment interprétatif. Dans cet article, nous présentons une méthodologie applicable à l’annotation des disfluences (ou « phénomènes de production ») que l’on rencontre fréquemment dans les corpus oraux. Le fait de constituer un tel corpus de données annotées, permet non seulement de représenter certains aspects pertinents de l’oral (de manière à servir de base aux observations et aux comparaisons avec d’autres données) mais aussi d’améliorer in fine le traitement automatique de l’oral (notamment l’analyse syntaxique automatique).
							</p>

							<p id="recital-2007-poster-007-key" class="mots_cles">
							<b>Mots clés : </b> corpus oraux, annotation, disfluences, prosodie, XML
							</p>

					</div>
					

					<div class="article">

						<b>Vladimir Popescu</b>


						<br/>

							<i>Architecture modulaire portable pour la génération du langage naturel en dialogue homme-machine</i> <br/>

						<a href="actes/recital-2007-poster-008.pdf">recital-2007-poster-008</a> 
						<a href="bibtex/recital-2007-poster-008.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-poster-008-abs');">résumé</a>
							<a onclick="toggle('recital-2007-poster-008-key');">mots clés</a> <br/>

							<p id="recital-2007-poster-008-abs" class="resume">
							<b>Résumé : </b> La génération du langage naturel pour le dialogue oral homme-machine pose des contraintes spécifiques, telles que la spontanéité et le caractère fragmenté des énoncés, les types des locuteurs ou les contraintes de temps de réponse de la part du système. Dans ce contexte, le problème d’une architecture rigoureusement spécifiée se pose, autant au niveau des étapes de traitement et des modules impliqués, qu’au niveau des interfaces entre ces modules. Afin de permettre une liberté quasi-totale à l’égard des démarches théoriques, une telle architecture doit être à la fois modulaire (c’est-à-dire, permettre l’indépendance des niveaux de traitement les uns des autres) et portable (c’est-à-dire, permettre l’interopérabilité avec des modules conçus selon des architectures standard en génération du langage naturel, telles que le modèle RAGS - « Reference Architecture for Generation Systems »). Ainsi, dans cet article on présente de manière concise l’architecture proposée, la comparant ensuite au modèle RAGS, pour argumenter les choix opérés en conception. Dans un second temps, la portabilité de l’architecture sera décrite à travers un exemple étendu, dont la généralité réside dans l’obtention d’un ensemble de règles permettant de plonger automatiquement les représentations des informations de notre architecture vers le format du modèle RAGS et inversement. Finalement, un ensemble de conclusions et perspectives clôturera l’article.
							</p>

							<p id="recital-2007-poster-008-key" class="mots_cles">
							<b>Mots clés : </b> génération, dialogue, architecture modulaire, portabilité, XML
							</p>

					</div>
					

					<div class="article">

						<b>Alain Régnier</b>


						<br/>

							<i>Résolution anaphorique intégrée à une analyse automatique de discours d’un corpus oral retranscrit</i> <br/>

						<a href="actes/recital-2007-poster-009.pdf">recital-2007-poster-009</a> 
						<a href="bibtex/recital-2007-poster-009.bib">bibtex</a> 
							<a onclick="toggle('recital-2007-poster-009-abs');">résumé</a>
							<a onclick="toggle('recital-2007-poster-009-key');">mots clés</a> <br/>

							<p id="recital-2007-poster-009-abs" class="resume">
							<b>Résumé : </b> Nous présentons une résolution anaphorique intégrée à une analyse automatique de discours. Cette étude traite des anaphores pronominales et des anaphores zéro. Notre analyse est basée sur trois approches : une analyse basée sur les contraintes, une analyse fonctionnelle et une analyse dynamique. Pour évaluer la faisabilité et la fiabilité de notre approche, nous l’avons expérimentée sur un corpus de 97 histoires produites à l’oral par des enfants. Nous présentons le résultat de cette évaluation.
							</p>

							<p id="recital-2007-poster-009-key" class="mots_cles">
							<b>Mots clés : </b> analyse de discours, résolution anaphorique, anaphore pronominales, anaphores zéro, grammaires de propriétés, grammaire fonctionnelle, analyse dynamique, discours oral
							</p>

					</div>
					


			</section>

			<footer>
				&copy; <a href="http://www.florianboudin.org">Florian Boudin</a>
			</footer>
			
		</div>
	</body>
</html>