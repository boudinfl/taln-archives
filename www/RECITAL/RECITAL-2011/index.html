<!DOCTYPE html>
<html lang="fr">
	<head>
		<meta charset="utf-8">
		<title>RECITAL'2011</title>
		<link rel="stylesheet" href="../../css/style.css">
		<script type="text/javascript">
			function toggle(id) {
				var e = document.getElementById(id);
				if(e.style.display == 'block')
					e.style.display = 'none';
				else
					e.style.display = 'block';
			}
		</script>
	</head>
	<body>
		<div id="container">
			<header>
				<h1><a href="../../index.html">TALN Archives</a></h1>
				<h2>Une archive numérique francophone des articles de recherche en Traitement Automatique de la Langue.</h2>
			</header>

			<section id="info">
				<h1>RECITAL'2011, 13e Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues</h1>
				<h2>Montpellier (France), du 2011-06-27 au 2011-07-01</h2>
				<p>Président(s) : Cédric Lopez</p>
				<p>Taux d'acceptation :
							papiers longs (62.5%)
							papiers courts (66.7%)
				</p>
			</section>

			<nav>
				<h1>Table des matières</h1>
				<ul>
				<li><a href="#long">Papiers longs</a></li>
				<li><a href="#court">Papiers courts</a></li>
				</ul>
			</nav>

			<section id="content">

				<h1 id="long">Papiers longs</h1>
			

					<div class="article">

						<b>Fanny Lalleman</b>


						<br/>

							<i>Analyse de l’ambiguïté des requêtes utilisateurs par catégorisation thématique</i> <br/>

						<a href="actes/recital-2011-long-001.pdf">recital-2011-long-001</a> 
						<a href="bibtex/recital-2011-long-001.bib">bibtex</a> 
							<a onclick="toggle('recital-2011-long-001-abs');">résumé</a>
							<a onclick="toggle('recital-2011-long-001-key');">mots clés</a> <br/>

							<p id="recital-2011-long-001-abs" class="resume">
							<b>Résumé : </b> Dans cet article, nous cherchons à identifier la nature de l’ambiguïté des requêtes utilisateurs issues d’un moteur de recherche dédié à l’actualité, 2424actu.fr, en utilisant une tâche de catégorisation. Dans un premier temps, nous verrons les différentes formes de l’ambiguïté des requêtes déjà décrites dans les travaux de TAL. Nous confrontons la vision lexicographique de l’ambiguïté à celle décrite par les techniques de classification appliquées à la recherche d’information. Dans un deuxième temps, nous appliquons une méthode de catégorisation thématique afin d’explorer l’ambiguïté des requêtes, celle-ci nous permet de conduire une analyse sémantique de ces requêtes, en intégrant la dimension temporelle propre au contexte des news. Nous proposons une typologie des phénomènes d’ambiguïté basée sur notre analyse sémantique. Enfin, nous comparons l’exploration par catégorisation à une ressource comme Wikipédia, montrant concrètement les divergences des deux approches.
							</p>

							<p id="recital-2011-long-001-key" class="mots_cles">
							<b>Mots clés : </b> recherche d’information, ambiguïté, classification de requêtes
							</p>

					</div>
					

					<div class="article">

						<b>Boutheina Smine, Rim Faiz, Jean-Pierre Desclés</b>


						<br/>

							<i>Extraction Automatique d&#39;Informations Pédagogiques Pertinentes à partir de Documents Textuels</i> <br/>

						<a href="actes/recital-2011-long-002.pdf">recital-2011-long-002</a> 
						<a href="bibtex/recital-2011-long-002.bib">bibtex</a> 
							<a onclick="toggle('recital-2011-long-002-abs');">résumé</a>
							<a onclick="toggle('recital-2011-long-002-key');">mots clés</a> <br/>

							<p id="recital-2011-long-002-abs" class="resume">
							<b>Résumé : </b> Plusieurs utilisateurs ont souvent besoin d&#39;informations pédagogiques pour les intégrer dans leurs ressources pédagogiques, ou pour les utiliser dans un processus d&#39;apprentissage. Une indexation de ces informations s&#39;avère donc utile en vue d&#39;une extraction des informations pédagogiques pertinentes en réponse à une requête utilisateur. La plupart des systèmes d&#39;extraction d&#39;informations pédagogiques existants proposent une indexation basée sur une annotation manuelle ou semi-automatique des informations pédagogiques, tâche qui n&#39;est pas préférée par les utilisateurs. Dans cet article, nous proposons une approche d&#39;indexation d&#39;objets pédagogiques (Définition, Exemple, Exercice, etc.) basée sur une annotation sémantique par Exploration Contextuelle des documents. L&#39;index généré servira à une extraction des objets pertinents répondant à une requête utilisateur sémantique. Nous procédons, ensuite, à un classement des objets extraits selon leur pertinence en utilisant l&#39;algorithme Rocchio. Notre objectif est de mettre en valeur une indexation à partir de contextes sémantiques et non pas à partir de seuls termes linguistiques.
							</p>

							<p id="recital-2011-long-002-key" class="mots_cles">
							<b>Mots clés : </b> extraction d’informations, objets pédagogiques, carte sémantique, exploration contextuelle, algorithme Rocchio
							</p>

					</div>
					

					<div class="article">

						<b>Nikola Tulechki</b>


						<br/>

							<i>Des outils de TAL en support aux experts de sûreté industrielle pour l’exploitation de bases de données de retour d’expérience</i> <br/>

						<a href="actes/recital-2011-long-003.pdf">recital-2011-long-003</a> 
						<a href="bibtex/recital-2011-long-003.bib">bibtex</a> 
							<a onclick="toggle('recital-2011-long-003-abs');">résumé</a>
							<a onclick="toggle('recital-2011-long-003-key');">mots clés</a> <br/>

							<p id="recital-2011-long-003-abs" class="resume">
							<b>Résumé : </b> Cet article présente des applications d’outils et méthodes du traitement automatique des langues (TAL) à la maîtrise du risque industriel grâce à l’analyse de données textuelles issues de volumineuses bases de retour d’expérience (REX). Il explicite d’abord le domaine de la gestion de la sûreté, ses aspects politiques et sociaux ainsi que l’activité des experts en sûreté et les besoins qu’ils expriment. Dans un deuxième temps il présente une série de techniques, comme la classification automatique de documents, le repérage de subjectivité, et le clustering, adaptées aux données REX visant à répondre à ces besoins présents et à venir, sous forme d’outils, en support à l’activité des experts.
							</p>

							<p id="recital-2011-long-003-key" class="mots_cles">
							<b>Mots clés : </b> REX, rapport d’incident, risque, sûreté industrielle, signaux faibles, classification automatique, clustering, recherche d’information, similarité, subjectivité
							</p>

					</div>
					

					<div class="article">

						<b>Charlotte Roze</b>

						- <span class="important">Prix du Meilleur Papier</span>

						<br/>

							<i>Vers une algèbre des relations de discours pour la comparaison de structures discursives</i> <br/>

						<a href="actes/recital-2011-long-004.pdf">recital-2011-long-004</a> 
						<a href="bibtex/recital-2011-long-004.bib">bibtex</a> 
							<a onclick="toggle('recital-2011-long-004-abs');">résumé</a>
							<a onclick="toggle('recital-2011-long-004-key');">mots clés</a> <br/>

							<p id="recital-2011-long-004-abs" class="resume">
							<b>Résumé : </b> Nous proposons une méthodologie pour la construction de règles de déduction de relations de discours, destinées à être intégrées dans une algèbre de ces relations. La construction de ces règles a comme principal objectif de pouvoir calculer la fermeture discursive d’une structure de discours, c’est-à-dire de déduire toutes les relations que la structure contient implicitement. Calculer la fermeture des structures discursives peut permettre d’améliorer leur comparaison, notamment dans le cadre de l’évaluation de systèmes d’analyse automatique du discours. Nous présentons la méthodologie adoptée, que nous illustrons par l’étude d’une règle de déduction.
							</p>

							<p id="recital-2011-long-004-key" class="mots_cles">
							<b>Mots clés : </b> Relation de discours, fermeture discursive, évaluation, déduction
							</p>

					</div>
					

					<div class="article">

						<b>Prajol Shrestha</b>


						<br/>

							<i>Alignment of Monolingual Corpus by Reduction of the Search Space</i> <br/>

						<a href="actes/recital-2011-long-005.pdf">recital-2011-long-005</a> 
						<a href="bibtex/recital-2011-long-005.bib">bibtex</a> 
							<a onclick="toggle('recital-2011-long-005-abs');">résumé</a>
							<a onclick="toggle('recital-2011-long-005-key');">mots clés</a> <br/>

							<p id="recital-2011-long-005-abs" class="resume">
							<b>Résumé : </b> Les corpus comparables monolingues, alignés non pas au niveau des documents mais au niveau d’unités textuelles plus fines (paragraphe, phrases, etc.), sont utilisés dans diverses applications de traitement automatique des langues comme par exemple en détection de plagiat. Mais ces types de corpus ne sont pratiquement pas disponibles et les chercheurs sont donc obligés de les construire et de les annoter manuellement, ce qui est un travail très fastidieux et coûteux en temps. Dans cet article, nous présentons une méthode, composée de deux étapes, qui permet de réduire ce travail d’annotation de segments de texte. Cette méthode est évaluée lors de l’alignement de paragraphes provenant de dépêches en langue anglaise issues de diverses sources. Les résultats obtenus montrent un apport considérable de la méthode en terme de réduction de temps d’annotation. Nous présentons aussi des premiers résultats obtenus à l’aide de simples traitements automatiques (recouvrement de mots, de racines, mesure cosinus) pour tenter de diminuer encore la charge de travail humaine.
							</p>

							<p id="recital-2011-long-005-key" class="mots_cles">
							<b>Mots clés : </b> corpus comparable monolingue, alignement, similarité
							</p>

					</div>
					

					

					

					

					

				<h1 id="court">Papiers courts</h1>
			

					

					

					

					

					

					<div class="article">

						<b>Prajol Shrestha</b>


						<br/>

							<i>Corpus-Based methods for Short Text Similarity</i> <br/>

						<a href="actes/recital-2011-court-001.pdf">recital-2011-court-001</a> 
						<a href="bibtex/recital-2011-court-001.bib">bibtex</a> 
							<a onclick="toggle('recital-2011-court-001-abs');">résumé</a>
							<a onclick="toggle('recital-2011-court-001-key');">mots clés</a> <br/>

							<p id="recital-2011-court-001-abs" class="resume">
							<b>Résumé : </b> Cet article concerne la détermination de la similarité entre des textes courts (phrases, paragraphes, ...). Ce problème est souvent abordé dans la littérature à l’aide de méthodes supervisées ou de ressources externes comme le thesaurus Wordnet ou le British National Corpus. Les méthodes que nous proposons sont non supervisées et n’utilisent pas de connaissances à priori. La première méthode que nous présentons est basée sur le modèle vectoriel de Salton auquel nous avons apporté des modifications pour prendre en compte le contexte, le sens et la relation entre les mots des textes. Dans un deuxième temps, nous testons les mesures de Dice et de ressemblance pour résoudre ce problème ainsi que l’utilisation de la racinisation. Enfin, ces différentes méthodes sont évaluées et comparées aux résultats obtenus dans la littérature.
							</p>

							<p id="recital-2011-court-001-key" class="mots_cles">
							<b>Mots clés : </b> Similarité, Modèle Vectoriel, Mesure de Similarité
							</p>

					</div>
					

					<div class="article">

						<b>Inga Gheorghita</b>


						<br/>

							<i>Ressources lexicales au service de recherche et d’indexation des images</i> <br/>

						<a href="actes/recital-2011-court-002.pdf">recital-2011-court-002</a> 
						<a href="bibtex/recital-2011-court-002.bib">bibtex</a> 
							<a onclick="toggle('recital-2011-court-002-abs');">résumé</a>
							<a onclick="toggle('recital-2011-court-002-key');">mots clés</a> <br/>

							<p id="recital-2011-court-002-abs" class="resume">
							<b>Résumé : </b> Cet article présente une méthodologie d’utilisation du Trésor de la Langue Française informatisée (TLFi) pour l’indexation et la recherche des images fondée sur l’annotation textuelle. Nous utilisons les définitions du TLFi pour la création automatique et l’enrichissement d’un thésaurus à partir des mots-clés de la requête de recherche et des mots-clés attribués à l’image lors de l’indexation. Plus précisement il s’agit d’associer, de façon automatisé, à chaque mot-clé de l’image une liste des mots extraits de ses définitions TLFi pour un domaine donné, en construisant ainsi un arbre hiérarchique. L’approche proposée permet une catégorisation très précise des images, selon les domaines, une indexation de grandes quantités d’images et une recherche rapide.
							</p>

							<p id="recital-2011-court-002-key" class="mots_cles">
							<b>Mots clés : </b> TLFi, indexation, recherche, images, thésaurus
							</p>

					</div>
					

					<div class="article">

						<b>Mathias Lambert</b>


						<br/>

							<i>Repérer les phrases évaluatives dans les articles de presse à partir d’indices et de stéréotypes d’écriture</i> <br/>

						<a href="actes/recital-2011-court-003.pdf">recital-2011-court-003</a> 
						<a href="bibtex/recital-2011-court-003.bib">bibtex</a> 
							<a onclick="toggle('recital-2011-court-003-abs');">résumé</a>
							<a onclick="toggle('recital-2011-court-003-key');">mots clés</a> <br/>

							<p id="recital-2011-court-003-abs" class="resume">
							<b>Résumé : </b> Ce papier présente une méthode de recherche des phrases évaluatives dans les articles de presse économique et financière à partir de marques et d’indices stéréotypés, propres au style journalistique, apparaissant de manière concomitante à l’expression d’évaluation(s) dans les phrases. Ces marques et indices ont été dégagés par le biais d’une annotation manuelle. Ils ont ensuite été implémentés, en vue d’une phase-test d’annotation automatique, sous forme de grammaires DCG/GULP permettant, par filtrage, de matcher les phrases les contenant. Les résultats de notre première tentative d’annotation automatique sont présentés dans cet article. Enfin les perspectives offertes par cette méthode relativement peu coûteuse en ressources (à base d’indices non intrinsèquement évaluatifs) font l’objet d’une discussion.
							</p>

							<p id="recital-2011-court-003-key" class="mots_cles">
							<b>Mots clés : </b> Opinion, évaluation, repérage de phrases évaluatives, presse économique et financière, style journalistique, indices/marques/stéréotypes d’écriture
							</p>

					</div>
					

					<div class="article">

						<b>Adrien Barbaresi</b>


						<br/>

							<i>La complexité linguistique Méthode d’analyse</i> <br/>

						<a href="actes/recital-2011-court-004.pdf">recital-2011-court-004</a> 
						<a href="bibtex/recital-2011-court-004.bib">bibtex</a> 
							<a onclick="toggle('recital-2011-court-004-abs');">résumé</a>
							<a onclick="toggle('recital-2011-court-004-key');">mots clés</a> <br/>

							<p id="recital-2011-court-004-abs" class="resume">
							<b>Résumé : </b> La complexité linguistique regroupe différents phénomènes dont il s’agit de modéliser le rapport. Le travail en cours que je décris ici propose une réflexion sur les approches linguistiques et techniques de cette notion et la mise en application d’un balayage des textes qui s’efforce de contribuer à leur enrichissement. Ce traitement en surface effectué suivant une liste de critères qui représentent parfois des approximations de logiques plus élaborées tente de fournir une image ``raisonnable&#39;&#39; de la complexité.
							</p>

							<p id="recital-2011-court-004-key" class="mots_cles">
							<b>Mots clés : </b> Complexité, lisibilité, allemand, analyse de surface
							</p>

					</div>
					


			</section>

			<footer>
				&copy; <a href="http://www.florianboudin.org">Florian Boudin</a>
			</footer>
			
		</div>
	</body>
</html>